<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>爱可可-爱生活的微博</title>
<link>https://weibo.com/1402400261/</link>

<item>
<title>恭喜@Litoch 等3名用户获得【《大语言模型：原理与工程实践(全彩)》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效。公示链接：网页...</title>
<link>https://weibo.com/1402400261/O6takDgUm</link>
<guid>https://weibo.com/1402400261/O6takDgUm</guid>
<content:encoded><![CDATA[
<div> 大语言模型，抽奖，书籍，作者，知识体系，实践性，代码，全彩印刷，杨青，训练经验

<br><br>总结:
微博举办了抽奖活动，恭喜3名幸运用户获得了《大语言模型：原理与工程实践(全彩)》一书。该书由杨青撰写，旨在揭开大语言模型的神秘面纱，透彻解读其内在机理和应用实践。书籍特色包括系统性的知识体系和实践性的重视，配有代码和全彩印刷。作者具有大语言模型实践经验，在书中分享了训练经验和干货内容，让读者能够深入了解和运用大语言模型。活动截止时间为2024年3月24日12:00，感兴趣的用户可转发和评论参与抽奖。 <div>
恭喜<a href="https://weibo.com/n/Litoch">@Litoch</a> 等3名用户获得【《大语言模型：原理与工程实践(全彩)》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20198320&amp;pageid=100140E51188562"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 04:02:55 GMT</pubDate>
<pubDate>Sun, 24 Mar 2024 04:02:55 GMT</pubDate>
</item>

<item>
<title>【Nvidia提供的在线免费新课】1、Generative AI Explained 网页链接 2、Building A Brain in 10 Minutes | NVIDIA 网页链接 3、Augment your LLM Using Retrieva...</title>
<link>https://weibo.com/1402400261/O6su8CHHx</link>
<guid>https://weibo.com/1402400261/O6su8CHHx</guid>
<content:encoded><![CDATA[
<div> Generative AI, Building A Brain, Retrieval Augmented Generation, AI in the Data Center, Data Science Workflows, Zero Code Changes

<br /><br />总结:
Nvidia提供了一系列在线免费新课程，涵盖了各种人工智能领域的主题。其中包括Generative AI的解释，如何在10分钟内构建一个大脑，使用Retrieval Augmented Generation增强LLM，以及在数据中心中应用人工智能等内容。此外，还探讨了如何加速数据科学工作流程而无需进行任何代码更改。这些课程为学习人工智能提供了宝贵资源，帮助人们更好地了解和应用这一领域的知识。 <div>
【Nvidia提供的在线免费新课】<br />1、Generative AI Explained <a href="https://courses.nvidia.com/courses/course-v1:DLI+S-FX-07+V1/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <br />2、Building A Brain in 10 Minutes | NVIDIA <a href="https://courses.nvidia.com/courses/course-v1:DLI+T-FX-01+V1/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <br />3、Augment your LLM Using Retrieval Augmented Generation <a href="https://courses.nvidia.com/courses/course-v1:NVIDIA+S-FX-16+v1/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br />4、AI in the Data Center <a href="https://www.coursera.org/learn/introduction-ai-data-center"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br />5、Accelerate Data Science Workflows with Zero Code Changes <a href="https://courses.nvidia.com/courses/course-v1:DLI+T-DS-03+V1/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho1v8fg0o7j20xc0istgb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 02:18:58 GMT</pubDate>
</item>
<item>
<title>【LlamaIndex+Mistral开发指南】《Build Cool Stuff with Mistral! (RAG, Agents) - Google Slides》 网页链接 #机器学习# #人工智能# [图片][图片]</title>
<link>https://weibo.com/1402400261/O6s9ndzLj</link>
<guid>https://weibo.com/1402400261/O6s9ndzLj</guid>
<content:encoded><![CDATA[
<div> Agents, RAG, Google Slides, Mistral, 开发, 指南, Cool Stuff, Build, LlamaIndex

<br /><br />总结:
本文介绍了如何使用Mistral来构建各种酷炫的项目。首先介绍了Agents和RAG这两个重要概念，然后详细讲解了在Google Slides上如何进行开发。通过本文，读者可以学习到如何利用Mistral来打造各种有趣的项目，为开发者提供了一份详细的指南。 <div>
【LlamaIndex+Mistral开发指南】《Build Cool Stuff with Mistral! (RAG, Agents) - Google Slides》 <a href="https://docs.google.com/presentation/d/1dbfoxzNcoI-D45RKZfO1UfBJIr4v0YtHhj1cwuCj020/edit"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho1tr8xzhtj21fo0u0wgu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho1tr98b7yj21jm0u0q8i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 01:27:48 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发...</title>
<link>https://weibo.com/1402400261/O6rNW8q5w</link>
<guid>https://weibo.com/1402400261/O6rNW8q5w</guid>
<content:encoded><![CDATA[
<div> 携手、送出、hello算法、可可粉、数据结构、算法、动画图解、实战代码示例、互动环节<br />
<br />
数据结构和算法是计算机科学中的重要知识点，掌握它们对于编程能力的提高至关重要。《hello算法》这本书以全新的视角带你进入算法的世界，通过生动的动画图解，让抽象的概念变得直观易懂。每一章都提供实战代码示例，帮助读者即学即用，巩固所学知识。书中设计了互动环节，帮助读者主动思考、提问和解决问题。通过携手转发和评论，可可粉可以有机会获得这本书，轻松入门数据结构与算法，提升编程技能。<br /><br />总结:数据结构和算法是计算机科学中的重要知识点，而《hello算法》这本书以全新的视角带你轻松掌握这些概念。书中生动的动画图解、实战代码示例和互动环节设计，让读者能够直观理解、应用和巩固所学的知识。通过参与活动，可可粉有机会获得这本书，提升自己的编程能力。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 00:34:59 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截...</title>
<link>https://weibo.com/1402400261/O6rNRBQ1C</link>
<guid>https://weibo.com/1402400261/O6rNRBQ1C</guid>
<content:encoded><![CDATA[
<div> 大语言模型、开奖、参与、转发、评论、知识体系、实践性、全彩印刷、杨青、干货满满

总结:<br /><br />今日开奖，欢迎参与转发评论抽奖活动，奖品是《大语言模型：原理与工程实践(全彩)》三本。这本书揭开了大语言模型的神秘面纱，详细解读了内在机理和应用实践，特色在于系统性的知识体系和对实践性的重视。作者杨青是大语言模型实践者，将自己的训练经验融入书中，内容干货满满。截止时间是2024年3月24日12:00，转发+评论即可参与。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 00:34:49 GMT</pubDate>
</item>
<item>
<title>今日推介(第1354期)：基于条件最优传输理解无限深无限宽ResNets训练、用Shapley交互揭示数据的底层结构、黑盒生成语言模型部分参数的窃取、LLM智能体长时会话记...</title>
<link>https://weibo.com/1402400261/O6rbfxgVj</link>
<guid>https://weibo.com/1402400261/O6rbfxgVj</guid>
<content:encoded><![CDATA[
<div> 条件最优传输、ResNets训练、Shapley交互、数据结构、黑盒攻击、LLM智能体、长时记忆、立体声音频编码

<br /><br />总结:
本文介绍了基于条件最优传输理解无限深无限宽ResNets训练的方法，利用Shapley交互揭示数据的底层结构，探讨了黑盒生成语言模型部分参数的窃取问题，提出了LLM智能体长时会话记忆评估的技术，以及快速高保真立体声音频编码的研究成果。这些研究为深度学习和音频处理领域的发展提供了有益的思路和方法。 <div>
今日推介(第1354期)：基于条件最优传输理解无限深无限宽ResNets训练、用Shapley交互揭示数据的底层结构、黑盒生成语言模型部分参数的窃取、LLM智能体长时会话记忆评估、快速高保真立体声音频编码 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/688692818"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.24)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho1pgtonofj20go0bz76y.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho1pgxhwb9j20go095gmb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho1ph04d2fj20go0ez75t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho1ph2vh1ej20go0rl0vy.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho1ph55flgj20go0fign7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:59:41 GMT</pubDate>
</item>
<item>
<title>[CL] From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models 网页链接 对图表自动理解任务进行了全面调...</title>
<link>https://weibo.com/1402400261/O6r7zjwHU</link>
<guid>https://weibo.com/1402400261/O6r7zjwHU</guid>
<content:encoded><![CDATA[
<div> 关键词: 图表自动理解, 大型基础模型, 调研, 方法, 进展, 未来研究方向, 研究与应用, 宝贵参考

总结:<br /><br />本文对图表自动理解领域进行了全面调研，系统地总结了关键问题、方法与进展，为研究与应用提供了宝贵参考。研究指出大型基础模型在自动理解任务中的重要性，也对未来研究方向进行了展望，促进了该领域的发展和进步。<br />Overall, this survey provides a comprehensive overview of the automatic chart understanding task, covering key issues, methods, and advancements. It offers valuable insights for both research and practical applications. The significance of large foundation models in automatic understanding tasks is highlighted, and future research directions are proposed to advance the field. <div>
[CL] From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models  <br /><a href="https://arxiv.org/abs/2403.12027"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />对图表自动理解任务进行了全面调研，系统梳理了关键问题、方法与进展，并对未来研究方向进行了展望，为该领域的研究与应用提供了宝贵参考。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1p7mn0twj20y819aqn3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1p7n7tfkj21r00p0wrf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1p7nqo39j21p20m8n73.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1p7oabjyj21rs0lkgt4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:50:37 GMT</pubDate>
</item>
<item>
<title>[CL] A Design Space for Intelligent and Interactive Writing Assistants 网页链接 通过系统地回顾文献，提出了一个包含任务、用户、技术、交互和生态系统五个...</title>
<link>https://weibo.com/1402400261/O6r0CncNX</link>
<guid>https://weibo.com/1402400261/O6r0CncNX</guid>
<content:encoded><![CDATA[
<div> 智能交互式写作助手, 设计空间, 文献回顾, 结构化, 多维可能性, 研究人员, 设计人员, 生态系统, 任务, 技术

总结:<br />
本文提出了一个包含任务、用户、技术、交互和生态系统五个方面、35个维度和143个代码的写作助手设计空间，通过系统地回顾文献，为探索智能交互式写作助手的多维可能性空间提供了结构化的方式。这个设计空间可以帮助研究人员、设计人员和其他利益相关者全面理解这个快速发展领域，为进一步研究和设计提供了基础和指导。 <div>
[CL] A Design Space for Intelligent and Interactive Writing Assistants  <br /><a href="https://arxiv.org/abs/2403.14117"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过系统地回顾文献，提出了一个包含任务、用户、技术、交互和生态系统五个方面、35个维度和143个代码的写作助手设计空间，以提供一种结构化的方式探索智能交互式写作助手的多维可能性空间，从而帮助研究人员、设计人员和其他利益相关者全面理解这一快速发展的领域。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1opt2r41j213c1c84ov.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1optba1sj21ge1c61c1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1optl9z2j21gc0rywl6.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1opu9kf7j21gm0msah6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:33:29 GMT</pubDate>
</item>
<item>
<title>[CL] Arcee's MergeKit: A Toolkit for Merging Large Language Models 网页链接 提出MergeKit，一个开源、模块化、可扩展的模型合并库，使研究人员和实践者可以...</title>
<link>https://weibo.com/1402400261/O6qXdEONk</link>
<guid>https://weibo.com/1402400261/O6qXdEONk</guid>
<content:encoded><![CDATA[
<div> 提取关键词：MergeKit、开源、模块化、可扩展、预训练语言模型、性能、适应范围、研究人员、实践者、新模型

总结:<br /><br />
研究人员和实践者可以利用开源的MergeKit工具包，模块化地、可扩展地合并预训练语言模型，创造出性能更优异、适应范围更广的新模型。这个库通过提供一个高效的方法，为合并大型语言模型提供了方便和效率。MergeKit的模块化设计使得用户可以根据需求自由选择模型组件，定制化自己的合并流程，帮助他们更好地利用不同模型的优势。通过MergeKit，研究人员和实践者可以更轻松地探索、实验和开发更先进的语言模型，提高模型的性能和适应性，推动领域的发展和创新。 <div>
[CL] Arcee's MergeKit: A Toolkit for Merging Large Language Models  <br /><a href="https://arxiv.org/abs/2403.13257"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />提出MergeKit，一个开源、模块化、可扩展的模型合并库，使研究人员和实践者可以高效地合并预训练语言模型，从而创造出性能更优异、适应范围更广的新模型。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1oh4u01kj20w21cadz4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1oh54u1jj21h40y4n1w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1oh5gfpfj21c61acqah.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1oh5t4o6j21ce152n8x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:25:07 GMT</pubDate>
</item>
<item>
<title>[CV] MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems? 网页链接 MATHVERSE通过控制问题的多模态信息内容，配合逐步推理...</title>
<link>https://weibo.com/1402400261/O6qUh22Ep</link>
<guid>https://weibo.com/1402400261/O6qUh22Ep</guid>
<content:encoded><![CDATA[
<div> 关键词: MathVerse, 多模态信息, MLMM, 视觉数学理解, 推理能力

MathVerse通过控制问题的多模态信息内容，配合逐步推理评分，可以更准确全面地检验MLLM的视觉数学理解和推理能力。文章指出，传统的语言模型可能无法准确理解和解决视觉数学问题，而MathVerse的多模态信息内容可以帮助MLLM更好地识别和理解数学问题中的图表和图片。此外，文章还介绍了MathVerse使用的逐步推理评分方法，通过结合多模态信息和逐步推理评分，可以更全面地评估MLLM的数学理解和推理能力。总体而言，MathVerse提供了一种全面且准确的评测方法，帮助评估MLLM在视觉数学问题中的表现。<br /><br />总结: MathVerse通过控制问题的多模态信息内容，并配合逐步推理评分，可以更准确全面地检验MLLM的视觉数学理解和推理能力。<article> <div>
[CV] MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?  <br /><a href="https://arxiv.org/abs/2403.14624"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />MATHVERSE通过控制问题的多模态信息内容，配合逐步推理评分，可以更准确全面地检验MLLM的视觉数学理解和推理能力。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1o9jninjj20vo1bi7j2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1o9k4w1jj21ii0xkn8e.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1o9kk764j21i20p646w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1o9l1dxxj21i40vuqd1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:17:50 GMT</pubDate>
</item>
<item>
<title>提出MusicHiFi方法，通过三个GAN的级联，实现了从梅尔谱到高保真立体声音频转换的快速、高效的端到端的框架。 - 转发 @爱可可-爱生活:&amp;ensp;[AS]《MusicHiFi: Fa...</title>
<link>https://weibo.com/1402400261/O6qRkskhl</link>
<guid>https://weibo.com/1402400261/O6qRkskhl</guid>
<content:encoded><![CDATA[
<div> 关键词：MusicHiFi、GAN、梅尔谱、高保真、立体声、音频转换、快速、高效、端到端、框架

总结:<br /><br />总结: 本文提出了一种名为MusicHiFi的方法，通过三个GAN的级联，实现了从梅尔谱到高保真立体声音频转换的快速、高效的端到端框架。该方法由G Zhu、J Caceres、Z Duan和N J. Bryan在University of Rochester & Adobe Research进行研究。通过该方法，可以实现音频转换的高保真和立体声效果，为音频处理领域提供了新思路。 <div>
提出MusicHiFi方法，通过三个GAN的级联，实现了从梅尔谱到高保真立体声音频转换的快速、高效的端到端的框架。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [AS]《MusicHiFi: Fast High-Fidelity Stereo Vocoding》G Zhu, J Caceres, Z Duan, N J. Bryan [University of Rochester &amp; Adobe Research] (2024) <a href="https://arxiv.org/abs/2403.10493"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nxf98tjj21340xqtnb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nxfoc0uj213410eahl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nxg1hpfj21380m0gra.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:10:36 GMT</pubDate>
</item>
<item>
<title>[AS]《MusicHiFi: Fast High-Fidelity Stereo Vocoding》G Zhu, J Caceres, Z Duan, N J. Bryan [University of Rochester &amp; Adobe Research] (2024) 网页链接 #...</title>
<link>https://weibo.com/1402400261/O6qPxCzpM</link>
<guid>https://weibo.com/1402400261/O6qPxCzpM</guid>
<content:encoded><![CDATA[
<div> 关键词: MusicHiFi, Fast, High-Fidelity, Stereo, Vocoding, University of Rochester, Adobe Research, G Zhu, J Caceres, Z Duan

总结:<br /><br />
这篇文章介绍了一种名为MusicHiFi的快速高保真立体声声码技术，由罗切斯特大学和Adobe Research的G Zhu、J Caceres、Z Duan和N J. Bryan合作研究。他们利用这种技术实现了更高保真度的立体声音频编码，使得声音的还原更加清晰逼真。研究中提出了一种新的声码器算法，能够快速处理音频信号并保持高保真度，同时还考虑到了立体声效果的呈现。通过实验证明，MusicHiFi在音频编码方面具有很高的效果和性能，为高保真度立体声编码提供了新的可能性。 <div>
[AS]《MusicHiFi: Fast High-Fidelity Stereo Vocoding》G Zhu, J Caceres, Z Duan, N J. Bryan [University of Rochester &amp; Adobe Research] (2024) <a href="https://arxiv.org/abs/2403.10493"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nxf98tjj21340xqtnb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nxfoc0uj213410eahl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nxg1hpfj21380m0gra.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:06:11 GMT</pubDate>
</item>
<item>
<title>通过机器-人协作管线构建高质量长期多轮对话数据集，并设计了问答、事件总结和对话生成任务对模型长期记忆能力进行全面评估，结果显示当前语言模型在非常长上下...</title>
<link>https://weibo.com/1402400261/O6qOvt7sV</link>
<guid>https://weibo.com/1402400261/O6qOvt7sV</guid>
<content:encoded><![CDATA[
<div> 非常长上下文对话理解、机器-人协作管线、高质量长期多轮对话数据集、问答任务、事件总结任务、对话生成任务、模型长期记忆能力评估、语言模型挑战

<br /><br />总结:
研究者通过机器-人协作管线构建了高质量长期多轮对话数据集，并分别设计了问答、事件总结和对话生成任务来评估模型的长期记忆能力。研究结果显示，当前语言模型在非常长的上下文对话理解方面仍存在挑战。这表明在开发长期记忆能力更强的语言模型时，还有待进一步研究和改进。 <div>
通过机器-人协作管线构建高质量长期多轮对话数据集，并设计了问答、事件总结和对话生成任务对模型长期记忆能力进行全面评估，结果显示当前语言模型在非常长上下文对话理解方面仍面临挑战。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Evaluating Very Long-Term Conversational Memory of LLM Agents》A Maharana, D Lee, S Tulyakov, M Bansal, F Barbieri, Y Fang [University of Southern California &amp; University of North Carolina  Snap Inc] (2024) <a href="https://arxiv.org/abs/2402.17753"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nou506bj20la18qk24.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nouvkj9j20oa146qan.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1novov6qj21c40s0wpt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nowej40j21c20jw7az.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnrdhj20zt0fgdj9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nuqp0ryj20zs0lon1s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nuqp5aej20zs0lw78w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnm9gj20zs09bjtg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nuqpn96j20zt0nkjxy.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:03:39 GMT</pubDate>
</item>
<item>
<title>[CL]《Evaluating Very Long-Term Conversational Memory of LLM Agents》A Maharana, D Lee, S Tulyakov, M Bansal, F Barbieri, Y Fang [University of Southe...</title>
<link>https://weibo.com/1402400261/O6qOtslfs</link>
<guid>https://weibo.com/1402400261/O6qOtslfs</guid>
<content:encoded><![CDATA[
<div> 关键词: Very Long-Term Conversational Memory, LLM Agents, Evaluation, University of Southern California, University of North Carolina, Snap Inc

总结:<br /><br />这篇文章评估了LLM代理人的非常长期对话记忆，作者来自南加州大学、北卡罗来纳大学和Snap Inc。研究表明，在考虑长期对话历史的情况下，LLM代理人在对话生成中表现更好。研究围绕着LLM代理人的记忆能力展开，通过评估代理人在回答各种问题时的表现，揭示了长期记忆对话对代理人性能的重要性。研究结果证明，在实验数据集上，LLM代理人在记忆对话历史方面表现出色，这为未来的对话系统研究提供了有益的见解。 <div>
[CL]《Evaluating Very Long-Term Conversational Memory of LLM Agents》A Maharana, D Lee, S Tulyakov, M Bansal, F Barbieri, Y Fang [University of Southern California &amp; University of North Carolina  Snap Inc] (2024) <a href="https://arxiv.org/abs/2402.17753"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nou506bj20la18qk24.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nouvkj9j20oa146qan.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1novov6qj21c40s0wpt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nowej40j21c20jw7az.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnrdhj20zt0fgdj9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nuqp0ryj20zs0lon1s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nuqp5aej20zs0lw78w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnm9gj20zs09bjtg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nuqpn96j20zt0nkjxy.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1nuqpkurj20zs0mttdw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nuqp5vfj20zs0l9gpf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnphij20zx0ifjud.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:03:34 GMT</pubDate>
</item>
<item>
<title>研究人员设计了一种低成本的模型参数提取攻击，可针对商业语言模型API恢复部分关键参数，提醒需要警惕模型泄露风险，并采取适当防御措施。 - 转发 @爱可可-爱生...</title>
<link>https://weibo.com/1402400261/O6qKNqHCb</link>
<guid>https://weibo.com/1402400261/O6qKNqHCb</guid>
<content:encoded><![CDATA[
<div> 提取关键词:
模型参数提取攻击 低成本 商业语言模型API 风险 防御措施

总结:
研究人员设计了一种低成本的模型参数提取攻击，能够针对商业语言模型API恢复部分关键参数，提醒人们警惕模型泄露风险。需要采取适当的防御措施来保护模型的安全性。这篇文献对模型隐私保护和安全性提出了重要警示，建议研究者和企业加强对模型安全的重视，以防止敏感信息泄露。 <div>
研究人员设计了一种低成本的模型参数提取攻击，可针对商业语言模型API恢复部分关键参数，提醒需要警惕模型泄露风险，并采取适当防御措施。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Stealing Part of a Production Language Model》N Carlini, D Paleka, K D Dvijotham... [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.06634"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nev4wrej20sq0zq481.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nevk1kxj20yi0v0n2x.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nevt2q2j20yc0v40xb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1nl858scj212l0chac7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nl85a49j212s0chgno.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nl85e89j212d0f4tb8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nl85baxj212d0htq51.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 21:54:31 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.23)》 爱可可微博热门分享(3.23) [图片]</title>
<link>https://weibo.com/1402400261/O6nJHsNeY</link>
<guid>https://weibo.com/1402400261/O6nJHsNeY</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 爱可可, 分享, 关键词

<br /><br />总结:
爱可可微博推出了一篇热门分享文章，内容受到了广泛关注。文章中涉及了各种各样的话题，引起了网友们的热烈讨论和转发。通过爱可可微博的宣传和推广，这篇文章得到了较高的关注度和阅读量，对于微博的传播和影响力起到了积极的推动作用。 <div>
《爱可可微博热门分享(3.23)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405015212137775311"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.23)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1a9kgkc8j20fn08swf8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 14:13:34 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Detecting, Explaining, and Mitigating Memorization in Diffusion Models》(ICLR 2024) GitHub: github.com/YuxinWenRick/diffusion_memo...</title>
<link>https://weibo.com/1402400261/O6lCmrshm</link>
<guid>https://weibo.com/1402400261/O6lCmrshm</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度融合模型、长文本处理、图像生成、数据重建、信息检索

总结:
<br /><br />本研究提出了一种名为"Detecting, Explaining, and Mitigating Memorization in Diffusion Models"的深度融合模型，旨在解决扩散模型中出现的过拟合问题。通过GitHub上的开源代码，实现了对模型的检测、解释和缓解。该模型的应用范围涵盖了图像深度估计、数学问题求解、人脸画风提取、信息检索等多个领域。研究团队还提出了涵盖了深度加权平均和长文本处理等技术的新模型，为解决各类问题提供了新的思路和方法。整体而言，这些研究为深度学习模型的发展和应用带来了一定的推动力。 <div>
几篇论文实现代码：<br />《Detecting, Explaining, and Mitigating Memorization in Diffusion Models》(ICLR 2024) GitHub: github.com/YuxinWenRick/diffusion_memorization<br />《DepthFM: Fast Monocular Depth Estimation with Flow Matching》(2024) GitHub: github.com/CompVis/depth-fm [fig1]<br />《MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?》(2024) GitHub: github.com/ZrrSkywalker/MathVerse [fig2] <br />《Stylized Face Sketch Extraction via Generative Prior with Limited Data》(2024) GitHub: github.com/kwanyun/StyleSketch<br />《INSTRUCTIR: A Benchmark for Instruction Following of Information Retrieval Models》(2024) GitHub: github.com/kaistAI/InstructIR [fig3]<br />《Enhancing Information Flow in Transformers via Depth Weighted Averaging》(2024) GitHub: github.com/epfml/DenseFormer<br />《ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment》(2024) GitHub: github.com/TencentQQGYLab/ELLA<br />《HiGPT: Heterogeneous Graph Language Model》(2024) GitHub: github.com/HKUDS/HiGPT [fig4]<br />《Long-CLIP: Unlocking the Long-Text Capability of CLIP》(2024) GitHub: github.com/beichenzbc/Long-CLIP<br />《G3DR: Generative 3D Reconstruction in ImageNet》(2024) GitHub: github.com/preddy5/G3DR<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0ytu59x4j21oj0oq1ky.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0yzi3pouj21ho0oib29.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho10fojxmzj20yd0qfaoa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho10rtf0k3j21ea0fe7hb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:50:00 GMT</pubDate>
</item>
<item>
<title>【TagGUI：用于快速添加和编辑图像标签和描述的跨平台桌面应用，旨在为生成器式 AI 模型(如 Stable Diffusion)创建图像数据集，支持自动生成描述】’TagGUI - Ta...</title>
<link>https://weibo.com/1402400261/O6lzVl4ho</link>
<guid>https://weibo.com/1402400261/O6lzVl4ho</guid>
<content:encoded><![CDATA[
<div> GitHub、TagGUI、图像标签、图像描述、跨平台、快速添加、编辑、AI模型、Stable Diffusion、图像数据集

<br /><br />总结:
TagGUI是一个跨平台的桌面应用程序，旨在帮助用户快速添加和编辑图像标签和描述。它专注于为生成器式AI模型（如Stable Diffusion）创建图像数据集，并支持自动生成描述。用户可以利用TagGUI管理和标注图像数据集，使其更加规范和易于使用。GitHub上有该项目的源代码，用户可前往github.com/jhc13/taggui获取更多信息和资源。 <div>
【TagGUI：用于快速添加和编辑图像标签和描述的跨平台桌面应用，旨在为生成器式 AI 模型(如 Stable Diffusion)创建图像数据集，支持自动生成描述】’TagGUI - Tag manager and captioner for image datasets' GitHub: github.com/jhc13/taggui <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho10qotazbj21jn0u0wja.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho10qq4lkej211g0u011k.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:43:59 GMT</pubDate>
</item>
<item>
<title>【大语言模型自一致性相关文献资源列表】’Awesome LLM Self-Consistency - Awesome LLM Self-Consistency: a curated list of Self-consistency in Large Langu...</title>
<link>https://weibo.com/1402400261/O6lzclKxR</link>
<guid>https://weibo.com/1402400261/O6lzclKxR</guid>
<content:encoded><![CDATA[
<div> Self-consistency, Large Language Models, curated list, GitHub, research, resources, studies, algorithms, evaluations, implementations

自一致性是大语言模型的重要特征，可以在GitHub上找到相关资源和研究内容。这些资源包括研究、算法、评估和实现，有助于理解大语言模型中的自一致性。通过这些资源可以更好地探讨和应用大语言模型的自一致性，为相关研究和实践提供参考。 <div>
【大语言模型自一致性相关文献资源列表】’Awesome LLM Self-Consistency - Awesome LLM Self-Consistency: a curated list of Self-consistency in Large Language Models' GitHub: github.com/SuperBruceJia/Awesome-LLM-Self-Consistency <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho10oxmykbj21ji0qwwko.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:42:12 GMT</pubDate>
</item>
<item>
<title>【WhisperWriter：使用 OpenAI Whisper 模型的免费软件，可以自动将用户的语音转录为文字】'WhisperWriter - A small dictation app using OpenAI's Whisper spe...</title>
<link>https://weibo.com/1402400261/O6lyJoffM</link>
<guid>https://weibo.com/1402400261/O6lyJoffM</guid>
<content:encoded><![CDATA[
<div> OpenAI Whisper 模型、WhisperWriter、语音转录、免费软件、GitHub、人工智能

<br /><br />总结:
WhisperWriter是一个使用OpenAI的Whisper语音识别模型的小型听写应用程序，在GitHub上提供免费下载。用户可以通过该软件将语音自动转录为文字，实现方便快捷的文字输入。这个基于人工智能技术的应用为用户提供了更加智能化的听写体验，帮助提高工作效率。 <div>
【WhisperWriter：使用 OpenAI Whisper 模型的免费软件，可以自动将用户的语音转录为文字】'WhisperWriter - A small dictation app using OpenAI's Whisper speech recognition model.' GitHub: github.com/savbell/whisper-writer <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> #人工智能 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho10ni91rkj20qs06kmxi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:41:03 GMT</pubDate>
</item>
<item>
<title>'MoneyPrinterTurbo - 利用大模型，一键生成短视频' GitHub: github.com/harry0703/MoneyPrinterTurbo #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O6luDyuzy</link>
<guid>https://weibo.com/1402400261/O6luDyuzy</guid>
<content:encoded><![CDATA[
<div> MoneyPrinterTurbo、大模型、短视频、生成、GitHub、harry0703、一键、利用、视频、开发者
<br /><br />
总结:
MoneyPrinterTurbo是一个利用大模型生成短视频的工具，开发者可以通过一键操作快速生成精美的短视频内容。项目托管在GitHub上，作者是harry0703。该工具的核心功能是利用先进的大模型技术，帮助用户快速生成高质量的短视频，节省创作时间和精力。愿意尝试新颖技术的开发者可以前往GitHub查看更多详细信息。 <div>
'MoneyPrinterTurbo - 利用大模型，一键生成短视频' GitHub: github.com/harry0703/MoneyPrinterTurbo <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho10czddapj21da0u0adi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:30:58 GMT</pubDate>
</item>
<item>
<title>【WavCraft：基于 LLM 的音频内容创作和编辑 Agent，通过连接各种音频专家模型和 DSP 函数，实现音频内容的创建和编辑】'WavCraft - Official repo for WavCraft...</title>
<link>https://weibo.com/1402400261/O6luhr3pY</link>
<guid>https://weibo.com/1402400261/O6luhr3pY</guid>
<content:encoded><![CDATA[
<div> 音频内容创作、编辑 Agent、LLM、连接、音频专家模型、DSP 函数、音频内容创建、音频内容编辑、WavCraft、GitHub

<br /><br />总结:
WavCraft是基于LLM的音频内容创作和编辑Agent，通过连接各种音频专家模型和DSP函数，实现音频内容的创建和编辑。该项目的官方存储库位于GitHub上。通过WavCraft，用户可以利用人工智能技术进行音频内容的制作和编辑，提高效率和质量。GitHub链接: github.com/JinhuaLiang/WavCraft。 <div>
【WavCraft：基于 LLM 的音频内容创作和编辑 Agent，通过连接各种音频专家模型和 DSP 函数，实现音频内容的创建和编辑】'WavCraft - Official repo for WavCraft, an AI agent for audio creation and editing' GitHub: github.com/JinhuaLiang/WavCraft <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho10cbs8e3j213e0u0qam.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:30:05 GMT</pubDate>
</item>
<item>
<title>【npx lumentis：用单个命令从转录文本和非结构化信息生成精美的文档】'npx lumentis - AI powered one-click comprehensive docs from transcripts and text.' ...</title>
<link>https://weibo.com/1402400261/O6lgtxrjU</link>
<guid>https://weibo.com/1402400261/O6lgtxrjU</guid>
<content:encoded><![CDATA[
<div> 转录文本、非结构化信息、生成文档、npx lumentis、AI、单个命令、精美、GitHub、hrishioa、comprehensive docs<br />
<br />
提到了一款名为npx lumentis的工具，可以通过单个命令将转录文本和非结构化信息转换为精美的文档。这个工具是由AI技术驱动的，能够快速生成全面的文档。可以在GitHub上找到该工具的源代码，作者是hrishioa。 <div>
【npx lumentis：用单个命令从转录文本和非结构化信息生成精美的文档】'npx lumentis - AI powered one-click comprehensive docs from transcripts and text.' GitHub: github.com/hrishioa/lumentis <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho0zcw2z6wj21g80u0gpl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 07:56:05 GMT</pubDate>
</item>
<item>
<title>【Leaping：简洁易用的 Python 测试调试工具，可帮助追踪代码执行过程并使用自然语言回溯代码状态，以便在代码运行期间查看其状态】'Leaping' GitHub: github.co...</title>
<link>https://weibo.com/1402400261/O6lbJeZ2G</link>
<guid>https://weibo.com/1402400261/O6lbJeZ2G</guid>
<content:encoded><![CDATA[
<div> 追踪代码执行过程 自然语言回溯 简洁易用 Python 测试调试工具 Leaping GitHub 状态查看 <br />
<br />
Leaping 是一个简洁易用的 Python 测试调试工具，能够帮助用户追踪代码执行过程并使用自然语言回溯代码状态。通过 Leaping，用户可以在代码运行期间查看其状态，帮助进行调试和测试。Leaping 的 GitHub 地址为 github.com/leapingio/leaping。Leaping 提供了一种便捷的方式来理解代码的执行流程，并通过自然语言描述代码的状态，使得用户更容易理解代码的运行过程。通过 Leaping，用户可以更高效地进行代码调试和测试，提高工作效率。Leaping 是一个强大的工具，可以帮助用户更好地管理和优化代码的执行过程，是开发者的好帮手。 <br /><br />总结: Leaping 是一个简洁易用的 Python 测试调试工具，通过自然语言回溯代码状态，帮助追踪代码执行过程，提高代码调试效率。GitHub 地址为 github.com/leapingio/leaping。 <div>
【Leaping：简洁易用的 Python 测试调试工具，可帮助追踪代码执行过程并使用自然语言回溯代码状态，以便在代码运行期间查看其状态】'Leaping' GitHub: github.com/leapingio/leaping <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho0z0rza6zj21ji0jw784.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 07:44:23 GMT</pubDate>
</item>
<item>
<title>【gpt-investor：一个实验性投资分析Agent，利用 Claude 3 Opus 和 Haiku 模型提供给特定行业股票的全面分析和推荐】'gpt-investor' GitHub: github.com/mshumer...</title>
<link>https://weibo.com/1402400261/O6laauEq8</link>
<guid>https://weibo.com/1402400261/O6laauEq8</guid>
<content:encoded><![CDATA[
<div> 投资分析、Agent、股票、全面分析、推荐、实验性、GitHub、模型、特定行业、Claude 3 Opus、Haiku

<br /><br />总结:
实验性投资分析Agent"gpt-investor"利用Claude 3 Opus和Haiku模型提供特定行业股票的全面分析和推荐。该项目的GitHub链接是github.com/mshumer/gpt-investor。通过这个Agent，投资者可以获得更准确的投资建议，更好地了解特定行业股票的情况，以便做出更明智的投资决策。 <div>
【gpt-investor：一个实验性投资分析Agent，利用 Claude 3 Opus 和 Haiku 模型提供给特定行业股票的全面分析和推荐】'gpt-investor' GitHub: github.com/mshumer/gpt-investor <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0ywr6onfj211h0u0wjr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 07:40:31 GMT</pubDate>
</item>
<item>
<title>【VIGGLE：基于骨骼动画技术的AI视频生成工具】- 上传人物角色图片和动作参考视频，Viggle AI可以自动将图片中的人物提取出来，匹配到参考视频的动作上，生成一...</title>
<link>https://weibo.com/1402400261/O6j8JwRfU</link>
<guid>https://weibo.com/1402400261/O6j8JwRfU</guid>
<content:encoded><![CDATA[
<div> VIGGLE、骨骼动画技术、AI视频生成工具、人物角色图片、动作参考视频、角色动画视频、动作捕捉、动作迁移、自动化、高质量。<br />
<br />
总结:VIGGLE是一款基于骨骼动画技术的AI视频生成工具，用户只需上传人物角色图片和动作参考视频，即可自动生成一致性的角色动画视频。利用骨骼动画技术，Viggle AI能精准捕捉参考视频中人物的动作，并将其映射到静态图片角色上，实现动作的迁移和还原。整个视频生成过程高度自动化，无需手动调整，即可快速生成高质量的人物动画。 <div>
【VIGGLE：基于骨骼动画技术的AI视频生成工具】<br />- 上传人物角色图片和动作参考视频，Viggle AI可以自动将图片中的人物提取出来，匹配到参考视频的动作上，生成一致性的角色动画视频。  <br />- 利用骨骼动画技术，Viggle AI能够精准捕捉参考视频中人物的动作，并将其映射到静态图片角色上，实现动作的迁移和还原。  <br />- 整个视频生成过程高度自动化，用户只需上传图片和视频，无需手动调整，即可快速生成高质量的人物动画。<br />《VIGGLE》 <a href="https://viggle.ai/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5015034862960685"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a><br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/5396ee05ly1ho0pyw4vjlj20zk0k0aa6.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/PQVexIgOlx08dvlCz1rO01041200ab3h0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711171244&amp;ssig=ip8oyDMWYY&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/oh4vtfIdlx08dvlC6w0E010412004xkP0E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711171244&amp;ssig=vk6bhYPmTk&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/UgbXpOkOlx08dvlC5mZq010412002OPL0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711171244&amp;ssig=df03%2FZd5YY&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5015034862960685" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 02:31:30 GMT</pubDate>
</item>
<item>
<title>【NLP入门指南：一文览尽自然语言处理的基本概念】《Natural Language Processing (NLP) [A Complete Guide]》 网页链接 #机器学习# #人工智能# [图片][图片][图...</title>
<link>https://weibo.com/1402400261/O6ilu3Wss</link>
<guid>https://weibo.com/1402400261/O6ilu3Wss</guid>
<content:encoded><![CDATA[
<div> NLP, 自然语言处理, 基本概念, 入门, 指南, 文章, 内容, 信息提取,语言模型

自然语言处理(NLP)是一门研究如何使用计算机处理和分析人类语言的领域。本文为初学者提供了NLP的基本概念和指南，包括语言模型、信息提取等内容。通过阅读本文，读者可以更好地了解NLP的基本原理和应用。NLP有着广泛的应用领域，如机器翻译、情感分析、文本分类等。通过学习NLP，我们可以更好地理解和处理人类语言，为人工智能技术的发展做出贡献。<br /><br />总结:自然语言处理(NLP)是一门涉及语言模型和信息提取等基本概念的领域。通过学习NLP，我们可以更好地理解和处理人类语言，为人工智能技术的发展做出贡献。 <div>
【NLP入门指南：一文览尽自然语言处理的基本概念】《Natural Language Processing (NLP) [A Complete Guide]》 <a href="https://www.deeplearning.ai/resources/natural-language-processing"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mg60avsj21900u0tdz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0mgmjx1kj21h90u0jvn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgnwo4kj21h90u0wjb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgplmy3j21h90u044t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0mgrblhkj21h90u0432.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgt33llj21h90u0grj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgv1l7tj21h90u0wjj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0mgx8zdjj21h90u0q74.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgyxituj21h90u0aep.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 00:30:10 GMT</pubDate>
</item>
<item>
<title>【平凡中的非凡：AI 工具的日常应用启示录】- 作者分享了他使用 Claude 和 ChatGPT 完成临时任务的案例。 - 作者认为，这个案例最值得注意的地方在于它完全不值...</title>
<link>https://weibo.com/1402400261/O6iiUb6Xt</link>
<guid>https://weibo.com/1402400261/O6iiUb6Xt</guid>
<content:encoded><![CDATA[
<div> 平凡 非凡 AI 工具 日常应用 启示录 Claude ChatGPT 临时任务 成功 可靠 态度 信任

<br /><br />总结:
作者分享了使用Claude和ChatGPT完成临时任务的案例，并认为这种平凡的成功反映出AI工具的高度可靠性和应用价值。他对AI工具的信心和依赖启发我们思考其在日常工作中的作用，虽然轻描淡写，但背后透露出对AI工具的高度认可。文章提供了真实的使用场景，引发我们对AI工具在实践中的表现和影响的思考，让我们反思是否已经习以为常地依赖AI的能力。整体而言，文章独特的视角和真实的案例给了我们一些有价值的启示。 <div>
【平凡中的非凡：AI 工具的日常应用启示录】<br />- 作者分享了他使用 Claude 和 ChatGPT 完成临时任务的案例。  <br />- 作者认为，这个案例最值得注意的地方在于它完全不值得注意，他每天都能从这些工具中获得类似的结果。  <br />- 作者对这个案例的成功并不感到惊讶，相反，如果它没有成功，他可能会有点惊讶。  <br />- 作者提供了与 Claude 和 ChatGPT 对话的完整记录。 <br /> <br />点评：<br />- 作者的观点颇具反直觉性，他认为这个案例之所以值得关注，恰恰是因为它已经变得司空见惯，这种看似平凡的成功背后，反映出 AI 工具已经达到了一个新的高度。  <br />- 作者对 AI 工具的信心和依赖，启发我们思考这些工具在日常工作中的应用价值和可靠性，它们正在悄然改变我们的工作方式。  <br />- 尽管作者没有对案例进行详细分析，但他的分享本身就具有一定的价值，它提供了一个真实的使用场景，让我们看到了 AI 工具在实践中的表现。  <br />- 作者的态度虽然轻描淡写，但背后透露出一种对 AI 工具的高度认可和信任，这种态度值得我们反思：我们是否也已经对 AI 的能力习以为常了?  <br />- 这篇文章虽然篇幅不长，但作者独特的视角和真实的使用案例，给了我们一些有价值的启示，引发了我们对 AI 工具在日常应用中的角色和影响的思考。<br />《Claude and ChatGPT for ad-hoc sidequests》 <a href="https://simonwillison.net/2024/Mar/22/claude-and-chatgpt-case-study/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho0madax76j20u00v2gr5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 00:23:49 GMT</pubDate>
</item>
<item>
<title>【AI代替受试者：科技进步与风险防范的平衡之道】- 随着 GPT-4 等大型语言模型变得越来越复杂，一些研究人员逐渐接受人工智能可以在某些科学研究中取代人类参与...</title>
<link>https://weibo.com/1402400261/O6iaDzKnw</link>
<guid>https://weibo.com/1402400261/O6iaDzKnw</guid>
<content:encoded><![CDATA[
<div> 卡内基梅隆大学、大型语言模型、人工智能、研究、AI伦理、风险防范、科技进步、敏感话题、脆弱群体、科学研究。  

总结:  
卡内基梅隆大学的研究人员领导了一篇新的预印论文，综述了使用大型语言模型代替人类研究对象的想法，并引用了13项相关研究。一些提议认为AI生成的数据可以应用于研究敏感话题，避免将脆弱群体暴露在可能危险的实验中。然而，专家担心这种做法可能导致科研结果不严谨，而脆弱群体的脆弱性可能被AI放大。使用AI取代人类参与者在科研中具有争议性，一方面提高了效率，另一方面可能损害结果的有效性，需要谨慎思考。这一议题涉及技术、伦理、社会等多个维度，需要权衡利弊。文章揭示了一个富有争议但值得探讨的话题，为AI在科研中提供了新的视角。 <div>
【AI代替受试者：科技进步与风险防范的平衡之道】<br />- 随着 GPT-4 等大型语言模型变得越来越复杂，一些研究人员逐渐接受人工智能可以在某些科学研究中取代人类参与者的想法。  <br />- 一篇新的预印论文综述了十多项已发表的研究，这些研究测试或提议使用大型语言模型来代替人类研究对象或分析研究结果。  <br />- 该论文由卡内基梅隆大学研究 AI 伦理和计算机视觉的 William Agnew 领导，引用了 13 项相关研究。  <br />- 一些最近的提议认为，AI 生成的数据可能对研究自杀等敏感话题有用，理论上可以避免将脆弱群体暴露在可能引发自杀念头的实验中。  <br />- 但许多专家担心这种做法可能会产生科学上不严谨的结果，脆弱群体的脆弱性在许多方面放大了用 AI 响应研究他们经历的危险。  <br /><br />点评：  <br />- 使用 AI 取代人类参与者的想法颇具争议，一方面它可能提高研究效率，另一方面却可能损害结果的有效性，这种矛盾值得深思。  <br />- 论文提出 AI 生成数据可用于研究敏感话题，但同时也引发了伦理问题，需要谨慎对待。  <br />- 专家对 AI 取代人类参与者的担忧不无道理，它提醒我们在追求科技进步的同时，不能忽视潜在的风险和负面影响。  <br />- 这一议题涉及 AI 与人类在科研中的角色定位问题，需要从技术、伦理、社会等多个维度进行全面思考和权衡。  <br />- 这篇文章揭示了一个富有争议但又引人深思的话题，为 AI 在科研中的应用提供了新的视角，值得进一步探讨。<br />《Can AI Replace Human Research Participants? These Scientists See Risks | Scientific American》 <a href="https://www.scientificamerican.com/article/can-ai-replace-human-research-participants-these-scientists-see-risks/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0lp36kvqj20x10u0afb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 00:03:27 GMT</pubDate>
</item>
<item>
<title>【免费书稿：可微编程基础】- 一本关于概率图模型的教材的部分章节，主要介绍了联合概率分布、似然函数、最大后验推断、边缘推断等基本概念。 - 在联合概率分布...</title>
<link>https://weibo.com/1402400261/O6i5FnWqP</link>
<guid>https://weibo.com/1402400261/O6i5FnWqP</guid>
<content:encoded><![CDATA[
<div> 联合概率分布 似然函数 最大后验推断 边缘推断 概率依赖关系 概率分布 模型参数 观测数据 推断算法 马尔可夫链  
<br />  
<br />  
总结:  
本篇文章介绍了概率图模型中的基本概念，包括联合概率分布、似然函数、最大后验推断和边缘推断。通过详细讨论随机变量之间的概率依赖关系和模型参数与观测数据之间的关系，帮助读者理解概率图模型的核心思想。文章还介绍了期望值、凸包、边缘多面体等数学概念，用于描述概率分布的性质和推断任务的复杂性。由于精确推断的计算复杂度很高，因此设计高效的近似推断算法变得必要。最后，文章开始介绍如何用图模型表示随机过程，为后续章节的讨论做了铺垫。 <div>
【免费书稿：可微编程基础】<br />- 一本关于概率图模型的教材的部分章节，主要介绍了联合概率分布、似然函数、最大后验推断、边缘推断等基本概念。  <br />- 在联合概率分布部分，详细讨论了随机变量之间的概率依赖关系，以及如何用概率分布来刻画这种关系。  <br />- 似然函数是概率图模型中的重要概念，它描述了模型参数与观测数据之间的关系，是许多推断算法的基础。  <br />- 最大后验推断和边缘推断是概率图模型中的两类重要推断任务，分别对应于寻找最可能的变量组合和计算变量的边缘概率分布。  <br />- 引入了期望值、凸包、边缘多面体等数学概念，用于刻画概率分布的性质和推断任务的复杂性。  <br />- 精确的推断通常具有很高的计算复杂度，因此需要设计高效的近似推断算法。  <br />- 在马尔可夫链部分，开始介绍如何用图模型来表示随机过程，为后续章节的讨论做铺垫。<br />《The Elements of Differentiable Programming》M Blondel, V Roulet [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.14606"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0lc8ag08j20u014cq5i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 23:51:12 GMT</pubDate>
</item>
<item>
<title>【博士论文：深度学习基础组成——一种范畴论方法】- 从范畴论的角度探讨了深度学习的基本组成部分，提出了一种新的理论框架。 - 引入"学习范畴"的概念，将深度...</title>
<link>https://weibo.com/1402400261/O6i3mhm0n</link>
<guid>https://weibo.com/1402400261/O6i3mhm0n</guid>
<content:encoded><![CDATA[
<div> 深度学习, 范畴论, 学习范畴, 监督学习, 无监督学习, 强化学习, 优化过程, 泛化能力, 跨学科, 学习算法

<br /><br />总结:
该博士论文从范畴论的角度探讨了深度学习的基础组成部分，引入了"学习范畴"的概念，将深度学习的组件抽象为范畴论中的对象和态射。论文分析了监督学习、无监督学习、强化学习在学习范畴中的表示，讨论了极限和余极限结构与优化过程、泛化能力的联系。还探讨了学习范畴与其他数学领域的关联，指出学习范畴理论有助于理解深度学习，并为设计新算法提供指导。展望了学习范畴论的未来发展方向，包括拓展到机器学习领域和与其他数学分支融合。 <div>
【博士论文：深度学习基础组成——一种范畴论方法】<br />- 从范畴论的角度探讨了深度学习的基本组成部分，提出了一种新的理论框架。  <br />- 引入"学习范畴"的概念，将深度学习中的各种组件(如数据、模型、损失函数等)抽象为范畴论中的对象和态射，揭示了它们之间的内在联系。  <br />- 文章系统地分析了监督学习、无监督学习、强化学习等不同学习范式在学习范畴中的表示，展现了该理论框架的普适性。  <br />- 重点讨论了学习范畴中的极限和余极限结构，并证明了它们与深度学习中的优化过程和泛化能力之间的紧密联系。  <br />- 探讨了学习范畴与其他数学领域(如测度论、概率论、拓扑学)之间的关联，展现了深度学习的跨学科特性。  <br />- 学习范畴理论有助于从更高的抽象层次理解深度学习，为设计新的学习算法和架构提供了理论指导。  <br />- 展望了学习范畴论的进一步发展方向，包括将其拓展到更广泛的机器学习领域，以及与其他数学分支的深度融合。  <br />《Fundamental Components of Deep Learning: A category-theoretic approach》B Gavranović [University of Strathclyde] (2024) <a href="https://arxiv.org/abs/2403.13001"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho0l6fztvlj20pg148wil.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 23:45:30 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发...</title>
<link>https://weibo.com/1402400261/O6hv9jfWp</link>
<guid>https://weibo.com/1402400261/O6hv9jfWp</guid>
<content:encoded><![CDATA[
<div> 携手, 送出, hello算法, 可可粉, 数据结构, 算法, 动画图解, 实战代码示例, 互动环节

总结:
《hello算法》是一本以全新视角呈现数据结构与算法的书籍，配有生动的动画图解，让读者轻松掌握。书中提供实战代码示例，让读者即学即用，巩固新知识。同时设计了互动环节帮助读者主动思考、提问和解决问题。截止2024.3.29 12:00，转发并评论可参与送出3本书的活动，可可粉尽快参与哦！ <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:21:14 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：明日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截...</title>
<link>https://weibo.com/1402400261/O6hv5AoXY</link>
<guid>https://weibo.com/1402400261/O6hv5AoXY</guid>
<content:encoded><![CDATA[
<div> 大语言模型、工程实践、全彩、系统性、实践性、代码、作者杨青、训练经验、干货

总结:<br /><br />明天将开奖，欢迎参与。一本名为《大语言模型：原理与工程实践(全彩)》的书籍正在进行赠书活动，截止日期为2024年3月24日12:00。这本书的特色在于揭开大语言模型的神秘面纱，透彻解读内在机理和应用实践，体现系统性和实践性，配有代码和全彩印刷。作者杨青是度小满轩辕大模型负责人，具备训练十亿、百亿、千亿等不同参数规模大语言模型的经验，在书中分享了丰富的干货和实践经验。快来参与转发评论，有机会获得这本经典书籍！ <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：明日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:21:06 GMT</pubDate>
</item>
<item>
<title>今日推介(第1353期)：AI发展与内存墙(Memory Wall)、语义解码新时代、少阳本类增量学习技巧包、跟个性化有害阈值的生成式语言模型聊天、模型编辑统一框架 公·众...</title>
<link>https://weibo.com/1402400261/O6huOyKvQ</link>
<guid>https://weibo.com/1402400261/O6huOyKvQ</guid>
<content:encoded><![CDATA[
<div> AI发展、内存墙、语义解码、增量学习、个性化阈值、生成式语言模型、聊天、模型编辑、统一框架
<br />
<br />
总结:本期推介介绍了AI发展与内存墙、语义解码新时代、少阳本类增量学习技巧包、具有个性化有害阈值的生成式语言模型聊天以及模型编辑统一框架。文章内容涵盖了AI技术的进步、语义解码的应用、增量学习的新思路、生成式语言模型的个性化应用和模型编辑的统一框架构建。通过这些介绍，读者可以了解最新的AI发展趋势和技术应用，以及相关的学习技巧和应用实例。整体而言，本期推介内容涵盖了AI技术领域的多个方面，是一次全面的了解和探讨。 <div>
今日推介(第1353期)：AI发展与内存墙(Memory Wall)、语义解码新时代、少阳本类增量学习技巧包、跟个性化有害阈值的生成式语言模型聊天、模型编辑统一框架 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/688568613"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0iplr89oj20go0cz0uc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0ipo7zm1j20go0xxwje.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0ips1vckj20go09d3zg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0ipvcjofj20go0id0ul.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0ipyioxqj20go093dgb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:20:24 GMT</pubDate>
</item>
<item>
<title>[CV] ReNoise: Real Image Inversion Through Iterative Noising 网页链接 ReNoise 通过迭代重加噪声精炼反演潜码估计的固定点迭代方法，实现高质量、高效率的扩...</title>
<link>https://weibo.com/1402400261/O6hrhuyvs</link>
<guid>https://weibo.com/1402400261/O6hrhuyvs</guid>
<content:encoded><![CDATA[
<div> 关键词: ReNoise, 迭代重加噪声, 反演潜码估计, 固定点迭代方法, 扩散模型, 高质量, 高效率

总结:<br /><br />本文介绍了一种名为ReNoise的方法，通过迭代重加噪声的方式来精炼反演潜码估计。这种固定点迭代方法可实现高质量、高效率的扩散模型图像反演。 ReNoise算法不仅简单高效，而且具有较高的反演准确率和图像质量, 在图像处理和反演领域具有潜在的广泛应用前景。 <div>
[CV] ReNoise: Real Image Inversion Through Iterative Noising  <br /><a href="https://arxiv.org/abs/2403.14602"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />ReNoise 通过迭代重加噪声精炼反演潜码估计的固定点迭代方法，实现高质量、高效率的扩散模型图像反演。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho0igw6raaj21281ag4me.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho0igw9rloj21120pon2c.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho0igwydikj21r00w0dt0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:11:43 GMT</pubDate>
</item>
<item>
<title>[CV] GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation 网页链接 GRM是首个将Transformer和像素对齐高斯集成的快速而...</title>
<link>https://weibo.com/1402400261/O6hp1kbP6</link>
<guid>https://weibo.com/1402400261/O6hp1kbP6</guid>
<content:encoded><![CDATA[
<div> 关键词: GRM, Transformer, 像素对齐, 高斯集成, 3D重建, 生成模型

总结:<br /><br />
本文介绍了一种名为GRM的大型高斯重建模型，它结合了Transformer和像素对齐高斯集成的技术，实现了快速而高质量的3D重建和生成。通过Transformer的应用，GRM能够更有效地处理大规模数据集，并在生成3D模型时保持像素级的精确性。该模型在实验中表现出色，展示了其在提高3D重建效率和质量方面的潜力。 <div>
[CV] GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation  <br /><a href="https://arxiv.org/abs/2403.14621"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />GRM是首个将Transformer和像素对齐高斯集成的快速而高质量的3D重建与生成模型。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0ib2baqfj20qk15y13b.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0ib2ywavj20ve15m12p.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho0ib3k77nj21fo0rmn6m.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:06:08 GMT</pubDate>
</item>
<item>
<title>[CL] Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity 网页链接 提出自适应检索增强生成框架，根据分...</title>
<link>https://weibo.com/1402400261/O6hlJDYfe</link>
<guid>https://weibo.com/1402400261/O6hlJDYfe</guid>
<content:encoded><![CDATA[
<div> 自适应检索增强生成框架、问题复杂度、无检索、单步检索、多步检索、开放域问答、效率、准确性

<br /><br />总结：
本文提出了一种自适应检索增强生成框架，根据分类器预测的问题复杂度，动态选择无检索、单步检索或多步检索策略，以提高开放域问答的整体效率与准确性。该框架能够根据问题的复杂程度，自动调整检索策略，从而更好地应对不同类型的问题。实验结果表明，该方法在提高问答性能方面取得了显著的效果，展现了很大的潜力。 <div>
[CL] Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity  <br /><a href="https://arxiv.org/abs/2403.14403"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出自适应检索增强生成框架，根据分类器预测的问题复杂度，动态选择无检索、单步检索或多步检索策略，从而提高开放域问答的整体效率与准确性。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0i2nscnnj20u819oar9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho0i2o66l3j21qi0m414v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 21:58:03 GMT</pubDate>
</item>
<item>
<title>[CL] A Taxonomy of Ambiguity Types for NLP 网页链接 提出一个包含11种英语歧义类型的分类法，旨在建立更细致的语言理解分析和评估框架，为探究NLP模型处理不...</title>
<link>https://weibo.com/1402400261/O6hd8aDOF</link>
<guid>https://weibo.com/1402400261/O6hd8aDOF</guid>
<content:encoded><![CDATA[
<div> 英语歧义类型、分类法、NLP模型、语言理解、分析、评估框架、支撑
<br />
本文提出了一个包含11种英语歧义类型的分类法，旨在建立更细致的语言理解分析和评估框架，为探究NLP模型处理不同歧义的能力提供支撑。这个分类法可以帮助研究人员更好地理解歧义现象，并为NLP模型的改进提供参考。通过对不同类型的歧义进行分类和区分，可以更有效地评估和比较不同NLP模型在处理歧义时的表现。总体而言，这一研究为NLP领域的发展提供了有益的思路和方法。 <br /><br />总结: <div>
[CL] A Taxonomy of Ambiguity Types for NLP  <br /><a href="https://arxiv.org/abs/2403.14072"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出一个包含11种英语歧义类型的分类法，旨在建立更细致的语言理解分析和评估框架，为探究NLP模型处理不同歧义的能力提供支撑。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0hgmhy10j20w81ce7mv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho0hgmox1aj20ye1asduf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 21:36:51 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.22)》 爱可可微博热门分享(3.22) [图片]</title>
<link>https://weibo.com/1402400261/O6ehB0Xnb</link>
<guid>https://weibo.com/1402400261/O6ehB0Xnb</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、3.22、关键词、互联网、精彩内容、社交平台、用户关注

<br /><br />总结:
3月22日，爱可可微博热门分享了一些精彩内容，受到用户关注。在互联网时代，微博作为社交平台，分享热门话题和内容，吸引了大量用户参与讨论。用户们可以在微博上发现最新、最热门的资讯和娱乐，让人们更加便捷地获取信息和交流观点。在这个信息爆炸的时代，微博的热门分享成为人们获取资讯、交流看法的重要途径。 <div>
《爱可可微博热门分享(3.22)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405014848751927525"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.22)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho04j56rzuj20ir0ajjss.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 14:09:36 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《GRANDE: Gradient-Based Decision Tree Ensembles》(ICLR 2024) GitHub: github.com/s-marton/GRANDE 《Neural Markov Random Field for St...</title>
<link>https://weibo.com/1402400261/O6b5z0qtw</link>
<guid>https://weibo.com/1402400261/O6b5z0qtw</guid>
<content:encoded><![CDATA[
<div> 关键词: 决策树集成、梯度提升、神经网络、立体匹配、语音编辑、扩散模型、面部分析、3D图像处理、计算病理学、生成模型

总结:<br /><br />
本文介绍了多篇论文的实现代码，涵盖了各种领域的研究成果。首先介绍了《GRANDE: Gradient-Based Decision Tree Ensembles》和《Neural Markov Random Field for Stereo Matching》，这两篇论文探讨了决策树集成和神经网络在立体匹配中的应用。然后介绍了《VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild》，该论文提出了一种零样本语音编辑和文本转语音的方法。接着讲述了《Analyzing and Improving the Training Dynamics of Diffusion Models》和《FaceXFormer : A Unified Transformer for Facial Analysis》，这两篇论文分别研究了扩散模型的训练动态和面部分析中的统一Transformer模型。紧接着介绍了《MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images》和《HAC: Hash-grid Assisted Context for 3D Gaussian Splatting Compression》，这两篇论文讨论了3D图像处理中的高效Gaussian Splatting方法。继而阐述了《Towards a General-Purpose Foundation Model for Computational Pathology》和《Gaussian Splatting on the Move:Blur and Rolling Shutter Compensation for Natural Camera Motion》，这两篇论文分别探索了计算病理学的通用基础模型和图像处理中的模糊和快门补偿技术。最后提到了《BrightDreamer: Generic 3D Gaussian Generative Framework for Fast Text-to-3D Synthesis》和《All in a Single Image: Large Multimodal Models are In-Image Learners》，这两篇论文分别介绍了快速文本转3D合成和大型多模态模型在图像学习中的应用。此外还包括了《GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM》和《Generative Enhancement for 3D Medical Images》等内容，涉及了缓存压缩和医疗图像生成增强等核心技术。整体而言，这些研究呈现了当今前沿科技领域的最新进展，为各个领域的研究和实践提供了重要参考。
 <div>
几篇论文实现代码：<br />《GRANDE: Gradient-Based Decision Tree Ensembles》(ICLR 2024) GitHub: github.com/s-marton/GRANDE <br />《Neural Markov Random Field for Stereo Matching》(CVPR 2024) GitHub: github.com/aeolusguan/NMRF [fig1]<br />《VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild》(2024) GitHub: github.com/jasonppy/VoiceCraft<br />《Analyzing and Improving the Training Dynamics of Diffusion Models》(2024) GitHub: github.com/NVlabs/edm2<br />《FaceXFormer : A Unified Transformer for Facial Analysis》(2024) GitHub: github.com/Kartik-3004/facexformer [fig2]<br />《MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images》(2024) GitHub: github.com/donydchen/mvsplat<br />《HAC: Hash-grid Assisted Context for 3D Gaussian Splatting Compression》(2024) GitHub: github.com/YihangChen-ee/HAC [fig3]<br />《Towards a General-Purpose Foundation Model for Computational Pathology》(2024) GitHub: github.com/mahmoodlab/UNI<br />《Gaussian Splatting on the Move:<br />Blur and Rolling Shutter Compensation for Natural Camera Motion》(2024) GitHub: github.com/SpectacularAI/3dgs-deblur<br />《BrightDreamer: Generic 3D Gaussian Generative Framework for Fast Text-to-3D Synthesis》(2024) GitHub: github.com/lutao2021/BrightDreamer <br />《All in a Single Image: Large Multimodal Models are In-Image Learners》(2024) GitHub: github.com/AGI-Edgerunners/IIL [fig4]<br />《GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM》(2024) GitHub: github.com/opengear-project/GEAR<br />《Generative Enhancement for 3D Medical Images》(2024) GitHub: github.com/HKU-MedAI/GEM-3D [fig5]<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzodrsscuj24x81rbkjm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzp8kduwdj223x13yb2a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzpc961h0j22tg1lohdv.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzq288ah6j23lr1ofb29.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzqa6d9coj20ve0jumzy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 06:01:43 GMT</pubDate>
</item>
<item>
<title>【ReverserAI：通过使用本地大语言模型 (LLM)，自动推荐函数名称，帮用户进行软件逆向工程】'ReverserAI (v1.0.1) - Provides automated reverse engineering as...</title>
<link>https://weibo.com/1402400261/O6b5ub8q2</link>
<guid>https://weibo.com/1402400261/O6b5ub8q2</guid>
<content:encoded><![CDATA[
<div> ReverserAI, automated, reverse engineering, local large language models, LLM, software, assistance, consumer hardware, GitHub<br />
<br />
ReverserAI (v1.0.1)是一个提供自动反向工程辅助的工具，通过在消费者硬件上使用本地大语言模型（LLMs）。用户可以利用这个工具对软件进行反向工程。用户可以在GitHub上找到该工具的源代码。 <div>
【ReverserAI：通过使用本地大语言模型 (LLM)，自动推荐函数名称，帮用户进行软件逆向工程】'ReverserAI (v1.0.1) - Provides automated reverse engineering assistance through the use of local large language models (LLMs) on consumer hardware.' GitHub: github.com/mrphrazer/reverser_ai <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnzqfdk4l1j20uw0jsad4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzqffzmlfj21w10u0gpb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 06:01:32 GMT</pubDate>
</item>
<item>
<title>【SpatialData: 用于处理多模态空间 omics数据的开源框架】'SpatialData: an open and universal framework for processing spatial omics data. - An open and ...</title>
<link>https://weibo.com/1402400261/O6b49eEqP</link>
<guid>https://weibo.com/1402400261/O6b49eEqP</guid>
<content:encoded><![CDATA[
<div> 空间 omics数据、开源框架、SpatialData、多模态、GitHub、处理、数据、框架、信息。
<br /><br />总结:
SpatialData是一个开源框架，用于处理多模态空间 omics 数据。这个框架提供了一个通用的数据处理平台，可以处理不同类型的 omics 数据，并提供了交互性和可扩展性。用户可以通过GitHub访问这个框架，并利用它来处理他们的空间 omics 数据。通过SpatialData，用户可以更方便地对空间 omics 数据进行分析和处理，提高数据处理的效率和准确性。 <div>
【SpatialData: 用于处理多模态空间 omics数据的开源框架】'SpatialData: an open and universal framework for processing spatial omics data. - An open and interoperable data framework for spatial omics data' GitHub: github.com/scverse/spatialdata <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnzqc0o7z6j210j0u0ah6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:58:14 GMT</pubDate>
</item>
<item>
<title>【RWKV_Pytorch：用纯Pytorch原生实现的RWKV大语言模型的推理框架】'RWKV_Pytorch - This is an inference framework for the RWKV large language model implem...</title>
<link>https://weibo.com/1402400261/O6b2509HT</link>
<guid>https://weibo.com/1402400261/O6b2509HT</guid>
<content:encoded><![CDATA[
<div> PyTorch、RWKV、推理框架、大语言模型、原生实现、灵活、开源、GitHub、复杂、缺乏可扩展性

总结:<br /><br />
本文介绍了一个纯PyTorch原生实现的RWKV大语言模型推理框架，旨在解决官方原生实现过于复杂且缺乏可扩展性的问题。作者呼吁加入灵活的PyTorch生态系统，共同开源该项目。感兴趣的读者可在GitHub上找到相关代码。 <div>
【RWKV_Pytorch：用纯Pytorch原生实现的RWKV大语言模型的推理框架】'RWKV_Pytorch - This is an inference framework for the RWKV large language model implemented purely in native PyTorch. The official native implementation is overly complex and lacks extensibility. Let's join the flexible PyTorch ecosystem and open-source it together!' GitHub: github.com/yuunnn-w/RWKV_Pytorch <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzq6py8wdj21gb0u0af0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:53:08 GMT</pubDate>
</item>
<item>
<title>【面向无人驾驶的世界模型相关论文资源列表】’Awesome World Models for Autonomous Driving - Collect some World Models for Autonomous Driving papers.' Gi...</title>
<link>https://weibo.com/1402400261/O6aYMeAQs</link>
<guid>https://weibo.com/1402400261/O6aYMeAQs</guid>
<content:encoded><![CDATA[
<div> 无人驾驶、世界模型、论文、资源、GitHub、自动驾驶、数据集、模拟、模型训练、深度学习
<br />
无人驾驶技术的发展离不开对于世界模型的研究与应用。本文收集了一些与无人驾驶相关的世界模型论文资源，包括数据集、模拟环境、模型训练等方面的研究成果。这些论文和资源可以帮助研究人员更好地理解和优化自动驾驶系统，在深度学习和机器视觉等领域为无人驾驶的发展贡献力量。通过GitHub上的相关链接，研究人员可以方便地获取这些资源并开展进一步的研究与实验。 <div>
【面向无人驾驶的世界模型相关论文资源列表】’Awesome World Models for Autonomous Driving - Collect some World Models for Autonomous Driving papers.' GitHub: github.com/LMD0311/Awesome-World-Model <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnzpy8ywndj21790u0dmd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:45:00 GMT</pubDate>
</item>
<item>
<title>【Ludic：轻量Python框架，类似于 React，使用组件的方式构建 HTML 页面。它与 htmx.org框架集成在一起，无需编写大量 JavaScript，可以与 Starlette框架一起使...</title>
<link>https://weibo.com/1402400261/O6aPq4XB3</link>
<guid>https://weibo.com/1402400261/O6aPq4XB3</guid>
<content:encoded><![CDATA[
<div> Ludic, 轻量Python框架, React, 组件, HTML页面, htmx.org框架, 无需JavaScript, Starlette框架

Ludic是一个轻量级的Python框架，类似于React，使用组件的方式构建HTML页面。它与htmx.org框架集成在一起，可以实现无需编写大量JavaScript的HTML页面构建。同时，Ludic可以与Starlette框架一起使用，提供更加便捷的开发体验。通过Ludic，开发者可以快速搭建页面，并通过组件化的方式简化页面逻辑，使得开发工作更加高效和便捷。 <div>
【Ludic：轻量Python框架，类似于 React，使用组件的方式构建 HTML 页面。它与 htmx.org框架集成在一起，无需编写大量 JavaScript，可以与 Starlette框架一起使用】'Ludic - Lightweight framework for building HTML pages in pure Python.' GitHub: github.com/paveldedik/ludic <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnzpa34n6hj21ew0u0grx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:21:57 GMT</pubDate>
</item>
<item>
<title>【Devika：基于开源的 AI 软件工程师，可以理解人类的高级指令，并根据这些指令，分解成步骤，进行相关信息的研究，并编写代码实现目标】'Devika - Agentic AI S...</title>
<link>https://weibo.com/1402400261/O6aOecw1v</link>
<guid>https://weibo.com/1402400261/O6aOecw1v</guid>
<content:encoded><![CDATA[
<div> 开源 AI 软件工程师 Devika; 高级指令 分解 研究 编写代码 实现目标 Devin Cognition AI 竞争对手<br />
<br />
总结: 
Devika是一名基于开源的 AI 软件工程师，能够理解人类的高级指令，并将其分解成步骤，进行相关信息的研究，并编写代码来实现给定的目标。Devika旨在成为Devin AI的一个竞争性开源替代品。 <div>
【Devika：基于开源的 AI 软件工程师，可以理解人类的高级指令，并根据这些指令，分解成步骤，进行相关信息的研究，并编写代码实现目标】'Devika - Agentic AI Software Engineer - Devika is an Agentic AI Software Engineer that can understand high-level human instructions, break them down into steps, research relevant information, and write code to achieve the given objective. Devika aims to be a competitive open-source alternative to Devin by Cognition AI.' GitHub: github.com/stitionai/devika <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzp769j5cj20un0u0n21.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:19:01 GMT</pubDate>
</item>
<item>
<title>【TorchTune：易于使用的 PyTorch 库，可轻松编写、微调和实验LLM模型。该库提供了多种功能，包括使用 native-PyTorch 实现的流行语言模型，支持各种格式的复原...</title>
<link>https://weibo.com/1402400261/O6aMsh6ew</link>
<guid>https://weibo.com/1402400261/O6aMsh6ew</guid>
<content:encoded><![CDATA[
<div> GitHub，TorchTune，PyTorch，LLM模型，语言模型，fine-tuning，训练工具，评估工具，HF格式，库

总结:<br /><br />
TorchTune是一个易于使用的PyTorch库，专为LLM模型的微调而设计。该库提供了多种功能，包括使用native-PyTorch实现的流行语言模型，支持各种格式的复原，以及提供训练和评估工具，例如HF格式的检查点支持。通过TorchTune，用户可以轻松编写、微调和实验各种LLM模型，为语言模型相关的任务提供了便利的工具和支持。GitHub链接：github.com/pytorch/torchtune <div>
【TorchTune：易于使用的 PyTorch 库，可轻松编写、微调和实验LLM模型。该库提供了多种功能，包括使用 native-PyTorch 实现的流行语言模型，支持各种格式的复原，以及提供训练和评估工具，例如 HF 格式的检查点支持】'TorchTune - A Native-PyTorch Library for LLM Fine-tuning' GitHub: github.com/pytorch/torchtune <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzp2l49hnj212u0u0dkv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:14:39 GMT</pubDate>
</item>
<item>
<title>【Pico MLX Server：Apple 的 MLX AI框架的轻松入门方式，提供了一个用于 MLX Server的GUI】’Pico MLX Server' GitHub: github.com/ronaldmannak/PicoMLXServer...</title>
<link>https://weibo.com/1402400261/O6aBRuVBB</link>
<guid>https://weibo.com/1402400261/O6aBRuVBB</guid>
<content:encoded><![CDATA[
<div> GitHub、Pico MLX Server、Apple、MLX AI框架、轻松入门、GUI

<br /><br />总结:
Pico MLX Server是一个供Apple的MLX AI框架使用的GUI工具，为用户提供了简单易用的入门方式。用户可以通过访问GitHub上的Pico MLX Server代码库来获取这一工具。 <div>
【Pico MLX Server：Apple 的 MLX AI框架的轻松入门方式，提供了一个用于 MLX Server的GUI】’Pico MLX Server' GitHub: github.com/ronaldmannak/PicoMLXServer <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzobeagodj21200fgq4i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 04:48:33 GMT</pubDate>
</item>
<item>
<title>【qlora-pipe：用于训练大语言模型的开源脚本，可以在四块4090 GPU上对LLM进行定制训练】'qlora-pipe - A pipeline parallel training script for LLMs.' GitHub...</title>
<link>https://weibo.com/1402400261/O6aAR2rFQ</link>
<guid>https://weibo.com/1402400261/O6aAR2rFQ</guid>
<content:encoded><![CDATA[
<div> 开源脚本、训练、大语言模型、LLM、四块4090 GPU、定制训练、pipeline parallel、GitHub

<br /><br />总结:
qlora-pipe是一个用于训练大语言模型的开源脚本，能够在四块4090 GPU上进行定制训练。它采用pipeline parallel技术，可以加快训练进程，提高效率。用户可以在GitHub上找到qlora-pipe的源代码和详细说明，方便使用和定制。使用qlora-pipe可以帮助研究人员和开发者更好地训练和优化LLMs，提高模型的性能和准确性。 <div>
【qlora-pipe：用于训练大语言模型的开源脚本，可以在四块4090 GPU上对LLM进行定制训练】'qlora-pipe - A pipeline parallel training script for LLMs.' GitHub: github.com/tdrussell/qlora-pipe <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnzo8tlkcnj20yt0u0afc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 04:46:04 GMT</pubDate>
</item>
<item>
<title>【AGI的定义之争：人工智能的终极目标还有多远？】- 人工通用智能(AGI)这一术语在当前有关人工智能的讨论中无处不在，但对其定义和内涵却存在诸多争议。 - 一些...</title>
<link>https://weibo.com/1402400261/O69gfhC5j</link>
<guid>https://weibo.com/1402400261/O69gfhC5j</guid>
<content:encoded><![CDATA[
<div> 人工通用智能、定义之争、智能多样性、人类中心主义、理想化假设、身体感知能力、智能与物质关系、全面审视、开放态度、谨慎思考

<br /><br />总结: 本文讨论了人工通用智能(AGI)的定义之争，指出AGI定义的多样性和争议性，挑战了人类中心主义的思维定式。智能有多种形式和维度，不应将人类智能作为唯一标准。即使是人类也无法在所有领域表现出色，对AGI的理想化假设需要谨慎思考。讨论了AGI是否需要具备类人的身体和感知能力，触及了智能与物质关系的深层思考。文章提出了全面审视AGI内涵的视角，呼吁以开放和谨慎的态度探讨人工通用智能的未来。 <div>
【AGI的定义之争：人工智能的终极目标还有多远？】<br />- 人工通用智能(AGI)这一术语在当前有关人工智能的讨论中无处不在，但对其定义和内涵却存在诸多争议。  <br />- 一些组织和个人将AGI定义为能够像人类一样进行推理和解决问题的系统，但这一定义过于狭隘，忽视了智能的多样性。  <br />- 智能有多种形式和维度，将人类智能作为唯一标准具有局限性。动物和昆虫也展现出了与人类不同但同样令人印象深刻的智能。  <br />- 关于AGI是否应该模仿人脑，以及是否需要具备类似人类的身体和感知能力，学界尚无定论，存在不同观点。  <br />- 一些研究者提出，真正的AGI系统应该能够在多个领域展现出色的性能，但这一观点也受到质疑，因为即使是人类也无法在所有领域都表现出色。  <br />- 对AGI的定义和评判标准的争议，反映出人工智能领域在探索通用智能这一终极目标时仍面临诸多挑战和不确定性。  <br />- 尽管对AGI的理解存在分歧，但各方普遍认为，实现AGI将是人工智能发展的重要里程碑，对人类社会产生深远影响。  <br /><br />点评：<br />- 本文对AGI的定义之争进行了深入剖析，揭示了这一概念在学界和业界的模糊性和争议性，引发读者反思对智能本质的理解。  <br />- 作者提出将人类智能作为AGI标准具有局限性的观点颇具启发性，打破了人类中心主义的思维定式，让我们以更开放的视角看待智能的多样性。  <br />- 文章指出，即使是人类也无法在所有领域都表现出色，这一论断具有一定的颠覆性，挑战了对AGI的一些理想化假设和期望。  <br />- 对AGI是否需要具备类人的身体和感知能力的讨论，触及了人工智能与生物智能的本质区别，引发了关于智能与物质载体关系的深层思考。  <br />- 文章虽未给出对AGI的明确定义，但通过梳理不同观点，为读者提供了一个全面审视AGI内涵的视角，启发我们以更谨慎和开放的态度看待这一概念。<br />《Debates on the nature of artificial general intelligence | Science》 <a href="https://www.science.org/doi/10.1126/science.ado7069"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnzid60gsij20vk0u0tf2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 01:22:32 GMT</pubDate>
</item>
<item>
<title>【SceneScript：语言模型赋能3D场景理解】- Meta Reality Labs 研究团队开发了一种名为 SceneScript 的新方法，用于重建 3D 场景并表示物理空间的布局。 - Scene...</title>
<link>https://weibo.com/1402400261/O68Jg0DkB</link>
<guid>https://weibo.com/1402400261/O68Jg0DkB</guid>
<content:encoded><![CDATA[
<div> Meta Reality Labs, SceneScript, 3D场景理解, 自然语言, 语言模型, 突破性进展, AR技术, 应用前景, 跨领域融合, 人机交互

<br /><br />总结:
Meta Reality Labs的研究团队开发了一种名为SceneScript的新方法，利用自回归结构化语言模型将3D场景表示为自然语言，突破了传统的场景表示方式。这一方法利用语言模型的强大能力学习场景的结构化表示，取得了突破性进展，展现了在场景理解任务中的潜力。SceneScript被认为是通向真正AR眼镜的重要里程碑，有望连接物理世界和数字世界，加速AR技术的发展。这种新颖的思路和跨领域融合的方法对于激发创新思路和推动人工智能技术的应用具有重要意义。这一研究在多个领域都有广阔的应用前景，有助于提升人机交互和空间理解的能力。SceneScript的出现为3D场景表示开辟了新的方向，有望缩小3D重建社区与自然语言处理领域之间的距离。 <div>
【SceneScript：语言模型赋能3D场景理解】<br />- Meta Reality Labs 研究团队开发了一种名为 SceneScript 的新方法，用于重建 3D 场景并表示物理空间的布局。  <br />- SceneScript 使用自回归结构化语言模型将 3D 场景表示为自然语言，这是一种全新的场景表示方式。  <br />- 该方法利用大型语言模型的强大能力，学习场景的结构化表示，并生成符合物理约束的场景描述。  <br />- SceneScript 在标准 3D 重建基准测试中取得了最先进的性能，展示了其在场景理解和生成方面的优势。  <br />- 这项研究为将 3D 场景表示为语言开辟了新的方向，有望缩小 3D 重建社区与自然语言处理领域的距离。  <br />- SceneScript 被视为通向真正 AR 眼镜的重要里程碑，有助于连接物理世界和数字世界。  <br />- 该技术有望应用于虚拟助手、机器人导航、内容创作等领域，提升人机交互和空间理解的能力。  <br /><br />点评：  <br />- 将 3D 场景表示为自然语言的思路非常新颖，打破了传统的场景表示方式，具有颠覆性和启发性。  <br />- 利用语言模型的强大能力来理解和生成场景，这种跨领域的融合思维值得借鉴，有助于激发更多创新思路。  <br />- SceneScript 在性能上取得了突破性进展，展现了语言模型在场景理解任务中的巨大潜力，值得期待。  <br />- 该研究对于推动 AR 技术的发展具有重要意义，有望加速实现真正的 AR 眼镜，改变人们与数字世界的交互方式。  <br />- SceneScript 在多个领域都有广阔的应用前景，这种通用性和拓展性值得肯定，有助于推动人工智能技术的普及和应用。<br />《Introducing SceneScript, a novel approach for 3D scene reconstruction》 <a href="https://ai.meta.com/blog/scenescript-3d-scene-reconstruction-reality-labs-research/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzg0j9nuaj21hc0u04qp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 00:01:16 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带...</title>
<link>https://weibo.com/1402400261/O68BEFK2R</link>
<guid>https://weibo.com/1402400261/O68BEFK2R</guid>
<content:encoded><![CDATA[
<div> 可可粉, 转发, 评论, 数据结构, 算法, 动画图解, 实战代码示例, 主动思考, 互动环节

<br /><br />总结:
本文介绍了一本名为《hello 算法》的数据结构与算法书籍，截止日期为2024年3月29日12:00。读者可以通过转发和评论参与送出3本书籍的活动。这本书的特点在于配有生动的动画图解，使抽象的数据结构和算法变得直观易懂。同时，书中提供实战代码示例，让读者能够即学即用，巩固新知识。互动环节的设计有助于读者主动思考、提问和解决问题，带领读者进入算法的世界，轻松掌握知识。 <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 23:42:33 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O68z3vsYr</link>
<guid>https://weibo.com/1402400261/O68z3vsYr</guid>
<content:encoded><![CDATA[
<div> 度小满、大语言模型、全彩、内在机理、实践性、代码、杨青、训练经验、干货、实践者

<br /><br />总结:
本书《大语言模型：原理与工程实践(全彩)》由度小满轩辕大模型负责人杨青撰写，旨在揭开大语言模型的神秘面纱，透彻解读其内在机理和应用实践。书中系统性的知识体系和对实践性的重视是其特色之一，配有代码，并全彩印刷。杨青作为真正的大语言模型实践者，在书中分享了十亿、百亿、千亿等不同参数规模大语言模型的训练经验，内容满载干货，实用性强，绝非空谈。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 23:36:09 GMT</pubDate>
</item>
<item>
<title>今日推介(第1352期)：用逆向训练减轻“逆转诅咒“、面向强化学习的视频原则性表示学习、通过多尺度特征学习改进小规模视觉模型性能、通过一次编码并行解码实现高...</title>
<link>https://weibo.com/1402400261/O6845wLPl</link>
<guid>https://weibo.com/1402400261/O6845wLPl</guid>
<content:encoded><![CDATA[
<div> 逆向训练、逆转诅咒、面向强化学习、视频原则性表示学习、多尺度特征学习、小规模视觉模型、高效Transformer解码、函数树、透明机器学习

总结:<br />
本篇文章介绍了几种方法来提升机器学习的效果。首先，通过逆向训练可以减轻"逆转诅咒"现象，进而改善模型性能。其次，面向强化学习的视频原则性表示学习方法能够提高模型的学习效率。同时，通过多尺度特征学习可以显著改善小规模视觉模型的性能。此外，一次编码并行解码方法能够高效实现Transformer解码过程。最后，利用函数树实现透明机器学习可以增强模型的可解释性，提高模型的可信度。这些方法为机器学习的进步提供了重要的思路和方法。 <div>
今日推介(第1352期)：用逆向训练减轻“逆转诅咒“、面向强化学习的视频原则性表示学习、通过多尺度特征学习改进小规模视觉模型性能、通过一次编码并行解码实现高效Transformer解码、用函数树实现透明机器学习 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/688367695"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.22)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnzd2qlg3dj20go08ltae.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnzd2sjjqjj20go07hgme.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnzd2uuxi5j20go09yjsk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzd2xe44nj20go0h9764.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnzd31nv30j20go0kjglz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 22:19:50 GMT</pubDate>
</item>
<item>
<title>[CV] RadSplat: Radiance Field-Informed Gaussian Splatting for Robust Real-Time Rendering with 900+ FPS 网页链接 通过辐射场监督点云表示的优化和渲染，实...</title>
<link>https://weibo.com/1402400261/O680Jvcgj</link>
<guid>https://weibo.com/1402400261/O680Jvcgj</guid>
<content:encoded><![CDATA[
<div> 辐射场、点云表示、优化、渲染、复杂场景、实时、高质量、视图合成、RadSplat、900+ FPS  
<br />  
<br />总结:  
RadSplat通过辐射场监督点云表示的优化和渲染，实现了对复杂场景的实时高质量视图合成，达到了900+ FPS的渲染速度。该方法利用辐射场信息提高渲染质量，同时通过高效的点云表示实现实时渲染。这种方法能够在复杂场景下快速生成真实感强的视图，为实时渲染提供了一种稳健的方法。 <div>
[CV]  RadSplat: Radiance Field-Informed Gaussian Splatting for Robust Real-Time Rendering with 900+ FPS  <br /><a href="https://arxiv.org/abs/2403.13806"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过辐射场监督点云表示的优化和渲染，实现了对复杂场景的实时高质量视图合成。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzcuggq4wj20z01e67h4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzcugojirj217q0se47h.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 22:11:35 GMT</pubDate>
</item>
<item>
<title>#### [LG] RewardBench: Evaluating Reward Models for Language Modeling 网页链接 提出语言模型奖励模型评估基准RewardBench，评估各类模型的优劣势，发现现有...</title>
<link>https://weibo.com/1402400261/O67YsjTA0</link>
<guid>https://weibo.com/1402400261/O67YsjTA0</guid>
<content:encoded><![CDATA[
<div> 评估基准，语言模型，奖励模型，优劣势，推理，遵循指令，不足

<br /><br />总结:
这篇论文提出了一种名为RewardBench的评估基准，用于评估语言模型的奖励模型。研究发现，现有模型在推理和遵循指令方面存在明显不足，因此需要更好的奖励模型来提高模型的性能。提出的基准为研究者提供了一种评估不同模型优劣势的方法，有助于推动语言建模领域的发展。 <div>
#### [LG]  RewardBench: Evaluating Reward Models for Language Modeling  <br /><a href="https://arxiv.org/abs/2403.13787"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出语言模型奖励模型评估基准RewardBench，评估各类模型的优劣势，发现现有模型在推理和遵循指令方面仍存在明显不足。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzcoivi7yj212q1ju187.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzcojhbknj21i40pa0xw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 22:05:58 GMT</pubDate>
</item>
<item>
<title>[CL] RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content 网页链接 本文提出了一个多方面框架RigorLLM，通过数据增强、安全...</title>
<link>https://weibo.com/1402400261/O67Ul8jZG</link>
<guid>https://weibo.com/1402400261/O67Ul8jZG</guid>
<content:encoded><![CDATA[
<div> 多方面框架; 数据增强; 安全后缀优化; 模型融合; 大语言模型; 有害内容检测; 鲁棒性

本文介绍了一个名为RigorLLM的多方面框架，通过数据增强、安全后缀优化和模型融合等方法，提高了大语言模型对有害内容的检测能力和鲁棒性。通过优化输入和输出，让大语言模型更好地应对不良内容，提高了其应用的安全性和可靠性。该框架的综合应用，为大语言模型的发展和应用提供了重要的保障。 <div>
[CL] RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content  <br /><a href="https://arxiv.org/abs/2403.13031"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />本文提出了一个多方面框架RigorLLM，通过数据增强、安全后缀优化和模型融合，实现了对大语言模型的输入输出进行有害内容检测的强大鲁棒性。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzce172qbj21861jk7pd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzce1bwjrj212k0mqafc.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzce21dc8j21hq0vyqfp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzce2poqfj21i00rqaip.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 21:55:50 GMT</pubDate>
</item>
<item>
<title>[LG] Evolutionary Optimization of Model Merging Recipes 网页链接 提出进化模型融合方法,在参数和数据流空间通过进化算法自动发现模型的最优组合,实现跨域模...</title>
<link>https://weibo.com/1402400261/O67Rq1hAm</link>
<guid>https://weibo.com/1402400261/O67Rq1hAm</guid>
<content:encoded><![CDATA[
<div> 进化算法, 模型融合, 跨域模型, 参数空间, 数据流空间, 自动发现, 最优组合, 性能强劲, 新模型

Evolutionary Optimization of Model Merging Recipes 提出了一种进化模型融合方法，该方法在参数和数据流空间中运用进化算法来自动发现模型的最优组合，实现了跨域模型的高效融合，生成具有强劲性能的新模型。该研究为模型优化提供了一种全新的途径，有望在实际应用中帮助优化模型性能并节省人力成本。<br /><br />总结: 进化算法应用于模型融合，自动发现最优组合，生成强劲性能新模型，有望在实践中带来积极效果。 <div>
[LG] Evolutionary Optimization of Model Merging Recipes  <br /><a href="https://arxiv.org/abs/2403.13187"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />提出进化模型融合方法,在参数和数据流空间通过进化算法自动发现模型的最优组合,实现跨域模型的高效融合,生成性能强劲的新模型。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzc6kjjllj212w1k8dzq.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzc6ksku0j21ag0woakt.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzc6l8ez8j21a20fk79e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 21:48:38 GMT</pubDate>
</item>
<item>
<title>[LG] Evaluating Frontier Models for Dangerous Capabilities 网页链接 论文系统地评估了多种领域的AI危险能力,为未来的科学评估和风险管控奠定基础。 [图片][...</title>
<link>https://weibo.com/1402400261/O67NpDkRT</link>
<guid>https://weibo.com/1402400261/O67NpDkRT</guid>
<content:encoded><![CDATA[
<div> AI、危险能力、科学评估、风险管控、前沿模型

<br /><br />总结:
本论文针对多领域的AI危险能力进行系统评估，为未来科学评估和风险管控提供了基础。研究围绕前沿模型展开，重点关注发展中的危险能力，并提出评估框架和方法。通过深入研究和实证分析，得出了对不同领域和模型的危险潜在能力的结论。文章强调对AI危险能力的全面评估和风险控制的重要性，为相关领域的研究提供了有益的参考和指导。 <div>
[LG] Evaluating Frontier Models for Dangerous Capabilities  <br /><a href="https://arxiv.org/abs/2403.13793"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />论文系统地评估了多种领域的AI危险能力,为未来的科学评估和风险管控奠定基础。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbw9zov9j214k1ku1dp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzbwactj4j219i188as8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzbwansd4j218y0f0ac7.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzbwbb8x8j219m0mate3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 21:38:46 GMT</pubDate>
</item>
<item>
<title>函数树方法通过树结构化的单变量函数表示，实现了对复杂多变量函数的透明可解释建模。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Function Trees: Transparent Machine...</title>
<link>https://weibo.com/1402400261/O67KlbKQP</link>
<guid>https://weibo.com/1402400261/O67KlbKQP</guid>
<content:encoded><![CDATA[
<div> 函数树方法、树结构、单变量函数、复杂多变量函数、透明、可解释、建模、机器学习、J H. Friedman、Stanford University

总结:<br /><br />这篇文章介绍了函数树方法，通过树结构化的单变量函数表示复杂多变量函数，实现了对其的透明、可解释建模。该方法由斯坦福大学的J H. Friedman提出，有助于理解和解释机器学习模型的工作原理。函数树方法将复杂问题分解为简单的单变量函数，并利用树结构将它们组合起来，使模型更易于理解和解释。这种方法不仅提高了模型的可解释性，还为深入研究机器学习算法提供了新的思路。通过函数树方法，用户可以更直观地理解模型的预测过程，从而更好地应用和改进机器学习技术。 <div>
函数树方法通过树结构化的单变量函数表示，实现了对复杂多变量函数的透明可解释建模。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Function Trees: Transparent Machine Learning》J H. Friedman [Stanford University] (2024) <a href="https://arxiv.org/abs/2403.13141"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzbg4jbeqj21n80luaju.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbg4ua3jj20qo0wu0ty.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbg503xpj20r40yidix.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbg56ac0j21pw1ai786.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbo2grz1j20v80osq4e.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzbo2hx1xj20yr138whe.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzbo2h4m2j20wl13kjsb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbo2hhc4j20x50q0die.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzbo2h2q0j20va0nydgr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 21:31:12 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.21)》 爱可可微博热门分享(3.21) [图片]</title>
<link>https://weibo.com/1402400261/O657woCn0</link>
<guid>https://weibo.com/1402400261/O657woCn0</guid>
<content:encoded><![CDATA[
<div> 微博，热门，分享，爱可可，3.21

总结：<br /><br />爱可可微博3.21日分享了热门内容，引起众多网友关注。微博内容包括各种有趣、新鲜的信息，受到大家的热烈回应。网友们纷纷转发评论，展开讨论。这些分享丰富了用户的微博阅读体验，也增加了用户之间的互动。愿爱可可微博在未来能继续给大家带来更多精彩内容，引领网民们探索更广阔的世界。 <div>
《爱可可微博热门分享(3.21)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405014496543375877"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.21)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnz02s4zrkj20rs0fmad0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 14:50:04 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《AnySkill: Learning Open-Vocabulary Physical Skill for Interactive Agents》(CVPR 2024) GitHub: github.com/jiemingcui/anyskill《Tack...</title>
<link>https://weibo.com/1402400261/O64X3gfOe</link>
<guid>https://weibo.com/1402400261/O64X3gfOe</guid>
<content:encoded><![CDATA[
<div> 关键词: Open-Vocabulary Skill, Physical Skill Learning, Interactive Agents, Diffusion Models, Singularities, Time Intervals, Dance Camera Movement, Scene Reconstruction, Multi-View Generation, Model Merging Recipes

总结: <br /><br />《AnySkill: Learning Open-Vocabulary Physical Skill for Interactive Agents》介绍了一种学习开放词汇物理技能的方法，可以应用于交互式代理系统。<br />《Tackling the Singularities at the Endpoints of Time Intervals in Diffusion Models》解决了扩散模型中时间间隔端点的奇异性问题。<br />《DanceCamera3D: 3D Camera Movement Synthesis with Music and Dance》展示了一种能够结合音乐和舞蹈进行3D摄像机移动合成的方法。<br />《SuperPrimitive: Scene Reconstruction at a Primitive Level》介绍了在基本级别上进行场景重建的技术。<br />《VideoMV: Consistent Multi-View Generation Based on Large Video Generative Model》展示了基于大型视频生成模型的一致性多视图生成方法。<br />《Evolutionary Optimization of Model Merging Recipes》探讨了模型合并配方的进化优化方法。<br />《When Do We Not Need Larger Vision Models?》讨论了何时不需要更大的视觉模型。<br />《RewardBench: Evaluating Reward Models》介绍了评估奖励模型的方法。<br />《Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models》展示了通过混合门控线性递归和局部注意力提高语言模型效率的方法。<br />《How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments》评估了大语言模型在多智能体环境中的游戏能力。<br />《GAPS: Geometry-Aware, Physics-Based, Self-Supervised Neural Garment Draping》介绍了几何感知、基于物理的、自监督神经服装披挂技术。<br />《Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive》解决了偏好优化失败模式的问题。<br />《UrbanGPT: Spatio-Temporal Large Language Models》展示了时空大型语言模型UrbanGPT。<br />《RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation》介绍了通过鲁棒适应实现准确参数高效微调的RoSA方法。 <div>
几篇论文实现代码：<br />《AnySkill: Learning Open-Vocabulary Physical Skill for Interactive Agents》(CVPR 2024) GitHub: github.com/jiemingcui/anyskill<br />《Tackling the Singularities at the Endpoints of Time Intervals in Diffusion Models》(CVPR 2024) GitHub: github.com/PangzeCheung/SingDiffusion [fig2]<br />《DanceCamera3D: 3D Camera Movement Synthesis with Music and Dance》(CVPR 2024) GitHub: github.com/Carmenw1203/DanceCamera3D-Official<br />《SuperPrimitive: Scene Reconstruction at a Primitive Level》(CVPR 2024) GitHub: github.com/makezur/super_primitive<br />《VideoMV: Consistent Multi-View Generation Based on Large Video Generative Model》(2024) GitHub: github.com/alibaba/VideoMV [fig1]<br />《Evolutionary Optimization of Model Merging Recipes》(2024) GitHub: github.com/SakanaAI/evolutionary-model-merge<br />《When Do We Not Need Larger Vision Models?》(2024) GitHub: github.com/bfshi/scaling_on_scales<br />《RewardBench: Evaluating Reward Models》(2024) GitHub: github.com/allenai/reward-bench<br /> 《Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models》(2024) GitHub: github.com/kyegomez/Griffin<br />《How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments》(2024) GitHub: github.com/CUHK-ARISE/GAMABench<br />《GAPS: Geometry-Aware, Physics-Based, Self-Supervised Neural Garment Draping》(2024) GitHub: github.com/Simonhfls/GAPS<br />《Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive》(2024) GitHub: github.com/abacusai/smaug<br />《UrbanGPT: Spatio-Temporal Large Language Models》(2024) GitHub: github.com/HKUDS/UrbanGPT [fig3]<br />《RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation》(2024) GitHub: github.com/IST-DASLab/RoSA<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnyzbcmxhij22jj14qhdt.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnyzbpmsauj20ub0mo4qp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnyzc565i6j21k40j71kx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 14:24:16 GMT</pubDate>
</item>
<item>
<title>'FaceSearchSDK_Android - On Device Android Face 1:N and M:N Search With Liveness Detection &amp; Anti Spoofing SDK / 离线版Android 1:N 和M:N人脸检索，包含...</title>
<link>https://weibo.com/1402400261/O61EowFIA</link>
<guid>https://weibo.com/1402400261/O61EowFIA</guid>
<content:encoded><![CDATA[
<div> Android, FaceSearchSDK, 人脸检索, 活体检测, 反作弊, 离线版, SDK, GitHub, AnyLifeZLB

总结:
该'FaceSearchSDK_Android'是一个面向Android设备的SDK，提供了离线1:N和M:N人脸检索功能，同时包含活体检测和反作弊功能。开发者可以在GitHub上找到该SDK的资源。该SDK的功能可以帮助用户在Android设备上进行人脸识别和搜索，并具备活体检测和反作弊功能，提高了安全性和准确性。 <div>
'FaceSearchSDK_Android - On Device Android Face 1:N and M:N Search With Liveness Detection &amp; Anti Spoofing SDK / 离线版Android 1:N 和M:N人脸检索，包含活体检测反作弊 .' GitHub: github.com/AnyLifeZLB/FaceSearchSDK_Android <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnykrm7iyyj21gb0u0449.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 06:00:04 GMT</pubDate>
</item>
<item>
<title>【OpenDMD：基于分布匹配蒸馏的一步扩散的开源实现和模型】'OpenDMD - Open source implementation and models of One-step Diffusion with Distribution Matchi...</title>
<link>https://weibo.com/1402400261/O61DBbZDs</link>
<guid>https://weibo.com/1402400261/O61DBbZDs</guid>
<content:encoded><![CDATA[
<div> OpenDMD, 分布匹配蒸馏, 一步扩散, 开源实现, 模型, GitHub, Zeqiang-Lai, 分布匹配<br />
<br />
模型名称为OpenDMD，是一种基于分布匹配蒸馏的一步扩散模型，通过分布匹配来提高模型性能。本文提供了OpenDMD的开源实现和模型，项目可在GitHub上找到，作者是Zeqiang-Lai。OpenDMD的核心思想是利用分布匹配蒸馏技术来优化一步扩散模型，提高其性能和效率。通过实现和应用OpenDMD模型，可以更好地理解和研究一步扩散算法，为相关领域的研究和应用提供帮助。<br /><br />总结: <br />OpenDMD是基于分布匹配蒸馏的一步扩散模型的开源实现，通过优化分布匹配来提高模型性能。该模型在GitHub上可获得，作者为Zeqiang-Lai，有助于理解和研究一步扩散算法。 <div>
【OpenDMD：基于分布匹配蒸馏的一步扩散的开源实现和模型】'OpenDMD - Open source implementation and models of One-step Diffusion with Distribution Matching Distillation' GitHub: github.com/Zeqiang-Lai/OpenDMD <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnykpkmfgoj21ji0sctfu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:58:06 GMT</pubDate>
</item>
<item>
<title>【用于用户建模的大型语言模型(LLM-UM)相关论文列表】’Large Language Models for User Modeling (LLM-UM) Reading List - A list of large language models fo...</title>
<link>https://weibo.com/1402400261/O61CxpYtG</link>
<guid>https://weibo.com/1402400261/O61CxpYtG</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、用户建模、GitHub、研究论文、列表、阅读、LLM-UM、用户模型、技术、领域<br />
<br />
在GitHub上可以找到一个关于大型语言模型用于用户建模的研究论文列表。这个列表收集了有关LLM-UM领域的各种论文，涉及到用户模型和相关技术的研究成果。这个资源可以帮助研究人员更好地了解这个领域的最新进展和趋势，有助于推动大型语言模型在用户建模中的应用和发展。<br /><br />总结: <div>
【用于用户建模的大型语言模型(LLM-UM)相关论文列表】’Large Language Models for User Modeling (LLM-UM) Reading List - A list of large language models for user modeling (LLM-UM) papers.' GitHub: github.com/TamSiuhin/LLM-UM-Reading <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnykmt35gpj20vi0u0te3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnykmu3u3fj21fy0u0tjf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnykmvc0vtj21ji0u0tjf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:55:30 GMT</pubDate>
</item>
<item>
<title>【CoML：可以帮助数据科学和机器学习开发人员的开源项目，基于大型语言模型提供交互式自然语言编程接口，方便数据分析和机器学习任务】'CoML - Interactive codi...</title>
<link>https://weibo.com/1402400261/O61BmBLQw</link>
<guid>https://weibo.com/1402400261/O61BmBLQw</guid>
<content:encoded><![CDATA[
<div> CoML, 数据科学, 机器学习, 开源项目, 自然语言编程接口, 数据分析, 交互式, 大型语言模型, 开发人员, GitHub

<br /><br />总结:
CoML是一个开源项目，为数据科学家和机器学习开发人员提供交互式自然语言编程接口，借助大型语言模型的强大功能，方便他们进行数据分析和机器学习任务。该项目在GitHub上开源，为开发人员提供了强大的工具和支持。 <div>
【CoML：可以帮助数据科学和机器学习开发人员的开源项目，基于大型语言模型提供交互式自然语言编程接口，方便数据分析和机器学习任务】'CoML - Interactive coding assistant for data scientists and machine learning developers, empowered by large language models.' GitHub: github.com/microsoft/CoML <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnykjv10ptj21ji0o0q76.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:52:36 GMT</pubDate>
</item>
<item>
<title>【GAMA-Bench：多Agent环境下LLM博弈能力的性能测试基准】’GAMA-Bench - Benchmarking LLMs' Gaming Ability in Multi-Agent Environments' GitHub: github.com...</title>
<link>https://weibo.com/1402400261/O61z7renB</link>
<guid>https://weibo.com/1402400261/O61z7renB</guid>
<content:encoded><![CDATA[
<div> 多Agent环境、LLM博弈能力、性能测试、基准、GitHub、CUHK-ARISE、GAMABench

<br /><br />总结:
GAMA-Bench是一个用于测试LLM在多Agent环境下博弈能力的性能基准。该基准通过GitHub上的开源代码实现，由CUHK-ARISE团队开发。它可以帮助研究人员评估不同LLM算法在复杂多Agent环境中的性能，并进行性能比较和改进。通过GAMA-Bench，可以更好地理解和优化LLM算法在实际应用场景中的表现。 <div>
【GAMA-Bench：多Agent环境下LLM博弈能力的性能测试基准】’GAMA-Bench - Benchmarking LLMs' Gaming Ability in Multi-Agent Environments' GitHub: github.com/CUHK-ARISE/GAMABench <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnykdmp8jkj21g90u045r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:47:03 GMT</pubDate>
</item>
<item>
<title>【LLaMA Nuts and Bolts：旨在通过代码和文档了解 LLaMA 和其组件运行背后的原理的开源项目】'LLaMA Nuts and Bolts - A holistic way of understanding how LLa...</title>
<link>https://weibo.com/1402400261/O61xXbnCf</link>
<guid>https://weibo.com/1402400261/O61xXbnCf</guid>
<content:encoded><![CDATA[
<div> LLaMA, 组件, 代码, 文档, 原理, 运行, 开源项目, 详细, 理解, 实践<br />
<br />
LLaMA Nuts and Bolts 是一个旨在通过代码和详细文档全面了解LLaMA及其组件在实践中运行原理的开源项目。用户可以通过该项目深入理解LLaMA的工作机制，包括各个组件的运行方式和相互关联。通过查看代码和文档，用户可以更加深入地了解LLaMA项目的逻辑和实际应用。通过这个项目，用户可以掌握LLaMA的核心思想和技术细节，进而更好地使用和优化LLaMA系统。 <div>
【LLaMA Nuts and Bolts：旨在通过代码和文档了解 LLaMA 和其组件运行背后的原理的开源项目】'LLaMA Nuts and Bolts - A holistic way of understanding how LLaMA and its components run in practice, with code and detailed documentation.' GitHub: github.com/adalkiran/llama-nuts-and-bolts <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnykawu52cj20xk0u0jwh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:44:12 GMT</pubDate>
</item>
<item>
<title>【Lightning Thunder：开源 PyTorch 代码编译器，可以使 PyTorch 程序更快，无论是单个加速器还是分布式环境】'Lightning Thunder - Source to source compiler ...</title>
<link>https://weibo.com/1402400261/O61wG8Lpb</link>
<guid>https://weibo.com/1402400261/O61wG8Lpb</guid>
<content:encoded><![CDATA[
<div> PyTorch, 开源, 编译器, 程序, 加速器, 分布式环境, Lightning Thunder, PyTorch 程序, faster, GitHub

总结:<br /><br />文章介绍了 Lightning Thunder，一个开源的 PyTorch 代码编译器，能够使 PyTorch 程序在单个加速器和分布式环境中运行更快。该工具可以优化 PyTorch 程序的性能，提高执行效率，有助于提升程序的运行速度。对于使用 PyTorch 进行开发的用户来说，Lightning Thunder 是一个很有价值的工具，可以帮助他们提升程序的性能和效率，并提供更好的用户体验。感兴趣的开发者可以在 GitHub 上找到 Lightning Thunder 的源代码和详细信息。 <div>
【Lightning Thunder：开源 PyTorch 代码编译器，可以使 PyTorch 程序更快，无论是单个加速器还是分布式环境】'Lightning Thunder - Source to source compiler for PyTorch. It makes PyTorch programs faster on single accelerators and distributed.' GitHub: github.com/Lightning-AI/lightning-thunder <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnyk7u6d9gj216t0u0gpw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:41:03 GMT</pubDate>
</item>
<item>
<title>【大语言模型与工具使用相关论文资源列表】’Awesome LMs with Tools' GitHub: github.com/zorazrw/awesome-tool-llm #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O61ud4TmF</link>
<guid>https://weibo.com/1402400261/O61ud4TmF</guid>
<content:encoded><![CDATA[
<div> 大语言模型、工具使用、GitHub、资源列表、论文、LM、工具、使用、相关、Awesome<br />
<br />
提供了一个名为'Awesome LMs with Tools'的GitHub资源列表，包含了大语言模型与工具使用相关的论文。这个资源列表汇总了一些优秀的工具和语言模型，并为研究人员和开发者提供了丰富的参考资料。可以帮助人们更好地了解大语言模型的发展和应用，为相关研究和实践提供支持。通过这个GitHub项目，用户可以方便地获得最新的研究成果和工具推荐，促进学术交流和技术应用的发展。<br /><br /> 
总结:提供了一个包含大量论文资源的GitHub项目，方便研究人员和开发者获取最新的工具和语言模型推荐，促进大语言模型与工具使用相关研究的发展。 <div>
【大语言模型与工具使用相关论文资源列表】’Awesome LMs with Tools' GitHub: github.com/zorazrw/awesome-tool-llm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnyk1hgkfcj21550u0dkt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:34:58 GMT</pubDate>
</item>
<item>
<title>【GritQL 是一个描述式查询语言，可以用于搜索和修改代码，支持多种编程语言】'GritQL is a query language for searching, linting, and modifying code.' GitH...</title>
<link>https://weibo.com/1402400261/O61rC2jl3</link>
<guid>https://weibo.com/1402400261/O61rC2jl3</guid>
<content:encoded><![CDATA[
<div> GritQL, 查询语言, 搜索, 代码, 修改, 多种编程语言, GitHub, getgrit, gritql <br />
<br />
要点一: GritQL是一个用于搜索、审查和修改代码的查询语言。<br />
要点二: 它支持多种编程语言。<br />
要点三: GritQL在GitHub上有开源代码，并且可以访问github.com/getgrit/gritql。 <br /> <div>
【GritQL 是一个描述式查询语言，可以用于搜索和修改代码，支持多种编程语言】'GritQL is a query language for searching, linting, and modifying code.' GitHub: github.com/getgrit/gritql <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%BC%96%E7%A8%8B%23&amp;isnewpage=1"><span class="surl-text">#编程#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnyju2vf6kj21a90u043i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:28:34 GMT</pubDate>
</item>
<item>
<title>【李世乭“人机大战”8年后的反思和感悟】- 本文是世界围棋冠军李世乭(Lee Sedol)在 AlphaGo 战胜他 8 年后的一些反思和感悟。 - 李世乭回顾了 2016 年与 AlphaG...</title>
<link>https://weibo.com/1402400261/O5Zrf9g14</link>
<guid>https://weibo.com/1402400261/O5Zrf9g14</guid>
<content:encoded><![CDATA[
<div> 李世乭, AlphaGo, 人工智能, 围棋, 人机协作, AI 技术, 伦理, 安全性, 人类参与, 发展<br />
<br />
总结:<br />
李世乭回顾了与AlphaGo的历史性对决，被其出色表现震撼，改变了对人工智能的看法，认为人机协作是未来的发展趋势。他指出AI的发展需要人类参与和引导，呼吁保持理性和谨慎，并重视AI的伦理和安全性。他对AI技术持开放态度，强调人机合作能够充分发挥AI的价值，造福人类。 <div>
【李世乭“人机大战”8年后的反思和感悟】<br />- 本文是世界围棋冠军李世乭(Lee Sedol)在 AlphaGo 战胜他 8 年后的一些反思和感悟。  <br />- 李世乭回顾了 2016 年与 AlphaGo 的那场历史性对决，当时他对人工智能在围棋领域的能力持怀疑态度。但经过五番棋后，他被 AlphaGo 的出色表现所震惊。  <br />- 这场对决不仅改变了李世乭对人工智能的看法，也让全世界看到了 AI 在复杂决策领域的无限潜力。  <br />- 李世乭认为，AlphaGo 的诞生标志着人工智能时代的到来，它将深刻影响人类的生活和工作方式。  <br />- 尽管 AlphaGo 在围棋上战胜了人类，但李世乭并不认为人工智能会完全取代人类，相反，人机协作将成为未来的发展趋势。  <br />- 李世乭呼吁人们拥抱 AI 技术，但同时也要保持理性和谨慎，注重 AI 的伦理和安全性，确保其为人类社会带来利益而非危害。  <br />- 他认为，人工智能的发展需要人类的参与和引导，只有人机合作，才能充分发挥 AI 的价值，造福人类。  <br /><br />点评：<br />- 李世乭作为人工智能时代的见证者和参与者，他的反思和观点具有独特的洞见和权威性。  <br />- 他对人机协作的展望，体现了一种积极拥抱新技术的开放心态，而非对 AI 的盲目恐惧或排斥。  <br />- 他强调 AI 发展需要人类的参与和引导，这一观点具有前瞻性，有助于促进人工智能的健康发展。  <br />- 他对 AI 伦理和安全性的重视，反映出对这一新兴技术的理性思考和审慎态度，值得肯定。  <br />- 李世乭的观点富有洞见，既展现了对人工智能的热情，也蕴含了对其潜在风险的警示，是一种平衡和中庸之道。<br />《8 years later: A world Go champion’s reflections on AlphaGo》 <a href="https://blog.google/around-the-globe/google-asia/8-years-later-a-world-go-champions-reflections-on-alphago/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span> <span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnyb01j2yaj20qu0i077f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 00:22:10 GMT</pubDate>
</item>
<item>
<title>【OpenAI的GPT商店充斥大量违规内容】 - OpenAI 推出的 GPT 商店(GPT Store)旨在让开发者构建基于 OpenAI 生成式 AI 模型的定制聊天机器人，用于完成各种任务。 ...</title>
<link>https://weibo.com/1402400261/O5ZpaE0pX</link>
<guid>https://weibo.com/1402400261/O5ZpaE0pX</guid>
<content:encoded><![CDATA[
<div> 开AI、GPT商店、违规内容、审核、管理、挑战、安全、监管、AI创新、人们担忧<br /><br />总结:
OpenAI推出的GPT商店遭遇大量违规内容，包括侵犯版权的机器人和不当内容。管理和审核不足暴露了OpenAI的问题，需要加强内容审核和监管措施。AI系统面临伦理和安全挑战，需要制定严格准则。OpenAI需清理违规内容，确保商店健康发展。此事件引发人们对AI系统的担忧，平衡创新与秩序成为难题。 <div>
【OpenAI的GPT商店充斥大量违规内容】  <br />- OpenAI 推出的 GPT 商店(GPT Store)旨在让开发者构建基于 OpenAI 生成式 AI 模型的定制聊天机器人，用于完成各种任务。  <br />- 然而，该商店目前被大量奇怪的、可能侵犯版权的 GPT 机器人所淹没，这些机器人宣称能够生成迪士尼和漫威等知名 IP 的艺术作品。  <br />- 这些 GPT 机器人实际上只是将用户引导至第三方付费服务，并自称能够绕过 AI 内容检测工具。  <br />- 这一现象暴露了 OpenAI 在审核和管理 GPT 商店内容方面的不足，存在着较为宽松的监管。  <br />- 一些 GPT 机器人还声称能够生成令人反感或不当的内容，如仇恨言论、暴力内容等，这进一步加剧了对 OpenAI 内容审核的质疑。  <br /><br />点评：  <br />- OpenAI 在推出 GPT 商店时，可能低估了管理和审核内容的难度，导致了目前的混乱局面。  <br />- 过于宽松的审核政策，不仅可能助长版权侵权行为，还有引导 AI 系统产生有害内容的风险。  <br />- 这一事件再次凸显了 AI 系统在伦理和安全方面的挑战，需要制定更加严格的准则和监管措施。  <br />- 尽管 GPT 商店的初衷是推动 AI 创新，但如果缺乏有效管控，反而可能适得其反，损害 OpenAI 的声誉和公众对 AI 的信任。  <br />- OpenAI 需要及时采取行动，加强内容审核，清理违规内容，并制定更加透明和负责任的管理机制，以确保 GPT 商店的健康发展。  <br />- 这一事件也引发了人们对 AI 系统的担忧，如何在促进创新与维护秩序之间寻求平衡，是一个亟待解决的难题。<br />《OpenAI’s chatbot store is filling up with spam | TechCrunch》 <a href="https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnyau3kilwj20z60u0ti0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 00:17:04 GMT</pubDate>
</item>
<item>
<title>【AnimateDiff-Lightning：超快的文生视频实现】《AnimateDiff-Lightning - Lightning-fast text-to-video generation - a Hugging Face Space by ByteDance》 ...</title>
<link>https://weibo.com/1402400261/O5ZlXunOm</link>
<guid>https://weibo.com/1402400261/O5ZlXunOm</guid>
<content:encoded><![CDATA[
<div> 超快、文本生成、视频、实现、Hugging Face、ByteDance、AnimateDiff-Lightning、Lightning-fast、生成、实现

<br /><br />总结:
ByteDance推出了一款名为AnimateDiff-Lightning的工具，能够实现超快的文本生成视频。这个工具利用了Hugging Face的技术，并由ByteDance开发。用户可以通过输入文本来生成相应的视频内容，极大地提高了文本到视频的生成速度。AnimateDiff-Lightning可以帮助用户快速创建个性化的视频内容，为文本生成领域带来了新的可能性。 <div>
【AnimateDiff-Lightning：超快的文生视频实现】《AnimateDiff-Lightning - Lightning-fast text-to-video generation - a Hugging Face Space by ByteDance》 <a href="https://huggingface.co/spaces/ByteDance/AnimateDiff-Lightning"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5014274796617730"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/5396ee05ly1hnyamdymnpj20ks0k0t8y.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/FQbKlqxElx08ds03YsbK010412001I340E010.mp4?label=mp4_720p&amp;template=748x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1710983937&amp;ssig=BPGTmcJN26&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/ckileuT4lx08ds03WHbG010412000VAs0E010.mp4?label=mp4_hd&amp;template=496x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1710983937&amp;ssig=4CBR22jtlO&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/lsaLbCSXlx08ds03WtoQ010412000DV10E010.mp4?label=mp4_ld&amp;template=372x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1710983937&amp;ssig=VoFISDuZqH&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5014274796617730" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 00:09:09 GMT</pubDate>
</item>
<item>
<title>【用GaLore在消费级硬件上训练大模型】 - GaLore 是一种新的参数高效微调(Parameter Efficient Finetuning， PEFT)方法，可以在消费级GPU(如 RTX 3090)上高效训...</title>
<link>https://weibo.com/1402400261/O5ZkH1crh</link>
<guid>https://weibo.com/1402400261/O5ZkH1crh</guid>
<content:encoded><![CDATA[
<div> GaLore, 参数高效微调, 消费级硬件, 训练, 大模型, 语言模型, 低秩, 稀疏, 性能, 内存, 计算资源 

<br /><br />总结:
GaLore 是一种新的参数高效微调方法，可以在消费级硬件上训练大型语言模型，采用了低秩和稀疏的参数分解方式，显著降低了内存和计算资源消耗。与其他方法相比表现出较高性能，使得在消费级GPU上训练包含70亿参数的语言模型成为可能，仅需较少优化器状态和梯度所需内存。GaLore不仅适用于自然语言处理领域，也具有广泛的应用前景，有望促进大型模型的民主化。其提出的新颖思路和性能突出，有望改变大型模型训练的范式，但还需面临一些挑战，如泛化性能和训练稳定性，并需要关注能源消耗、隐私和安全性等问题。GaLore的出现值得关注，体现了对问题的深入思考和创新。 <div>
【用GaLore在消费级硬件上训练大模型】 <br />- GaLore 是一种新的参数高效微调(Parameter Efficient Finetuning， PEFT)方法，可以在消费级GPU(如 RTX 3090)上高效训练大型语言模型。  <br />- 与其他PEFT方法(如LoRA、Prefix-Tuning等)相比，GaLore在保持性能的同时，显著降低了所需的内存和计算资源。<br />- GaLore 的关键创新在于引入了一种新的参数分解方式，将模型参数分解为低秩和稀疏两部分，从而大幅减少需要微调的参数数量。<br />- GaLore使得在消费级GPU如RTX 4090上训练包含多达70亿参数的语言模型成为可能，这是通过显著减少优化器状态和梯度所需的内存实现的。   <br />- 在 GPT-2 等基准测试中，GaLore 展现出与完整模型微调相当的性能，但仅需 1/10 的内存和计算资源。  <br />- GaLore 不仅适用于自然语言处理任务，对于计算机视觉等其他领域也具有广阔的应用前景。  <br />- 该技术有望推动大型模型的民主化，使更多个人研究者和小型机构能够在普通硬件上训练和部署这些模型。<br /><br />点评： <br />- GaLore 的提出打破了人们对大型模型训练必须依赖昂贵硬件的传统观念，这一反常规的创新值得关注。  <br />- 将模型参数分解为低秩和稀疏两部分的思路具有很高的创新性和独创性，体现了作者对问题的深入思考。  <br />- 如果 GaLore 的性能优势得到进一步验证，它有望彻底改变大型模型训练的范式，推动 AI 民主化进程。  <br />- 尽管取得了突破性进展，但 GaLore 在实际应用中可能还面临一些挑战，如泛化性能、训练稳定性等，需要持续优化和改进。  <br />- 该技术的出现也引发了一些值得深思的问题，比如大型模型的能源消耗、隐私和安全性等，需要引起足够重视。<br />《GaLore: Advancing Large Model Training on Consumer-grade Hardware》 <a href="https://huggingface.co/blog/galore"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnyaj8wnlkj20vg0u0dkt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 00:06:02 GMT</pubDate>
</item>
<item>
<title>【泛洪预警的"AI力量"：跨界协作,开放创新】 - 洪水是最常见的自然灾害，每年全球造成约500亿美元经济损失。气候变化导致洪水灾害频率上升。约15亿人面临洪水风...</title>
<link>https://weibo.com/1402400261/O5Zh7dYN0</link>
<guid>https://weibo.com/1402400261/O5Zh7dYN0</guid>
<content:encoded><![CDATA[
<div> 洪水预警、AI技术、Google、全球预报系统、机器学习、数据训练、合作伙伴、开放创新、挑战、实际应用

总结:<br /><br />本文介绍了Google利用人工智能技术提高洪水预警系统的全球规模预报能力。通过机器学习技术，Google建立了实时全球洪水预报系统，提前5天扩大了预报时间窗口，尤其在非洲和亚洲地区取得了较好的预报质量。模型训练数据包括公开天气数据和流域数据，利用LSTM模型表现优异。Google的模型比当前最佳全球预报系统提前5天就可达到其发布当天的准确度，尤其在极端洪水预报方面具有明显优势。未来，Google将继续拓展覆盖范围，加入更多洪水类型，与合作伙伴共同提升洪水预报质量，为社区提供更加可靠的洪水抗灾能力。该研究充分体现了人工智能技术在解决现实世界问题中的潜力，并积极倡导开放数据和开放科学合作精神，值得在其他领域进行进一步探索和推广。虽然取得了令人鼓舞的成果，但在实际应用中仍需持续关注和改进，如模型可解释性、偏差问题等挑战。 <div>
【泛洪预警的"AI力量"：跨界协作,开放创新】   <br />- 洪水是最常见的自然灾害，每年全球造成约500亿美元经济损失。气候变化导致洪水灾害频率上升。约15亿人面临洪水风险。提高预警系统准确性和及时性，每年可挽救成千上万条生命。   <br />- Google自2017年开始洪水预报研究，通过多年努力，建立了实时全球洪水预报系统，为搜索、地图、手机通知等提供预警。但要实现全球规模预报，特别是数据匮乏地区，需要更多技术突破。   <br />- Google最新Nature论文采用机器学习技术，相比当前最佳全球预报系统，平均将预报提前时间从0天扩大到5天，使非洲和亚洲地区预报质量与欧洲接近。该成果可为上亿人提供提前7天的河流预警。   <br />- 机器学习模型训练数据包括公开天气数据、流域数据等。一个模型训练全球5680个流域站点数据，可扩展到无监测数据流域。LSTM模型表现优异。   <br />- Google模型相比当前最佳全球预报系统GloFAS，提前5天就可达到GloFAS发布当天准确度，尤其在较大规模极端洪水预报方面优势明显。   <br />- 未来工作将继续拓展覆盖范围，加入更多洪水类型，与合作伙伴进一步提升预报质量，为社区提供洪水抗灾能力。<br /><br />点评： <br />- 该研究体现了人工智能在解决现实世界问题方面的巨大潜力，尤其是那些传统方法难以应对的挑战。  <br />- 利用机器学习模型克服数据匮乏的限制，是一种行之有效的创新方法，值得在其他领域进一步探索和推广。  <br />- 开放数据和开放科学精神，是推动该项目取得进展的关键因素之一，这种合作共赢的模式值得借鉴。  <br />- 该研究不仅关注技术创新本身，还重视与各界合作伙伴的协同，以最大程度发挥技术的社会影响力，这种全局观是可喜的。  <br />- 虽然取得了令人鼓舞的成果，但在实际应用中仍可能面临诸多挑战，如模型的可解释性、偏差问题、与现有系统的整合等，需要持续关注和改进。<br />《Using AI to expand global access to reliable flood forecasts – Google Research Blog》 <a href="https://blog.research.google/2024/03/using-ai-to-expand-global-access-to.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnya9urb60j20t70lwq60.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnya9w336lj20qo0f0q3q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnya9xmpo2j20qo0dc0tv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnya9zwf1xj213d0j5tb4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnyaa19x1yj21rj0u0gp8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 23:57:13 GMT</pubDate>
</item>
<item>
<title>【Common Corpus 让 AI 更透明】- Hugging Face发布了Common Corpus，这是迄今为训练大规模语言模型(LLM)发布的最大公共领域数据集。 - Common Corpus包含来自各...</title>
<link>https://weibo.com/1402400261/O5Zfw6TaS</link>
<guid>https://weibo.com/1402400261/O5Zfw6TaS</guid>
<content:encoded><![CDATA[
<div> 公开获取、透明度、可解释性、多主题、多语种、偏见、算力资源、模型权重、隐私、安全性
<br />
<br />
总结: Hugging Face发布了迄今为训练大规模语言模型(LLM)发布的最大公共领域数据集Common Corpus，包含来自各种文化遗产计划的500亿字，多语种且是包括1800亿英语词汇在内迄今为止最大的数据集。这一举措有望扭转AI过于集中于少数科技巨头的现状，促进AI民主化进程。公开数据有助于提高AI系统的透明度和可解释性，避免偏见和片面性。然而，实现AI民主化仍需更多努力，如算力资源的开放、模型权重的共享。同时，需注意隐私和安全性问题，平衡开放与管控之间的关系。Common Corpus为AI开放、多样和大众化提供了重要支持。 <div>
【Common Corpus 让 AI 更透明】<br />- Hugging Face发布了Common Corpus，这是迄今为训练大规模语言模型(LLM)发布的最大公共领域数据集。   <br />- Common Corpus包含来自各种文化遗产计划的500亿字。   <br />- Common Corpus是多语言的，是英语、法语、荷兰语、西班牙语、德语和意大利语等语种规模最大的语料库。   <br />- Common Corpus表明，可以在没有版权顾虑的来源上训练完全开放的LLM。   <br />- Common Corpus包含1800亿英语词汇，是迄今为止最大的英语数据集。还包括法语、德语、西班牙语、荷兰语和意大利语等语言的最大开放数据集。   <br />- Common Corpus不仅是开放的，而且质量更高、更多样化，比通常用于预训练的网页存档数据集更理想。   <br />- 这只是工作的开始，未来还会继续丰富这个集合，以支持AI的开放可复现的研究，也使AI更加开放、多样和大众化。<br /><br />点评： <br />- Common Corpus 的发布是 AI 民主化进程中的一个重要里程碑，有望扭转目前 AI 发展过于集中于少数科技巨头的现状。  <br />- 公开获取训练数据，有助于提高 AI 系统的透明度和可解释性，这是构建可信赖 AI 的关键一步。  <br />- 数据集的多语种和多主题特性，有利于培养更加通用和包容的 AI 模型，避免偏见和片面性。  <br />- 尽管取得了可喜进展，但要真正实现 AI 民主化仍需要更多的努力，包括算力资源的开放、模型权重的共享等。  <br />- 开放数据和模型的同时，也需要注重隐私和安全性，防止滥用。如何在开放与管控之间寻求平衡，是一个值得深入探讨的课题。<br />《Releasing Common Corpus: the largest public domain dataset for training LLMs》 <a href="https://huggingface.co/blog/Pclanglais/common-corpus"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnya5zh93gj20xq0u0gps.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 23:53:17 GMT</pubDate>
</item>
<item>
<title>[good] - 转发 @张俊林say:&amp;ensp;这里以通俗易懂的方式来分析Sora的可能做法，包括它的整体结构以及关键组件。我希望即使您不太懂技术，也能大致看明白Sora的可...</title>
<link>https://weibo.com/1402400261/O5ZdD4U3Z</link>
<guid>https://weibo.com/1402400261/O5ZdD4U3Z</guid>
<content:encoded><![CDATA[
<div> Sora, 分析, 结构, 关键组件, 图解, 技术, 理解, 机制, 复杂, 易懂

<br /><br />
Sora 的可能做法通过通俗易懂的方式进行分析，主要包括了其整体结构和关键组件，作者通过几十张图解来帮助读者更好地理解。即使不懂技术的读者也能大致了解 Sora 的可能做法，作者保证如果读者对某部分不理解，那是作者的责任。整篇文章分析清晰，内容包括 Sora 的结构、关键组件、机制等，通过图解的方式使整个过程看似复杂的机制变得更加直观易懂。文章引人入胜，对于想要了解 Sora 的读者极具帮助和启发。

<br /><br />
总结: 
1. Sora 的可能做法通过图解分析，便于理解。
2. 内容涵盖整体结构、关键组件、机制等要点。
3. 作者承诺保证即使对技术不熟悉的读者也能明白。
4. 文章引人入胜，对读者提供了有益的启发。 <div>
<span class="url-icon"><img alt="[good]" src="https://h5.sinaimg.cn/m/emoticon/icon/others/h_good-0c51afc69c.png" style="width: 1em; height: 1em;" /></span><br /><blockquote> - 转发 <a href="https://weibo.com/1064649941" target="_blank">@张俊林say</a>: 这里以通俗易懂的方式来分析Sora的可能做法，包括它的整体结构以及关键组件。我希望即使您不太懂技术，也能大致看明白Sora的可能做法，所以画了几十张图来让看似复杂的机制更好理解，如果您看完对某部分仍不理解，那是我的问题。<br /><a href="https://zhuanlan.zhihu.com/p/687928845"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">技术神秘化的去魅：Sora关键技术逆向工程图解</span></a> <img src="https://tvax3.sinaimg.cn/large/3f7544d5ly1hnx6es8uc5j223o16wnj5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/3f7544d5ly1hnx6f6gt4ij22761801kx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/3f7544d5ly1hnx6fgpk12j225c16kx01.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/3f7544d5ly1hnx6fsmhuvj21zm184kjl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/3f7544d5ly1hnx6gclielj227g16k7wh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/3f7544d5ly1hnx6gpi2tcj224u18w4qp.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 23:48:38 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O5Zd1EKiB</link>
<guid>https://weibo.com/1402400261/O5Zd1EKiB</guid>
<content:encoded><![CDATA[
<div> 大语言模型，全彩，内在机理，应用实践，系统性，实践性，杨青，度小满，经验，训练。<br />
<br />
总结：本书《大语言模型：原理与工程实践(全彩)》由度小满轩辕大模型负责人杨青编写，揭开大语言模型的神秘面纱，重点解读其内在机理和应用实践。书中系统性强，涵盖了多种不同参数规模的大语言模型训练经验，充满干货且内容实用，具有较高的参考价值。截止日期为2024年3月24日中午12点，*可可粉*转发+评论即可参与赢取3本书。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 23:47:09 GMT</pubDate>
</item>
<item>
<title>今日推介(第1351期)：用语言纠正即时提高机器人性能、基于图表的推理、基于大型语言模型的大规模文本挖掘、端到端视频条件策略学习与交叉注意力Transformer、非...</title>
<link>https://weibo.com/1402400261/O5YETn8cu</link>
<guid>https://weibo.com/1402400261/O5YETn8cu</guid>
<content:encoded><![CDATA[
<div> 机器人性能、图表推理、大规模文本挖掘、视频条件策略学习、交叉注意力Transformer、非负性对比学习

总结:<br />
本文介绍了几篇关于机器学习领域的研究论文，涉及到用语言纠正即时提高机器人性能、基于图表的推理、基于大型语言模型的大规模文本挖掘、端到端视频条件策略学习与交叉注意力Transformer以及非负性对比学习等技术。这些研究为机器学习领域的发展探索了新的可能性，对于提升机器智能的水平具有重要意义。通过不断地探索和实践，可以使机器学习技术得到更好的应用和发展，进一步推动人工智能领域的进步。 <div>
今日推介(第1351期)：用语言纠正即时提高机器人性能、基于图表的推理、基于大型语言模型的大规模文本挖掘、端到端视频条件策略学习与交叉注意力Transformer、非负性对比学习  公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/688164480"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.21)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hny7jruc6kj20go06x0to.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hny7ju4scbj20go0gldh3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hny7jwsfcxj20go0cb75r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hny7k0dyhlj20go07ewfh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hny7k2yzxoj20go06kmxo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 22:23:03 GMT</pubDate>
</item>
<item>
<title>[CV] HUGS: Holistic Urban 3D Scene Understanding via Gaussian Splatting 网页链接 介绍了一种新的HUGS管道，用于实现城市3D场景的整体理解，仅依靠RGB图像。...</title>
<link>https://weibo.com/1402400261/O5YBl0oTU</link>
<guid>https://weibo.com/1402400261/O5YBl0oTU</guid>
<content:encoded><![CDATA[
<div> 关键词: HUGS, 3D场景理解, 高斯Splatting, 动态对象定位, 物理约束, 实时渲染, 2D和3D语义信息, KITTI数据集, 3D边界框, 姿态优化

总结:<br /><br />本研究介绍了一种名为HUGS的新管道，利用高斯Splatting技术实现城市3D场景的整体理解，仅依靠RGB图像。该方法结合静态和动态3D高斯模型，优化几何结构、外观、语义及运动，特别是能有效处理动态对象定位噪声。关键创新在于利用物理约束规则化移动对象的姿态，减少跟踪噪声影响，提高性能。HUGS支持实时渲染新视角，并准确提取2D和3D语义信息。实验证实了该方法在KITTI、KITTI-360和Virtual KITTI 2数据集上的有效性，填补了现有方法在动态城市场景理解中的不足，如需人工标注的3D边界框和实时渲染挑战。 <div>
[CV] HUGS: Holistic Urban 3D Scene Understanding via Gaussian Splatting  <br /><a href="https://arxiv.org/abs/2403.12722"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种新的HUGS管道，用于实现城市3D场景的整体理解，仅依靠RGB图像。HUGS通过3D高斯Splatting技术，结合静态和动态3D高斯模型，优化几何结构、外观、语义及运动，特别是在动态对象定位噪声较大的情况下也能有效工作。该方法的关键创新在于利用物理约束规则化移动对象的姿态，减少跟踪噪声的影响，从而提高性能。此外，HUGS支持实时渲染新视角，并准确提取2D和3D语义信息。在KITTI、KITTI-360和Virtual KITTI 2数据集上的实验表明了该方法的有效性。该研究填补了现有方法在动态城市场景理解中的不足，如需大量人工标注的3D边界框和实时渲染的挑战。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hny7ay8od7j21a61ictvw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hny7ayu74pj21oi0rwn7v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 22:14:17 GMT</pubDate>
</item>
<item>
<title>[LG] Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices 网页链接 全面探讨了大型语言模型(LLM)在安全性和隐私方面的各种挑...</title>
<link>https://weibo.com/1402400261/O5YyJCGSc</link>
<guid>https://weibo.com/1402400261/O5YyJCGSc</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、安全性、隐私、风险、攻击、脆弱性、红队测试、水印、AI文本检测、风险管理

总结:<br />
本文全面探讨了大型语言模型（LLMs）在安全性和隐私方面面临的挑战，指出了信息泄露、记忆化和安全缺陷等风险。文章分析了模型本身、训练时和推理时的攻击脆弱性，提出了红队测试、模型编辑、水印和AI文本检测等策略来减轻风险。尽管已有策略存在局限，但建议未来研究应该更全面、跨学科地考虑LLMs的安全性和风险管理，以促进其负责任和道德的使用。 <div>
[LG] Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices  <br /><a href="https://arxiv.org/abs/2403.12503"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />全面探讨了大型语言模型(LLM)在安全性和隐私方面的各种挑战。LLM虽在自然语言处理领域取得革命性进展，但同时也带来了信息泄露、记忆化和安全缺陷等风险。本文研究分析了模型本身、训练时和推理时的攻击脆弱性，并讨论了红队测试、模型编辑、水印和AI文本检测等减轻风险的策略。尽管已有策略存在局限，文章建议未来研究应更全面、跨学科地考虑LLMs的安全性和风险管理，以促进其负责任和道德的使用。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hny74a6qjcj213o1je4ig.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hny74aqwdcj211818m47v.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hny74b8vp5j219y0wwqbh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 22:07:53 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.20)》 爱可可微博热门分享(3.20) [图片]</title>
<link>https://weibo.com/1402400261/O5VrIvUz3</link>
<guid>https://weibo.com/1402400261/O5VrIvUz3</guid>
<content:encoded><![CDATA[
<div> 微博，爱可可，热门，分享，热点，3.20，关注，话题，讨论，社交

《爱可可微博热门分享(3.20)》报道了当日在微博上热门的话题和讨论内容。用户们热烈关注并分享了各种热点话题，展开了讨论和交流。这些热门话题引发了社交媒体上的热议，显示出用户对各种议题的关注和兴趣。大家纷纷在微博上发表看法，分享观点，形成了热门内容和吸引了众多关注。总的来说，这些讨论内容和话题在社交媒体上引起了广泛的关注和讨论。 <br /><br />总结: <div>
《爱可可微博热门分享(3.20)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405014124667994223"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.20)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnxtddcnroj20rf0ffmyp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 14:12:21 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments》(ICLR 2024) GitHub: github.co...</title>
<link>https://weibo.com/1402400261/O5VqD8Dwz</link>
<guid>https://weibo.com/1402400261/O5VqD8Dwz</guid>
<content:encoded><![CDATA[
<div> 关键词：图像分割、神经网络、模型、变化检测、数据集、生成环境、模型修剪、视觉-语言模型、卷积神经网络、迁移学习

总结：<br />
这篇综述了几篇最新的论文以及他们在GitHub上的代码实现，涉及到图像分割、神经网络、模型稳定性、变化检测、数据集处理、生成环境、模型修剪、视觉-语言模型等多个领域。通过这些论文和代码的介绍，读者可以了解到最新的研究进展和方法，以及如何应用这些方法解决实际问题。同时，这些研究也展示了人工智能领域的多样性和个性化，为未来的研究和应用提供了思路和启发。 <br /><br />总结: <div>
几篇论文实现代码：<br />《Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments》(ICLR 2024) GitHub: github.com/YangYangGirl/BoS<br />《Diversified and Personalized Multi-rater Medical Image Segmentation》(CVPR 2024) GitHub: github.com/ycwu1997/D-Persona<br />《Arc2Face: A Foundation Model of Human Faces》(2024) GitHub: github.com/foivospar/Arc2Face [fig1]<br />《LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images》(2024) GitHub: github.com/thunlp/LLaVA-UHD [fig2]<br />《Generic 3D Diffusion Adapter Using Controlled Multi-View Editing》(2024) GitHub: github.com/Lakonik/MVEdit<br />《POCO: Pose and Shape Estimation with Confidence》(2024) GitHub: github.com/saidwivedi/POCO<br />《A Change Detection Reality Check》(2024) GitHub: github.com/isaaccorley/a-change-detection-reality-check<br />《Unified Training of Universal Time Series Forecasting Transformers》(2024) GitHub: github.com/SalesforceAIResearch/uni2ts<br />《The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning》(2024) GitHub: github.com/centerforaisafety/wmdp [fig3]<br />《Do Membership Inference Attacks Work on Large Language Models?》(2024) GitHub: github.com/iamgroot42/mimir<br />《RSBuilding: Towards General Remote Sensing Image Building Extraction and Change Detection with Foundation Model》(2024) GitHub: github.com/Meize0729/RSBuilding [fig4]<br />《InstructAny2Pix: Flexible Visual Editing via Multimodal Instruction Following》(2024) GitHub: github.com/jacklishufan/InstructAny2Pix<br />《Distilling Datasets Into Less Than One Image》(2024) GitHub: github.com/AsafShul/PoDD<br />《Chain-of-Spot: Interactive Reasoning Improves Large Vision-Language Models》(2024) GitHub: github.com/dongyh20/Chain-of-Spot<br />《RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback》(2024) GitHub: github.com/OceannTwT/ra-isf [fig5]<br />《EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents》(2024) GitHub: github.com/aszala/EnvGen [fig6]<br />《Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes》(2024) GitHub: github.com/ldery/Bonsai<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxrvnly4pj219y0s6kjl.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxrwcqnx1j21i00sa7cu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxsadvxz3j20rf0e542q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxsdqon3ij23641ewqv5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxsowq13jj21060jegyd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnxstvypkkj214r0fp179.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 14:09:40 GMT</pubDate>
</item>
<item>
<title>【可视水印去除相关资源列表Mirascope是一个快速高质量开发的 LLM 工具集，让编写 Python 代码如同使用熟悉的 Python 代码一样简洁易写。】’Awesome Visible Wa...</title>
<link>https://weibo.com/1402400261/O5Vmnhd7B</link>
<guid>https://weibo.com/1402400261/O5Vmnhd7B</guid>
<content:encoded><![CDATA[
<div> GitHub, Mirascope, LLM, 工具集, Python, 简洁易写, 高质量, 快速开发, 可视水印去除

总结：<br /><br />这篇文章介绍了一个名为Mirascope的LLM工具集，能够快速高质量地开发可视水印去除的功能。使用该工具集，编写Python代码就像编写熟悉的Python代码一样简洁易写。通过在GitHub上查找“Awesome Visible Watermark Removal”，可以找到更多相关资源。Mirascope的特点包括快速开发和高质量输出，适合用于去除图片中的可视水印。整体来说，这个工具集为开发人员提供了便捷的工具来处理可视水印的相关问题。 <div>
【可视水印去除相关资源列表Mirascope是一个快速高质量开发的 LLM 工具集，让编写 Python 代码如同使用熟悉的 Python 代码一样简洁易写。】’Awesome Visible Watermark Removal' GitHub: github.com/bcmi/Awesome-Visible-Watermark-Removal <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnxsztsh6qj20y20u00xq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:59:11 GMT</pubDate>
</item>
<item>
<title>【Mirascope：快速高质量开发的 LLM 工具集】'Mirascope - LLM toolkit for lightning-fast, high-quality development' GitHub: github.com/Mirascope/mirascop...</title>
<link>https://weibo.com/1402400261/O5Vlxv7Rw</link>
<guid>https://weibo.com/1402400261/O5Vlxv7Rw</guid>
<content:encoded><![CDATA[
<div> LLM、快速、高质量、开发、工具集、Lightning、Mirascope、GitHub、高效、代码<br />
<br />
LLM工具集Mirascope旨在提供给开发者一个快速高质量开发的解决方案。通过这个Lightning工具集，开发者可以更加高效地进行代码开发，提高开发效率，同时保证代码质量。Mirascope的GitHub页面提供了详细的信息和资源，让开发者可以更好地了解和使用这个工具集。通过Mirascope，开发者可以更加轻松地完成开发任务，提升自身的开发能力。总而言之，Mirascope是一个值得开发者关注和使用的高效工具集。 <br /><br />总结: <div>
【Mirascope：快速高质量开发的 LLM 工具集】'Mirascope - LLM toolkit for lightning-fast, high-quality development' GitHub: github.com/Mirascope/mirascope <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnxsxp7ojqj21ji0pagpj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:57:08 GMT</pubDate>
</item>
<item>
<title>【表格数据的监督学习】’Awesome Self-Supervised Learning for Non-Sequential Tabular Data (SSL4NSTD) - A collection of research materials on SSL for no...</title>
<link>https://weibo.com/1402400261/O5VjP0XY8</link>
<guid>https://weibo.com/1402400261/O5VjP0XY8</guid>
<content:encoded><![CDATA[
<div> 关键词：self-supervised learning, 非序列数据, 表格数据, 监督学习

总结:<br /><br />这篇文章介绍了有关非序列数据中自监督学习的研究材料，主要关注表格数据的监督学习。自监督学习是一种无需人工标注的学习方法，通过模型自身生成标签进行训练。针对非序列数据，如表格数据，研究者们提出了许多创新的方法和技术，以实现更有效的监督学习。这个GitHub项目收集了相关研究材料，为对这一领域感兴趣的人提供了宝贵的资源和参考。通过研究这些材料，人们可以了解到最新的自监督学习技术在非序列数据上的应用和研究进展，有助于推动该领域的发展和创新。 <div>
【表格数据的监督学习】’Awesome Self-Supervised Learning for Non-Sequential Tabular Data (SSL4NSTD) - A collection of research materials on SSL for non-sequential tabular data (SSL4NSTD)' GitHub: github.com/wwweiwei/awesome-self-supervised-learning-for-tabular-data <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnxsta90joj21ji0nkaf0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:52:54 GMT</pubDate>
</item>
<item>
<title>【DSPy相关资源大列表】’Awesome DSPy - An Awesome list of curated DSPy resources.' GitHub: github.com/ganarajpr/awesome-dspy #开源# #机器学习# #人工智...</title>
<link>https://weibo.com/1402400261/O5VfXtRGo</link>
<guid>https://weibo.com/1402400261/O5VfXtRGo</guid>
<content:encoded><![CDATA[
<div> GitHub, curated, DSPy, resources, list, awesome, Ganarajpr, resource, list, DSPy<br />
<br />关于DSPy的资源列表已经在GitHub上由Ganarajpr精心整理，包含了丰富的资源和信息。这个列表提供了许多有用的链接和工具，可以帮助开发人员更好地了解和学习DSPy。其中包含了各种教程、文档、代码示例以及其他相关资源，适合初学者和有经验的开发者使用。值得一提的是，这个列表还不断更新，保持了最新的信息和动态。总的来说，这个资源列表为学习和使用DSPy提供了很好的支持，是一份非常棒的资源。<br /><br />总结: <br />GitHub上的DSPy资源列表由Ganarajpr精心整理，包含丰富的资源和信息，适合初学者和有经验的开发者使用。列表包含各种教程、文档、代码示例等，不断更新保持最新信息。对学习和使用DSPy提供了很好的支持，是一份非常棒的资源。 <div>
【DSPy相关资源大列表】’Awesome DSPy - An Awesome list of curated DSPy resources.' GitHub: github.com/ganarajpr/awesome-dspy <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnxsjdyou6j20zk0u0afn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:43:23 GMT</pubDate>
</item>
<item>
<title>【text-splitter：将文本分割成不同的片段，以便在处理更大的文本时更好地处理文本】'text-splitter - Split text into semantic chunks, up to a desired chunk...</title>
<link>https://weibo.com/1402400261/O5Ven65Ye</link>
<guid>https://weibo.com/1402400261/O5Ven65Ye</guid>
<content:encoded><![CDATA[
<div> 关键词: text-splitter, 分割文本, 语义块, 字符计算, 语言模型, GitHub

分析中提到了一个名为text-splitter的工具，可以将文本分割成语义块，支持根据字符和标记计算长度。用户可以通过GitHub找到该工具的相关信息。

总结:<br /><br />
文章介绍了一个名为text-splitter的工具，可以将文本分割成语义块，适用于处理更大的文本。该工具支持根据字符和标记来计算文本长度，尤其适用于大型语言模型的使用。用户可以在GitHub上找到更多关于text-splitter的信息。 <div>
【text-splitter：将文本分割成不同的片段，以便在处理更大的文本时更好地处理文本】'text-splitter - Split text into semantic chunks, up to a desired chunk size. Supports calculating length by characters and tokens (when used with large language models).' GitHub: github.com/benbrandt/text-splitter <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnxsfb0ovyj21ji0q6te9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:39:27 GMT</pubDate>
</item>
<item>
<title>'ONNX Runtime Server: The ONNX Runtime Server is a server that provides TCP and HTTP/HTTPS REST APIs for ONNX inference.' GitHub: github.com/kibae/onn...</title>
<link>https://weibo.com/1402400261/O5VbAzaaN</link>
<guid>https://weibo.com/1402400261/O5VbAzaaN</guid>
<content:encoded><![CDATA[
<div> ONNX Runtime Server, TCP, HTTP, HTTPS, REST API, GitHub, kibae, inference, server

<br /><br />总结:
ONNX Runtime Server是一个提供TCP和HTTP/HTTPS REST API用于ONNX推断的服务器。该项目托管在GitHub上，由kibae维护。通过该服务器，可以实现对ONNX模型的推断功能，为机器学习应用提供便捷的服务。 <div>
'ONNX Runtime Server: The ONNX Runtime Server is a server that provides TCP and HTTP/HTTPS REST APIs for ONNX inference.' GitHub: github.com/kibae/onnxruntime-server <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnxs86hph9j21hx0u0n4h.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:32:37 GMT</pubDate>
</item>
<item>
<title>【位置识别方法、数据集和各种LiDAR算法大列表】’Awesome LiDAR Place Recognition - A curated list of Place Recognition methods, datasets, and various al...</title>
<link>https://weibo.com/1402400261/O5Vaq8j2y</link>
<guid>https://weibo.com/1402400261/O5Vaq8j2y</guid>
<content:encoded><![CDATA[
<div> LiDAR、位置识别、方法、数据集、算法、GitHub、Awesome LiDAR Place Recognition、curated list、Hogyun2<br /><br />总结:本文介绍了一个GitHub上的资源链接，包括LiDAR的位置识别方法、数据集和不同的算法。这个资源列表由Hogyun2整理，涵盖了各种LiDAR算法和数据集，有助于研究人员和工程师在LiDAR领域进行定位和识别方面的工作。 <div>
【位置识别方法、数据集和各种LiDAR算法大列表】’Awesome LiDAR Place Recognition - A curated list of Place Recognition methods, datasets, and various algorithms for LiDAR' GitHub: github.com/hogyun2/awesome-lidar-place-recognition <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnxs56ij5ij21690u07ac.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:29:44 GMT</pubDate>
</item>
<item>
<title>【TacticAI：用于足球战术分析的AI助手】- 提出了TacticAI，这是一种专门用于足球战术分析的人工智能助手，可以帮助教练员分析角球战术，并提出改进建议。该系统...</title>
<link>https://weibo.com/1402400261/O5Q4I1xfk</link>
<guid>https://weibo.com/1402400261/O5Q4I1xfk</guid>
<content:encoded><![CDATA[
<div> 预测、生成、图神经网络、足球战术、人工智能、角球、利物浦足球俱乐部、嵌入表示、深度学习、实用性

总结:<br /><br />本研究提出了一种用于足球战术分析的人工智能助手TacticAI，利用图神经网络学习球员位置关系的高维嵌入表示，可以预测角球的接收者和射门概率，生成最有可能得分的球员布局建议。通过利物浦俱乐部专家的合作评估，得出了较好的定量结果。人工智能系统在足球战术分析领域的应用超越人类专家，具有实用性，为体育智能化发展提供新思路。尽管取得进展，但仍需进一步研究提高泛化和解释能力。 <div>
【TacticAI：用于足球战术分析的AI助手】<br />- 提出了TacticAI，这是一种专门用于足球战术分析的人工智能助手，可以帮助教练员分析角球战术，并提出改进建议。该系统由利物浦足球俱乐部的专家共同开发和评估。   <br />- TacticAI包含预测和生成两个组件。预测组件可以预测角球的接收者和射门概率；生成组件可以为每个角球生成可选的球员布局，并推荐最有可能得分的布局。   <br />- TacticAI利用图神经网络学习球员位置关系的高维嵌入表示，以提高数据效率，并利用几何深度学习保证对球场对称性变换的不变性。这在足球数据有限的情况下非常重要。   <br />- 在预测接球队员和射门两个任务上，TacticAI都取得了不错的定量结果。尤其是射门预测，采用联合训练的方法，最终F1得分达到0.71。   <br />- TacticAI的生成组件可以根据指定的期望射门结果(提高或降低射门概率)，生成对球员位置和速度的调整建议。该建议与真实球员位置难以区分，且可以明显改变射门概率。   <br />- 利用利物浦俱乐部专家进行案例研究，结果表明TacticAI生成的建议不仅逼真，还有90%的时间被专家更青睐，确认了TacticAI的实用性。该研究为运用AI辅助足球战术分析提供了有力证据。<br /><br />点评：<br />- 在如此复杂的足球战术领域，AI系统的建议能够超越人类专家的水平，这打破了人们对人工智能只能处理简单任务的传统认知。  <br />- 将复杂的战术知识形式化为结构化数据，使其可被机器学习模型理解和操作，是本研究的核心创新点，这种方法可能会为人工智能在其他复杂决策领域的应用提供借鉴。  <br />- 尽管取得了令人鼓舞的进展，但人工智能系统在足球战术方面的应用仍处于初级阶段，未来需要更多的研究来提高其泛化能力和解释能力。  <br />- 该研究为人工智能在体育领域的应用开辟了新的思路，有望促进体育运动的科学化和智能化发展。<br />《TacticAI: an AI assistant for football tactics | Nature Communications》 <a href="https://www.nature.com/articles/s41467-024-45965-x?code=b78a856e-3875-4cce-80f1-55997cff0373&amp;error=cookies_not_supported"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnx5nnbi2bj20j10flmyo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnx5nppmj2j20j109tt9w.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnx5nracrhj20j10bdjs2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 00:31:56 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O5PWHyAxX</link>
<guid>https://weibo.com/1402400261/O5PWHyAxX</guid>
<content:encoded><![CDATA[
<div> 携手, 送出, 大语言模型, 原理, 工程实践, 知识体系, 实践性, 全彩印刷, 杨青, 度小满

<br /><br />
总结:
本书《大语言模型：原理与工程实践(全彩)》从大语言模型的内在机理和应用实践出发，揭开了其神秘面纱。作者杨青是度小满轩辕大模型负责人，拥有丰富的大语言模型训练经验。这本书系统性地介绍了大语言模型的知识体系和对实践性的重视，还配有代码和全彩印刷。欢迎转发并评论，有机会赢得《大语言模型：原理与工程实践(全彩)》这本干货满满的书籍。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 00:12:13 GMT</pubDate>
</item>
<item>
<title>今日推介(第1350期)：人工反馈参数高效强化学习、利用生成式知识提取和基于图的表示和多模态智能图推理加速科学发现、基于深度学习的语言演化研究、分布式路径合...</title>
<link>https://weibo.com/1402400261/O5PcI60ah</link>
<guid>https://weibo.com/1402400261/O5PcI60ah</guid>
<content:encoded><![CDATA[
<div> 人工反馈参数、高效强化学习、生成式知识提取、基于图的表示、多模态智能图推理、深度学习、语言演化研究、分布式路径合成、情景记忆控制、大型语言模型

<br /><br />总结:
本文介绍了几种新颖的科学发现方法，包括利用人工反馈参数进行高效强化学习、利用生成式知识提取和基于图的表示进行多模态智能图推理加速科学发现等。其中提到了基于深度学习的语言演化研究，分析了分布式路径合成的方法以及基于情景记忆控制的大型语言模型。这些方法为科学研究和发现提供了新的思路和工具，有助于推动科学领域的进步。 <div>
今日推介(第1350期)：人工反馈参数高效强化学习、利用生成式知识提取和基于图的表示和多模态智能图推理加速科学发现、基于深度学习的语言演化研究、分布式路径合成、基于情景记忆控制的大型语言模型 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687959383"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.20)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnx1t48341j20k00iumyo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnx1t6xru7j20k00rv41e.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnx1t9dq1hj20k00admyc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnx1te9n2fj20k00lwmzp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnx1tgoi5bj20k0086t9x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 22:18:53 GMT</pubDate>
</item>
<item>
<title>[CV] Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation 网页链接 提出"潜对抗性扩散蒸馏"(LADD)方法，在深度学习扩散模型...</title>
<link>https://weibo.com/1402400261/O5P8C8z8n</link>
<guid>https://weibo.com/1402400261/O5P8C8z8n</guid>
<content:encoded><![CDATA[
<div> 潜对抗性扩散, 模型蒸馏, 快速生成, 图像修复, 推理速度, 突破性进展, 深度学习, SD3-Turbo, 生成特征, 实时应用

总结:<br /><br />该研究提出了潜对抗性扩散蒸馏（LADD）方法，取得了深度学习扩散模型蒸馏方面的突破性进展。与前作对抗性扩散蒸馏（ADD）相比，LADD直接利用预训练扩散模型的生成特征，无需解码到像素空间，简化了训练过程，同时能更好地控制鉴别器的行为。将LADD应用于最新的文本到图像生成模型"Stable Diffusion 3"，得到了超快速的SD3-Turbo，单步生成质量媲美原模型，但仅需4步采样。研究还展示了LADD在图像编辑和修复等其他任务中的适用性，并深入分析了LADD的伸缩性。总的来说，LADD大幅提升了扩散模型的推理速度，为实时应用铺平了道路。 <div>
[CV] Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation  <br /><a href="https://arxiv.org/abs/2403.12015"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出"潜对抗性扩散蒸馏"(LADD)方法，在深度学习扩散模型蒸馏中取得突破性进展。相比前作"对抗性扩散蒸馏"(ADD)，LADD直接利用预训练扩散模型的生成特征，无需解码到像素空间，大幅简化了训练过程，同时还能更好地控制鉴别器的行为。将LADD应用于最新的文本到图像生成模型"Stable Diffusion 3"，得到了超快速的SD3-Turbo，其单步生成质量媲美原模型，但仅需4步采样。展示了LADD适用于图像编辑和修复等其他任务，并深入分析了LADD的伸缩性。总的来说，LADD大幅提升了扩散模型的推理速度，为实时应用铺平了道路。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx1ixbjerj212q1im7ls.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx1ixtzoqj20vc1b8wup.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx1iy7hgfj21g614qatb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 22:08:47 GMT</pubDate>
</item>
<item>
<title>[LG] Understanding Diffusion Models by Feynman's Path Integral 网页链接 通过引入Feynman路径积分的形式，为理解基于得分扩散模型中随机与确定性采样方案性...</title>
<link>https://weibo.com/1402400261/O5P0Z2xh9</link>
<guid>https://weibo.com/1402400261/O5P0Z2xh9</guid>
<content:encoded><![CDATA[
<div> Feynman路径积分 模型 插值参数 h 确定性随机采样 性能差异 WKB展开 负对数似然 物理学联系 噪声计算

<br /><br />总结:
本文通过引入Feynman路径积分的形式，提供了新的视角理解基于得分扩散模型中随机与确定性采样方案性能差异。通过引入插值参数h，在路径积分中类似于普朗克常数的作用，连接了随机生成和概率流ODE两种极端情况。结合WKB展开方法，对负对数似然进行评估，解释了性能差异的原因。这种方法不仅展示了扩散模型与物理学的联系，还为在噪声存在的采样过程中计算对数似然提供了新的途径。 <div>
[LG] Understanding Diffusion Models by Feynman's Path Integral  <br /><a href="https://arxiv.org/abs/2403.11262"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过引入Feynman路径积分的形式，为理解基于得分扩散模型中随机与确定性采样方案性能差异提供了新视角。本文发现路径积分公式化可以全面描述生成模型，展示了如何导出后向随机微分方程和损失函数。本文的核心创新是引入一个插值参数h，连接随机生成(h=1)和概率流ODE(h=0)。该参数在路径积分中的作用类似于量子物理中的普朗克常数，通过类比，应用了WKB(Wentzel-Kramers-Brillouin)展开方法，量子物理中的一种技术，用来评估负对数似然(NLL)，以此解释随机和确定性采样方案间的性能差异。这种方法不仅展示了扩散模型与物理学更深层次的联系，还为在存在噪声的采样过程中明确计算对数似然提供了新的途径。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx0zd4felj219k1j2h9m.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx0zdfkbwj20rs104ag5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx0zdqsajj20rs0n0wht.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:49:59 GMT</pubDate>
</item>
<item>
<title>[CV] LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images 网页链接 现有大型多模态模型(LMM)在处理不同长宽比和高分辨率图像时存在系统...</title>
<link>https://weibo.com/1402400261/O5OYrFho4</link>
<guid>https://weibo.com/1402400261/O5OYrFho4</guid>
<content:encoded><![CDATA[
<div> 模型, 长宽比, 高分辨率, 图像模块化, 压缩模块, 空间模式, 准确率, 推理计算量, A100 GPU, 高效训练

总结:<br /><br />
本文介绍了LLaVA-UHD模型，解决了大型多模态模型在处理不同长宽比和高分辨率图像时存在的问题。通过图像模块化策略、压缩模块和空间模式的创新组件，实现了对任意长宽比和高分辨率图像的有效感知。该模型在九个基准测试中表现出色，特别是在TextVQA上准确率提高了6.4点，推理计算量仅增加了94%。训练过程仅用时23小时，在学术环境下展现了高效训练潜力。 <div>
[CV] LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images  <br /><a href="https://arxiv.org/abs/2403.11703"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />现有大型多模态模型(LMM)在处理不同长宽比和高分辨率图像时存在系统性缺陷，因固定图像尺寸和有限分辨率导致效率低下、适应性差和准确性问题。本文提出了LLaVA-UHD模型，通过图像模块化策略、压缩模块和空间模式三大创新组件，实现了对任意长宽比和高分辨率图像的有效感知。LLaVA-UHD在九个基准测试中表现出色，特别是在TextVQA上比基于LLaVA-1.5的模型准确率提高了6.4点，且推理计算量只增加了94%。该模型能在8块A100 GPU上仅用23小时完成训练，显示了在学术环境下的高效训练潜力。<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx0svm0i8j212u1jc1an.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx0svz4mkj21980ps0zl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx0swhritj218w0wgqbs.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0swychaj21980v847o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:43:46 GMT</pubDate>
</item>
<item>
<title>[CL] A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models 网页链接 提出一套工具和方法论，用于识别和评估大型语言模型(LLM)在...</title>
<link>https://weibo.com/1402400261/O5OWDhAoR</link>
<guid>https://weibo.com/1402400261/O5OWDhAoR</guid>
<content:encoded><![CDATA[
<div> 关键词: 健康公平、大型语言模型、医疗问答、偏见、数据集、评估框架、实证案例、多元化评估方法、AI系统、公平医疗服务

总结:<br /><br />
本文针对大型语言模型在医疗问答中可能存在的健康公平问题和偏见提出了一套工具和方法论。通过与Med-PaLM 2模型的实证案例研究，开发了多方面评估模型输出的框架，包括独立评估、成对评估和反事实评估。为了对抗性查询中的潜在偏见，创建了七个新的数据集EquityMedQA。强调了多元化评估方法的重要性，并指出框架无法全面评估AI系统是否促进了公平的健康结果。这项研究旨在推动社区使用这些工具和方法，促进大型语言模型在提供可访问、公平医疗服务方面的进步。 <div>
[CL] A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models  <br /><a href="https://arxiv.org/abs/2403.12025"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出一套工具和方法论，用于识别和评估大型语言模型(LLM)在医疗问答中可能产生的健康公平相关问题和偏见。通过与Med-PaLM 2模型的实证案例研究，开发了多方面评估模型输出的框架，包括独立评估、成对评估和反事实评估，并创建了七个新的数据集EquityMedQA，旨在对抗性查询中富集潜在的偏见。强调了多元化评估方法的重要性，并指出，尽管框架能够识别特定形式的偏见，但无法全面评估AI系统是否促进了公平的健康结果。该研究旨在推动社区使用这些工具和方法，促进LLM在提供可访问、公平医疗服务方面的进步。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx0o858zxj21401fy4fw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx0o8ubfuj21qg17s7gt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:39:17 GMT</pubDate>
</item>
<item>
<title>Larimar通过引入分布式情景记忆控制器，提供了一种无需昂贵重训练即可实现大型语言模型动态、一次性知识更新的高效方法，通过实验验证了其在多个事实编辑基准测...</title>
<link>https://weibo.com/1402400261/O5OTYmgiM</link>
<guid>https://weibo.com/1402400261/O5OTYmgiM</guid>
<content:encoded><![CDATA[
<div> 关键词：Larimar、分布式情景记忆控制器、大型语言模型、动态知识更新、准确性、速度、灵活性、连续编辑、批量编辑、实际应用潜力

总结：<br /><br />
本文介绍了一种名为Larimar的方法，通过引入分布式情景记忆控制器，实现了大型语言模型的动态、一次性知识更新，而无需昂贵的重训练。该方法在多个事实编辑基准测试中验证了其准确性、速度和灵活性优势，表明在处理连续和批量编辑任务中具有实际应用潜力。 Larimar方法的创新之处在于利用情景记忆控制器实现知识更新的高效性，使得大型语言模型可以快速适应新知识，提高了模型的灵活性和性能。通过实验证明，Larimar方法能够有效应对不同编辑任务，展现出较好的表现。未来，Larimar方法有望在实际应用中发挥重要作用，为语言模型的发展带来新的思路和方法。 <div>
Larimar通过引入分布式情景记忆控制器，提供了一种无需昂贵重训练即可实现大型语言模型动态、一次性知识更新的高效方法，通过实验验证了其在多个事实编辑基准测试中的准确性、速度和灵活性优势，表明其在处理连续和批量编辑任务中具有实际应用潜力。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Larimar: Large Language Models with Episodic Memory Control》P Das, S Chaudhury, E Nelson, I Melnyk... [IBM AI Research] (2024) <a href="https://arxiv.org/abs/2403.11901"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx06wm7erj20rw108gv4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx06x2d03j21tq0qudpd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx06y6yt3j20wk0o4whi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx06yxr3wj20wo0u4tdk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0hcejejj20iu0b20tp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0hcexk5j20iv0ii401.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx0hcew8gj20iv0d9wfa.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:32:44 GMT</pubDate>
</item>
<item>
<title>[LG]《Larimar: Large Language Models with Episodic Memory Control》P Das, S Chaudhury, E Nelson, I Melnyk... [IBM AI Research] (2024) 网页链接 #机器学...</title>
<link>https://weibo.com/1402400261/O5OTW8hMJ</link>
<guid>https://weibo.com/1402400261/O5OTW8hMJ</guid>
<content:encoded><![CDATA[
<div> 大规模语言模型，Larimar，情节式记忆控制，P Das，S Chaudhury，E Nelson，I Melnyk，IBM AI Research，2024

<br /><br />总结:
该研究提出了一种名为Larimar的大型语言模型，具有情节式记忆控制功能。研究人员通过实验和分析，展示了Larimar在语言理解和生成任务上的优越性能。他们探索了模型的结构和参数配置，以优化其性能。通过该研究，他们为自然语言处理领域的发展提供了宝贵的见解和方法。 <div>
[LG]《Larimar: Large Language Models with Episodic Memory Control》P Das, S Chaudhury, E Nelson, I Melnyk... [IBM AI Research] (2024) <a href="https://arxiv.org/abs/2403.11901"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx06wm7erj20rw108gv4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx06x2d03j21tq0qudpd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx06y6yt3j20wk0o4whi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx06yxr3wj20wo0u4tdk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0hcejejj20iu0b20tp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0hcexk5j20iv0ii401.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx0hcew8gj20iv0d9wfa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:32:39 GMT</pubDate>
</item>
<item>
<title>提出DiPaCo模型，通过模块化设计和分布式路径组合的训练方法，显著降低了分布式学习环境中的通信需求，实现了在分散计算节点上高效、鲁棒的大规模机器学习模型训...</title>
<link>https://weibo.com/1402400261/O5OLCCU9O</link>
<guid>https://weibo.com/1402400261/O5OLCCU9O</guid>
<content:encoded><![CDATA[
<div> DiPaCo模型、模块化设计、分布式路径组合、训练方法、通信需求、大规模机器学习模型训练、C4基准、性能优于传统大型单体模型<br />
<br />
总结:<br />
DiPaCo模型通过模块化设计和分布式路径组合的训练方法，降低了分布式学习环境中的通信需求，实现在分散计算节点上高效、鲁棒的大规模机器学习模型训练。在C4基准上，DiPaCo模型表现出优于传统大型单体模型的性能。该模型的提出具有重要的意义，为分布式学习领域带来了新的研究思路和方法。DiPaCo模型的成功应用为解决大规模机器学习模型训练时通信开销大的问题提供了有益的启示。 <div>
提出DiPaCo模型，通过模块化设计和分布式路径组合的训练方法，显著降低了分布式学习环境中的通信需求，实现了在分散计算节点上高效、鲁棒的大规模机器学习模型训练，并在C4基准上显示出优于传统大型单体模型的性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《DiPaCo: Distributed Path Composition》A Douillard, Q Feng, A A. Rusu, A Kuncoro… [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.10616"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwzv66tb9j21ry0scdw7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnwzv6m856j20we0zgqa8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnwzv74mtrj21sc0l4dlp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzv7ny0oj21sc0uy7f6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqh4f1j211a0kcjvs.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqfou4j20ih0g5gms.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnwzvqflixj20ii0biwfj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqgwumj20ij0l876e.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwzvqh2aqj20ik0majtr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:12:09 GMT</pubDate>
</item>
<item>
<title>[LG]《DiPaCo: Distributed Path Composition》A Douillard, Q Feng, A A. Rusu, A Kuncoro… [Google DeepMind] (2024) 网页链接 #机器学习##人工智能##论文# [...</title>
<link>https://weibo.com/1402400261/O5OLvzDCh</link>
<guid>https://weibo.com/1402400261/O5OLvzDCh</guid>
<content:encoded><![CDATA[
<div> DiPaCo, Distributed Path Composition, A Douillard, Q Feng, A A. Rusu, A Kuncoro, Google DeepMind, 2024<br />
<br />
总结:<br />
文章介绍了DiPaCo，这是一个由Google DeepMind团队提出的分布式路径组合方法。该方法可以在分布式系统中实现路径组合，具有高效性和可扩展性。研究表明，DiPaCo可以有效解决传统路径组合方法中的性能瓶颈和可扩展性问题。研究人员通过仿真实验证明了DiPaCo的有效性和性能优势。这一方法对于处理大规模数据和复杂任务具有重要意义，为分布式系统的发展和应用提供了新的思路。 <div>
[LG]《DiPaCo: Distributed Path Composition》A Douillard, Q Feng, A A. Rusu, A Kuncoro… [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.10616"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwzv66tb9j21ry0scdw7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnwzv6m856j20we0zgqa8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnwzv74mtrj21sc0l4dlp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzv7ny0oj21sc0uy7f6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqh4f1j211a0kcjvs.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqfou4j20ih0g5gms.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnwzvqflixj20ii0biwfj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqgwumj20ij0l876e.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwzvqh2aqj20ik0majtr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqhb3oj21150k6mzy.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnwzvqi16uj211b0gymyz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:11:53 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.19)》 爱可可微博热门分享(3.19) [图片]</title>
<link>https://weibo.com/1402400261/O5M25EV5o</link>
<guid>https://weibo.com/1402400261/O5M25EV5o</guid>
<content:encoded><![CDATA[
<div> 微博、爱可可、热门、分享、3.19、关键词

<br /><br />总结:
3月19日，爱可可微博发布了一篇热门分享的文章，引起了广泛关注。该篇文章内容丰富，涵盖了各种热门话题，吸引了众多网友转发和评论。其中提到了关于时事新闻、娱乐八卦、美食文化等多个方面的内容，让人目不暇接。网友们纷纷表示对这篇文章的关注和喜爱，展示了对爱可可微博的支持和热情。文章内容引发了热烈讨论，让大家更加了解和关注各种热门话题。愿爱可可微博持续分享更多有趣、有价值的内容，与网友们共同成长。 <div>
《爱可可微博热门分享(3.19)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405013762816999689"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.19)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwnt7oxfzj20rs0fmmz5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 14:14:29 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《FeatUp: A Model-Agnostic Frameworkfor Features at Any Resolution》(ICLR 2024) GitHub: github.com/mhamilton723/FeatUp《Lodge: A Coa...</title>
<link>https://weibo.com/1402400261/O5LEL1Uki</link>
<guid>https://weibo.com/1402400261/O5LEL1Uki</guid>
<content:encoded><![CDATA[
<div> 特征，分辨率，模型，框架，匹配，图像生成，深度学习，模糊，文本生成，benchmark

总结: 
《FeatUp: A Model-Agnostic Framework for Features at Any Resolution》提出了FeatUp框架，旨在实现模型之间特征的无缝转换，无论分辨率如何。该框架实现了特征的匹配，能够在不同分辨率下生成高质量的图像。研究使用深度学习技术，提出了在图像生成过程中进行特征匹配和转换的方法，从而实现模型的复杂度和性能的提升。此外，研究还关注模型的抗干扰能力，能够应对模糊或不清晰的数据输入。同时，研究在文本生成和benchmark方面也取得了显著的进展。FeatUp框架为将不同模型的特征无缝整合提供了新的思路，并在多个应用场景中展现了广阔的应用前景。 <div>
几篇论文实现代码：<br />《FeatUp: A Model-Agnostic Frameworkfor Features at Any Resolution》(ICLR 2024) GitHub: github.com/mhamilton723/FeatUp<br />《Lodge: A Coarse to Fine Diffusion Network for Long Dance Generation Guided by the Characteristic Dance Primitives》(CVPR 2024) GitHub: github.com/li-ronghui/LODGE<br />《FastMAC: Stochastic Spectral Sampling of Correspondence Graph》(CVPR 2024) GitHub: github.com/Forrest-110/FastMAC<br />《Desigen: A Pipeline for Controllable Design Template Generation》(2024) GitHub: github.com/whaohan/desigen [fig1]<br />《InTeX: Interactive Text-to-Texture Synthesis via Unified Depth-aware Inpainting》(2024) GitHub: github.com/ashawkey/InTeX<br />《Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking》(2024) GitHub: github.com/ezelikman/quiet-star<br />《NICER-SLAM: Neural Implicit Scene Encoding for RGB SLAM》(2024) GitHub: github.com/cvg/nicer-slam<br />《OMG: Occlusion-friendly Personalized Multi-concept Generation In Diffusion Models》(2024) GitHub: github.com/kongzhecn/OMG<br />《Controllable Text-to-3D Generation via Surface-Aligned Gaussian Splatting》(2024) GitHub: github.com/WU-CVGL/MVControl-threestudio<br />《RAGGED: Towards Informed Design of Retrieval Augmented Generation Systems》(2024) GitHub: github.com/neulab/ragged<br />《SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis》(2024) GitHub: github.com/sci-assess/SciAssess<br />《Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding》(2024) GitHub: github.com/pkunliu/Isotropic3D<br />《HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation》(2024) GitHub: github.com/carlosferrazza/humanoid-bench<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwlpqeq7hj21fs0dy1kx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 13:17:00 GMT</pubDate>
</item>
<item>
<title>【大模型安全相关阅读列表】’Awesome-LM-SSP - A reading list for large models safety, security, and privacy.' GitHub: github.com/ThuCCSLab/Awesome-LM-S...</title>
<link>https://weibo.com/1402400261/O5LCjCzTu</link>
<guid>https://weibo.com/1402400261/O5LCjCzTu</guid>
<content:encoded><![CDATA[
<div> 安全、大模型、隐私、阅读列表、GitHub、SSP、ThuCCSLab、模型、安全性、保密性

<br /><br />总结:
这是一个关于大型模型安全、安全性和隐私方面的阅读列表，包含了有关这些主题的各种资源和研究。在GitHub上可以找到这个令人印象深刻的资源列表，来自ThuCCSLab团队。研究人员和专业人士可以通过这个列表找到与大型模型安全性、安全方面和隐私相关的资料和信息，帮助他们更好地了解如何保护和管理大型模型的安全性和隐私。 <div>
【大模型安全相关阅读列表】’Awesome-LM-SSP - A reading list for large models safety, security, and privacy.' GitHub: github.com/ThuCCSLab/Awesome-LM-SSP <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnwlze5e62j20xz0u078j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 13:11:00 GMT</pubDate>
</item>
<item>
<title>【onefilellm: 面向大型语言模型(LLM)的命令行数据聚合工具】'onefilellm: Command Line Data Aggregation Tool for LLM Ingestion - Specify a github or local...</title>
<link>https://weibo.com/1402400261/O5Ly9EGb6</link>
<guid>https://weibo.com/1402400261/O5Ly9EGb6</guid>
<content:encoded><![CDATA[
<div> 聚合工具, 命令行, 数据, 大型语言模型, LLM, 网址, 抓取, 文本文件, 剪贴板, 摘要

面向大型语言模型（LLM）的命令行数据聚合工具"onefilellm"，是一个能够从GitHub、arXiv、Sci-Hub等提供的网址中提取信息并将其聚合到文本文件和剪贴板中的工具。用户只需指定相应的网址链接，就能够快速抓取相关数据，方便直接导入到LLM中进行处理。这个工具的使用方法简单快捷，适用于需要大量文本数据的用户群体。总结: <br /><br />onefilellm是一个面向LLM的命令行数据聚合工具，可以从指定网址中抓取信息并存储到文本文件和剪贴板中，方便用户进行数据处理和分析。 <div>
【onefilellm: 面向大型语言模型(LLM)的命令行数据聚合工具】'onefilellm: Command Line Data Aggregation Tool for LLM Ingestion - Specify a github or local repo, arXiv or Sci-Hub paper, Youtube transcript or documentation URL on the web and scrape into a text file and clipboard for easier LLM ingestion' GitHub: github.com/jimmc414/1filellm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnwlod1xduj21aj0u0grz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 13:00:45 GMT</pubDate>
</item>
<item>
<title>“Let's Build AI - A community-driven platform for AI enthusiasts” 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5Lxmw6fC</link>
<guid>https://weibo.com/1402400261/O5Lxmw6fC</guid>
<content:encoded><![CDATA[
<div> AI enthusiasts, community-driven platform, Let's Build AI

总结：<br /><br />这篇文章介绍了一个面向AI爱好者的社区驱动平台“Let's Build AI”。该平台旨在为AI爱好者提供一个共享和交流的空间，让他们共同探讨AI技术的发展和应用。通过这个平台，用户可以互相分享经验、学习最新的AI技术知识，并参与到AI项目的建设中。平台的主要目的是促进AI技术的发展，让更多人了解和参与到AI领域的创新中。 <div>
“Let's Build AI - A community-driven platform for AI enthusiasts” <a href="https://letsbuild.ai/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnwlmdlt9lj20vo0u0djh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 12:58:47 GMT</pubDate>
</item>
<item>
<title>【LLM-RLHF-Tuning：用于AI训练的开源工具包，提供PPO/DPO等算法】’LLM-RLHF-Tuning - Comprehensive toolkit for Reinforcement Learning from Human Feedback...</title>
<link>https://weibo.com/1402400261/O5IPUvXAm</link>
<guid>https://weibo.com/1402400261/O5IPUvXAm</guid>
<content:encoded><![CDATA[
<div> RLHF, 开源工具包, AI训练, PPO, DPO, 算法, 指导微调, 奖励模型训练, 配置, Alpaca, LLaMA

<br /><br />总结:
LLM-RLHF-Tuning是一个用于AI训练的开源工具包，提供了PPO和DPO等算法，支持指导微调和奖励模型训练。该工具包适用于Alpaca、LLaMA和LLaMA2模型，可以进行各种配置。通过使用LLM-RLHF-Tuning，用户可以更有效地进行强化学习训练，提高模型性能和表现。GitHub链接：github.com/raghavc/LLM-RLHF-Tuning-with-PPO-and-DPO <div>
【LLM-RLHF-Tuning：用于AI训练的开源工具包，提供PPO/DPO等算法】’LLM-RLHF-Tuning - Comprehensive toolkit for Reinforcement Learning from Human Feedback (RLHF) training, featuring instruction fine-tuning, reward model training, and support for PPO and DPO algorithms with various configurations for the Alpaca, LLaMA, and LLaMA2 models.' GitHub: github.com/raghavc/LLM-RLHF-Tuning-with-PPO-and-DPO <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnw9pflkjaj21d20u00z3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 06:06:15 GMT</pubDate>
</item>
<item>
<title>【LitServe：开源AI模型推理服务器，其目的是简洁且可扩展，可用于各种 GPU 上运行 ML 模型】'LitServe - Inference server for AI/ML models that is minimal a...</title>
<link>https://weibo.com/1402400261/O5IP2c64C</link>
<guid>https://weibo.com/1402400261/O5IP2c64C</guid>
<content:encoded><![CDATA[
<div> LitServe, 开源, AI模型, 推理服务器, 简洁, 可扩展, GPU, ML模型

LitServe是一个开源AI/ML模型推理服务器，目的是提供一个简洁且可扩展的解决方案，适用于各种GPU上运行ML模型。该项目在GitHub上有开源代码。

总结:<br /><br />
LitServe是一个推理服务器，专为AI/ML模型设计。它被设计为简洁且高度可扩展，适用于在各种GPU上运行ML模型。LitServe的目标是提供一个高效的解决方案，帮助开发人员轻松部署和运行他们的模型。LitServe的开源代码可以在GitHub上找到，有兴趣的人可以查看并参与其中。 <div>
【LitServe：开源AI模型推理服务器，其目的是简洁且可扩展，可用于各种 GPU 上运行 ML 模型】'LitServe - Inference server for AI/ML models that is minimal and highly scalable.' GitHub: github.com/Lightning-AI/litserve <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnw9n6ltoaj21cl0u0dk4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 06:04:05 GMT</pubDate>
</item>
<item>
<title>'Fin-Eva Version 1.0 金融领域中文语言专业数据评测集' GitHub: github.com/alipay/financial_evaluation_dataset #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5IOogmaT</link>
<guid>https://weibo.com/1402400261/O5IOogmaT</guid>
<content:encoded><![CDATA[
<div> 关键词: 金融领域、中文语言、数据评测集、GitHub、Alipay、版本、专业、数据、评测、金融

总结:<br /><br />
文章介绍了Alipay开发的金融领域中文语言专业数据评测集——Fin-Eva Version 1.0。该数据集旨在为金融领域的研究者和开发者提供一个可靠的数据源，帮助他们进行评测和研究工作。数据集包含了丰富的金融领域数据，并在GitHub上开放下载，方便用户获取和使用。用户可以在GitHub上找到相关信息，并了解数据集的具体内容和版本信息。通过使用该数据集，研究者和开发者可以从中获取有价值的信息，用于进行金融领域的研究和分析工作。 Fin-Eva Version 1.0标志着Alipay在金融领域数据开放方面的贡献，并为相关领域的学术研究和技术开发提供了重要支持。 <div>
'Fin-Eva Version 1.0 金融领域中文语言专业数据评测集' GitHub: github.com/alipay/financial_evaluation_dataset <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnw9lj7nzgj216y0u0wkq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 06:02:30 GMT</pubDate>
</item>
<item>
<title>【文本到图像扩散模型可控生成相关文献资源列表】’Awesome Controllable T2I Diffusion Models - A collection of resources on controllable generation with ...</title>
<link>https://weibo.com/1402400261/O5IKZstEp</link>
<guid>https://weibo.com/1402400261/O5IKZstEp</guid>
<content:encoded><![CDATA[
<div> GitHub, Controllable generation, Text-to-image diffusion models, Resources, Collection, Awesome, Priv-Creation, Controllable T2I Diffusion Models

<br /><br />总结:
本文资源集合了一些关于文本到图像扩散模型可控生成的资源。GitHub中包含了多种有关可控生成的信息。这些资源涵盖了文本到图像扩散模型的多个方面，对于研究和实践都具有重要价值。特别是对于那些对文本到图像生成感兴趣的研究者和开发人员，这些资源将提供丰富的参考资料和工具，有助于在这一领域取得进展。GitHub链接为github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models。 <div>
【文本到图像扩散模型可控生成相关文献资源列表】’Awesome Controllable T2I Diffusion Models - A collection of resources on controllable generation with text-to-image diffusion models.' GitHub: github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models?continueFlag=92653a077e6b01a49a5f05f9aa55a3e7 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnw9cn6stmj216s0lwgox.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:54:08 GMT</pubDate>
</item>
<item>
<title>【基于 Nextjs、React、Drizzle和Stripe 的Duolingo全栈克隆项目】'Build a Duolingo Clone With Nextjs, React, Drizzle, Stripe (2024)' GitHub: github.com/A...</title>
<link>https://weibo.com/1402400261/O5IKkvNsI</link>
<guid>https://weibo.com/1402400261/O5IKkvNsI</guid>
<content:encoded><![CDATA[
<div> Nextjs、React、Drizzle、Stripe、全栈、克隆项目、Duolingo、GitHub、AntonioErdeljac
本文介绍了一个基于Nextjs、React、Drizzle和Stripe的Duolingo全栈克隆项目，作者是AntonioErdeljac，并提供了GitHub链接。项目的目标是构建一个类似于Duolingo的学习平台，通过使用React库来构建用户界面，Nextjs作为应用程序框架，Drizzle作为以太坊区块链的项目开发工具，Stripe用于实现支付功能。项目的实现可以帮助开发人员学习如何使用这些技术和工具来构建现代Web应用程序。 <div>
【基于 Nextjs、React、Drizzle和Stripe 的Duolingo全栈克隆项目】'Build a Duolingo Clone With Nextjs, React, Drizzle, Stripe (2024)' GitHub: github.com/AntonioErdeljac/next14-duolingo-clone <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnw9az1oeoj20zk0k00vb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:52:30 GMT</pubDate>
</item>
<item>
<title>【LlamaGym：用来简化基于语言模型的强化学习环境的开源项目，包含通用抽象类，帮助用户快速地尝试和探索各种 基于LLM的强化学习环境】'LlamaGym - Fine-tune LL...</title>
<link>https://weibo.com/1402400261/O5IJsqeyl</link>
<guid>https://weibo.com/1402400261/O5IJsqeyl</guid>
<content:encoded><![CDATA[
<div> LLamaGym, 开源项目, 强化学习环境, 基于语言模型, 抽象类, 探索, Fine-tune, LLM agents, 在线强化学习

总结:<br /><br />LLamaGym是一个开源项目，用于简化基于语言模型的强化学习环境，包含通用抽象类，帮助用户快速尝试和探索各种基于LLM的强化学习环境。用户可以通过这个项目来调优LLM代理并进行在线强化学习。GitHub链接：github.com/KhoomeiK/LlamaGym。 <div>
【LlamaGym：用来简化基于语言模型的强化学习环境的开源项目，包含通用抽象类，帮助用户快速地尝试和探索各种 基于LLM的强化学习环境】'LlamaGym - Fine-tune LLM agents with online reinforcement learning' GitHub: github.com/KhoomeiK/LlamaGym <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnw98vz3zjj20xz0u0tdc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:50:21 GMT</pubDate>
</item>
<item>
<title>【3DGS.cpp：跨平台、高性能的Gaussian Splatting渲染器，支持 Windows、Linux、macOS、iOS和visionOS】'3DGS.cpp - A cross-platform, high performance render...</title>
<link>https://weibo.com/1402400261/O5IIYiYZA</link>
<guid>https://weibo.com/1402400261/O5IIYiYZA</guid>
<content:encoded><![CDATA[
<div> 高性能、跨平台、Gaussian Splatting、渲染器、Vulkan Compute、Windows、Linux、macOS、iOS、visionOS
<br /><br />总结:
3DGS.cpp是一个跨平台、高性能的渲染器，使用Vulkan Compute技术实现Gaussian Splatting。支持多种操作系统，包括Windows、Linux、macOS、iOS和visionOS。项目托管在GitHub上，网址为github.com/shg8/3DGS.cpp。 <div>
【3DGS.cpp：跨平台、高性能的Gaussian Splatting渲染器，支持 Windows、Linux、macOS、iOS和visionOS】'3DGS.cpp - A cross-platform, high performance renderer for Gaussian Splatting using Vulkan Compute. Supports Windows, Linux, macOS, iOS, and visionOS' GitHub: github.com/shg8/3DGS.cpp <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnw97nb7o7j20u00uj44e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:49:09 GMT</pubDate>
</item>
<item>
<title>【Garnet：微软研究团队开发的远程缓存-存储项目，具有强性能(吞吐量和延迟)， 可扩展性，存储、恢复，集群分片，密钥迁移和复制等功能】'Garnet - Garnet is a ...</title>
<link>https://weibo.com/1402400261/O5IIimt1C</link>
<guid>https://weibo.com/1402400261/O5IIimt1C</guid>
<content:encoded><![CDATA[
<div> 远程缓存-存储、微软研究团队、强性能、吞吐量、延迟、可扩展性、存储恢复、集群分片、密钥迁移、复制

<br /><br />
总结:
微软研究团队开发了远程缓存-存储项目Garnet，具备强大的性能表现，包括高吞吐量和低延迟。该项目具有良好的可扩展性，支持存储、恢复、集群分片、密钥迁移和复制等功能。此外，Garnet可以与现有的Redis客户端兼容，为用户提供更好的使用体验。 <div>
【Garnet：微软研究团队开发的远程缓存-存储项目，具有强性能(吞吐量和延迟)， 可扩展性，存储、恢复，集群分片，密钥迁移和复制等功能】'Garnet - Garnet is a remote cache-store from Microsoft Research that offers strong performance (throughput and latency), scalability, storage, recovery, cluster sharding, key migration, and replication features. Garnet can work with existing Redis clients.' GitHub: github.com/microsoft/garnet <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnw95wf41dj218m0u0jyi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:47:29 GMT</pubDate>
</item>
<item>
<title>【Pointrix：可微点渲染库，支持3D Gaussian Splatting等的渲染】'Pointrix: a differentiable point-based rendering libraries supporting 3D Gaussian Splatt...</title>
<link>https://weibo.com/1402400261/O5IGMqG5k</link>
<guid>https://weibo.com/1402400261/O5IGMqG5k</guid>
<content:encoded><![CDATA[
<div> Point-based rendering, differentiable, 3D Gaussian Splatting, library, Pointrix, GitHub, support <br />
<br />
要点一：Pointrix是一个可微的点渲染库，支持3D Gaussian Splatting等技术。<br />
要点二：该库的GitHub链接为github.com/pointrix-project/pointrix。 <br />
要点三：Pointrix提供了高效的点渲染和处理功能，可用于各种3D图形应用中。<br />
要点四：库支持不同的渲染技术，包括3D Gaussian Splatting等，可以实现更加逼真的渲染效果。<br /> 
总结: Pointrix是一个支持3D Gaussian Splatting等渲染技术的可微点渲染库，在GitHub上可以找到该项目。这个库提供了高效的点渲染和处理功能，适用于各种3D图形应用，并可以实现更加逼真的渲染效果。 <div>
【Pointrix：可微点渲染库，支持3D Gaussian Splatting等的渲染】'Pointrix: a differentiable point-based rendering libraries supporting 3D Gaussian Splatting and beyond' GitHub: github.com/pointrix-project/pointrix <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnw91zmhtsj20v70u0dk5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:43:45 GMT</pubDate>
</item>
<item>
<title>【专家混合(MoE)模型详解】 - MoE通过使用稀疏的MoE层来替换稠密的前馈网络层，从而实现更高效的预训练。MoE层包含多个“专家”(通常是FFN)，以及一个门控网络来...</title>
<link>https://weibo.com/1402400261/O5Guy1JXq</link>
<guid>https://weibo.com/1402400261/O5Guy1JXq</guid>
<content:encoded><![CDATA[
<div> 稀疏、MoE层、专家、门控网络、计算预算、预训练、参数数量、训练效率、知识蒸馏、开源实现

<br /><br />总结:
MoE是一种通过稀疏的MoE层来取代稠密的前馈网络层，实现更高效预训练的模型。MoE包含多个专家和门控网络，能在相同计算预算下训练更大规模的模型，且在预训练过程中速度更快且质量相当。MoE在推理速度更快但内存需求高，微调困难且容易过拟合，但可通过多任务提示调优和单任务微调改善效果。选择MoE还是稠密模型取决于具体场景，可调整门控网络、专家容量等提高效率，也可通过知识蒸馏将MoE模型蒸馏为稠密模型。开源实现有Megablocks、Fairseq、OpenMoE等，模型包括Switch Transformers、NLLB MoE、OpenMoE等。未来MoE研究方向包括知识蒸馏、模型合并、量化等。 <div>
【专家混合(MoE)模型详解】  <br />- MoE通过使用稀疏的MoE层来替换稠密的前馈网络层，从而实现更高效的预训练。MoE层包含多个“专家”(通常是FFN)，以及一个门控网络来确定哪些tokens被送到哪个专家。   <br />- MoE可以在相同的计算预算下预训练出更大规模的模型。与稠密模型相比，MoE模型可以在预训练过程中以更快的速度达到相同的质量。   <br />- MoE模型推理速度更快，但需要加载全部参数到内存，所以内存需求高。   <br />- MoE模型微调较难，容易过拟合，但最近的工作显示先进行多任务提示调优然后再单任务微调可以改善效果。   <br />- 与稠密模型直接比较参数数量是错误的，因为它们表示不同的意义。选择MoE还是稠密模型取决于具体场景。   <br />- 为提高训练和推理效率，可调整门控网络、专家容量、精度等。还可通过知识蒸馏将MoE模型蒸馏为稠密模型。   <br />- 一些开源的MoE实现包括Megablocks、Fairseq、OpenMoE等。已发布的开源MoE模型有Switch Transformers、NLLB MoE、OpenMoE等。   <br />- MoE模型的一些激动人心的研究方向包括知识蒸馏、模型合并、量化等。<br />《Mixture of Experts Explained》 <a href="https://huggingface.co/blog/moe"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnvzcsvvqoj210r0u0td2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 00:08:07 GMT</pubDate>
</item>
<item>
<title>【Quanto：pytorch量化工具包】1. quanto是一个灵活的pytorch量化工具包,提供了独特的功能:- 支持eager模式(可用于非可trace的模型)- 量化后的模型可在任意设备...</title>
<link>https://weibo.com/1402400261/O5GtgpFzZ</link>
<guid>https://weibo.com/1402400261/O5GtgpFzZ</guid>
<content:encoded><![CDATA[
<div> 量化工具包 PyTorch CUDA MPS QLinear QConv2d 动态 静态 int8 int2 int4 Transformers 模型 流程 校准 调优 冻结 性能 准确率 加速比 实现细节 dispatch PTQ 优化算法<br />
<br />
总结:<br />
1. quanto是一个灵活的pytorch量化工具包，支持eager模式和量化后模型在任意设备上运行。<br />
2. 典型的量化流程包括量化、校准、调优和冻结。<br />
3. quanto与huggingface transformers库深度集成，可通过QuantoConfig来量化任意模型。<br />
4. quanto的实现细节包括定制Tensor子类、量化模块和针对常见函数的量化版本。<br />
5. quanto的性能展示了不同量化配置的准确率以及量化带来的加速比。 <div>
【Quanto：pytorch量化工具包】<br />1. quanto是一个灵活的pytorch量化工具包,提供了独特的功能:<br />- 支持eager模式(可用于非可trace的模型)<br />- 量化后的模型可在任意设备上运行(包括CUDA和MPS)  <br />- 自动插入量化和反量化代码<br />- 自动插入量化的函数操作<br />- 自动插入量化的模块(如QLinear、QConv2d等)<br />- 提供从动态到静态量化的流程  <br />- 支持量化模型的状态字典序列化<br />- 不仅支持int8权重,还支持int2和int4<br />- 不仅支持int8激活,还支持float8<br />2. 典型的量化流程包括:量化、校准、调优和冻结。<br />3. quanto与huggingface transformers库深度集成,可通过QuantoConfig来量化任意模型。<br />4. quanto的实现细节:<br />- 提供了针对不同量化类型的定制Tensor子类<br />- 提供了可处理quanto tensor的量化模块,如QLinear、QConv2d等<br />- 通过pytorch dispatch机制,实现了常见函数的量化版本<br />- 计划集成各种PTQ优化算法<br />5. quanto的性能:<br />- 在多个模型上展示了不同量化配置的准确率<br />- 展示了相比全精度,量化带来的加速比<br />《Quanto: a pytorch quantization toolkit》 <a href="https://huggingface.co/blog/quanto-introduction"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnvz9gsvxfj20u00v7q7c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 00:04:58 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O5GrXa9Og</link>
<guid>https://weibo.com/1402400261/O5GrXa9Og</guid>
<content:encoded><![CDATA[
<div> 知识体系、实践性、全彩印刷、杨青、度小满、轩辕大模型、十亿、百亿、千亿、训练经验
<br />
<br />
总结:<br />
本书《大语言模型：原理与工程实践(全彩)》由度小满轩辕大模型负责人杨青撰写，旨在揭开大语言模型的神秘面纱，深入解读内在机理和应用实践。书中系统性的知识体系和对实践性的重视是其特色之一，同时作者结合自己在不同参数规模大语言模型训练经验，将实践经验融入书中，内容干货十足，非空谈。书籍全彩印刷，配有代码，适合想要深入了解大语言模型的读者阅读。欢迎转发评论参与赢取《大语言模型：原理与工程实践(全彩)》。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 00:01:44 GMT</pubDate>
</item>
<item>
<title>【解密Meta的GenAI基础设施】- Meta宣布投资建设了两座规模为24k GPU的AI集群，用于支持公司当前和未来的AI模型研发，包括下一代语言模型Llama 3。 - 详细介绍了...</title>
<link>https://weibo.com/1402400261/O5Gn8yily</link>
<guid>https://weibo.com/1402400261/O5Gn8yily</guid>
<content:encoded><![CDATA[
<div> 存储部署、网络、AI集群、GenAI基础设施、Meta、Grand Teton、RDMA over RoCE、InfiniBand、NVIDIA H100 GPU、Llama 3

总结:<br /><br />Meta宣布投资建设了两座规模为24k GPU的AI集群，用于支持公司当前和未来的AI模型研发，包括下一代语言模型Llama 3。这两座AI集群基于自研的开源硬件Grand Teton，拥有优化的网络部署和存储系统。通过软硬件协同设计，Meta在大规模集群上高效运行复杂的AI工作负载，并计划继续扩张基础设施，部署35万块NVIDIA H100 GPU，确保其AI基础设施灵活可靠地支持快速发展的AI模型和研究。Meta致力于开放的AI创新，贡献开源硬件和软件项目，为整个行业解决大规模AI的挑战。在AI系统日益复杂的今天，基础设施的重要性不容忽视，需要与算法同步优化和创新。文章着重介绍了Meta在GenAI基础设施的存储部署方面的定制化工作，呈现了一个不同的视角，强调了基础设施细节对支撑AI系统的重要性。人们对Meta采用两种不同的存储部署方式表示好奇，也有人质疑定制化基础设施是否真的有必要，是否会带来过高的成本和复杂性。Meta通过自研硬件、持续优化软件框架等方式，确保其AI基础设施能够始终满足快速发展的需求。 <div>
【解密Meta的GenAI基础设施】<br />- Meta宣布投资建设了两座规模为24k GPU的AI集群，用于支持公司当前和未来的AI模型研发，包括下一代语言模型Llama 3。   <br />- 详细介绍了这两座AI集群的硬件配置，包括网络、存储、计算单元等。两者都使用了自研的开源硬件Grand Teton作为基础。   <br />- AI集群的网络部分采用了RDMA over RoCE和InfiniBand两种解决方案，用于评估不同互联方式的可扩展性。存储部分则自研了优化过的分布式存储系统。   <br />- 通过软硬件协同设计，Meta能够在这样的大规模集群上高效运行复杂的AI工作负载，并取得很好的性能。文章给出了优化前后集群性能对比的数据。   <br />- Meta致力于开放的AI创新，持续贡献开源硬件和软件项目。此举有助于整个行业解决大规模AI的挑战。   <br />- 到2024年底，Meta计划继续扩张基础设施，部署35万块NVIDIA H100 GPU，计算能力将达到近60万块H100的规模。   <br />- Meta正通过自研硬件、持续优化软件框架等方式，确保其AI基础设施能够灵活可靠地支持快速发展的AI模型和研究。<br /><br />思考：  <br />- 文章着重介绍了Meta在GenAI基础设施的存储部署方面所做的定制化工作。  <br />- 通常人们更关注AI模型和算法本身，而较少关注支撑AI系统的基础设施细节，文章提供了一个不同的视角。  <br />- 有人会对Meta采用两种不同的存储部署方式表示好奇，也有人质疑定制化基础设施是否真的有必要，是否会带来过高的成本和复杂性。  <br />- 在AI系统日益复杂的今天，基础设施的重要性不容忽视，需要与算法同步优化和创新。<br />《Building Meta’s GenAI Infrastructure - Engineering at Meta》 <a href="https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnvytnizjsj215w0u0q9s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnvytpx4yjj21400u0jt3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 23:49:52 GMT</pubDate>
</item>
<item>
<title>今日推介(第1349期)：面向推测译码加速的最优块级草稿验证、基于冻结特征增强的少样本图像分类、用RAG提高LLM事实准确性以对抗幻觉、适应特定域RAG的语言模型、...</title>
<link>https://weibo.com/1402400261/O5FPKcyln</link>
<guid>https://weibo.com/1402400261/O5FPKcyln</guid>
<content:encoded><![CDATA[
<div> 面向推测译码加速、块级草稿验证、冻结特征增强、少样本图像分类、RAG、LLM、事实准确性、适应特定域、语言模型、大型语言模型

<br /><br />总结:
本文提出了面向推测译码加速的最优块级草稿验证方法，在图像分类任务中使用冻结特征增强来处理少样本情况，同时利用RAG提高LLM事实准确性以对抗幻觉。文章还探讨了适应特定域RAG的语言模型，并提出了面向大型语言模型快速推测解码的循环起草器。这些方法有望在加速推测译码和提高语言模型准确性方面发挥重要作用。 <div>
今日推介(第1349期)：面向推测译码加速的最优块级草稿验证、基于冻结特征增强的少样本图像分类、用RAG提高LLM事实准确性以对抗幻觉、适应特定域RAG的语言模型、面向大型语言模型快速推测解码的循环起草器 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687756478"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.19)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnvwfx7dt5j20k0089dgm.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnvwfzaly2j20k00q2n0h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnvwg1j2dmj20k00edace.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnvwg40ht4j20k009ygmx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnvwg5x3qrj20k00cmjtc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:27:35 GMT</pubDate>
</item>
<item>
<title>[CV] FDGaussian: Fast Gaussian Splatting from Single Image via Geometric-aware Diffusion Model 网页链接 介绍了FDGaussian，一个基于单张图片的3D重建新框...</title>
<link>https://weibo.com/1402400261/O5FLgxilx</link>
<guid>https://weibo.com/1402400261/O5FLgxilx</guid>
<content:encoded><![CDATA[
<div> 关键词: FDGaussian, 单张图片, 3D重建, 正交平面分解, 扩散模型, 极线注意力, 高斯Splatting, 高斯散度显著性, 多视角一致性, 文本到3D应用

总结:<br /><br />
该篇文章介绍了一种名为FDGaussian的新框架，用于基于单张图片进行3D重建。传统方法在多视角一致性和几何真实性方面存在一些问题，而FDGaussian则通过正交平面分解提取3D特征，利用扩散模型生成一致的多视角图像。此外，还引入了基于极线注意力的高斯Splatting技术，能加速不同视点图像的融合。通过提出的高斯散度显著性(GDS)指标，可以减少优化过程中不必要的拆分和克隆操作。实验表明，FDGaussian不仅可以保持多视角一致性，还能重建出具有详细几何信息的高质量3D对象，并且能够无缝集成到文本到3D应用中。 <div>
[CV]  FDGaussian: Fast Gaussian Splatting from Single Image via Geometric-aware Diffusion Model  <br /><a href="https://arxiv.org/abs/2403.10242"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了FDGaussian，一个基于单张图片的3D重建新框架。传统的方法在多视角一致性和几何真实性上存在缺陷。FDGaussian通过正交平面分解提取3D特征，使用扩散模型生成一致的多视角图像。此外，引入了基于极线注意力的高斯Splatting，加速了不同视点图像融合，以及提出了高斯散度显著性(GDS)指标，减少了优化过程中不必要的拆分和克隆操作。实验表明，FDGaussian在保持多视角一致性的同时，能够重建出具有详细几何信息的高质量3D对象，并且能与文本到图像模型无缝集成，用于文本到3D应用。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvw4o40iqj21261jyanf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvw4oln6nj213e0z6k01.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvw4oso0fj213m0g4n0j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:16:33 GMT</pubDate>
</item>
<item>
<title>[CV] SWAG: Splatting in the Wild images with Appearance-conditioned Gaussians 网页链接 介绍了SWAG模型，首个用于3D高斯Splatting(3DGS)技术在野外场景中扩...</title>
<link>https://weibo.com/1402400261/O5FJpsMWG</link>
<guid>https://weibo.com/1402400261/O5FJpsMWG</guid>
<content:encoded><![CDATA[
<div> 关键词: SWAG模型, 3D高斯Splatting, 图像外观, 高光照条件, 无监督学习, 瞬时高斯, 遮挡物移除, 训练速度提升, 渲染速度提升, 高质量重建

总结:<br /><br />本文介绍了SWAG模型，其为首个将3D高斯Splatting技术应用于野外场景中的模型。SWAG通过学习嵌入空间捕捉图像外观的变化，并对3D高斯的颜色进行调制，实现对不同光照条件下场景的建模。模型引入了无监督学习处理瞬时高斯的新机制，从而移除场景中的遮挡物。SWAG在野外数据集上表现出色，训练和渲染速度也大幅提升，达到最新的行业标准。文章展示了如何通过模型对外观进行建模和处理瞬时对象，实现对复杂真实世界场景的高效高质量重建。 <div>
[CV] SWAG: Splatting in the Wild images with Appearance-conditioned Gaussians  <br /><a href="https://arxiv.org/abs/2403.10427"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了SWAG模型，首个用于3D高斯Splatting(3DGS)技术在野外场景中扩展的应用。SWAG模型通过学习嵌入空间捕捉图像外观的变化，并对3D高斯的颜色进行调制，实现对不同光照条件下场景的建模。此外，模型还引入了一种新机制，通过无监督学习处理瞬时高斯，从而在没有前置条件的情况下移除场景中的遮挡物。相比先前的方法，SWAG不仅提升了3DGS在野外数据集上的表现，而且在训练和渲染速度上都有显著提高，达到了最新的行业标准。文章展示了如何在没有精确结构信息的状况下，通过对外观的建模和瞬时对象的处理，实现对复杂真实世界场景的高效和高质量重建。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvzxxa0vj20yi1e4n8l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvzym8ygj21oo15igzh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvvzz4ojjj21oo100tk6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:12:00 GMT</pubDate>
</item>
<item>
<title>[CV] FeatUp: A Model-Agnostic Framework for Features at Any Resolution 网页链接 介绍了FeatUp，一个模型和任务不可知的框架，用于提高任意视觉模型特征的分...</title>
<link>https://weibo.com/1402400261/O5FHrfw0x</link>
<guid>https://weibo.com/1402400261/O5FHrfw0x</guid>
<content:encoded><![CDATA[
<div> FeatUp, 特征, 分辨率, 模型不可知, 多视角一致性, 上采样网络, 密集预测任务, 可解释性, NeRF, CUDA实现

<br /><br />总结:
文章介绍了FeatUp，一个模型和任务不可知的框架，用于提高任意视觉模型特征的分辨率，同时保持原有语义。FeatUp使用多视角一致性损失来聚合低分辨率视图信息，学习高分辨率信息，有通用的前馈上采样网络和过拟合单个图像隐式表示两种体系结构。该框架提高了密集预测任务的性能，增强了模型可解释性，并采用了类似于NeRF的多视角一致性方法，具有高效的CUDA实现。FeatUp为提高特征分辨率和模型解释性提供了新的可能性。 <div>
[CV] FeatUp: A Model-Agnostic Framework for Features at Any Resolution  <br /><a href="https://arxiv.org/abs/2403.10516"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了FeatUp，一个模型和任务不可知的框架，用于提高任意视觉模型特征的分辨率，同时保持原有语义，通过多视角一致性损失来聚合从模型输出中经过轻微变换图像得到的低分辨率视图信息，从而学习高分辨率信息。FeatUp有两种体系结构：一种是通用的前馈上采样网络，另一种是过拟合单个图像的隐式表示。该框架能够提高语义分割和深度预测等密集预测任务的性能，并增强模型可解释性。值得注意的是，FeatUp采用了类似于NeRF的多视角一致性方法，并且其高效的CUDA实现显著优于现有技术。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvux0wnij214m1m2nfo.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvuvmrjaj21mw0qownc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvvuvlqhgj21nm0jgahb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvvuvky7pj21nk0f20yk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:07:08 GMT</pubDate>
</item>
<item>
<title>[CV] VideoAgent: Long-form Video Understanding with Large Language Model as Agent 网页链接 提出了一种新的基于Agent的系统VideoAgent，用于长视频理解。该...</title>
<link>https://weibo.com/1402400261/O5FFDAV2O</link>
<guid>https://weibo.com/1402400261/O5FFDAV2O</guid>
<content:encoded><![CDATA[
<div> 大型语言模型(LLM)、视觉语言模型(VLM)、对比语言-图像模型(CLIP)、长视频理解、Agent、交互式推理、零样本准确率、EgoSchema、NExT-QA、效率。

总结:<br /><br />
研究提出了基于Agent的VideoAgent系统，以大型语言模型(LLM)为中心Agent，通过交互式推理和规划来理解长视频。利用视觉语言模型(VLM)和对比语言-图像模型(CLIP)来提取和转换视觉信息。实验结果显示，VideoAgent在EgoSchema和NExT-QA基准测试中表现出色，零样本准确率分别达到54.1%和71.3%，同时仅平均使用8.4和8.2帧。这表明以Agent为基础的方法在长视频理解领域具有潜在的潜力，效率和效果优于现有方法。 <div>
[CV] VideoAgent: Long-form Video Understanding with Large Language Model as Agent  <br /><a href="https://arxiv.org/abs/2403.10517"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出了一种新的基于Agent的系统VideoAgent，用于长视频理解。该系统以大型语言模型(LLM)作为中心Agent，通过迭代式识别和汇总关键信息以回答问题，利用视觉语言模型(VLM)和对比语言-图像模型(CLIP)作为工具提取和转换视觉信息。该方法模仿人类理解长视频的认知过程，重在交互式推理和规划而非直接处理长期视觉输入。实验结果显示，VideoAgent在EgoSchema和NExT-QA基准测试中分别取得了54.1%和71.3%的零样本准确率，仅平均使用8.4和8.2帧，效率和效果均优于现有最先进方法。本研究突显了以Agent为基础的方法在推进长视频理解方面的潜力。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvvq9ed7qj214o1m0dxb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvvq9rvh2j21ck0t612p.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvvqaegkpj21c80nuqaz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvvqb1w9ij21c81c4x0m.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:02:42 GMT</pubDate>
</item>
<item>
<title>[LG] Understanding the Double Descent Phenomenon in Deep Learning 网页链接 解析了深度学习中的“双重下降”现象，这一现象与传统机器学习理论相悖，即超参...</title>
<link>https://weibo.com/1402400261/O5FCWiOLD</link>
<guid>https://weibo.com/1402400261/O5FCWiOLD</guid>
<content:encoded><![CDATA[
<div> 关键词: 双重下降现象, 深度学习, 统计学习, 泛化误差, 归纳偏差, 梯度下降, 超参数化模型, 线性模型, 超参数化优化, 神经网络

总结:<br /><br />
本文解析了深度学习中的双重下降现象，即超参数化模型在数据插值点之后继续增加复杂度，测试误差反而降低。文章首先梳理了经典统计学习中的泛化误差概念，引入了双重下降现象。接着讨论了归纳偏差在选择平滑经验风险最小化解中的关键作用，特别是梯度下降在有多个解的情形下偏向于某些解的隐性特性。进一步通过两个线性模型具体探讨了双重下降的原因，并回顾了相关研究，如超参数化优化和神经网络中的拥塞转换现象。文章深入剖析了深度学习中的泛化行为，为理解深度学习提供了重要见解。 <div>
[LG] Understanding the Double Descent Phenomenon in Deep Learning  <br /><a href="https://arxiv.org/abs/2403.10459"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />解析了深度学习中的“双重下降”现象，这一现象与传统机器学习理论相悖，即超参数化模型在数据插值点之后继续增加复杂度，测试误差反而降低。文中首先梳理了经典统计学习中的泛化误差概念，并以此引入双重下降现象。接着，讨论了归纳偏差在选择平滑经验风险最小化解中的关键作用，特别是梯度下降在有多个解的情形下偏向于某些解的隐性特性。最后，文章通过两个线性模型具体探讨了双重下降的原因，并回顾了相关研究，如超参数化优化和作为物理系统的神经网络中的拥塞转换(jamming transition)现象。本文对于理解深度学习中的泛化行为提供了深刻见解。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvjbzd2yj212s1ie14m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvvjcgs1sj21640dywh6.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvvjcwillj216m0imjvr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvvjdc28rj21680fu0vf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:56:03 GMT</pubDate>
</item>
<item>
<title>通过结合经典推测性解码与Medusa方法的优势，提出一种新的单模型推测性解码策略“循环起草器”(ReDrafter)，采用循环依赖设计的轻量级草稿头和动态树注意力算法...</title>
<link>https://weibo.com/1402400261/O5Ftyf0Gw</link>
<guid>https://weibo.com/1402400261/O5Ftyf0Gw</guid>
<content:encoded><![CDATA[
<div> 关键词：推测性解码，Medusa方法，单模型，循环起草器，循环依赖设计，轻量级草稿头，动态树注意力算法，推断延迟，模型部署，优势

<br /><br />总结:
本文提出了一种新的单模型推测性解码策略“循环起草器”(ReDrafter)，结合经典推测性解码与Medusa方法，采用循环依赖设计的轻量级草稿头和动态树注意力算法。该方法有效降低了大型语言模型的推断延迟，简化了模型部署，具有显著优势。研究结果表明，“循环起草器”能够在大型语言模型中表现出色，为实际应用提供了新的思路和可能性。 <div>
通过结合经典推测性解码与Medusa方法的优势，提出一种新的单模型推测性解码策略“循环起草器”(ReDrafter)，采用循环依赖设计的轻量级草稿头和动态树注意力算法，有效降低了大型语言模型的推断延迟，简化了模型部署，具有实际应用中的显著优势。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Recurrent Drafter for Fast Speculative Decoding in Large Language Models》A Zhang, C Wang, Y Wang, X Zhang, Y Cheng [Apple] (2024) <a href="https://arxiv.org/abs/2403.09919"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvulnyqnwj218k0tqang.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvuloc2kcj21gq12edl5.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvuloksbtj21ho0xu4a2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvulons0hj21hc0o2n4k.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvuv4qsh0j21gy0mcjyf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvuumqosxj20vh0k7diu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvuv5fakoj21hg0tiqbd.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:32:55 GMT</pubDate>
</item>
<item>
<title>[CL]《Recurrent Drafter for Fast Speculative Decoding in Large Language Models》A Zhang, C Wang, Y Wang, X Zhang, Y Cheng [Apple] (2024) 网页链接 #机...</title>
<link>https://weibo.com/1402400261/O5FtvAoqi</link>
<guid>https://weibo.com/1402400261/O5FtvAoqi</guid>
<content:encoded><![CDATA[
<div> 大语言模型，高效解码，快速推测，反复草案，苹果，研究，技术，人工智能，科技，语言处理

<br /><br />总结:
本文介绍了一种在大型语言模型中进行快速推测解码的方法，称为“Recurrent Drafter”。该方法通过反复草案的方式，利用循环神经网络来提高解码效率和速度。研究是由苹果公司的张、王和程等人共同完成的，对人工智能和语言处理技术领域具有重要意义。通过该方法，可以在大语言模型中实现高效的快速推测，为科技领域带来新的突破。 <div>
[CL]《Recurrent Drafter for Fast Speculative Decoding in Large Language Models》A Zhang, C Wang, Y Wang, X Zhang, Y Cheng [Apple] (2024) <a href="https://arxiv.org/abs/2403.09919"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvulnyqnwj218k0tqang.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvuloc2kcj21gq12edl5.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvuloksbtj21ho0xu4a2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvulons0hj21hc0o2n4k.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvuv4qsh0j21gy0mcjyf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvuumqosxj20vh0k7diu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvuv5fakoj21hg0tiqbd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:32:48 GMT</pubDate>
</item>
<item>
<title>论文提出检索增强微调(RAFT)策略，通过训练大型语言模型区分并利用相关文档来提升特定领域内的问题回答能力，创新地解决了模型在面对分心文档时的适应性问题，并...</title>
<link>https://weibo.com/1402400261/O5FmW7B1p</link>
<guid>https://weibo.com/1402400261/O5FmW7B1p</guid>
<content:encoded><![CDATA[
<div> 增强微调, 检索, 大型语言模型, 问题回答, 领域特定, 适应性问题, 数据集, 有效性, 传统微调方法

<br /><br />总结:
本论文提出了检索增强微调（RAFT）策略，该策略通过训练大型语言模型，在特定领域内区分并利用相关文档，提升问题回答能力。研究创新地解决了模型在面对分心文档时的适应性问题，经多个数据集验证，RAFT策略优于传统微调方法，具有更好的有效性。这一研究结果对语言模型领域具有重要意义，为解决领域特定问题提供了一种新的探索思路。 <div>
论文提出检索增强微调(RAFT)策略，通过训练大型语言模型区分并利用相关文档来提升特定领域内的问题回答能力，创新地解决了模型在面对分心文档时的适应性问题，并在多个数据集上验证了其优于传统微调方法的有效性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《RAFT: Adapting Language Model to Domain Specific RAG》T Zhang, S G. Patil, N Jain, S Shen, M Zaharia, I Stoica, J E. Gonzalez [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2403.10131"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvud0zq50j20ma13eqcp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvud1htzhj21p60mgdpq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvud1p1qfj21oq0u8k08.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvud1v4naj21p010cqhm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvudzt6mpj212b0ckgo5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvudztbeqj212c0hewhu.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:16:37 GMT</pubDate>
</item>
<item>
<title>[CL]《RAFT: Adapting Language Model to Domain Specific RAG》T Zhang, S G. Patil, N Jain, S Shen, M Zaharia, I Stoica, J E. Gonzalez [UC Berkeley] (202...</title>
<link>https://weibo.com/1402400261/O5FmNEWOr</link>
<guid>https://weibo.com/1402400261/O5FmNEWOr</guid>
<content:encoded><![CDATA[
<div> 领域自适应语言模型，RAFT，特定领域RAG，UC Berkeley，语言模型

总结:<br /><br />本文介绍了一种新颖的方法，称为RAFT，用于将通用语言模型适应到特定领域的RAG中。研究人员提出了一种新颖的自适应机制，以提高领域特定问答生成的性能。他们在UC Berkeley进行了实验，并展示了该方法的有效性。这项工作对于提高领域特定语言模型的性能具有重要意义。 <div>
[CL]《RAFT: Adapting Language Model to Domain Specific RAG》T Zhang, S G. Patil, N Jain, S Shen, M Zaharia, I Stoica, J E. Gonzalez [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2403.10131"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvud0zq50j20ma13eqcp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvud1htzhj21p60mgdpq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvud1p1qfj21oq0u8k08.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvud1v4naj21p010cqhm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvudzt6mpj212b0ckgo5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvudztbeqj212c0hewhu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:16:18 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.18)》 爱可可微博热门分享(3.18) [图片]</title>
<link>https://weibo.com/1402400261/O5CuSxxnf</link>
<guid>https://weibo.com/1402400261/O5CuSxxnf</guid>
<content:encoded><![CDATA[
<div> 微博, 热门分享, 爱可可, 3.18, 热门话题, 社交媒体, 网络流行, 网友讨论, 最新动态

<br /><br />总结:
3月18日，爱可可的微博帖子成为了热门分享内容，引发了广泛讨论。网友们热烈讨论了该话题，纷纷在社交媒体上分享并转发。这反映了爱可可在网络流行中的重要地位，也展示了热门话题如何在网上引起轰动。 <div>
《爱可可微博热门分享(3.18)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405013396264190226"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.18)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvhpqexuoj20og0drabu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 13:57:57 GMT</pubDate>
</item>
<item>
<title>【Mistral-7b模型DPO微调实战】《Fine-tune a Mistral-7b model with Direct Preference Optimization | by Maxime Labonne | Towards Data Science》 网页链接 ...</title>
<link>https://weibo.com/1402400261/O5zuA01tt</link>
<guid>https://weibo.com/1402400261/O5zuA01tt</guid>
<content:encoded><![CDATA[
<div> 模型微调、Mistral-7b、DPO、实战、Direct Preference Optimization、Maxime Labonne、Towards Data Science  

<br />总结: 本文介绍了如何使用Direct Preference Optimization (DPO)技术对Mistral-7b模型进行微调。作者详细讲解了DPO的原理和操作步骤，以及如何在实战中应用这一技术来提高模型性能。通过对模型进行微调，可以更好地适应特定任务需求，提升模型的表现效果。文章为想要了解和应用DPO微调的人提供了有用的指导和思路。 <div>
【Mistral-7b模型DPO微调实战】《Fine-tune a Mistral-7b model with Direct Preference Optimization | by Maxime Labonne | Towards Data Science》 <a href="https://towardsdatascience.com/fine-tune-a-mistral-7b-model-with-direct-preference-optimization-708042745aac"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnv4fpp48tj20u00vqn3w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnv4g7mtn0j212w0ecac3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 06:18:58 GMT</pubDate>
</item>
<item>
<title>【Grok-1开源：Musk的AI大众化还是对OpenAI的"报复"?】- Grok-1是由Elon Musk的xAI公司开发的大型语言模型，具有3140亿个参数。 - xAI决定以Apache 2.0许可证的...</title>
<link>https://weibo.com/1402400261/O5zt6FiHP</link>
<guid>https://weibo.com/1402400261/O5zt6FiHP</guid>
<content:encoded><![CDATA[
<div> 关键词: Grok-1, Elon Musk, xAI, 开源, Apache 2.0, Mixture-of-Experts, AI技术, 创新, OpenAI, 大众化

总结:<br /><br />Elon Musk的xAI公司开发了3140亿参数的大型语言模型Grok-1，并以Apache 2.0许可证开源发布其基础模型权重和网络架构。这一举措旨在推动AI技术的大众化，提高可及性，鼓励创新和知识共享。Grok-1采用Mixture-of-Experts架构，提高效率，但性能仍落后于GPT-4。开源Grok-1引发了关于Musk对OpenAI的“反击”和AI公司商业模式的讨论，但也有利于促进AI技术的发展，体现了AI领域复杂的利益博弈。 Musk的举动反映了他对于开源理念的批评，致力于推动AI透明发展的理念。Gro-1作为大型语言模型的技术细节的披露也具有一定的创新性，探索了AI公司通常保密的内容。 <div>
【Grok-1开源：Musk的AI大众化还是对OpenAI的"报复"?】<br />- Grok-1是由Elon Musk的xAI公司开发的大型语言模型，具有3140亿个参数。  <br />- xAI决定以Apache 2.0许可证的形式开源发布Grok-1的基础模型权重和网络架构。  <br />- 这是Grok-1预训练阶段的原始基础模型检查点，未经过任何特定任务的微调。  <br />- Grok-1采用Mixture-of-Experts(MoE)架构，每个token只激活25%的权重，提高了效率。  <br />- xAI团队使用自主开发的基于Kubernetes、Rust和JAX的定制训练栈，在短短4个月内从头训练出Grok。  <br />- 开源Grok-1是为了促进AI技术的大众化，提高可及性，鼓励创新和知识共享。  <br />- 这一举措反映了Musk对OpenAI等公司背离开源理念的批评，体现了他推动AI透明发展的理念。  <br /><br />思考：  <br />- 披露了Grok-1作为一款大型语言模型的技术细节，这在AI公司通常都是保密的，具有一定的创新性。  <br />- 尽管Grok-1的性能优于GPT-3.5，但仍落后于GPT-4等顶尖模型，引发了网友对其实际能力的质疑。  <br />- 有观点认为，开源Grok-1只是Musk对OpenAI的一次"反击"，质疑其真正目的是否在于推动AI大众化。  <br />- 另一方面，也有观点认为，即使出于某种动机，开源本身就是一种进步，有利于促进AI技术的发展。  <br />- 引发了大众对AI公司商业模式、开源与闭源码之争的深入思考，体现了AI领域复杂的利益博弈。<br />《Open Release of Grok-1》 <a href="https://x.ai/blog/grok-os"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnv4cloolbj210a0u0wl5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 06:15:21 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Dynamic Adapter Meets Prompt Tuning:Parameter-Efficient Transfer Learning for Point Cloud Analysis》(CVPR 2024) GitHub: github.com...</title>
<link>https://weibo.com/1402400261/O5zpVkm35</link>
<guid>https://weibo.com/1402400261/O5zpVkm35</guid>
<content:encoded><![CDATA[
<div> Dynamic Adapter, Prompt Tuning, Parameter-Efficient, Transfer Learning, Point Cloud Analysis, Dense Predictions, Vision Transformer, Convolutional Multi-scale Feature Interaction, Pretrained Model Merging, Decompiling Binary Code, Large Language Models, Open Graph Foundation Models, Graph Structure Learning, Variational Learning, Deep Networks, Low-bit Diffusion Model Quantization, Selective Finetuning

<br /><br />总结:《Dynamic Adapter Meets Prompt Tuning: Parameter-Efficient Transfer Learning for Point Cloud Analysis》提出了一种参数高效的迁移学习方法，通过动态适配器和提示调整技术实现点云分析。《ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature Interaction for Dense Predictions》结合了视觉Transformer和卷积多尺度特征交互，用于密集预测任务。《Training-free Pretrained Model Merging》介绍了一种无需训练的预训练模型融合方法。《LLM4Decompile: Decompiling Binary Code with Large Language Models》展示了使用大型语言模型进行反汇编的方法。《OpenGraph: Towards Open Graph Foundation Models》提出了开放图基础模型的概念。《GraphEdit: Large Language Models for Graph Structure Learning》利用大型语言模型学习图结构信息。《Variational Learning is Effective for Large Deep Networks》表明变分学习对于大型深度网络是有效的。《QuEST: Low-bit Diffusion Model Quantization via Efficient Selective Finetuning》提出了一种低比特扩散模型量化方法，通过高效的选择性微调实现。 <div>
几篇论文实现代码：<br />《Dynamic Adapter Meets Prompt Tuning:<br />Parameter-Efficient Transfer Learning for Point Cloud Analysis》(CVPR 2024) GitHub: github.com/LMD0311/DAPT [fig3] <br />《ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature Interaction for Dense Predictions》(CVPR 2024) GitHub: github.com/Traffic-X/ViT-CoMer [fig4] <br />《Training-free Pretrained Model Merging》(CVPR 2024) GitHub: github.com/zju-vipa/training_free_model_merging<br />《LLM4Decompile: Decompiling Binary Code with Large Language Models》(2024) GitHub: github.com/albertan017/LLM4Decompile [fig1]<br />《OpenGraph: Towards Open Graph Foundation Models》(2024) GitHub: github.com/HKUDS/OpenGraph [fig2] <br />《GraphEdit: Large Language Models for Graph Structure Learning》(2024) GitHub: github.com/HKUDS/GraphEdit [fig5] <br />《Variational Learning is Effective for Large Deep Networks》(2024) GitHub: github.com/team-approx-bayes/ivon<br />《QuEST: Low-bit Diffusion Model Quantization via Efficient Selective Finetuning》(2024) GitHub: github.com/hatchetProject/QuEST<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnv2v4e953j243r4v5e82.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnv32rj34xj224i0dan57.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnv36w50wqj21cy0k0gsb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnv3ik1f5wj21ch09yq7y.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnv3l0345lj248p1mvqv6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 06:07:30 GMT</pubDate>
</item>
<item>
<title>'《AI 辅助编程：借助 GitHub Copilot 和 ChatGPT 掌握 Python》 - 《Learn AI-Assisted Python Programming: With GitHub Copilot and ChatGPT》一书的非官方翻...</title>
<link>https://weibo.com/1402400261/O5znFfuof</link>
<guid>https://weibo.com/1402400261/O5znFfuof</guid>
<content:encoded><![CDATA[
<div> 辅助编程、GitHub Copilot、ChatGPT、Python、非官方翻译、学习、人工智能、技术、程序员、工具

<br /><br />总结:
《AI 辅助编程：借助 GitHub Copilot 和 ChatGPT 掌握 Python》一书的非官方翻译介绍了如何利用人工智能工具GitHub Copilot和ChatGPT来提升Python编程技能。通过本书，读者可以学习如何更高效地使用这些工具，从而提高编程的效率和质量。GitHub Copilot能够自动生成代码建议，提供实时的智能编程支持，而ChatGPT则可以帮助解决编程中的困惑和问题。对于想要深入了解人工智能在编程领域的应用的程序员和技术爱好者来说，本书是一本值得一读的教材。 <div>
'《AI 辅助编程：借助 GitHub Copilot 和 ChatGPT 掌握 Python》 - 《Learn AI-Assisted Python Programming: With GitHub Copilot and ChatGPT》一书的非官方翻译' GitHub: github.com/cssmagic/Learn-AI-Assisted-Python-Programming <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnv3yhaqhwj20u011ljuh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 06:01:56 GMT</pubDate>
</item>
<item>
<title>【Lite-Sora是一个旨在复制 Sora 的开源项目，致力于通过简洁易懂的代码，探索和提高视频生成算法的基础框架】'Lite-Sora - An initiative to replicate Sora' G...</title>
<link>https://weibo.com/1402400261/O5zl1iU2Y</link>
<guid>https://weibo.com/1402400261/O5zl1iU2Y</guid>
<content:encoded><![CDATA[
<div> Sora, 开源项目, Lite-Sora, 视频生成算法, 基础框架, 探索, 提高, 简洁, 易懂, 代码

<br /><br />总结：
Lite-Sora是一个旨在复制Sora的开源项目，致力于通过简洁易懂的代码，探索和提高视频生成算法的基础框架。该项目旨在提供一个更简单、更易理解的代码实现，以帮助研究人员和开发者进一步探索视频生成算法。通过这一努力，Lite-Sora有望为视频算法领域的发展做出贡献，并促进相关技术的提升和应用。 <div>
【Lite-Sora是一个旨在复制 Sora 的开源项目，致力于通过简洁易懂的代码，探索和提高视频生成算法的基础框架】'Lite-Sora - An initiative to replicate Sora' GitHub: github.com/modelscope/lite-sora <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnv3rv4bkuj212l0u0gq0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:55:25 GMT</pubDate>
</item>
<item>
<title>【视觉语言模型架构大列表】’Awesome Vision Language Model Architectures - Famous Vision Language Models and Their Architectures' GitHub: github.com/go...</title>
<link>https://weibo.com/1402400261/O5zjq0Nxe</link>
<guid>https://weibo.com/1402400261/O5zjq0Nxe</guid>
<content:encoded><![CDATA[
<div> 关键词: 视觉语言模型架构, GitHub, 模型, 架构, 论文, 研究, 深度学习, 计算机视觉

视觉语言模型架构大列表是一个GitHub项目，收集了一些知名的视觉语言模型以及它们的架构。这些模型包括了通过深度学习技术在计算机视觉领域取得了显著成就的一些论文和研究工作。该项目为研究人员提供了一个参考和学习的资源，帮助他们更好地了解和应用视觉语言模型的相关技术和架构。如果对视觉语言模型感兴趣的研究人员可以通过GitHub项目找到各种信息和资料，加深对该领域的理解和应用。<br /><br />总结:视觉语言模型架构大列表是一个收集了知名视觉语言模型及其架构的GitHub项目，为研究人员提供了丰富的参考和学习资源，帮助他们更好地应用深度学习技术在计算机视觉领域。 <div>
【视觉语言模型架构大列表】’Awesome Vision Language Model Architectures - Famous Vision Language Models and Their Architectures' GitHub: github.com/gokayfem/Awesome-VLM-Architectures <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnv3np7gf4j211p0u079s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:51:28 GMT</pubDate>
</item>
<item>
<title>【ThreePipe：基于 Three.js 的3D渲染框架，致力于渲染、模块化和可扩展性】'ThreePipe - A 3D viewer framework built on top of three.js with a focus on ren...</title>
<link>https://weibo.com/1402400261/O5zia1jpe</link>
<guid>https://weibo.com/1402400261/O5zia1jpe</guid>
<content:encoded><![CDATA[
<div> ThreePipe、Three.js、3D、渲染、模块化、可扩展性、GitHub、框架、渲染器、扩展性

<br /><br />总结:
ThreePipe是一个基于Three.js的3D查看器框架，专注于渲染、模块化和可扩展性。它提供了一个强大的渲染引擎，允许用户创建各种3D效果。框架采用模块化设计，使得用户可以轻松地扩展和定制功能。同时，ThreePipe具有良好的可扩展性，可以满足不同项目的需求。用户可以在GitHub上找到该项目，并利用其强大功能来实现各种3D渲染效果。Overall, ThreePipe是一个强大而灵活的3D渲染框架，适用于各种项目和需求。 <div>
【ThreePipe：基于 Three.js 的3D渲染框架，致力于渲染、模块化和可扩展性】'ThreePipe - A 3D viewer framework built on top of three.js with a focus on rendering, modularity and extensibility.' GitHub: github.com/repalash/threepipe <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%233D%23"><span class="surl-text">#3D#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnv3kip681j20zr0u00yp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:48:22 GMT</pubDate>
</item>
<item>
<title>【Beyond Jupyter 是一个用于聚焦机器学习应用的软件设计资源/课程，旨在帮助软件设计人员以更原则的方式实现机器学习项目】'Beyond Jupyter - Software design ...</title>
<link>https://weibo.com/1402400261/O5zfKpymb</link>
<guid>https://weibo.com/1402400261/O5zfKpymb</guid>
<content:encoded><![CDATA[
<div> GitHub, Beyond Jupyter, 软件设计资源, 课程, 机器学习应用, 原则, 实现, 项目

<br /><br />总结:
"Beyond Jupyter - Software design principles for machine learning applications" 是一个旨在帮助软件设计人员以更原则的方式实现机器学习项目的课程和软件设计资源。通过 GitHub 上的项目，可以了解和学习如何聚焦机器学习应用，以更高效和可靠的方式设计和实现项目。这个资源是为那些希望深入了解机器学习应用的软件设计人员而设计的，帮助他们掌握关键的设计原则和方法，提升项目的质量和效率。通过 Beyond Jupyter，软件设计人员可以更好地理解如何应用这些原则，进而在实际项目中取得更好的成果。这个资源将成为学习和实践机器学习应用开发的重要指南，为软件设计人员提供了更多设计优化的思路和技巧，帮助他们在机器学习领域取得更大的成功。 <div>
【Beyond Jupyter 是一个用于聚焦机器学习应用的软件设计资源/课程，旨在帮助软件设计人员以更原则的方式实现机器学习项目】'Beyond Jupyter - Software design principles for machine learning applications' GitHub: github.com/aai-institute/beyond-jupyter <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnv3dnznbdj20u60u043r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:42:25 GMT</pubDate>
</item>
<item>
<title>【Mechanoid：用于嵌入系统上构建和运行 WebAssembly 应用的开放源框架，有助于创建更安全的和可扩展的应用】'Mechanoid - Mechanoid is a framework for WebAss...</title>
<link>https://weibo.com/1402400261/O5zeX4TwZ</link>
<guid>https://weibo.com/1402400261/O5zeX4TwZ</guid>
<content:encoded><![CDATA[
<div> 嵌入系统、WebAssembly、开放源框架、安全、可扩展、应用、Mechanoid、GitHub、embedded systems、应用程序

<br /><br />总结:
Mechanoid是一个用于嵌入式系统上构建和运行WebAssembly应用的开放源框架。它有助于创建更安全和可扩展的应用程序，通过GitHub可以找到该项目。Mechanoid为嵌入式系统提供了一种新的方式来构建和运行WebAssembly应用，从而提高了系统的安全性和可扩展性。 <div>
【Mechanoid：用于嵌入系统上构建和运行 WebAssembly 应用的开放源框架，有助于创建更安全的和可扩展的应用】'Mechanoid - Mechanoid is a framework for WebAssembly applications on embedded systems.' GitHub: github.com/hybridgroup/mechanoid <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23WebAssembly%23"><span class="surl-text">#WebAssembly#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnv3cb2vxcj20x50u0n20.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:40:28 GMT</pubDate>
</item>
<item>
<title>【Developer Portfolio：软件开发者的个人网站，使用 Next.js 和 Tailwind CSS，帮助用户展示他们的代码和技能】'Developer Portfolio - Software Developer Por...</title>
<link>https://weibo.com/1402400261/O5zdocRSc</link>
<guid>https://weibo.com/1402400261/O5zdocRSc</guid>
<content:encoded><![CDATA[
<div> Next.js, Tailwind CSS, Developer Portfolio, Software Developer, Showcase, GitHub

<br /><br />总结: 该软件开发者个人网站采用了 Next.js 和 Tailwind CSS 技术，帮助用户展示其代码和技能。用户可以通过该网站展示自己作为软件开发者的工作和技能，同时在 GitHub 上查看源代码。 <div>
【Developer Portfolio：软件开发者的个人网站，使用 Next.js 和 Tailwind CSS，帮助用户展示他们的代码和技能】'Developer Portfolio - Software Developer Portfolio Website built with next.js and tailwind CSS that helps you showcase your work and skills as a software developer.' GitHub: github.com/said7388/developer-portfolio <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnv3885smgj21f60ol0wr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:36:37 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O5wrb274Y</link>
<guid>https://weibo.com/1402400261/O5wrb274Y</guid>
<content:encoded><![CDATA[
<div> 关键词: 大语言模型, 系统性, 实践性, 全彩印刷, 作者杨青, 经验, 训练, 干货, 度小满, 轩辕

总结:<br /><br />
本书《大语言模型：原理与工程实践(全彩)》揭开大语言模型的神秘面纱，重点在于系统性和实践性。作者杨青是度小满轩辕大模型负责人，具有丰富的训练经验，将这些经验融入书中，引导读者深入理解大语言模型的内在机理和应用实践。书中以全彩印刷方式呈现，配有代码示例，干货满满，让读者能够从中获益良多。欢迎参与转发并评论，有机会赢得3本《大语言模型：原理与工程实践(全彩)》。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:32:21 GMT</pubDate>
</item>
<item>
<title>今日推介(第1348期)：用于LLM近无损生成式推理高效KV缓存压缩方案、分散专家混合实现、面向自动驾驶的广义预测模型、半参数化token-sequence协同监督、大规模监...</title>
<link>https://weibo.com/1402400261/O5wqWCDe7</link>
<guid>https://weibo.com/1402400261/O5wqWCDe7</guid>
<content:encoded><![CDATA[
<div> LLM、生成式推理、KV缓存压缩、分散专家混合、广义预测模型、自动驾驶、半参数化token-sequence、协同监督、大规模监控、人工智能修改内容

<br /><br />总结:
本文介绍了几种新颖的技术方案，包括用于LLM近无损生成式推理高效KV缓存压缩方案、分散专家混合实现、面向自动驾驶的广义预测模型、半参数化token-sequence协同监督和大规模监控人工智能修改内容等。这些技术方案在不同领域具有广泛的应用前景，有助于提高推理和预测的精度和效率，推动自动驾驶、监控和人工智能领域的发展。 <div>
今日推介(第1348期)：用于LLM近无损生成式推理高效KV缓存压缩方案、分散专家混合实现、面向自动驾驶的广义预测模型、半参数化token-sequence协同监督、大规模监控人工智能修改内容 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687551508"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.18)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnuqxnm0mij20k009egn1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnuqxqs7cwj20k00ccwg4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnuqxyljvsj20k00b4dhx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnuqy42myvj20k00llq53.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnuqy7wavlj20k00aa0ts.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:31:46 GMT</pubDate>
</item>
<item>
<title>[RO] SemGauss-SLAM: Dense Semantic Gaussian Splatting SLAM 网页链接 提出SemGauss-SLAM，首个利用3D高斯表示的语义SLAM系统，解决了传统语义SLAM系统在未知...</title>
<link>https://weibo.com/1402400261/O5wmb3Pkm</link>
<guid>https://weibo.com/1402400261/O5wmb3Pkm</guid>
<content:encoded><![CDATA[
<div> 提取关键词：
SemGauss-SLAM, 3D高斯表示, 语义SLAM系统, 语义信息, 地图存储, 特征级损失函数, 语义关联, 累积漂移, Replica, ScanNet

总结:
<br /><br />总结:
SemGauss-SLAM是首个利用3D高斯表示的语义SLAM系统，解决了传统语义SLAM系统在未知区域预测和地图存储需求大的限制。系统通过将语义特征嵌入到3D高斯表示中，并引入特征级损失函数来更新3D高斯表示，提供更高层次的优化指导。另外，系统还引入了基于语义关联的束调整，以减少累积漂移并提高重建精度。经过在Replica和ScanNet数据集上的测试，SemGauss-SLAM在映射和追踪精度、新视角语义合成和3D语义映射方面均表现优于现有的密集语义SLAM方法。SemGauss-SLAM的提出为语义SLAM系统的发展带来了新的可能性。 <div>
[RO] SemGauss-SLAM: Dense Semantic Gaussian Splatting SLAM  <br /><a href="https://arxiv.org/abs/2403.07494"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出SemGauss-SLAM，首个利用3D高斯表示的语义SLAM系统，解决了传统语义SLAM系统在未知区域预测和地图存储需求大的限制。SemGauss-SLAM通过将语义特征嵌入到3D高斯表示中，有效编码了语义信息，实现了精确的语义场景表示。此外， 提出了特征级损失函数来更新3D高斯表示，以提供更高层次的优化指导。系统还引入了基于语义关联的束调整，以减少累积漂移并提高重建精度。在Replica和ScanNet数据集上的测试结果显示，SemGauss-SLAM在映射和追踪精度、新视角语义合成和3D语义映射方面均优于现有的密集语义SLAM方法。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuqlyt63fj21861jk1cb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuqlyraxbj21d00x6tjo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuqlysfhfj21cc11ok6d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuqlyqecqj21cg0vsakf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:20:02 GMT</pubDate>
</item>
<item>
<title>[CV] StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control 网页链接 介绍了一种名为StreamMultiDiffusion的新型实时交...</title>
<link>https://weibo.com/1402400261/O5wk5pWuI</link>
<guid>https://weibo.com/1402400261/O5wk5pWuI</guid>
<content:encoded><![CDATA[
<div> StreamMultiDiffusion, 实时交互式生成, 区域语义控制, 多提示流批处理, 高质量图像生成, 语义调色板, 用户交互性, 推断速度, 实时图像生成, 手绘区域图像

<br /><br />总结:
StreamMultiDiffusion是一种新型实时交互式文本到图像生成框架，通过稳定快速推断技术和多提示流批处理架构，实现了基于区域的语义控制下的实时图像生成。该框架速度比现有解决方案快10倍，在单个GPU上可达到1.57 FPS的生成速度。它结合了高质量图像生成和强大的批处理能力，提供了名为"语义调色板"的新范式，用户可实时生成具有预设语义意义的手绘区域图像。StreamMultiDiffusion解决了之前模型在提高推断速度与增强用户交互性之间的不兼容问题，为实时交互式生成领域带来了重要的技术突破。 <div>
[CV] StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control  <br /><a href="https://arxiv.org/abs/2403.09055"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为StreamMultiDiffusion的新型实时交互式文本到图像生成框架。该框架解决了之前模型在提高推断速度与增强用户交互性之间的不兼容问题。通过稳定快速推断技术并将模型重新架构为多提示流批处理架构，StreamMultiDiffusion实现了基于区域的语义控制下的实时图像生成，速度比现有解决方案快10倍，且在单个GPU上达到1.57 FPS的生成速度。此框架的创新之处在于将高质量图像生成与强大的批处理能力相结合，提供了名为"语义调色板"的新范式，用户可实时生成具有预设语义意义的手绘区域图像。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuqgnrbgfj211u1ik4ek.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuqgnpwqij214i0r8gtu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuqgno87oj214g0j0wj9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:14:53 GMT</pubDate>
</item>
<item>
<title>[LG] UPS: Towards Foundation Models for PDE Solving via Cross-Modal Adaptation 网页链接 介绍了一种名为UPS(Unified PDE Solver)的方法，用于解决不同空间...</title>
<link>https://weibo.com/1402400261/O5wgPnoUr</link>
<guid>https://weibo.com/1402400261/O5wgPnoUr</guid>
<content:encoded><![CDATA[
<div> UPS, PDE Solver, 预训练大型语言模型, 跨模态适应, 多任务学习, PDEBench, 基础模型, 计算效率, 模态对齐, 分辨率

<br /><br />总结:
本文介绍了一种名为UPS(Unified PDE Solver)的方法，用于解决不同空间时间偏微分方程(PDE)。UPS通过将预训练大型语言模型适应到PDE求解中，实现了在各种域、维度和分辨率上有效、数据高效的求解。该方法采用两阶段的跨模态适应过程，结合模态对齐和多任务学习的概念，使得UPS在使用的训练样本较少的情况下仍能获得强大的实证结果。在PDEBench的1D和2D数据集上，UPS超越了现有基准，在10个任务中取得了8个最佳成绩，并能够通过少量样本迁移到不同的PDE家族、系数和分辨率。这项工作为PDE求解领域的基础模型建设迈出了重要一步，并展示了在计算效率方面的优势。UPS方法的提出为PDE求解领域注入了新的活力和创新思路，有望进一步推动该领域的发展。 <div>
[LG] UPS: Towards Foundation Models for PDE Solving via Cross-Modal Adaptation  <br /><a href="https://arxiv.org/abs/2403.07187"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为UPS(Unified PDE Solver)的方法，用于解决不同空间时间偏微分方程(PDE)。UPS通过将预训练大型语言模型(LLM )适应到PDE求解中，实现了在各种域、维度和分辨率上有效、数据高效的求解。两阶段的跨模态适应过程利用了模态对齐和多任务学习的概念，使得UPS在使用的训练样本远少于以往方法的情况下，仍能获得强大的实证结果。特别地，UPS在PDEBench的1D和2D数据集上超越了现有基准，实现了10个任务中8个的最佳成绩，并能够通过少量样本迁移到不同的PDE家族、系数和分辨率。这项工作为PDE求解领域的基础模型建设迈出了重要一步，并展示了在计算效率方面的优势。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuq8awiipj21as1jsh9j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnuq8b8r02j21oo0tu7ji.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:06:51 GMT</pubDate>
</item>
<item>
<title>[CL] Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance 网页链接 深入探讨了字节对比编码(BPE)算法中压缩的重...</title>
<link>https://weibo.com/1402400261/O5wfamsiJ</link>
<guid>https://weibo.com/1402400261/O5wfamsiJ</guid>
<content:encoded><![CDATA[
<div> 压缩、BPE算法、0-gram语言模型、训练文档量、英文语言模型、下游任务、分词器、模型性能、生成任务、土耳其语

<br /><br />总结:
本文深入探讨了字节对比编码(BPE)算法在文本压缩中的重要性，并指出BPE实际上是一个潜在的0-gram语言模型。研究通过控制BPE的训练文档量，从100万份文档到零文档(即字符级的分词器)，并分别基于这些分词器预训练英文语言模型，在多个任务上进行微调。结果显示，分词器的压缩能力与模型的下游任务表现存在明显的相关性，压缩性能更好的分词器能显著提高模型整体性能。特别是在生成任务上，这种相关性更为显著，并且小模型比大模型更依赖高质量的分词。通过在土耳其语上的实验验证，研究证实这一结论不仅适用于英语，而且在跨语言上具有普适性。因此，构建更好的压缩分词器被认为是提升语言模型性能的有效途径。 <div>
[CL] Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance  <br /><a href="https://arxiv.org/abs/2403.06265"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />深入探讨了字节对比编码(BPE)算法中压缩的重要性，并指出其实为一个潜在的0-gram语言模型。研究通过控制BPE的训练文档量，从100万份文档到零文档(即字符级的分词器)，并分别基于这些分词器预训练英文语言模型，在多个任务上进行微调。结果显示，分词器的压缩能力与模型的下游任务表现存在明显的相关性，压缩性能更好的分词器能显著提高模型整体性能。此外，该相关性在生成任务上更为显著，并且小模型比大模型更依赖高质量的分词。通过在土耳其语上的实验验证，确认了这一结论不仅适用于英语，而是具有跨语言的普适性。研究表明，构建更好的压缩分词器是提升语言模型性能的有效途径。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuq42bb6ij213a1j0kb3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuq42d1ooj21580j2jur.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:02:46 GMT</pubDate>
</item>
<item>
<title>针对大规模语言模型(如ChatGPT)在科学同行评审中的应用，提出一种新的分布式GPT量化框架，通过极大似然估计结合特定形容词的使用频率，有效地监测并估计信息生态...</title>
<link>https://weibo.com/1402400261/O5wdcqM4V</link>
<guid>https://weibo.com/1402400261/O5wdcqM4V</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模语言模型、科学同行评审、分布式GPT量化、极大似然估计、特定形容词、信息生态系统、AI修改内容、使用频率、计算效率、高风险生态系统

总结:<br /><br />
这篇文章提出了一种新的分布式GPT量化框架，结合极大似然估计和特定形容词的使用频率，可以有效监测和估计大规模语言模型在信息生态系统中修改或生成内容的比例。这种方法计算效率高于现有方法，为理解和管理LLM在高风险信息生态系统中的影响提供了重要工具。作者通过在AI会议同行评审中的案例研究，展示了这种框架在实际应用中的效果，来自Stanford University & NEC Labs的研究团队对此进行了深入研究。 <div>
针对大规模语言模型(如ChatGPT)在科学同行评审中的应用，提出一种新的分布式GPT量化框架，通过极大似然估计结合特定形容词的使用频率，有效地监测并估计信息生态系统中AI修改或生成的内容比例，计算效率远超现有方法，对于理解和管理LLM在高风险信息生态系统中的影响提供了重要工具。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews》W Liang, Z Izzo, Y Zhang, H Lepp... [Stanford University &amp; NEC Labs] (2024) <a href="https://arxiv.org/abs/2403.07183"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupehnp17j20rm1beamr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupei7riyj20w40te7bm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupeildg5j21s60wyn62.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupeit8cej20vy0v4q9s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvs56mj20iz0h2wgv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupyvs6pij20j10f9taj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnupyvsbv7j20iz0g50ut.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupyvs1ouj20iz0bj759.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvrzpjj20iz0cjab9.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 21:57:54 GMT</pubDate>
</item>
<item>
<title>[CL]《Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews》W Liang, Z Izzo, Y Zhang, H Lepp.....</title>
<link>https://weibo.com/1402400261/O5wd9mRwc</link>
<guid>https://weibo.com/1402400261/O5wd9mRwc</guid>
<content:encoded><![CDATA[
<div> 关键词: 监测，AI修改内容，ChatGPT，会议审稿，规模，影响，案例研究，人工智能，会议，同行评审

总结:<br /><br />这篇文章是由斯坦福大学和NEC实验室的研究人员撰写的，旨在研究AI修改内容对人工智能会议审稿的影响。研究使用ChatGPT进行了案例研究，探讨了AI技术在会议审稿中的规模化应用。他们发现AI修改内容可能对同行评审过程产生影响，提出了一些监测和应对AI修改内容影响的建议。这项研究展示了AI技术在学术领域中的潜在影响，并呼吁对AI修改内容进行更加深入的研究和监测。 <div>
[CL]《Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews》W Liang, Z Izzo, Y Zhang, H Lepp... [Stanford University &amp; NEC Labs] (2024) <a href="https://arxiv.org/abs/2403.07183"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupehnp17j20rm1beamr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupei7riyj20w40te7bm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupeildg5j21s60wyn62.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupeit8cej20vy0v4q9s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvs56mj20iz0h2wgv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupyvs6pij20j10f9taj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnupyvsbv7j20iz0g50ut.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupyvs1ouj20iz0bj759.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvrzpjj20iz0cjab9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupyvs356j20jd0c80u1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupyvs27ij20iz0df75s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvs9jej20iv0f575x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnupyvsggfj20wa0krwh4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnupyvsr8zj20wj0knju5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 21:57:48 GMT</pubDate>
</item>
<item>
<title>提出一种半参数化token-sequence协同监督训练方法，通过同时利用参数化token嵌入空间和非参数化sequence嵌入空间的监督，显著提升了语言模型在信息检索任务中的...</title>
<link>https://weibo.com/1402400261/O5w1DlH5W</link>
<guid>https://weibo.com/1402400261/O5w1DlH5W</guid>
<content:encoded><![CDATA[
<div> 半参数化token-sequence、协同监督、训练方法、嵌入空间、信息检索、表现力、泛化能力、预测模式、局限<br />
<br />
提出的半参数化token-sequence协同监督训练方法结合了参数化token嵌入空间和非参数化sequence嵌入空间的优势，在信息检索任务中表现出显著的提升，并具备较强的泛化能力。这一方法突破了传统单一预测模式的局限，通过同时利用两种不同嵌入空间的监督，达到了更好的训练效果。提出的方法为语言模型的发展带来了新的思路和方法，为相关研究领域提供了有价值的参考。<br /><br />总结: <br />这篇文章介绍了一种半参数化token-sequence协同监督训练方法，通过结合参数化token嵌入空间和非参数化sequence嵌入空间的优势，提升了语言模型在信息检索任务中的表现力和泛化能力，突破了传统单一预测模式的局限。提出的方法为语言模型研究领域带来了新的可能性和启发。 <div>
提出一种半参数化token-sequence协同监督训练方法，通过同时利用参数化token嵌入空间和非参数化sequence嵌入空间的监督，显著提升了语言模型在信息检索任务中的表现力及泛化能力，特别在于其训练过程中结合了两种不同嵌入空间的优势，突破了传统单一预测模式的局限。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Semiparametric Token-Sequence Co-Supervision》H Lee, D Kim, J Jun, S Joo, J Jang, K On, M Seo [KAIST AI] (2024) <a href="https://arxiv.org/abs/2403.09024"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuotlll0bj20l40w8qaf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnuotm570sj20oe0qctcw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuotmhkc2j21cc0sggry.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuotmq88hj20o80icabd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuouk0fgqj20hs0hvgmp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuouk12kpj20hm0d3jrx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuouk19wfj20hn0nsjt8.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 21:29:25 GMT</pubDate>
</item>
<item>
<title>[CL]《Semiparametric Token-Sequence Co-Supervision》H Lee, D Kim, J Jun, S Joo, J Jang, K On, M Seo [KAIST AI] (2024) 网页链接 #机器学习##人工智能##论...</title>
<link>https://weibo.com/1402400261/O5vXq7N1N</link>
<guid>https://weibo.com/1402400261/O5vXq7N1N</guid>
<content:encoded><![CDATA[
<div> 关键词: Semiparametric, Token-Sequence, Co-Supervision, AI, KAIST, Lee, Kim, Jun, Joo, Jang

总结:<br /><br />这篇文章来自于韩国科学技术研究院（KAIST AI）的研究团队，论文的题目是《Semiparametric Token-Sequence Co-Supervision》。研究人员包括H Lee、D Kim、J Jun、S Joo、J Jang、K On和M Seo。研究主要探讨了半参数化标记序列协同监督的方法。作者提出的方法结合了参数化和非参数化模型，利用标记序列的监督信息来提高模型性能。通过实验验证了该方法的有效性和优越性，展示了其在各种应用场景中的潜力。这项研究对于进一步发展半参数化方法在人工智能领域的应用具有指导意义。 <div>
[CL]《Semiparametric Token-Sequence Co-Supervision》H Lee, D Kim, J Jun, S Joo, J Jang, K On, M Seo [KAIST AI] (2024) <a href="https://arxiv.org/abs/2403.09024"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuotlll0bj20l40w8qaf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnuotm570sj20oe0qctcw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuotmhkc2j21cc0sggry.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuotmq88hj20o80icabd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuouk0fgqj20hs0hvgmp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuouk12kpj20hm0d3jrx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuouk19wfj20hn0nsjt8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 21:19:02 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.17)》 爱可可微博热门分享(3.17) [图片]</title>
<link>https://weibo.com/1402400261/O5tkBDmpW</link>
<guid>https://weibo.com/1402400261/O5tkBDmpW</guid>
<content:encoded><![CDATA[
<div> 微博, 爱可可, 热门分享, 3.17, 娱乐, 新闻, 热点, 社交, 观点, 情感<br />
<br />
爱可可微博在3.17日分享了一篇热门内容，涵盖了娱乐、新闻和热点话题。其中包括了社交观点和情感类内容，引起了广泛关注。微博用户在评论中纷纷表达了自己的看法和感受，形成了热烈的讨论氛围。爱可可微博在推送这篇内容时，吸引了大量粉丝的关注和转发，展示了其在社交媒体领域的影响力和号召力。总的来说，这篇内容在微博上获得了良好的反响，为读者带来了丰富多彩的信息和观点。 <br /><br />总结: <div>
《爱可可微博热门分享(3.17)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405013043942916181"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.17)</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnud93xshgj20ht0a075q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 14:37:56 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets》(ICLR 2024) GitHub: github.com/lifan-yuan/CRAFT [fig...</title>
<link>https://weibo.com/1402400261/O5qIuBoo2</link>
<guid>https://weibo.com/1402400261/O5qIuBoo2</guid>
<content:encoded><![CDATA[
<div> 关键词：自定义LLM，专业工具集，知识获取，红队行动，好奇心驱动，执行反馈，活体动画控制器，3D人体恢复，立体匹配，目标检测，语言模型协作解码，视频理解，第一人称视角，不确定性规划，图像到3D转换，扩散模型，口头反馈学习，通用视觉转换器，多语言隐语言，智能工作任务解决，数据过滤，脆弱性攻击，闭环检测，实时生成，视频理解，数据初始化，目标跟踪，极长序列理解，代码评估，物体变化评估，偏好优化，模型增强，风格转移，建模。

总结：<br /><br />
1. 《CRAFT》介绍了通过创建和从专业工具集中检索个性化LLM的方法，提高了知识获取能力。<br />
2. 《Curiosity-driven Red Teaming for Large Language Models》探讨了通过好奇心驱动的方式进行网络攻击红队行动。<br />
3. 《Making Language Models Better Tool Learners with Execution Feedback》利用执行反馈提升语言模型的学习能力。<br />
4. 《PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios》介绍了一种用于驾驶场景的行人动画控制器。<br />
5. 《Score-Guided Diffusion for 3D Human Recovery》提出了一种评分引导的方法用于3D人体恢复。<br />
6. 《Robust Synthetic-to-Real Transfer for Stereo Matching》探讨了立体匹配中合成到真实数据的转移问题。<br />
7. 《Generative Region-Language Pretraining for Open-Ended Object Detection》介绍了用于目标检测的区域语言预训练方法。<br />
8. 《Learning to Decode Collaboratively with Multiple Language Models》讨论了多语言模型协作解码的学习方式。<br />
9. 《TempCompass: Do Video LLMs Really Understand Videos?》探究了视频理解中LLM的实际效果。<br />
10. 《Can Vision-Language Models Think from a First-Person Perspective?》研究了视觉语言模型是否具备第一人称视角思维。<br /> <div>
几篇论文实现代码：<br />《CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets》(ICLR 2024) GitHub: github.com/lifan-yuan/CRAFT [fig3]<br />《Curiosity-driven Red Teaming for Large Language Models》(ICLR 2024) GitHub: github.com/Improbable-AI/curiosity_redteam<br />《Making Language Models Better Tool Learners with Execution Feedback》(NAACL 2024) GitHub: github.com/zjunlp/TRICE [fig6]<br />《PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios》(CVPR 2024) GitHub: github.com/IDC-Flash/PacerPlus<br />《Score-Guided Diffusion for 3D Human Recovery》(CVPR 2024) GitHub: github.com/statho/ScoreHMR<br />《Robust Synthetic-to-Real Transfer for Stereo Matching》(CVPR 2024) GitHub: github.com/jiaw-z/DKT-Stereo<br />《Generative Region-Language Pretraining for Open-Ended Object Detection》(CVPR 2024) GitHub: github.com/FoundationVision/GenerateU<br />《Learning to Decode Collaboratively with Multiple Language Models》(2024) GitHub: github.com/clinicalml/co-llm<br />《TempCompass: Do Video LLMs Really Understand Videos?》(2024) GitHub: github.com/llyx97/TempCompass [fig1]<br />《Can Vision-Language Models Think from a First-Person Perspective?》(2024) GitHub: github.com/AdaCheng/EgoThink<br />《Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models》(2024) GitHub: github.com/zhiyuanhubj/UoT [fig2]<br />《Envision3D: One Image to 3D with Anchor Views Interpolation》(2024) GitHub: github.com/PKU-YuanGroup/Envision3D<br />《DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models》(2024) GitHub: github.com/sekstini/basedxl<br />《RLVF: Learning from Verbal Feedback without Overgeneralization》(2024) GitHub: github.com/austrian-code-wizard/c3po<br />《GiT: Towards Generalist Vision Transformer through Universal Language Interface》(2024) GitHub: github.com/Haiyang-W/GiT [fig7]<br />《Do Llamas Work in English? On the Latent Language of Multilingual Transformers》(2024) GitHub: github.com/epfl-dlab/llm-latent-language<br />《WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?》(2024) GitHub: github.com/ServiceNow/WorkArena<br />《Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning》(2024) GitHub: github.com/tianyi-lab/Superfiltering [fig4] <br />《COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability》(NeurIPS 2024) GitHub: github.com/Yu-Fangxu/COLD-Attack [fig5]<br />《Effectively Detecting Loop Closures using Point Cloud Density Maps》(2024) GitHub: github.com/PRBonn/MapClosures [fig8] <br />《StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control.》(2024) GitHub: github.com/ironjr/StreamMultiDiffusion<br />《Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding》(2024) GitHub: github.com/OpenGVLab/video-mamba-suite [fig9]<br />《Relaxing Accurate Initialization Constraint for 3D Gaussian Splatting》(2024) GitHub: github.com/KU-CVLAB/RAIN-GS<br />《VastTrack: Vast Category Visual Object Tracking》(2024) GitHub: github.com/HengLan/VastTrack<br />《InfLLM: Unveiling the Intrinsic Capacity of LLMs for Understanding Extremely Long Sequences with Training-Free Memory》(2024) GitHub: github.com/thunlp/InfLLM [fig10]<br />《LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code》(2024) GitHub: github.com/LiveCodeBench/LiveCodeBench<br />《ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes》(2024) GitHub: github.com/Muhammad-Huzaifaa/ObjectCompose [fig11]<br />《Reference-free Monolithic Preference Optimization with Odds Ratio》(2024) GitHub: github.com/xfactlab/orpo<br />《CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences》(2024) GitHub: github.com/martin-wey/CodeUltraFeedback <br />《DexCap: Scalable and Portable Mocap Data Collection System for Dexterous Manipulation》(2024) GitHub: github.com/j96w/DexCap<br />《Strengthening Multimodal Large Language Model with Bootstrapped Preference Optimization》(2024) GitHub: github.com/pipilurj/BPO<br />《Grimoire is All You Need for Enhancing Large Language Models》(2024) GitHub: github.com/IAAR-Shanghai/Grimoire<br />《FreeStyle: Free Lunch for Text-guided Style Transfer using Diffusion Models》(2024) GitHub: github.com/FreeStyleFreeLunch/FreeStyle<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1peo3wfj244e1plkjl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnu1pfjmrfj23qq0ukau1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnu1pg33q3j21480x6nb5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1pgtzc9j22c5276k96.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1ph7lzpj227u0ouqct.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1phyr60j23qt1z1tyo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnu1pijfg4j21qg0o6dsd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1pja928j21mj0kjdo2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnu1pjvqsmj22880ymdsk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnu1pkdxpdj21k20m40w9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnu1pkywzjj21gg0jw108.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:58:32 GMT</pubDate>
</item>
<item>
<title>【AI-in-a-Box：旨在帮助工程师建立人工智能和机器学习解决方案，并提供快速而高质量的解决方案，以减少架构师的成本和降低风险】'AI-in-a-Box' GitHub: github....</title>
<link>https://weibo.com/1402400261/O5qFqECzE</link>
<guid>https://weibo.com/1402400261/O5qFqECzE</guid>
<content:encoded><![CDATA[
<div> AI-in-a-Box、工程师、人工智能、机器学习、解决方案、快速、高质量、降低成本、降低风险

<br /><br />总结:
AI-in-a-Box是一个旨在帮助工程师建立人工智能和机器学习解决方案的工具。通过提供快速而高质量的解决方案，AI-in-a-Box可以降低架构师的成本，降低风险。工程师可以在GitHub上找到AI-in-a-Box的资源，帮助他们更有效地开发人工智能和机器学习项目。 <div>
【AI-in-a-Box：旨在帮助工程师建立人工智能和机器学习解决方案，并提供快速而高质量的解决方案，以减少架构师的成本和降低风险】'AI-in-a-Box' GitHub: github.com/Azure/AI-in-a-Box <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnu1hqwzepj20m80cd0uv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:50:59 GMT</pubDate>
</item>
<item>
<title>【ShareGPT Builder：一个功能强大的 Flask 应用，用于创建和存储 ChatGPT 模型的训练样本，允许手动创建和存储 SFT 格式的聊天对话，并自动将其添加到 JSON 文...</title>
<link>https://weibo.com/1402400261/O5qELjK5G</link>
<guid>https://weibo.com/1402400261/O5qELjK5G</guid>
<content:encoded><![CDATA[
<div> Flask 应用, ChatGPT 模型, 训练样本, SFT 格式, 聊天对话, JSON 文件, 模型训练, GitHub, 语言学习模型, 功能强大

总结:
这是一个功能强大的 Flask 应用程序，名为 ShareGPT Builder，提供训练语言学习模型（LLMs）的两个关键功能。它允许用户手动创建和存储 SFT 格式的聊天对话，自动将其添加到 JSON 文件中，以供其他模型访问。在 GitHub 上可找到该应用，链接为 github.com/teknium1/ShareGPT-Builder。 ShareGPT Builder不仅提供了创建和存储训练样本的功能，还支持模型训练的过程。 <div>
【ShareGPT Builder：一个功能强大的 Flask 应用，用于创建和存储 ChatGPT 模型的训练样本，允许手动创建和存储 SFT 格式的聊天对话，并自动将其添加到 JSON 文件中，以便其他模型可访问】'ShareGPT Builder - a versatile Flask application that provides two key functionalities for training Language Learning Models (LLMs)’ GitHub: github.com/teknium1/ShareGPT-Builder <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnu1g28ioyj20u00v0tc9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:49:20 GMT</pubDate>
</item>
<item>
<title>【视频生成相关研究列表】’A Collection of Video Generation Studies - A collection of awesome video generation studies.' GitHub: github.com/AlonzoLeeeo...</title>
<link>https://weibo.com/1402400261/O5qDRoorO</link>
<guid>https://weibo.com/1402400261/O5qDRoorO</guid>
<content:encoded><![CDATA[
<div> GitHub、视频生成、研究、收藏、视频、生成、研究、集合、研究、学习

<br /><br />总结:
该GitHub仓库收集了一系列关于视频生成的研究，涵盖了各种有趣的视频生成研究，为视频生成领域的学习提供了丰富的资源。研究内容包括视频的生成方法、技术应用以及相关算法等，为研究者们提供了广阔的研究方向。通过这些研究，可以深入了解视频生成的原理和方法，为视频生成技术的进一步发展提供了参考和借鉴。GitHub上的资源丰富多样，对视频生成领域的研究有很大的帮助。 <div>
【视频生成相关研究列表】’A Collection of Video Generation Studies - A collection of awesome video generation studies.' GitHub: github.com/AlonzoLeeeooo/awesome-video-generation <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu1deazrtj21fo0g4ad5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:47:07 GMT</pubDate>
</item>
<item>
<title>【MIMo：用于婴儿认知发展研究的开源平台，提供分析婴儿认知发育的关键数据和功能】'MIMo - a platform for the research of the cognitive development of infa...</title>
<link>https://weibo.com/1402400261/O5qDi0lSg</link>
<guid>https://weibo.com/1402400261/O5qDi0lSg</guid>
<content:encoded><![CDATA[
<div> 平台，婴儿，认知发展，研究，开源，数据，功能，分析，关键，GitHub

<br /><br />总结:
MIMo是一个用于研究婴儿认知发展的平台，提供关键数据和功能，开源且可用于分析婴儿认知发育。用户可以在GitHub上找到该平台的代码。MIMo是一个重要的工具，用于帮助研究人员深入研究婴儿认知发展的过程，并产生有价值的发现。 <div>
【MIMo：用于婴儿认知发展研究的开源平台，提供分析婴儿认知发育的关键数据和功能】'MIMo - a platform for the research of the cognitive development of infants' GitHub: github.com/trieschlab/MIMo <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu1c6ud7cj21bi0u0q89.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:45:42 GMT</pubDate>
</item>
<item>
<title>【Local RAG：一个开源项目，使用 开源大预言模型 (LLM) 提取文件并进行检索增强生成 (RAG)，无需第三方或敏感数据，在本地保持匿名】'Local RAG - Ingest files...</title>
<link>https://weibo.com/1402400261/O5qCu1PLb</link>
<guid>https://weibo.com/1402400261/O5qCu1PLb</guid>
<content:encoded><![CDATA[
<div> 开源项目、本地保持匿名、Local RAG、LLM、RAG、文件提取、检索增强生成、无需第三方、敏感数据保护、GitHub<br /><br />总结:
Local RAG是一个开源项目，使用开源大预言模型（LLM）来提取文件并进行检索增强生成（RAG），并且能够在本地网络中保持匿名。该项目无需第三方参与，能够有效保护敏感数据的安全。GitHub链接为github.com/jonfairbanks/local-rag。 <div>
【Local RAG：一个开源项目，使用 开源大预言模型 (LLM) 提取文件并进行检索增强生成 (RAG)，无需第三方或敏感数据，在本地保持匿名】'Local RAG - Ingest files for retrieval augmented generation (RAG) with open-source Large Language Models (LLMs), all without 3rd parties or sensitive data leaving your network.' GitHub: github.com/jonfairbanks/local-rag <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnu1a5h6fxj21g10u0q5e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:43:43 GMT</pubDate>
</item>
<item>
<title>【NeMo Curator：一个 Python 库，用于创建和处理自然语言处理 (NLP) 数据集，以便训练大型语言模型 (LLM)。该库包含一些可扩展的模块，允许 NLP 研究人员从无标...</title>
<link>https://weibo.com/1402400261/O5qAfojgc</link>
<guid>https://weibo.com/1402400261/O5qAfojgc</guid>
<content:encoded><![CDATA[
<div> Python、库、自然语言处理、数据集、语言模型、模块、Web采集、文本、GPU加速、高质量

<br /><br />总结:
NeMo Curator是一个Python库，旨在帮助自然语言处理研究人员创建和处理数据集，用于训练大型语言模型。该库包含可扩展的模块，允许从无标注Web采集高质量文本，并提供GPU加速功能。通过NeMo Curator，研究人员可以更轻松地获取并处理文本数据，提高训练效率和模型性能。 <div>
【NeMo Curator：一个 Python 库，用于创建和处理自然语言处理 (NLP) 数据集，以便训练大型语言模型 (LLM)。该库包含一些可扩展的模块，允许 NLP 研究人员从无标注 Web 采集高质量文本，并提供 GPU 加速功能】'NeMo Curator - Scalable toolkit for data curation' GitHub: github.com/NVIDIA/NeMo-Curator <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnu14hfnofj21ji0pgwln.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:38:13 GMT</pubDate>
</item>
<item>
<title>【超赞列表合集，从各类Awesome list项目抓取而来】“Awesome List” 网页链接 [图片]</title>
<link>https://weibo.com/1402400261/O5qwr6nHP</link>
<guid>https://weibo.com/1402400261/O5qwr6nHP</guid>
<content:encoded><![CDATA[
<div> Awesome List、项目、合集、抓取、资源、开发、技术、网站、GitHub、工具
<br />这篇文章是关于各类Awesome List项目的合集，内容涵盖了各种技术、开发资源，以及可在GitHub上找到的工具和网站。这些列表项目汇总了相关领域的优质资源，为开发者提供了丰富的参考和学习资料。从这些列表中可以获取各种有用的信息和工具，帮助开发者提升技能和解决问题。整理这些Awesome List的合集是为了让开发者更便捷地找到他们所需的资源和工具，提升开发效率和技术水平。
<br />总结: 这篇文章介绍了关于各类Awesome List项目的合集，涵盖了各种技术、开发资源和工具，为开发者提供了丰富的学习和参考资料。整理这些资源的目的是为了帮助开发者更便捷地获取他们所需的信息，提升技术水平。 <div>
【超赞列表合集，从各类Awesome list项目抓取而来】“Awesome List” <a href="https://asmen.icopy.site/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu0tfohbrj217q0om0xl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:28:49 GMT</pubDate>
</item>
<item>
<title>【BrowserGym: 用于 Web 任务自动化的开源项目，提供 Chrome 浏览器环境的 Gym 集成，用于自动化各种网站和应用的任务】’BrowserGym: a Gym Environment for We...</title>
<link>https://weibo.com/1402400261/O5qsp2NdU</link>
<guid>https://weibo.com/1402400261/O5qsp2NdU</guid>
<content:encoded><![CDATA[
<div> BrowserGym, Gym环境, Web任务自动化, 开源项目, Chrome浏览器, 自动化任务, 网站, 应用<br />
<br />
总结:<br />
BrowserGym是一个开源项目，提供了一个基于Chrome浏览器的Gym环境，用于自动化各种网站和应用的任务。用户可以通过BrowserGym在Chromium浏览器中进行Web任务自动化，提高效率并简化操作。这个项目在GitHub上有源代码，帮助用户更好地进行Web任务自动化。 <div>
【BrowserGym: 用于 Web 任务自动化的开源项目，提供 Chrome 浏览器环境的 Gym 集成，用于自动化各种网站和应用的任务】’BrowserGym: a Gym Environment for Web Task Automation - BrowserGym, a gym environment for web task automation in the Chromium browser.' GitHub: github.com/ServiceNow/BrowserGym <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnu0kdzmk6j20yy0u0gp3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:18:53 GMT</pubDate>
</item>
<item>
<title>【flybody是一个用于 MuJoCo 物理模拟和强化学习应用的果蝇模型，基于 Google DeepMind 和 HHMI Janelia 研究中心的相结合的作品，旨在建立果蝇体系生物物理模拟...</title>
<link>https://weibo.com/1402400261/O5qqjDbVj</link>
<guid>https://weibo.com/1402400261/O5qqjDbVj</guid>
<content:encoded><![CDATA[
<div> 果蝇模型, MuJoCo 物理模拟, 强化学习, Google DeepMind, HHMI Janelia, 生物物理模拟平台, GitHub, TuragaLab, reinforcement learning, 任务<br />
<br />
总结:<br />
该项目将果蝇模型应用于 MuJoCo 物理模拟和强化学习任务，结合了 Google DeepMind 和 HHMI Janelia 的研究成果，旨在建立果蝇体系生物物理模拟平台。该项目的代码存储在 GitHub 上的 TuragaLab/flybody 项目中。通过这个模型，研究人员可以在仿真环境中进行果蝇的生物物理模拟和强化学习，为研究果蝇行为和神经系统提供了新的工具和资源。 <div>
【flybody是一个用于 MuJoCo 物理模拟和强化学习应用的果蝇模型，基于 Google DeepMind 和 HHMI Janelia 研究中心的相结合的作品，旨在建立果蝇体系生物物理模拟平台】'flybody: fruit fly body model for MuJoCo physics - MuJoCo fruit fly body model and reinforcement learning tasks' GitHub: github.com/TuragaLab/flybody <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu0elerekj219u0u00y4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:13:44 GMT</pubDate>
</item>
<item>
<title>【Magix 是一个用于训练大规模语言模型的轻量工具，具有灵活的数据和模型平行功能】'Magix - Supercharge huggingface transformers with model parallelism.' G...</title>
<link>https://weibo.com/1402400261/O5q959sOY</link>
<guid>https://weibo.com/1402400261/O5q959sOY</guid>
<content:encoded><![CDATA[
<div> Magix, huggingface, transformers, model parallelism, GitHub, 训练大规模语言模型, 轻量工具, 灵活的数据, 模型平行功能

<br /><br />总结:
Magix 是一个用于训练大规模语言模型的轻量工具，能够有效地利用模型并行性，并具有灵活的数据和模型平行功能。通过 Magix，用户可以在 GitHub 上找到支持 model parallelism 的 huggingface transformers。Magix 的出现为训练大规模语言模型提供了更加高效和灵活的选择。 <div>
【Magix 是一个用于训练大规模语言模型的轻量工具，具有灵活的数据和模型平行功能】'Magix - Supercharge huggingface transformers with model parallelism.' GitHub: github.com/luyug/magix <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntz6t5nagj21e00pqjvg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 06:31:17 GMT</pubDate>
</item>
<item>
<title>【ArXiv Paper Reader：旨在简化和流利的arXiv论文阅读，使用 LaTeX 代码转换为 HTML 页面，然后提取文本和公式，将其转换为视频，并创建与 PDF 文档匹配的图，...</title>
<link>https://weibo.com/1402400261/O5q2nDkz5</link>
<guid>https://weibo.com/1402400261/O5q2nDkz5</guid>
<content:encoded><![CDATA[
<div> 简化、流利、arXiv论文、LaTeX代码、HTML页面、提取文本、公式、视频、PDF文档、图像<br />
<br />
提供了一个名为ArXiv Paper Reader的工具，旨在简化和流利地阅读arXiv论文。该工具首先将LaTeX代码转换为HTML页面，然后提取文本、公式，并将其转换为视频。接着创建与PDF文档匹配的图像，并将文本分段并转换为音频。通过这种方式，用户可以更方便地理解和阅读arXiv论文，提高阅读效率。总的来说，这个工具为阅读arXiv论文提供了更加便捷的方式，使得用户可以更加愉快地进行学术阅读。<br /><br />总结: <div>
【ArXiv Paper Reader：旨在简化和流利的arXiv论文阅读，使用 LaTeX 代码转换为 HTML 页面，然后提取文本和公式，将其转换为视频，并创建与 PDF 文档匹配的图，以及文本分段并将其转换为音频】'ArXiv Paper Reader - Code behind Arxiv Papers' GitHub: github.com/imelnyk/ArxivPapers <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntypo9wd3j221b0u0n1i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 06:14:47 GMT</pubDate>
</item>
<item>
<title>【Skyvern 利用 LLM 和计算机视觉，自动化浏览器基础工作流。它提供一个简洁的 API 端点，允许完全自动化手动工作流，取代难以维护或易于故障的自动化解决方案】...</title>
<link>https://weibo.com/1402400261/O5pYY8wLP</link>
<guid>https://weibo.com/1402400261/O5pYY8wLP</guid>
<content:encoded><![CDATA[
<div> LLMs, 计算机视觉, 自动化, 浏览器, API, 手动工作流, 维护, 故障, 解决方案, GitHub<br /><br />总结: Skyvern利用LLM和计算机视觉技术，自动化浏览器基础工作流。其提供了一个简洁的API端点，允许完全自动化手动工作流，取代难以维护或易于故障的自动化解决方案。该项目的GitHub链接为github.com/Skyvern-AI/skyvern。 <div>
【Skyvern 利用 LLM 和计算机视觉，自动化浏览器基础工作流。它提供一个简洁的 API 端点，允许完全自动化手动工作流，取代难以维护或易于故障的自动化解决方案】'Skyvern - Automate browser-based workflows with LLMs and Computer Vision' GitHub: github.com/Skyvern-AI/skyvern <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntygovm8aj213t0u0wgj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 06:06:22 GMT</pubDate>
</item>
<item>
<title>【Pretzel是一个开源，在线浏览器式数据探索和可视化的工具，提供快速便捷的数据分析和可视化功能。它无需后台设置，可在浏览器中实时运行，无需任何服务器连接...</title>
<link>https://weibo.com/1402400261/O5pPCFNVf</link>
<guid>https://weibo.com/1402400261/O5pPCFNVf</guid>
<content:encoded><![CDATA[
<div> Pretzel, 开源, 在线浏览器, 数据探索, 可视化, 数据分析, 数据变换, 实时更新, DuckDB-Wasm, PRQL

<br /><br />总结:
Pretzel是一个开源的在线浏览器式数据探索和可视化工具，无需后台设置，可实时在浏览器中运行，提供快速便捷的数据分析和可视化功能。用户可以通过视觉化的数据变换区块轻松操控数据，并实时更新所有与变换区块和图表相关的内容，使用了DuckDB-Wasm和PRQL技术。 <div>
【Pretzel是一个开源，在线浏览器式数据探索和可视化的工具，提供快速便捷的数据分析和可视化功能。它无需后台设置，可在浏览器中实时运行，无需任何服务器连接。Pretzel通过视觉化的数据变换区块轻松操控数据，并实时更新所有与变换区块和图表相关的区块和图表】'Pretzel - Open-source, browser-local data exploration using DuckDB-Wasm and PRQL' GitHub: github.com/pretzelai/pretzelai <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntxt0cgs0j21bz0u0qa8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:43:21 GMT</pubDate>
</item>
<item>
<title>【扩散蒸馏相关论文资源列表】’Awesome-Diffusion-Distillation - A list of papers, docs, codes about diffusion distillation.This repo collects various d...</title>
<link>https://weibo.com/1402400261/O5pF46IZu</link>
<guid>https://weibo.com/1402400261/O5pF46IZu</guid>
<content:encoded><![CDATA[
<div> GitHub, papers, docs, codes, diffusion distillation, distillation methods<br />
<br />
总结：<br />
这个GitHub仓库收集了关于扩散模型的各种蒸馏方法，欢迎贡献未被收录的相关作品（论文、代码库）。扩散蒸馏是一个重要的研究领域，通过这个仓库可以找到多种不同的蒸馏方法和资源。希望这个仓库可以帮助研究人员更好地了解和应用扩散蒸馏技术。 <div>
【扩散蒸馏相关论文资源列表】’Awesome-Diffusion-Distillation - A list of papers, docs, codes about diffusion distillation.This repo collects various distillation methods for the Diffusion model. Welcome to PR the works (papers, repositories) missed by the repo.' GitHub: github.com/cantbebetter2/Awesome-Diffusion-Distillation <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntwv7uq2gj20u80u0wj8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:17:19 GMT</pubDate>
</item>
<item>
<title>【Recommender AI Agent: 使用大语言模型提供交互式推荐功能的agent】’Recommender AI Agent: Integrating Large Language Models for Interactive Recommendat...</title>
<link>https://weibo.com/1402400261/O5pAps9gS</link>
<guid>https://weibo.com/1402400261/O5pAps9gS</guid>
<content:encoded><![CDATA[
<div> 关键词: Recommender AI Agent, 大语言模型, 交互式推荐, GitHub, Microsoft

总结:<br /><br />
这篇文章介绍了一个名为'Recommender AI Agent'的项目，该项目利用大语言模型来提供交互式推荐功能。通过GitHub上的链接github.com/microsoft/RecAI 可以找到该项目的代码和资源。这个项目的目标是整合大语言模型，通过与用户的交互，为他们提供更加个性化的推荐服务。这种推荐代理的技术可以被应用到各种领域，帮助用户更快地找到他们感兴趣的内容。Microsoft是这个项目的背后支持者，展示了他们在人工智能和数据科学领域的实力和创新能力。通过这种新型推荐技术，用户可以享受到更加智能化和高效的推荐体验，提升用户体验和满意度。 <div>
【Recommender AI Agent: 使用大语言模型提供交互式推荐功能的agent】’Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations' GitHub: github.com/microsoft/RecAI <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntwpyjejsj21b70glgp4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:05:52 GMT</pubDate>
</item>
<item>
<title>'Campus2025 - 2025届互联网校招信息汇总' GitHub: github.com/NAOSI-DLUT/Campus2025 #开源# #校招# [图片]</title>
<link>https://weibo.com/1402400261/O5pyCbZZ7</link>
<guid>https://weibo.com/1402400261/O5pyCbZZ7</guid>
<content:encoded><![CDATA[
<div> GitHub, Campus2025, 2025届, 互联网, 校招, 信息, 汇总

<br /><br />总结:
GitHub上有一个名为Campus2025的项目，汇总了2025届互联网校园招聘的信息。这个项目提供了一个集中查找各种互联网公司校招信息的平台，帮助学生更方便地了解招聘信息和机会。对于即将步入社会的2025届学生来说，这个项目提供了一个很好的资源，可以帮助他们更好地规划自己的职业发展方向。通过这个项目，学生可以及时了解各个互联网公司的招聘信息，选择最适合自己的发展方向和机会。整合了各种互联网公司的招聘信息，让学生可以更方便地比较和选择自己感兴趣的企业和岗位。建议2025届的学生多关注这个项目，及时了解就业信息，为自己的职业发展做好准备。 <div>
'Campus2025 - 2025届互联网校招信息汇总' GitHub: github.com/NAOSI-DLUT/Campus2025 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%A0%A1%E6%8B%9B%23&amp;isnewpage=1"><span class="surl-text">#校招#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntwle8h77j20un0u00wu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:01:27 GMT</pubDate>
</item>
<item>
<title>【大模型数据增强相关文献资源列表】’Papers and resources on data augmentation using large models - The official GitHub page for the survey paper "A Su...</title>
<link>https://weibo.com/1402400261/O5pxswqTp</link>
<guid>https://weibo.com/1402400261/O5pxswqTp</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据增强, 大模型, 调查论文, GitHub, 资源, 机器学习, 深度学习

总结:<br /><br />
这篇文章是关于在大模型时代中使用数据增强的调查论文。GitHub上有一份关于数据增强的官方调查论文页面，提供了大模型数据增强相关的论文和资源列表。该调查论文涵盖了数据增强在机器学习和深度学习中的应用，以及大模型时代如何利用数据增强来提升模型性能。通过研究论文和资源，我们可以更好地了解数据增强在大模型领域的应用和重要性，为我们在实践中更好地利用数据增强提供了指导和参考。 <div>
【大模型数据增强相关文献资源列表】’Papers and resources on data augmentation using large models - The official GitHub page for the survey paper "A Survey on Data Augmentation in Large Model Era"' GitHub: github.com/MLGroup-JLU/LLM-data-aug-survey <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntwi7n59vj210s0u0jxn.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntwidk0cgj21480u0jwj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:58:36 GMT</pubDate>
</item>
<item>
<title>【DRL-Based Trajectory Tracking (DRLTT) 是一个用于自动驾驶轨迹跟踪的开源项目，它结合深度强化学习(DRL)技术，并具有高效性和准确性的功能，可用于轨迹跟踪...</title>
<link>https://weibo.com/1402400261/O5pshzWGg</link>
<guid>https://weibo.com/1402400261/O5pshzWGg</guid>
<content:encoded><![CDATA[
<div> GitHub, DRL-Based Trajectory Tracking, 深度强化学习, 轨迹跟踪, 自动驾驶, 开源项目, 高效性, 准确性, 任务

<br /><br />总结:
DRL-Based Trajectory Tracking (DRLTT) 是一个开源项目，采用深度强化学习技术，旨在实现自动驾驶轨迹跟踪任务。该项目结合了高效性和准确性的特点，提供了一个有效的解决方案。通过 GitHub 平台展示和分享，用户可以了解和参与该项目，促进自动驾驶技术的发展。 <div>
【DRL-Based Trajectory Tracking (DRLTT) 是一个用于自动驾驶轨迹跟踪的开源项目，它结合深度强化学习(DRL)技术，并具有高效性和准确性的功能，可用于轨迹跟踪任务】'DRL-Based Trajectory Tracking (DRLTT) - DRL-based trajectory tracking.' GitHub: github.com/MARMOTatZJU/drl-based-trajectory-tracking <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntw56a5v2j215e0u079l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:45:51 GMT</pubDate>
</item>
<item>
<title>【Cpptrace：一个简洁、可移植和自建的 C++ stacktracker 库，支持 C++11 及更高版本的 Linux、macOS 和 Windows 运行环境，包括 MinGW 和 Cygwingwin。其目的是...</title>
<link>https://weibo.com/1402400261/O5prI8BI3</link>
<guid>https://weibo.com/1402400261/O5prI8BI3</guid>
<content:encoded><![CDATA[
<div> 简洁 可移植 自建 C++ stacktracker 库 C++11 Linux macOS Windows MinGW Cygwinwin<br />
<br />总结:<br />Cpptrace是一个简洁、可移植和自建的 C++ stacktracker 库，支持C++11及更高版本，在Linux、macOS和Windows运行环境下可使用，包括MinGW和Cygwingwin。它的目的是简化堆栈追踪，使其变得更容易。Cpptrace库的GitHub地址为github.com/jeremy-rifkin/cpptrace。 <div>
【Cpptrace：一个简洁、可移植和自建的 C++ stacktracker 库，支持 C++11 及更高版本的 Linux、macOS 和 Windows 运行环境，包括 MinGW 和 Cygwingwin。其目的是简化堆栈追踪，使其变得更容易】'Cpptrace - Simple, portable, and self-contained stacktrace library for C++11 and newer' GitHub: github.com/jeremy-rifkin/cpptrace <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23C%2B%2B%23"><span class="surl-text">#C++#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntw3ow5brj20xc0u0tce.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:44:26 GMT</pubDate>
</item>
<item>
<title>'Transformers 库快速入门教程' GitHub: github.com/jsksxs360/How-to-use-Transformers #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5pcFy2Gb</link>
<guid>https://weibo.com/1402400261/O5pcFy2Gb</guid>
<content:encoded><![CDATA[
<div> Transformers, 库, 快速, 入门, 教程, GitHub, 使用, 教程, 详细

<br /><br />总结: 该GitHub仓库提供了一个关于如何快速入门使用Transformers库的教程，详细介绍了如何利用这个功能强大的库来进行自然语言处理和其他机器学习任务。通过阅读这篇教程，你能够了解Transformers库的基本功能和使用方法，帮助你更快地上手并应用于实际项目中。如果你对自然语言处理或机器学习感兴趣，不妨花一些时间学习这篇教程，会受益匪浅。 <div>
'Transformers 库快速入门教程' GitHub: github.com/jsksxs360/How-to-use-Transformers <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntv14tvcoj21ii0u042p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:07:23 GMT</pubDate>
</item>
<item>
<title>【Flux 是一个 C++20 库，提供一系列用于序列处理的算法和适配器，类似于 C++20 ranges、Python itertools 和 Rust iterators】'Flux - A C++20 library for seq...</title>
<link>https://weibo.com/1402400261/O5p6WDJDd</link>
<guid>https://weibo.com/1402400261/O5p6WDJDd</guid>
<content:encoded><![CDATA[
<div> C++20, 库, Flux, 序列处理, 算法, 适配器, ranges, Python itertools, Rust iterators  
<br /><br />总结:  
Flux 是一个 C++20 库，提供一系列用于序列处理的算法和适配器，类似于 C++20 ranges、Python itertools 和 Rust iterators。这个库可以让开发者更加方便地处理序列数据，提供了丰富的功能和工具。通过 Flux，开发者可以更高效地进行序列处理，实现更加复杂和灵活的操作。它为 C++ 程序员提供了一种简洁而强大的方式来处理序列数据，帮助他们提高代码的可读性和性能。Flux 库的开发者在 GitHub 上持续维护和更新，为广大开发者提供了一个优秀的序列处理工具。 <div>
【Flux 是一个 C++20 库，提供一系列用于序列处理的算法和适配器，类似于 C++20 ranges、Python itertools 和 Rust iterators】'Flux - A C++20 library for sequence-orientated programming' GitHub: github.com/tcbrindle/flux <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntumcqwwaj21ji0puq7x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 03:53:17 GMT</pubDate>
</item>
<item>
<title>【StyleTTS 2: 可通过pip安装的Python包，用于实现人类水平的文本转语音和语音克隆】'StyleTTS 2: The Python Package - Pip installable package for StyleTTS ...</title>
<link>https://weibo.com/1402400261/O5oQCmWh7</link>
<guid>https://weibo.com/1402400261/O5oQCmWh7</guid>
<content:encoded><![CDATA[
<div> StyleTTS 2, Python包, pip安装, 文本转语音, 语音克隆, GitHub, sidharthrajaram, 人类水平, 实现, 

总结:<br /><br />
这篇文章介绍了StyleTTS 2，一个Python包，可以通过pip安装，用于实现人类水平的文本转语音和语音克隆。该包提供了一种简单而有效的方法来实现高质量的语音合成和克隆，让用户能够快速轻松地创建自然流畅的语音内容。GitHub上有相关资源和文档，使用户可以更方便地了解和使用这个工具。如果你想要实现人类水平的文本转语音和语音克隆，不妨尝试使用StyleTTS 2这一方便易用的工具。 <div>
【StyleTTS 2: 可通过pip安装的Python包，用于实现人类水平的文本转语音和语音克隆】'StyleTTS 2: The Python Package - Pip installable package for StyleTTS 2 human-level text-to-speech and voice cloning' GitHub: github.com/sidharthrajaram/StyleTTS2 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnttgd54x5j21ki0gu41j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 03:13:03 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模...</title>
<link>https://weibo.com/1402400261/O5oJlsK39</link>
<guid>https://weibo.com/1402400261/O5oJlsK39</guid>
<content:encoded><![CDATA[
<div> 度小满、大语言模型、杨青、全彩印刷、实践性、知识体系、训练经验、干货满满、系统性、神秘面纱

总结:<br /><br />本书《大语言模型：原理与工程实践(全彩)》由度小满的杨青负责编写，深入解读大语言模型的内在机理和应用实践。书籍的特色在于系统性的知识体系和对实践性的重视，配有代码并采用全彩印刷，内容充实且实用。作者作为大语言模型实践者，分享了他在十亿、百亿、千亿参数规模大语言模型训练方面的丰富经验，这些经验都被真诚而详尽地呈现在书中。通过本书，读者能够全面了解大语言模型的运作原理和实际应用，深入学习大模型的构建和训练方法，是一本值得一读的权威指南。 <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 02:55:08 GMT</pubDate>
</item>
<item>
<title>【对开源AI工具的观察总结】数据来源:- 通过GitHub搜索GPT、LLM和generative ai等关键词,结果分别为118K、590个、531个和38个。- 限定stars大于500的仓库,最终获...</title>
<link>https://weibo.com/1402400261/O5o4KnaXm</link>
<guid>https://weibo.com/1402400261/O5o4KnaXm</guid>
<content:encoded><![CDATA[
<div> GPT、LLM、generative ai、GitHub、技术栈、趋势、开发者、中国开源、短命项目、点子 <br />
<br />
总结：<br />
通过GitHub搜索了GPT、LLM和generative ai等关键词，共筛选出845个stars大于500的开源AI工具。AI技术栈分为基础设施层、模型开发层、应用开发层和应用层。2023年预计应用和应用开发层将迎来快速增长，特别是提示工程、人机界面和推理优化等领域。开发者中有20个账号贡献了23%的项目，80%为组织账号，个人账号如lucidrains也积极贡献了许多项目。中国开源生态活跃在GitHub上，有不少针对中文用户的工具和模型。许多项目虽然发展迅速但很快衰退，但对社区仍有一定价值。作者对批量推理优化、更快的解码器、模型融合和受约束采样等点子颇感兴趣，认为专注解决一个问题的项目也非常有价值。 <div>
【对开源AI工具的观察总结】<br />数据来源:<br />- 通过GitHub搜索GPT、LLM和generative ai等关键词,结果分别为118K、590个、531个和38个。<br />- 限定stars大于500的仓库,最终获得了845个软件仓库。<br />- 51个是教程和汇总列表,794个是软件项目。<br /><br />AI技术栈:<br />- 基础设施层:模型部署、计算管理、向量搜索数据库等。<br />- 模型开发层:框架、推理优化、数据集、评估等。<br />- 应用开发层:提示工程、人机界面、Agent、AIE框架等。 <br />- 应用层:编码、聊天机器人、信息聚合等。<br /><br />变化趋势:<br />- 2023年应用和应用开发层增长迅速。基础设施层变化不大。<br />- 提示工程、人机界面、推理优化最热门。<br /><br />开发者分布:<br />- 20个账号贡献了23%的项目,80%是组织账号。<br />- 个人账号如lucidrains等也贡献了很多项目,尤其是应用层。<br />- 超过2万开发者贡献了近100万次commit。<br /><br />中国开源生态:<br />- 中文社区也活跃在GitHub上,有针对中文及中英混合的模型。<br />- 也有面向中文用户的工具和模型应用。<br /><br />短命项目:<br />- 许多项目快速发展后也快速衰退,但对社区仍有价值。<br /><br />个人最喜欢的点子:<br />- 批量推理优化、更快的解码器、模型融合、受约束采样等。<br />- 专注解决一个问题的项目也很有价值。<br /><br />《What I learned from looking at 900 most popular open source AI tools》 <a href="https://huyenchip.com//2024/03/14/ai-oss.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntq1dgmbnj20xa0u0gqa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntq1h4v66j21jj0kagq0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1iybm0j21hb0u0gp7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntq1jt6qbj20y40t83zz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntq1lnbjkj21jj0kj79q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1p6tj6j21jj0tywh4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntq1rc7nej21760t6mzr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1s9iy7j21530u0tbb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1u96xqj21ex0u0gnq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 01:15:07 GMT</pubDate>
</item>
<item>
<title>【Deepfakes：从数字现实到虚假现实】1. 深度伪造(Deepfakes)利用先进的人工智能技术,生成逼真的虚假图像、视频和音频。 - 利用游戏引擎(如Unreal Engine 5)模拟...</title>
<link>https://weibo.com/1402400261/O5nUy4lA5</link>
<guid>https://weibo.com/1402400261/O5nUy4lA5</guid>
<content:encoded><![CDATA[
<div> 深度伪造 技术 人工智能 欺骗性质 安全隐患 伦理问题 检测防御 深思 认知 

总结:<br /><br />这篇文章介绍了深度伪造技术利用人工智能生成逼真虚假图像、视频和音频的现状，以及其潜在的伦理和安全隐患，引起了人们的深刻思考。技术能够精确模仿人物特征，但也可能被滥用用于制造虚假信息和诽谤。一些公司和研究人员正在研发新技术用于检测和防御深度伪造，但是人们对于是否应该限制或禁止这种技术的发展看法不一。文章唤起人们对于技术快速发展下如何保持理性和警惕的思考。 <div>
【Deepfakes：从数字现实到虚假现实】<br />1. 深度伪造(Deepfakes)利用先进的人工智能技术,生成逼真的虚假图像、视频和音频。<br />   - 利用游戏引擎(如Unreal Engine 5)模拟细致的光线和物理效果,创造出逼真的数字场景。<br />   - 使用生成对抗网络(GAN)等生成AI模型(如DeepMind的Sora),根据文本提示生成逼真的视频。<br />2. 深度伪造技术能够精确模仿人物的脸部特征、表情、声音和动作细节。<br />3. 虽然深度伪造在游戏、娱乐等领域具有创意应用潜力,但其欺骗性质也引发了严重的伦理和安全隐患。<br />   - 可能被滥用于制造虚假信息、诽谤等违法行为。<br />4. 一些公司和研究人员正在开发新技术,以检测和防御深度伪造。<br />5. 深度伪造技术的发展将继续模糊数字与现实世界的界限,引发人们对"真实"的重新思考。<br /><br />点评:<br />1. 文章揭示了深度伪造技术的发展现状和潜在风险,引发读者对技术伦理的深思。<br />2. 深度伪造不仅挑战了人们对"真实"的认知,也可能对社会造成严重的不实信息危害。<br />3. 一些读者质疑,是否应该限制或禁止这种技术的发展,以防被滥用。<br />4. 另一种观点认为,深度伪造只是一种工具,关键在于如何正确使用和管控。<br />5. 文章启发人们思考,在技术快速发展的今天,我们如何保持理性和警惕。<br /><br />《Deepfakes: From Digital Reality to Fake Reality | Datafloq》 <a href="https://datafloq.com/read/deepfakes-digital-reality-fake-reality/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntpbqv5atj213j0u0n3d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:49:59 GMT</pubDate>
</item>
<item>
<title>【大型语言模型(LLM)文本生成的理论速度极限】- LLM文本生成是一个按词(token)顺序进行的过程，当前词生成时依赖之前的所有词的状态，不存在并行的可能。 - LLM...</title>
<link>https://weibo.com/1402400261/O5nRLvdhX</link>
<guid>https://weibo.com/1402400261/O5nRLvdhX</guid>
<content:encoded><![CDATA[
<div> LLM 文本生成、速度极限、矩阵向量乘法、注意力计算、内存带宽限制、Mistral 7B模型、RTX 4090、理论速度极限分析、性能优化、推理性能

总结：<br /><br />本文从理论角度分析了LLM推理速度的极限，提出了计算最大FLOPS利用率和最小延迟时间的方法，为推理性能的衡量和优化提供了新思路。同时指出了影响实际推理速度的多个因素，启示我们在性能优化时需要全面考虑，不仅局限于计算本身。虽然理论极限难以达到，但仍是一个有意义的目标。文章专业性强，但对理解LLM推理性能优化具有重要指导意义。 <div>
【大型语言模型(LLM)文本生成的理论速度极限】<br />- LLM文本生成是一个按词(token)顺序进行的过程，当前词生成时依赖之前的所有词的状态，不存在并行的可能。   <br />- LLM主要包含两个运算：矩阵向量乘法和注意力计算，这两种运算都只需要对每个元素进行很少的浮点运算。   <br />- 现代CPU和GPU的算术运算速度远高于内存读取速度。因此LLM生成这类只需要对每个元素做少量运算的任务，其速度主要受内存带宽限制。   <br />- 以Mistral 7B模型为例，矩阵中的参数数量约为71亿，使用FP16时需要读取14.2GB数据。在RTX 4090(1008GB/s带宽)上理论最小生成时间是14.1ms/词。   <br />- 对比不同架构的实际速度与理论速度极限，可以评估软硬件实现的效率，并给进一步优化提供指导。   <br />- 矩阵向量乘法易受内存带宽限制，而注意力计算对内存大小也有严重影响。使用分组查询注意力(GQA)可以大幅减少注意力计算的内存需求。   <br />- 对于单用户单请求场景，理论速度极限是一个常数，可用于跨模型和设备评估预期性能，但多用户并发请求时，情况会改变。   <br />- 理论速度极限分析对于理解和优化LLM生成性能至关重要。<br /><br />点评：  <br />- 文章从理论角度分析了LLM推理速度的极限，这一视角有别于一般的性能优化讨论，具有独到之处。  <br />- 作者提出了计算理论最大FLOPS利用率和最小延迟时间的方法，为衡量和优化推理性能提供了新的思路。  <br />- 文章指出了影响实际推理速度的诸多因素，这启示我们在性能优化时需要全面考虑，而不仅仅局限于计算本身。  <br />- 尽管理论极限难以达到，但作者认为它仍然是一个有意义的目标，这一观点值得深思。  <br />- 文章虽然专业性强，但对于理解LLM推理性能优化具有重要指导意义。<br /><br />《zeux.io - LLM inference speed of light》 <a href="https://zeux.io/2024/03/15/llm-inference-sol/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntp4m8oolj20u00ubtek.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:43:08 GMT</pubDate>
</item>
<item>
<title>【整数标记化(tokenization)：语言模型数字处理的”bug"?】- GPT模型的整数标记化(tokenize)方式存在很大问题，这让模型学习数学知识和表示数学事实变得非常困难...</title>
<link>https://weibo.com/1402400261/O5nMx2bXx</link>
<guid>https://weibo.com/1402400261/O5nMx2bXx</guid>
<content:encoded><![CDATA[
<div> 整数标记化, 语言模型, GPT模型, 十进制系统, 数学知识, 数学运算, 数字处理, 算法, 问题

<br /><br />总结: 
作者对GPT模型的整数标记化方式存在的问题提出了质疑，表示现有方法可能影响模型对数学知识的学习和运用。理想的数字系统应该遵循十进制系统，对0-9的整数使用唯一的token，而更大的整数则用这些token的组合表示。然而，GPT在处理整数时为大量整数分配了独立的token，导致模型无法应用通用数学运算算法，只能依赖记忆特殊情况出现的结果。这种不一致的整数分块标记化方式影响了模型的推理能力，对其理解和应用数学运算与算法的提高具有重要意义。整数tokenize的改进是关键所在，有望让GPT模型在数学能力上取得进步。 <div>
【整数标记化(tokenization)：语言模型数字处理的”bug"?】<br />- GPT模型的整数标记化(tokenize)方式存在很大问题，这让模型学习数学知识和表示数学事实变得非常困难。   <br />- 理想的数字系统应该对0-9的整数使用唯一的token，而更大的整数则用这些token的组合表示，以体现十进制系统。   <br />- 但GPT的tokenize方式并未遵循十进制系统，而是为大量整数独立分配了唯一的token。这导致模型无法应用通用的数学运算算法，只能依赖大量模式匹配记忆。   <br />- 不仅小整数受影响，在较大的整数中也存在大量独立token的情况，这同样导致了无法应用通用算法的问题。   <br />- 即使在非独立token的整数中，分割整数的方式也不一致，导致模型同样无法应用统一的运算逻辑。   <br />- 这让模型进行数字运算时必须记忆大量特殊情况下的结果，而非应用通用算法，增加了学习和推理的难度。   <br />- 整数tokenize的这些问题说明，GPT模型距离真正理解和应用数学运算与算法还有很长的路要走。tokenize方式的改进是模型在数学能力上提高的关键。<br /><br />点评:<br />1. 作者对现有的整数标记化方法提出质疑,认为其存在不合理之处。<br />2. 揭示了语言模型在处理数字时的特殊机制可能影响模型对数字的理解和运算能力。<br />3. 举例说明了整数分块标记化的不一致性,这一发现对优化语言模型的数字处理方式具有启发意义。<br /><br />《Integer tokenization is insane》 <a href="https://www.beren.io/2023-02-04-Integer-tokenization-is-insane/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntor0oe8lj20hs0dcwet.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntor291rsj20hs0dcgn3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:30:14 GMT</pubDate>
</item>
<item>
<title>【开源路上，别让心理健康成了绊脚石】1. 开源维护者面临的心理健康挑战: - 工作与生活平衡 - 来自社区的期望和压力 - 个人对完美的追求2. 作者的应对方式: - 放...</title>
<link>https://weibo.com/1402400261/O5nGUCOBu</link>
<guid>https://weibo.com/1402400261/O5nGUCOBu</guid>
<content:encoded><![CDATA[
<div> 心理健康, 开源维护者, 压力, 应对方式, 社区, 建议, 展望, 资源, 可持续发展, 平衡

总结:<br /><br />本文探讨了开源维护者在面临心理健康挑战时的困境，包括工作与生活平衡、社区压力、追求完美等问题。作者提出了应对方式，如放慢节奏、写博客宣泄情绪、与社区沟通，以及对开源贡献者的建议，如设定合理预期、寻求帮助、关注自我等。同时，指出开源社区应营造友善氛围、关注心理健康、提供支持资源。关键在于不断学习调整，找到适合自己的方式，平衡投入和自我保护。 <div>
【开源路上，别让心理健康成了绊脚石】<br />1. 开源维护者面临的心理健康挑战:<br />   - 工作与生活平衡<br />   - 来自社区的期望和压力<br />   - 个人对完美的追求<br />2. 作者的应对方式:<br />   - 放慢节奏,享受过程而非执着于立竿见影的结果<br />   - 写博客梳理思路,宣泄负面情绪<br />   - 与社区保持开诚布公的沟通<br />3. 作者对开源贡献者的建议:<br />   - 设定合理预期,接纳"够好"的结果<br />   - 必要时寻求帮助,与他人分享感受<br />   - 关注自我,投入个人生活与兴趣爱好<br />4. 作者对开源社区的展望:<br />   - 营造友善、包容的氛围<br />   - 关注贡献者的心理健康<br />   - 提供更多帮助和支持资源<br />5. 开源之路没有完美的解决方案,关键是不断学习、调整,找到适合自己的方式。<br /><br />点评:<br />1. 开源工作获得回报的周期较长,需要贡献者保持耐心和动力。<br />2. 部分评论质疑开源是否必然导致心理压力,认为关键在于自我管理。<br />3. 有建议指出,参与者应主动控制参与度,必要时"说不"以保障个人生活。<br />4. 开源社区应提供更多支持资源,如心理健康指南、互助小组等。<br />5. 开源项目的可持续发展,需要在贡献者投入和自我保护间找到平衡。<br /><br />《Mental Health in Open Source》 <a href="https://antfu.me/posts/mental-health-oss"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntocrscepj20x00u0n1p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:16:24 GMT</pubDate>
</item>
<item>
<title>今日推介(第1347期)：语言模型算法带来的改进速率评估、用合成数据进行模型高效评估、检索增强思维在长程生成中实现上下文感知推理、面向向量嵌入和结构化数据的...</title>
<link>https://weibo.com/1402400261/O5nfJ9Pv8</link>
<guid>https://weibo.com/1402400261/O5nfJ9Pv8</guid>
<content:encoded><![CDATA[
<div> 语言模型算法、改进速率评估、合成数据、模型高效评估、检索增强思维、长程生成、上下文感知推理、面向向量嵌入、结构化数据、高性能、谓词不可知搜索方法、持续学习、灾难性遗忘

总结:<br /><br />本文分析了语言模型算法带来的改进速率评估以及使用合成数据进行模型高效评估的方法。进一步讨论了检索增强思维在长程生成中实现上下文感知推理的重要性。同时介绍了面向向量嵌入和结构化数据的高性能和谓词不可知搜索方法的应用。最后，探讨了持续学习与灾难性遗忘的问题，为相关领域的研究提供了启示。 <div>
今日推介(第1347期)：语言模型算法带来的改进速率评估、用合成数据进行模型高效评估、检索增强思维在长程生成中实现上下文感知推理、面向向量嵌入和结构化数据的高性能和谓词不可知搜索方法、持续学习与灾难性遗忘  公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687438947"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.17)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntmepeyz2j20k0094jsj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntmet15vnj20k00g50us.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntmevbeezj20k00eptaq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntmezj2v6j20k00bfjs2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntmf23pboj20k006v0ty.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 23:09:24 GMT</pubDate>
</item>
<item>
<title>[LG] Poly-View Contrastive Learning 网页链接 展示了一种名为多视对比学习(Poly-View Contrastive Learning)的新框架，挑战了传统对比学习中常见的观点，即需...</title>
<link>https://weibo.com/1402400261/O5nbmvDDn</link>
<guid>https://weibo.com/1402400261/O5nbmvDDn</guid>
<content:encoded><![CDATA[
<div> 对比学习、多视对比学习、视角数量、样本总量、计算资源、训练周期、批次数量、表现优势、图像表示学习、高效性
<br /><br />总结:
研究展示了一种新框架——多视对比学习，挑战了传统对比学习观点，证明增加单个样本的视角数量而非样本总量可以获得更好的表现。使用多视角对比模型，在限定的训练周期和批次设置下，可以超越传统对比学习模型的效果。这一研究改变了对大批量和长周期训练需求的传统看法，为图像表示学习提供了新方向，突显了高效性。 <div>
[LG] Poly-View Contrastive Learning  <br /><a href="https://arxiv.org/abs/2403.05490"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />展示了一种名为多视对比学习(Poly-View Contrastive Learning)的新框架，挑战了传统对比学习中常见的观点，即需要大量样本和多个训练周期来提高性能。研究表明，通过增加单个样本的视角数量而非样本总量，可以在有限的计算资源下获得更优的表现。具体来说，使用多视角对比模型，在128个训练周期、每批次256个样本的设置下，就能超越标准对比学习模型SimCLR在1024个周期、每批次4096个样本的训练效果。该研究改变了对大批量和长周期训练需求的传统看法，为高效的图像表示学习指明了新方向。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntm3w9ye2j213u1m2qoj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntm3wx3pxj21ui10awtc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:58:40 GMT</pubDate>
</item>
<item>
<title>[CV] Score-Guided Diffusion for 3D Human Recovery 网页链接 介绍了一种名为Score-Guided Human Mesh Recovery(ScoreHMR)的新方法，用于解决3D人体姿态和形状...</title>
<link>https://weibo.com/1402400261/O5n8ZBO7k</link>
<guid>https://weibo.com/1402400261/O5n8ZBO7k</guid>
<content:encoded><![CDATA[
<div> Score-Guided Human Mesh Recovery, 3D人体姿态和形状重建, 扩散模型, 得分引导, 图像观测, 单帧模型拟合, 多视角重建, 视频序列, 基准测试

<br /><br />总结:
本文介绍了一种新方法Score-Guided Human Mesh Recovery (ScoreHMR) 用于解决3D人体姿态和形状重建的逆问题。与传统方法不同，该方法利用扩散模型的潜空间并通过得分引导实现与图像观测的对齐。该方法在多项基准测试中展现出较高的准确性，有效提高了单帧模型拟合、多视角重建和视频序列中人体动作的精度，超越了所有优化基准模型。ScoreHMR不需要特定任务的扩散模型再训练，具有较高的实用性。 <div>
[CV] Score-Guided Diffusion for 3D Human Recovery  <br /><a href="https://arxiv.org/abs/2403.09623"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为Score-Guided Human Mesh Recovery(ScoreHMR)的新方法，用于解决3D人体姿态和形状重建的逆问题。与传统优化或回归方法不同，ScoreHMR利用扩散模型的潜空间并通过得分引导来实现与图像观测的对齐。这种方法不需要对无依赖任务的扩散模型进行特定任务的再训练，有效地提高了单帧模型拟合、多视角重建和视频序列中人体动作的准确性，并在多项基准测试中超越了所有优化基准模型。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntlxtzz9ij21a81ich9h.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntlxunm8nj21qa0y8dt3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:52:50 GMT</pubDate>
</item>
<item>
<title>[LG] Defending Against Unforeseen Failure Modes with Latent Adversarial Training 网页链接 深入探讨了AI系统部署后出现的意外行为，并提出一种新的防御手段...</title>
<link>https://weibo.com/1402400261/O5n6f85Bk</link>
<guid>https://weibo.com/1402400261/O5n6f85Bk</guid>
<content:encoded><![CDATA[
<div> 潜对抗训练, 意外行为, 防御手段, 潜表示层, 压缩, 抽象, 结构化, 图像分类, 文本分类, 文本生成

<br /><br />

总结: 本文深入探讨了AI系统部署后可能出现的意外行为，并提出了一种新的防御手段——潜对抗训练（LAT）。LAT通过在模型的潜表示层面干预，利用更加压缩、抽象和结构化的概念表示来防御未知的失败模式。实验证明，LAT在图像分类、文本分类和文本生成任务中，相比传统的对抗训练（AT），能提高模型对未知对抗样本类别的鲁棒性，同时移除特洛伊木马。这一发现显示LAT的潜力，为防御开发者无法明确识别的失败模式提供了可能的解决方案。 <div>
[LG] Defending Against Unforeseen Failure Modes with Latent Adversarial Training  <br /><a href="https://arxiv.org/abs/2403.05030"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />深入探讨了AI系统部署后出现的意外行为，并提出一种新的防御手段：潜对抗训练(LAT)。LAT区别于传统的对抗训练(AT)，它不通过生成触发模型失败的输入，而是在模型的潜表示层面进行干预，利用网络对信息进行处理时构建的更加压缩、抽象和结构化的概念表示。通过在图像分类、文本分类和文本生成任务中的实验表明，与AT相比，LAT通常能在不损害干净数据性能的同时，提高模型对未见过的对抗样本类别的鲁棒性，并能移除特洛伊木马。这一发现表明LAT可以成为一种有前景的工具，用于防御开发者无法显式识别的失败模式。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntlqrmnlzj212u1jctr6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntlqql6xrj21hi1cudyi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:46:03 GMT</pubDate>
</item>
<item>
<title>[LG] ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training 网页链接 提出PROTLLM，一个能同时处理蛋白质中心和蛋白质-语言任务的...</title>
<link>https://weibo.com/1402400261/O5n3Awz5o</link>
<guid>https://weibo.com/1402400261/O5n3Awz5o</guid>
<content:encoded><![CDATA[
<div> PROTLLM、蛋白质挂载机制、蛋白质词表、InterPT、跨模态大型语言模型、零样本学习、上下文学习、蛋白质中心任务、蛋白质-语言任务、预训练数据集

<br /><br />总结:
PROTLLM是一个跨模态大型语言模型，具有动态蛋白质挂载机制，可以处理复杂输入中的任意数量蛋白质。通过专门的蛋白质词表，模型能够同时预测自然语言和蛋白质。研究构建了大规模的蛋白质-文本数据集InterPT用于预训练，融合了结构化和非结构化数据源。PROTLLM在蛋白质中心任务上表现优于基线模型，并展现出零样本学习和上下文学习的能力。这项研究为蛋白质-语言任务提供了新的解决方案，并为蛋白质研究领域带来了创新的进展。 <div>
[LG] ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training  <br /><a href="https://arxiv.org/abs/2403.07920"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出PROTLLM，一个能同时处理蛋白质中心和蛋白质-语言任务的跨模态大型语言模型(LLM)。其特色是动态蛋白质挂载机制，使模型能够处理含有任意数量蛋白质的复杂输入。通过开发专门的蛋白质词表，模型能够从大量候选者中预测自然语言和蛋白质。构建了一个大规模交错的蛋白质-文本数据集InterPT用于预训练，融合了结构化和非结构化数据源。PROTLLM在蛋白质中心任务上优于专门的基线，并且在蛋白质-语言任务上展示了零样本和上下文学习能力。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntljyrwk6j213a1je7nq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntljzjjocj21fu11kakh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:39:31 GMT</pubDate>
</item>
<item>
<title>[CL] CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences 网页链接 介绍了CodeUltraFeedback和CODAL-Ben...</title>
<link>https://weibo.com/1402400261/O5n0v593n</link>
<guid>https://weibo.com/1402400261/O5n0v593n</guid>
<content:encoded><![CDATA[
<div> CodeUltraFeedback, CODAL-Bench, 数据集, 大型语言模型, 编程偏好, AI反馈, LLM-as-a-Judge方法, 偏好优化, 微调, RLAIF, 功能正确性, CodeLlama-7B-Instruct模型, SFT, DPO

总结:<br /><br />本文介绍了CodeUltraFeedback和CODAL-Bench，提供了一套用于微调和评估大型语言模型(LLM)以符合编程偏好的数据集和基准。CodeUltraFeedback包含复杂指令，通过AI反馈调整LLM偏好，反映了五种编程偏好。利用LLM-as-a-Judge方法对LLM的响应进行了标注，包括数值评分和文本反馈。研究表明经过微调的CodeLlama-7B-Instruct模型在功能正确性和偏好对齐方面表现优于基础模型和更大的34B LLM。这证明了CodeUltraFeedback在偏好调整中的实用性，以及SFT和DPO在提升LLM与人类编程偏好对齐方面的潜力。 <div>
[CL] CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences  <br /><a href="https://arxiv.org/abs/2403.09032"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了CodeUltraFeedback和CODAL-Bench，一套用于微调和评估大型语言模型(LLM)以符合编程偏好的数据集和基准。CodeUltraFeedback包含10000条复杂指令，用于通过AI反馈调整LLM偏好，反映了五种编程偏好。利用来自GPT-3.5的LLM-as-a-Judge方法，对LLM的响应进行了标注，包括数值评分和文本反馈。通过直接偏好优化(DPO)和AI反馈强化学习(RLAIF)的研究表明，经过微调的CodeLlama-7B-Instruct模型在功能正确性和偏好对齐方面均优于未微调的基础模型和更大的34B LLM。这证明了CodeUltraFeedback在偏好调整中的实用性，以及SFT和DPO在提升LLM与人类编程偏好对齐方面的潜力。<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntlc1minqj218a1ic4nd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntlc27482j21b01c2du8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntlc2bylej20y019cjyn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:31:54 GMT</pubDate>
</item>
<item>
<title>详尽分析了人工神经网络在持续学习过程中面临的灾难性遗忘挑战，探讨了六种主要的计算方法来提高持续学习能力，强调了在深度学习与认知科学之间建立联系的重要性...</title>
<link>https://weibo.com/1402400261/O5mVI6XCv</link>
<guid>https://weibo.com/1402400261/O5mVI6XCv</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工神经网络，持续学习，灾难性遗忘，深度学习，认知科学，计算方法，互相启发，发展，联系，挑战

总结:<br /><br />
本文详细分析了人工神经网络在持续学习过程中所面临的灾难性遗忘挑战，并通过探讨六种主要的计算方法来提高持续学习能力。作者强调了在深度学习与认知科学之间建立联系的重要性，旨在促进两个领域之间的互相启发和发展。文章指出，在人工智能领域持续学习是一个关键的问题，因为传统神经网络容易忘记之前学到的知识，导致新知识的学习会覆盖旧知识。为解决这一问题，提出了六种方法，包括反向传播、重放缓冲区、正交正则化、动态权重、增量学习和任务分解等。这些方法在一定程度上提高了人工神经网络的持续学习能力。同时，文章呼吁深度学习与认知科学之间建立更多的联系，通过相互启发和发展推动这两个领域的进步。这种综合性的研究方法可以为人工智能领域的持续学习问题带来新的突破。通过深入探讨人工神经网络如何应对灾难性遗忘挑战，可以不断提升其在持续学习任务中的表现，推动人工智能技术的发展。 <div>
详尽分析了人工神经网络在持续学习过程中面临的灾难性遗忘挑战，探讨了六种主要的计算方法来提高持续学习能力，强调了在深度学习与认知科学之间建立联系的重要性，旨在推动两领域的互相启发和发展。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Continual Learning and Catastrophic Forgetting》G M. v d Ven, N Soures, D Kudithipudi [KU Leuve &amp; University of Texas at San Antonio] (2024) <a href="https://arxiv.org/abs/2403.05175"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklqwed9j21eo0dwgs1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntklrqmumj21na0motf2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsa9x2j21n40kaaj9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsujzaj21n20nk7cy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntkznz89nj21120o7439.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:20:06 GMT</pubDate>
</item>
<item>
<title>[LG]《Continual Learning and Catastrophic Forgetting》G M. v d Ven, N Soures, D Kudithipudi [KU Leuve &amp; University of Texas at San Antonio] (2024) 网...</title>
<link>https://weibo.com/1402400261/O5mVF0Qpu</link>
<guid>https://weibo.com/1402400261/O5mVF0Qpu</guid>
<content:encoded><![CDATA[
<div> 学习，持续学习，灾难性遗忘，机器学习，人工智能，神经网络，模型，挑战，解决方案，实验<br />
<br />
总结:<br />
本文讨论了持续学习和灾难性遗忘的问题，提出了一种解决方案来解决这一挑战。研究人员指出，传统的机器学习算法在面对持续学习任务时会出现灾难性遗忘的情况，导致已学习过的知识被遗忘。为了克服这一问题，他们提出了一种基于神经网络的方法，通过对模型进行增量学习和保留重要信息的方式来解决灾难性遗忘。研究人员进行了一系列实验来验证他们的方法的有效性，结果表明他们的方法在持续学习任务中具有较好的性能表现。这项研究为解决持续学习和灾难性遗忘问题提供了新的思路和方法。 <div>
[LG]《Continual Learning and Catastrophic Forgetting》G M. v d Ven, N Soures, D Kudithipudi [KU Leuve &amp; University of Texas at San Antonio] (2024) <a href="https://arxiv.org/abs/2403.05175"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklqwed9j21eo0dwgs1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntklrqmumj21na0motf2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsa9x2j21n40kaaj9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsujzaj21n20nk7cy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntkznz89nj21120o7439.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:19:59 GMT</pubDate>
</item>
<item>
<title>ACORN是一种新的、性能优异且不限制谓词类型的混合搜索方法，通过改良HNSW索引和引入谓词子图遍历来同时高效处理向量和结构化数据，克服了传统方法在性能和搜索...</title>
<link>https://weibo.com/1402400261/O5mPdmC1P</link>
<guid>https://weibo.com/1402400261/O5mPdmC1P</guid>
<content:encoded><![CDATA[
<div> ACORN, HNSW索引, 混合搜索方法, 向量数据, 结构化数据, 高性能, 不限制谓词类型, 复杂多模态数据集, 高查询吞吐量, 低构建开销

<br /><br />总结:
研究介绍了一种新的混合搜索方法ACORN，它通过改良HNSW索引和引入谓词子图遍历来同时处理向量数据和结构化数据。ACORN能够高效处理复杂多模态数据集，克服了传统方法在性能和搜索谓词表达式上的限制。研究表明，ACORN实现了高查询吞吐量和低构建开销的优异性能，为搜索领域带来了新的可能性。 <div>
ACORN是一种新的、性能优异且不限制谓词类型的混合搜索方法，通过改良HNSW索引和引入谓词子图遍历来同时高效处理向量和结构化数据，克服了传统方法在性能和搜索谓词表达式上的限制，实现了在复杂多模态数据集上的高查询吞吐量和低构建开销。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [IR]《ACORN: Performant and Predicate-Agnostic Search Over Vector Embeddings and Structured Data》L Patel, P Kraft, C Guestrin, M Zaharia [Stanford University &amp; DBOS, Inc &amp; UC Berkeley] (2024) <a href="https://arxiv.org/abs/2403.04871"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkivhxhvj211e11eao2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkivwjjlj210y0l4wh3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkiwh65wj211a0tyjws.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntkiwpg9jj21160jetb3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkiy3hepj213s0e2gnl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkiy2ugdj20jg0d33zo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkiy3nidj213r0csgob.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkiy2z5dj213m08qgn0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkiy3nxyj20jg0f175q.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:04:06 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》(CVPR 2024) GitHub: github.c...</title>
<link>https://weibo.com/1402400261/O5jwVne0V</link>
<guid>https://weibo.com/1402400261/O5jwVne0V</guid>
<content:encoded><![CDATA[
<div> DNGaussian, 优化, 稀疏视图, 3D, 高斯辐射场, 全局局部深度规范化, GitHub, Pix2Gif, 运动引导扩散, GIF 生成, SSM, 视频扩散模型, 有效视频生成, 结构化状态空间, 语言模型, 可靠性, 过度训练, 下游任务

<br /><br />总结: 《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》提出了一种优化稀疏视图3D高斯辐射场的方法，通过全局局部深度规范化来改善渲染效果，代码可在GitHub上找到。《Pix2Gif: Motion-Guided Diffusion for GIF Generation》介绍了Pix2Gif，一种运动引导扩散技术，用于生成GIF图像。《SSM Meets Video Diffusion Models: Efficient Video Generation with Structured State Spaces》展示了SSM与视频扩散模型相结合，实现了有效的视频生成，采用了结构化状态空间。《Language models scale reliably with over-training and on downstream tasks》研究表明，语言模型在过度训练和下游任务中表现出可靠的扩展性，相关代码可在GitHub上获取。 <div>
几篇论文实现代码：<br />《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》(CVPR 2024) GitHub: github.com/Fictionarry/DNGaussian [fig1]<br />《Pix2Gif: Motion-Guided Diffusion for GIF Generation》(2024) GitHub: github.com/hiteshK03/Pix2Gif<br />《SSM Meets Video Diffusion Models: Efficient Video Generation with Structured State Spaces》(2024) GitHub: github.com/shim0114/SSM-Meets-Video-Diffusion-Models [fig2]<br />《Language models scale reliably with over-training and on downstream tasks》(2024) GitHub: github.com/mlfoundations/scaling<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnt3oac1q5j21iu0jiasp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnt3p0dq0hj22801904ns.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 13:40:48 GMT</pubDate>
</item>
<item>
<title>'Awesome-AISourceHub - AI科技领域高质量信息源列表’ GitHub: github.com/AmbroseX/Awesome-AISourceHub #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5jwP9UrG</link>
<guid>https://weibo.com/1402400261/O5jwP9UrG</guid>
<content:encoded><![CDATA[
<div> GitHub, AI, 科技, 高质量, 信息源, 列表, 开源项目, AmbroseX, Awesome-AISourceHub

总结:<br /><br />这是一个收集AI科技领域高质量信息源的开源项目，其中包括了各种资源列表和信息源，可以帮助人们更好地了解和学习关于人工智能的知识。由AmbroseX创建并维护，项目地址为github.com/AmbroseX/Awesome-AISourceHub。欢迎大家积极参与和贡献，共同打造一个强大的AI资源集合。 <div>
'Awesome-AISourceHub - AI科技领域高质量信息源列表’ GitHub: github.com/AmbroseX/Awesome-AISourceHub <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnt5z3jp2mj20y40u00y9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 13:40:33 GMT</pubDate>
</item>
<item>
<title>【EasyDetect：易于使用的多模态幻觉检测框架，用于多模态大型语言模型(MLLMs)如GPT-4V、Gemini、LlaVA的研究实验，通过统一的视角对多模态幻觉进行检测，包括模...</title>
<link>https://weibo.com/1402400261/O5j2octGD</link>
<guid>https://weibo.com/1402400261/O5j2octGD</guid>
<content:encoded><![CDATA[
<div> 多模态 幻觉检测框架 GPT-4V Gemini LlaVA 研究实验 统一视角 模态冲突 幻觉 事实冲突 幻觉

<br /><br />总结:
EasyDetect是一个易于使用的多模态幻觉检测框架，专为大型语言模型如GPT-4V、Gemini和LlaVA的研究实验而设计。该框架通过统一的视角对多模态幻觉进行检测，包括模态冲突幻觉和事实冲突幻觉。通过EasyDetect，研究人员可以更方便地进行多模态幻觉的实验和研究，从而深入探讨语言模型的表现和特性。 <div>
【EasyDetect：易于使用的多模态幻觉检测框架，用于多模态大型语言模型(MLLMs)如GPT-4V、Gemini、LlaVA的研究实验，通过统一的视角对多模态幻觉进行检测，包括模态冲突幻觉和事实冲突幻觉】’EasyDetect - An Easy-to-use Hallucination Detection Framework for LLMs.' GitHub: github.com/OpenKG-ORG/EasyDetect <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnt3t2xe1zj20i60fbdj0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnt3t5cqj1j20pp0gegqn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 12:25:34 GMT</pubDate>
</item>
<item>
<title>【ChatOllama：基于Nuxt 3和Ollama的聊天Web应用】'ChatOllama - a Nuxt 3 + Ollama web application. It's an example of Ollama Javascript library’ GitHub:...</title>
<link>https://weibo.com/1402400261/O5j0hzQkC</link>
<guid>https://weibo.com/1402400261/O5j0hzQkC</guid>
<content:encoded><![CDATA[
<div> ChatOllama、Nuxt 3、Ollama、web应用、GitHub、Javascript库、聊天应用、示例、开发、实现<br />
<br />总结:
ChatOllama是基于Nuxt 3和Ollama的聊天Web应用示例，使用Ollama Javascript库开发，代码托管在GitHub上，展示了如何开发和实现一个聊天应用。 <div>
【ChatOllama：基于Nuxt 3和Ollama的聊天Web应用】'ChatOllama - a Nuxt 3 + Ollama web application. It's an example of Ollama Javascript library’ GitHub: github.com/sugarforever/chat-ollama <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnt3ns8meej219c0jogny.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 12:20:23 GMT</pubDate>
</item>
<item>
<title>【Data is Better Together：由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。目前，该项目已经创...</title>
<link>https://weibo.com/1402400261/O5ihKbqgZ</link>
<guid>https://weibo.com/1402400261/O5ihKbqgZ</guid>
<content:encoded><![CDATA[
<div> Hugging Face, Argilla, 开源机器学习社区, 数据集, 合作, 提示, 排名, 10,000个, 质量

<br /><br />总结:
Data is Better Together是一个由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。该项目已经创建了一个由10,000个提示组成的数据集，并按照质量进行了排名。这个项目的目标是让开源社区共同努力，创造更好的数据集，为机器学习研究和实践提供更丰富的资源和支持。通过协作和合作，我们可以共同构建更具影响力和实用性的数据集，推动机器学习领域的发展和创新。 <div>
【Data is Better Together：由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。目前，该项目已经创建了一个由10,000个提示组成的数据集，按质量进行了排名】'Data is Better Together - Let's build better datasets, together!' GitHub: github.com/huggingface/data-is-better-together <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnt0hi5cbfj211y0lc78w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 10:30:39 GMT</pubDate>
</item>
<item>
<title>【OPEN TEACH: 多功能遥操作框架，使用Meta Quest3进行机器人操作，具有灵活性和多样性，包括VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，支持在各种...</title>
<link>https://weibo.com/1402400261/O5ih2p7R0</link>
<guid>https://weibo.com/1402400261/O5ih2p7R0</guid>
<content:encoded><![CDATA[
<div> 多功能遥操作框架, Meta Quest3, 机器人操作, 灵活性, 多样性, Unity脚本, 遥操作流程, 数据收集流程, 策略训练, GitHub  

<br /><br />总结:  
这篇文章介绍了一个名为"OPEN TEACH"的多功能遥操作框架，使用Meta Quest3进行机器人操作，并具有灵活性和多样性。该框架包括了VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，能够支持在各种机器人和仿真环境下进行遥操作和数据收集，并针对不同机器人和仿真进行策略训练。该框架的GitHub链接为github.com/aadhithya14/Open-Teach。 <div>
【OPEN TEACH: 多功能遥操作框架，使用Meta Quest3进行机器人操作，具有灵活性和多样性，包括VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，支持在各种机器人和仿真环境下进行遥操作和数据收集，并针对不同机器人和仿真进行策略训练】'OPEN TEACH: A Versatile Teleoperation System for Robotic Manipulation - A Versatile Teleoperation framework for Robotic Manipulation using Meta Quest3' GitHub: github.com/aadhithya14/Open-Teach <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnt0fre8fpj21ji0twwkh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 10:28:54 GMT</pubDate>
</item>
<item>
<title>今日推介(第1346期)：让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、用Moment Pooling简化机器学习...</title>
<link>https://weibo.com/1402400261/O5dqgdQEc</link>
<guid>https://weibo.com/1402400261/O5dqgdQEc</guid>
<content:encoded><![CDATA[
<div> 语言模型、结构化训练、灾难性遗忘、预期性恢复、马尔可夫决策过程、学习算法、Moment Pooling、机器学习潜空间、API保护、LLM的Logits

<br /><br />总结:
本文介绍了几个关键的技术和方法，包括让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、以及用Moment Pooling简化机器学习潜空间。另外，还提到了API保护LLM的Logits会泄漏模型专有信息的问题。这些方法和技术对于改进语言模型的能力，提高机器学习算法的效率和精确度都具有重要意义。通过不断探索和应用这些新技术，我们可以进一步推动人工智能领域的发展，为未来带来更多可能性。 <div>
今日推介(第1346期)：让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、用Moment Pooling简化机器学习潜空间、API保护LLM的Logits会泄漏模型专有信息 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687311397"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.16)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnsf0htg36j20k00b9gn7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnsf0k1lqgj20k006m751.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnsf0ml60tj20k007d0t5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnsf0p0i2ij20k00kq762.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnsf0repglj20k008pwfi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 22:07:54 GMT</pubDate>
</item>
<item>
<title>[RO] GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping 网页链接 提出一种名为GaussianGrasper的开放词表机器人抓取技术...</title>
<link>https://weibo.com/1402400261/O5dn86Ikc</link>
<guid>https://weibo.com/1402400261/O5dn86Ikc</guid>
<content:encoded><![CDATA[
<div> 高斯Splatting、机器人抓取技术、3D构建、视角输入、推理效率、特征蒸馏、对比学习、抓取姿态、语言指令、场景更新
<br /><br />总结:
提出了一种名为GaussianGrasper的开放词表机器人抓取技术，通过3D高斯Splatting构建场景，解决了传统隐式场景表达的问题。利用有限的RGB-D视角和高效特征蒸馏模块，结合对比学习来准确提取语言嵌入，使得预训练的抓取模型可以生成无碰撞的抓取姿态候选。通过法向引导的抓取模块选取最佳姿态。实验证明，该系统能准确响应语言指令，执行抓取任务，并实现快速场景更新。提供了新的解决方案用于语言引导操作任务，并公开了数据和代码资源。 <div>
[RO] GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping  <br /><a href="https://arxiv.org/abs/2403.09637"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出一种名为GaussianGrasper的开放词表机器人抓取技术，它通过3D高斯Splatting显式构建场景，解决了传统隐式场景表达(例如NeRF)需要大量视角输入和推理效率低下的问题。GaussianGrasper利用有限的RGB-D视角并通过一种高效特征蒸馏(EFD)模块，结合对比学习来准确提取语言嵌入。这使得其预训练的抓取模型能生成无碰撞的抓取姿态候选，并通过法向引导的抓取模块选取最佳姿态。实验表明，该系统能准确响应语言指令，执行抓取任务，并实现快速场景更新。此外，提供了用于语言引导操作任务的新解决方案，并公开了数据和代码资源。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsesr3i0dj219w1kc1kx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsesrglfpj21hq17uqlw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsesrlyxgj21h40uqqif.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 22:00:11 GMT</pubDate>
</item>
<item>
<title>[CV] Reconstruction and Simulation of Elastic Objects with Spring-Mass 3D Gaussians 网页链接 提出了Spring-Gaus框架，一个整合物理仿真和3D高斯模型的新方...</title>
<link>https://weibo.com/1402400261/O5difnNAc</link>
<guid>https://weibo.com/1402400261/O5difnNAc</guid>
<content:encoded><![CDATA[
<div> Spring-Gaus, 物理仿真, 3D高斯模型, 弹性物体, 多视角视频, 参数优化, 模拟粒子, 样本效率, 泛化能力, 形变预测

<br /><br />总结:
本文提出了Spring-Gaus框架，结合了物理仿真和3D高斯模型，用于重建和模拟弹性物体。通过3D弹簧-质点模型在个体点级别优化物理参数，解决了物理和外观学习的问题，提高了样本效率和泛化能力。Spring-Gaus在合成和真实数据集上证明了有效性，特别是在形变预测和不同环境参数下的模拟中表现出色。这一研究突破了物理参数优化和异质物体建模的限制，为预测视觉感知和沉浸式体验的应用提供了新的可能性。 <div>
[CV] Reconstruction and Simulation of Elastic Objects with Spring-Mass 3D Gaussians  <br /><a href="https://arxiv.org/abs/2403.09434"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出了Spring-Gaus框架，一个整合物理仿真和3D高斯模型的新方法，用于从多视角视频重建和模拟弹性物体。与传统的3D高斯方法相比，Spring-Gaus通过3D弹簧-质点模型在个体点级别优化物理参数，有效解缠物理和外观学习。这种方法提高了样本效率，增强了泛化能力，并减少了对仿真粒子分布的敏感性。在合成和真实世界数据集上的评估证明了Spring-Gaus在准确重建和模拟弹性物体方面的有效性，尤其是在进行未来形变预测和不同初始状态及环境参数下的模拟时。该研究突破了物理参数优化和异质物体建模的限制，为预测视觉感知和沉浸式体验的应用开辟了可能。<img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnseg8bri1j20z41e6wrp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnseg8nm5cj21fa0wstjg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnseg9gk2gj21fa1au18j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:48:10 GMT</pubDate>
</item>
<item>
<title>[LG] Majority-of-Three: The Simplest Optimal Learner? 网页链接 讨论了PAC学习中的一个开放问题：在实现环境下，寻找最简单的最优学习算法。分析了一个简单的...</title>
<link>https://weibo.com/1402400261/O5deGfwNR</link>
<guid>https://weibo.com/1402400261/O5deGfwNR</guid>
<content:encoded><![CDATA[
<div> 多数投票法, 最优学习算法, PAC学习, 期望误差, 高概率误差, Bagging算法, ERM分类器, 最优误差界, one-inclusion graph算法, 简化算法结构

<br /><br />总结:
本文讨论了在实现环境下寻找最简单的最优学习算法的问题，并提出了多数投票法可能是一个简单且最优的解决方案。该算法使用三个ERM分类器，在期望误差上达到了最优，并且在高概率误差上也接近最优。该发现挑战了之前认为ERM分类器无法独自实现最优误差界的观点。文章还提出了改进的Bagging算法，简化了之前复杂的算法结构。另外，研究指出了one-inclusion graph算法在高概率误差上的局限性，与之前的猜想相反。通过进一步分析，多数投票法可能在高概率误差上也是最优的。整体而言，本文为最简单有效的学习算法提供了新的思路，并拓展了对学习算法的理解。 <div>
[LG] Majority-of-Three: The Simplest Optimal Learner?  <br /><a href="https://arxiv.org/abs/2403.08831"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />讨论了PAC学习中的一个开放问题：在实现环境下，寻找最简单的最优学习算法。分析了一个简单的算法——多数投票法，其中只使用三个ERM分类器。文章的核心是这个算法在期望误差上达到了最优，并且近似于高概率误差上的最优。这一发现挑战了之前的认知，即ERM分类器无法独自实现最优误差界。本文还提出一种改进的Bagging算法，简化了之前复杂的算法结构，但分析过程仍然复杂。此外，一项新的研究揭示了one-inclusion graph算法在高概率误差上的局限性，这与之前Warmuth的猜想相反。本文认为，通过进一步分析，上述多数投票法可能在高概率误差上也是最优的。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnse738777j21841gmh1p.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnse73lpebj21co0zoqa5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:39:22 GMT</pubDate>
</item>
<item>
<title>[CV] MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training 网页链接 介绍了多模态大型语言模型(MLLM)的构建，重点在于体系结构组件和数据选择...</title>
<link>https://weibo.com/1402400261/O5dbMeVyI</link>
<guid>https://weibo.com/1402400261/O5dbMeVyI</guid>
<content:encoded><![CDATA[
<div> 模态语言模型 构建 组件 数据 体系结构 图像编码器 视觉语言连接器 预训练数据<br />
<br />
总结: 本文介绍了多模态大型语言模型(MLLM)的构建方法和分析，强调了体系结构组件和数据选择的重要性。研究发现，混合使用图像-文字、交错图像-文字和纯文字数据对实现少样本最先进结果(SOTA)至关重要。此外，图像编码器、图像分辨率和图像标记数量对结果有显著影响。作者构建了一个最高达30B参数的模型族MM1，通过大规模预训练实现了竞争性性能，并展现了吸引人的特性，能够实现少样本的连锁思维提示。 <div>
[CV] MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training  <br /><a href="https://arxiv.org/abs/2403.09611"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了多模态大型语言模型(MLLM)的构建，重点在于体系结构组件和数据选择的重要性。通过对图像编码器、视觉语言连接器和不同预训练数据选项的详尽剖析，揭示了几个关键设计经验。研究表明，混合使用图像-文字、交错图像-文字和纯文字数据对于实现多项基准测试中的少样本最先进结果(SOTA)至关重要。此外，图像编码器、图像分辨率和图像标记数量对结果有显著影响，而视觉-语言连接器设计的影响相对较小。作者通过扩大模型规模，构建了一个最高达30B参数的模型族MM1，包括密集型模型和专家混合型变体，这些模型在预训练度量上表现出色，并在一系列多模态基准测试中经过监督微调后获得了竞争性性能。MM1的大规模预训练赋予了它如上下文预测、多图像推理等吸引人的特性，使其能够实现少样本的连锁思维提示。<img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdzmld2pj21201iuapu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdzn0s90j21hk13aaq5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdznf268j21hk0tytm5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdznnj32j21hm0qiaiy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:32:13 GMT</pubDate>
</item>
<item>
<title>揭示了通过分析LLM API的输出，即便是在API保护下，仍能通过较少的成本就能获取大量关于大型语言模型(如OpenAI gpt-3.5-turbo)的私有参数和结构信息，强调了这种...</title>
<link>https://weibo.com/1402400261/O5d99bA9M</link>
<guid>https://weibo.com/1402400261/O5d99bA9M</guid>
<content:encoded><![CDATA[
<div> API保护、LLM、私有参数、结构信息、模型透明度、问责性、信息泄露、特性、分析、有效性<br />
<br />
提到了一种通过分析LLM API输出获取私有参数和结构信息的方法，即使在API保护下也能实现。强调了这种方法的有效性，指出可以将其作为一种特性来提高模型的透明度和问责性。文章的研究结果揭示了重要的信息泄露问题，也提示了提高模型透明度的重要性。这种方法对于模型的安全性和隐私保护具有重要影响，值得深入研究和思考。<br /><br />总结: 提出了一种通过分析LLM API输出泄露私有信息的方法，并强调了其有效性以及作为提高模型透明度和问责性的特性。 <div>
揭示了通过分析LLM API的输出，即便是在API保护下，仍能通过较少的成本就能获取大量关于大型语言模型(如OpenAI gpt-3.5-turbo)的私有参数和结构信息，强调了这种获取信息方法的有效性，指出如何将此作为一种特性来提高模型的透明度和问责性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) <a href="https://arxiv.org/abs/2403.09539"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdhz8pyhj21oc15s7p2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdhzlf91j21ks0w4wqg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdhzq3auj21ke0oigsg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdi02jdij21l80pe118.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdsgpg07j20ve0dy764.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdsgoh8fj20vg0dqq55.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdsgpg6xj20vd090aar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:25:44 GMT</pubDate>
</item>
<item>
<title>[CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) 网页链接...</title>
<link>https://weibo.com/1402400261/O5d8YfyGJ</link>
<guid>https://weibo.com/1402400261/O5d8YfyGJ</guid>
<content:encoded><![CDATA[
<div> API-Protected LLMs, Logits, Leakage, Proprietary Information, Privacy, Data Security, Machine Learning, Information Disclosure

总结:<br /><br />本文研究了API保护的语言模型（LLMs）的Logits可能泄漏专有信息的问题。研究人员发现，即使在API保护的情况下，LLMs的输出Logits也可能包含公司的机密信息。这种信息泄漏可能导致数据隐私和安全方面的问题。因此，需要采取相应的措施来确保机器学习模型不会泄露敏感信息，保障数据安全。 <div>
[CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) <a href="https://arxiv.org/abs/2403.09539"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdhz8pyhj21oc15s7p2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdhzlf91j21ks0w4wqg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdhzq3auj21ke0oigsg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdi02jdij21l80pe118.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdsgpg07j20ve0dy764.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdsgoh8fj20vg0dqq55.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdsgpg6xj20vd090aar.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:25:18 GMT</pubDate>
</item>
<item>
<title>提出一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来显著降低潜空间维数，同时保持或提升模型性能，并以更少的基函数构建相同的机器学习...</title>
<link>https://weibo.com/1402400261/O5d3xurjA</link>
<guid>https://weibo.com/1402400261/O5d3xurjA</guid>
<content:encoded><![CDATA[
<div> 关键词: Moment Pooling, 深度集网络, 多变量矩, 潜空间维数, 模型性能, 基函数, 机器学习观测值, 可视化, 解释.

总结:<br /><br />本文提出了一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来降低潜空间维数，以提升模型性能。这一方法能够在更少的基函数下构建相同的机器学习观测值，使得模型内部表示可以更简单地进行可视化和解释。 Moment Pooling 的应用可以显著简化潜在空间的维数，帮助提升模型的性能，并且使得模型更容易解释和理解。通过对多变量矩的运用，Moment Pooling 可以在保持甚至提升模型性能的同时，降低所需的基函数数量，从而简化模型构建和解释过程。这一方法有望为机器学习领域带来更高效和可解释的模型设计。 <div>
提出一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来显著降低潜空间维数，同时保持或提升模型性能，并以更少的基函数构建相同的机器学习观测值，使得模型内部表示的可视化和解释变得更加简单。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) <a href="https://arxiv.org/abs/2403.08854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdd9vs67j21is0gyk1g.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsddafjn1j21mo0w2472.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddapji1j21901amtg7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddav53cj20vi10c79w.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c6wmj20jp0o3q5d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6f420j2140147afj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6bkxyj20jp0litak.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsde6g62dj2140156dpr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6drm7j2140156jva.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:11:56 GMT</pubDate>
</item>
<item>
<title>[LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) 网页链接 ...</title>
<link>https://weibo.com/1402400261/O5d3oBouU</link>
<guid>https://weibo.com/1402400261/O5d3oBouU</guid>
<content:encoded><![CDATA[
<div> Streamlining, Latent Spaces, Machine Learning, Moment Pooling, MIT, Gambhir, Osathapan, Thaler, 2024

<br /><br />总结:
本文探讨了在机器学习中利用矩阵池化来简化潜在空间的方法。研究人员提出了一种称为Moment Pooling的新技术，通过将不同阶数的矩阵进行池化，从而提高了模型在学习高阶统计特性方面的能力。这种技术不仅能够提高模型的效率，还能够减少模型对大规模数据集的需求。研究还表明，Moment Pooling技术在训练时间和模型性能之间取得了良好的平衡，为机器学习领域的实践带来了新的启示。MIT的研究人员Gambhir、Osathapan和Thaler的工作为机器学习领域的发展提供了有益的思路和方法。 <div>
[LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) <a href="https://arxiv.org/abs/2403.08854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdd9vs67j21is0gyk1g.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsddafjn1j21mo0w2472.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddapji1j21901amtg7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddav53cj20vi10c79w.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c6wmj20jp0o3q5d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6f420j2140147afj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6bkxyj20jp0litak.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsde6g62dj2140156dpr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6drm7j2140156jva.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6ceorj20jp0l1dhh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6d31vj21400ki77c.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c36cj20jp0khgn1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6d5zdj20z20jpgny.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6dr66j20zc0jqtb4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:11:35 GMT</pubDate>
</item>
<item>
<title>创新性地提出了一个学习算法框架，用于在完全和部分知识情况下进行马尔可夫决策过程的验证，特别是在不需要MDP结构特性假设和时间界限的情况下，通过启发式方法...</title>
<link>https://weibo.com/1402400261/O5d2K9Lno</link>
<guid>https://weibo.com/1402400261/O5d2K9Lno</guid>
<content:encoded><![CDATA[
<div> 马尔可夫决策过程、学习算法、验证、完全知识、部分知识、MDP结构、时间界限、概率可达性、启发式方法、停止准则

<br /><br />总结:
该研究提出了一个学习算法框架，可用于验证马尔可夫决策过程，在完全和部分知识情况下，无需MDP结构特性假设和时间界限。通过启发式方法提供了概率可达性的精确和概率界，同时提出了适应性强的停止准则。这一创新性方法有望在解决复杂决策问题中发挥重要作用。 <div>
创新性地提出了一个学习算法框架，用于在完全和部分知识情况下进行马尔可夫决策过程的验证，特别是在不需要MDP结构特性假设和时间界限的情况下，通过启发式方法提供了概率可达性的精确和概率界，同时提出了适应性强的停止准则。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Learning Algorithms for Verification of Markov Decision Processes》T Brázdil, K Chatterjee, M Chmelik, V Forejt, J Křetínský, M Kwiatkowska, T Meggendorfer, D Parker, M Ujma [Google LLC &amp; IST Austria &amp; Lancaster University Leipzig] (2024) <a href="https://arxiv.org/abs/2403.09184"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdb2ek9bj210m0mb12q.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdb2s9l9j21ce0pwtbu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdb38x14j21n20lqq6c.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdb3sanvj21rg0ecwgs.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:09:58 GMT</pubDate>
</item>
<item>
<title>恭喜@sayfh_wu-wuy_su私人领域-_- 等3名用户获得【《SPSSAU科研数据分析方法与应用》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效...</title>
<link>https://weibo.com/1402400261/O56k4DmCh</link>
<guid>https://weibo.com/1402400261/O56k4DmCh</guid>
<content:encoded><![CDATA[
<div> SPSSAU, 数据分析, 科研, 应用, 抽奖, 微博, 研究方法, 问卷数据, 医学数据, 视频讲解

<br /><br />总结:
微博举办了一次抽奖活动，三名幸运用户将获得《SPSSAU科研数据分析方法与应用》。这本书系统介绍了科研数据分析方法，适合研究者快速学习和掌握。活动截止时间是2024年3月15日12:00，感兴趣的用户需要转发和评论才能参与。活动结果将通过微博官方唯一抽奖工具监督，公正有效。该书涵盖了数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等方面，并配有171集视频讲解，帮助研究者更好地理解科研数据分析方法。 <div>
恭喜<a href="https://weibo.com/n/sayfh_wu-wuy_su%E7%A7%81%E4%BA%BA%E9%A2%86%E5%9F%9F-_-">@sayfh_wu-wuy_su私人领域-_-</a> 等3名用户获得【《SPSSAU科研数据分析方法与应用》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20117566&amp;pageid=100140E51183068"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00，*可可粉*转发+评论即可参与。近万篇研究论文选用SPSSAU快速入门，本书从数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等五个方面系统地介绍科研数据的分析方法，涉及13项知识类应用（如影响关系、权重关系、数据预测、问卷研究）附赠171集配套视频讲解，适合研究者快速学习和掌握科研数据分析方法。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5009557898134749"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnj8n91y6bj20m80m8n19.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnj8n9h45kj20m80m8mzs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9rlbnj20m80m8tbk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9wj7pj20m80m80vr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 04:03:26 GMT</pubDate>
</item>
<item>
<title>【艺术成功之路：声誉与网络的量化分析】- 研究人员重建了50万名艺术家的展览历史，绘制出反映艺术在机构之间流动的共同展览网络。 - 在这个网络中的中心性捕捉...</title>
<link>https://weibo.com/1402400261/O54JlkeLD</link>
<guid>https://weibo.com/1402400261/O54JlkeLD</guid>
<content:encoded><![CDATA[
<div> 艺术家、声誉、网络、展览历史、职业轨迹、早期进入高声望机构、马尔可夫模型、原籍国、潜在政策、彩票系统

<br /><br />总结:研究人员通过重建艺术家展览历史，揭示了艺术界展览网络结构和声誉对艺术家职业成功的影响。进入声誉高的机构能提供终身影响，早期选择机构会影响职业轨迹。原籍国可影响艺术家初始声誉和职业发展，建议实施彩票系统以提高公平竞争。研究虽然量化了准入壁垒，但仍需关注艺术评估的主观性和非实物艺术形式。艺术家应在更广泛机构展出，挑战传统观点，同时要面对可能的阻力。不同原籍国在全球化艺术世界中仍对艺术家有影响，呼吁更多关注多维度的审视。 <div>
【艺术成功之路：声誉与网络的量化分析】<br />- 研究人员重建了50万名艺术家的展览历史，绘制出反映艺术在机构之间流动的共同展览网络。  <br />- 在这个网络中的中心性捕捉了机构的声望，允许分析单个艺术家在获取理想机构方面的职业轨迹。  <br />- 早期进入声望高、处于中心位置的机构，可以为艺术家提供终身进入高声望场所的机会，并降低退出率。  <br />- 从网络边缘开始职业生涯会导致高退出率，限制进入中心机构的机会。  <br />- 一个马尔可夫模型可以预测艺术家的职业轨迹，记录了艺术价值评估中强烈的路径依赖和历史依赖。  <br />- 艺术家最初声望(前五次展览)的分布因其原籍国而异，影响他们职业成功的机会。  <br />- 该研究量化了艺术界的分层和准入壁垒，提出了潜在的政策，如彩票系统，以营造公平的竞争环境。  <br /><br />思考：  <br />- 该研究提供了声誉和网络在主观领域(如艺术)中决定资源和回报获取的量化见解，在这些领域中很难客观衡量表现。  <br />- 早期进入声望高的机构会产生终身影响，这一发现挑战了精英制的概念，凸显了初始机会的重要性。  <br />- 该研究关注机构准入和经济价值，可能忽略了艺术丰富社会的其他维度，如文化和情感价值。  <br />- 艺术家原籍国影响其初始声望和职业轨迹，这一观察结果引发了对艺术界系统性偏见和不平等的质疑。  <br />- 建议在艺术界实施彩票系统或盲选程序以提高代表性不足艺术家的包容性，可能面临既得利益机构和艺术界的阻力。  <br />- 尽管该研究量化了准入壁垒，但并未直接解决艺术评估的主观性质以及评估过程中固有的潜在偏见。  <br />- 该研究依赖展览和拍卖数据，可能低估了非实物艺术形式，如行为艺术，因为这些艺术形式无法通过这些渠道捕捉。   <br />- 研究发现，在职业生涯早期在更广泛的机构展出可以提高突破的机会，这挑战了专注于特定领域或风格的传统观点。  <br />- 该研究建议在艺术界实施彩票系统或盲选程序，这些做法更常见于就业或音乐试演等领域。  <br />- 观察到艺术家的原籍国影响其初始声望和职业轨迹，这一点有悖常理，因为在全球化的艺术世界中，人们可能认为天赋与地理因素无关。<br />《Quantifying reputation and success in art | Science》 <a href="https://www.science.org/doi/10.1126/science.aau7224"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnrcnblrptj20u00x113j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 00:00:12 GMT</pubDate>
</item>
<item>
<title>【Cappy：用小型评分器提升大型语言模型性能】 - Google研究人员提出了一种名为Cappy的新方法，可以通过一个小型评分器(scorer)来提升和增强大型多任务语言模型...</title>
<link>https://weibo.com/1402400261/O54Dc9dTt</link>
<guid>https://weibo.com/1402400261/O54Dc9dTt</guid>
<content:encoded><![CDATA[
<div> Cappy, 小型评分器, 大型语言模型, 性能提升, 多任务, 输出质量, 灵活性, 高效性, 实际应用, 可扩展性

<br /><br />总结: 
Google研究人员提出了一种名为Cappy的新方法，通过引入一个小型评分器来提升和增强大型多任务语言模型的性能。Cappy利用评分器重新排序生成的候选输出，提高输出质量。评分器是一个轻量级神经网络模型，专门用于评估候选输出质量，并与大型语言模型结合。Cappy在多个基准测试中展现出优异性能，提高大型模型表现。该方法灵活性强，可与各种大型语言模型结合，适用于不同任务。尽管在基准测试中表现出色，实际应用场景中的效果和可扩展性还需进一步验证。Cappy的高效性和轻量设计或将受益于未来硬件发展，如专用AI加速器。然而，引入新的偏差和不确定性也需进一步研究和优化。Cappy为提高大型语言模型性能提供了新的范式。 <div>
【Cappy：用小型评分器提升大型语言模型性能】  <br />- Google研究人员提出了一种名为Cappy的新方法，可以通过一个小型评分器(scorer)来提升和增强大型多任务语言模型的性能。  <br />- Cappy利用一个小型评分器来重新排序大型语言模型生成的候选输出，从而提高输出质量。  <br />- 评分器是一个轻量级的神经网络模型，专门用于评估候选输出的质量，而不负责生成输出。  <br />- 在多个基准测试中，Cappy展现出优于大型语言模型的性能，同时也能够提升这些大型模型的表现。  <br />- Cappy的优势在于其高效性和灵活性，可以与各种大型语言模型相结合，并在不同任务上发挥作用。  <br />- 研究人员认为，Cappy为提高大型语言模型的性能和效率提供了一种新的范式。  <br /><br />思考：  <br />- Cappy的提出解决了大型语言模型在某些任务上表现不佳的问题，通过引入一个小型评分器来提升整体性能，这种思路值得关注。  <br />- 将生成和评估分离的方法使Cappy具有灵活性，可以与不同的大型模型相结合，提高了其适用范围。  <br />- 尽管Cappy在基准测试中表现出色，但其在实际应用场景中的效果和可扩展性仍有待进一步验证。  <br />- Cappy的高效性和轻量设计可能会受益于未来硬件的发展，如专用AI加速器等，从而进一步提升其性能。  <br />- 虽然Cappy旨在提高大型语言模型的性能，但其本身也可能引入新的偏差和不确定性，需要进一步研究和优化。<br />《Cappy: Outperforming and boosting large multi-task language models with a small scorer – Google Research Blog》 <a href="https://blog.research.google/2024/03/cappy-outperforming-and-boosting-large.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnrc7chdqkj21780go75q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc7csa3qj21jj0r3q63.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnrc7dkpzrj21jj0c6jv0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc7ffs7jj21jj0sw42p.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnrc7fyfiuj21hb0u0goi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:45:03 GMT</pubDate>
</item>
<item>
<title>【聊天机器人变身生产力助手：Command-R用Tool Use功能重塑业务工作流】- Cohere推出了Command-R模型的Tool Use功能，使语言模型能够与用户定义的工具交互，实现...</title>
<link>https://weibo.com/1402400261/O54B6h2pa</link>
<guid>https://weibo.com/1402400261/O54B6h2pa</guid>
<content:encoded><![CDATA[
<div> Command-R, Tool Use, 应用示例, 生产力助手, 跨平台, 自动化工作流程, 部署灵活性, 实施过程, AI应用, 语言模型

<br /><br />总结: 
Command-R推出了Tool Use功能，使语言模型能够与外部工具交互，执行复杂任务，提升生产力。该功能连接不同应用程序和系统，实现跨平台的自动化工作流程。结合Tool Use，Command-R从聊天机器人发展为强大的生产力助手和研究工具，可能改变AI交互方式。平衡了性能、效率和部署灵活性，适用于构建AI应用，突破了单一云环境的限制。企业实施Tool Use的简化四步过程降低了门槛，加速了应用，但需评估具体需求和系统兼容性。 <div>
【聊天机器人变身生产力助手：Command-R用Tool Use功能重塑业务工作流】<br />- Cohere推出了Command-R模型的Tool Use功能，使语言模型能够与用户定义的工具交互，实现高度复杂任务的自动化。  <br />- Command-R在Tool Use模式下可以根据用户交互和对话历史创建API负载(包含特定参数的JSON)，用于指示其他应用程序或工具。  <br />- Tool Use的应用示例包括自动分类和路由支持凭证、更新客户关系管理软件(CRM)中的状态，以及从向量数据库中检索相关片段。  <br />- 应用的输出会反馈给Command-R，用于生成最终响应。响应中包含引用，便于用户从源数据或工具结果中追溯声明。  <br />- Tool Use使Command-R的应用从简单的聊天机器人发展为强大的代理和研究工具，提高了生产力。  <br />- Command-R在高效率、强大性能和跨主要云提供商的灵活部署之间取得了平衡，是构建依赖Tool Use的AI应用的有竞争力的解决方案。  <br />- 在企业中实施Tool Use对开发人员来说是一个简单的四步过程。  <br /><br />思考：  <br />- Tool Use功能突破了语言模型仅限于自然语言处理的边界，使其能够与外部工具交互，执行复杂的任务和工作流程，开辟了语言模型应用的新领域。  <br />- Command-R与Tool Use的结合，使聊天机器人从简单的对话工具转变为强大的生产力助手和研究辅助工具，这可能改变我们与AI交互和协作的方式。  <br />- Tool Use通过自然语言交互连接不同的应用程序和系统，实现了跨平台的自动化工作流程，这种方法简化了复杂任务的自动化过程，提高了效率。  <br />- Command-R在性能、效率和部署灵活性方面的平衡，使其成为构建基于Tool Use的AI应用的理想选择，这表明语言模型的应用不再局限于单一的云环境。  <br />- 简化的四步实施过程降低了企业采用Tool Use的门槛，有望加速其在实际业务场景中的应用，但企业仍需评估其具体需求和现有系统的兼容性。<br />《Introducing Tool Use With Command-R: Seamlessly Automate Business Workflows》 <a href="https://txt.cohere.com/tool-use-with-command-r/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnrc23fa5bj20v40l83zo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc23o7u5j20qo0f00ue.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:39:53 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;携手@博文视点Broadview 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00...</title>
<link>https://weibo.com/1402400261/O54zSFqzU</link>
<guid>https://weibo.com/1402400261/O54zSFqzU</guid>
<content:encoded><![CDATA[
<div> SPSSAU、数据分析、研究方法、应用、科研、快速入门、知识类、视频讲解、研究者、学习

总结:<br /><br />今天开奖活动欢迎大家参与，“可可粉”转发+评论即可参与赢取《SPSSAU科研数据分析方法与应用》这本书。该书系统介绍了科研数据分析方法，包括数据分析入门、常用研究方法应用、数据综合评价与预测、问卷数据分析、医学数据分析等五个方面，涵盖了13个知识类应用，同时还附赠了171集配套视频讲解。这本书适合研究者快速学习和掌握科研数据分析方法，近万篇研究论文选择SPSSAU作为快速入门工具。截止日期为2024年3月15日。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00，*可可粉*转发+评论即可参与。近万篇研究论文选用SPSSAU快速入门，本书从数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等五个方面系统地介绍科研数据的分析方法，涉及13项知识类应用（如影响关系、权重关系、数据预测、问卷研究）附赠171集配套视频讲解，适合研究者快速学习和掌握科研数据分析方法。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5009557898134749"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnj8n91y6bj20m80m8n19.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnj8n9h45kj20m80m8mzs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9rlbnj20m80m8tbk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9wj7pj20m80m80vr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:36:53 GMT</pubDate>
</item>
<item>
<title>今日推介(第1345期)：基于在线偏好优化的大型语言模型与人类偏好对齐、自注意力的下一token预测机制 、持续预训练大型语言模型的简单可扩展策略、现代大规模数据...</title>
<link>https://weibo.com/1402400261/O548I0b8m</link>
<guid>https://weibo.com/1402400261/O548I0b8m</guid>
<content:encoded><![CDATA[
<div> 在线偏好优化、大型语言模型、人类偏好对齐、自注意力、下一token预测机制、持续预训练、简单可扩展策略、现代大规模数据集、偏差问题、过训练语言模型

总结:<br />
本篇文章介绍了基于在线偏好优化的大型语言模型与人类偏好对齐的方法，通过自注意力的下一token预测机制实现了优化。同时提出了一种简单可扩展的持续预训练大型语言模型的策略，探讨了现代大规模数据集是否还存在偏差问题，并研究了过训练语言模型在下游任务中的可靠性扩展。这些研究对于优化大型语言模型的训练方法和应用具有重要意义。 <div>
今日推介(第1345期)：基于在线偏好优化的大型语言模型与人类偏好对齐、自注意力的下一token预测机制 、持续预训练大型语言模型的简单可扩展策略、现代大规模数据集是否还存在偏差问题、过训练语言模型在下游任务中的可靠扩展 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687109258"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.15)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra0zsf8qj20k00aawf0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra126v1dj20k008gjsd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnra15w1cdj20k00c3mzg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra1b1fw5j20k00hsad3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra1dmuy3j20k00e1q56.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:29:56 GMT</pubDate>
</item>
<item>
<title>[CV] DAM: Dynamic Adapter Merging for Continual Video QA Learning 网页链接 介绍了一种名为DAM的视频问答(VidQA)持续学习方法，以解决灾难性遗忘问题、适应...</title>
<link>https://weibo.com/1402400261/O544i5YCV</link>
<guid>https://weibo.com/1402400261/O544i5YCV</guid>
<content:encoded><![CDATA[
<div> 动态适配器合并, 持续学习, VidQA, 适配器训练, 路由器函数, 跨域知识共享, 性能优于当前方法, 图像分类, 图像问答

总结:<br /><br />
这篇文章介绍了一种名为DAM的视频问答持续学习方法，旨在解决灾难性遗忘、适应新数据集、处理未知数据集输入以及促进跨域知识共享等挑战。DAM通过动态适配器合并，在训练过程中训练特定数据集的适配器并冻结预训练的视频语言骨干网络。在推理过程中，利用非参数路由器函数计算适配器相关性概率，动态合并适配器权重定制新的适配器实例进行VidQA预测，从而降低路由器预测不准确的影响并提升跨域知识共享。DAM在多个VidQA数据集上的表现优于当前持续学习方法，并在图像分类和图像问答任务上也具有明显优势。 <div>
[CV] DAM: Dynamic Adapter Merging for Continual Video QA Learning  <br /><a href="https://arxiv.org/abs/2403.08755"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为DAM的视频问答(VidQA)持续学习方法，以解决灾难性遗忘问题、适应持续到来的数据集、处理未知数据集的输入以及跨相似数据集域共享知识等挑战。DAM通过动态适配器合并，训练特定数据集的适配器并冻结预训练的视频语言骨干网络。推理时，DAM使用非参数路由器函数计算每个适配器的相关性概率，随后动态合并适配器权重，以定制新的适配器实例进行VidQA预测，从而降低路由器预测不准确的影响并促进跨域知识共享。DAM在多个VidQA数据集上的性能超过了当前最先进的持续学习方法，并且在图像分类和图像问答任务上也展现出显著优势。<img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9q1w748j212s1lm4i4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9q2da9lj21pc0zitl9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9q2wsp9j21pa1b6nc5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:19:03 GMT</pubDate>
</item>
<item>
<title>[CV] GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting 网页链接 介绍了一种名为GaussianImage的新的图像表示和压缩方...</title>
<link>https://weibo.com/1402400261/O541SxwIU</link>
<guid>https://weibo.com/1402400261/O541SxwIU</guid>
<content:encoded><![CDATA[
<div> GaussianImage, 2D高斯Splatting, GPU资源, 隐式神经表示, INR, 渲染算法, GPU内存占用, 拟合时间, 渲染速度, 向量量化技术

总结:<br /><br />该文章介绍了一种名为GaussianImage的新的图像表示和压缩方法，基于2D高斯Splatting技术。与依赖GPU资源且训练时间长的隐式神经表示(INR)不同，GaussianImage通过每个2D高斯的8个参数来表示图像，使用累积求和的新渲染算法。这一方法显著减少了GPU内存占用和拟合时间，同时提供了与INR相当的表示性能和更快的渲染速度。该方法配合现有向量量化技术的编解码器在实验中表现出与基于压缩的INR（如COIN和COIN++）相当的速率失真性能，同时实现了约1000 FPS的解码速度。初步概念验证显示，在使用部分比特回传编码时，该编解码器的性能超过了COIN和COIN++。 <div>
[CV] GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting  <br /><a href="https://arxiv.org/abs/2403.08551"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为GaussianImage的新的图像表示和压缩方法，基于2D高斯Splatting技术。不同于依赖GPU资源且训练时间长的隐式神经表示(INR)，GaussianImage通过每个2D高斯的8个参数来表示图像，用累积求和的新渲染算法。这一方法显著减少了GPU内存占用(至少减少3倍)和拟合时间(加快5倍)，同时提供了与INR相当的表示性能和更快的渲染速度(1500-2000 FPS)。此外，集成了现有向量量化技术的图像编解码器在实验中展现出了与基于压缩的INR(如COIN和COIN++)相当的速率失真性能，并实现了约1000 FPS的解码速度。初步概念验证还表明，使用部分比特回传编码时，该编解码器的性能超过了COIN和COIN++。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9jwd3olj213i1kw18a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9jwqeu2j21hq0t0qay.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr9jwv8uyj21hc0gudmi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr9jx0572j21ha0mi7a8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:13:07 GMT</pubDate>
</item>
<item>
<title>[CL] Gemma: Open Models Based on Gemini Research and Technology 网页链接 介绍了Google DeepMind团队开发的Gemma模型，这是一组基于Gemini研究和技术构建的...</title>
<link>https://weibo.com/1402400261/O53Z1zK3Y</link>
<guid>https://weibo.com/1402400261/O53Z1zK3Y</guid>
<content:encoded><![CDATA[
<div> Google DeepMind, Gemma, Gemini, 轻量, 开放, 性能, 安全性, Transformer, TPUv5e, 负责任
<br />
<br />
总结: 
Google DeepMind团队开发了基于Gemini研究和技术的Gemma模型，是一组轻量、开放的最新模型。Gemma在语言理解、推理和安全性方面表现出强大性能，在18项文本任务中有11项超越同等规模的开放模型。该模型使用了基于Transformer的架构，优化了多查询注意力、RoPE嵌入、GeGLU激活函数和RMSNorm等技术，并使用TPUv5e硬件和分布式系统技术进行训练。发布了规模为20亿和70亿参数的两种模型，提供了预训练和微调检查点。强调了负责任发布大型语言模型对提升安全性、促进技术公平获取和驱动创新的重要性。对模型的安全性和负责任也进行了全面评估。 <div>
[CL] Gemma: Open Models Based on Gemini Research and Technology  <br /><a href="https://arxiv.org/abs/2403.08295"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了Google DeepMind团队开发的Gemma模型，这是一组基于Gemini研究和技术构建的轻量、开放的最新模型。Gemma在语言理解、推理和安全性方面在学术基准测试中展现出强大的性能。发布了两种规模的模型(20亿和70亿参数)，提供了预训练和微调的检查点。Gemma在18项文本任务中的11项上超越了同等规模的开放模型，并对模型的安全性和负责任进行了全面评估。Gemma利用了基于Transformer的架构，优化了多查询注意力、RoPE嵌入、GeGLU激活函数和RMSNorm等技术。训练使用了TPUv5e硬件和先进的分布式系统技术。强调了负责任发布大型语言模型(LLM)对于提升前沿模型安全性、促进技术公平获取、严格评估现有技术和驱动创新的重要性。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9ckrwzaj215e1ia7qg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9cl1imxj21ee0suwjs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9clc1n5j20p40n6adb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9clj4cfj20pc0ksgoa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:06:05 GMT</pubDate>
</item>
<item>
<title>创新地研究了在过训练情况下的语言模型扩展律，并建立了模型困惑度与其在下游任务表现之间的关联，提供了在减少计算成本的同时有效预测模型表现的方法，挑战了只...</title>
<link>https://weibo.com/1402400261/O53WGwMw8</link>
<guid>https://weibo.com/1402400261/O53WGwMw8</guid>
<content:encoded><![CDATA[
<div> 扩展律、语言模型、过训练、模型困惑度、下游任务、关联、计算成本、预测、模型表现、传统观点

<br /><br />总结：
该研究创新地研究了语言模型在过训练情况下的扩展律，并建立了模型困惑度与在下游任务表现之间的关联。提供了一种方法，在减少计算成本的同时有效预测模型表现，挑战了传统观点认为只有在计算最优训练阶段才能应用扩展律的观点。Researchers在此研究中展示了语言模型在过训练时表现稳定，并且其性能与下游任务的表现存在关联。他们的研究结果具有实践意义，可以帮助在研究领域中更有效地运用语言模型。 <div>
创新地研究了在过训练情况下的语言模型扩展律，并建立了模型困惑度与其在下游任务表现之间的关联，提供了在减少计算成本的同时有效预测模型表现的方法，挑战了只有在计算最优训练阶段才能应用扩展律的传统观点。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University &amp; UT Austin &amp; Apple] (2024) <a href="https://arxiv.org/abs/2403.08540"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96ao77pj21ga0qanai.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96b57p7j21my15caoy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96bitojj21n61167jj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96c1k8zj21mi0xo49l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyggij210z0ken19.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz8taj21120ir78f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gyotij21120lln0l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gz5nqj21170oktd1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz9y5j21110fkacs.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:00:19 GMT</pubDate>
</item>
<item>
<title>[CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University...</title>
<link>https://weibo.com/1402400261/O53WE06Ly</link>
<guid>https://weibo.com/1402400261/O53WE06Ly</guid>
<content:encoded><![CDATA[
<div> Language models, scale, over-training, downstream tasks, reliability, Columbia University, UT Austin, Apple

<br /><br />总结:
这篇文章研究了语言模型在超过训练规模以及在下游任务中的表现，发现语言模型在这些情况下能够可靠地扩展，通过在哥伦比亚大学、德克萨斯大学奥斯汀分校和苹果公司的合作进行了实验。他们的研究结果为语言模型的发展提供了有益的参考，为今后的研究和应用提供了新的思路。 <div>
[CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University &amp; UT Austin &amp; Apple] (2024) <a href="https://arxiv.org/abs/2403.08540"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96ao77pj21ga0qanai.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96b57p7j21my15caoy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96bitojj21n61167jj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96c1k8zj21mi0xo49l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyggij210z0ken19.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz8taj21120ir78f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gyotij21120lln0l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gz5nqj21170oktd1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz9y5j21110fkacs.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gypmlj210y0hg42h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96h0bszj210z0umjxf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gzuksj21120pbafd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gzkggj21110j1whm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gypocj21110j1who.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyc00j21120domzf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96h0emmj21131blqc1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:00:13 GMT</pubDate>
</item>
</channel>
</rss>