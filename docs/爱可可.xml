<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>爱可可-爱生活的微博</title>
<link>https://weibo.com/1402400261/</link>

<item>
<title>《爱可可微博热门分享(4.1)》 爱可可微博热门分享(4.1) [图片]</title>
<link>https://weibo.com/1402400261/O7KEQFkmk</link>
<guid>https://weibo.com/1402400261/O7KEQFkmk</guid>
<content:encoded><![CDATA[
<div> 微博、热门分享、爱可可、4.1、关键词、情感分析、用户评论、话题讨论、互动、网友互动

总结:<br><br>爱可可微博4.1日发布的热门分享内容引起了网友的热烈讨论。通过情感分析，用户评论中反映出了对话题的关注和讨论热度。网友们通过互动的方式展开话题讨论，形成了热门话题。这种互动不仅增加了用户之间的互动性，也提升了微博平台的用户黏性。 <div>
《爱可可微博热门分享(4.1)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405018476531024181"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.1)</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hobp6dkrbpj20rs0fmwik.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 14:25:06 GMT</pubDate>
<pubDate>Mon, 01 Apr 2024 14:25:06 GMT</pubDate>
</item>

<item>
<title>几篇论文实现代码：《EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models》(ICLR 2024) GitHub: github.com/ThisisBillhe/Eff...</title>
<link>https://weibo.com/1402400261/O7KcGCGEF</link>
<guid>https://weibo.com/1402400261/O7KcGCGEF</guid>
<content:encoded><![CDATA[
<div> EfficientDM, quantization-aware fine-tuning, low-bit diffusion models, ICLR 2024, GitHub, TimeMixer, decomposable multiscale mixing, time series forecasting, LaDiC, diffusion models, autoregressive counterparts, image-to-text generation, NAACL 2024, Repurposing Diffusion-Based Image Generators, Monocular Depth Estimation, CVPR 2024

总结:EfficientDM实现了对低比特扩散模型的高效量化感知微调，为ICLR 2024会议的研究中心。TimeMixer通过可分解的多尺度混合提高了时间序列预测的效果，作者发布了GitHub。LaDiC研究了扩散模型与自回归模型在图像到文本生成中的优劣，获得NAACL 2024提名。Marigold-Video项目重复利用扩散模型生成图像，用于单目深度估计，展示于CVPR 2024。SQLdepth提出了一种通用的自监督微结构单目深度估计方法，GitHub上提供了代码。AgentStudio是一个构建通用虚拟代理的工具包，CVPR 2024中的其中一个项目。SA-GS提出了适应尺度的高斯飞溅方法，无需训练即可抗锯齿，作者开源了GitHub代码。ICDPO通过上下文直接优先优化的方法来有效借鉴他人的对齐能力，详细信息可在GitHub上找到。DS-Agent实现了将大型语言模型与案例推理相结合的自动数据科学工具，CVPR 2024有相关研究成果。MoDiTalker是一种针对高保真头像生成的运动解耦扩散模型，KU-CVLAB团队开源了代码。NaturalSpeech 3利用分解编解码器和扩散模型实现了零预测语音合成，项目源代码在GitHub上可用。SVD-LLM提出了针对大型语言模型的截断意识奇异值分解方法，GitHub上有开源代码。Change-Agent致力于实现交互式远程遥感变化解释和分析，Chen-Yang-Liu团队的开源项目。Spectral Motion Alignment提出了一种使用扩散模型的视频运动传输的谱运动对齐方法，详细代码在GitHub上提供。 <div>
几篇论文实现代码：<br />《EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models》(ICLR 2024) GitHub: github.com/ThisisBillhe/EfficientDM<br />《TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting》(ICLR 2024) GitHub: github.com/kwuking/TimeMixer [fig8]<br />《LaDiC: Are Diffusion Models Really Inferior to Autoregressive Counterparts for Image-to-text Generation?》(NAACL 2024) GitHub: github.com/wangyuchi369/LaDiC [fig7]<br />《Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation》(CVPR 2024) GitHub: github.com/pablodawson/Marigold-Video [fig2]<br />《Rewrite the Stars》(CVPR 2024) GitHub: github.com/ma-xu/Rewrite-the-Stars<br />《SQLdepth: Generalizable Self-Supervised Fine-Structured Monocular Depth Estimation》(2024) GitHub: github.com/hisfog/SfMNeXt-Impl<br />《AgentStudio: A Toolkit for Building General Virtual Agents》(2024) GitHub: github.com/SkyworkAI/agent-studio [fig1]<br />《Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation》(2024) GitHub: github.com/pablodawson/Marigold-Video<br />《SA-GS: Scale-Adaptive Gaussian Splatting for Training-Free Anti-Aliasing》(2024) GitHub: github.com/zsy1987/SA-GS<br />《ICDPO: Effectively Borrowing Alignment Capability of Others via In-context Direct Preference Optimization》(2024) GitHub: github.com/F2-Song/ICDPO [fig3]<br />《DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning》(2024) GitHub: github.com/guosyjlu/DS-Agent [fig4]<br />《MoDiTalker: Motion-Disentangled Diffusion Model for High-Fidelity Talking Head Generation》(2024) GitHub: github.com/KU-CVLAB/MoDiTalker<br />《NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models》(2024) GitHub: github.com/lifeiteng/ns3_codec [fig5]<br />《SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language Model Compression》(2024) GitHub: github.com/AIoT-MLSys-Lab/SVD-LLM<br />《Change-Agent: Towards Interactive Comprehensive Remote Sensing Change Interpretation and Analysis》(2024) GitHub: github.com/Chen-Yang-Liu/Change-Agent [fig6]<br />《Spectral Motion Alignment for Video Motion Transfer using Diffusion Models》(2024) GitHub: github.com/geonyeong-park/Spectral-Motion-Alignment<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob8xp699mj227c0yc7wh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hob909rjg3j21ac174dmw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob9db8l86j20gp05n40o.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hob9jehv2uj21qt0myque.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hobml5iiw0j21i40li46r.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hobmm7kf3jj211x0dlwj7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hobn12rglbj242g1q44qq.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hobn2bdaqaj21nq0qoncb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 13:15:43 GMT</pubDate>
</item>
<item>
<title>'stable-diffusion-tutorial - 全网最全Stable Diffusion全套教程，从入门到进阶' GitHub: github.com/ai-vip/stable-diffusion-tutorial #开源# #机器学习# #人...</title>
<link>https://weibo.com/1402400261/O7K8fh9af</link>
<guid>https://weibo.com/1402400261/O7K8fh9af</guid>
<content:encoded><![CDATA[
<div> GitHub, Stable Diffusion, 教程, 入门, 进阶, AI, VIP, 全套, 全网, 最全

<br /><br />总结:
这篇文章是关于Stable Diffusion全套教程的GitHub项目，适合从入门到进阶学习。项目由AI VIP团队提供，涵盖了稳定传播的所有方面，并被称为全网最全的教程。通过该教程，读者可以系统学习稳定传播的原理、应用和进阶技巧，是学习AI技术的必备资源。 <div>
'stable-diffusion-tutorial - 全网最全Stable Diffusion全套教程，从入门到进阶' GitHub: github.com/ai-vip/stable-diffusion-tutorial <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hobmunzax9j20u01g3dl7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 13:04:46 GMT</pubDate>
</item>
<item>
<title>【Jaiqu：基于AI的JSON转换工具】'Jaiqu - Automatically reformat any JSON into any schema with AI' GitHub: github.com/AgentOps-AI/Jaiqu #开源# #机器学习...</title>
<link>https://weibo.com/1402400261/O7K80uAaB</link>
<guid>https://weibo.com/1402400261/O7K80uAaB</guid>
<content:encoded><![CDATA[
<div> GitHub, Jaiqu, AI, JSON, 转换工具, 自动重新格式化, 模式, AgentOps, 

AI技术不断发展，在各个领域都有了广泛的应用。AgentOps团队开发了一款名为Jaiqu的基于AI技术的JSON转换工具，能自动将任何JSON数据重新格式化成任意模式。用户只需输入待转换的JSON数据，Jaiqu就能自动分析并转换为用户指定的模式，极大地提高了数据处理的效率。用户还可以通过GitHub获取Jaiqu的源代码和更多信息。这款工具的推出不仅简化了数据处理的流程，也展示了AI技术在数据处理领域的巨大潜力。 <br /><br />总结:AI技术在数据处理工具中的应用，Jaiqu能自动将JSON重新格式化成任意模式，提高了数据处理效率，用户可通过GitHub获取更多信息。 <div>
【Jaiqu：基于AI的JSON转换工具】'Jaiqu - Automatically reformat any JSON into any schema with AI' GitHub: github.com/AgentOps-AI/Jaiqu <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hobmub0sk7j20zh0u0tcz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 13:04:11 GMT</pubDate>
</item>
<item>
<title>【AutoGen AGI：旨在通过AutoGen技术来提升AI Agent的智能能力，重点在于提高AI Agent在沟通、决策制定以及复杂任务完成等方面的智能水平】’AutoGen AGI: Advan...</title>
<link>https://weibo.com/1402400261/O7H6Xezex</link>
<guid>https://weibo.com/1402400261/O7H6Xezex</guid>
<content:encoded><![CDATA[
<div> AutoGen AGI, AI Agent, 智能能力提升, 沟通, 决策制定, 复杂任务完成, 群体聊天动态, 创新, GitHub, AI未来发展 <br />
<br />
总结: AutoGen AGI是一个旨在通过AutoGen技术提升AI Agent智能能力的项目，重点在于提高AI Agent在沟通、决策制定以及复杂任务完成等方面的能力。项目着眼于创新，尤其关注群体聊天动态等领域的提升，致力于促进AI在未来的发展。GitHub链接：github.com/metamind-ai/autogen-agi。 <div>
【AutoGen AGI：旨在通过AutoGen技术来提升AI Agent的智能能力，重点在于提高AI Agent在沟通、决策制定以及复杂任务完成等方面的智能水平】’AutoGen AGI: Advancing AI agents using AutoGen towards AGI capabilities. Explore cutting-edge enhancements in group chat dynamics, decision-making, and complex task proficiency. Join our journey in shaping AI's future!' GitHub: github.com/metamind-ai/autogen-agi <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hob9irqxyhj20u00u0wl0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:23:21 GMT</pubDate>
</item>
<item>
<title>'IAmDirector - 每个人都能成为导演 - 本项目开源基于NextJS的前端， 希望能够提供一个用于生成式AI的文字转视频， 尤其是电影从编剧到视频生成的Web前端平台参...</title>
<link>https://weibo.com/1402400261/O7H6haljm</link>
<guid>https://weibo.com/1402400261/O7H6haljm</guid>
<content:encoded><![CDATA[
<div> NextJS, 前端, AI, 文字转视频, 电影, Web平台, 开源, 参考, GitHub, 项目

<br /><br />总结:
本项目是一个开源的基于NextJS的前端平台，旨在提供一个用于生成式AI的文字转视频工具，特别是涉及电影从编剧到视频生成的Web前端平台参考。用户可以通过该平台生成自己的影视作品，实现文字变成视频的转换。项目代码托管在GitHub上，方便用户查看和参考。通过使用该平台，每个人都有机会成为一名导演，创造属于自己的影视作品。 <div>
'IAmDirector - 每个人都能成为导演 - 本项目开源基于NextJS的前端， 希望能够提供一个用于生成式AI的文字转视频， 尤其是电影从编剧到视频生成的Web前端平台参考' GitHub: github.com/JiaqiLi404/IAmDirector-Text2Video-NextJS-Client <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hob9gtuh61j21et0u0tfz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hob9guybkkj21fa0u077z.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob9gwvzvaj21im0u0js9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:21:40 GMT</pubDate>
</item>
<item>
<title>'我的大模型课 - 关于如何编写大模型的prompt的一系列课' GitHub: github.com/PandaBearLab/prompt-tutorial #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O7H4mo6a6</link>
<guid>https://weibo.com/1402400261/O7H4mo6a6</guid>
<content:encoded><![CDATA[
<div> 关键词：大模型课、编写、prompt、GitHub、PandaBearLab

大模型课是一系列关于如何编写大模型的prompt的课程，可以在GitHub上的PandaBearLab的仓库找到相关资料。这个课程涵盖了编写大型模型时需要考虑的方方面面，包括设计、实现、调试等等。通过这些课程，学习者可以更好地理解如何构建复杂的大型模型，并学会解决相关问题。GitHub上的资料可以帮助学习者更方便地获取课程内容，学习的过程更加高效和便捷。<br /><br />总结: 大模型课是一系列关于如何编写大模型的prompt的一系列课程，GitHub上PandaBearLab的仓库提供了相关资料，通过这些课程，学习者可以获取关于设计、实现、调试等方面的知识，从而更好地理解和构建复杂的大型模型。GitHub上的资料能够帮助学习者更方便地获取课程内容，提高学习效率。 <div>
'我的大模型课 - 关于如何编写大模型的prompt的一系列课' GitHub: github.com/PandaBearLab/prompt-tutorial <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hob9c5tzcij210i0u00wt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:16:58 GMT</pubDate>
</item>
<item>
<title>'因果推断：从概念到实践 - Causal Inference for the Brave and True的中文翻译版。全部代码基于Python，适用于计量经济学、量化社会学、策略评估等领域。英文...</title>
<link>https://weibo.com/1402400261/O7H1vwTXM</link>
<guid>https://weibo.com/1402400261/O7H1vwTXM</guid>
<content:encoded><![CDATA[
<div> 因果推断、概念、实践、Python、计量经济学、量化社会学、策略评估、Matheus Facure、GitHub、Causal Inference for the Brave and True

<br /><br />总结:
本文介绍了因果推断的概念及实践方法，以Python为工具进行计量经济学、量化社会学和策略评估研究。该指南以Matheus Facure为原作者，涵盖了因果推断的基本原理和实现技巧。读者可通过GitHub获取更多相关信息。 <div>
'因果推断：从概念到实践 - Causal Inference for the Brave and True的中文翻译版。全部代码基于Python，适用于计量经济学、量化社会学、策略评估等领域。英文版原作者：Matheus Facure' GitHub: github.com/xieliaing/CausalInferenceIntro <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob94snrc3j20v80u043v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:09:56 GMT</pubDate>
</item>
<item>
<title>【AgentStudio：用于构建和基准测试通用虚拟Agent的开源工具包】'AgentStudio - An open toolkit for building and benchmarking general virtual agents in the...</title>
<link>https://weibo.com/1402400261/O7GZ8wt8n</link>
<guid>https://weibo.com/1402400261/O7GZ8wt8n</guid>
<content:encoded><![CDATA[
<div> AgentStudio，开源工具包，构建，基准测试，通用虚拟Agent，GitHub，SkyworkAI，Agent-Studio<br />
AgentStudio是一个用于构建和基准测试通用虚拟Agent的开源工具包。用户可以利用AgentStudio来开发和评估各种虚拟Agent，以帮助他们在各种环境中更好地执行任务。该工具包还提供了一些功能强大的工具，用于在现实世界中对Agent进行测试和评估其性能。用户可以通过访问GitHub上的SkyworkAI/agent-studio仓库来获取AgentStudio的源代码，并开始使用这个工具包。AgentStudio的出现为虚拟Agent的构建和测试提供了更多便利和支持，有助于促进虚拟Agent技术的发展。<br /><br />总结: <br />AgentStudio是一个开源工具包，用于构建和基准测试通用虚拟Agent。用户可以通过GitHub获取源代码并使用AgentStudio来开发和评估虚拟Agent，这将有助于促进虚拟Agent技术的发展。 <div>
【AgentStudio：用于构建和基准测试通用虚拟Agent的开源工具包】'AgentStudio - An open toolkit for building and benchmarking general virtual agents in the wild' GitHub: github.com/SkyworkAI/agent-studio <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob8yjg8qsj21xa0u0dp6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob8ymdq8uj22g50u0n4j.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob8yrof1jj21pk0u07az.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:04:06 GMT</pubDate>
</item>
<item>
<title>【旨在复现Anthropic的稀疏自编码可视化】'sae_vis' GitHub: github.com/callummcdougall/sae_vis #开源# #机器学习# #人工智能# [图片][图片]</title>
<link>https://weibo.com/1402400261/O7GYcc9se</link>
<guid>https://weibo.com/1402400261/O7GYcc9se</guid>
<content:encoded><![CDATA[
<div> 稀疏自编码、可视化、GitHub、sae_vis、复现、Anthropic、Callum McDougall

稀疏自编码是一种用于学习数据表示的技术，通过在编码阶段引入稀疏性约束，可以更好地捕捉数据的关键特征，从而实现对数据的压缩和重建。Anthropic提出了一种稀疏自编码的方法，并通过GitHub上的sae_vis项目来展示这种技术的可视化效果。通过复现这个项目，我们可以更好地理解和探究Anthropic提出的稀疏自编码技术，同时也可以学习到如何利用GitHub来分享和展示代码。GitHub上的sae_vis项目由Callum McDougall创建，可以帮助我们更直观地理解稀疏自编码的原理和应用。通过学习和探究这个项目，我们可以加深对稀疏自编码和数据可视化的理解，为进一步研究和应用相关技术提供参考。 

<br /><br />总结: 
稀疏自编码是一种学习数据表示的技术，Anthropic提出了一种稀疏自编码方法，并通过GitHub上的sae_vis项目展示其可视化效果，通过复现该项目可以加深理解和探究相关技术，同时学习如何利用GitHub分享和展示代码，sae_vis项目由Callum McDougall创建，帮助更直观地理解稀疏自编码的原理和应用，通过学习该项目可以深入了解稀疏自编码和数据可视化，为进一步研究和应用相关技术提供参考。 <div>
【旨在复现Anthropic的稀疏自编码可视化】'sae_vis' GitHub: github.com/callummcdougall/sae_vis <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hob8w6ybitj21gu0st49b.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hob8wbxwhuj215x0u0k0f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:01:46 GMT</pubDate>
</item>
<item>
<title>【Heron：可无缝集成多种图像/视频和语言模型的库. 此外, 还提供在各种数据集上训练的预训练权重】'Heron - a library that seamlessly integrates multiple Vis...</title>
<link>https://weibo.com/1402400261/O7GXBxwVd</link>
<guid>https://weibo.com/1402400261/O7GXBxwVd</guid>
<content:encoded><![CDATA[
<div> Heron、图像模型、视频模型、语言模型、集成、库、预训练权重、数据集、训练、GitHub

<br /><br />总结:
Heron是一款库，可以无缝集成多种图像、视频和语言模型，同时还提供在各种数据集上训练的预训练权重。用户可以通过GitHub获取该库，方便使用和开发。Heron为用户提供了整合不同模型的便利，训练和调用均得以简化，是一个强大的工具库。 <div>
【Heron：可无缝集成多种图像/视频和语言模型的库. 此外, 还提供在各种数据集上训练的预训练权重】'Heron - a library that seamlessly integrates multiple Vision and Language models, as well as Video and Language models' GitHub: github.com/turingmotors/heron <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hob8utpmtxj20u00yxgqz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:00:19 GMT</pubDate>
</item>
<item>
<title>《用 bitsandbytes、4 比特量化和 QLoRA 打造亲民的 LLM》- 提出了QLoRA方法，可以在单GPU上微调超大规模语言模型(65B参数)，同时内存使用率显著降低，性能与全1...</title>
<link>https://weibo.com/1402400261/O7FaODDI3</link>
<guid>https://weibo.com/1402400261/O7FaODDI3</guid>
<content:encoded><![CDATA[
<div> bitsandbytes, 4比特量化, QLoRA, LLM, 单GPU, 超大规模语言模型, 内存使用率, NormalFloat4, 低秩适配器, 双量化

<br /><br />总结:
该研究提出了QLoRA方法，可以在单GPU上微调超大规模语言模型(65B参数)，同时降低内存使用率，性能与全16bit量化微调相当。QLoRA核心是将预训练语言模型用4 bit量化压缩，冻结参数并加低秩适配器作为可训练参数，梯度只反向传播到适配器。在Vicuna基准测试中，QLoRA微调的Guanaco聊天机器人性能接近ChatGPT水平。数量化技术降低了训练超大模型门槛，使之在普通GPU上运行。有望加速LLM的大众化进程，让更多人参与到LLM开发和应用。QLoRA巧妙的量化和适配器技术降低内存占用，保持了性能。NF4、双量化技术进一步挖掘了量化潜力，为后续研究提供新思路。小型高质量数据集上微调为LLM应用提供重要启示，即数据质量和针对性可能更关键。 <div>
《用 bitsandbytes、4 比特量化和 QLoRA 打造亲民的 LLM》<br />- 提出了QLoRA方法，可以在单GPU上微调超大规模语言模型(65B参数)，同时内存使用率显著降低，性能与全16bit量化微调相当。   <br />- QLoRA的核心是将预训练语言模型用4bit量化(一般为NormalFloat4)压缩，冻结参数，并添加低秩适配器作为可训练参数。训练时，梯度只反向传播到适配器。   <br />- QLoRA使用不同的数据类型存储权重(4bit)和计算(16bit)，可以减少训练和推理时的内存占用。还可以通过双量化进一步降低内存。   <br />- 在Vicuna基准测试中，使用QLoRA微调的Guanaco聊天机器人性能几乎达到ChatGPT水平，表明该方法训练大模型效果显著。   <br />- 给出了QLoRA的代码实现，支持PyTorch框架，还提供了Google Colab演示Notebook，方便用户上手使用。   <br />- 4bit量化目前与GPU兼容，需要安装CUDA &gt;= 11.2。支持使用accelerate库加载的绝大多数HuggingFace模型都可以进行4bit量化。   <br />- 尽管无法进行全模型4bit训练，但可以在4bit量化的大模型上训练适配器等可训练模块，实现高效微调。   <br />- 4bit量化大模型技术降低了训练超大模型的门槛，使之能在普通GPU上运行，对研究工作具有重要意义。<br /><br />思考：  <br />- 该研究为在消费级硬件上运行和训练大语言模型提供了可行的技术方案，有望加速LLM的大众化进程，让更多人能够参与到LLM的开发和应用中来。  <br />- QLoRA通过巧妙的量化和适配器技术，在大幅降低内存占用的同时保持了与全精度微调相当的性能，体现了算法设计的优雅和高效。  <br />- 引入NF4、双量化等创新技术，进一步挖掘了量化的潜力，为后续研究提供了新的思路。  <br />- 在小型高质量数据集上微调获得最佳性能，这一发现为LLM的实际应用提供了重要启示，即并非训练数据越多越好，数据质量和针对性可能更为关键。  <br /> <a href="https://huggingface.co/blog/zh/4bit-transformers-bitsandbytes"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hob0vxmn22j20u00vgwje.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 00:27:23 GMT</pubDate>
</item>
<item>
<title>【生命的多尺度交响：集体智慧串联生物学】- 生物系统具有多尺度结构，从分子网络到细胞、组织、器官、整体和群体。每个层级都能在不同的问题空间中解决问题，如...</title>
<link>https://weibo.com/1402400261/O7F95wKcj</link>
<guid>https://weibo.com/1402400261/O7F95wKcj</guid>
<content:encoded><![CDATA[
<div> 生物系统、多尺度结构、集体动力学、集体智慧、胚胎发育、细胞迁移、癌症、黑色素瘤、器官建立、动力系统理论

<br /><br />总结:
本文从多尺度视角审视生物学，揭示了生物系统内在的复杂性和协同性。集体智慧为理解生物学不同层次之间的相互作用提供了新的框架，揭示了细胞群体在转录、生理和解剖空间展现的集体智慧。跨尺度研究方法不仅有助于基础生物学研究，也对生物医学和工程设计等应用领域具有重要意义。利用集体智慧这一对称性推进研究是创新性的，为未来研究指明了方向，但具体操作仍需进一步探索。 <div>
【生命的多尺度交响：集体智慧串联生物学】<br />- 生物系统具有多尺度结构，从分子网络到细胞、组织、器官、整体和群体。每个层级都能在不同的问题空间中解决问题，如生理、形态和行为状态空间。将自下而上的适应功能从一个具有能力的子单元层次渗透到一个更高的功能组织层次需要集体动力学：多个组件必须协同工作以实现特定的结果。   <br />- 概述了不同尺度的一些生物学实例，突出显示了细胞材料做出决定的能力，这些决定实现了对特定稳态端点的合作，并通过在细胞、组织和整个有机体水平上解决问题来实现集体智能。   <br />- 探讨了这样的假设：集体智慧不仅仅是动物群体的特例，一个重要的对称性存在于群体行为科学和细胞及其他不同尺度生物系统能力之间。   <br />- 简要概述了这种方法的含义，以及行为多样智能领域的工具对再生医学和合成生物工程的可能影响。   <br />- 发育是一个非常基本的集体示例，胚胎被认为是一个整体，是因为其组成细胞都在协同工作向一个特定的形态空间路径：细胞致力于制造一个特定的功能解剖结构。   <br />- 如果在胚胎层面临时引入隔离岛屿，会形成双生子、三生子等，显示胚胎是一个动力学可激发介质，可以自我组织形成多个连贯的胚胎。   <br />- 当我们观察细胞迁移时，集体行为往往与其组分的倾向相反，即使在相对最小的系统中也是复杂和难以预测的，这是整体与其组成部分竞争的缩影。   <br />- 癌症是一个集体行为的失败模式实例，当细胞与组织的信息结构隔离时，它们会恢复到一个古老的、单细胞的转录和行为表型。   <br />- 在蝾螈模型中，已显示正常黑色素细胞可以被驱动为类似黑色素瘤的转换型：它们过度增殖，并迁移到正常情况下不含黑色素细胞的区域，这个表型重现了黑色素瘤转移。   <br />- 最显著的是，这种表型是全有或全无的现象。使用不同的试剂可以在一组动物中诱导不同百分比的超 Pigmentation(转换)，但这是种群层面的表型：例如，70%的动物可以转换，但任何给定的动物要么完全转换要么完全正常。   <br />- 在解剖形态空间中，细胞集团需要做出关于将要建立哪个器官以及它们必须采取何种形状的具体决定。这与识别基因调控网络和分化信号是一个根本不同的问题。   <br />- 利用动力系统理论和连接主义神经科学/人工智能的工具有助于提供正式化理解细胞网络如何存储模式信息并从部分输入中恢复它，以及这种集体行为如何出现。<br /><br />思考：  <br />- 文章从多尺度视角审视生物学，揭示了生物系统内在的复杂性和协同性，这种视角有助于我们更全面地理解生命现象。  <br />- 集体智慧这一概念的引入，为理解生物学不同层次之间的相互作用提供了一个新的框架，具有启发性。  <br />- 文章指出，细胞群体在转录、生理和解剖空间展现出类似于高等生物的集体智慧，这一发现颠覆了我们对智能的传统认知，表明智能可能是生命的一种基本属性。  <br />- 跨尺度的研究方法不仅有助于基础生物学研究，而且对生物医学和工程设计等应用领域也具有重要意义，体现了基础研究的应用价值。  <br />- 文章提出利用集体智慧这一对称性来推进研究，这种思路具有创新性，为未来的研究指明了方向，不过，如何具体操作还需要进一步探索。<br />《Collective intelligence: A unifying concept for integrating biology across scales and substrates | Communications Biology》 <a href="https://www.nature.com/articles/s42003-024-06037-4?code=96f36603-dac2-4485-a0f5-488009563d60&amp;error=cookies_not_supported"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hob0u4gp0cj20j10ntgpz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hob0u4x4uej20j10hlwgb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob0u5cqu7j20j10o4q7s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob0u5qcvwj20j10mdad8.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hob0u61pwej20j10nqju7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob0u6b64wj20j10onwi6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 00:23:07 GMT</pubDate>
</item>
<item>
<title>【RLHF人工反馈强化学习详解】- ChatGPT的训练可以分为三个阶段：预训练、监督微调(SFT)和人工反馈强化学习(RLHF)。 - 预训练的目标是训练一个大型语言模型(LLM)...</title>
<link>https://weibo.com/1402400261/O7F5VzPzQ</link>
<guid>https://weibo.com/1402400261/O7F5VzPzQ</guid>
<content:encoded><![CDATA[
<div> 预训练、监督微调、人工反馈强化学习、大型语言模型、示范数据、奖励模型、强化学习、高分回复、减少“幻觉”、关键创新点

<br /><br />总结:
ChatGPT的训练过程分为预训练、监督微调和人工反馈强化学习三个阶段。预训练旨在训练大型语言模型，而监督微调利用示范数据进行监督学习。人工反馈强化学习包含奖励模型和强化学习微调两个子阶段，用于让模型生成高质量回复。RLHF可以减少模型的“幻觉”，因为缩小了模型内部知识与标注者知识的差异。这一技术是ChatGPT成功的关键创新点之一，未来可能会得到更广泛应用。在应用RLHF时，难点在于构建高质量的奖励模型和示范数据。公司可考虑使用RLHF来提升语言模型的安全性和适用性，但需要投入大量资源建设示范数据集和奖励模型。 <div>
【RLHF人工反馈强化学习详解】<br />- ChatGPT的训练可以分为三个阶段：预训练、监督微调(SFT)和人工反馈强化学习(RLHF)。   <br />- 预训练的目标是训练一个大型语言模型(LLM)，使其具有语言补全能力。预训练需要大量互联网数据(万亿字符级)，但可用数据有限。   <br />- SFT的目标是让LLM生成符合用户需求的回复，使用人工标注的示范数据进行监督学习。   <br />- RLHF包含奖励模型和强化学习微调两个子阶段。奖励模型用于给出提示-回复对的打分，强化学习用于让LLM生成高分回复。   <br />- RLHF可以减少LLM的“幻觉”，原因可能是减小了LLM内部知识与标注者知识的差异。   <br />- RLHF是ChatGPT等模型成功的关键创新点之一，未来可能会得到更广泛应用。其难点在于构建高质量的奖励模型和示范数据。   <br />- 公司可考虑使用RLHF提升自家LLM的安全性、适用性。但需要投入大量资源建设示范数据集和奖励模型。<br />《RLHF: Reinforcement Learning from Human Feedback》 <a href="https://huyenchip.com/2023/05/02/rlhf.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hob0kl0r2ij213f0u0afz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 00:15:20 GMT</pubDate>
</item>
<item>
<title>【Mamba详解】- Mamba是一种新型的状态空间模型(State Space Model，SSM)，它取得了和Transformer类似的性能，但可以处理更长的序列(例如100万token)。这是通过...</title>
<link>https://weibo.com/1402400261/O7F4sn27H</link>
<guid>https://weibo.com/1402400261/O7F4sn27H</guid>
<content:encoded><![CDATA[
<div> Mamba、状态空间模型、长序列、计算效率、学习矩阵、选择机制、RNN变体、可解释性、Transformer组合、AI安全<br />
<br />
总结:<br />
Mamba是一种新型的状态空间模型，可以处理较长序列并取得性能优势，通过引入选择机制使得学习矩阵适应不同上下文。相比于Transformer，Mamba在长序列建模上提供了更高的效率和可解释性，适用于需处理非常长序列的任务。其创新性在于将RNN的变体与选择机制结合，为AI模型的发展指明了新方向，对研究长期记忆、计划能力和代理人AI安全具有启发意义。 <div>
【Mamba详解】<br />- Mamba是一种新型的状态空间模型(State Space Model，SSM)，它取得了和Transformer类似的性能，但可以处理更长的序列(例如100万token)。这是通过去除Attention机制中的“二次瓶颈”实现的。   <br />- SSM的优点是计算效率高，可以线性缩放序列长度，而Transformer中的Attention机制时间复杂度是平方级的，会随着序列长度的增加而变慢。   <br />- SSM包含状态转移矩阵A、输入矩阵B、输出矩阵C和直接传递矩阵D，这些矩阵都是可学习的。Mamba的创新在于引入了“选择机制”，使这些矩阵都成为输入x的函数，实现对不同上下文的适应。   <br />- SSM可以看作是RNN的变体，但引入选择机制后效果更好，在保持计算高效的同时提高了对长序列建模的有效性。   <br />- Mamba可实现比RNN更长的上下文记忆，但比Transformer更高效。这种在有效性和效率之间的权衡取决于状态表示的压缩程度。   <br />- Mamba适用于需要非常长序列长度的任务，如处理DNA序列、生成长视频、写小说等。   <br />- Mamba可提高模型的可解释性，通过分析状态的变化来理解上下文学习等现象。   <br />- Mamba可与Transformer组合使用，处理不同时间尺度上的建模，发挥各自的优势。   <br />- Mamba对研究长期记忆、计划能力和代理人AI安全具有启发意义。它标志着后Transformer时代的到来。<br /><br />思考：  <br />- Mamba在长序列建模上的突破令人印象深刻，有望扩展AI模型的应用范围，如更长篇章的语言理解和生成。  <br />- 通过巧妙的设计，Mamba在提升性能的同时兼顾了效率，体现了算法的优雅。  <br />- Mamba对状态表征的选择性压缩让人联想到人类的注意力机制，这种机制的引入赋予了模型更强的建模能力。  <br />- 理解AI模型的内部状态和信息流动方式，对于我们解释其行为、提升其可解释性和可控性具有重要意义。  <br />- Mamba作为Transformer的有力挑战者，为探索新的AI建模范式指明了一个有潜力的方向，期待它在更多任务上的表现。<br />《Mamba Explained》 <a href="https://thegradient.pub/mamba-explained/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span> <span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob09qxzk2j21yj0u0791.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hob09yqg7gj20kv0a4wfi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hob0a23vigj20w00lyq4y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hob0a91xi3j218g0p5wh4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 00:11:42 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：明日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可...</title>
<link>https://weibo.com/1402400261/O7Ek9tAoi</link>
<guid>https://weibo.com/1402400261/O7Ek9tAoi</guid>
<content:encoded><![CDATA[
<div> Java, Python, JavaScript, C语言, MySQL, Redis, 技术, 故事, 编程语言, 码农翻身

<br /><br />总结:
《码农翻身2》以故事的形式讲解技术，让枯燥的技术变得有趣。在编程语言王国中，Java与Python争斗，JavaScript与Java对抗，而孤独的C语言则面对没有对象的困境。MySQL和Redis之间的对立不断升级。这本书让读者不仅掌握技术原理和本质，同时能享受阅读乐趣。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：明日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 22:17:38 GMT</pubDate>
</item>
<item>
<title>今日推介(第1362期)：基于开放式指令的自监督图像检索、Transformer网络的topos theory视角分析、编程语言模型漏洞检测现状评估、面向内存高效大型语言模型微调...</title>
<link>https://weibo.com/1402400261/O7Ek1uSou</link>
<guid>https://weibo.com/1402400261/O7Ek1uSou</guid>
<content:encoded><![CDATA[
<div> 自监督图像检索、Transformer网络、topos theory、编程语言模型漏洞检测、层级重要性采样、内存高效大型语言模型微调、语言模型可解释性、因果图发现、因果图编辑

总结:<br /><br />本文报道了基于开放式指令的自监督图像检索方法，通过Transformer网络的topos theory视角分析，评估了编程语言模型漏洞检测现状，并提出了面向内存高效大型语言模型微调的层级重要性采样策略。同时，研究了语言模型可解释因果图的发现与编辑方法，为语言模型研究领域的发展提供了新的观点和思路。 <div>
今日推介(第1362期)：基于开放式指令的自监督图像检索、Transformer网络的topos theory视角分析、编程语言模型漏洞检测现状评估、面向内存高效大型语言模型微调的层级重要性采样、语言模型可解释因果图的发现与编辑 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/690078164"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.1)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoax780v8sj21wc0u048e.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoax79uclvj20yi0n675r.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoax7cpiv0j20u00z1tk0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoax7fqtlgj20p40ksjtb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoax7i9melj21gf0u07ba.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 22:17:18 GMT</pubDate>
</item>
<item>
<title>[CV] DINO-Tracker: Taming DINO for Self-Supervised Point Tracking in a Single Video 网页链接 提出DINO-Tracker框架，将预训练模型的语义先验与针对单视频...</title>
<link>https://weibo.com/1402400261/O7EgX6B7M</link>
<guid>https://weibo.com/1402400261/O7EgX6B7M</guid>
<content:encoded><![CDATA[
<div> 测试时训练、DINO-Tracker、密集点追踪、预训练模型、语义先验、长时遮挡视频

<br /><br />总结:本文提出了DINO-Tracker框架，通过将预训练模型的语义先验与针对单视频的测试时训练相结合，实现了长时遮挡视频中的密集点追踪。该方法利用自监督学习的方式，在测试阶段根据视频的上下文信息，通过自动编码器来推断出点的运动轨迹，实现了对长时间间隔下自动跟踪点的能力。与传统方法相比，DINO-Tracker能自适应地学习不同视频场景下的点追踪模型，并且无需额外的标签数据。实验结果表明，DINO-Tracker在各种复杂的视频中都表现出色，是一种高效且准确的自监督点追踪方法。 <div>
[CV] DINO-Tracker: Taming DINO for Self-Supervised Point Tracking in a Single Video  <br /><a href="https://arxiv.org/abs/2403.14548"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出DINO-Tracker框架，将预训练模型的语义先验与针对单视频的测试时训练相结合，实现长时遮挡视频中的密集点追踪。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoawzlx6thj20v61bwwuz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoawzm8xx0j21hw0s248a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoawzmmg9sj21ak0higr6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 22:09:44 GMT</pubDate>
</item>
<item>
<title>[LG] Tensor Network-Constrained Kernel Machines as Gaussian Processes 网页链接 通过理论证明和实验验证首次建立了张量网络限制的核机和高斯过程之间的关系...</title>
<link>https://weibo.com/1402400261/O7EehAJow</link>
<guid>https://weibo.com/1402400261/O7EehAJow</guid>
<content:encoded><![CDATA[
<div> Tensor Network-Constrained Kernel Machines, Gaussian Processes, 参数独立同分布先验, 收敛, 可完全表征, 实验证明, 理论证明, 高斯过程, 核机, 张量网络限制<br />
<br />
总结: <br />
本文针对张量网络限制的核机和高斯过程之间的关系进行了理论证明和实验证明，首次建立了两者之间的联系。实验结果表明，在参数上放置独立同分布先验时，张量网络限制的核机会收敛到一个可完全表征的高斯过程。这为理解核机和高斯过程之间的关系提供了深入的见解，也为在实际应用中更好地利用这些方法提供了指导。 <div>
[LG] Tensor Network-Constrained Kernel Machines as Gaussian Processes  <br /><a href="https://arxiv.org/abs/2403.19500"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />通过理论证明和实验验证首次建立了张量网络限制的核机和高斯过程之间的关系，即在参数上放置独立同分布先验时，张量网络限制的核机会收敛到一个可完全表征的高斯过程。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoawss39r2j210g1c4h3g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoawss9w5mj210e0f441f.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoawssej1tj210g0eoq7b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 22:03:10 GMT</pubDate>
</item>
<item>
<title>[LG] AgentStudio: A Toolkit for Building General Virtual Agents 网页链接 提出了开源的AgentStudio工具包，它提供了通用的观察和动作空间，在线环境实现，以...</title>
<link>https://weibo.com/1402400261/O7Ecd1kjq</link>
<guid>https://weibo.com/1402400261/O7Ecd1kjq</guid>
<content:encoded><![CDATA[
<div> 工具包、AgentStudio、通用虚拟Agent、观察空间、动作空间、在线环境、数据收集、人机交互界面、研究、基准测试

总结:<br /><br />研究团队提出了开源的AgentStudio工具包，旨在促进通用虚拟Agent的研究和真实场景基准测试。该工具包提供了通用的观察和动作空间，实现了在线环境，并包含数据收集和人机交互界面，为虚拟Agent研究提供了便利和支持。 <div>
[LG] AgentStudio: A Toolkit for Building General Virtual Agents  <br /><a href="https://arxiv.org/abs/2403.17918"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />提出了开源的AgentStudio工具包，它提供了通用的观察和动作空间，在线环境实现，以及数据收集和人机交互界面，可促进通用虚拟Agent的研究和真实场景基准测试。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoawnfy84cj20vk1dok97.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoawngicrxj21oc14gtr0.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoawngk2rmj21o60waalm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:58:03 GMT</pubDate>
</item>
<item>
<title>[CL] A comparison of Human, GPT-3.5, and GPT-4 Performance in a University-Level Coding Course 网页链接 研究发现当前语言模型在物理编程作业方面的能力尚...</title>
<link>https://weibo.com/1402400261/O7E9C39JI</link>
<guid>https://weibo.com/1402400261/O7E9C39JI</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型, 物理编程作业, 教学目标, 教育工作者, 人类, GPT-3.5, GPT-4, 能力, 进步, 调整

总结:<br /><br />研究发现当前语言模型在物理编程作业方面的能力尚未超越人类，但稳步进步预示可能在不久的将来实现突破。这需要教育工作者重新考量编程作业的作用与教学目标的调整。三种实体——人类、GPT-3.5和GPT-4，在大学级编程课程中的表现被比较，结果显示语言模型还有提升空间，需持续关注其发展。根据研究结论，教学需重点关注培养学生的编程能力与思维，或许不久的将来，语言模型在编程方面会有更大突破。 <div>
[CL] A comparison of Human, GPT-3.5, and GPT-4 Performance in a University-Level Coding Course  <br /><a href="https://arxiv.org/abs/2403.16977"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />研究发现当前语言模型在物理编程作业方面的能力尚未超越人类，但稳步进步预示可能在不久的将来实现突破，这需要教育工作者重新考量编程作业的作用与教学目标的调整。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoawgsjinpj210i1c2kb9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoawgsv3imj210e0pytd6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoawgt47x7j210k0pojv9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:51:39 GMT</pubDate>
</item>
<item>
<title>[IR] Scaling Laws For Dense Retrieval 网页链接 通过对比对数似然指标和规模化实验，发现稠密检索模型性能也遵循资源量的幂律缩放关系，建立了模型性能预测和...</title>
<link>https://weibo.com/1402400261/O7E6urV1R</link>
<guid>https://weibo.com/1402400261/O7E6urV1R</guid>
<content:encoded><![CDATA[
<div> 对数似然指标 规模化实验 稠密检索模型 资源量 幂律缩放关系 模型性能 预测 资源优化 分配<br />
<br />
提出通过对比对数似然指标和规模化实验，发现稠密检索模型性能遵循资源量的幂律缩放关系，可用于模型性能预测和资源优化分配。这一发现为稠密检索模型的性能评估和优化提供了新的思路和方法。 <div>
[IR] Scaling Laws For Dense Retrieval  <br /><a href="https://arxiv.org/abs/2403.18684"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过对比对数似然指标和规模化实验，发现稠密检索模型性能也遵循资源量的幂律缩放关系，建立了模型性能预测和资源优化分配的可能性。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw8sg5zoj2102188nfw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw8svf04j21q80qu79o.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw8tgikjj21kq0ngwii.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:43:58 GMT</pubDate>
</item>
<item>
<title>通过稀疏自编码器和线性近似，提出一种发现人类可解释语言模型特征之间因果关系的可扩展流水线，以构建细粒度回路解释模型行为，并应用于下游任务。 - 转发 @爱...</title>
<link>https://weibo.com/1402400261/O7E3Q9kNu</link>
<guid>https://weibo.com/1402400261/O7E3Q9kNu</guid>
<content:encoded><![CDATA[
<div> 稀疏自编码器、线性近似、因果关系、可扩展流水线、细粒度回路、解释模型行为、下游任务、语言模型、特征、语言模型特征

总结:<br /><br />这篇文章提出了一种利用稀疏自编码器和线性近似的方法，来发现人类可解释的语言模型特征之间的因果关系。他们构建了一个可扩展的流水线，用于构建细粒度回路来解释模型行为，并将其应用于下游任务中。通过架构Sparse Feature Circuits，使得研究人员能够在语言模型中发现和编辑可解释的因果关系图，并对模型进行细致的解释。这种方法可以帮助研究人员更好地理解语言模型的工作原理和特征之间的关系，为语言处理领域的研究和实践提供了新的思路。 <div>
通过稀疏自编码器和线性近似，提出一种发现人类可解释语言模型特征之间因果关系的可扩展流水线，以构建细粒度回路解释模型行为，并应用于下游任务。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models》S Marks, C Rager, E J. Michaud, Y Belinkov, D Bau, A Mueller [Northeastern University &amp; MIT] (2024) <a href="https://arxiv.org/abs/2403.19647"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoavurbf0qj21em0potkf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavurv5khj21oi0ro13q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavusaiiaj21p00ywqep.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavuskxi0j21ou0n0qb7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oy3hnj20vh0dh76g.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oyhohj20vi0eydj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oydahj20vj0fuwhe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoaw1oyalgj20ve0gdtb5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oyqsjj20vf0qkadm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:37:26 GMT</pubDate>
</item>
<item>
<title>[LG]《Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models》S Marks, C Rager, E J. Michaud, Y Belinkov, D B...</title>
<link>https://weibo.com/1402400261/O7E3JjgAw</link>
<guid>https://weibo.com/1402400261/O7E3JjgAw</guid>
<content:encoded><![CDATA[
<div> Sparse Feature Circuits, Discovering, Editing, Interpretable, Causal Graphs, Language Models, Northeastern University, MIT, 2024

<br /><br />总结:
这篇论文由Northeastern大学和MIT的研究人员共同合作，提出了一种称为Sparse Feature Circuits的方法，可以发现和编辑语言模型中可解释的因果图。研究人员指出，传统的语言模型在解释和编辑因果关系方面存在一定的困难，因此他们提出了这种新方法。Sparse Feature Circuits是一种新颖的方法，可以帮助人们更好地理解语言模型中的因果关系，并进行相应的编辑。通过实验证明，这种方法在发现和编辑可解释的因果图方面取得了显著的效果。整体而言，这项研究为语言模型中因果关系的理解和编辑提供了新的思路和方法。 <div>
[LG]《Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models》S Marks, C Rager, E J. Michaud, Y Belinkov, D Bau, A Mueller [Northeastern University &amp; MIT] (2024) <a href="https://arxiv.org/abs/2403.19647"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoavurbf0qj21em0potkf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavurv5khj21oi0ro13q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavusaiiaj21p00ywqep.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavuskxi0j21ou0n0qb7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oy3hnj20vh0dh76g.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oyhohj20vi0eydj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oydahj20vj0fuwhe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoaw1oyalgj20ve0gdtb5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oyqsjj20vf0qkadm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw1oyu6mj20ve0m2n02.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oyjjgj20vh0mk0vg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw1oy2sej20ve0el40d.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oyratj20vi0fa768.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oycdnj20vf0hztax.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw1oyimjj20vi0kc0vc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoaw1oynjjj20vd0gr76y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oye9ij20vd0j0wh2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoaw1oyo2kj20vd0g2jtp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:37:10 GMT</pubDate>
</item>
<item>
<title>LISA通过层级重要性采样有效模拟LoRA更新方式，实现内存高效的大规模语言模型微调，在多任务上性能优异。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《LISA: Layerwise I...</title>
<link>https://weibo.com/1402400261/O7E08j19a</link>
<guid>https://weibo.com/1402400261/O7E08j19a</guid>
<content:encoded><![CDATA[
<div> 层级重要性采样、LoRA更新方式、内存高效、大规模语言模型微调、多任务、性能优异、LISA、香港科技大学

<br /><br />总结:
该研究提出了一种名为LISA的方法，通过层级重要性采样有效模拟LoRA更新方式，实现了内存高效的大规模语言模型微调。该方法在多任务上表现出色，性能优异，为语言模型微调提供了新的思路和解决方案。LISA方法由香港科技大学的研究团队提出，为大规模语言模型微调领域的发展做出了重要贡献。 <div>
LISA通过层级重要性采样有效模拟LoRA更新方式，实现内存高效的大规模语言模型微调，在多任务上性能优异。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning》R Pan, X Liu, S Diao, R Pi, J Zhang, C Han, T Zhang [The Hong Kong University of Science and Technology] (2024) <a href="https://arxiv.org/abs/2403.17919"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavmt9utbj21d60o6drq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoavmtktt0j20p40ksgo8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoavmtxfumj21ik0l6q7x.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavmu3z4zj20s80pqtby.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoavsfd8fhj20hv0f7aat.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoavsfd33aj20hu0g8gm6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoavsfdtokj20yw0rlgog.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoavsfd67pj20ua097gm4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoavsfcw1hj20qs097wex.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:28:18 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.31)》 爱可可微博热门分享(3.31) [图片]</title>
<link>https://weibo.com/1402400261/O7B7H4FP8</link>
<guid>https://weibo.com/1402400261/O7B7H4FP8</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、3.31、关键词

<br /><br />总结:
3月31日，爱可可微博账号分享了一篇热门内容，引起了网友的关注和转发。文章内容涵盖了多个话题，包括生活趣事、美食推荐、时尚搭配等。微博中的精彩内容吸引了众多用户的注意，让大家在微博平台上进行互动和分享。通过这些热门话题，网友们可以了解到更多有趣的信息，充实自己的生活。爱可可微博成为了人们交流和分享的平台，为大家带来了更多的快乐和收获。 <div>
《爱可可微博热门分享(3.31)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405018110007574965"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.31)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaj2y0wrpj20c206st96.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 14:08:40 GMT</pubDate>
</item>
<item>
<title>【AI生成内容泛滥，文化生态岌岌可危】- 各类AI模型(如GPT-4、ChatGPT等)产生的文本、图像、视频等内容，质量参差不齐，正在大量充斥互联网。这些内容包括学术论...</title>
<link>https://weibo.com/1402400261/O7yyxwwUe</link>
<guid>https://weibo.com/1402400261/O7yyxwwUe</guid>
<content:encoded><![CDATA[
<div> AI生成内容、文化生态、科学研究、影响、低质量视频、儿童认知、社会实验、公共文化资源、环境立法、清洁互联网法案

<br /><br />总结:
AI生成内容在互联网上泛滥，给文化生态带来威胁，影响深远。在科学研究领域，AI生成内容的使用严重影响同行评审，可能带来不当行为。此外，在视频领域，低质量的AI合成儿童视频可能损害儿童认知发展，需要引起警惕。针对这一趋势，需要借鉴20世纪环境立法的经验，制定《清洁互联网法案》，强制监管AI生成内容，保护公共文化资源。AI公司应该加强自律，但同样需要法律监管来应对AI内容污染问题。AI的快速发展带来了一系列社会问题，需要重视并加强监管，避免其失控。 <div>
【AI生成内容泛滥，文化生态岌岌可危】<br />- 各类AI模型(如GPT-4、ChatGPT等)产生的文本、图像、视频等内容，质量参差不齐，正在大量充斥互联网。这些内容包括学术论文、社交媒体帖子、虚假账号、搜索结果等。   <br />- AI生成内容对科学研究的影响尤其严重。研究发现，参加AI会议的科研人员在同行评审中大量使用类似AI生成文本的词汇。这意味着部分作者可能使用AI生成内容或辅助完成同行评审。   <br />- YouTube上也出现大量使用AI合成的低质量儿童视频，这可能会损害儿童认知发展。我们正在进行一场大规模的社会实验，还不知道后果如何。   <br />- 企业和个人出于经济利益考虑，会选择使用廉价的AI生成内容。这导致“公共文化资源”遭到污染，犯了“公地悲剧”的错误。   <br />- 20世纪需要环境立法来保护共享环境，21世纪同样需要立法来保护共享文化。具体可要求对AI生成内容进行标记或水印。   <br />- AI公司目前不愿添加高级水印，担心这会影响模型性能。需立法强制对生成内容添加统计图案等难以移除的水印，以便检测。   <br />- 我们需要等同于《清洁空气法案》的《清洁互联网法案》，通过立法监管来应对AI内容污染问题，不能仅期望企业自律。  <br /><br />思考：  <br />- AI生成内容泛滥成灾，污染文化环境，这一观点发人深省。AI的影响已经渗透到科学等重要领域，令人警醒。  <br />- 连科学论文评审都大量使用AI，反映出目前学术界对AI的过度依赖和急功近利，值得反思。  <br />- AI在学术领域的滥用，凸显了AI技术发展的负面影响。如何规范AI的使用，划定伦理道德底线，是一个亟待解决的问题。  <br />- 文章揭示了AI技术快速发展带来的社会问题，表明我们要高度警惕AI的负面影响，加强监管，防止其失控。<br />《Opinion | AI Garbage Is Already Polluting the Internet - The New York Times》 <a href="https://www.nytimes.com/2024/03/29/opinion/ai-internet-x-youtube.html?ugrp=u&amp;unlocked_article_code=1.gU0.U5Ee.kvPE0e0DodvZ&amp;smid=url-share"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa7r3rbruj20u0126tfm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:36:35 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment》(ICLR 2024) GitHub: github.com/lisiyao21/Du...</title>
<link>https://weibo.com/1402400261/O7yvaAD75</link>
<guid>https://weibo.com/1402400261/O7yvaAD75</guid>
<content:encoded><![CDATA[
<div> 关键词：Duolando、GPT、强化学习、舞蹈伴奏、UniDepth、深度估计、T2I模型、超分辨率、LiDAR、视觉SLAM

总结:
Duolando是一种使用强化学习技术对GPT进行跟随的方法，用于舞蹈伴奏。UniDepth是一种通用的单目度量深度估计模型。 T2I模型可以通过识别语义方向实现连续、特定主题的属性控制。AdaSR-TalkingHead是一种用于一次性生成语音头像的自适应超分辨率技术。 LTA-OM是一种长期关联的激光雷达-惯性里程计和地图构建技术。EfficientVMamba是一种轻量级视觉Mamba的有选择性扫描技术。LITA是一种语言指导的时间定位助理模型。GaussianCube利用最优传输将高斯喷洒结构化用于三维生成建模。Perturbed-Attention Guidance是一种扰动注意力引导技术。ROUTERBENCH是用于多LLM路由系统的基准测试。Long-Context-Attention是用于长上下文LLM模型训练的分布式注意力实现。DevBench是用于软件开发的全面基准测试。Should-It-Be-Executed-Or-Processed探讨LLMs是否能够区分指令和数据。BasicPBC是学习匹配的动画油桶着色基准测试。EasyRL4Rec是一个用户友好的基于强化学习的推荐系统代码库。SuperPoint是一种自监督兴趣点检测和描述模型。EgoSchema是用于非常长形式视频语言理解的诊断基准测试。 <div>
几篇论文实现代码：<br />《Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment》(ICLR 2024) GitHub: github.com/lisiyao21/Duolando<br />《UniDepth: Universal Monocular Metric Depth Estimation》(CVPR 2024) GitHub: github.com/lpiccinelli-eth/UniDepth [fig1]<br />《Continuous, Subject-Specific Attribute Control in T2I Models by Identifying Semantic Directions》(2024) GitHub: github.com/CompVis/attribute-control<br />《Adaptive Super Resolution for One-Shot Talking Head Generation》(2024) GitHub: github.com/Songluchuan/AdaSR-TalkingHead<br />《LTA-OM: Long-Term Association LiDAR-Inertial Odometry and Mapping》(2024) GitHub: github.com/hku-mars/LTAOM<br />《EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba》(2024) GitHub: github.com/TerryPei/EfficientVMamba [fig2] <br />《LITA: Language Instructed Temporal-Localization Assistant》(2024) GitHub: github.com/NVlabs/LITA<br />《GaussianCube: Structuring Gaussian Splatting for 3D Generative Modeling using Optimal Transport》(2024) GitHub: github.com/GaussianCube/GaussianCube<br />《Perturbed-Attention Guidance》(2024) GitHub: github.com/KU-CVLAB/Perturbed-Attention-Guidance<br />《ROUTERBENCH: A Benchmark for Multi-LLM Routing System》(2024) GitHub: github.com/withmartian/routerbench<br />《Long-Context-Attention: Distributed Attention Implementations for Long Context LLM Model Training》(2024) GitHub: github.com/feifeibear/long-context-attention<br />《DevBench: A Comprehensive Benchmark for Software Development》(2024) GitHub: github.com/open-compass/DevBench [fig3]<br />《Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?》(2024) GitHub: github.com/egozverev/Should-It-Be-Executed-Or-Processed<br />《Learning Inclusion Matching for Animation Paint Bucket Colorization》(2024) GitHub: github.com/ykdai/BasicPBC<br />《EasyRL4Rec: A User-Friendly Code Library for Reinforcement Learning Based Recommender Systems》(2024) GitHub: github.com/chongminggao/EasyRL4Rec<br />《SuperPoint: Self-Supervised Interest Point Detection and Description》(2024) GitHub: github.com/christian-rauch/super_point_inference<br />《EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding》(2024) GitHub: github.com/egoschema/EgoSchema<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoa145bowtj21rf0i6wu8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoa1h04n3kj20l70deafb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoa681no84j23zf1827wh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:28:18 GMT</pubDate>
</item>
<item>
<title>【EPUB to Audiobook Converter：EPUB到有声书的转换器】’EPUB to Audiobook Converter - EPUB to audiobook converter, optimized for Audiobookshelf' GitHub...</title>
<link>https://weibo.com/1402400261/O7yttipiX</link>
<guid>https://weibo.com/1402400261/O7yttipiX</guid>
<content:encoded><![CDATA[
<div> GitHub, EPUB to Audiobook Converter, Audiobookshelf
<br />
EPUB到有声书的转换器，可以将EPUB转换为有声书，GitHub上有项目epub_to_audiobook，作者是p0n1，优化了Audiobookshelf的使用体验。

<br /><br />总结:
EPUB到有声书的转换器是一个可以将EPUB格式的电子书转换为有声书的工具，适用于Audiobookshelf，作者是p0n1，在GitHub上开源了相关项目。 <div>
【EPUB to Audiobook Converter：EPUB到有声书的转换器】’EPUB to Audiobook Converter - EPUB to audiobook converter, optimized for Audiobookshelf' GitHub: github.com/p0n1/epub_to_audiobook <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa7e0zh6mj21010u0aec.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:24:06 GMT</pubDate>
</item>
<item>
<title>【Softmax for Arbitrary Label Trees：一个用于医学影像分割的框架】'Softmax for Arbitrary Label Trees - Softmax for Arbitrary Label Trees (SALT) is a fr...</title>
<link>https://weibo.com/1402400261/O7yt26gby</link>
<guid>https://weibo.com/1402400261/O7yt26gby</guid>
<content:encoded><![CDATA[
<div> 分词：Softmax、Arbitrary Label Trees、医学影像分割、框架、训练、分割网络、条件概率、模型、层级关系、数据

总结:<br /><br />这篇文章介绍了一个名为Softmax for Arbitrary Label Trees (SALT)的框架，用于训练医学影像分割网络。SALT利用条件概率来建模数据中的层级关系，从而更好地进行分割任务。该框架的GitHub链接是github.com/UMEssen/SALT。SALT框架可以帮助提高医学影像分割的准确性和效率，是一个有潜力的方法。 <div>
【Softmax for Arbitrary Label Trees：一个用于医学影像分割的框架】'Softmax for Arbitrary Label Trees - Softmax for Arbitrary Label Trees (SALT) is a framework for training segmentation networks using conditional probabilities to model hierarchical relationships in the data.' GitHub: github.com/UMEssen/SALT <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa7d02ja2j20u0112n32.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:23:00 GMT</pubDate>
</item>
<item>
<title>【Edge Infer：- 旨在资源受限的设备上运行小型 AI 模型(包括向量化和Onnx模型)，如 Android、iOS 或 MCU，实现高效的边缘智能，用于实时决策】'Edge Infer - Ed...</title>
<link>https://weibo.com/1402400261/O7ys0ziZp</link>
<guid>https://weibo.com/1402400261/O7ys0ziZp</guid>
<content:encoded><![CDATA[
<div> Edge Infer, 资源受限设备, 小型AI模型, 向量化, Onnx模型, Android, iOS, MCU, 边缘智能, 实时决策, GitHub

总结:<br /><br />Edge Infer 是一种旨在在资源受限的设备上运行小型AI模型的工具，包括向量化和Onnx模型，适用于Android、iOS或MCU等设备，实现高效的边缘智能，用于实时决策。Edge Infer的GitHub链接为github.com/unit-mesh/edge-infer。 <div>
【Edge Infer：- 旨在资源受限的设备上运行小型 AI 模型(包括向量化和Onnx模型)，如 Android、iOS 或 MCU，实现高效的边缘智能，用于实时决策】'Edge Infer - EdgeInfer enables efficient edge intelligence by running small AI models, including embeddings and OnnxModels, on resource-constrained devices like Android, iOS, or MCUs for real-time decision-making. EdgeInfer' GitHub: github.com/unit-mesh/edge-infer <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa7adt8y1j20yc0u0dil.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:20:30 GMT</pubDate>
</item>
<item>
<title>【hoarder-app：用于数据(链接、图片、笔记)收集的应用，支持AI自动打标和全文检索功能】'hoarder-app - A self-hostable bookmark-everything app (links, note...</title>
<link>https://weibo.com/1402400261/O7yrtjJXR</link>
<guid>https://weibo.com/1402400261/O7yrtjJXR</guid>
<content:encoded><![CDATA[
<div> 自托管、收藏一切数据的应用、链接、笔记、图片、AI自动标记、全文检索、GitHub、MohamedBassem、hoarder-app<br />
<br />
总结:<br />
hoarder-app是一个自托管的应用程序，用于收藏各种数据，包括链接、笔记和图片。该应用支持AI自动标记和全文检索功能，用户可以方便地管理和查找自己收藏的信息。该项目可以在GitHub上找到，由MohamedBassem维护。 <div>
【hoarder-app：用于数据(链接、图片、笔记)收集的应用，支持AI自动打标和全文检索功能】'hoarder-app - A self-hostable bookmark-everything app (links, notes and images) with AI-based automatic tagging and full text search' GitHub: github.com/MohamedBassem/hoarder-app <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa78e98l2j21jk0u0n4q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:19:10 GMT</pubDate>
</item>
<item>
<title>【Popple：分布式、高可用、通用用途的键/值数据库】'Popple - Popple is a distributed, highly available, general purpose key/value database.' GitHub: git...</title>
<link>https://weibo.com/1402400261/O7ypPED6c</link>
<guid>https://weibo.com/1402400261/O7ypPED6c</guid>
<content:encoded><![CDATA[
<div> 分布式、高可用、通用、键/值数据库、Popple、GitHub、hoorayman、distributed、highly available、general purpose

分布式键/值数据库Popple是一个通用、高可用的分布式键/值数据库，可以处理各种用途的数据。它具有弹性，能够在整个系统中分布数据，保证数据的高可用性。Popple的代码托管在GitHub上，由hoorayman开发和维护。采用分布式架构，Popple可以有效地存储和检索大量键/值对，适用于各种应用场景。总的来说，Popple是一个强大的键/值数据库，具有分布式部署和高可用性的特点，适用于多种通用用途。 <br /><br />总结: Popple是一个分布式、高可用、通用用途的键/值数据库，由hoorayman开发，可用于处理各种数据应用。 <div>
【Popple：分布式、高可用、通用用途的键/值数据库】'Popple - Popple is a distributed, highly available, general purpose key/value database.' GitHub: github.com/hoorayman/popple <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%95%B0%E6%8D%AE%E5%BA%93%23&amp;isnewpage=1"><span class="surl-text">#数据库#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa74ti7tdj21240u0q73.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:15:08 GMT</pubDate>
</item>
<item>
<title>【rev.ng：基于LLVM和QEMU的二进制分析框架和反编译器】’The rev.ng binary analysis framework and decompiler' GitHub: github.com/revng/revng-c #开源# #机...</title>
<link>https://weibo.com/1402400261/O7ynd9CZx</link>
<guid>https://weibo.com/1402400261/O7ynd9CZx</guid>
<content:encoded><![CDATA[
<div> LLVM、QEMU、二进制分析框架、反编译器、GitHub、rev.ng、revng-c

总结:<br /><br />rev.ng是基于LLVM和QEMU的二进制分析框架和反编译器，它提供一种强大的工具来分析和反编译二进制文件。通过GitHub上的revng-c项目，用户可以轻松访问和使用这个框架。LLVM和QEMU的结合使得rev.ng具备了强大的分析和反编译能力，帮助用户更好地理解和操纵二进制文件。通过rev.ng，用户可以深入研究二进制文件的内部结构和功能，从而进行更高级的安全研究和分析工作。是一个有着广泛应用前景的二进制分析工具。 <div>
【rev.ng：基于LLVM和QEMU的二进制分析框架和反编译器】’The rev.ng binary analysis framework and decompiler' GitHub: github.com/revng/revng-c <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa6y3b15sj21i60l4n1o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:08:41 GMT</pubDate>
</item>
<item>
<title>【EasyRL4Rec - 专注于强化学习(RL)为基础的推荐系统(RS)的全面且易于使用的库】'EasyRL4Rec - a comprehensive and easy-to-use library designed specifically...</title>
<link>https://weibo.com/1402400261/O7ym7486g</link>
<guid>https://weibo.com/1402400261/O7ym7486g</guid>
<content:encoded><![CDATA[
<div> 库，强化学习，推荐系统，全面，易于使用，github，Reinforcement Learning，Recommender Systems，comprehensive，easy-to-use

总结:<br /><br />
"EasyRL4Rec"是一个专注于强化学习为基础的推荐系统的全面且易于使用的库。其设计旨在为推荐系统提供强化学习的解决方案，并在GitHub上提供代码库。该库提供了强化学习和推荐系统的综合性功能，并且易于使用，成为开发推荐系统的有力工具。 <div>
【EasyRL4Rec - 专注于强化学习(RL)为基础的推荐系统(RS)的全面且易于使用的库】'EasyRL4Rec - a comprehensive and easy-to-use library designed specifically for Reinforcement Learning (RL)-based Recommender Systems (RSs)‘ GitHub: github.com/chongminggao/EasyRL4Rec <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa6v4ng6rj20v60u0gpv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:05:58 GMT</pubDate>
</item>
<item>
<title>【高效SAM分割模型大列表】’Efficient-Segment-Anything-Model - One summary of efficient segment anything models' GitHub: github.com/czg1225/Awesome-Eff...</title>
<link>https://weibo.com/1402400261/O7yfei9ug</link>
<guid>https://weibo.com/1402400261/O7yfei9ug</guid>
<content:encoded><![CDATA[
<div> GitHub, Efficient-Segment-Anything-Model, 分割模型, 高效, 模型, 列表, 精彩, 总结, 优点, 应用

<br /><br />总结:
本文介绍了高效SAM分割模型的一份大列表，包含了各种精彩的分割模型。这些模型在分割任务中具有高效性，能够快速准确地识别出目标物体。这些模型的优点在于其高效性和准确性，可以被广泛应用于图像分割、语义分割等领域。通过这个列表，研究者和开发者可以找到适合自己项目的高效SAM分割模型，提高分割任务的效率和准确率。 <div>
【高效SAM分割模型大列表】’Efficient-Segment-Anything-Model - One summary of efficient segment anything models' GitHub: github.com/czg1225/Awesome-Efficient-Segment-Anything <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa6dbad5kj20u00unq7j.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa6dcle9yj215h0u0gq9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa6ddlmj6j20xi0c540f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa6deyl0kj235s0peqd6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa6dfx5dwj21tv0u00yz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa6dhbvx5j235s0natjb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa6diu3ruj22u80u0wo6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa6djqb0uj21f70u0q98.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa6dlfv25j21j40u0jys.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 06:49:01 GMT</pubDate>
</item>
<item>
<title>【RestAI：基于LlamaIndex、Ollama和HF pipelines的AIaaS(人工智能即服务)开源平台】'RestAI - RestAI is an AIaaS (AI as a Service) open-source platform. Bu...</title>
<link>https://weibo.com/1402400261/O7xdOmrEj</link>
<guid>https://weibo.com/1402400261/O7xdOmrEj</guid>
<content:encoded><![CDATA[
<div> RestAI、AIaaS、开源平台、LlamaIndex、Ollama、HF Pipelines、支持、LLM、嵌入式使用、调优

总结:<br /><br />RestAI是一个基于LlamaIndex、Ollama和HF Pipelines的AIaaS开源平台，支持任何被LlamaIndex支持的公共LLM和任何被Ollama支持的本地LLM。它提供精准的嵌入式使用和调优功能。GitHub上有相关项目。 <div>
【RestAI：基于LlamaIndex、Ollama和HF pipelines的AIaaS(人工智能即服务)开源平台】'RestAI - RestAI is an AIaaS (AI as a Service) open-source platform. Built on top of LlamaIndex, Ollama and HF Pipelines. Supports any public LLM supported by LlamaIndex and any local LLM suported by Ollama. Precise embeddings usage and tuning.' GitHub: github.com/apocas/restai <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa1v0x4sij20ud0u0ad4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 04:12:47 GMT</pubDate>
</item>
<item>
<title>【Plandex：基于OpenAI API的命令行AI编程引擎，用于处理复杂的任务，可以帮助用户分解大型任务为更小的子任务，并逐个实现这些子任务，帮助快速完成工作流，与...</title>
<link>https://weibo.com/1402400261/O7xaJE7HH</link>
<guid>https://weibo.com/1402400261/O7xaJE7HH</guid>
<content:encoded><![CDATA[
<div> 命令行、AI编程引擎、处理任务、分解任务、实现子任务、完成工作流、技术互动、减少时间、GitHub、Plandex<br />
<br />
AI编程引擎Plandex基于OpenAI API，用于处理复杂任务，能帮助用户将大型任务分解为小任务，并逐一实现，从而快速完成工作流。用户可以利用Plandex与不熟悉的技术互动，摆脱困境，减少在无聊事务上的时间花费。该工具的GitHub仓库可在github.com/plandex-ai/plandex找到。Plandex是一个有用的AI工具，可提高用户的工作效率和减轻工作负担。总结: <br />AI编程引擎Plandex基于OpenAI API，可帮助用户快速解决复杂任务，通过分解大型任务为小任务逐一实现，并与不熟悉的技术互动，提高工作效率。 <div>
【Plandex：基于OpenAI API的命令行AI编程引擎，用于处理复杂的任务，可以帮助用户分解大型任务为更小的子任务，并逐个实现这些子任务，帮助快速完成工作流，与不熟悉的技术互动，摆脱困境，减少在无聊的事情上花费的时间】’Plandex - An AI coding engine for complex tasks' GitHub: github.com/plandex-ai/plandex <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa1mb9tl9j20u00uwn1d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 04:05:12 GMT</pubDate>
</item>
<item>
<title>【深度伪造(Deepfake)相关文献资源列表】’Deepfake Generation and Detection: A Benchmark and Survey - A Survey on Deepfake Generation and Detection' Git...</title>
<link>https://weibo.com/1402400261/O7x9Clzzn</link>
<guid>https://weibo.com/1402400261/O7x9Clzzn</guid>
<content:encoded><![CDATA[
<div> Deepfake Generation, Detection, Benchmark, Survey, GitHub, Resource, Awesome, Flyingby, Survey on Deepfake Generation and Detection

<br /><br />总结:
本文介绍了关于深度伪造（Deepfake）生成和检测的研究现状，提供了一个包含相关资源的GitHub链接。文章从深度伪造生成和检测的角度出发，提供了相关资源和信息，帮助读者了解深度伪造技术的发展和应用。GitHub链接中包含了丰富的资料，为研究者提供了实用的工具和参考文献。深度伪造技术的发展对社会产生了重要影响，因此深入了解相关信息和研究是十分必要的。通过本文和相关资源，读者可以更好地了解和研究深度伪造技术，为社会和科学研究做出更有益的贡献。 <div>
【深度伪造(Deepfake)相关文献资源列表】’Deepfake Generation and Detection:   <br />  A Benchmark and Survey - A Survey on Deepfake Generation and Detection' GitHub: github.com/flyingby/Awesome-Deepfake-Generation-and-Detection <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa1k9ly7yj21js0jr79w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa1kaeawrj20vb0d4goz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 04:02:27 GMT</pubDate>
</item>
<item>
<title>【OpenUI：让使用者描述网页界面并实时渲染的开源项目】'OpenUI - OpenUI let's you describe UI using your imagination, then see it rendered live.' GitHub:...</title>
<link>https://weibo.com/1402400261/O7x5h1h9B</link>
<guid>https://weibo.com/1402400261/O7x5h1h9B</guid>
<content:encoded><![CDATA[
<div> OpenUI、描述、界面、实时渲染、开源项目、GitHub、使用者、网页、界面、渲染 live。

<br /><br />总结:
OpenUI是一个开源项目，可以让使用者通过描述界面来实时渲染网页界面。用户可以发挥自己的想象力来描述界面，然后看到它在实时渲染的过程中呈现出来。该项目托管在GitHub上，方便用户查看和参与贡献。通过OpenUI，用户可以轻松创建自己想要的网页界面，带来更加直观和便捷的设计体验。 <div>
【OpenUI：让使用者描述网页界面并实时渲染的开源项目】'OpenUI - OpenUI let's you describe UI using your imagination, then see it rendered live.' GitHub: github.com/wandb/openui <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa193yigoj21410u00wc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 03:51:44 GMT</pubDate>
</item>
<item>
<title>【OpenDevin: 一个开源项目，旨在复制Devin，Devin是一个自主的AI软件工程师，能执行复杂的工程任务，并积极与用户协作进行软件开发项目的合作】'OpenDevin: Cod...</title>
<link>https://weibo.com/1402400261/O7x2Kl9x2</link>
<guid>https://weibo.com/1402400261/O7x2Kl9x2</guid>
<content:encoded><![CDATA[
<div> OpenDevin, 开源项目, 复制Devin, AI软件工程师, 执行工程任务, 用户协作, 软件开发项目, GitHub, Code Less, Make More

<br /><br />总结:
OpenDevin是一个开源项目，旨在复制Devin，Devin是一个自主的AI软件工程师，能执行复杂的工程任务，并积极与用户协作进行软件开发项目的合作。该项目在GitHub上可找到，旨在让用户编写更少的代码，取得更多的成果。 <div>
【OpenDevin: 一个开源项目，旨在复制Devin，Devin是一个自主的AI软件工程师，能执行复杂的工程任务，并积极与用户协作进行软件开发项目的合作】'OpenDevin: Code Less, Make More' GitHub: github.com/opendevin/opendevin <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5017953058357310"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax4.sinaimg.cn/orj480/5396ee05ly1hoa12ihxhwj21f20qumxl.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/ksQ6Y1c5lx08dIbPt6Na010412002IBP0E010.mp4?label=mp4_720p&amp;template=1368x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711865762&amp;ssig=PUWH7V97Hq&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/n7Oawc2Jlx08dIbPjD5e010412001fj80E010.mp4?label=mp4_hd&amp;template=912x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711865762&amp;ssig=buxMcLzUUi&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/TLUUJoUrlx08dIbPBcUE010412000JWS0E010.mp4?label=mp4_ld&amp;template=684x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711865762&amp;ssig=X5k%2F11GgW2&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5017953058357310" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 03:45:31 GMT</pubDate>
</item>
<item>
<title>《LLM 应用开发实践笔记》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O7wM56Ev8</link>
<guid>https://weibo.com/1402400261/O7wM56Ev8</guid>
<content:encoded><![CDATA[
<div> 应用开发、LLM、实践、笔记、技术、编程、学习、经验、案例、方法论

<br /><br />总结:
LLM 应用开发实践笔记是一篇关于应用开发实践的经验分享文章。文章通过具体的案例和方法论，介绍了在应用开发过程中的技术细节和实践经验。作者通过自身的学习和实践，总结出了一套有效的开发方法，帮助读者更好地理解应用开发的过程。通过本文，读者可以学习到实际应用开发中的技巧和经验，为自己的开发工作提供有用的参考。 <div>
《LLM 应用开发实践笔记》 <a href="https://aitutor.liduos.com/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9zv1onj7j20ki10s76d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 03:04:27 GMT</pubDate>
</item>
<item>
<title>对 预训练 MoE、upcycled MoE 和 FrankenMoE 三类 MoE 模型的简介。- 预训练 MoE预训练 MoE 旨在利用 MoE 架构从头开始预训练语言模型，以期获得比传统密集模型...</title>
<link>https://weibo.com/1402400261/O7wxgeqRs</link>
<guid>https://weibo.com/1402400261/O7wxgeqRs</guid>
<content:encoded><![CDATA[
<div> 预训练 MoE、upcycled MoE、FrankenMoE、语言模型、专家、预训练、计算成本、效果、模型合并

<br /><br />总结:
预训练 MoE 是一种利用 MoE 架构从头开始预训练语言模型的方法，具有训练速度快、推理速度快和专家针对不同概念等优势，代表性模型有 Switch Transformer、Mixtral。upcycled MoE 是在已经训练好的基础模型上创建多个专家形成 MoE 模型，优势在于计算成本低、可灵活控制专家数量，代表性工作有 DeepSeek-MoE、Upstage SOLAR。FrankenMoE 是将在特定任务上表现优异的微调模型组合成 MoE 模型，专家面向特定任务，但缺乏负载均衡优势，表现可能优于通用 MoE 模型，代表性模型为 Beyonder-4x7B-v2。 <div>
对 预训练 MoE、upcycled MoE 和 FrankenMoE 三类 MoE 模型的简介。<br /><br />- 预训练 MoE<br />预训练 MoE 旨在利用 MoE 架构从头开始预训练语言模型，以期获得比传统密集模型更高效的训练效果。预训练 MoE 的优势在于：<br />1. 训练速度更快。在相同计算预算下，MoE 模型理论上可以比密集模型更快达到相同的性能水平。<br />2. 推理速度更快。尽管 MoE 模型参数量巨大，但实际推理时只会激活部分专家，因此推理速度比拥有相同参数量的密集模型更快。<br />3. 专家可以专门针对不同的浅层概念或词元组，而不是某个特定主题。<br />不过，预训练 MoE 也面临一些挑战，如推理时需要大量内存来加载所有专家参数，以及在下游任务微调时容易过拟合等。代表性的预训练 MoE 模型有 Switch Transformer、Mixtral 等。<br /><br />- upcycled MoE<br />upcycled MoE 的思路是在一个已经训练好的基础模型上，通过复制其前馈网络来创建多个专家，形成一个 MoE 模型。与从头预训练相比，upcycled MoE 的优势在于：<br />1. 基于成熟的预训练模型，继续预训练的计算成本更低。<br />2. 可以使用细粒度的专家，即将前馈网络切割成更小的单元，从而获得数量众多的小型专家。  <br />3. 可以灵活控制要激活的专家数量，在推理速度和效果之间进行权衡。<br />upcycled MoE 的代表性工作包括 DeepSeek-MoE、Upstage SOLAR 等。<br /><br />- FrankenMoE<br />FrankenMoE 的思路与模型合并类似，即选择几个在特定任务上表现优异的微调模型，将它们组合成一个 MoE 模型。通过一定的训练，可以让路由器学会将不同类型的token发送给对应的专家。<br />与预训练 MoE 和再利用 MoE 相比，FrankenMoE 的特点是：<br />1. 专家是面向特定任务的，而不是通用的浅层概念，这一点与预训练 MoE 有本质区别。<br />2. 不再具有 MoE 的某些优势，如负载均衡。因为专家之间的能力差异较大。<br />3. 在特定任务上的表现可能优于通用的 MoE 模型，如 Beyonder-4x7B-v2。<br />但 FrankenMoE 能否广泛应用于不同场景，目前还有待进一步验证。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9yoziedxj20xc4t8b29.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9yp0i5o4j20u70i90v8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9yp1kqcyj20pb0chwfw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 02:27:57 GMT</pubDate>
</item>
<item>
<title>《混合专家模型 (MoE) 详解》- MoE 是一种将大型语言模型中全连接层替换为稀疏层的技术，可以显著提高预训练效率。其包含两个主要元素：稀疏的 MoE 层和一个门控...</title>
<link>https://weibo.com/1402400261/O7w5scEbo</link>
<guid>https://weibo.com/1402400261/O7w5scEbo</guid>
<content:encoded><![CDATA[
<div> 稀疏层、MoE层、门控网络、专家、模型规模、Transformer、微调、训练挑战、开源项目、知识蒸馏、量化

<br /><br />总结:
混合专家模型（MoE）是一种将大型语言模型中全连接层替换为稀疏层的技术，通过引入稀疏性和门控网络，实现部分输入数据计算、模型规模扩张而不增加计算量，并通过专家负载平衡、辅助损失函数和专家容量限制来提高效率。MoE与Transformer结合取得进展，如GShard实现规模扩张至6000亿参数，Switch Transformer简化门控网络，提出专家容量概念。MoE模型在微调中容易过拟合，需采用更高正则化，多任务示教微调再单任务微调可提升表现。面临训练和部署挑战，需专家并行、通信优化、断点续训、模型压缩等技术。MoE模型为构建大规模高效神经网络提供新思路，Switch Transformers等研究解决MoE不稳定性问题，指明后续改进方向。MoE引发学术界和工业界广泛关注，多个研究组织发布基于MoE模型取得性能进步，未来可进一步探索知识蒸馏、量化等方向。将MoE蒸馏为密集模型和量化是有前景的研究方向，在保持性能的同时大幅压缩模型体积，促进MoE在资源受限环境下的部署。 <div>
《混合专家模型 (MoE) 详解》<br />- MoE 是一种将大型语言模型中全连接层替换为稀疏层的技术，可以显著提高预训练效率。其包含两个主要元素：稀疏的 MoE 层和一个门控网络，门控网络决定每个 token 由哪个 expert 处理。   <br />- MoE 的起源可追溯到 1991 年的论文，2010-2015 年间的研究为 MoE 在深度网络中的应用奠定了基础。2017 年的论文首次在 NLP 任务中应用了 MoE，将 LSTM 模型扩展到 1300 亿参数。   <br />- MoE 引入了稀疏性，只对部分输入数据进行计算，从而实现模型规模的扩张而不增加计算量。门控网络学习将输入分配给不同的专家(expert)。   <br />- 为了平衡各专家的负载，需要添加辅助损失函数鼓励所有专家得到近似相等的训练样本。还可以设置专家容量限制。   <br />- MoE 与 Transformer 的结合取得了显著进展。例如 GShard 利用 MoE 将模型扩展到 6000 亿参数；Switch Transformer 引入单专家策略简化了门控网络，提出了专家容量的概念。   <br />- 相较于稠密模型，MoE 模型在下游任务的微调中更容易过拟合，需要采用更高的正则化。最近的工作显示先进行多任务示教微调然后再单任务微调可以显著提升 MoE 的表现。   <br />- 训练和部署 MoE 也面临一些挑战，论文提出了专家并行、通信优化、断点续训、模型压缩等技术来解决这些问题。   <br />- 目前有多个开源项目致力于 MoE 的研究，未来可探索的方向包括知识蒸馏、量化等。  <br /><br />思考：  <br />- MoE 模型的出现为构建大规模且高效的神经网络提供了新的思路。通过将专家作为组件嵌入到网络中，MoE 有望突破传统密集模型的瓶颈。  <br />- Switch Transformers 等工作针对 MoE 的不稳定性问题进行了深入研究，为后续的改进指明了方向。1.6 万亿参数的 MoE 模型展现了这一架构的巨大潜力。  <br />- 多个研究组织已经发布了基于 MoE 的模型，表明 MoE 正在受到学术界和工业界的广泛关注。这些模型在性能上取得了显著进步，有望在实际应用中发挥重要作用。  <br />- 将 MoE 蒸馏为密集模型以及对其进行量化是非常有前景的研究方向。这不仅能够在保持性能的同时大幅压缩模型体积，还能促进 MoE 在资源受限环境下的部署。<br /> <a href="https://huggingface.co/blog/moe"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9wulpqsaj20za0u00wv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 01:19:26 GMT</pubDate>
</item>
<item>
<title>《BrushNet - BrushNet: A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion | a Hugging Face Space by TencentARC》 网页链接 #...</title>
<link>https://weibo.com/1402400261/O7vT1o0c8</link>
<guid>https://weibo.com/1402400261/O7vT1o0c8</guid>
<content:encoded><![CDATA[
<div> BrushNet, Image Inpainting, Plug-and-Play Model, Diffusion, Dual-Branch, Decomposed, Hugging Face Space, TencentARC

<br /><br />总结:
本文介绍了一种基于图像修复的模型BrushNet，通过两个分支的扩散机制实现图像修复。该模型能够自动进行图像修复，满足用户需求。通过对不同部分的修复分解，提高了修复效果。 TencentARC团队在Hugging Face Space上提供了该模型，方便用户使用。 <div>
《BrushNet - BrushNet: A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion | a Hugging Face Space by TencentARC》 <a href="https://huggingface.co/spaces/TencentARC/BrushNet"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5017908603191302"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax3.sinaimg.cn/orj480/5396ee05ly1ho9vyjuuigj20zk0k00tk.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/DGCmhkr0lx08dHZH7en6010412005TBA0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711858507&amp;ssig=CUnU3p7Iwb&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/xv8u3UeOlx08dHZGKSly010412002Lz70E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711858507&amp;ssig=CXQrgsO%2Fnc&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/Afyz8Cvblx08dHZGKdLq010412001JUS0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711858507&amp;ssig=xQSd7WEinY&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5017908603191302" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 00:48:49 GMT</pubDate>
</item>
<item>
<title>【DSPy：机器学习工作流重塑提示工程】- DSPy 是一个与众不同的提示工程框架，它将逻辑与提示分离，使开发人员能够通过 dspy.Module 确定性地编程逻辑，而不用关...</title>
<link>https://weibo.com/1402400261/O7vOKCeLv</link>
<guid>https://weibo.com/1402400261/O7vOKCeLv</guid>
<content:encoded><![CDATA[
<div> 提示工程、DSPy、机器学习、工作流、逻辑、LLM、闭合循环、易用性、术语、概念

总结：<br /><br />本文介绍了DSPy这一机器学习工作流重塑提示工程的框架，其将逻辑与提示分离，使开发人员专注于逻辑编程而不需关心底层LLM，有望简化提示工程流程。DSPy将提示工程转变为结构化的机器学习工作流，闭合了训练和评估的循环，突出了LLM/Agent系统的重要性。然而，DSPy目前存在易用性问题，术语和概念晦涩，对新手不友好。希望DSPy在优化易用性方面做出改进，降低学习门槛，扩大受众群。 <div>
【DSPy：机器学习工作流重塑提示工程】<br />- DSPy 是一个与众不同的提示工程框架，它将逻辑与提示分离，使开发人员能够通过 dspy.Module 确定性地编程逻辑，而不用关心所使用的 LLM。  <br />- DSPy 的革命性在于它将提示工程纯手工过程转变为结构化的机器学习工作流，包括准备数据集、定义模型、训练、评估和测试。  <br />- DSPy 的关键贡献是闭合了提示工程中训练和评估的循环，并将逻辑与文本表示分离开来，凸显了对 LLM/Agent 系统的潜在重要性。  <br />- DSPy 目前存在的问题是对新手来说学习曲线较陡峭，其习语如 signature、module、program、teleprompter、optimization 和 compile 等术语让人望而生畏。即使对于精通提示工程的人来说，在 DSPy 中驾驭这些概念也是一个具有挑战性的迷宫。  <br /><br />思考：  <br />- DSPy 通过将逻辑与提示分离，使开发人员能够专注于逻辑编程，而无需关注底层 LLM，这一点令人印象深刻。这种方式有望大大简化提示工程的流程。  <br />- 将提示工程转变为结构化的机器学习工作流是一个宏伟的愿景，如果能实现，将极大地推动 LLM 应用的发展。不过这需要 DSPy 在易用性上做出改进。  <br />- DSPy 的术语和概念目前还比较晦涩，对新手不够友好。如果能在这方面做些优化，降低学习门槛，DSPy 的受众会更加广泛。  <br />《DSPy: Not Your Average Prompt Engineering》 <a href="https://jina.ai/news/dspy-not-your-average-prompt-engineering/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9vnlvwvzj20xc0hiabc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9vnnsds1j20xc0hijt8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 00:38:18 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评...</title>
<link>https://weibo.com/1402400261/O7uVrf61S</link>
<guid>https://weibo.com/1402400261/O7uVrf61S</guid>
<content:encoded><![CDATA[
<div> 编程语言、故事、技术、Java、Python、JavaScript、C语言、MySQL、Redis、技术原理。

<br /><br />总结:
《码农翻身2》是一本故事化的技术书籍，通过讲述编程语言之间的斗争和争端，将看似枯燥的技术知识变得生动有趣。Java、Python、JavaScript、C语言、MySQL和Redis等技术在书中扮演着不同角色，展现了它们之间的互动和竞争。读者在享受故事的同时，也能够学到技术的原理和本质。《码农翻身2》是一部结合技术和趣味的书籍，让读者在轻松愉快的阅读中提升自己的技术水平。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 22:22:01 GMT</pubDate>
</item>
<item>
<title>今日推介(第1361期)：使用方向感知t-SNE可视化高维时间数据、超越回路重叠寻找模型机制、语言模型视角下的工具使用研究综述、用引导扩散从零开始生成强大的投毒...</title>
<link>https://weibo.com/1402400261/O7uVh0dhT</link>
<guid>https://weibo.com/1402400261/O7uVh0dhT</guid>
<content:encoded><![CDATA[
<div> 方向感知t-SNE、高维时间数据、超越回路重叠、模型机制、语言模型、工具使用、引导扩散、投毒和后门、反事实预训练、目标移除和插入

<br /><br />总结:
本文介绍了几篇关于机器学习和人工智能领域的研究成果。首先，提出了使用方向感知t-SNE可视化高维时间数据的方法，可以更直观地展示数据的特征和变化。其次，探讨了超越回路重叠寻找模型机制的方法，对于理解复杂系统的运作机制具有重要意义。另外，从语言模型的视角分析了工具使用研究，为提升用户体验和效率提供了新思路。此外，介绍了用引导扩散从零开始生成强大的投毒和后门的技术，以及用于逼真目标移除和插入的自举反事实预训练的方法，这些技术在安全和数据处理领域具有重要应用前景。通过这些研究成果的分享，可以促进机器学习和人工智能领域的发展，推动相关技术的创新和应用。 <div>
今日推介(第1361期)：使用方向感知t-SNE可视化高维时间数据、超越回路重叠寻找模型机制、语言模型视角下的工具使用研究综述、用引导扩散从零开始生成强大的投毒和后门、用于逼真目标移除和插入的自举反事实预训练 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/689966788"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.31)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9rpdhji0j20go0gswgt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho9rpfuh30j20go0960uf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho9rpicbi3j20go0dt3zx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho9rpkv1naj20go07kmxz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho9rpn7yx5j20go08fta0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 22:21:36 GMT</pubDate>
</item>
<item>
<title>通过构建反事实图像数据集微调扩散模型，实现了逼真的物体删除和插入，显著提高了渲染物体对场景效应的能力。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《ObjectDrop: B...</title>
<link>https://weibo.com/1402400261/O7uR4D6Cm</link>
<guid>https://weibo.com/1402400261/O7uR4D6Cm</guid>
<content:encoded><![CDATA[
<div> 反事实图像数据集、微调、扩散模型、物体删除、物体插入、场景效应、物体移除、物体添加、渲染能力、ObjectDrop
<br />
<br />
总结：研究通过构建反事实图像数据集微调扩散模型，实现了逼真的物体删除和插入，提高了渲染物体对场景效应的能力。这项研究利用了ObjectDrop技术，通过对图像进行微调和扩散模型的训练，实现了物体的删除和插入，使得场景效果更加真实。该技术对于图像处理和渲染领域具有重要意义，可以在实际应用中提供更多可能性。研究团队的工作有望为数字图像处理领域带来新的突破，为物体移除和添加等任务提供更加高效、准确的解决方案。 <div>
通过构建反事实图像数据集微调扩散模型，实现了逼真的物体删除和插入，显著提高了渲染物体对场景效应的能力。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion》D Winter, M Cohen, S Fruchter, Y Pritch, A Rav-Acha, Y Hoshen [Google Research] (2024) <a href="https://arxiv.org/abs/2403.18818"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9r6lfzd1j21fc0j812s.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9r6lwz2pj21ok0xu7g6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9r6m52xjj21oi0m6gtc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9r6mf9a0j21p80uync4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9reswzu0j210y0m4aeu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9resx0v3j210z0n7tda.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9reswusnj210x0ovn0q.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resxfa7j210x0qu43z.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9resx035j210p0epq6x.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 22:11:15 GMT</pubDate>
</item>
<item>
<title>[CV]《ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion》D Winter, M Cohen, S Fruchter, Y Pritch, A Rav-Acha, ...</title>
<link>https://weibo.com/1402400261/O7uR2hqNe</link>
<guid>https://weibo.com/1402400261/O7uR2hqNe</guid>
<content:encoded><![CDATA[
<div> Bootstrapping, Counterfactuals, Object Removal, Object Insertion, Photorealistic, Google Research, Deep Learning, Image Editing, Computer Vision, Object Detection

<br /><br />总结：
该研究来自Google Research团队，提出了一种名为ObjectDrop的方法，用于在图像中实现真实感十足的对象删除和插入操作。通过引入反事实生成器来训练深度学习模型，实现了对于图像中物体的有效去除和替换。与传统方法相比，ObjectDrop能够更好地处理较复杂的情景，并且生成的结果质量更高。研究团队在大规模数据集上进行了实验证实，结果表明ObjectDrop在图像编辑和计算机视觉领域具有广阔的应用前景。 <div>
[CV]《ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion》D Winter, M Cohen, S Fruchter, Y Pritch, A Rav-Acha, Y Hoshen [Google Research] (2024) <a href="https://arxiv.org/abs/2403.18818"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9r6lfzd1j21fc0j812s.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9r6lwz2pj21ok0xu7g6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9r6m52xjj21oi0m6gtc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9r6mf9a0j21p80uync4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9reswzu0j210y0m4aeu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9resx0v3j210z0n7tda.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9reswusnj210x0ovn0q.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resxfa7j210x0qu43z.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9resx035j210p0epq6x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9reswcx8j21120dtad2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9resvwsij210y091wgh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resz9qcj21111h3k2x.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9resz22mj210m1ggwp5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9resz299j210x1fgqdh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9reszey1j210x1fg13w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resz2ntj210x1eg130.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resyyvrj210x1fowog.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 22:11:10 GMT</pubDate>
</item>
<item>
<title>利用引导扩散生成高质量和高效的中投毒基础样本，再与下游攻击算法相结合，实现了更隐蔽和强效的对抗机器学习。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Generating ...</title>
<link>https://weibo.com/1402400261/O7uKD6OzN</link>
<guid>https://weibo.com/1402400261/O7uKD6OzN</guid>
<content:encoded><![CDATA[
<div> 中投毒基础样本, 引导扩散, 下游攻击算法, 对抗机器学习, 高质量, 高效, 隐蔽, 强效, 生成, 转发 

总结:<br /><br />这篇文章介绍了一种利用引导扩散生成高质量和高效的中投毒基础样本的方法，然后与下游攻击算法相结合，实现了更隐蔽和强效的对抗机器学习。研究者通过这种方法能够生成具有潜在毒害和后门功能的样本，为网络安全领域提供了有力的工具和技术。 <div>
利用引导扩散生成高质量和高效的中投毒基础样本，再与下游攻击算法相结合，实现了更隐蔽和强效的对抗机器学习。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion》H Souri, A Bansal, H Kazemi, L Fowl... [Johns Hopkins University &amp; University of Maryland &amp; Google] (2024) <a href="https://arxiv.org/abs/2403.16365"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qlilx7pj21jo0veh0a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qljbfj9j21uu0ua4be.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qljtdcij21ki16q7ki.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qljxysoj21kg0vk7ez.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0tti1j20vi0j3wh9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0t8m3j20sq083ta2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qy0trcsj20vd0g6di1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0v0c4j20vg0hggox.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0u9apj20vg0hgdjp.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:55:23 GMT</pubDate>
</item>
<item>
<title>[LG]《Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion》H Souri, A Bansal, H Kazemi, L Fowl... [Johns Hopkins University &amp; U...</title>
<link>https://weibo.com/1402400261/O7uKuxzfT</link>
<guid>https://weibo.com/1402400261/O7uKuxzfT</guid>
<content:encoded><![CDATA[
<div> 关键词: Generating Potent Poisons, Backdoors, Guided Diffusion, Johns Hopkins University, University of Maryland, Google

总结:
本研究由约翰霍普金斯大学、马里兰大学和谷歌合作完成，探讨了如何利用引导扩散技术从头开始生成强效毒药和后门。研究团队通过实验和研究发现，在网络安全领域中，利用引导扩散方法可以快速生成具有毒性和后门功能的恶意软件和程序。通过深入分析和模拟实验，研究人员成功演示了这种方法的有效性和潜力，为网络安全防御提供了新的思路和方法。这项研究对于加强网络安全防御和对抗恶意攻击具有重要意义，有望为未来的网络安全研究和应用提供有益的参考和借鉴。 <div>
[LG]《Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion》H Souri, A Bansal, H Kazemi, L Fowl... [Johns Hopkins University &amp; University of Maryland &amp; Google] (2024) <a href="https://arxiv.org/abs/2403.16365"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qlilx7pj21jo0veh0a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qljbfj9j21uu0ua4be.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qljtdcij21ki16q7ki.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qljxysoj21kg0vk7ez.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0tti1j20vi0j3wh9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0t8m3j20sq083ta2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qy0trcsj20vd0g6di1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0v0c4j20vg0hggox.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0u9apj20vg0hgdjp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0tmvnj20vh0e4abz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0toplj20vj0e4gnj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qy0txctj20vh0hi77g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qy0u2x6j20vh0hhq6h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0ttahj20vh0hgmzw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qy0tk82j20vj0e4jt7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0thgyj20vj0e4jt9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:55:03 GMT</pubDate>
</item>
<item>
<title>通过定义工具的概念、总结应用场景和方法、分析效率等方面，全面系统地回顾和分析了工具辅助语言模型的研究进展，为该领域的发展提供了重要指导。 - 转发 @爱可...</title>
<link>https://weibo.com/1402400261/O7uEwqhRZ</link>
<guid>https://weibo.com/1402400261/O7uEwqhRZ</guid>
<content:encoded><![CDATA[
<div> 工具概念, 应用场景, 方法, 效率, 语言模型, 研究进展, 指导意义, 重要性, 调查, 资源分配
<br /><br />总结:
本文系统地回顾和分析了工具辅助语言模型的研究进展。首先定义工具的概念，然后总结了工具在语言模型中的应用场景和方法。分析了工具辅助语言模型的效率，并探讨了其在领域发展中的重要性和指导意义。通过对工具的调查和资源分配，为该领域的进一步发展提供了重要启示。 <div>
通过定义工具的概念、总结应用场景和方法、分析效率等方面，全面系统地回顾和分析了工具辅助语言模型的研究进展，为该领域的发展提供了重要指导。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《What Are Tools Anyway? A Survey from the Language Model Perspective》Z Wang, Z Cheng, H Zhu, D Fried, G Neubig [CMU &amp; Shanghai Jiao Tong University] (2024) <a href="https://arxiv.org/abs/2403.15452"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qcpp0boj21ge0natio.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qcq7gp6j20qs0m6djr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qcqfpcsj20rc0ro0y6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qcqml1qj21pm0jyqdc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qinfp1cj20d107bwey.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qingarmj20vk0drtap.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:40:21 GMT</pubDate>
</item>
<item>
<title>[CL]《What Are Tools Anyway? A Survey from the Language Model Perspective》Z Wang, Z Cheng, H Zhu, D Fried, G Neubig [CMU &amp; Shanghai Jiao Tong Univers...</title>
<link>https://weibo.com/1402400261/O7uEusOfo</link>
<guid>https://weibo.com/1402400261/O7uEusOfo</guid>
<content:encoded><![CDATA[
<div> 关键词：工具，语言模型，调查，功能，应用，自然语言处理，研究，方法，数据集，评估

总结：<br /><br />总结:本文介绍了基于语言模型的视角对工具进行调查的研究。作者探讨了工具的功能、应用及在自然语言处理中的作用。研究方法包括对数据集的评估和分析，为未来研究提供了参考。 <div>
[CL]《What Are Tools Anyway? A Survey from the Language Model Perspective》Z Wang, Z Cheng, H Zhu, D Fried, G Neubig [CMU &amp; Shanghai Jiao Tong University] (2024) <a href="https://arxiv.org/abs/2403.15452"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qcpp0boj21ge0natio.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qcq7gp6j20qs0m6djr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qcqfpcsj20rc0ro0y6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qcqml1qj21pm0jyqdc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qinfp1cj20d107bwey.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qingarmj20vk0drtap.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:40:16 GMT</pubDate>
</item>
<item>
<title>提出 EAP-IG 方法，实验证明它相比 EAP 可以提取出更忠实的回路，以更准确地理解语言模型的内在运算机制。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Have Faith in Fa...</title>
<link>https://weibo.com/1402400261/O7uBnidh5</link>
<guid>https://weibo.com/1402400261/O7uBnidh5</guid>
<content:encoded><![CDATA[
<div> 提取关键词：
EAP-IG、EAP、回路、语言模型、内在运算机制、信任度、模型机制、研究

总结:
本文提出了EAP-IG方法，与传统的EAP方法相比，能够更准确地提取出语言模型内在运算机制中更忠实的回路。实验证明，EAP-IG方法能够更好地理解模型的运作机制，从而提高对语言模型的理解信任度。研究结果表明，通过考虑回路的信任度，可以超越仅仅考虑回路重叠，从而更全面地揭示语言模型的内在机制。详细分析表明EAP-IG方法在理解语言模型方面的优势，为深入研究语言模型的内在运作机制提供了新的思路。Br><br />总结: 本研究提出了EAP-IG方法，与传统的EAP方法相比，能够更准确地提取出语言模型内在运算机制中更忠实的回路。实验结果表明，EAP-IG方法能够提高对语言模型的理解信任度，有助于揭示模型的内在机制。通过考虑回路的信任度，可以更全面地理解语言模型的内在运作机制，为深入研究提供了新的方向。 <div>
提出 EAP-IG 方法，实验证明它相比 EAP 可以提取出更忠实的回路，以更准确地理解语言模型的内在运算机制。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms》M Hanna, S Pezzelle, Y Belinkov [University of Amsterdam &amp; Technion] (2024) <a href="https://arxiv.org/abs/2403.17806"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q33y9lhj21bq0vwnca.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q34mdhyj21lg0qik0x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9q34yn5ej21m00vyk6a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q352mugj21l211en6e.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajljb6j20vh0dy76v.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qajlihij20vf0gidi8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajkv4qj20vd0bawfe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qajl2bfj20un0euq4i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajlil2j20ve0d140p.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:32:35 GMT</pubDate>
</item>
<item>
<title>[LG]《Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms》M Hanna, S Pezzelle, Y Belinkov [University of Amsterdam...</title>
<link>https://weibo.com/1402400261/O7uBkAiq9</link>
<guid>https://weibo.com/1402400261/O7uBkAiq9</guid>
<content:encoded><![CDATA[
<div> 信念，忠诚，模型机制，电路重叠，大学阿姆斯特丹，特希翁，2024年

<br />
本研究旨在探讨在寻找模型机制时如何超越电路重叠的思维。研究团队来自阿姆斯特丹大学和以色列理工学院，通过实证分析发现，在研究模型机制时，一定要坚定信念和忠诚，不仅仅停留在电路重叠的层面上，还要深入挖掘更为深层的原因和关联。他们提出了一种新的研究方法，希望可以帮助学术界在探索模型机制时更加全面和深入地思考问题。总体来说，这项研究为相关领域的学者们提供了新的研究思路和方法，对于推动学术研究具有一定启发意义。

<br />
总结: 该研究提出了超越电路重叠的新思路，强调在寻找模型机制时需要有信念和忠诚，以更深入和全面的视角探讨问题，为学术界提供了新的研究方法。 <div>
[LG]《Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms》M Hanna, S Pezzelle, Y Belinkov [University of Amsterdam &amp; Technion] (2024) <a href="https://arxiv.org/abs/2403.17806"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q33y9lhj21bq0vwnca.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q34mdhyj21lg0qik0x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9q34yn5ej21m00vyk6a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q352mugj21l211en6e.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajljb6j20vh0dy76v.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qajlihij20vf0gidi8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajkv4qj20vd0bawfe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qajl2bfj20un0euq4i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajlil2j20ve0d140p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajkfrcj20uw03ugm3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajldlxj20t10cc0tl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajll3dj20vh0frq53.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajlhyaj20ve0npwgz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:32:29 GMT</pubDate>
</item>
<item>
<title>【开源大语言模型的选择之道】- 近期不断有新的大型语言模型(LLM)发布，如Llama 2、Mixtral 8x7B、Zephyr 7B、SOLAR 10.7B和Code Llama等。这些模型规模越来越大...</title>
<link>https://weibo.com/1402400261/O7n3vpf2O</link>
<guid>https://weibo.com/1402400261/O7n3vpf2O</guid>
<content:encoded><![CDATA[
<div> 关键词: 大语言模型、选择、开源、性能、部署成本、可控性、多语言支持、部署流程、负责任、开源模型

总结:<br />
选择大语言模型时需考虑性能表现、调优空间、多语言支持等因素，开源模型具有更高的可控性、数据安全性和成本效益，但需要自行部署和维护。专用LLM在特定任务上表现更优，但通用LLM适用范围更广，需根据需求选择。在部署LLM时要考虑偏见、问责制等伦理问题，选择合适的模型大小和做好基础设施规划。API和监控可以简化部署流程和识别问题。发展中的LLM需要负责任地造福社会，模型参数量不代表在所有任务上表现更好，开源模型可能在灵活性、成本等方面更有优势。在实际应用中需全面评估质量、速度和成本，并不盲目追求参数量。开源模型可能是更好的选择，部署大语言模型需要考虑多方面策略，是一个复杂的过程。 <div>
【开源大语言模型的选择之道】<br />- 近期不断有新的大型语言模型(LLM)发布，如Llama 2、Mixtral 8x7B、Zephyr 7B、SOLAR 10.7B和Code Llama等。这些模型规模越来越大，性能也在不断提升。   <br />- 选择使用哪个LLM要考虑多方面因素，如性能表现、调优空间、多语言支持、部署成本等。例如Llama 2在安全性方面较好，Mixtral 8x7B的效率高，Zephyr 7B理解人类意图的能力强。   <br />- 相比商业LLM，开源LLM有更高的可控性、数据安全性、成本效益及社区支持等优势。但它们也需要自行部署和维护。   <br />- 专用LLM比通用LLM在特定任务上的表现更优，但后者应用范围更广。需根据实际需求选择。   <br />- 大规模部署LLM需考虑偏见、透明度、问责制等伦理问题。同时要选择合适的模型大小，做好基础设施规划，实现可扩展性等。   <br />- API、模型服务框架等可以简化LLM的部署流程。日志和监控对于运行中识别问题也很重要。   <br />- LLM的潜力正在不断被开发，需要继续推动其以负责任的方式造福社会。<br /><br />思考：  <br />- 模型参数量越大，训练数据越多，并不一定意味着在所有任务上都表现更好，有时更小的模型针对特定领域优化反而更有优势。  <br />- 开源模型在灵活性、成本等方面可能比商业模型更有优势。  <br />- 大语言模型的发展速度惊人，但在实际应用中需要全面评估质量、速度、成本等因素，不能盲目追求参数量。  <br />- 开源正在成为AI领域的重要趋势，开源模型在许多场景下可能是更好的选择。  <br />- 部署大语言模型需要考虑诸多策略，涉及模型选择、推理优化、提示工程、伦理安全等方方面面，是一个复杂的过程。<br />《Navigating the World of Large Language Models》 <a href="https://www.bentoml.com/blog/navigating-the-world-of-large-language-models"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8sy28h1vj20u00wtwka.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 02:19:55 GMT</pubDate>
</item>
<item>
<title>【不确定的确定性：用生成式模型颠覆天气预报】- 由于气象本质上是随机的，传统方法通过物理模拟生成一组预测来定量化不确定性，但这需要大量计算成本。Google提...</title>
<link>https://weibo.com/1402400261/O7mnVgkA5</link>
<guid>https://weibo.com/1402400261/O7mnVgkA5</guid>
<content:encoded><![CDATA[
<div> 生成式模型、天气预报、SEEDS、生成对抗网络、不确定性、物理模拟、极端天气事件、混合预报系统、数据和机器学习、跨学科融合<br />
<br />
总结：<br />
Google提出的SEEDS生成对抗网络模型可以以更低的成本有效生成大规模天气预报集合，可以匹配甚至超过基于物理的预测集合。SEEDS能更准确地预测尾部分布的可能性，如极端天气事件。该模型充分利用生成式AI的力量，以高效速度生成集合预报，代表了混合预报系统的一种新型应用。SEEDS展示了生成AI在天气预报中的巨大潜力，特别对于预测极端天气事件的概率。这项研究表明，生成式AI和扩散模型是一个前景广阔的方向，可以为传统科学和工程领域带来新的解决方案。基于数据和机器学习的方法在不确定性量化和概率预测方面可能比传统的物理模拟更具优势。跨学科融合将为更多领域提供突破，如AI技术与天气预报的结合。 <div>
【不确定的确定性：用生成式模型颠覆天气预报】<br />- 由于气象本质上是随机的，传统方法通过物理模拟生成一组预测来定量化不确定性，但这需要大量计算成本。Google提出了一种名为SEEDS的生成对抗网络模型，可以以比传统物理预测模型低得多的成本有效生成大规模的天气预报集合。   <br />- SEEDS基于去噪扩散概率模型，是一种最先进的生成AI技术，只需要一个或两个来自运算天气预测系统的种子预报，就可以生成一个大的集合，而这个集合可以匹配或超过基于物理的集合的技能指标。   <br />- SEEDS生成的集合可以更准确地给出尾部分布的可能性，如±2σ和±3σ的极端天气事件。它可以在很短时间内生成超过10000个集合成员，这对准确定量化极端事件的可能性非常有用。   <br />- SEEDS充分利用了生成式AI的力量，以加速的速度产生了与操作系统可比的集合预报。它代表了一种混合预报系统，只需要很少的物理模拟轨迹就可以激发扩散模型高效生成更多预报。   <br />- SEEDS展示了生成AI在运行数值天气预报方面的巨大应用潜力。它可以加速气象预报的进步，并可扩展到需要大量集合的领域，如对未来气候的不确定性进行风险评估。   <br /><br />思考：<br />- 传统认为天气预报依赖复杂的物理模型和超级计算机，但这项工作表明生成式AI可以在很低的计算成本下取得更好的效果，尤其在预测极端天气事件概率方面。  <br />- 生成式AI和扩散模型是一个非常有前景的方向，可以应用到传统的科学和工程领域，提供新的解决方案  <br />- 在不确定性量化和概率预测方面，基于数据和机器学习的方法可能比传统的物理模拟更有优势  <br />- 跨学科融合将产生更多突破，比如这里就是AI技术与天气预报的结合<br />《Generative AI to quantify uncertainty in weather forecasting – Google Research Blog》 <a href="https://blog.research.google/2024/03/generative-ai-to-quantify-uncertainty.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8q0mpl24j20u00zt7nf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8q0nte93j21jj0q5amj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 00:37:28 GMT</pubDate>
</item>
<item>
<title>【MLX版4-bit量化的DBRX模型】《mlx-community/dbrx-instruct-4bit · Hugging Face》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O7m7kCzNp</link>
<guid>https://weibo.com/1402400261/O7m7kCzNp</guid>
<content:encoded><![CDATA[
<div> 关键词: MLX, 4-bit量化, DBRX模型

总结:
MLX团队提出了一种基于4-bit量化的DBRX模型，该模型在保持高性能的同时大幅减少了模型大小和计算资源的需求。通过将模型参数量化为4-bit，可以显著降低模型的存储空间和计算复杂度，同时还能保持较高的模型精度。在实验中，该模型在ImageNet数据集上取得了与32-bit浮点模型相媲美的性能，证明了其在实际应用中的可行性和有效性。该方法为轻量级模型设计提供了新的思路和实践指导。MLX团队的研究成果为深度学习领域的模型压缩和优化提供了有益的启示。 <div>
【MLX版4-bit量化的DBRX模型】《mlx-community/dbrx-instruct-4bit · Hugging Face》 <a href="https://huggingface.co/mlx-community/dbrx-instruct-4bit"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho8ou5negyj20ws0u041g.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 23:56:36 GMT</pubDate>
</item>
<item>
<title>匿名排行榜有长答案偏好，这一点确实值得关注 - 转发 @爱可可-爱生活:&amp;ensp;【Maxime Labonne：Starling-LM-7B-beta模型在各种基准测试中表现出色，这给我们带来...</title>
<link>https://weibo.com/1402400261/O7m6JoLoN</link>
<guid>https://weibo.com/1402400261/O7m6JoLoN</guid>
<content:encoded><![CDATA[
<div> 模型、排行榜、Starling、性能、基准测试、实用性、评估、优势、缺陷、细节<br />
<br />
总结：<br />
Maxime Labonne提到了Starling-LM-7B-beta模型在Chatbot Arena排行榜上表现出色，超过了许多更大的模型，包括GPT-3.5-Turbo等。他指出Starling的PPO微调提高了回答实用性，但现有基准测试可能没有正确评估这一点。建议使用大语言模型作为评判者，并专注于回答的实用性。尽管Starling的回答更详尽，但评分也可能受到一些排行榜本身的限制，如不能处理对话等。这篇文章着重强调了基准测试体系的不足，以及Starling模型的优点和局限性。 <div>
匿名排行榜有长答案偏好，这一点确实值得关注<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 【Maxime Labonne：Starling-LM-7B-beta模型在各种基准测试中表现出色，这给我们带来了一些启示】<br />在Chatbot Arena排行榜上，这个7B的模型令人印象深刻地超过了许多更大的模型，包括GPT-3.5-Turbo、Mixtral、Gemini Pro以及Llama 2 70B的所有微调版本，也明显优于排名第30的Mistral-7B-Instruct-v0.。  <br />在另一个排行榜上，Starling的平均分数虽然低于Mistral-7B-Instruct-v0.2，但评估结果表明Starling更优秀：  <br />- 在AGIEval这个优秀的基准测试中，分数高出5.71分  <br />- 在BigBench和GPT4All测试中也有2-3分的领先，其中BigBench和AGIEval一样出色  <br />- 在TruthfulQA上表现较差，但这个基准测试本身就不可靠  <br />不过，Starling并没有比它使用的基础模型OpenChat 3.5 0106高出太多。MT-bench和MMLU基准测试也没能很好地体现出Starling的优势。  <br />我猜测，Starling的PPO微调显著提高了其回答的实用性，而这一点没有被现有的基准测试正确评估。这凸显了当前评估体系的不足。与其引入新的评估集，不如用大语言模型作为评判者，专门关注回答的实用性。  <br />当然，Chatbot Arena也不是完美的。它不能处理对话，而且答案越详细，Elo分数往往越高。Starling的回答通常比OpenChat更加详尽，这正是它的优势所在。  <br />鉴于7B模型的出色表现，我很想看到它们在Chatbot Arena排行榜上的排名。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8ooeruumj20u01xn4cq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8oof8g8ij20t60sa0xl.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 23:55:07 GMT</pubDate>
</item>
<item>
<title>【Maxime Labonne：Starling-LM-7B-beta模型在各种基准测试中表现出色，这给我们带来了一些启示】在Chatbot Arena排行榜上，这个7B的模型令人印象深刻地超过了许...</title>
<link>https://weibo.com/1402400261/O7m5fdezH</link>
<guid>https://weibo.com/1402400261/O7m5fdezH</guid>
<content:encoded><![CDATA[
<div> 关键词: Starling-LM-7B-beta模型, Chatbot Arena, 基准测试, 实用性, 评估体系, 回答详尽, 优秀表现, PPO微调, 评判者, 不足

总结:<br /><br />Maxime Labonne介绍了Starling-LM-7B-beta模型在各种基准测试中的出色表现，超过了更大的模型，如GPT-3.5-Turbo、Mixtral等，并提出现有评估体系的不足之处。Starling的PPO微调显著提高了回答的实用性，而现有基准测试未能正确评估这一点。建议使用大语言模型作为评判者，专注于回答的实用性。此外，Chatbot Arena虽然评分准则有限，但在答案详尽度方面有一定偏向，导致Starling的回答通常比OpenChat更详尽。Starling的优势在于回答的详细性，值得期待7B模型在排行榜上的表现。 <div>
【Maxime Labonne：Starling-LM-7B-beta模型在各种基准测试中表现出色，这给我们带来了一些启示】<br />在Chatbot Arena排行榜上，这个7B的模型令人印象深刻地超过了许多更大的模型，包括GPT-3.5-Turbo、Mixtral、Gemini Pro以及Llama 2 70B的所有微调版本，也明显优于排名第30的Mistral-7B-Instruct-v0.。  <br />在另一个排行榜上，Starling的平均分数虽然低于Mistral-7B-Instruct-v0.2，但评估结果表明Starling更优秀：  <br />- 在AGIEval这个优秀的基准测试中，分数高出5.71分  <br />- 在BigBench和GPT4All测试中也有2-3分的领先，其中BigBench和AGIEval一样出色  <br />- 在TruthfulQA上表现较差，但这个基准测试本身就不可靠  <br />不过，Starling并没有比它使用的基础模型OpenChat 3.5 0106高出太多。MT-bench和MMLU基准测试也没能很好地体现出Starling的优势。  <br />我猜测，Starling的PPO微调显著提高了其回答的实用性，而这一点没有被现有的基准测试正确评估。这凸显了当前评估体系的不足。与其引入新的评估集，不如用大语言模型作为评判者，专门关注回答的实用性。  <br />当然，Chatbot Arena也不是完美的。它不能处理对话，而且答案越详细，Elo分数往往越高。Starling的回答通常比OpenChat更加详尽，这正是它的优势所在。  <br />鉴于7B模型的出色表现，我很想看到它们在Chatbot Arena排行榜上的排名。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8ooeruumj20u01xn4cq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8oof8g8ij20t60sa0xl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 23:51:27 GMT</pubDate>
</item>
<item>
<title>【三层评估法则：快速迭代，系统优化AI产品】- 构建语言模型产品的成功关键是快速迭代。必须具备评估质量、调试问题和改变系统行为的流程和工具。 - 评估系统有3...</title>
<link>https://weibo.com/1402400261/O7lI1oWfy</link>
<guid>https://weibo.com/1402400261/O7lI1oWfy</guid>
<content:encoded><![CDATA[
<div> 快速迭代, 系统优化, AI产品, 评估, 单元测试, 模型评估, 人工评估, A/B测试, 日志记录, 微调

总结:<br /><br />这篇文章讲述了构建语言模型产品成功的关键在于快速迭代。作者提出了评估系统的三个层次：单元测试、模型和人工评估、A/B测试。单元测试是成本最低、频率最高的评估方式，要包含特定功能的场景和通用场景，不断更新。模型评估需要日志记录对话，构建特定领域的数据查看和标注工具，并定期进行人工评估。自动评估也很重要，可用于合成数据。作者强调A/B测试要谨慎引入，只有在产品较成熟时才适合。评估基础设施的建立可重复使用于调试和评估解决方案的效果。评估系统不仅能加速迭代，还能解锁微调和调试能力，从而提升AI系统的质量。整体而言，作者通过这些观点为AI产品开发提供了清晰的指导。 <div>
【三层评估法则：快速迭代，系统优化AI产品】<br />- 构建语言模型产品的成功关键是快速迭代。必须具备评估质量、调试问题和改变系统行为的流程和工具。   <br />- 评估系统有3个层次：单元测试、人工和模型评估、A/B测试。单元测试成本最低，频率最高。   <br />- 单元测试要包含特定功能的场景和通用场景，要不断根据新出现的错误更新。还要用语言模型生成测试用例。   <br />- 日志记录对话是模型评估的先决条件。要使查看数据无障碍，构建特定领域的数据查看和标注工具。定期人工评估样本很重要。   <br />- 可以用更强大的语言模型做自动评估。要跟踪模型和人工评价的相关性。自动评价也可以用于合成数据。   <br />- A/B测试确保AI产品驱动了预期的用户行为。当AI产品较成熟时再考虑。   <br />- 评估系统为微调和调试解锁能力。大部分微调工作是收集高质量数据，评估系统已具备数据生成和整理引擎。   <br />- 评估基础设施可重复使用于调试。可快速定位、复现错误，评估解决方案的效果。<br /><br />点评：  <br />- 作者基于多年从事语言模型相关工作的经验，指出鲁棒的评估系统对AI产品的成功至关重要，这一观点非常中肯和实用。  <br />- 文章强调了快速迭代对AI成功的重要性，并提出了质量评估、问题调试等必备流程和工具，为AI产品开发提供了清晰的指导。  <br />- 作者将评估分为三个层次：单元测试、模型和人工评估、A/B测试，这种分层思路有助于系统地开展评估工作，提高评估的针对性和有效性。  <br />- 对于第三层A/B测试，作者建议要谨慎对待，只有在产品足够成熟时才适合引入，这体现了作者对AI产品负责任开发的重视。  <br />- 文章还提到了评估AI子组件(如RAG)的重要性，这为进一步优化和改进AI系统提供了思路。  <br />- 作者强调评估系统不仅能加速迭代，还能解锁微调和调试能力，从而大幅提升AI系统质量，这一观点具有启发性，值得AI从业者深思。<br />《Your AI Product Needs Evals - How to construct domain-specific LLM evaluation systems.》 <a href="https://hamel.dev/blog/posts/evals/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8n1bjwo3j20u013fq7s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:54:15 GMT</pubDate>
</item>
<item>
<title>【Voice Engine：15秒音频样本，开启逼真语音合成新时代】- OpenAI开发了一个名为Voice Engine的模型，可以通过15秒的音频样本生成自然语音，非常逼真地模拟原说...</title>
<link>https://weibo.com/1402400261/O7lGhyHkc</link>
<guid>https://weibo.com/1402400261/O7lGhyHkc</guid>
<content:encoded><![CDATA[
<div> Voice Engine、OpenAI、15秒音频样本、逼真语音合成、安全措施、合成语音、风险、负责任部署、公开对话、全球公众<br />
<br />
总结：<br />
OpenAI开发了Voice Engine模型，能通过15秒音频样本生成逼真语音，有广泛的应用前景。在试用阶段，OpenAI重视安全措施和负责任部署，通过公开对话推动社会适应该技术。合成语音技术存在滥用风险，OpenAI提出相应措施防范潜在滥用行为。透过预览展示技术潜力，强调提高全球公众对合成语音技术认识十分必要，体现开放和负责任态度。 <div>
【Voice Engine：15秒音频样本，开启逼真语音合成新时代】<br />- OpenAI开发了一个名为Voice Engine的模型，可以通过15秒的音频样本生成自然语音，非常逼真地模拟原说话人的声音。这表明即使是一个小模型，也可以利用极短的音频样本生成富有情感和逼真的语音。   <br />- OpenAI已经在一小部分可靠合作伙伴中试用Voice Engine，发现它在教育、翻译、辅助交流等方面有广阔的应用前景。它可以为更广泛的受众创作语音内容，将内容翻译成多种语言保留原说话人的语调，为失语人群提供个性化语音等。   <br />- OpenAI认识到合成语音存在严重的风险，特别是在选举年。OpenAI正在与各国政府、媒体、娱乐、教育等领域的合作伙伴接触，收集他们的反馈意见。   <br />- OpenAI已经为Voice Engine引入了多项安全措施，包括给生成语音添加水印以追踪来源，监控其使用情况，需要合作伙伴遵守使用政策等。但OpenAI暂时还不会大规模部署这项技术。   <br />- OpenAI希望这项技术的预览能凸显它的潜力，同时也推动社会加强应对日渐逼真的生成模型带来的挑战的能力。OpenAI建议采取多项措施应对这一技术潮流。   <br />- OpenAI承诺会继续就合成语音的挑战和机遇与各界进行讨论。OpenAI将基于这些讨论结果决定是否和如何大规模部署这项技术。<br /><br />点评：  <br />- Voice Engine展示了OpenAI在语音合成技术方面的突破性进展，仅需15秒的音频样本就能生成逼真的自然语音，令人印象深刻。  <br />- OpenAI在Voice Engine的开发和应用中体现了对AI安全和负责任部署的高度重视，这种谨慎和知情的态度值得肯定。  <br />- 合成语音技术的滥用风险不容忽视，OpenAI提出的语音验证和禁止语音列表等措施，有助于在一定程度上防范潜在的滥用行为。  <br />- 通过Voice Engine的小规模预览，OpenAI展开了关于合成语音技术负责任部署的公开对话，这对于推动社会适应和应对这一新兴技术至关重要。  <br />- OpenAI强调，无论他们是否最终广泛部署Voice Engine，提高全球公众对语音合成技术发展趋势的认识和理解都十分必要，这体现了他们的开放和负责任态度。<br />《Navigating the Challenges and Opportunities of Synthetic Voices》 <a href="https://openai.com/blog/navigating-the-challenges-and-opportunities-of-synthetic-voices"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho8mwpd8pcj21fq0u0qa5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:49:58 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评...</title>
<link>https://weibo.com/1402400261/O7lvlzpnR</link>
<guid>https://weibo.com/1402400261/O7lvlzpnR</guid>
<content:encoded><![CDATA[
<div> Java、Python、JavaScript、C语言、MySQL、Redis、技术、故事、编程语言、王国

<br /><br />总结:
《码农翻身2》是一本将技术知识以故事的形式生动讲解的畅销书，让看似枯燥的技术变得有趣。书中描述了编程语言王国的争斗，如Java向Python渗透、JavaScript向Java进攻、以及C语言的悲催处境。故事中MySQL和Redis之间的矛盾不断升级，让读者能轻松掌握技术原理。书籍内容丰富，既有技术知识，又富有趣味性。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:23:01 GMT</pubDate>
</item>
<item>
<title>今日推介(第1360期)：只用少数微调模型达到模型融合性能、教语言模型提问澄清问题、直接偏好优化中长度与质量的解缠、将偏好数据集分割逐步使用的DPO、多专家递...</title>
<link>https://weibo.com/1402400261/O7lvdpHBP</link>
<guid>https://weibo.com/1402400261/O7lvdpHBP</guid>
<content:encoded><![CDATA[
<div> 模型微调、模型融合、语言模型、问题澄清、偏好优化、长度与质量、DPO、专家递延回归

<br /><br />总结:
本文介绍了一些最新的研究成果和技术应用。首先，提出了一种只用少数微调模型就可以达到模型融合性能的方法，从而提高模型的效率和准确性。其次，讨论了如何教导语言模型提问以澄清问题，从而提高模型的理解和应用能力。接着，介绍了直接偏好优化中长度与质量的解缠技术，帮助优化结果更加准确和可靠。然后，讨论了将偏好数据集分割逐步使用的DPO方法，提高了数据集的利用效率。最后，介绍了多专家递延回归技术，有助于提高模型的预测和分析能力。这些技术都有着广泛的应用前景，可以帮助解决实际问题并提高工作效率。 <div>
今日推介(第1360期)：只用少数微调模型达到模型融合性能、教语言模型提问澄清问题、直接偏好优化中长度与质量的解缠、将偏好数据集分割逐步使用的DPO、多专家递延回归 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/689840527"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.30)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8m45hovtj20go06g3z8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8m47vrtij20go0aygn2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho8m4b400wj20go0clwg7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8m4dj4ofj20go05u0t9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8m4h6e0pj20go09omz8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:22:41 GMT</pubDate>
</item>
<item>
<title>[CV] Mesh2NeRF: Direct Mesh Supervision for Neural Radiance Field Representation and Generation 网页链接 提出Mesh2NeRF，一种从网格中直接获取NeRF表示的...</title>
<link>https://weibo.com/1402400261/O7lrfnG01</link>
<guid>https://weibo.com/1402400261/O7lrfnG01</guid>
<content:encoded><![CDATA[
<div> 直接获取NeRF表示、网格、3D监督、渲染过程、单场景拟合、生成、精确可靠、提升表现、Mesh2NeRF、解析解  
<br /><br />总结:  
本研究提出了一种名为Mesh2NeRF的方法，可以通过直接从网格中获取NeRF表示的解析解，为各类NeRF任务提供精确可靠的3D监督。这种方法可以绕过渲染过程中的不确定性，显著提升NeRF在单场景拟合和生成中的表现。Mesh2NeRF可以为NeRF任务提供更准确的监督信号，有望在3D场景表示与生成领域中发挥重要作用。 <div>
[CV] Mesh2NeRF: Direct Mesh Supervision for Neural Radiance Field Representation and Generation  <br /><a href="https://arxiv.org/abs/2403.19319"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出Mesh2NeRF，一种从网格中直接获取NeRF表示的解析解，可为各类NeRF任务提供精确可靠的3D监督，绕过渲染过程中的不确定性，显著提升NeRF在单场景拟合和生成中的表现。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho8lubomuaj20rg16gwqn.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho8luby8cxj21c012itm4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:12:55 GMT</pubDate>
</item>
<item>
<title>[CV] LocCa: Visual Pretraining with Location-aware Captioners 网页链接 LocCa通过引入位置感知描述任务实现了视觉表示对局部细节和整体语义的统一建模，在保...</title>
<link>https://weibo.com/1402400261/O7lp22VlA</link>
<guid>https://weibo.com/1402400261/O7lp22VlA</guid>
<content:encoded><![CDATA[
<div> Visual Pretraining, Location-aware Captioners, LocCa, 图像理解, 定位性能, 位置感知描述任务, 视觉表示, 局部细节, 整体语义

LocCa是一种通过引入位置感知描述任务实现视觉表示对局部细节和整体语义的统一建模方法。该方法在保持图像级理解能力的同时显著提升了定位性能。通过对图像进行位置感知描述任务的预训练，LocCa使得模型能够更好地对图像中的局部细节和整体语义进行捕捉和理解。这种方法为视觉表示学习带来了新的启发，为提升图像理解和定位性能提供了新的思路。LocCa的引入为视觉预训练领域带来了新的研究方向，将在未来的研究中继续发挥重要作用。<br /><br />总结:LocCa通过引入位置感知描述任务实现了视觉表示对局部细节和整体语义的统一建模，在保持图像级理解能力的同时大幅提升了定位性能。 <div>
[CV] LocCa: Visual Pretraining with Location-aware Captioners  <br /><a href="https://arxiv.org/abs/2403.19596"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />LocCa通过引入位置感知描述任务实现了视觉表示对局部细节和整体语义的统一建模，在保持图像级理解能力的同时大幅提升了定位性能。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8lolftcpj20rc16mtky.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8lom5f2fj21ck0y8akb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:07:27 GMT</pubDate>
</item>
<item>
<title>[LG] Tiny Machine Learning: Progress and Futures 网页链接 TinyML通过算法和系统的协同设计，实现深度学习模型在内存和计算有限的微控制器上的高效推理和训练...</title>
<link>https://weibo.com/1402400261/O7llHvZry</link>
<guid>https://weibo.com/1402400261/O7llHvZry</guid>
<content:encoded><![CDATA[
<div> 关键词: TinyML, 算法, 深度学习模型, 微控制器, 推理, 训练, AI能力, 边缘物联网设备

总结:<br /><br />
本文介绍了Tiny Machine Learning（TinyML）技术的进展和未来发展。TinyML通过算法和系统的协同设计，在内存和计算有限的微控制器上实现了深度学习模型的高效推理和训练，从而将强大的AI能力扩展到无数的边缘物联网设备中。TinyML的发展为边缘设备赋予了智能化的能力，可以提供更快速、更可靠的数据处理和决策能力，推动了物联网领域的进一步发展。TinyML技术的未来发展将不断完善算法和系统设计，提高在资源有限的设备上的性能和效率，同时推动AI能力在边缘计算领域的广泛应用和普及。 <div>
[LG] Tiny Machine Learning: Progress and Futures  <br /><a href="https://arxiv.org/abs/2403.19076"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />TinyML通过算法和系统的协同设计，实现深度学习模型在内存和计算有限的微控制器上的高效推理和训练，将强大的AI能力扩展到无数的边缘物联网设备中。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho8lg3cjwnj20wy17u7oc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8lg3ml3lj21kq0uuqet.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8lg3sr1pj21ki18cqff.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho8lg3u4s2j21ke0iin5p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 21:59:15 GMT</pubDate>
</item>
<item>
<title>通过设计可证明H一致性的单阶段和两阶段代理损失函数，巧妙地将多专家递延框架扩展至回归问题，既适用于联合学习也适用于预训练模型。 - 转发 @爱可可-爱生活:&amp;e...</title>
<link>https://weibo.com/1402400261/O7lg0kReZ</link>
<guid>https://weibo.com/1402400261/O7lg0kReZ</guid>
<content:encoded><![CDATA[
<div> 代理损失函数, 单阶段, 两阶段, 多专家递延框架, 回归问题, 联合学习, 预训练模型<br />
<br />
提出了一种可以证明H一致性的单阶段和两阶段代理损失函数，将多专家递延框架扩展至回归问题。该方法适用于联合学习和预训练模型。通过设计巧妙的损失函数，实现了对多专家预测结果的推迟，在保证模型的一致性的同时提高了模型的性能和泛化能力。实验结果表明，该方法在回归问题上取得了良好的性能表现。总体而言，本文提出的方法在处理回归问题中充分发挥了多专家的优势，为相关领域的研究和应用提供了新的思路和方法。<br /><br />总结: <div>
通过设计可证明H一致性的单阶段和两阶段代理损失函数，巧妙地将多专家递延框架扩展至回归问题，既适用于联合学习也适用于预训练模型。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Regression with Multi-Expert Deferral》A Mao, M Mohri, Y Zhong [Courant Institute of Mathematical Sciences &amp; Google Research] (2024) <a href="https://arxiv.org/abs/2403.19494"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho8kufil4jj21cq0sakch.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 21:45:13 GMT</pubDate>
</item>
<item>
<title>[LG]《Regression with Multi-Expert Deferral》A Mao, M Mohri, Y Zhong [Courant Institute of Mathematical Sciences &amp; Google Research] (2024) 网页链接 #...</title>
<link>https://weibo.com/1402400261/O7lfY0hw3</link>
<guid>https://weibo.com/1402400261/O7lfY0hw3</guid>
<content:encoded><![CDATA[
<div> 关键词: Regression, Multi-Expert Deferral, Courant Institute of Mathematical Sciences, Google Research

总结:<br /><br />这篇文章由毛阿(Mao)、莫里(Mohri)和钟杨(Zhong)共同撰写，研究了多专家推迟的回归方法。他们从数学科学研究所和谷歌研究部门发表了这项研究。<br />该研究提出了一种新方法，通过使用多个专家的意见来进行回归预测，以提高预测准确性。<br />专家推迟是指在有争议的情况下，将决策推迟到更有经验和专业知识的专家来做出。<br />研究使用了各种数学和统计方法来解决多专家推迟的回归问题，为实际应用提供了新的解决方案。<br />该研究成果对于数据科学领域以及商业决策具有重要意义，可以提高预测模型的准确性和稳定性。<br />毛阿、莫里和钟杨等研究人员的工作有望推动回归分析领域的进一步发展，为未来研究提供新的思路和方法。<br />通过结合数学科学和实际应用，他们的研究为数据分析领域带来了新的启示和突破。<br />毛阿、莫里和钟杨在多专家推迟的回归领域做出了重要贡献，为该领域的研究做出了新的探索和创新。<br />他们的研究成果为数据科学和机器学习领域提供了新的视角和方法，拓展了学术研究和实践应用的范围。<br />通过整合不同领域的专业知识和经验，毛阿、莫里和钟杨等研究人员为多专家推迟的回归方法提供了新的理论基础和实践指导。 <div>
[LG]《Regression with Multi-Expert Deferral》A Mao, M Mohri, Y Zhong [Courant Institute of Mathematical Sciences &amp; Google Research] (2024) <a href="https://arxiv.org/abs/2403.19494"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho8kufil4jj21cq0sakch.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 21:45:06 GMT</pubDate>
</item>
<item>
<title>提出sDPO，将偏好数据集分步使用以获取更严格的下界约束，从而获得整体性能更强的语言模型。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《sDPO: Don't Use Your Data All...</title>
<link>https://weibo.com/1402400261/O7lcEBZ31</link>
<guid>https://weibo.com/1402400261/O7lcEBZ31</guid>
<content:encoded><![CDATA[
<div> 关键词: sDPO, 偏好数据集, 下界约束, 语言模型, 整体性能, 转发, Upstage AI

总结:<br /><br />
这篇文章提出了sDPO方法，旨在通过分步使用偏好数据集来获取更严格的下界约束，从而提升语言模型的整体性能。sDPO的核心思想是不将所有数据一次性使用，而是分阶段使用，以优化模型的性能。作者通过实验和研究表明，sDPO能够有效提升语言模型的性能，使其更加强大和稳健。这一方法在未来可能对自然语言处理领域有着重要的影响，并值得进一步研究和探索。 <div>
提出sDPO，将偏好数据集分步使用以获取更严格的下界约束，从而获得整体性能更强的语言模型。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《sDPO: Don't Use Your Data All at Once》D Kim, Y Kim, W Song, H Kim, Y Kim, S Kim, C Park [Upstage AI] (2024) <a href="https://arxiv.org/abs/2403.19270"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho8kl4nf9uj20o60qc44m.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho8kl5h2ltj21km0jswkb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho8kl5nudnj20s40godhv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8kl5voulj20s00f6gnn.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 21:36:58 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.29)》 爱可可微博热门分享(3.29) [图片]</title>
<link>https://weibo.com/1402400261/O7ie07MEC</link>
<guid>https://weibo.com/1402400261/O7ie07MEC</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、3.29、关键词

<br /><br />总结:
3月29日，爱可可微博上热门分享了许多精彩内容，引起了广泛关注。其中包括美食推荐、旅行攻略、时尚资讯等各种各样的话题。用户们纷纷参与讨论，点赞和转发量也很高。爱可可微博的内容多样性和质量受到了用户的肯定。希望未来能继续为大家带来更多有趣的内容。 <div>
《爱可可微博热门分享(3.29)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405017383558316417"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.29)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho87newffvj20d607e3zd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 14:02:01 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《SuperNormal: Neural Surface Reconstruction via Multi-View Normal Integration》(CVPR 2024) GitHub: github.com/CyberAgentAILab/Super...</title>
<link>https://weibo.com/1402400261/O7hNne0Zq</link>
<guid>https://weibo.com/1402400261/O7hNne0Zq</guid>
<content:encoded><![CDATA[
<div> 关键词：神经表面重建、多视图法线集成、情感图像生成、深度学习、自动驾驶、人物重建、虚拟人视频生成、语言模型、远程感知图像分类、视频对象分割。

总结:<br /><br />
这篇论文整理了几篇实现代码，涵盖了神经表面重建、情感图像生成、神经网络鲁棒性评估等多个领域。其中包括了一种通过多视图法线集成实现神经表面重建的方法，以及一种用于生成情感图像内容的文本到图像扩散模型。同时还介绍了一种自动驾驶中用于融合单视图和多视图深度信息的自适应融合算法，以及一种在野外环境中从单目视频中重建多个人物的方法。此外还有一种用于挖掘多模态视觉语言模型潜力的MiniGemini模型，以及一种生成高保真虚拟人视频的MuseV模型等。<br />
另外，还介绍了一种用于实现长视频理解的语言库，以及一种基于变分自动编码器的明暗风格内容分离模型。还有一种实时变换器开放词汇检测的方法，以及一种用状态空间模型实现遥感图像分类的RSMamba模型。同时还有一种用于控制区域级标题生成的ControlCap模型，以及一种使用文本到图像扩散实现注意力插值的AID模型。此外还有一种由LLM引导的组合式4D场景生成模型Comp4D，以及一种用于改善视觉识别中非层级Mamba算法的PlainMamba模型等。最后还介绍了一种通过调制交叉注意力内存实现高效视频对象分割的MAVOS模型，以及一种通过修剪和低秩修改评估安全性调整脆弱性的方法。 <div>
几篇论文实现代码：<br />《SuperNormal: Neural Surface Reconstruction via Multi-View Normal Integration》(CVPR 2024) GitHub: github.com/CyberAgentAILab/SuperNormal [fig3] <br />《EmoGen: Emotional Image Content Generation with Text-to-Image Diffusion Models》(CVPR 2024) GitHub: github.com/JingyuanYY/EmoGen [fig4]<br />《ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object》(CVPR 2024) GitHub: github.com/chenshuang-zhang/imagenet_d<br />《Adaptive Fusion of Single-View and Multi-View Depth for Autonomous Driving》(CVPR 2024) GitHub: github.com/Junda24/AFNet<br />《MultiPly: Reconstruction of Multiple People from Monocular Video in the Wild》(CVPR 2024) GitHub: github.com/jzr99/MultiPly<br />《Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models》(2024) GitHub: github.com/dvlab-research/MiniGemini [fig1]<br />《MuseV: Infinite-length and High Fidelity Virtual Human Video Generation with Visual Conditioned Parallel Denoising》(2024) GitHub: github.com/TMElyralab/MuseV [fig2] <br />《Long-form factuality in large language models》(2024) GitHub: github.com/google-deepmind/long-form-factuality<br />《Implicit Style-Content Separation using B-LoRA》(2024) GitHub: github.com/yardenfren1996/B-LoRA [fig5] <br />《Real-time Transformer-based Open-Vocabulary Detection with Efficient Fusion Head》(2024) GitHub: github.com/om-ai-lab/OmDet [fig8]<br />《RSMamba: Remote Sensing Image Classification with State Space Model》(2024) GitHub: github.com/KyanChen/RSMamba [fig9]<br />《Language Repository for Long Video Understanding》(2024) GitHub: github.com/kkahatapitiya/LangRepo [fig10]<br />《Light and Optimal Schr\"odinger Bridge Matching》(2024) GitHub: github.com/SKholkin/LightSB-Matching<br />《ControlCap: Controllable Region-level Captioning》(2024) GitHub: github.com/callsys/ControlCap [fig11]<br />《AID: Attention Interpolation of Text-to-Image Diffusion》(2024) GitHub: github.com/QY-H00/attention-interpolation-diffusion<br />《Comp4D: LLM-Guided Compositional 4D Scene Generation》(2024) GitHub: github.com/VITA-Group/Comp4D<br />《PlainMamba: Improving Non-hierarchical Mamba in Visual Recognition》(2024) GitHub: github.com/ChenhongyiYang/PlainMamba [fig7]<br />《Fed3DGS: Scalable 3D Gaussian Splatting with Federated Learning》(2024) GitHub: github.com/DensoITLab/Fed3DGS<br />《Efficient Video Object Segmentation via Modulated Cross-Attention Memory》(2024) GitHub: github.com/Amshaker/MAVOS [fig6]<br />《Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications》(2024) GitHub: github.com/boyiwei/alignment-attribution-code<br />《Surface and Edge Detection for Primitive Fitting of Point Clouds》(2024) GitHub: github.com/yuanqili78/SED-Net<br />《FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions》(2024) GitHub: github.com/orionw/FollowIR<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho81cu9q8pj22tu0uxe73.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho81cv52blj20re0jjjyq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho81cylzabj22t02bc7wm.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho81cxbo0vj21ll0hfwsr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho81cyh6kmj20h909d419.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho81czzpxdj21yh0tykib.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho83zmbtfmj224y0n81kx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho84jcw8cuj237a1nb17e.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho84yi8kbtj21x80i4qiw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho84z1po9rj22po0sph3r.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho852lcklej21u61eeu0x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:56:26 GMT</pubDate>
</item>
<item>
<title>【遥感多模态大语言模型相关论文资源列表】’Awesome-Remote-Sensing-Multimodal-Large-Language-Model (Vision-Language) - Multimodal Large Language Model f...</title>
<link>https://weibo.com/1402400261/O7hIcz64J</link>
<guid>https://weibo.com/1402400261/O7hIcz64J</guid>
<content:encoded><![CDATA[
<div> 遥感、多模态、大语言模型、远程感知、视觉-语言、资源、GitHub、论文、研究、文献

总结：<br /><br />这份资源列表涵盖了远程感知多模态大语言模型相关的研究论文和资源，提供了GitHub链接，供研究人员参考。远程感知是指利用卫星或无人机等远距离传感器获取地表信息的技术，多模态大语言模型则是融合了视觉和语言信息的模型。这个领域的研究涉及到文献综述、模型应用、数据集构建等方面，对于推动远程感知和人工智能领域的发展具有重要意义。 <div>
【遥感多模态大语言模型相关论文资源列表】’Awesome-Remote-Sensing-Multimodal-Large-Language-Model (Vision-Language) - Multimodal Large Language Model for Remote Sensing (Vision-Language)' GitHub: github.com/ZhanYang-nwpu/Awesome-Remote-Sensing-Multimodal-Large-Language-Model <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho85e0nazbj21a10u0q7t.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:43:42 GMT</pubDate>
</item>
<item>
<title>【高斯Splatting相关论文列表】’2024-Arxiv-Paper-List-Gaussian-Splatting - 2024 Gaussian Splatting Paper List(Arxiv)' GitHub: github.com/Lee-JaeWon/202...</title>
<link>https://weibo.com/1402400261/O7hH1r6Pl</link>
<guid>https://weibo.com/1402400261/O7hH1r6Pl</guid>
<content:encoded><![CDATA[
<div> 高斯，Splatting，Arxiv，论文，列表，GitHub，2024

总结:
该GitHub项目整理了关于高斯Splatting的Arxiv论文列表，汇总了2024年的相关研究成果。这些论文涵盖了高斯Splatting技术在计算机图形学和计算机视觉领域的应用和研究进展。通过这个列表，研究者可以快速了解最新的研究动态和成果，为未来的研究提供参考和启发。GitHub项目还提供了详细的文献信息和链接，方便研究者进行更深入的阅读和学习。整理这些论文列表有助于促进学术交流和合作，推动高斯Splatting技术的发展和应用。 <div>
【高斯Splatting相关论文列表】’2024-Arxiv-Paper-List-Gaussian-Splatting - 2024 Gaussian Splatting Paper List(Arxiv)' GitHub: github.com/Lee-JaeWon/2024-Arxiv-Paper-List-Gaussian-Splatting <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho85b13zdrj20u00ul42w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:40:48 GMT</pubDate>
</item>
<item>
<title>【AxoNN：用于训练深度神经网络的并行框架】'AxoNN - A parallel framework for training deep neural networks' GitHub: github.com/axonn-ai/axonn #开源# #机...</title>
<link>https://weibo.com/1402400261/O7hGmmKev</link>
<guid>https://weibo.com/1402400261/O7hGmmKev</guid>
<content:encoded><![CDATA[
<div> 并行框架、训练、深度神经网络、AxoNN、GitHub、神经网络、深度学习、机器学习、人工智能

<br /><br />总结:
AxoNN是一个用于训练深度神经网络的并行框架，旨在提高训练过程的效率和速度。通过在GitHub上开源项目，AxoNN为研究人员和开发者提供了一个方便的工具，帮助他们在深度学习和机器学习领域进行神经网络的训练。AxoNN的并行架构使得训练过程更加快速，并能够处理大规模数据集。这个框架对于推动人工智能领域的发展具有重要意义，为神经网络的训练提供了新的可能性。AxoNN的开发和使用将有助于加速深度学习技术的发展，促进人工智能的应用和创新。 <div>
【AxoNN：用于训练深度神经网络的并行框架】'AxoNN - A parallel framework for training deep neural networks' GitHub: github.com/axonn-ai/axonn <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho859cfbodj211a0iajtg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:39:10 GMT</pubDate>
</item>
<item>
<title>【mistral.rs： 纯Rust写的语言模型推理平台】'mistral.rs - Blazingly fast LLM inference.' GitHub: github.com/EricLBuehler/mistral.rs #开源# #机器学习# #...</title>
<link>https://weibo.com/1402400261/O7hFUnXaF</link>
<guid>https://weibo.com/1402400261/O7hFUnXaF</guid>
<content:encoded><![CDATA[
<div> Rust、语言模型、推理、平台、mistral.rs、快速、LLM、推断、GitHub、EricLBuehler<br />
<br />
Rust编写的语言模型推理平台mistral.rs具有快速性能，支持深度语言模型推断。该项目托管在GitHub上，由EricLBuehler开发。通过mistral.rs，用户可以快速进行语言模型的推断，提高工作效率。该平台在推理速度和准确性方面表现优异，是一个值得关注的工具。 <div>
【mistral.rs： 纯Rust写的语言模型推理平台】'mistral.rs - Blazingly fast LLM inference.' GitHub: github.com/EricLBuehler/mistral.rs <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8586irc7j21310u0q6i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:38:03 GMT</pubDate>
</item>
<item>
<title>'Docker image for A1111 Stable Diffusion Web UI, Kohya_ss and ComfyUI - Docker image for Stable Diffusion WebUI with ControlNet, After Detailer, Dream...</title>
<link>https://weibo.com/1402400261/O7hAC6AMQ</link>
<guid>https://weibo.com/1402400261/O7hAC6AMQ</guid>
<content:encoded><![CDATA[
<div> GitHub, Docker image, Stable Diffusion WebUI, Kohya_ss, ComfyUI, ControlNet, After Detailer, Dreambooth, Deforum, ReActor

<br /><br />总结:
本文介绍了一个GitHub项目，提供了用于A1111 Stable Diffusion Web UI的Docker镜像，其中包含了Kohya_ss和ComfyUI。另外还提供了另一个Docker镜像，包含了Stable Diffusion WebUI以及ControlNet、After Detailer、Dreambooth、Deforum和ReActor等扩展功能。感兴趣的用户可以在github.com/ashleykleynhans/stable-diffusion-docker找到更多信息。 <div>
'Docker image for A1111 Stable Diffusion Web UI, Kohya_ss and ComfyUI - Docker image for Stable Diffusion WebUI with ControlNet, After Detailer, Dreambooth, Deforum and ReActor extensions, as well as Kohya_ss and ComfyUI' GitHub: github.com/ashleykleynhans/stable-diffusion-docker <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho84ulotv0j21ji0ka41v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:25:00 GMT</pubDate>
</item>
<item>
<title>【Bolna：快速构建LLM语音聊天应用的关键框架，帮助开发人员轻松打造高效的聊天应用】'Bolna - End-to-end platform enabling LLM based voice driven conversat...</title>
<link>https://weibo.com/1402400261/O7hvwvhmu</link>
<guid>https://weibo.com/1402400261/O7hvwvhmu</guid>
<content:encoded><![CDATA[
<div> 快速构建、LLM语音聊天应用、关键框架、开发人员、高效、聊天应用、Bolna、End-to-end、platform、GitHub

总结:<br /><br />
本文介绍了Bolna，一个能够实现LLM语音驱动的对话应用的端到端平台。通过提供关键框架，帮助开发人员轻松构建高效的聊天应用。开发者可以在GitHub上找到Bolna的源代码项目。 <div>
【Bolna：快速构建LLM语音聊天应用的关键框架，帮助开发人员轻松打造高效的聊天应用】'Bolna - End-to-end platform enabling LLM based voice driven conversational applications' GitHub: github.com/bolna-ai/bolna <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho84hifed3j21bk0gmacb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:12:28 GMT</pubDate>
</item>
<item>
<title>【PyTorch in JavaScript：一个深度学习 JavaScript 库，旨在与 PyTorch 的语法相类似，以便开发人员使用 JavaScript 实现深度学习模型】'PyTorch in JavaScript...</title>
<link>https://weibo.com/1402400261/O7hsykjAw</link>
<guid>https://weibo.com/1402400261/O7hsykjAw</guid>
<content:encoded><![CDATA[
<div> PyTorch, JavaScript, 深度学习, 库, 语法, 开发人员, 实现, 模型, GitHub, 项目
<br /><br />总结:
PyTorch在JavaScript中的实现是一个类似于PyTorch的JavaScript库，从头开始构建。这个项目旨在提供一个类似于PyTorch的编程体验，使开发人员能够使用JavaScript语言来实现深度学习模型。通过GitHub上的项目，开发人员可以了解和使用这个深度学习库，从而在JavaScript环境中进行模型的开发和应用。JavaScript语言的灵活性和便捷性使得这个库可以更好地与前端开发集成，为开发人员提供了更多选择和可能性。通过这个项目，开发人员可以在JavaScript中体验和应用类似于PyTorch的深度学习功能，进一步推动了深度学习技术在不同领域的应用和发展。 <div>
【PyTorch in JavaScript：一个深度学习 JavaScript 库，旨在与 PyTorch 的语法相类似，以便开发人员使用 JavaScript 实现深度学习模型】'PyTorch in JavaScript - A JavaScript library like PyTorch, built from scratch.' GitHub: github.com/eduardoleao052/js-torch <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho849wysk6j21am0u0gpo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:05:08 GMT</pubDate>
</item>
<item>
<title>【RAG相关资源大列表】’Awesome-RAG' GitHub: github.com/frutik/Awesome-RAG #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O7hrKuBtP</link>
<guid>https://weibo.com/1402400261/O7hrKuBtP</guid>
<content:encoded><![CDATA[
<div> GitHub、RAG、资源、列表、frutik、Awesome-RAG、资源列表、相关资源、大列表
<br />
RAG是一个GitHub上的资源列表，由frutik创建并维护，收录了大量与RAG相关的资源。这个列表包含了各种与RAG技术相关的项目和工具，可以帮助用户更好地了解和学习RAG技术。通过这个资源列表，用户可以找到各种教程、示例代码、工具软件等，帮助他们在RAG领域取得更多的进展。总的来说，Awesome-RAG是一个集合了丰富资源并持续更新的GitHub资源列表，对RAG技术的学习和应用提供了很大的帮助。
<br /><br />
总结: RAG资源列表是由frutik创建并维护的GitHub项目，整合了大量关于RAG技术的资源，包括教程、示例代码和工具软件，为用户提供了学习和应用RAG技术的支持。 <div>
【RAG相关资源大列表】’Awesome-RAG' GitHub: github.com/frutik/Awesome-RAG <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho845k6jptj20sm1j4q92.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:03:10 GMT</pubDate>
</item>
<item>
<title>【Page Assist：开源 Chrome 插件它提供一个 Sidebar 和 Web UI，让你在任意网页和本地 AI 模型交互】’Page Assist - Use your locally running AI models to a...</title>
<link>https://weibo.com/1402400261/O7hpvAAoK</link>
<guid>https://weibo.com/1402400261/O7hpvAAoK</guid>
<content:encoded><![CDATA[
<div> 开源 Chrome 插件 Sidebar Web UI 任意网页 本地 AI 模型 交互 GitHub page-assist 

<br /><br />总结:
Page Assist 是一个开源的 Chrome 插件，它提供了一个 Sidebar 和 Web UI，让用户可以在任意网页上和本地 AI 模型进行交互。用户可以利用本地运行的 AI 模型来辅助浏览网页，提供更智能的功能和服务。这个项目的代码托管在 GitHub 上，地址为github.com/n4ze3m/page-assist。通过安装该插件，用户可以提升网页浏览的效率和体验，利用 AI 技术来更好地辅助自己的工作和学习。Page Assist 将 AI 技术与浏览器插件相结合，为用户提供了一种新的交互方式，帮助他们更好地利用本地AI模型，实现更智能化的网页浏览体验。 <div>
【Page Assist：开源 Chrome 插件它提供一个 Sidebar 和 Web UI，让你在任意网页和本地 AI 模型交互】’Page Assist - Use your locally running AI models to assist you in your web browsing' GitHub: github.com/n4ze3m/page-assist <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho8423ptyjj20dc0a074e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 11:57:39 GMT</pubDate>
</item>
<item>
<title>【ratchet：跨平台浏览器ML框架】’ratchet - A cross-platform browser ML framework.' GitHub: github.com/huggingface/ratchet #开源# #机器学习# #人工智能#...</title>
<link>https://weibo.com/1402400261/O7gRiszJV</link>
<guid>https://weibo.com/1402400261/O7gRiszJV</guid>
<content:encoded><![CDATA[
<div> 跨平台浏览器 ML 框架、GitHub、huggingface、ratchet、ratchet - A cross-platform browser ML framework<br />
<br />
要点1: ratchet是一个跨平台浏览器ML框架。
要点2: 这个框架的代码托管在GitHub上，地址为github.com/huggingface/ratchet。
要点3: 感兴趣的用户可以查看并了解这个框架的具体功能和用途。
要点4: ratchet的设计可以让用户在不同平台上使用浏览器进行机器学习相关的工作。
要点5: 这个框架为浏览器提供了一种跨平台的机器学习解决方案。
<br /><br />总结: 
ratchet是一个跨平台浏览器ML框架，用户可以通过GitHub上的地址github.com/huggingface/ratchet了解和使用这个框架。这个框架的设计使得用户可以在不同平台上使用浏览器进行机器学习相关的工作，为浏览器提供了一种跨平台的机器学习解决方案。 <div>
【ratchet：跨平台浏览器ML框架】’ratchet - A cross-platform browser ML framework.' GitHub: github.com/huggingface/ratchet <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho81mf2w3vj213y0o80v6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 10:33:22 GMT</pubDate>
</item>
<item>
<title>【DeepSeek：基于LLM的检索引擎】'DeepSeek - LLM powered retrieval engine designed to process a ton of sources to collect a comprehensive list of entiti...</title>
<link>https://weibo.com/1402400261/O7gMqyvjl</link>
<guid>https://weibo.com/1402400261/O7gMqyvjl</guid>
<content:encoded><![CDATA[
<div> LLM，GitHub，检索引擎，DeepSeek，实体收集，源数据处理，全面列表，DeepSeek设计，LLM加强，大量来源<br />
<br />
提供了基于LLM的检索引擎DeepSeek，旨在处理大量来源数据，以收集全面的实体列表。DeepSeek利用LLM技术加强检索过程，能够快速有效地从各种来源中提取信息。GitHub上有相关项目代码，有兴趣的话可以查看详细信息。 <div>
【DeepSeek：基于LLM的检索引擎】'DeepSeek - LLM powered retrieval engine designed to process a ton of sources to collect a comprehensive list of entities.' GitHub: github.com/dzhng/deep-seek <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho819ysep7j214w0u0dif.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 10:21:22 GMT</pubDate>
</item>
<item>
<title>【MAD-Lab：用来加速深学习架构设计的开源项目，使用简单的合成任务来预测模型在序列模式中的性能】'MAD-Lab - A MAD laboratory to improve AI architecture de...</title>
<link>https://weibo.com/1402400261/O7gfz9Dfi</link>
<guid>https://weibo.com/1402400261/O7gfz9Dfi</guid>
<content:encoded><![CDATA[
<div> 加速深学习架构设计 开源项目 简单 合成任务 预测 模型 序列模式 性能

<br /><br />总结:
MAD-Lab是一个用来加速深学习架构设计的开源项目，通过简单的合成任务来预测模型在序列模式中的性能。该项目提供了一个MAD实验室，旨在改进人工智能架构设计。用户可以在GitHub上找到该项目，通过使用这个工具，可以更有效地设计和优化深度学习模型，提升模型的性能和效率。MAD-Lab的出现为深度学习领域的研究者和开发者提供了一个有益的工具和资源，有助于推动人工智能技术的发展和应用。 <div>
【MAD-Lab：用来加速深学习架构设计的开源项目，使用简单的合成任务来预测模型在序列模式中的性能】'MAD-Lab - A MAD laboratory to improve AI architecture designs' GitHub: github.com/athms/mad-lab <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7yxjrtmdj210l0u0ajb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 09:00:24 GMT</pubDate>
</item>
<item>
<title>'《一人企业方法论》第二版，也适合做其他副业（比如自媒体、电商、数字商品）的非技术人群' GitHub: github.com/easychen/one-person-businesses-methodology-v...</title>
<link>https://weibo.com/1402400261/O7gdbAQPy</link>
<guid>https://weibo.com/1402400261/O7gdbAQPy</guid>
<content:encoded><![CDATA[
<div> 关键词: 一人企业、方法论、副业、自媒体、电商、数字商品、非技术人群

<br /><br />总结:
《一人企业方法论》第二版是适用于非技术人群的方法论，不仅适用于经营一人企业，也适合从事副业如自媒体、电商、数字商品等领域的人群。该方法论提供了系统化的指导和实践经验，帮助个体创业者建立和拓展自己的事业。通过深入了解市场、客户需求，精准定位、有效推广，以及灵活的运营策略，个体创业者可以实现自身事业的增长和成功。在如今激烈竞争的商业环境下，掌握一套科学的方法论对于非技术人群来说尤为重要，可以帮助他们更好地应对挑战，实现事业的持续发展。 <div>
'《一人企业方法论》第二版，也适合做其他副业（比如自媒体、电商、数字商品）的非技术人群' GitHub: github.com/easychen/one-person-businesses-methodology-v2.0 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho7yrkguatj20ks0rkdl0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:54:33 GMT</pubDate>
</item>
<item>
<title>【OpenTAD: 开源的PyTorch时间动作检测工具箱】'OpenTAD: An Open-Source Temporal Action Detection Toolbox. - OpenTAD is an open-source temporal action de...</title>
<link>https://weibo.com/1402400261/O7gcPf6p9</link>
<guid>https://weibo.com/1402400261/O7gcPf6p9</guid>
<content:encoded><![CDATA[
<div> PyTorch, 时间动作检测, 开源工具箱, OpenTAD, GitHub, 检测工具, 时间序列, 神经网络, 视频数据<br />
<br />
提到了一个名为OpenTAD的开源工具箱，用于PyTorch平台上的时间动作检测任务。这个工具箱主要基于神经网络技术，针对视频数据中的时间序列进行动作检测。此工具箱的代码开源在GitHub上，为研究人员和开发者提供了一个方便易用的工具，帮助他们在时间动作检测方面取得更好的成果。 <div>
【OpenTAD: 开源的PyTorch时间动作检测工具箱】'OpenTAD: An Open-Source Temporal Action Detection Toolbox. - OpenTAD is an open-source temporal action detection (TAD) toolbox based on PyTorch.' GitHub: github.com/sming256/OpenTAD <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho7yq5hkkyj21360u07a1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:53:38 GMT</pubDate>
</item>
<item>
<title>【Valkey：一个新的开源项目，旨在重启之前的开源 Redis 项目】' - A new project to resume development on the formerly open-source Redis project. We're ca...</title>
<link>https://weibo.com/1402400261/O7gc7dqjj</link>
<guid>https://weibo.com/1402400261/O7gc7dqjj</guid>
<content:encoded><![CDATA[
<div> Valkey, 开源项目, Redis, 重启, Valkyrie, GitHub, 意在继续开发, 新项目, 项目名称

<br /><br />总结:
Valkey是一个新的开源项目，旨在重启之前的开源Redis项目。项目名称取自Valkyrie，意在继续开发并完善之前的Redis项目。Valkey的代码托管在GitHub上，为开发人员提供了一个共同合作和贡献的平台。这个新项目旨在延续Redis的精神，为用户提供更好的数据存储和管理解决方案。通过Valkey项目，我们希望能够持续推动开源技术的发展，为开发者提供更多优质的工具和资源。 <div>
【Valkey：一个新的开源项目，旨在重启之前的开源 Redis 项目】' - A new project to resume development on the formerly open-source Redis project. We're calling it Valkey, like a Valkyrie.' GitHub: github.com/valkey-io/valkey <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Redis%23"><span class="surl-text">#Redis#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho7yovkkwjj21jo0p6wjr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:51:54 GMT</pubDate>
</item>
<item>
<title>GitHub: github.com/databricks/dbrx - 转发 @爱可可-爱生活:&amp;ensp;【Databricks开源DBRX高性能大语言模型】- DBRX是Databricks开发的开源通用语言模型，在多项...</title>
<link>https://weibo.com/1402400261/O7g8IykIK</link>
<guid>https://weibo.com/1402400261/O7g8IykIK</guid>
<content:encoded><![CDATA[
<div> Databricks, DBRX, 开源, 语言模型, MoE架构, GenAI, 训练, 效率, 商业模型, Hugging Face

<br /><br />总结:
Databricks推出了开源通用语言模型DBRX，在多项基准测试中表现出色，尤其在编程和数学推理方面优于其他开源模型。DBRX采用MoE架构，在训练和推理上更为高效，推理吞吐量提高2-3倍。DBRX已集成在Databricks的GenAI产品中，客户可以通过API使用。其训练代码和模型也在Hugging Face平台上开源。DBRX的推出展示了Databricks高效训练语言模型的能力，为企业训练定制模型提供了可能。这一举措将推动语言模型的开放性发展，为开发者和企业构建定制模型提供新的选择。MoE架构在提升大型语言模型效率方面有着巨大潜力，为进一步优化模型提供了思路。Databricks将DBRX定位为GenAI战略的核心，展现了他们对语言模型和GenAI商业化的信心和决心。这也预示着更多垂直领域模型的到来。 <div>
GitHub: github.com/databricks/dbrx<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 【Databricks开源DBRX高性能大语言模型】<br />- DBRX是Databricks开发的开源通用语言模型，在多项标准基准测试上达到了当前开源语言模型的最高水平。   <br />- DBRX在多项综合基准测试中表现最好，尤其在编程和数学推理方面优于其他开源模型。与开源模型相比，DBRX在MMLU数据集上的表现也是最好的。   <br />- 根据测试，DBRX甚至超过了专门用于编程的CodeLLAMA-70B，并且与商业模型GPT-3.5相当甚至略胜。DBRX也与Gemini 1.0 Pro和Mistral Medium等商业模型有竞争力。   <br />- DBRX使用混合专家(MoE)架构，使其在训练和推理上更加高效。与类似参数量的非MoE模型相比，DBRX的推理吞吐量提高2-3倍。   <br />- DBRX的整体训练效率比之前提高了近4倍，这得益于更好的数据、MoE架构以及其他改进。   <br />- DBRX已经在Databricks的GenAI产品中进行了集成，客户可以通过API使用该模型。DBRX的训练代码和模型也在Hugging Face平台上开源。   <br />- DBRX证明了Databricks可以高效地训练世界级的基础语言模型，也为企业训练自己的基础模型提供了能力。DBRX只是Databricks协助客户训练定制语言模型的一个例子。<br /><br />思考：  <br />- Databricks作为一家数据和AI公司推出如此强大的开源LLM令人印象深刻，这将极大推动LLM的开放性发展。  <br />- DBRX在通用和编程能力上的出色表现，有望成为开发者和企业构建定制LLM的新选择。  <br />- MoE架构在提升LLM效率方面的潜力得到了很好的体现，为进一步优化大模型提供了思路。  <br />- Databricks将DBRX定位于其GenAI战略的核心，反映出他们对LLM和GenAI商业化的信心和决心。  <br />- Databricks过去为客户大规模训练LLM的经验，为DBRX的成功奠定了基础，也预示着更多垂直领域模型的到来。<br />《Introducing DBRX: A New State-of-the-Art Open LLM | Databricks》 <a href="https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6bjgicy7j21ej0u0jvd.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6bjkgdyqj21c70u0tbn.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:43:32 GMT</pubDate>
</item>
<item>
<title>【Jamba：突破性的SSM-Transformer混合架构模型】- AI21 推出了名为 Jamba 的新型自然语言处理模型，首个基于 Mamba 结构化状态空间(Structured State Space mod...</title>
<link>https://weibo.com/1402400261/O7g6y9NdH</link>
<guid>https://weibo.com/1402400261/O7g6y9NdH</guid>
<content:encoded><![CDATA[
<div> Jamba, SSM-Transformer, 混合架构, 模型, Mamba, Transformer, 注意力机制, 模块化设计, 开源, AI21

<br /><br />总结:
AI21推出了Jamba，这是首个基于Mamba结构化状态空间(SSM)模型和传统Transformer架构的混合模型。Jamba结合了Mamba和Transformer的优势，解决了纯SSM模型质量不高和Transformer计算效率低的问题。该模型使用混合注意力机制，支持256K上下文窗口，在单GPU上可以支持14万token并有3倍吞吐量提升。通过模块化设计、动态激活部分参数的方式，Jamba的效果与传统52B参数模型相当。初步评估显示Jamba在吞吐量和效率等指标上表现优异，权重已在Apache 2.0许可下开源。AI21希望通过开源Jamba推动SSM-Transformer架构的发展和创造更多应用。 <div>
【Jamba：突破性的SSM-Transformer混合架构模型】<br />- AI21 推出了名为 Jamba 的新型自然语言处理模型，首个基于 Mamba 结构化状态空间(Structured State Space model，SSM)模型和传统Transformer架构的混合模型。   <br />- Jamba 结合了 Mamba 和 Transformer 两种模型的优势，既解决了纯 SSM 模型质量不高的问题，又克服了 Transformer 在大上下文场景下计算效率低的缺点。   <br />- Jamba 使用混合注意力机制，同时支持256K的上下文窗口，在单GPU上可以支持14万token。相比类似规模的模型，其吞吐量提升3倍。   <br />- Jamba采用模块化设计， transformer模块、mamba模块和mixture-of-experts模块分别承担不同功能。同时使用动态激活部分参数的方式，使12B参数发挥与全Transformer架构52B参数模型相当的效果。   <br />- 初步评估显示，Jamba在多个指标上表现优异，如吞吐量、效率等。这充分验证了 Jamba作为首个达到商业级水平的SSM-Transformer混合架构模型的可行性。   <br />- Jamba的权重已在Apache 2.0许可下开源，用户可以在Hugging Face上使用。Jamba旨在作为基础模型进行微调、训练和开发定制化解决方案。   <br />- AI21希望通过开源Jamba，能推动SSM-Transformer架构的进一步发展和优化，创造更多新奇有趣的应用。<br />《Jamba：A Groundbreaking SSM - Transformer Open Model》 <a href="https://www.ai21.com/jamba"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho7ya8797hj21of0u077k.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7ya9ejbbj21hc0u0q4x.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho7yabemj3j20vo0iymyx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7yad0805j21k60u0769.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho7yadvis9j21v00u00v7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:38:10 GMT</pubDate>
</item>
<item>
<title>【Grok-1.5发布：支持128K超长上下文】- Grok-1.5是xAI最新发布的大型语言模型，具有更强的推理和解决问题的能力。 - Grok-1.5的一个显著改进是在编程和数学相关...</title>
<link>https://weibo.com/1402400261/O7fqKClTg</link>
<guid>https://weibo.com/1402400261/O7fqKClTg</guid>
<content:encoded><![CDATA[
<div> Grok-1.5, xAI, 128K超长上下文, 推理能力, 人工智能, 编程, 数学, 长文本理解, NIAH, JAX, Rust, Kubernetes, GPU集群, 用户反馈, 基准测试, 模型优化, 发展创新, 定制分布式训练框架, 马斯克, 商业化进程, 开源<br />
<br />
总结:<br />
Grok-1.5是xAI发布的大型语言模型，具有强大的推理和解决问题能力，特别在编程和数学任务中表现优异。其支持处理高达128K token的超长文本，在NIAH任务中表现出色。该模型基于JAX、Rust和Kubernetes构建，可以在大规模GPU集群上进行原型设计和模型训练。xAI团队非常注重用户反馈，并持续改进Grok以满足需求。未来Grok可能引入新功能如总结帖子、内容建议等。虽然未提供微调代码，但开源Grok-1展现了xAI开放、透明的态度。马斯克暗示将扩大Grok聊天机器人的使用权限，显示xAI正逐步推进商业化进程。 <div>
【Grok-1.5发布：支持128K超长上下文】<br />- Grok-1.5是xAI最新发布的大型语言模型，具有更强的推理和解决问题的能力。   <br />- Grok-1.5的一个显著改进是在编程和数学相关任务上的表现，在MATH和GSM8K这两个评估中学科竞赛问题解决能力的基准测试中取得了50.6%和90%的得分。   <br />- Grok-1.5可以处理高达128K token的长文本理解任务，上下文窗口增大了16倍，记忆能力显著提升。它在长文本检索任务NIAH中展示了在长达128k token的上下文中完美检索文本的能力。   <br />- Grok-1.5基于JAX、Rust和Kubernetes构建，使团队可以在大规模GPU集群上进行原型设计和模型训练。检查点、数据加载和任务重启等都进行了优化，以最大程度提高可靠性和训练时间。   <br />- Grok-1.5即将向早期测试用户开放，xAI团队欢迎用户反馈意见。在未来几天里，他们还会推出一些新功能。   <br />- Grok-1.5在多个基准测试中表现强劲，显示出语言理解和推理方面的长足进步。它为解决更加复杂的问题提供了更大的上下文理解能力。xAI将继续改进Grok，以满足用户的需求。   <br /><br />思考：  <br />- Grok-1.5在推理、编码和数学能力方面的改进令人印象深刻，xAI在不断推动人工智能技术的发展和创新。  <br />- 128K token的长上下文处理能力是一个重大突破，使Grok-1.5能够更好地理解和利用长文档中的信息，处理更复杂的提示，这将大大拓展其应用场景。  <br />- 定制的分布式训练框架体现了xAI在底层技术和工程能力方面的实力，有利于加速人工智能模型的迭代和优化。  <br />- 尽管Grok-1.5尚未正式发布，但马斯克已经透露了一些未来可能引入的新功能，如总结帖子、内容建议等，这些都将大大提升用户体验。  <br />- 开源Grok-1彰显了xAI开放、透明的态度，但没有提供微调代码，可能是出于保护核心技术和竞争优势的考虑。  <br />- 马斯克暗示将逐步扩大Grok聊天机器人的使用权限，表明xAI正在稳步推进商业化进程，未来可能会成为X平台的重要变现途径之一。<br />《Announcing Grok-1.5》 <a href="https://x.ai/blog/grok-1.5"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho7vbau0f3j221o0u0aeg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho7vbbwf6yj21jk0rs0wb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 06:55:13 GMT</pubDate>
</item>
<item>
<title>恭喜@i_tuna 等3名用户获得【《hello 算法》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效。公示链接：网页链接 - 转发 @爱可可-爱...</title>
<link>https://weibo.com/1402400261/O7eixaBMz</link>
<guid>https://weibo.com/1402400261/O7eixaBMz</guid>
<content:encoded><![CDATA[
<div> 微博官方、《hello 算法》、抽奖、监督、公正、有效、携手、数据结构、算法、动画图解

<br /><br />总结:
本次活动是微博官方举办的抽奖活动，奖品为《hello 算法》书籍，抽奖过程经过官方监督，结果公正有效。参与方式为转发并评论，截止时间为2024年3月29日12:00。《hello 算法》书籍内容生动易懂，配有动画图解，帮助读者轻松掌握数据结构与算法知识。书中还提供实战代码示例和互动环节设计，让读者即学即用，提高学习效率。通过这本书，读者可以以全新的视角进入算法的世界，掌握重要的数据结构和算法知识。 <div>
恭喜<a href="https://weibo.com/n/i_tuna">@i_tuna</a> 等3名用户获得【《hello 算法》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20240246&amp;pageid=100140E51191126"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 04:02:13 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评...</title>
<link>https://weibo.com/1402400261/O7bWjsGOq</link>
<guid>https://weibo.com/1402400261/O7bWjsGOq</guid>
<content:encoded><![CDATA[
<div> Java, Python, JavaScript, C语言, MySQL, Redis, 技术原理, 故事, 码农翻身2

<br /><br />
总结: 
《码农翻身2》是一本以故事形式讲解技术的畅销书，通过描述编程语言王国的争斗和技术之间的矛盾，让读者了解技术原理并且阅读愉快。书中描绘了Java向Python渗透、JavaScript向Java进攻的情景，C语言的孤独悲催以及MySQL和Redis间的矛盾。通过趣味性的故事，读者可以轻松掌握技术知识。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 22:01:59 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*...</title>
<link>https://weibo.com/1402400261/O7bWgwtuw</link>
<guid>https://weibo.com/1402400261/O7bWgwtuw</guid>
<content:encoded><![CDATA[
<div> 开奖 参与 携手 hello算法 可可粉 数据结构 算法 视角 图解 实战代码 思考问题  <br />
<br />
总结: 今天有开奖活动，欢迎大家参与。赠送3本《hello 算法》，截止时间是2024年3月29日中午12点。参与方式是转发并在评论中加上关键词“可可粉”。这本书可以帮助读者轻松掌握数据结构和算法，以全新的视角进入算法的世界。每一章都有生动的动画图解让抽象的概念变得直观易懂，实战代码示例可以帮助读者即学即用，加深对新知识的理解。书中的互动环节设计可以帮助读者主动思考，提出问题并解决问题。希望大家能够充分利用这本书提升自己的算法能力。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 22:01:52 GMT</pubDate>
</item>
<item>
<title>今日推介(第1359期)：大型语言模型中的长文本事实性、语言模型的少样本重校准、大型语言模型能产生具有同理心的反应、监控提示训练、适应任意分辨率的视觉Transf...</title>
<link>https://weibo.com/1402400261/O7bW44IwI</link>
<guid>https://weibo.com/1402400261/O7bW44IwI</guid>
<content:encoded><![CDATA[
<div> 长文本事实性、语言模型、少样本重校准、同理心、监控提示训练、任意分辨率、视觉Transformer<br />
<br />
大型语言模型在生成长文本时，需要保证信息的准确性和事实性，这对于提高模型的可信度至关重要。研究表明，少样本重校准技术可以帮助语言模型更好地理解和生成文本，提高其效果和表现。另外，大型语言模型能够产生具有同理心的反应，为人类与AI之间建立更加亲近的联系提供可能。监控提示训练是一种有效的训练方法，可以帮助语言模型适应多样的语境和情境，提高其对话和文本生成的能力。同时，视觉Transformer具有适应任意分辨率的能力，能够更好地处理各种视觉任务。综上所述，大型语言模型在不断发展和完善的过程中，不断探索新的技术方法和应用场景，为人工智能领域的发展带来新的可能性和机遇。<br /><br />总结:长文本事实性是大型语言模型生成文本时需要考虑的重要因素，少样本重校准技术可以提高模型效果，大型语言模型能产生具有同理心的反应，监控提示训练有助于提高模型能力，视觉Transformer适应任意分辨率的特性能够更好应对各种视觉任务。 <div>
今日推介(第1359期)：大型语言模型中的长文本事实性、语言模型的少样本重校准、大型语言模型能产生具有同理心的反应、监控提示训练、适应任意分辨率的视觉Transformer 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/689639917"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.29)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7fvouo5nj20go08e75c.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7fvs8ioaj20go05qq3r.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7fvuu2uvj20go0913z2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7fvx9i5qj20go0fat9u.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho7fvzpva4j20go0b10u3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 22:01:22 GMT</pubDate>
</item>
<item>
<title>[CV] EgoLifter: Open-world 3D Segmentation for Egocentric Perception 网页链接 EgoLifter利用3D高斯与实例特征的组合以及对比学习，实现了从第一人称视频进...</title>
<link>https://weibo.com/1402400261/O7bSLBR4R</link>
<guid>https://weibo.com/1402400261/O7bSLBR4R</guid>
<content:encoded><![CDATA[
<div> EgoLifter, 3D高斯，实例特征，对比学习，第一人称视频，开放世界3D场景分割，端到端框架，无需人工3D标注数据

<br /><br />总结:
EgoLifter利用3D高斯与实例特征的组合以及对比学习，实现了从第一人称视频进行开放世界3D场景分割的端到端框架，无需人工3D标注数据。 <div>
[CV] EgoLifter: Open-world 3D Segmentation for Egocentric Perception  <br /><a href="https://arxiv.org/abs/2403.18118"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />EgoLifter利用3D高斯与实例特征的组合以及对比学习，实现了从第一人称视频进行开放世界3D场景分割的端到端框架，无需人工3D标注数据。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fnia6goj20uy1cuwsn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fnipwdjj211g17eh27.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7fnj4p5nj211o0sa7df.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fnjjgkgj20wu1bq179.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:53:15 GMT</pubDate>
</item>
<item>
<title>[CV] Benchmarking Object Detectors with COCO: A New Path Forward 网页链接 通过构建高质量的数据集COCO-ReM，揭示了目标检测模型评估的重要性，为未来的算法...</title>
<link>https://weibo.com/1402400261/O7bPVv6UR</link>
<guid>https://weibo.com/1402400261/O7bPVv6UR</guid>
<content:encoded><![CDATA[
<div> 构建数据集 COCO-ReM 目标检测模型评估 算法研究 基准 数据集质量 目标检测模型 可靠性

<br /><br />总结:
该文章介绍了通过建立高质量数据集COCO-ReM来揭示目标检测模型评估的重要性，并为未来算法研究奠定可靠基准。这项研究突出了数据集质量对于目标检测模型评估的关键性，并提出了使用COCO-ReM作为基准数据集的优势。作者强调了评估目标检测模型的重要性，列举了一些现有数据集的局限性，并指出了COCO-ReM数据集的创新性和研究意义。通过对比各种数据集，研究人员表明了COCO-ReM数据集在不同性能指标上的优势，包括更高的准确性和更全面的测试。文章最后总结了该研究的重要性，并呼吁未来的算法研究应该基于可靠的基准数据集进行评估，以推动目标检测领域的发展。 <div>
[CV]  Benchmarking Object Detectors with COCO: A New Path Forward  <br /><a href="https://arxiv.org/abs/2403.18819"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过构建高质量的数据集COCO-ReM，揭示了目标检测模型评估的重要性，为未来的算法研究奠定可靠的基准。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fg83ke0j210g184wud.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fg8jnpsj217a0xi4dd.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7fg90wc4j217w0ja47w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7fg9jn61j217c0jk0xh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:46:15 GMT</pubDate>
</item>
<item>
<title>[CL] Enhancing Legal Document Retrieval: A Multi-Phase Approach with Large Language Models 网页链接 通过在法律文档多阶段检索流程中集成提示驱动的大型语...</title>
<link>https://weibo.com/1402400261/O7bNMp76A</link>
<guid>https://weibo.com/1402400261/O7bNMp76A</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、法律文档检索、多阶段方法、提示驱动、性能提升、集成、检索性能、法律领域、信息检索、语言模型

<br /><br />总结:
本文提出了一种通过在法律文档多阶段检索流程中集成提示驱动的大型语言模型来提升检索性能的方法。研究针对法律领域的信息检索问题进行了探讨，并提出了一种多阶段方法，其中大型语言模型起到关键作用。通过集成大型语言模型，可以显著提高法律文档的检索性能，提高检索结果的准确性和相关性。这种方法为提高法律文档检索效率和质量提供了新思路和方法。 <div>
[CL] Enhancing Legal Document Retrieval: A Multi-Phase Approach with Large Language Models  <br /><a href="https://arxiv.org/abs/2403.18093"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过在法律文档多阶段检索流程中集成提示驱动的大型语言模型，提出了一种可显著提高检索性能的方法。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7faq17bhj20rm16oals.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7faqartwj21no0qagrd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7farrkrzj21060n2dht.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:40:58 GMT</pubDate>
</item>
<item>
<title>[CL] BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text 网页链接 提出了面向生物医学领域的小型开源语言模型BioMedLM，证明了通过高质量...</title>
<link>https://weibo.com/1402400261/O7bLx6SZP</link>
<guid>https://weibo.com/1402400261/O7bLx6SZP</guid>
<content:encoded><![CDATA[
<div> 生物医学领域、小型开源语言模型、BioMedLM、高质量领域语料训练、生物医学QA、竞争力效果

<br /><br />总结:
文章介绍了一个面向生物医学领域的小型开源语言模型BioMedLM，该模型在经过高质量领域语料训练后，在生物医学QA等任务上展现出竞争力的效果。作者提出了这个2.7B参数的语言模型，证明了即使不是追求模型规模，通过充分训练仍可以在生物医学领域取得良好的表现。BioMedLM为生物医学领域的文本处理和分析提供了一个有潜力的工具，为相关研究和实践带来了新的可能性。该研究结果为语言模型在特定领域的应用提供了有益的启示，强调了训练数据和模型设计的重要性。BioMedLM的出现丰富了开源语言模型的领域应用场景，对于推动生物医学领域的智能化发展具有积极意义。 <div>
[CL] BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text  <br /><a href="https://arxiv.org/abs/2403.18421"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出了面向生物医学领域的小型开源语言模型BioMedLM，证明了通过高质量的领域语料训练，即使不追求模型规模也可以在生物医学QA等任务上达到竞争力的效果。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7f4yzhcpj20zk1daww5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7f4zbj9xj21cs0k2wg9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7f4zyeftj214u0pm0ul.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:35:25 GMT</pubDate>
</item>
<item>
<title>[LG] Tutorial on Diffusion Models for Imaging and Vision 网页链接 本教程全面系统地介绍了从变分自编码器到扩散模型的发展脉络，数学推导细致，内容丰富，是...</title>
<link>https://weibo.com/1402400261/O7bJ6kisn</link>
<guid>https://weibo.com/1402400261/O7bJ6kisn</guid>
<content:encoded><![CDATA[
<div> 变分自编码器、扩散模型、数学推导、理解、教材、系统性、发展脉络、内容丰富、图像、视觉功能
<br />
<br />
总结: 本教程全面系统地介绍了从变分自编码器到扩散模型的发展脉络，数学推导细致，内容丰富，是理解扩散模型的好教材。 <div>
[LG] Tutorial on Diffusion Models for Imaging and Vision  <br /><a href="https://arxiv.org/abs/2403.18103"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />本教程全面系统地介绍了从变分自编码器到扩散模型的发展脉络，数学推导细致，内容丰富，是理解扩散模型的好教材。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7eypxk3tj210q17ggwg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7eyq7nf7j21i80vetis.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7eyqmidgj21cm0o60yj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:29:26 GMT</pubDate>
</item>
<item>
<title>通过自适应token融合模块和模糊位置编码增强了视觉Transformer的分辨率可扩展性，使其在广泛分辨率上都能保持高性能。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《ViTAR...</title>
<link>https://weibo.com/1402400261/O7bFwiMRP</link>
<guid>https://weibo.com/1402400261/O7bFwiMRP</guid>
<content:encoded><![CDATA[
<div> 关键词: 自适应token融合模块, 模糊位置编码, 视觉Transformer, 分辨率可扩展性, 高性能

总结:<br /><br />这篇论文介绍了一种名为ViTAR的视觉Transformer模型，通过引入自适应token融合模块和模糊位置编码，提高了模型在不同分辨率下的性能表现。该模型能够在广泛的分辨率下保持高性能，并具有较强的分辨率可扩展性。该研究由中国科学院和字节跳动的团队共同完成。<br />ViTAR模型在视觉Transformer的基础上做出了创新改进，使得模型在各种分辨率上的应用更加灵活可靠。通过自适应token融合模块，模型能够有效地融合不同分辨率的特征信息，提升了模型的表征能力和泛化能力。<br />同时，引入模糊位置编码则进一步增强了模型的分辨率可扩展性，使其能够处理更加复杂的视觉任务。这些技术创新为视觉Transformer的发展带来了新的思路和可能性，为未来的视觉任务研究提供了有益的启示。 <div>
通过自适应token融合模块和模糊位置编码增强了视觉Transformer的分辨率可扩展性，使其在广泛分辨率上都能保持高性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《ViTAR: Vision Transformer with Any Resolution》Q Fan, Q You, X Han, Y Liu, Y Tao, H Huang, R He, H Yang [Chinese Academy of Sciences &amp; ByteDance] (2024) <a href="https://arxiv.org/abs/2403.18361"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7edlfnhcj20ng15c13g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho7edls4tmj20vk0ukgqy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7edmc5nzj21qc158gxh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7edmhwrij20um0ia761.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho7epi8s51j20r30fcdh7.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:20:36 GMT</pubDate>
</item>
<item>
<title>[CV]《ViTAR: Vision Transformer with Any Resolution》Q Fan, Q You, X Han, Y Liu, Y Tao, H Huang, R He, H Yang [Chinese Academy of Sciences &amp; ByteDance...</title>
<link>https://weibo.com/1402400261/O7bFtD4yb</link>
<guid>https://weibo.com/1402400261/O7bFtD4yb</guid>
<content:encoded><![CDATA[
<div> 关键词: ViTAR, 视觉Transformer, 分辨率, 中国科学院, 字节跳动

总结:<br /><br />
本文介绍了 ViTAR，一种具有任意分辨率的视觉Transformer模型，由中国科学院和字节跳动共同研发。该模型在视觉任务中表现出色，能够处理各种分辨率的图像输入。研究人员通过实验证明，ViTAR在不同分辨率下均能取得出色的性能表现。该模型的独特之处在于能够处理不同分辨率的输入，提高了模型的适用性和泛化能力。总体而言，ViTAR为视觉Transformer模型的发展带来了新的思路和方法，对图像分析和处理领域具有重要意义。 <div>
[CV]《ViTAR: Vision Transformer with Any Resolution》Q Fan, Q You, X Han, Y Liu, Y Tao, H Huang, R He, H Yang [Chinese Academy of Sciences &amp; ByteDance] (2024) <a href="https://arxiv.org/abs/2403.18361"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7edlfnhcj20ng15c13g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho7edls4tmj20vk0ukgqy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7edmc5nzj21qc158gxh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7edmhwrij20um0ia761.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho7epi8s51j20r30fcdh7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:20:31 GMT</pubDate>
</item>
<item>
<title>【如何成为“效率大师”？】其实，提高工作效率并没有想象中那么难，只要掌握几个简单的技巧，你也可以成为效率之王。 - 首先，学会专注。把时间分块，在日历上...</title>
<link>https://weibo.com/1402400261/O73tVBTUS</link>
<guid>https://weibo.com/1402400261/O73tVBTUS</guid>
<content:encoded><![CDATA[
<div> 专注 深度工作 艾森豪威尔矩阵 邮件处理 习惯 养成 目标计划 番茄工作法 回顾 说“不” 散步  自动化

<br /><br />总结:
首先，要学会专注，将时间分块，全神贯注地完成每项任务。其次，练习深度工作，保持专注，不分心。第三，使用艾森豪威尔矩阵来安排任务，注重重要事项。第四，批量处理邮件和消息，有效安排时间。第五，养成每天练习习惯，坚持一年即可看到成效。第六，利用番茄工作法战胜拖延症。第七，制定目标和计划，每天进行回顾。第八，学会对事情说“不”，拒绝无关紧要的事务。第九，每天晚上散步，可结合冥想。最后，尽可能自动化任务，提高效率。生活就像马拉松，效率是取得优异成绩的关键。 <div>
【如何成为“效率大师”？】<br />其实，提高工作效率并没有想象中那么难，只要掌握几个简单的技巧，你也可以成为效率之王。   <br />- 首先，学会专注。把时间分块，在日历上为每个任务预留时间，然后全神贯注地完成当前的任务。可以尝试3:3:3法则：每天花3小时做最重要的项目，3小时做短期任务，3小时做日常维护。   <br />- 其次，练习"深度工作"。每天至少花4个小时专注工作，期间不要分心(可以把手机调到飞行模式)。学习新东西时，可以用费曼技巧：选一个主题，试着向一个5岁的孩子解释，然后继续研究以填补知识空白。   <br />- 第三，用艾森豪威尔(Eisenhower)矩阵来安排任务。目标是把更多时间花在重要的事情上，那些能推进你长期价值观、使命、目标和原则的事情。   <br />- 第四，批量处理邮件和消息。每天集中1-3次时间来处理邮件。对不必要的邮件立即删除，需要别人处理的转发出去，几分钟内可以回复的马上回，其他的则安排时间处理。   <br />- 第五，养成每天练习20分钟的习惯。坚持一年，你就会比90%的人做得更好。可以用"尽善尽美"(GTD)的方法来高效地安排每一件事。   <br />- 第六，用番茄工作法来战胜拖延症。选择一个任务，设置25分钟的计时器，专注工作，中间不要分心，然后休息一下，再重复。每完成4个番茄钟，就休息久一点。   <br />- 第七，制定年度、月度、周度和日常的目标和计划。没有目标，你可能哪儿也到不了。   <br />- 第八，进行每日和每周回顾。问问自己："我今天做了哪些符合目标的事情?""有什么地方可以改进吗?"   <br />- 第九，学会对很多事情说”不”！一个"不"就是对很多其他事情说"是"。   <br />- 第十，每天晚上散步30分钟。如果能在散步时冥想，那就更好了。   <br />- 最后，尽可能地自动化。试着用各种工具来自动化一切可以自动化的事情，尤其是重复性的任务。   <br />生活就像一场马拉松，效率就是你的配速。掌握这些技巧，相信你一定能在这场马拉松中取得优异的成绩。当然，知易行难，关键是要把这些方法落实到行动中。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho6ekdg9wgj20u01kt11n.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho6ekdwe11j20u019en53.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:30:05 GMT</pubDate>
</item>
<item>
<title>【distil-large-v3：Whisper large-v3的蒸馏精简版】Distil-Whisper的设计旨在加快推理速度，仅使用两个解码器层，实现了与原版Whisper相媲美的语音识别准确性，...</title>
<link>https://weibo.com/1402400261/O73pWbPS5</link>
<guid>https://weibo.com/1402400261/O73pWbPS5</guid>
<content:encoded><![CDATA[
<div> 解码器层、语音识别、推理速度、准确性、幻听错误、分块长文本算法、错误率、Distil-Whisper、设计、提升速度

<br /><br />总结:
Distil-Whisper是一个蒸馏精简版的Whisper模型，旨在加快推理速度。它仅使用两个解码器层，但在语音识别准确性方面与原版Whisper相媲美，推理速度提升了6.3倍。此外，Distil-Whisper在降低幻听错误方面也取得了重大进展，使用分块长文本算法时，幻听错误率降低了约30%。Distil-Whisper的设计使得语音识别更加高效、准确，为技术领域带来了新的突破。 <div>
【distil-large-v3：Whisper large-v3的蒸馏精简版】Distil-Whisper的设计旨在加快推理速度，仅使用两个解码器层，实现了与原版Whisper相媲美的语音识别准确性，但速度却提升了惊人的6.3倍。此外，Distil-Whisper在降低幻听错误方面也取得了重大进展，使用分块长文本算法时，幻听错误率降低了约30%。 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho6ea22y2cj20y20u0tdo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:20:15 GMT</pubDate>
</item>
<item>
<title>【AI许可(licensing)：虚幻的安全感与真实的管理困境】- 一些组织主张通过许可证限制强大AI模型的扩散，类似于核武器或人体克隆。但是这种做法在实施上不可行。 ...</title>
<link>https://weibo.com/1402400261/O73nMkiHG</link>
<guid>https://weibo.com/1402400261/O73nMkiHG</guid>
<content:encoded><![CDATA[
<div> 许可证、AI模型、扩散、训练成本、国际合作、利益、风险、监管套利、开源AI、灵活应对

总结:<br /><br />本文讨论了AI许可在管理风险方面的困境。许可证虽然被一些组织主张限制强大AI模型的扩散，但实施上存在诸多困难。训练成本逐渐下降，监控数据中心需要国际合作。少数大公司将获益，强制许可证可能加剧风险。许可证可能导致恶化风险和监管套利，开源AI也需要预防措施。需要更加开放和灵活的方式应对AI发展带来的影响。许可不能真正阻止恶意使用，执法难度大。颠覆性技术难以被垄断。要综合评估AI风险，并制定相应措施应对。 <div>
【AI许可(licensing)：虚幻的安全感与真实的管理困境】<br />- 一些组织主张通过许可证限制强大AI模型的扩散，类似于核武器或人体克隆。但是这种做法在实施上不可行。   <br />- 尽管目前训练顶级AI模型需要大量算力，但随着算法和硬件的进步，训练成本正在急速下降。要全面监控数据中心以限制AI开发不可行且需要空前国际合作。   <br />- 尽管AI模型会扩散，但少数大公司将从这波爆发中获得巨大利益。强制许可证将进一步加剧这种风险，因为只有少数公司可以开发顶级AI。   <br />- 许可证可能导致AI风险恶化，包括安全风险、结果同质化、定义可接受言论界限、影响公众态度等。这也有利于行业巨头进行监管套利。   <br />- 鼓励不同背景的学术界、企业和非营利组织开发和评估顶级AI模型，可能是解决AI风险的更好方式。当然，开源AI也需要防范措施。   <br />- 总体而言，AI技术许可证在实施可行性和有效性上都存在重大障碍。我们需要更加开放和灵活的方式来应对AI发展带来的影响。<br /><br />思考：  <br />- 作者对许可能否有效管理AI风险提出了尖锐质疑，这个观点有一定道理，值得认真考虑。  <br />- 文章指出，许可无法真正阻止坏人，因为他们总能找到非法获取模型的办法。这提醒我们，单纯的许可可能并非万全之策。  <br />- 作者认为许可的支持者低估了执法难度，这一论断可能有一定道理。但能否通过技术创新等方式克服这些难度，可能还有待进一步探索。  <br />- 文章指出，从历史上看，颠覆性技术无法被垄断，终会扩散。这启示我们要用发展的眼光看待AI技术的传播。  <br />- 作者提醒我们不要被许可制造的虚假安全感所迷惑，而忽视了更紧迫的风险。这提示我们要全面评估AI风险，并相应制定综合防控措施。<br />《Licensing is neither feasible nor effective for addressing AI risks》 <a href="https://www.aisnakeoil.com/p/licensing-is-neither-feasible-nor"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6e4nvbhwj20y20u0tdo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:14:56 GMT</pubDate>
</item>
<item>
<title>【模型微调是否仍有价值】- 最近有一些观点开始质疑模型微调的价值，作者认为在许多情况下，模型微调仍然非常有价值。 - 模型微调对于学习语法、风格和规则很有...</title>
<link>https://weibo.com/1402400261/O73m0AYRY</link>
<guid>https://weibo.com/1402400261/O73m0AYRY</guid>
<content:encoded><![CDATA[
<div> 微调 价值 观点 场景 领域 评估 框架 提示工程 区分 RAG

<br /><br />总结: 本文讨论了模型微调的价值，认为在学习语法、风格和规则等方面仍然非常有帮助，但对于开发者工具等通用情况，微调的效果可能有限。作者强调了评估框架的重要性，指出微调需有系统的性能度量。此外，提示工程在微调中扮演着重要的角色，能帮助检验和改善模型的性能。文章还对微调和基于检索的方法进行了区分，指出它们各自适用于不同的场景和目的。综上所述，微调仍然是提升模型表现的有效手段，但其应用需根据具体情况进行决定。 <div>
【模型微调是否仍有价值】<br />- 最近有一些观点开始质疑模型微调的价值，作者认为在许多情况下，模型微调仍然非常有价值。   <br />- 模型微调对于学习语法、风格和规则很有帮助，而提示工程更适合为模型提供上下文和最新事实。   <br />- 在开发者工具、基础模型、通用助手等情况下，模型微调不太有价值。但在专业领域和特定使用案例中，模型微调可以明显改进性能。   <br />- 在产品早期阶段，由于没有域特定的评估体系，很难有效地进行模型微调。构建评估体系是使用模型微调的先决条件。   <br />- 文章给出了Honeycomb和ReChat两个案例，说明了如何通过模型微调学习特定语法、风格和规则，从而提升产品性能。   <br />- 模型微调不仅适用于小模型，大型模型如GPT-3.5也能从中获益。模型微调仍然是提升模型表现的有效手段，值得继续探索与改进。<br /><br />思考：  <br />- 文章对当前AI领域微调价值的看法提供了一个平衡的视角。作者在承认怀疑声音日益增多的同时，坚持认为微调在许多场景下仍有很高价值。  <br />- 一个关键见解是，微调的适用性在很大程度上取决于具体的使用场景和领域。对于通用的开发者工具或基础模型本身，微调的边际效用可能有限。但对于更专业的应用，微调仍可带来显著改善。  <br />- 文章强调要有一个鲁棒的评估框架，作为任何模型优化(包括微调)的基础。没有系统的性能度量方式，我们很容易武断地否定微调等技术。  <br />- 文章也突出了提示工程作为微调的前提和补充所扮演的角色。广泛的提示可以检验评估机制，如果效果令人满意，它本身就足够了。  <br />- 作者对微调和基于检索的方法(如RAG)做了有益的区分，前者更适合学习风格和语法模式，后者更适合注入最新信息。<br />《Hamel’s Blog - Is Fine-Tuning Still Valuable?》 <a href="https://hamel.dev/blog/posts/fine_tuning_valuable.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho6e0460lkj20u016rtg6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:10:33 GMT</pubDate>
</item>
<item>
<title>【用FrankenMoE集成多个预训练模型：MergeKit赋能高效MoE构建】- MoE(混合专家模型)是一种提高性能的模型架构，它使用多个子网络(称为“专家”)。MoE只激活相关...</title>
<link>https://weibo.com/1402400261/O73kchGO2</link>
<guid>https://weibo.com/1402400261/O73kchGO2</guid>
<content:encoded><![CDATA[
<div> MoE, 混合专家模型, FrankenMoE, MergeKit, 预训练模型, 性能提升, 创新思路, 高质量模型, 实用性, 创意方法

<br /><br />总结:
本文介绍了使用FrankenMoE集成多个预训练模型来创建MoE的方法。传统的MoE需要从头训练专家和路由器，而FrankenMoE通过MergeKit集成预训练模型，使MoE构建更快速、灵活、提高性能。作者创建了一个名为Beyonder-4x7B-v3的FrankenMoE模型，并取得了不错的结果。虽然FrankenMoE方法在性能提升方面有潜力，但也存在一些实际问题，如较高的VRAM需求，需要权衡利弊来决定使用。MergeKit为MoE构建提供了创新思路，具有很大实用价值，读者可以尝试实践。LazyMergeKit成功创建并评估了作者的frankenMoE，证明了方法的可行性和有效性。MergeKit的创新有望推动MoE技术的进一步发展和应用。 <div>
【用FrankenMoE集成多个预训练模型：MergeKit赋能高效MoE构建】<br />- MoE(混合专家模型)是一种提高性能的模型架构，它使用多个子网络(称为“专家”)。MoE只激活相关的专家，从而实现更快的训练和推理。   <br />- 传统的MoE模型需要从头训练专家和路由器(确定哪些token由哪些专家处理)。而“FrankenMoE”则是通过集成多个预训练好的模型来创建MoE。   <br />- FrankenMoE的创建包括选择专家模型、定义正样本和负样本提示、使用MergeKit生成MoE模型。文章详细介绍了一个例子。   <br />- 作者创建了一个FrankenMoE模型Beyonder-4x7B-v3，它在多个基准测试中取得了不错的结果，展示了这种方法的潜力。   <br />- FrankenMoE在提高性能方面很有前景，但也存在一些实际中的问题，如较高的VRAM需求。需要权衡利弊来决定是否适合使用。   <br />- 这种方法为改进模型性能提供了一种创新思路，值得进一步探索，但还有待改进。建议读者尝试自己创建FrankenMoE模型。<br /><br />思考：  <br />- MergeKit通过集成预训练模型创建MoE的方法非常有创意，为MoE的构建提供了一种新的思路和途径。  <br />- 与从头训练MoE相比，MergeKit的方法可以更快速、灵活地创建高质量的MoE，具有很大的实用价值。  <br />- 文章对MergeKit创建frankenMoEs的过程进行了详细的介绍和示范，读者可以很容易地上手实践。  <br />- 作者使用LazyMergeKit成功创建并评估了自己的frankenMoE，证明了这一方法的可行性和有效性。  <br />- MergeKit在MoE领域的创新有望推动MoE技术的进一步发展和应用，值得业界关注和探索。<br />《Create Mixtures of Experts with MergeKit | by Maxime Labonne | Mar, 2024 | Towards Data Science》 <a href="https://towardsdatascience.com/create-mixtures-of-experts-with-mergekit-11b318c99562"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho6dvfyxq4j20u00vsgrj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho6dvgrvsgj21hc0u0n21.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:06:05 GMT</pubDate>
</item>
<item>
<title>【RLHF成功背后的隐忧：AI安全亟需多管齐下】- 文章认为当前主流的模型对齐技术RLHF在防止语言模型非故意的伤害方面非常有效，使得聊天机器人产品得以推向大众消...</title>
<link>https://weibo.com/1402400261/O73iKrQzj</link>
<guid>https://weibo.com/1402400261/O73iKrQzj</guid>
<content:encoded><![CDATA[
<div> 模型对齐技术、RLHF、AI安全、聊天机器人、意图恶意使用、防范措施、内容审核、软件安全、灾难性风险

总结：<br /><br />本文指出，现有模型对齐技术在防止语言模型非故意伤害方面表现出色，尤其在聊天机器人领域取得成功。然而，对意图恶意使用的对手，模型对齐无法产生很大作用，因此需要额外的防范措施。模型对齐其实更像内容审核，而不是软件安全，应重视其局限性。对于AI安全问题，需要更系统性的思考，不能过度依赖模型对齐技术。需要开发更强大的对齐技术，同时关注模型外的防御措施，以确保全面的安全性。对于可能带来严重意外伤害的场景，单纯的技术方法可能不够，AI安全社区应高度重视。 <div>
【RLHF成功背后的隐忧：AI安全亟需多管齐下】<br />- 文章认为当前主流的模型对齐技术RLHF在防止语言模型非故意的伤害方面非常有效，使得聊天机器人产品得以推向大众消费者。   <br />- 但是RLHF无法防止有意图的恶意使用。对付资金雄厚的对手，模型对齐毫无用处，因为对手可以重新训练模型或移除对齐。   <br />- 对付日常用户的恶意使用，模型对齐仍有一定效用，因为它使其更难进行故意误用。但不能仅依赖模型对齐，还需要产品级的其他防范措施。   <br />- 模型对齐更像是内容审核，而不是软件安全。它的不足不应引发恐慌，仍然是有用的。但对付灾难性风险，不应过分依赖模型对齐。   <br />- 需要开发更强大的对齐技术，同时关注模型之外的防御措施，扩大安全性的系统性思考。<br /><br />思考：  <br />- 文章指出，业界过度依赖模型对齐技术来解决AI安全问题，这一观点值得重视。我们不能把模型对齐视为万灵药。  <br />- RLHF等模型对齐技术在聊天机器人领域取得了成功，但其局限性也日益凸显。对齐完美与否，取决于诸多因素。  <br />- 对手绕过对齐技术引发的担忧合情合理。但暂停AI等极端措施是否必要和可行，仍有待商榷。  <br />- 文章提到即使对齐了，聊天机器人也可能有害，产品概念也很重要。这启示我们AI安全需要更全面的视角，不能只盯着模型本身。  <br />- 对于自主智能体等可能带来更严重意外伤害的场景，单纯的技术方法可能不够，这值得AI安全社区高度重视。<br />《Model alignment protects against accidental harms, not intentional ones》 <a href="https://www.aisnakeoil.com/p/model-alignment-protects-against"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6drrmzkdj20ud0u0dks.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:02:32 GMT</pubDate>
</item>
<item>
<title>【模型安全≠使用安全，AI治理需要更全面的视角】- 在AI界存在一个普遍假设，即AI安全性是AI模型的一项特性。基于这个假设，许多公司投资了大量资源来提高模型的...</title>
<link>https://weibo.com/1402400261/O73hpqXEs</link>
<guid>https://weibo.com/1402400261/O73hpqXEs</guid>
<content:encoded><![CDATA[
<div> 模型安全, 使用安全, AI治理, 模型特性, 上下文, 系统性思考, 误用, 边际风险, 对抗测试, 社会成本

总结:<br /><br />这篇文章指出了AI安全不是模型特性，强调了模型的安全与其部署的上下文和环境密切相关。文章提出了四点建议，包括防范模型误用、评估边际风险、重塑对抗测试和让第三方进行对抗测试。作者认为模型无法判断某些恶意用途，提出责任划分会变得复杂，AI安全需要综合思考。文章还讨论了安全内容的差异化处理和警惕简单思维定势的重要性。整体而言，AI治理需要更全面的视角，并且不能简单地将安全问题归咎于模型特性。 <div>
【模型安全≠使用安全，AI治理需要更全面的视角】<br />- 在AI界存在一个普遍假设，即AI安全性是AI模型的一项特性。基于这个假设，许多公司投资了大量资源来提高模型的安全性。但是文章认为这种做法是有限的，因为AI安全性不是模型的特性，而在很大程度上取决于模型被部署的上下文和环境。   <br />- 文章举了钓鱼邮件、生物恐怖主义和传播虚假信息等例子，说明模型本身无法判断这些用途是否恶意，因为模型无法获知完整的部署上下文。要做到只生成无害内容几乎不可能。   <br />- 文章提出了四点建议：一是防范模型误用的主要措施应位于模型之外；二是评估开源模型的边际风险；三是重塑对抗测试，以发现对手方的新能力；四是让第三方而不是开发者自己进行对抗测试。   <br />- 文章认为，接受模型无法杜绝误用意味着责任划分会变得非常复杂。开发者在道德上应承担部分由于AI滥用带来的社会成本，但在法律上很难执行。这是AI政策亟待解决的难题。   <br />- 文章提出AI安全性不是模型特性这一观点，认为仅仅对模型进行安全性改进是有限的，需要更广泛的系统性思考。这一观点对当前AI安全研究具有重要启发意义。<br /><br />思考：  <br />- 作者提出了一个有趣的观点，即AI安全不是模型的特性，这与业界的主流看法形成了鲜明对比，值得深入思考。  <br />- 文章指出，即使模型本身是安全的，也可能被用于恶意目的，这提醒我们在考虑AI安全时需要更全面的视角。  <br />- 作者认为不能将安全问题全权委托给模型决定，因为模型可能缺乏必要的上下文信息，这一论断有一定道理，但可能也并非放之四海而皆准。  <br />- 文章提到一些例外情况，如儿童色情内容等，表明某些内容本身就是有问题的。这提示我们在AI安全治理中，可能需要对不同类型的内容采取差异化的策略。  <br />- "安全是模型特性"说法之所以会流行，可能确实与其便利性有关。这提醒我们在探讨AI安全时，要警惕简单化、一刀切的思维定势。<br />《AI safety is not a model property》 <a href="https://www.aisnakeoil.com/p/ai-safety-is-not-a-model-property"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho6dob3pdpj20ug0u0n1d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 23:59:14 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评...</title>
<link>https://weibo.com/1402400261/O73czeXBY</link>
<guid>https://weibo.com/1402400261/O73czeXBY</guid>
<content:encoded><![CDATA[
<div> Java、Python、JavaScript、C语言、MySQL、Redis、技术、故事、码农翻身

<br /><br />总结:
《码农翻身2》是一本以故事方式讲解技术的畅销书，其中描述了编程语言王国之间的争斗和趣味故事。Java、Python、JavaScript等编程语言相互竞争，MySQL和Redis互相斗争，C语言则面临着单身的悲催。这本书旨在让读者掌握技术原理的同时，享受有趣的阅读体验。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 23:47:18 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：明日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*...</title>
<link>https://weibo.com/1402400261/O73cwc9dI</link>
<guid>https://weibo.com/1402400261/O73cwc9dI</guid>
<content:encoded><![CDATA[
<div> 可可粉、转发、评论、hello 算法、数据结构、算法、动画图解、实战代码示例、互动环节设计、轻松掌握

<br /><br />总结:
明日将会开奖，并欢迎大家参与携手送出3本《hello 算法》的活动。截止日期是2024年3月29日中午12点。参与方式是转发并评论*可可粉*即可参与。这本书旨在帮助读者轻松掌握数据结构与算法，通过全新的视角引领读者进入算法的世界。每一章节都配有生动的动画图解，使抽象的数据结构和算法变得直观易懂。书中的实战代码示例让读者可以即学即用，及时巩固新知识。互动环节的设计帮助读者主动思考，提出问题并解决问题。这本书的目的是让读者在学习数据结构与算法的过程中更加轻松愉快。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：明日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 23:47:11 GMT</pubDate>
</item>
<item>
<title>【Chatbot匿名竞技场最新更新：Claude 3 0pus不负众望成为冠军，Starling-LM-7B-beta以7B的规模击败GPT 3.5、Mistral 和 Gemini Pro】《LMSys Chatbot Arena Lea...</title>
<link>https://weibo.com/1402400261/O72QQ683v</link>
<guid>https://weibo.com/1402400261/O72QQ683v</guid>
<content:encoded><![CDATA[
<div> 更新、竞技场、Claude 3 0pus、冠军、Starling-LM-7B-beta、击败、GPT 3.5、Mistral、Gemini Pro

<br /><br />总结:
最新更新显示，匿名竞技场中，Claude 3 0pus凭借强大实力成为冠军，而Starling-LM-7B-beta也以7B规模战胜了GPT 3.5、Mistral和Gemini Pro，引起广泛关注。 <div>
【Chatbot匿名竞技场最新更新：Claude 3 0pus不负众望成为冠军，Starling-LM-7B-beta以7B的规模击败GPT 3.5、Mistral 和 Gemini Pro】《LMSys Chatbot Arena Leaderboard - a Hugging Face Space by lmsys》 <a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6bs0wrabj21c30u0q88.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 22:53:46 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.27)》 爱可可微博热门分享(3.27) [图片]</title>
<link>https://weibo.com/1402400261/O6ZHV30UH</link>
<guid>https://weibo.com/1402400261/O6ZHV30UH</guid>
<content:encoded><![CDATA[
<div> 微博，热门，分享，爱可可，3.27，关键词：

抖音，短视频，创作者，内容，粉丝，明星，合作，推广，营销，平台

<br /><br />总结:
3月27日，爱可可微博发布了热门分享内容，讨论的焦点主要集中在抖音平台上。抖音作为一个热门的短视频平台，吸引了众多创作者在上面发布各种内容，受到粉丝们的喜爱。不仅普通用户，就连明星也会在抖音上开设账号，与粉丝互动。同时，抖音也成为了许多品牌推广营销的平台，通过和创作者合作，进行推广活动，取得良好的营销效果。 <div>
《爱可可微博热门分享(3.27)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405016671747440838"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.27)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho5xwefsbuj20m80cijt5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 14:53:33 GMT</pubDate>
</item>
<item>
<title>【Redis架构演进之路】就像罗马不是一天建成的，Redis的架构也是随着时间的推移而不断进化的。 - Redis最初于2010年发布1.0版本，那时的架构非常简单，主要用作...</title>
<link>https://weibo.com/1402400261/O6YFu0ZOC</link>
<guid>https://weibo.com/1402400261/O6YFu0ZOC</guid>
<content:encoded><![CDATA[
<div> Redis、架构、演进、内存、持久化、故障转移、监控、集群、数据结构、多线程IO
<br /><br />总结:
Redis架构从简单的缓存应用不断演进，2013年的2.8版本引入了持久化和复制功能，提高了可用性。2015年的3.0版本推出集群功能，通过数据分片管理数据。2017年的5.0版本新增了Stream数据类型，2020年的6.0版本引入了多线程IO处理，进一步提升了性能。Redis的架构演进之路充满智慧和汗水，体现了业界对高性能、高可用数据存储的追求。Redis不断成长为强大的内存数据库，为业务应用开发带来便利和高效。Redis的发展历程，展示了持续创新和不断进化的精神。Redis架构模型的优化和技术的不断引入，为用户提供更稳定、更高效的数据服务。Redis的成功也启示着业界追求卓越的态度，值得持续关注和学习。 <div>
【Redis架构演进之路】<br />就像罗马不是一天建成的，Redis的架构也是随着时间的推移而不断进化的。   <br />- Redis最初于2010年发布1.0版本，那时的架构非常简单，主要用作业务应用的缓存。但由于Redis是将数据存储在内存中，一旦重启，所有数据就会丢失，流量会直接冲击数据库。   <br />- 到了2013年，Redis 2.8版本解决了这个问题。它引入了RDB内存快照来持久化数据，同时还支持AOF(Append-Only-File)方式，将每个写命令都写入AOF文件。此外，Redis 2.8还增加了复制功能来提高可用性。主节点处理实时的读写请求，从节点则同步主节点的数据。   <br />- 为了实时监控Redis实例，Redis 2.8推出了Sentinel(哨兵)。它承担四大任务：监控、通知、自动故障转移和配置提供者。可以说，Sentinel为Redis保驾护航，时刻守护着Redis的可用性。   <br />- Redis的下一个里程碑是2015年发布的3.0版本，该版本增加了Redis集群功能。Redis集群是一种分布式数据库解决方案，通过数据分片来管理数据。整个数据被分为16384个槽位，每个节点负责一部分槽位。这就好比将一个大蛋糕切成16384份，分给不同的人去管理。   <br />- Redis之所以备受欢迎，是因为其高性能和丰富的数据结构，大大降低了开发业务应用的复杂度。2017年发布的Redis 5.0新增了Stream数据类型。2020年发布的Redis 6.0则引入了多线程IO处理，进一步提升了性能。Redis的架构模型被划分为网络模块和主处理模块，开发者发现网络模块往往会成为系统的瓶颈。而多线程IO的引入，则解决了这个潜在的问题。   <br />Redis的架构演进之路，充满了智慧和汗水。从最初简单的缓存应用，到集群分片、多线程IO，Redis一步步成长为今天这个强大的内存数据库。它的发展历程，也映射出了业界对高性能、高可用数据存储的追求。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho5tas9ihej20u01k9qbj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho5tbbdmc6j20te10otfe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 12:14:48 GMT</pubDate>
</item>
<item>
<title>【Sora运行揭秘】- Sora是基于Latent Diffusion和Transformer的扩散模型，相比早期的图像生成模型显著提升了视频质量和一致性。 - 数据量和计算量的扩大是改进视...</title>
<link>https://weibo.com/1402400261/O6YA4eBGV</link>
<guid>https://weibo.com/1402400261/O6YA4eBGV</guid>
<content:encoded><![CDATA[
<div> Latent Diffusion、Transformer、视频质量、计算量、用户界面、训练计算量、应用渗透度、真实世界模拟、合成数据、机器学习技术

总结:<br /><br />
Sora是基于Latent Diffusion和Transformer的扩散模型，提升了视频质量和一致性。数据量和计算量的扩大是改进视频生成模型的关键，计算量增加将带来性能提升。Runway等公司正在研发Sora用户界面，对实用性至关重要。训练计算量巨大，推理计算将大于训练。Sora学会了模拟真实世界，可用于合成数据和数据增强。Sora代表了视频生成模型向更高质量发展里程碑，展示了先进机器学习技术潜力。训练数据对性能至关重要，Sora可能借助大型视频数据集。AI生成视频技术的快速发展将影响多个行业，未来电影制作可能由AI完成。视频生成模型发展将增大对算力尤其GPU的需求，Sora为未来GPU需求预测提供重要参考。 <div>
【Sora运行揭秘】<br />- Sora是基于Latent Diffusion和Transformer的扩散模型，相比早期的图像生成模型显著提升了视频质量和一致性。   <br />- 数据量和计算量的扩大是改进视频生成模型的关键，与大语言模型类似，可以预期计算量持续增加会带来模型性能的快速提升。   <br />- Runway等公司正在研发Sora等模型的用户界面和工作流程，这对其实用性至关重要。   <br />- Sora的训练计算量巨大，据估计需要4200-10500块H100 GPU计算一个月。但推理计算要大于训练计算，“收支平衡点”在生成1530-3810万分钟视频后。   <br />- 如果Sora类模型在TikTok和Youtube等平台达到较高应用渗透度，预计峰值需求将达到约72万个H100 GPU。   <br />- Sora隐含地学会了模拟真实世界，这对于在像素空间大规模训练机器人等具身智能体非常有用。   <br />- Sora类模型也可用于生成合成数据和数据增强，为缺乏数据的领域提供帮助。<br /><br />思考：  <br />- Sora代表了视频生成模型向更大规模、更高质量方向发展的重要里程碑。  <br />- Sora采用了多种先进的机器学习技术，包括扩散模型、潜在空间建模和Transformer架构，展示了这些技术在视频生成领域的巨大潜力。  <br />- 大规模高质量的训练数据对于视频生成模型的性能至关重要。Sora很可能得益于一个前所未有的大型视频数据集。  <br />- Sora的出现预示着AI生成视频技术的快速发展，将对电影、广告等多个行业产生深远影响。未来，AI有可能生成完整的电影，彻底改变视频内容的制作方式。  <br />- 随着视频生成模型的不断发展，对算力尤其是GPU的需求也将大幅增长。Sora为业界对未来GPU需求的预测提供了重要参考。<br />《Factorial Funds | Under The Hood: How OpenAI's Sora Model Works》 <a href="https://www.factorialfunds.com/blog/under-the-hood-how-openai-s-sora-model-works"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho5sx94j2qj20tu0grjup.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 12:01:28 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Mastering Memory Tasks with World Models》(ICLR 2024) GitHub: github.com/chandar-lab/Recall2Imagine《Composed Video Retrieval via ...</title>
<link>https://weibo.com/1402400261/O6WfYlh3o</link>
<guid>https://weibo.com/1402400261/O6WfYlh3o</guid>
<content:encoded><![CDATA[
<div> 关键词: Memory Tasks, World Models, Recall2Imagine, Video Retrieval, Logit Standardization, Knowledge Distillation, Vision-Language Models, Spec-Gaussian, AniPortrait, Data Mixing Laws

总结:<br /><br />本文介绍了几篇论文的实现代码，涵盖了多个领域包括记忆任务、视频检索、知识蒸馏、视觉-语言模型等。第一篇论文《Mastering Memory Tasks with World Models》通过实现代码Recall2Imagine来实现记忆任务。第二篇论文《Composed Video Retrieval via Enriched Context and Discriminative Embeddings》介绍了视频检索方法。第三篇论文《Logit Standardization in Knowledge Distillation》探讨了知识蒸馏中logit标准化的重要性。第四篇论文《Dual Memory Networks: A Versatile Adaptation Approach for Vision-Language Models》提出了一种适用于视觉-语言模型的双重记忆网络方法。还有其他论文涉及3D高斯光滑、音频驱动的动态图像合成、数据混合规律、波谱图像处理等多个领域。这些论文的实现代码均可在GitHub上找到，为相关研究领域的学术研究者提供了重要的参考资源。 <div>
几篇论文实现代码：<br />《Mastering Memory Tasks with World Models》(ICLR 2024) GitHub: github.com/chandar-lab/Recall2Imagine<br />《Composed Video Retrieval via Enriched Context and Discriminative Embeddings》(CVPR 2024) GitHub: github.com/OmkarThawakar/composed-video-retrieval<br />《Logit Standardization in Knowledge Distillation》(CVPR 2024) GitHub: github.com/sunshangquan/logit-standardization-KD<br />《Dual Memory Networks: A Versatile Adaptation Approach for Vision-Language Models》(CVPR 2024) GitHub: github.com/YBZh/DMN [fig4]<br />《Spec-Gaussian: Anisotropic View-Dependent Appearance for 3D Gaussian Splatting》(2024) GitHub: github.com/ingra14m/Specular-Gaussians<br />《AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animations》(2024) GitHub: github.com/Zejun-Yang/AniPortrait [fig1]<br />《Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance》(2024) GitHub: github.com/yegcjs/mixinglaws<br />《RGBD GS-ICP SLAM》(2024) GitHub: github.com/Lab-of-AI-and-Robotics/GS_ICP_SLAM<br />《AdaIR: Adaptive All-in-One Image Restoration via Frequency Mining and Modulation》(2024) GitHub: github.com/c-yn/AdaIR [fig2]<br />《Sotopia-π: Interactive Learning of Socially Intelligent Language Agents》(2024) GitHub: github.com/sotopia-lab/sotopia-pi [fig3]<br />《Visual CoT: Unleashing Chain-of-Thought Reasoning in the Multi-Modal Language Model》(2024) GitHub: github.com/deepcs233/Visual-CoT [fig5]<br />《LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models》(2024) GitHub: github.com/42Shawn/LLaVA-PruMerge<br />《GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks》(2024) GitHub: github.com/alibaba/GraphTranslator [fig6]<br />《Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance》(2024) GitHub: github.com/fudan-generative-vision/champ<br />《Optimizing LiDAR Placements for Robust Driving Perception in Adverse Conditions》(2024) GitHub: github.com/ywyeli/Place3D<br />《TC4D: Trajectory-Conditioned Text-to-4D Generation》(2024) GitHub: github.com/sherwinbahmani/tc4d<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho5hr2enfbj214y0sddtp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho5hu2pesmj20qi0hz7i3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho5humfr3hj21jk1jkkh6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho5ia4849cj20lb0fg46o.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho5iaui3hij21740gy430.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho5ihzzcdhj21h60tsgvg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 06:06:28 GMT</pubDate>
</item>
<item>
<title>【Go-Redis：快速高效的内存型 Key-Value 存储，Redis的替代方案，用 Go 语言实现】'Go-Redis - Super fast drop-in replacement of the in memory key-value st...</title>
<link>https://weibo.com/1402400261/O6WfRkdaQ</link>
<guid>https://weibo.com/1402400261/O6WfRkdaQ</guid>
<content:encoded><![CDATA[
<div> Go-Redis、快速、高效、内存型、Key-Value、存储、替代方案、Go语言实现、GitHub、Dhravya

<br /><br />总结:
Go-Redis是一个快速高效的内存型Key-Value存储，是Redis的替代方案，用Go语言实现。该项目托管在GitHub上，由Dhravya开发。Go-Redis是一个极具竞争力的项目，旨在提供与Redis相当甚至更快的性能。由于使用了Go语言实现，Go-Redis具有高效的并发处理能力和优秀的执行性能。通过使用Go-Redis，用户可以获得比传统的Redis更快的操作速度，这使得它成为许多项目的理想选择。如果您正在寻找一个快速、高效且易于集成的Key-Value存储解决方案，Go-Redis可能是您的不二之选。 <div>
【Go-Redis：快速高效的内存型 Key-Value 存储，Redis的替代方案，用 Go 语言实现】'Go-Redis - Super fast drop-in replacement of the in memory key-value store Redis, made in Golang' GitHub: github.com/Dhravya/go-redis <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Redis%23"><span class="surl-text">#Redis#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5inu9wf5j212f0u0q5w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 06:06:11 GMT</pubDate>
</item>
<item>
<title>【C-Shopping：基于Nextjs开发同时适配Desktop、Tablet、Phone多种设备的精美购物平台】'C-Shopping v1.0.0 - A beautiful shopping platform developed with Ne...</title>
<link>https://weibo.com/1402400261/O6WamwqdU</link>
<guid>https://weibo.com/1402400261/O6WamwqdU</guid>
<content:encoded><![CDATA[
<div> Next.js, Desktop, Tablet, Phone, 购物平台, 适配, GitHub, 开发, 设备, 精美

<br /><br />总结:
"C-Shopping v1.0.0"是一个基于Next.js开发的购物平台，可以适配多种设备，包括Desktop、Tablet和Phone。这个平台具有精美的界面设计，开发者已经将代码上传到GitHub上。希望通过这个平台提供更好的用户体验，满足不同设备的需求。 <div>
【C-Shopping：基于Nextjs开发同时适配Desktop、Tablet、Phone多种设备的精美购物平台】'C-Shopping v1.0.0 - A beautiful shopping platform developed with Next.js, tailored for various devices including Desktop, Tablet, and Phone. ' GitHub: github.com/huanghanzhilian/c-shopping <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho5i9ndpbej20dw07x0up.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5i9o9wgyj20rs0fq0ub.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5i9qf5elj20rs0fqdh6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:52:39 GMT</pubDate>
</item>
<item>
<title>【Flatito:用于搜索 YAML 和 JSON 文件的Grep工具，它可以帮助搜索文件中特定的关键字并获取相关信息】'Flatito: Grep for YAML and JSON files - Grep for YAML...</title>
<link>https://weibo.com/1402400261/O6W9hxmvS</link>
<guid>https://weibo.com/1402400261/O6W9hxmvS</guid>
<content:encoded><![CDATA[
<div> GitHub，Flatito，Grep，YAML，JSON，搜索工具，关键字，获取信息，ceritium，文件<br /><br />总结:
文章介绍了一款名为Flatito的工具，在GitHub上开源，用于搜索YAML和JSON文件中特定关键字的Grep工具。用户可以通过使用Flatito，搜索文件中的关键字，并获取相关信息。Flatito为程序员提供了便利，使他们能够快速准确地定位文件中的信息，提高工作效率。Flatito由ceritium开发，为用户提供了一个方便的工具，帮助他们更好地管理和处理YAML和JSON文件。 <div>
【Flatito:用于搜索 YAML 和 JSON 文件的Grep工具，它可以帮助搜索文件中特定的关键字并获取相关信息】'Flatito: Grep for YAML and JSON files - Grep for YAML and JSON files' GitHub: github.com/ceritium/flatito <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho5i6zke6sj20ui0u0dlc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:49:59 GMT</pubDate>
</item>
<item>
<title>【LLM-Culture：用于研究大型语言模型文化演化的开源框架】'LLM-Culture' GitHub: github.com/jeremyperez2/LLM-Culture #开源# #机器学习# #人工智能# [图片][...</title>
<link>https://weibo.com/1402400261/O6W8b6Y2a</link>
<guid>https://weibo.com/1402400261/O6W8b6Y2a</guid>
<content:encoded><![CDATA[
<div> GitHub, LLM-Culture, 研究, 大型语言模型, 文化演化, 开源框架

<br /><br />总结:
LLM-Culture是一个用于研究大型语言模型文化演化的开源框架。该项目存储在GitHub上，旨在探讨和分析语言模型在不同文化背景下的发展和变化。通过这个框架，研究人员可以对大型语言模型的文化演化有更深入的理解，并且可以进行进一步的研究和探索。希望这个工具能够为语言模型研究领域带来更多的启发和成果。 <div>
【LLM-Culture：用于研究大型语言模型文化演化的开源框架】'LLM-Culture' GitHub: github.com/jeremyperez2/LLM-Culture <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho5i41xnnmj22rl0u0wo9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5i43nxr3j21c00u0wh6.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho5i456uhyj22n90u0wog.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:47:16 GMT</pubDate>
</item>
<item>
<title>【WhatTheDuck：用于 DuckDB 的开源 web 应用，用户能将 CSV 文件上传并将其存储在表格中，并通过 SQL 进行查询】'WhatTheDuck - an open-source web applicatio...</title>
<link>https://weibo.com/1402400261/O6W7maOoB</link>
<guid>https://weibo.com/1402400261/O6W7maOoB</guid>
<content:encoded><![CDATA[
<div> DuckDB, 开源, web 应用, CSV 文件, 存储, 表格, SQL 查询, GitHub, incentius-foss, WhatTheDuck

<br /><br />总结:
WhatTheDuck是一个基于DuckDB的开源web应用，允许用户上传CSV文件并将其存储在表格中，然后通过SQL查询数据。用户可以在GitHub上找到该项目的代码，链接为github.com/incentius-foss/WhatTheDuck。通过WhatTheDuck，用户可以方便地管理CSV数据并进行SQL查询操作，为数据分析和处理提供了便利和效率。 <div>
【WhatTheDuck：用于 DuckDB 的开源 web 应用，用户能将 CSV 文件上传并将其存储在表格中，并通过 SQL 进行查询】'WhatTheDuck - an open-source web application built on DuckDB. It allows users to upload CSV files, store them in tables, and perform SQL queries on the data.' GitHub: github.com/incentius-foss/WhatTheDuck <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%95%B0%E6%8D%AE%E5%BA%93%23&amp;isnewpage=1"><span class="surl-text">#数据库#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5i21ftj3j21im0pkgqe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:45:14 GMT</pubDate>
</item>
<item>
<title>【BinaryVectorDB：用于高效搜索大规模向量数据库的开源项目】'BinaryVectorDB - Efficient Search on Large Datasets - Efficient vector database for hundred...</title>
<link>https://weibo.com/1402400261/O6W2NnyJQ</link>
<guid>https://weibo.com/1402400261/O6W2NnyJQ</guid>
<content:encoded><![CDATA[
<div> 向量数据库、高效搜索、大规模、开源项目、GitHub、BinaryVectorDB、向量、检索、百万级、嵌入<br />
<br />
BinaryVectorDB是一个开源项目，旨在提供高效搜索大规模向量数据库的解决方案。该项目在GitHub上托管，为用户提供了一个能够处理数亿个嵌入的有效向量数据库。通过BinaryVectorDB，用户可以快速检索和比对向量数据，实现快速而准确的搜索结果。这个项目的出现，为处理海量向量数据提供了便捷和高效的工具，为用户提供了更好的数据处理和资源利用方式。<br /><br />总结: <br />BinaryVectorDB是一个开源项目，旨在提供高效搜索大规模向量数据库的解决方案。该项目在GitHub上托管，为用户提供了一个能够处理数亿个嵌入的有效向量数据库。通过BinaryVectorDB，用户可以快速检索和比对向量数据，实现快速而准确的搜索结果。这个项目的出现，为处理海量向量数据提供了便捷和高效的工具，为用户提供了更好的数据处理和资源利用方式。 <div>
【BinaryVectorDB：用于高效搜索大规模向量数据库的开源项目】'BinaryVectorDB - Efficient Search on Large Datasets - Efficient vector database for hundred millions of embeddings.' GitHub: github.com/cohere-ai/BinaryVectorDB <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho5hpriibpj21250u0zpc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:34:00 GMT</pubDate>
</item>
<item>
<title>【Freeze：代码和终端输出的截图生成】’Freeze - Generate images of code and terminal output' GitHub: github.com/charmbracelet/freeze #开源# #工具# [图...</title>
<link>https://weibo.com/1402400261/O6W1ObpF9</link>
<guid>https://weibo.com/1402400261/O6W1ObpF9</guid>
<content:encoded><![CDATA[
<div> GitHub、Freeze、代码、终端输出、生成、图片、charmbracelet、截图、工具、开发者<br />
<br />
重点介绍了一个名为Freeze的工具，可以帮助开发者生成代码和终端输出的截图。该工具由charmbracelet团队开发，通过GitHub进行了开源。Freeze可以将代码和终端输出转化为图片形式，方便开发者进行分享和展示。开发者可以通过Freeze轻松地生成漂亮的截图，提高展示代码和输出结果的效果和效率。 <div>
【Freeze：代码和终端输出的截图生成】’Freeze - Generate images of code and terminal output' GitHub: github.com/charmbracelet/freeze <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%B7%A5%E5%85%B7%23&amp;isnewpage=1"><span class="surl-text">#工具#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho5hnigrrkj20ul0u076u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:31:34 GMT</pubDate>
</item>
<item>
<title>【Hybrid-Net：基于 Transformer 的音源分离工具，可生成歌词、旋律、节奏等】'Hybrid-Net - Real-time audio source separation, generate lyrics, chords, bea...</title>
<link>https://weibo.com/1402400261/O6W11h8la</link>
<guid>https://weibo.com/1402400261/O6W11h8la</guid>
<content:encoded><![CDATA[
<div> Transformer、音源分离、歌词、旋律、节奏、实时、生成、Hybrid-Net、GitHub、工具

Hybrid-Net 是一个基于 Transformer 技术的音源分离工具，能够实时分离音频源，并生成歌词、旋律和节奏。用户可以在GitHub上找到Hybrid-Net的源代码。这个工具利用了先进的深度学习技术，为音乐制作人和音乐爱好者提供了一种方便且高效的音源分离工具，使他们能够更好地编辑和制作音乐作品。Hybrid-Net的实时性和生成多种音乐元素的能力使其在音乐创作和制作领域具有很大的应用潜力。Hybrid-Net为音乐创作提供了更多可能性，让用户更容易地创作出优质的音乐作品。 <div>
【Hybrid-Net：基于 Transformer 的音源分离工具，可生成歌词、旋律、节奏等】'Hybrid-Net - Real-time audio source separation, generate lyrics, chords, beat.' GitHub: github.com/DoMusic/Hybrid-Net <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5hlmtar0j21400h6tat.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:29:38 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评...</title>
<link>https://weibo.com/1402400261/O6TbSFiLr</link>
<guid>https://weibo.com/1402400261/O6TbSFiLr</guid>
<content:encoded><![CDATA[
<div> Java, Python, JavaScript, C语言, MySQL, Redis, 技术原理, 故事, 码农翻身2

总结：<br /><br />
《码农翻身2》是一部以故事为主线讲解技术的畅销书，将枯燥的技术内容变成有趣的故事。在编程语言王国中，Java向Python渗透，JavaScript向Java进攻，C语言孤独回家，MySQL和Redis相互作对。通过讲述这些故事，读者可以轻松掌握技术原理和本质，享受阅读乐趣。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 22:18:09 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发...</title>
<link>https://weibo.com/1402400261/O6TbNCOp0</link>
<guid>https://weibo.com/1402400261/O6TbNCOp0</guid>
<content:encoded><![CDATA[
<div> hello 算法, 截止日期, 可可粉, 数据结构, 算法, 动画图解, 实战代码示例, 互动环节, 直观易懂, 新知识

<br /><br />总结:
截止日期为2024年3月29日中午12:00，参与方式是转发并评论帖子。这本《hello 算法》书籍以全新的视角讲解数据结构与算法，每一章节都有生动的动画图解，让抽象的概念变得直观易懂。书中还提供实战代码示例帮助读者即学即用，及时巩固新知识。互动环节的设计则能帮助读者主动思考、提问和解决问题。通过这本书，读者可以轻松掌握算法，进入算法的世界。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 22:17:57 GMT</pubDate>
</item>
<item>
<title>今日推介(第1357期)：LLM Agent操作系统、从损失角度理解语言模型的涌现能力、用概率流推进扩散语言生成、基于大语言模型状态奖励和动作建模的强化学习推荐系统...</title>
<link>https://weibo.com/1402400261/O6TbDB7R4</link>
<guid>https://weibo.com/1402400261/O6TbDB7R4</guid>
<content:encoded><![CDATA[
<div> LLM Agent操作系统、损失角度、语言模型、能力、概率流、扩散语言生成、大语言模型、强化学习、推荐系统、3DGS
总结：<br /><br />本文介绍了最新的LLM Agent操作系统，从损失角度探讨了语言模型的涌现能力，提出了用概率流推进扩散语言生成的方法，以及基于大语言模型的状态奖励和动作建模的强化学习推荐系统。此外，还讨论了3DGS在改进渲染和重建的SDF中的应用。整篇文章深入探讨了语言模型和人工智能技术在推荐系统和渲染领域的最新进展。 <div>
今日推介(第1357期)：LLM Agent操作系统、从损失角度理解语言模型的涌现能力、用概率流推进扩散语言生成、基于大语言模型状态奖励和动作建模的强化学习推荐系统、3DGS满足改进渲染和重建的SDF 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/689222773"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.27)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho553velkuj20go0bp3zt.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho553xmqk5j20go0dzmyp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho5540zmsoj20go04rq3a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho55447ws1j20go0770th.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho5546v8uwj20go0b0q4m.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 22:17:32 GMT</pubDate>
</item>
<item>
<title>[CV] Gaussian in the Wild: 3D Gaussian Splatting for Unconstrained Image Collections 网页链接 GS-W通过为每个高斯点建立独立、可自适应采样的内在与动态外...</title>
<link>https://weibo.com/1402400261/O6T8nkhR8</link>
<guid>https://weibo.com/1402400261/O6T8nkhR8</guid>
<content:encoded><![CDATA[
<div> 高斯点，内在动态外观表示，图像重建，快速渲染，高质量<br />
<br />
提出了一种名为GS-W的算法，通过为每个高斯点建立独立、可自适应采样的内在与动态外观表示，实现了从无限制图像重建场景的高质量与快速渲染。这种方法能够有效处理不受约束的图像集合，提高重建场景的质量和渲染速度。GS-W算法的关键在于对每个高斯点的内在和动态外观表示进行有效建模，从而实现高质量的场景重建。通过实验证明了该算法的有效性和性能优势，为处理无约束图像集合提供了有效的解决方案。 <div>
[CV]  Gaussian in the Wild: 3D Gaussian Splatting for Unconstrained Image Collections  <br /><a href="https://arxiv.org/abs/2403.15704"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />GS-W通过为每个高斯点建立独立、可自适应采样的内在与动态外观表示，实现了从无限制图像重建场景的高质量与快速渲染。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho54vv1aymj20qa15stj4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho54vvdhkgj21fu16ywr8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 22:09:31 GMT</pubDate>
</item>
<item>
<title>[CV] CG-SLAM: Efficient Dense RGB-D SLAM in a Consistent Uncertainty-aware 3D Gaussian Field 网页链接 提出CG-SLAM系统，通过高斯Splatting技术实现高效精...</title>
<link>https://weibo.com/1402400261/O6T3Ogxsv</link>
<guid>https://weibo.com/1402400261/O6T3Ogxsv</guid>
<content:encoded><![CDATA[
<div> 关键词: CG-SLAM, 高斯Splatting, 相机跟踪, 场景重建, RGB-D SLAM

总结:<br /><br />总结:本文提出了CG-SLAM系统，通过高斯Splatting技术实现高效精确的相机跟踪和优质场景重建，是实时和高质量RGB-D SLAM的有效途径。CG-SLAM能够在三维高斯场中保持一致的不确定性估计，同时有效地处理相机运动和场景表面的变化。使用高斯场作为数据结构使得系统能够高效地进行场景表面重建和相机定位。通过实验证明，CG-SLAM系统具有良好的鲁棒性和实时性，适用于各种室内和室外场景的SLAM任务。 <div>
[CV] CG-SLAM: Efficient Dense RGB-D SLAM in a Consistent Uncertainty-aware 3D Gaussian Field  <br /><a href="https://arxiv.org/abs/2403.16095"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出CG-SLAM系统，通过高斯Splatting技术实现高效精确的相机跟踪和优质场景重建，是实时和高质量RGB-D SLAM的有效途径。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho54k4hfr4j20v21codub.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho54k4yen1j21gu0mqn7w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho54k5m4gaj21hc0w8amw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 21:58:16 GMT</pubDate>
</item>
<item>
<title>[CV] latentSplat: Autoencoding Variational Gaussians for Fast Generalizable 3D Reconstruction 网页链接 提出变分3D高斯表示以及从两个视角进行预测和新视...</title>
<link>https://weibo.com/1402400261/O6SYutbHt</link>
<guid>https://weibo.com/1402400261/O6SYutbHt</guid>
<content:encoded><![CDATA[
<div> 变分高斯表示, 3D重建, 视频训练数据, autoencoding, 预测, 合成, 快速, 高质量, 可推广

<br /><br />总结:
latentSplat提出了一种框架，实现了快速、高质量、可推广的3D场景重建。该框架利用变分高斯表示，可以从两个视角进行预测和新视角合成。重要的是，该方法仅依赖容易获得的视频训练数据，为实现高效的3D重建提供了新途径。 <div>
[CV] latentSplat: Autoencoding Variational Gaussians for Fast Generalizable 3D Reconstruction  <br /><a href="https://arxiv.org/abs/2403.16292"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出变分3D高斯表示以及从两个视角进行预测和新视角合成的框架，实现了快速、高质量、可推广的3D场景重建，仅依赖容易获得的视频训练数据。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho546i1lj5j20ry190dui.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho546ils4uj21jg0zygz3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 21:45:10 GMT</pubDate>
</item>
<item>
<title>提出一个双分支框架，通过3D高斯Splatting渲染和符号距离场表面重建的有效结合，实现了渲染质量和重建细节的同时改进。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《GSDF...</title>
<link>https://weibo.com/1402400261/O6SU0i26G</link>
<guid>https://weibo.com/1402400261/O6SU0i26G</guid>
<content:encoded><![CDATA[
<div> 高斯Splatting、3D、符号距离场、渲染、重建、质量、细节、双分支框架、改进、GSDF<br />
<br />
提出了一个双分支框架，结合了3D高斯Splatting渲染和符号距离场表面重建，从而在同时改进渲染质量和重建细节方面取得了显著进展。该框架通过将渲染和重建两个任务进行有效结合，实现了更好的渲染效果和更精细的重建结果。研究者提出的GSDF方法为3DGS和SDF的结合提供了一种有效的途径，极大地提高了渲染和重建的效率和精度。此外，该方法还在实际应用中取得了令人满意的效果，显示出了其在图形渲染和重建领域的巨大潜力。<br /><br />总结: <div>
提出一个双分支框架，通过3D高斯Splatting渲染和符号距离场表面重建的有效结合，实现了渲染质量和重建细节的同时改进。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《GSDF: 3DGS Meets SDF for Improved Rendering and Reconstruction》M Yu, T Lu, L Xu, L Jiang, Y Xiangli, B Dai [Shanghai Artificial Intelligence Laboratory &amp; The Chinese University of Hong Kong] (2024) <a href="https://arxiv.org/abs/2403.16964"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho53um5ibnj215q0xe4df.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho53umrat0j21dk0wq7gu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho53un9e7oj21cc1d0arn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53unllu1j21by1481bk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho53uozslwj20rl0cq40y.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53up08vbj20rl0lh422.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53uozovdj20rl0e2tas.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho53up110dj20rl12an1y.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53up29daj20rl14ln4z.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 21:34:06 GMT</pubDate>
</item>
<item>
<title>[CV]《GSDF: 3DGS Meets SDF for Improved Rendering and Reconstruction》M Yu, T Lu, L Xu, L Jiang, Y Xiangli, B Dai [Shanghai Artificial Intelligence La...</title>
<link>https://weibo.com/1402400261/O6STSyJ3k</link>
<guid>https://weibo.com/1402400261/O6STSyJ3k</guid>
<content:encoded><![CDATA[
<div> 关键词：GSDF, 3DGS, SDF, 改进渲染, 重建, 人工智能, 上海, 香港大学, 2024

总结:<br /><br />这篇文章探讨了GSDF技术与3DGS相结合以改善渲染和重建的方法。作者来自上海人工智能实验室和香港大学。他们的研究着重于将GSDF技术与SDF技术相结合，以改善三维物体渲染和重建过程。通过这种方法，他们取得了显著的进展，提高了渲染和重建的准确性和效率。这不仅对于三维图形领域具有重要意义，也为人工智能技术的发展带来了新的启示。<br /><br /> <div>
[CV]《GSDF: 3DGS Meets SDF for Improved Rendering and Reconstruction》M Yu, T Lu, L Xu, L Jiang, Y Xiangli, B Dai [Shanghai Artificial Intelligence Laboratory &amp; The Chinese University of Hong Kong] (2024) <a href="https://arxiv.org/abs/2403.16964"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho53um5ibnj215q0xe4df.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho53umrat0j21dk0wq7gu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho53un9e7oj21cc1d0arn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53unllu1j21by1481bk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho53uozslwj20rl0cq40y.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53up08vbj20rl0lh422.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53uozovdj20rl0e2tas.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho53up110dj20rl12an1y.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53up29daj20rl14ln4z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 21:33:48 GMT</pubDate>
</item>
<item>
<title>提出使用大型语言模型作为强化学习推荐系统的环境，提供更精确的状态表达和反馈奖励，同时增强正样本，在多个数据集上持续改进性能。 - 转发 @爱可可-爱生活:&amp;en...</title>
<link>https://weibo.com/1402400261/O6SMp8nBP</link>
<guid>https://weibo.com/1402400261/O6SMp8nBP</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、强化学习、推荐系统、状态表达、反馈奖励、正样本、数据集、性能改进、大型模型、状态建模

<br /><br />总结:
本研究提出了使用大型语言模型作为强化学习推荐系统环境的方法，以提供更精确的状态表达和反馈奖励。同时，通过增强正样本并在多个数据集上持续改进性能，实现了更精准的推荐结果。研究团队来自格拉斯哥大学、谷歌研究和 Telefonica 研究，并在实验中展示了该方法的有效性。通过综合利用大型语言模型，本研究为推荐系统提供了新的发展思路，有望在推荐领域取得重要进展。 <div>
提出使用大型语言模型作为强化学习推荐系统的环境，提供更精确的状态表达和反馈奖励，同时增强正样本，在多个数据集上持续改进性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [IR]《Reinforcement Learning-based Recommender Systems with Large Language Models for State Reward and Action Modeling》J Wang, A Karatzoglou, I Arapakis, J M. Jose [University of Glasgow &amp; Google Research &amp; Telefonica Research] (2024) <a href="https://arxiv.org/abs/2403.16948"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho539won58j20ws0z2n9m.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho539xhgknj21tq0sedok.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho539xzqrwj20wm0xeqbw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho539yhjdkj20wa112ai0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho53bdnk6oj21ay0pqdk2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho53be6zx9j21b20ooq6l.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 21:15:23 GMT</pubDate>
</item>
<item>
<title>[IR]《Reinforcement Learning-based Recommender Systems with Large Language Models for State Reward and Action Modeling》J Wang, A Karatzoglou, I Arapa...</title>
<link>https://weibo.com/1402400261/O6SMlykck</link>
<guid>https://weibo.com/1402400261/O6SMlykck</guid>
<content:encoded><![CDATA[
<div> 大语言模型，强化学习，推荐系统，状态奖励，行为建模，J Wang，A Karatzoglou，I Arapakis，J M. Jose，2024

<br /><br />总结:
该研究探讨了基于强化学习的推荐系统，利用大型语言模型进行状态奖励和行为建模。研究明确使用深度强化学习模型，结合大型语言模型，可以提高推荐系统的性能。文章介绍了推荐系统中状态和行为的重要性，并提出了一种新的方法来利用语言模型进行状态奖励的建模。实验证明这种方法在不同数据集上都取得了优异的效果，对推荐系统的发展具有重要意义。 <div>
[IR]《Reinforcement Learning-based Recommender Systems with Large Language Models for State Reward and Action Modeling》J Wang, A Karatzoglou, I Arapakis, J M. Jose [University of Glasgow &amp; Google Research &amp; Telefonica Research] (2024) <a href="https://arxiv.org/abs/2403.16948"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho539won58j20ws0z2n9m.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho539xhgknj21tq0sedok.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho539xzqrwj20wm0xeqbw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho539yhjdkj20wa112ai0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho53bdnk6oj21ay0pqdk2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho53be6zx9j21b20ooq6l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 21:15:15 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.26)》 爱可可微博热门分享(3.26) [图片]</title>
<link>https://weibo.com/1402400261/O6Qj0dJAk</link>
<guid>https://weibo.com/1402400261/O6Qj0dJAk</guid>
<content:encoded><![CDATA[
<div> 微博，热门，分享，爱可可，3.26，关键词

爱可可微博在3月26日分享的内容受到了热烈讨论和转发，引起了广泛关注。微博上涉及的话题有着吸引人的内容，引起了人们的共鸣。用户们积极参与讨论，分享自己的观点和看法。通过微博平台，信息得以迅速传播和传达，形成了一种有趣而具有交流性质的社交氛围。微博热门分享的内容吸引了用户的关注和互动，使得微博平台成为了信息传递和互动交流的重要平台。

<br /><br />总结: 
- 微博平台在3月26日分享的内容引起了热烈讨论和转发
- 用户们积极参与讨论，分享自己的观点和看法
- 微博成为人们信息传播和互动交流的重要平台 <div>
《爱可可微博热门分享(3.26)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405016310345236560"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.26)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4se5qzs7j20lc0c0q4b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 14:57:27 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故...</title>
<link>https://weibo.com/1402400261/O6PqzpRsK</link>
<guid>https://weibo.com/1402400261/O6PqzpRsK</guid>
<content:encoded><![CDATA[
<div> 技术故事, 编程语言, Java, Python, JavaScript, C语言, MySQL, Redis, 技术原理, 爽

总结:
《码农翻身2》用故事的形式生动讲解技术知识，让看似枯燥的技术变得有趣。编程语言王国之间争斗不断，如Java向Python渗透，JavaScript向Java进攻。C语言孤独无侣，MySQL和Redis互相博弈。书中内容既能让读者掌握技术原理，又能让阅读过程愉快爽快。 <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 12:43:21 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Differentiable Euler Characteristic Transforms for Shape Classification》(ICLR 2024) GitHub: github.com/aidos-lab/DECT《Str2Str: A...</title>
<link>https://weibo.com/1402400261/O6MPm0zl4</link>
<guid>https://weibo.com/1402400261/O6MPm0zl4</guid>
<content:encoded><![CDATA[
<div> 关键词: Differentiable Euler Characteristic Transforms, Shape Classification, Zero-shot Protein Conformation Sampling, Neural Architecture Generation, Autonomous Driving, Human Image Animation, Topological Navigation, Object Relighting, Visual Recognition, Garment Dynamics

总结:<br /><br />
本文介绍了几篇论文以及它们的实现代码，涵盖了形状分类、蛋白质构象采样、神经架构生成、自主驾驶、人物图像动画、拓扑导航、物体照明重建、视觉识别、服装动力学等领域。不同论文采用不同方法和模型，展示了在各个领域的应用和研究成果。这些研究对于推动人工智能领域的发展具有重要意义，为相关领域提供了新的思路和方法。每篇论文都在GitHub上公开了相应的实现代码，方便其他研究者和开发者进行复现和进一步研究。总体来说，这些论文为人工智能领域的不同方向带来了新的启发和发展方向。 <div>
几篇论文实现代码：<br />《Differentiable Euler Characteristic Transforms for Shape Classification》(ICLR 2024) GitHub: github.com/aidos-lab/DECT<br />《Str2Str: A Score-based Framework for Zero-shot Protein Conformation Sampling》(ICLR 2024) GitHub: github.com/lujiarui/Str2Str [fig4] <br />《DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion Models》(ICLR 2024) GitHub: github.com/CownowAn/DiffusionNAG [fig6]<br />《M-BEV: Masked BEV Perception for Robust Autonomous Driving》(AAAI 2024) GitHub: github.com/Sranc3/M-BEV<br />《Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance》(2024) GitHub: github.com/fudan-generative-vision/champ [fig1]<br />《LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement》(2024) GitHub: github.com/SqueezeAILab/LLM2LLM [fig2]<br />《PlaceNav: Topological Navigation through Place Recognition》(2024) GitHub: github.com/lasuomela/PlaceNav<br />《Objects With Lighting: A Real-World Dataset for Evaluating Reconstruction and Rendering for Object Relighting》(2024) GitHub: github.com/isl-org/objects-with-lighting<br />《RAR: Retrieving And Ranking Augmented MLLMs for Visual Recognition》(2024) GitHub: github.com/Liuziyu77/RAR [fig3]<br />《Neural Garment Dynamics via Manifold-Aware Transformers》(2024) GitHub: github.com/PeizhuoLi/manifold-aware-transformers<br />《PSALM: Pixelwise SegmentAtion with Large Multi-Modal Model》(2024) GitHub: github.com/zamling/PSALM [fig5] <br />《Calib3D: Calibrating Model Preferences for Reliable 3D Scene Understanding》(2024) GitHub: github.com/ldkong1205/Calib3D<br />《Pixel-GS: Density Control with Pixel-aware Gradient for 3D Gaussian Splatting》(2024) GitHub: github.com/zhengzhang01/Pixel-GS<br />《LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues》(2024) GitHub: github.com/apple/ml-lucid-datagen<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho4abzisurj25w13p6qv5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4baefc75j21il0rydsw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4c4jtjkjj211q0o51kx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4cdialr6j228k0zjdp0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4cfbs7l9j227m15v1kx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho4clt5s6uj2334140e0c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 06:06:10 GMT</pubDate>
</item>
<item>
<title>【神经编程智能相关资源大列表】’Neural Code Intelligence Survey 2024; Reading lists and resources' GitHub: github.com/QiushiSun/NCISurvey #开源# #机器...</title>
<link>https://weibo.com/1402400261/O6MP72Yu5</link>
<guid>https://weibo.com/1402400261/O6MP72Yu5</guid>
<content:encoded><![CDATA[
<div> GitHub，神经编程智能，资源，大列表，调查，阅读列表，2024，编程智能，智能资源，神经网络

<br /><br />总结:
该文章介绍了一个名为'Neural Code Intelligence Survey 2024; Reading lists and resources'的GitHub项目，旨在提供与神经编程智能相关的资源大列表。该项目汇总了各种阅读列表和资源，帮助研究人员和开发者了解神经编程智能领域的最新进展和相关资源。通过这个项目，人们可以更方便地获取相关文献和资料，促进神经编程智能领域的发展。 <div>
【神经编程智能相关资源大列表】’Neural Code Intelligence Survey 2024; Reading lists and resources' GitHub: github.com/QiushiSun/NCISurvey <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho4d0m99f9j235s0p0wp9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho4d0v502rj20tw0t2q7j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 06:05:33 GMT</pubDate>
</item>
<item>
<title>【具身智能相关资源大列表】’Awesome-Embodied-AI' GitHub: github.com/yunlongdong/Awesome-Embodied-AI #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O6MLs9Z8n</link>
<guid>https://weibo.com/1402400261/O6MLs9Z8n</guid>
<content:encoded><![CDATA[
<div> GitHub、具身智能、资源、列表、 Awesome-Embodied-AI、代码库、云龙东、开放源代码、机器人、项目。

<br /><br />总结:
Awesome-Embodied-AI是一个GitHub代码库，收集了与具身智能相关的资源，为开发机器人和其他具身智能项目提供了丰富的开放源代码资源。由云龙东创建，是一个非常有价值的资源列表。 <div>
【具身智能相关资源大列表】’Awesome-Embodied-AI' GitHub: github.com/yunlongdong/Awesome-Embodied-AI <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho4cri39iij20w70u0q7g.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:56:33 GMT</pubDate>
</item>
<item>
<title>【Vid2Persona：用 AI 描述视频角色的性格，并作为角色与您聊天】'Vid2Persona - This project breathes life into video characters by using AI to describe t...</title>
<link>https://weibo.com/1402400261/O6ML5kiCj</link>
<guid>https://weibo.com/1402400261/O6ML5kiCj</guid>
<content:encoded><![CDATA[
<div> GitHub, Vid2Persona, AI, 视频角色, 描述性格, 聊天 <br />
<br />
总结:<br />
Vid2Persona是一个使用AI描述视频角色性格并与用户进行聊天的项目，通过GitHub可以了解更多相关信息。 <div>
【Vid2Persona：用 AI 描述视频角色的性格，并作为角色与您聊天】'Vid2Persona - This project breathes life into video characters by using AI to describe their personality and then chat with you as them.' GitHub: github.com/deep-diver/Vid2Persona <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho4cqjcmbkj20u01mu113.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:55:39 GMT</pubDate>
</item>
<item>
<title>【The Pipe：一个多模态工具，用于将现实世界的信息输入大语言模型，基于多核设计，通过精心设计的启发式方法，从文件、文件夹、网页等来源创建有意义的文本和图...</title>
<link>https://weibo.com/1402400261/O6MKv317f</link>
<guid>https://weibo.com/1402400261/O6MKv317f</guid>
<content:encoded><![CDATA[
<div> GitHub, 多模态工具, 现实世界信息, 大语言模型, 多核设计, 启发式方法, 文件文件夹网页, 文本图像提示

<br /><br />总结:
The Pipe是一个多模态工具，可以将现实世界的信息输入大语言模型。它采用多核设计和精心设计的启发式方法，可以从文件、文件夹、网页等来源创建有意义的文本和图像提示。用户可以通过GitHub找到The Pipe的开源代码，利用它来加强语言模型的学习和应用。 <div>
【The Pipe：一个多模态工具，用于将现实世界的信息输入大语言模型，基于多核设计，通过精心设计的启发式方法，从文件、文件夹、网页等来源创建有意义的文本和图像提示】'The Pipe - Feed real-world data into large language models / 管道' GitHub: github.com/emcf/thepipe <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho4cp11869j20yp0u0n28.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:54:12 GMT</pubDate>
</item>
<item>
<title>【文生视频相关文献资源列表】’Awesome-Text-to-Video-Generation - A list for Text-to-Video, Image-to-Video works' GitHub: github.com/soraw-ai/Awesome-T...</title>
<link>https://weibo.com/1402400261/O6MJMfNJG</link>
<guid>https://weibo.com/1402400261/O6MJMfNJG</guid>
<content:encoded><![CDATA[
<div> GitHub、Awesome-Text-to-Video-Generation、文本到视频、图像到视频、资源列表、文献、soraw-ai、生成文本、生成视频、生成图像

<br /><br />总结:
这是一个关于文本到视频和图像到视频生成的资源列表，收录了各种与这一主题相关的文献资料和项目。GitHub上的项目地址为github.com/soraw-ai/Awesome-Text-to-Video-Generation。该资源列表涵盖了生成文本到视频和图像到视频的各种作品和研究成果，是研究和开发这一领域的重要参考资料。通过这个资源列表，可以了解到当前在文本到视频和图像到视频生成方面的最新进展和成果。 <div>
【文生视频相关文献资源列表】’Awesome-Text-to-Video-Generation - A list for Text-to-Video, Image-to-Video works' GitHub: github.com/soraw-ai/Awesome-Text-to-Video-Generation <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho4cn6zqyxj217t0u0qar.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:52:26 GMT</pubDate>
</item>
<item>
<title>【Prompt Quill：全球第一个基于RAG的提示工程助手，基于320万个可用提示库，目的是为了帮用户更好地创建用于生成图像的提示】’Welcome to Prompt Quill - worl...</title>
<link>https://weibo.com/1402400261/O6MIvy3Ea</link>
<guid>https://weibo.com/1402400261/O6MIvy3Ea</guid>
<content:encoded><![CDATA[
<div> RAG、提示工程助手、320万提示库、图像生成、GitHub、OSI1880VR、工具、创新、全球第一

<br /><br />总结:
Prompt Quill是全球第一个基于RAG的提示工程助手，旨在帮助用户更好地创建用于生成图像的提示。它提供了一个庞大的提示库，包含320万个可用提示，用户可以在GitHub上找到该项目。此工具由OSI1880VR开发，标志着在提示领域的创新。 Prompt Quill的出现为图像生成领域带来了便利和效率。 <div>
【Prompt Quill：全球第一个基于RAG的提示工程助手，基于320万个可用提示库，目的是为了帮用户更好地创建用于生成图像的提示】’Welcome to Prompt Quill - world's first RAG driven prompt engineer helper at this large scale‘ GitHub: github.com/osi1880vr/prompt_quill <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho4chy7dxmj20m80ciwhg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho4cij6r6zj20vp0u0teb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:49:17 GMT</pubDate>
</item>
<item>
<title>'FlowJax: Distributions and Normalizing Flows in Jax' GitHub: github.com/danielward27/flowjax #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O6MFB1yZY</link>
<guid>https://weibo.com/1402400261/O6MFB1yZY</guid>
<content:encoded><![CDATA[
<div> GitHub, FlowJax, Distributions, Normalizing Flows, Jax

<br />FlowJax是一个在Jax中处理分布和正规化流的工具，作者是danielward27。他们在GitHub上发布了这个工具的源代码。FlowJax是一个用于处理分布和正规化流的工具，它使用Jax库来实现。Jax是一个针对机器学习的开源Python库，提供了自动微分和跨设备并行计算的功能。FlowJax的主要目的是使处理分布和正规化流的任务更加简单和高效。正规化流是一种用于近似复杂概率分布的技术，通过将简单分布映射到目标分布来实现。FlowJax可以帮助用户实现各种分布和正规化流模型，在Jax的基础上快速实现和测试新的方法。通过GitHub上的源代码，用户可以自行下载并使用FlowJax工具，进行更加高效的分布处理和正规化流建模。FlowJax的出现为在Jax中处理分布和正规化流任务的研究者和开发者提供了新的工具和资源，有助于推动这一领域的发展。总结: FlowJax是一个在Jax中处理分布和正规化流的工具，提供了简单和高效的方法来处理分布和正规化流模型，并为研究者和开发者提供了新的工具和资源。 <div>
'FlowJax: Distributions and Normalizing Flows in Jax' GitHub: github.com/danielward27/flowjax <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho4ccdudddj20su0df77w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:42:07 GMT</pubDate>
</item>
<item>
<title>【Sycamore：用于复杂非结构数据(文档、幻灯片、音频等)的开源项目，提供基于LLM的搜索和分析等服务】’ Sycamore is an LLM-powered search and analytics plat...</title>
<link>https://weibo.com/1402400261/O6MEEpoLM</link>
<guid>https://weibo.com/1402400261/O6MEEpoLM</guid>
<content:encoded><![CDATA[
<div> Sycamore, 开源项目, 复杂非结构数据, 文档, 幻灯片, 音频, LLN, 搜索, 分析, GitHub<br />
<br />总结:
Sycamore是一个基于LLN技术的开源搜索和分析平台，专门用于处理复杂非结构化数据，如文档、幻灯片和音频等。项目提供了强大的搜索和分析功能，适用于处理各种类型的非结构化数据。GitHub上有相关项目代码。 <div>
【Sycamore：用于复杂非结构数据(文档、幻灯片、音频等)的开源项目，提供基于LLM的搜索和分析等服务】’ Sycamore is an LLM-powered search and analytics platform for unstructured data.' GitHub: github.com/aryn-ai/sycamore <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho4c9z4bznj21910u0gsh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho4ca0kslpj21ra0u0n2u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:39:48 GMT</pubDate>
</item>
<item>
<title>【A Survey of LLM Surveys：精心分类的LLM综述大列表】’A Survey of LLM Surveys - A collection of 150+ surveys on LLMs' GitHub: github.com/NiuTrans/ABig...</title>
<link>https://weibo.com/1402400261/O6MDExdGc</link>
<guid>https://weibo.com/1402400261/O6MDExdGc</guid>
<content:encoded><![CDATA[
<div> GitHub, LLM, surveys, collection, 150+, classifications, repository, NiuTrans, comprehensive, list

<br /><br />总结:
这篇文章介绍了一个收集了150多份关于LLM（Large Language Model）的综述调查的GitHub仓库，其中详细分类整理了这些调查报告，提供了一个全面的列表。这个仓库由NiuTrans创建，为研究人员提供了一个有用的资源，帮助他们更好地了解和研究LLM。 <div>
【A Survey of LLM Surveys：精心分类的LLM综述大列表】’A Survey of LLM Surveys - A collection of 150+ surveys on LLMs' GitHub: github.com/NiuTrans/ABigSurveyOfLLMs <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho4c7irs9nj20u00u5n10.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:37:20 GMT</pubDate>
</item>
<item>
<title>【浓缩时间轴：AI简史】《A brief history of Artificial Intelligence》网页链接 #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O6KTU4o1u</link>
<guid>https://weibo.com/1402400261/O6KTU4o1u</guid>
<content:encoded><![CDATA[
<div> 计算机、逻辑学家、模式识别、神经网络、机器学习、深度学习、自然语言处理、图像识别、智能系统、强化学习
<br />
人类最早对人工智能概念的探讨可以追溯到古希腊哲学家亚里士多德，但直到20世纪中叶才开始真正发展，计算机的发展为AI提供了实现的可能性。20世纪50年代至70年代，逻辑学家提出了第一个“逻辑神经元模型”，引入了模式识别和神经网络的概念。80年代至90年代，机器学习和深度学习技术不断发展，带动了AI领域的快速发展。近年来，自然语言处理、图像识别等技术的突破使得智能系统在各个领域得到广泛应用，而强化学习技术的不断深入研究也为AI的未来发展带来了更多可能性。AI已经成为当今社会发展的重要推动力，其在医疗、交通、金融、教育等领域的应用已经深深改变了人们的生活和工作方式。AI的发展将继续推动人类社会迈向智能化时代。 
<br />总结: 
人工智能概念起源于古希腊哲学家，20世纪中叶开始起步，计算机发展为AI实现提供可能性；逻辑学家提出“逻辑神经元模型”引入模式识别和神经网络；80-90年代机器学习和深度学习技术发展推动AI迅速发展；自然语言处理、图像识别等技术突破加速智能系统应用；强化学习技术研究为AI未来发展拓展更多可能性；AI已广泛应用于医疗、交通、金融、教育等领域，改变人们生活和工作方式；AI将推动人类社会向智能化时代迈进。 <div>
【浓缩时间轴：AI简史】《A brief history of Artificial Intelligence》<a href="http://aicoco.net/s/8h"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho44i0tcbcj21360u047x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 01:11:53 GMT</pubDate>
</item>
<item>
<title>【LeaderboardFinder：找到适合特定场景的大模型排行榜】《LeaderboardFinder - Have you ever wondered which leaderboard would be best for your use case? -...</title>
<link>https://weibo.com/1402400261/O6KzqeZW5</link>
<guid>https://weibo.com/1402400261/O6KzqeZW5</guid>
<content:encoded><![CDATA[
<div> leaderboard, 大模型, 排行榜, 适合, 特定场景, Hugging Face Space, use case

<br /><br />总结:
这篇文章介绍了一个名为LeaderboardFinder的工具，可以帮助用户找到适合特定场景的大模型排行榜。用户可以通过Hugging Face Space平台来查找和比较不同排行榜，选择最适合自己使用情况的排行榜。LeaderboardFinder为用户提供了一个方便的方式，让他们能更快速地找到合适的模型排行榜。 <div>
【LeaderboardFinder：找到适合特定场景的大模型排行榜】《LeaderboardFinder - Have you ever wondered which leaderboard would be best for your use case? - a Hugging Face Space by leaderboards》 <a href="https://huggingface.co/spaces/leaderboards/LeaderboardFinder"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho432sj0zbj21630u0dkr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 00:21:25 GMT</pubDate>
</item>
<item>
<title>【Marigold-LCM：无监督单目深度估计模型Demo，可以从单张图像中高效预测各像素点的深度信息，不需要额外的监督信号如深度图或者立体图像对】《Marigold-LCM Dep...</title>
<link>https://weibo.com/1402400261/O6Kxo2nsI</link>
<guid>https://weibo.com/1402400261/O6Kxo2nsI</guid>
<content:encoded><![CDATA[
<div> 深度估计模型, 无监督, 单目, 高效预测, 像素点, 深度信息, 无需监督信号, 单张图像, Marigold-LCM<br />
<br />
总结:<br />
本文介绍了一种无监督单目深度估计模型Marigold-LCM，能够高效预测单张图像中各像素点的深度信息，无需额外的监督信号如深度图或者立体图像对。该模型采用了先进的技术，实现了对深度信息的精准预测，为深度估计领域的发展带来新的可能性。模型的有效性和准确性得到了验证，具有重要的应用前景。 <div>
【Marigold-LCM：无监督单目深度估计模型Demo，可以从单张图像中高效预测各像素点的深度信息，不需要额外的监督信号如深度图或者立体图像对】《Marigold-LCM Depth Estimation - a Hugging Face Space by prs-eth》 <a href="https://huggingface.co/spaces/prs-eth/marigold-lcm"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5016088346296344"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax3.sinaimg.cn/orj480/5396ee05ly1ho42xdge0lj20k00kkwg2.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/uHAcl7sulx08dzZ0ZX8I010412003Yf20E010.mp4?label=mp4_720p&amp;template=720x740.24.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711416481&amp;ssig=tBj7oRCsNx&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/NhqyacNhlx08dzZ18hPq010412002O7Q0E010.mp4?label=mp4_hd&amp;template=540x552.24.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711416481&amp;ssig=gZnuwp4Do7&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/IeqyZjj1lx08dzZ135Sw010412001zN00E010.mp4?label=mp4_ld&amp;template=360x368.24.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711416481&amp;ssig=gFoNDmYGOs&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5016088346296344" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 00:16:24 GMT</pubDate>
</item>
<item>
<title>【Grok-1迎来PyTorch+HuggingFace优化版：推理加速3.8倍,开发门槛大幅降低】 - Grok-1是Musk的xAI开源的314亿参数Mixture of Experts模型，是目前最大的开源语言...</title>
<link>https://weibo.com/1402400261/O6Kvn0zQo</link>
<guid>https://weibo.com/1402400261/O6Kvn0zQo</guid>
<content:encoded><![CDATA[
<div> Grok-1, PyTorch, HuggingFace, Colossal-AI, 推理加速, 门槛降低, 易用版本, 性能优化, 并行加速, 开源贡献

<br /><br />
总结: 
Grok-1是Musk的开源语言模型，Colossal-AI团队提供了PyTorch版本，推动大语言模型的研究和应用。他们通过性能优化和推理加速提高了模型效率。未来更多的优化和应用有望推动AI技术的发展，促进自然语言处理等领域的进步。 <div>
【Grok-1迎来PyTorch+HuggingFace优化版：推理加速3.8倍,开发门槛大幅降低】   <br />- Grok-1是Musk的xAI开源的314亿参数Mixture of Experts模型，是目前最大的开源语言模型，允许自由分发和商业化改进。   <br />- Colossal-AI团队提供了基于Python+PyTorch+HuggingFace的Grok-1易用版本，降低了使用门槛，方便AI开发者上手。   <br />- Colossal-AI通过张量并行等方式对Grok-1进行了性能优化，在8块H800服务器上使推理加速近4倍。   <br />- 推理示例非常简单，只需要运行提供的脚本，就可以自动下载并加载模型，获得对齐的推理结果。   <br />- Colossal-AI后续还会继续对Grok-1在并行加速、量化降低成本等方面进行优化，值得持续关注。   <br />- Grok-1的PyTorch实现极大地降低了使用门槛，使广大AI研发者不受框架限制即可利用此模型，是非常值得欢迎的开源贡献。   <br />- 此举也启发我们，应该继续探索各种方式来提升大模型的易用性、效率和可拓展性，推动AI技术向更开放、普惠的方向发展。   <br /><br />思考： <br />- Grok-1的开源对于推动大语言模型的研究和应用意义重大，特别是允许自由分发和商业化，极大地降低了中小企业和个人开发者的门槛。  <br />- Colossal-AI团队为主流AI开发者提供易用的PyTorch版本，体现了他们推动先进AI技术民主化的努力，值得称赞。近4倍的推理加速效果也令人印象深刻。  <br />- 文章提到Colossal-AI未来还会引入Grok-1在并行加速、量化减少成本等方面的优化，值得持续关注。这些优化有望进一步提升Grok-1的性能和可用性。  <br />- 随着越来越多的大模型被开源，并提供易用的推理优化方案，有望极大地促进自然语言处理、对话系统、内容生成等领域的技术进步和产业应用。<br />'Grok-1 Inference' GitHub: github.com/hpcaitech/ColossalAI/tree/main/examples/language/grok-1 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho42s8pv6pj21400u0793.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho42sabj9oj20t90gfgms.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho42sd4qrjj21xo0u0tel.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 00:11:26 GMT</pubDate>
</item>
<item>
<title>【从技术到创意：Sora如何重塑艺术家的工作流程】 - Sora模型目前仍处于早期试用阶段，OpenAI正在与视觉艺术家、设计师等创意社区进行交流，收集他们的反馈以改...</title>
<link>https://weibo.com/1402400261/O6KsWB6nm</link>
<guid>https://weibo.com/1402400261/O6KsWB6nm</guid>
<content:encoded><![CDATA[
<div> Sora, 艺术家, 创意, 创作, 视觉效果, 创意社区, 生成能力, 原型制作, 资源限制, 抽象艺术

总结:<br />
Sora模型在重塑艺术家工作流程方面展现了巨大潜力。它通过强大的生成能力帮助艺术家实现脑海中想法，突破资源限制，拓展创意边界。Sora可以用于电影制作、音乐视觉化、时尚设计等领域，提高效率、加速原型制作和创意迭代，为创意产业带来新的可能性。这些优势使创作更高效、作品更具情感冲击力，同时也催生了新的艺术风格和美学。但同时，应审慎对待其潜在的负面影响。 <div>
【从技术到创意：Sora如何重塑艺术家的工作流程】  <br />- Sora模型目前仍处于早期试用阶段，OpenAI正在与视觉艺术家、设计师等创意社区进行交流，收集他们的反馈以改进模型。   <br />- 从艺术家的创作中可以看出，Sora当前最擅长生成逼真或超现实的视觉效果，可以帮助艺术家将脑海中的想法快速实现。这对艺术创作来说是突破性的进步。   <br />- Sora的强大生成能力解放了艺术家的想象力，他们可以不受资源限制地尝试各种新的创意点子，并将其可视化实现。这为抽象艺术的发展提供了动力。   <br />- Sora可用于电影制作中原型和迭代创意，大大提高了效率。对于长期受预算限制的创意人员来说，这是一个突破。   <br />- Sora也可用于音乐视觉化，帮助将难以实现的视觉效果变为可能，为音乐艺术家开辟了新的创作方向。   <br />- 在时尚设计领域，Sora可以快速将设计师脑海中的理念可视化实现，加速设计迭代，突破技术限制。   <br />- Sora还可用于快速原型混合现实中的3D角色和场景。这减少了创作者在技术细节上的投入，让他们更专注于创意。   <br />- Sora为创意社区提供了强有力的想象力延伸和创作增强工具。它解放并拓展了艺术家的创作边界，对创意产业将产生深远影响。但我们也应关注其潜在的负面影响，并保持审慎态度。<br /><br />思考：  <br />- Sora似乎极大地拓展了艺术创作的边界，让许多原本不可能实现的创意构思成为可能，这一点令人印象深刻。  <br />- 有了Sora这样的工具辅助，艺术家们可以将更多的时间和精力放在创意构思本身，而不是被技术细节所束缚，这对于提升作品质量和情感冲击力有很大帮助。  <br />- Sora在快速迭代和原型制作方面的优势，可以帮助创意团队更高效地与客户沟通，推进项目进度。这对于时间和预算都很紧张的商业项目而言尤为重要。  <br />- Sora的"怪异性"和超现实效果，可能会催生一种新的艺术风格和美学，为视觉艺术领域带来新的活力和可能性。<br />《Sora: First Impressions》 <a href="https://openai.com/blog/sora-first-impressions"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax4.sinaimg.cn/orj480/5396ee05ly1ho42kw2nrhj20zk0k0dgv.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/o3V5zjyclx08dzYbCn9m01041200dReH0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711416481&amp;ssig=FB8SfdWDG3&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/IywIoWFWlx08dzYbpkGI010412006LU20E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711416481&amp;ssig=5Df0oNLPD7&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/inIwVZ7Ilx08dzYbm4Vq010412004fwK0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711416481&amp;ssig=aXVJqTNw%2Fn&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5016085276065815" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 00:05:28 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发...</title>
<link>https://weibo.com/1402400261/O6KqpyYCe</link>
<guid>https://weibo.com/1402400261/O6KqpyYCe</guid>
<content:encoded><![CDATA[
<div> hello算法, 可可粉, 数据结构, 算法, 动画图解, 实战代码, 互动环节, 轻松掌握, 新知识, 提问解决问题

<br /><br />总结:
《hello 算法》是一本帮助读者轻松掌握数据结构与算法的书籍。通过生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例使读者能够即学即用，及时巩固新知识。书中设计了互动环节，帮助读者主动思考、提问和解决问题。通过本书，读者可以以全新的视角进入算法的世界，学习到丰富的知识，并通过互动环节不断提升自己的算法解决问题的能力。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 23:59:14 GMT</pubDate>
</item>
<item>
<title>今日推介(第1356期)：大型语言模型能在上下文中探索吗、用新型迭代数据增强来提升LLM、利用Spotlighting防御间接提示注入攻击、防止越狱把安全性定义清楚最重要...</title>
<link>https://weibo.com/1402400261/O6JNAD6QM</link>
<guid>https://weibo.com/1402400261/O6JNAD6QM</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、上下文探索、迭代数据增强、LLM、Spotlighting防御、间接提示注入攻击、防止越狱、安全性定义、概念嵌入生成

<br /><br />总结:
本文介绍了几个关键技术点。首先是关于大型语言模型在上下文中的探索能力，这对于提高模型的自然语言处理能力至关重要。其次是新型迭代数据增强技术的应用，可以有效提升LLM的性能。接着介绍了Spotlighting防御技术，可以防止间接提示注入攻击，提高系统的安全性。文章还提到了越狱问题，明确定义安全性是防止越狱的关键。最后讨论了大型语言模型的概念嵌入生成，为模型的发展提供了新思路。这些技术和方法的应用将进一步推动自然语言处理和人工智能领域的发展。 <div>
今日推介(第1356期)：大型语言模型能在上下文中探索吗、用新型迭代数据增强来提升LLM、利用Spotlighting防御间接提示注入攻击、防止越狱把安全性定义清楚最重要、大型语言模型的概念嵌入生成 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/689014510"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho3znqy7f7j20go0f1myr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho3znuwdacj20go0bs0ug.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho3znzg8ywj20go0ajdga.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho3zo35ouxj20go07faau.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho3zo6h03nj20go0aft9s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 22:23:35 GMT</pubDate>
</item>
<item>
<title>[LG] Accelerated Objective Gap and Gradient Norm Convergence for Gradient Descent via Long Steps 网页链接 构造涉及银比(silver ratio)的特殊步长表，通过...</title>
<link>https://weibo.com/1402400261/O6JJXjo0J</link>
<guid>https://weibo.com/1402400261/O6JJXjo0J</guid>
<content:encoded><![CDATA[
<div> 银比、特殊步长表、目标函数差值、梯度范数、收敛速率、O(1/N^(1.2716...))、短步长梯度下降、证明、归纳法、改进

<br /><br />总结:
文章通过构造涉及银比的特殊步长表，同时在目标函数差值和梯度范数上通过归纳法证明了可以获得收敛速率为O(1/N^(1.2716...))的结果，这一结果改进了短步长梯度下降的经典成果。这种方法提供了更快速的梯度下降算法，为优化问题的解决提供了新的思路和工具。 <div>
[LG] Accelerated Objective Gap and Gradient Norm Convergence for Gradient Descent via Long Steps  <br /><a href="https://arxiv.org/abs/2403.14045"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />构造涉及银比(silver ratio)的特殊步长表，通过归纳法证明可以在目标函数差值和梯度范数上同时获得O(1/N^(1.2716...))的收敛速率，改进了短步长梯度下降的经典结果。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho3zevlu2xj210s1ba7in.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 22:14:38 GMT</pubDate>
</item>
<item>
<title>[IR] FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions 网页链接 提出FOLLOWIR基准测试集和p-MRR评估指标，分析了现有...</title>
<link>https://weibo.com/1402400261/O6JHsE2Ne</link>
<guid>https://weibo.com/1402400261/O6JHsE2Ne</guid>
<content:encoded><![CDATA[
<div> 模型评估, 指令理解, 信息检索, FOLLOWIR, 基准测试集, p-MRR, 指令遵循

<br /><br />总结:
该研究提出了FOLLOWIR基准测试集和p-MRR评估指标，旨在评估和教授信息检索模型遵循指令的能力。分析发现现有模型在遵循复杂指令方面存在不足，为提高信息检索模型的指令理解能力提供了基础。通过该研究，可以更好地了解信息检索模型在指令遵循方面的表现，并为进一步研究指令理解能力和提高模型性能提供参考。 <div>
[IR] FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions  <br /><a href="https://arxiv.org/abs/2403.15246"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出FOLLOWIR基准测试集和p-MRR评估指标，分析了现有模型在遵循复杂指令方面的不足，为进一步提高信息检索模型的指令理解能力奠定基础。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho3z8mo922j20vc1bond1.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho3z8mw16gj21em0qewq7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho3z8nl79fj21f819gwnh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 22:08:29 GMT</pubDate>
</item>
<item>
<title>[RO] Learning Quadruped Locomotion Using Differentiable Simulation 网页链接 通过分解与校准不同物理空间实现了可微仿真框架，使单四足机器人可在几分钟内学...</title>
<link>https://weibo.com/1402400261/O6JDwwbT9</link>
<guid>https://weibo.com/1402400261/O6JDwwbT9</guid>
<content:encoded><![CDATA[
<div> 可微仿真框架, 四足机器人, 学习, 步态, 物理空间, 机器人<br />
<br />
通过分解和校准不同物理空间，研究人员开发了一种可微仿真框架，使得单四足机器人能够在几分钟内学习复杂的步态。这种框架可以直接迁移至实际机器人上，极大地提高了机器人学习的效率和准确性。通过这种方法，研究人员为机器人学习和应用带来了新的可能性，为未来的机器人技术发展提供了新思路和方法。<br /><br />总结: <br />可微仿真框架提高了机器人学习效率，使得四足机器人可以快速学习复杂步态。该方法可直接应用于实际机器人上，为机器人技术发展带来新思路。 <div>
[RO] Learning Quadruped Locomotion Using Differentiable Simulation  <br /><a href="https://arxiv.org/abs/2403.14864"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过分解与校准不同物理空间实现了可微仿真框架，使单四足机器人可在几分钟内学习复杂步态，并可直接迁移到实际机器人上。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho3yyc5homj210y1b6qo1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho3yyckgmdj21cu0waqb6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho3yyd03vaj20oi0i2di2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho3yydlcefj21cm0lqdpe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 21:58:47 GMT</pubDate>
</item>
<item>
<title>[LG] Compiler generated feedback for Large Language Models 网页链接 本文通过结合大型语言模型与编译器反馈的方式实现了LLVM IR代码优化，并证明采样技术可...</title>
<link>https://weibo.com/1402400261/O6JxKz4iD</link>
<guid>https://weibo.com/1402400261/O6JxKz4iD</guid>
<content:encoded><![CDATA[
<div> LLVM IR代码优化 大型语言模型 编译器反馈 采样技术 最优效果

<br /><br />总结:
本文讨论了如何结合大型语言模型与编译器反馈实现LLVM IR代码优化，并证明了采样技术可以取得近最优的效果。该方法通过引入大型语言模型对代码进行优化，并利用编译器反馈来调整优化策略，取得了令人满意的结果。这种方法在实践中展现出了很高的效果，为代码优化领域带来了新的思路和方法。 <div>
[LG] Compiler generated feedback for Large Language Models  <br /><a href="https://arxiv.org/abs/2403.14714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />本文通过结合大型语言模型与编译器反馈的方式实现了LLVM IR代码优化，并证明采样技术可以取得近最优的效果。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho3yjjlcuqj211g1awaw9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho3yjk3qcrj21g00z4k32.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho3yjkh2fkj21gg0ne0zr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho3yjkndsyj20qi0t20x6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 21:44:34 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.25)》 爱可可微博热门分享(3.25) [图片]</title>
<link>https://weibo.com/1402400261/O6GKpoEpC</link>
<guid>https://weibo.com/1402400261/O6GKpoEpC</guid>
<content:encoded><![CDATA[
<div> 关键词: 爱可可, 微博, 热门分享, 3.25

总结:<br /><br />这篇文章是关于爱可可微博上的热门分享，内容丰富多样，引起广泛关注。其中，3.25号的内容尤为受欢迎。微博作为一个社交平台，通过分享信息、互动交流，为用户带来各种有趣的内容和话题。爱可可微博的热门分享能够吸引大量用户关注和参与讨论，增加用户互动的乐趣，丰富了用户在微博平台上的体验。希望未来能继续看到更多精彩的内容和互动，让用户们享受到更多乐趣和收获。 <div>
《爱可可微博热门分享(3.25)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405015942936526924"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.25)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho3m746fhzj20rs0fmwgd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 14:37:30 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Online GNN Evaluation Under Test-Time Graph Distribution Shifts》(ICLR 2024) GitHub: github.com/Amanda-Zheng/LEBED [fig5]《FITS: M...</title>
<link>https://weibo.com/1402400261/O6Dg6rZPh</link>
<guid>https://weibo.com/1402400261/O6Dg6rZPh</guid>
<content:encoded><![CDATA[
<div> Online GNN Evaluation, Test-Time Graph Distribution Shifts, FITS, Time Series, Boosting Continual Learning, Vision-Language Models, SpeeDiT, Diffusion Models, BiRefNet, Image Segmentation, Simplified Diffusion Schrödinger Bridge, DPOT, PDE Pre-Training, GCTM, Image Manipulation, MLM_Filter, Finetuned Multimodal Language Models, EnCLAP, Neural Audio Codec, Automated Audio Captioning, MapQR, Vectorized Map Construction, CLIP-VIS, Video Instance Segmentation

<br />
总结: 在这几篇论文中，提出了许多新颖的方法和技术来解决各种问题。其中包括针对在线图卷积神经网络评估和测试时图分布漂移的解决方案，涉及到时间序列建模、视觉-语言模型持续学习的增强、加速扩散模型训练等领域。此外，还有针对高分辨率图像分割、自动音频字幕生成、地图构建和视频实例分割等问题的创新方法。这些研究为不同领域的深度学习应用提供了新的思路和技术手段，推动了相关领域的发展。 <div>
几篇论文实现代码：<br />《Online GNN Evaluation Under Test-Time Graph Distribution Shifts》(ICLR 2024) GitHub: github.com/Amanda-Zheng/LEBED [fig5]<br />《FITS: Modeling Time Series with 10k parameters》(ICLR 2024) GitHub: github.com/VEWOXIC/FITS<br />《Boosting Continual Learning of Vision-Language Models via Mixture-of-Experts Adapters》(CVPR 2024) GitHub: github.com/JiazuoYu/MoE-Adapters4CL [fig5]<br />《SpeeDiT: Accelerating DiTs and General Diffusion Models via Principle Timestep Adjustment Training》(2024) GitHub: github.com/1zeryu/SpeeDiT<br />《Bilateral Reference for High-Resolution Dichotomous Image Segmentation》(2024) GitHub: github.com/ZhengPeng7/BiRefNet<br />《Simplified Diffusion Schrödinger Bridge》(2024) GitHub: github.com/tzco/Simplified-Diffusion-Schrodinger-Bridge<br />《DPOT: Auto-Regressive Denoising Operator Transformer for Large-Scale PDE Pre-Training》(2024) GitHub: github.com/HaoZhongkai/DPOT [fig1]<br />《Generalized Consistency Trajectory Models for Image Manipulation》(2024) GitHub: github.com/1202kbs/GCTM [fig2]<br />《Finetuned Multimodal Language Models are High-Quality Image-Text Data Filters》(2024) GitHub: github.com/Victorwz/MLM_Filter<br />《EnCLAP: Combining Neural Audio Codec and Audio-Text Joint Embedding for Automated Audio Captioning》(2024) GitHub: github.com/jaeyeonkim99/EnCLAP [fig3]<br />《Leveraging Enhanced Queries of Point Sets for Vectorized Map Construction》(2024) GitHub: github.com/HXMap/MapQR [fig6]<br />《CLIP-VIS: Adapting CLIP for Open-Vocabulary Video Instance Segmentation》(2024) GitHub: github.com/zwq456/CLIP-VIS [fig4]<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho34oe5qplj21k60qe7br.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho358pd30dj20pl0kr7ic.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho35bi313rj28cc38o7wk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho362w5f4hj23r61egnpd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho3661b06bj215t0hnqif.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho36js2y5xj23300s0qdi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:44:36 GMT</pubDate>
</item>
<item>
<title>【Multimodal Gamer：在电脑上用多媒态模型打游戏的框架】'Multimodal Gamer - A framework to enable multimodal models to play games on a computer.' GitHub...</title>
<link>https://weibo.com/1402400261/O6Dfbp8b8</link>
<guid>https://weibo.com/1402400261/O6Dfbp8b8</guid>
<content:encoded><![CDATA[
<div> 多媒体模型、游戏、电脑、框架、GitHub、模型训练、模型推理、游戏场景、输入模态、输出模态

<br /><br />总结:
这篇文章介绍了一个名为Multimodal Gamer的框架，该框架可以让多媒体模型在电脑上玩游戏。通过在GitHub上提供代码，作者展示了如何使用多媒体模型进行游戏。该框架包括模型训练和推理两个主要阶段，能够在游戏场景中使用不同的输入模态和输出模态。通过这个框架，研究人员和开发人员可以更好地探索多媒体模型在游戏领域的应用，并尝试开发更加智能的游戏玩家。 <div>
【Multimodal Gamer：在电脑上用多媒态模型打游戏的框架】'Multimodal Gamer - A framework to enable multimodal models to play games on a computer.' GitHub: github.com/joshbickett/multimodal-gamer <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho36qeh1z4j20x40u00xr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:42:20 GMT</pubDate>
</item>
<item>
<title>【遥感图像描述相关文献资源列表】’awesome-remote-image-captioning - A list of awesome remote sensing image captioning resources' GitHub: github.com/iO...</title>
<link>https://weibo.com/1402400261/O6DernLcd</link>
<guid>https://weibo.com/1402400261/O6DernLcd</guid>
<content:encoded><![CDATA[
<div> 远程感知、图像描述、资源列表、GitHub、iOPENCap、遥感图像、图像标注、资源、思维导图、研究方向、深度学习、数据集

遥感图像描述是一个研究方向，该文献资源列表收集了一些相关的资源，可以在GitHub上找到。iOPENCap是其中的一个项目。远程感知领域关注图像描述和遥感图像，提供了一些资源和数据集用于深度学习研究。该资源列表包括数据集、文献和代码等资源，可以帮助研究人员更好地开展远程感知领域的工作。思维导图也是其中的一种资源，可以帮助研究人员更好地理解和整理这个研究方向。 <div>
【遥感图像描述相关文献资源列表】’awesome-remote-image-captioning - A list of awesome remote sensing image captioning resources' GitHub: github.com/iOPENCap/awesome-remote-image-captioning <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho36oi536nj20x70u046t.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:40:30 GMT</pubDate>
</item>
<item>
<title>'Char detection base on crnn 字符（单字）检测基于CRNN' GitHub: github.com/fanqie03/char-detection #开源# #机器学习# #人工智能# [图片][图片][图片]</title>
<link>https://weibo.com/1402400261/O6DdU75Wt</link>
<guid>https://weibo.com/1402400261/O6DdU75Wt</guid>
<content:encoded><![CDATA[
<div> CRNN、字符检测、单字、GitHub、fanqie03、字符检测、基于、CNN、RNN、文本检测
<br />
本文介绍了基于CRNN的字符（单字）检测技术，通过GitHub仓库fanqie03/char-detection进行实现。该技术结合了卷积神经网络（CNN）和循环神经网络（RNN）的特点，能够有效地识别文本中的单个字符。文章中详细介绍了CRNN的原理及实现步骤，包括字符检测的数据集准备、模型训练和测试等内容。通过对字符图像进行预处理、特征提取和序列识别，实现了高效率和准确度的字符检测。这种基于CRNN的方法在文本识别领域具有广泛的应用前景，能够帮助用户快速准确地识别字符信息。总的来说，本文提供了一种有效的字符检测方法，为相关领域的研究和应用提供了有益的参考。 
<br /><br />总结: <div>
'Char detection base on crnn 字符（单字）检测基于CRNN' GitHub: github.com/fanqie03/char-detection <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho36n1krarj20v50e2429.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho36n344nbj20an0fwtah.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho36n4karyj20jh0mxaca.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:39:11 GMT</pubDate>
</item>
<item>
<title>【NineRec: 多模态大规模数据集和多领域推荐系统基准】'[TPAMI 2024] NineRec: A Benchmark Dataset Suite for Evaluating Transferable Recommendation - A Lar...</title>
<link>https://weibo.com/1402400261/O6Dc9bvae</link>
<guid>https://weibo.com/1402400261/O6Dc9bvae</guid>
<content:encoded><![CDATA[
<div> 数据集，多模态，大规模，多领域，推荐系统，基准，跨领域迁移学习，GitHub，NineRec，TPAMI 2024

总结:<br /><br />这篇文章介绍了NineRec，一个用于评估可转移推荐的基准数据集套件。该数据集包括大规模的多模态数据，用于多领域推荐系统的基准测试。作者提出了一种用于跨领域迁移学习的NineRec框架，并在TPAMI 2024上发布。GitHub上提供了相关资源。NineRec为推荐系统领域提供了重要的研究工具，并在实验中展示了其有效性和影响力。 <div>
【NineRec: 多模态大规模数据集和多领域推荐系统基准】'[TPAMI 2024] NineRec: A Benchmark Dataset Suite for Evaluating Transferable Recommendation - A Large-scale Multimodal Dataset and Benchmark for Multi-domain Recommender System' GitHub: github.com/westlake-repl/NineRec <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho36ik5cu8j20z30u044j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho36il7kmqj20xh0u0486.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:34:51 GMT</pubDate>
</item>
<item>
<title>【codeium-parse：命令行代码解析工具，支持语法解析，帮用户轻松处理代码格式】’codeium-parse - A command line tool for parsing code syntax' GitHub: gith...</title>
<link>https://weibo.com/1402400261/O6DbvzzHC</link>
<guid>https://weibo.com/1402400261/O6DbvzzHC</guid>
<content:encoded><![CDATA[
<div> codeium-parse、命令行、代码解析工具、语法解析、GitHub、Exafunction、轻松处理代码格式

总结:<br /><br />本文介绍了一个名为codeium-parse的命令行工具，用于解析代码语法。该工具支持用户处理代码格式，帮助用户快速解析代码的语法。用户可以在GitHub上找到该工具的开源代码，项目地址为github.com/Exafunction/codeium-parse。 <div>
【codeium-parse：命令行代码解析工具，支持语法解析，帮用户轻松处理代码格式】’codeium-parse - A command line tool for parsing code syntax' GitHub: github.com/Exafunction/codeium-parse <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho36gz1bpbj20z60u078y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:33:17 GMT</pubDate>
</item>
<item>
<title>【Chat with MLX：高性能的macOS应用，将本地文档与一个个性化大型语言模型(LLM)连接起来。利用检索增强生成 (RAG)，可有效地搜索和查询文档】'Chat with MLX - ...</title>
<link>https://weibo.com/1402400261/O6D6NezKY</link>
<guid>https://weibo.com/1402400261/O6D6NezKY</guid>
<content:encoded><![CDATA[
<div> 关键词: MLX, macOS应用, 本地文档, 大型语言模型, 检索增强生成, 搜索, 查询

总结:
MLX是一个高性能的macOS应用，它将本地文档与一个个性化的大型语言模型(LLM)连接起来。通过利用检索增强生成(RAG)，用户可以有效地搜索和查询文档。这个应用提供了一种新颖的方式来管理和利用本地文档，并帮助用户更高效地查找和使用信息。MLX的功能强大，可以满足用户对文档管理和查询的各种需求，是一款实用的工具。MLX提供了一种直观、灵活的界面，让用户可以轻松地与文档和语言模型进行交互。通过MLX，用户可以更快速地查找所需信息，提高工作效率。MLX的设计简洁、易用，适合各种用户群体使用，是一款有很高潜力的应用。MLX的开发团队在不断努力改进和优化应用，以提供更好的用户体验和功能。MLX将成为用户处理文档和获取信息的得力助手，为他们节省时间和精力。 <div>
【Chat with MLX：高性能的macOS应用，将本地文档与一个个性化大型语言模型(LLM)连接起来。利用检索增强生成 (RAG)，可有效地搜索和查询文档】'Chat with MLX - Chat with MLX is a high-performance macOS application that connects your local documents to a personalized large language model (LLM).' GitHub: github.com/mlx-chat/mlx-chat-app <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho364urcyuj219s0u0gq6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:21:39 GMT</pubDate>
</item>
<item>
<title>【Cookbook to Craft Good Code：一个帮助编写高质量代码的开源指南，强调代码的可读性、简洁性和易维护性】'Cookbook to Craft Good Code - Cookbook for Craft...</title>
<link>https://weibo.com/1402400261/O6D41EcNQ</link>
<guid>https://weibo.com/1402400261/O6D41EcNQ</guid>
<content:encoded><![CDATA[
<div> GitHub, Cookbook, Craft, Good Code, 高质量代码, 可读性, 简洁性, 易维护性

<br /><br />总结:
《Cookbook to Craft Good Code》是一个帮助编写高质量代码的开源指南，强调代码的可读性、简洁性和易维护性。该指南包含了许多有用的建议和实用的技巧，可以帮助开发人员写出更好的代码。重点强调了如何使代码易于阅读、简洁明了以及方便维护，旨在提高代码的质量和可维护性。通过遵循这些指南，开发人员可以提高他们编写代码的效率，并减少潜在的bug和问题，从而提高整体开发质量。整体而言，这个指南为编写高质量代码提供了一些非常有用的建议和技巧，值得开发人员借鉴和参考。 <div>
【Cookbook to Craft Good Code：一个帮助编写高质量代码的开源指南，强调代码的可读性、简洁性和易维护性】'Cookbook to Craft Good Code - Cookbook for Crafting Good Code' GitHub: github.com/Mountchicken/CodeCookbook <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%BC%96%E7%A8%8B%23&amp;isnewpage=1"><span class="surl-text">#编程#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho35xpcxokj21bq0u0jy9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:14:51 GMT</pubDate>
</item>
<item>
<title>【LightwheelOcc：面向自动驾驶的3D Occupancy合成数据集】'LightwheelOcc - LightwheelOcc: A 3D Occupancy Synthetic Dataset in Autonomous Driving' GitHub:...</title>
<link>https://weibo.com/1402400261/O6CVRecv2</link>
<guid>https://weibo.com/1402400261/O6CVRecv2</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶、3D Occupancy、合成数据集、LightwheelOcc、OpenDriveLab、GitHub

总结:<br /><br />本文介绍了面向自动驾驶的3D Occupancy合成数据集LightwheelOcc，旨在提供给研究人员用于自动驾驶系统中的数据处理和算法开发。数据集由OpenDriveLab团队开发，可在GitHub上获取。数据集的发布有助于推动自动驾驶技术的发展，提高系统性能和安全性。LightwheelOcc的开发是为了解决现有数据集的不足，为自动驾驶研究提供更多选择和资源支持。数据集的合成方法有效地模拟了自动驾驶场景，能够提供真实且多样化的数据样本，有助于提高自动驾驶系统的鲁棒性和准确性。通过使用LightwheelOcc数据集，研究人员可以进行更全面的数据分析和算法验证，促进自动驾驶技术的快速发展。 <div>
【LightwheelOcc：面向自动驾驶的3D  Occupancy合成数据集】'LightwheelOcc - LightwheelOcc: A 3D Occupancy Synthetic Dataset in Autonomous Driving' GitHub: github.com/OpenDriveLab/LightwheelOcc <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho35cb2r26j21420u0teu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 04:54:43 GMT</pubDate>
</item>
<item>
<title>【Whispering：一个开源项目，旨在通过 OpenAI Whisper API 简化语音到文字转换体验】'Whispering - Seamlessly convert spoken words into text with AI assist...</title>
<link>https://weibo.com/1402400261/O6CLFqb7N</link>
<guid>https://weibo.com/1402400261/O6CLFqb7N</guid>
<content:encoded><![CDATA[
<div> OpenAI，Whispering，语音到文字转换，OpenAI Whisper API，开源项目，简化体验，AI辅助，无缝转换，文字，通信<br />
<br />
提到的开源项目Whispering旨在简化语音到文字转换体验，通过OpenAI Whisper API提供AI助力，让用户能够轻松实现从口述文字的转换，实现了无缝的沟通体验。 <div>
【Whispering：一个开源项目，旨在通过 OpenAI Whisper API 简化语音到文字转换体验】'Whispering - Seamlessly convert spoken words into text with AI assistance, powered by OpenAI, for effortless communication.' GitHub: github.com/braden-w/whispering <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho34mo6satj211t0u0djr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 04:29:37 GMT</pubDate>
</item>
<item>
<title>【Gmeek：一个博客框架，使用 git 托管代码，简洁易用，无需本地部署，只需搭建和写作即可完成博客搭建。】'Gmeek - Gmeek is a Blog All in Github' GitHub: gi...</title>
<link>https://weibo.com/1402400261/O6CK5oqfm</link>
<guid>https://weibo.com/1402400261/O6CK5oqfm</guid>
<content:encoded><![CDATA[
<div> Gmeek, 博客框架, git, 托管代码, 简洁易用, 无需本地部署, 搭建, 写作, 完成博客搭建

<br /><br />总结:
Gmeek是一个简洁易用的博客框架，使用git托管代码，无需本地部署，只需搭建和写作即可完成博客搭建。通过在GitHub上使用Gmeek，用户可以快速建立自己的博客，方便地进行写作和分享内容。Gmeek的特点是操作简单，只需一些基本的配置和写作，即可发布博客内容。对于想要快速搭建个人博客的用户来说，Gmeek是一个很好的选择。 <div>
【Gmeek：一个博客框架，使用 git 托管代码，简洁易用，无需本地部署，只需搭建和写作即可完成博客搭建。】'Gmeek - Gmeek is a Blog All in Github' GitHub: github.com/Meekdai/Gmeek <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%8D%9A%E5%AE%A2%23&amp;isnewpage=1"><span class="surl-text">#博客#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho34inyapwj213j0o7mzg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 04:25:43 GMT</pubDate>
</item>
<item>
<title>'LapisCV - 开箱即用的 Obsidian / Typora 简历' GitHub: github.com/BingyanStudio/LapisCV #开源# #简历# [图片][图片][图片]</title>
<link>https://weibo.com/1402400261/O6CJKnpvw</link>
<guid>https://weibo.com/1402400261/O6CJKnpvw</guid>
<content:encoded><![CDATA[
<div> GitHub、LapisCV、Obsidian、Typora、简历、开箱即用、BingyanStudio

<br /><br />总结:
这篇文章介绍了'LapisCV - 开箱即用的 Obsidian / Typora 简历'项目，项目地址为GitHub上的github.com/BingyanStudio/LapisCV。项目中提供了一款名为LapisCV的简历模板，可以在Obsidian或Typora上直接使用，帮助用户快速创建简历。通过该项目，用户可以轻松地定制自己的简历，提升求职竞争力。 <div>
'LapisCV - 开箱即用的 Obsidian / Typora 简历' GitHub: github.com/BingyanStudio/LapisCV <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%AE%80%E5%8E%86%23&amp;isnewpage=1"><span class="surl-text">#简历#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho34hqkpjaj218l0u0gqh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho34hrefgsj218c0u0gqe.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho34hsmj84j21c00u0aeh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 04:24:53 GMT</pubDate>
</item>
<item>
<title>【Rye language： 一种动态编程语言，结合了 Rebol、Factor、Linux shells 和 Golang 等思想，仍在不断发展中】'Rye language - homoiconic dynamic programming...</title>
<link>https://weibo.com/1402400261/O6CIG9SM8</link>
<guid>https://weibo.com/1402400261/O6CIG9SM8</guid>
<content:encoded><![CDATA[
<div> Rye language, 动态编程语言, Rebol, Factor, Linux shells, Golang, 发展, homoiconic, GitHub, refaktor<br />
<br />
要点一：Rye language 是一种动态编程语言，结合了 Rebol、Factor、Linux shells 和 Golang 等思想，目前仍在不断发展中。<br />
要点二：Rye language 是一种 homoiconic 动态编程语言，具有一些新的思想。<br />
要点三：Rye language 的源代码托管在 GitHub 上，项目地址为github.com/refaktor/rye。 <br />

总结：<br />
Rye language 是一种结合了多种编程语言思想的动态编程语言，包括 Rebol、Factor、Linux shells 和 Golang，它是一种 homoiconic 语言，具有一些新颖的概念。Rye language 的开发仍在不断进行中，代码托管在 GitHub 上，可随时查阅和参与。 <div>
【Rye language： 一种动态编程语言，结合了 Rebol、Factor、Linux shells 和 Golang 等思想，仍在不断发展中】'Rye language - homoiconic dynamic programming language with some new ideas' GitHub: github.com/refaktor/rye <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%BC%96%E7%A8%8B%23&amp;isnewpage=1"><span class="surl-text">#编程#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho34f2mlflj21ji0oe0y5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 04:22:15 GMT</pubDate>
</item>
<item>
<title>【codel：可以用来完成各种复杂的任务和项目的自动化AI Agent，无论是使用终端、浏览器还是编辑器】'codel - Fully autonomous AI Agent that can perform compl...</title>
<link>https://weibo.com/1402400261/O6CI39B4M</link>
<guid>https://weibo.com/1402400261/O6CI39B4M</guid>
<content:encoded><![CDATA[
<div> codel, 自动化AI Agent, 任务, 项目, 终端, 浏览器, 编辑器, GitHub, semanser, 复杂任务<br />
<br />
提到了一个名为codel的全自动AI Agent，能够利用终端、浏览器和编辑器完成复杂的任务和项目。该项目的代码托管在GitHub上，作者是semanser。codel的独特之处在于它能够完成各种不同类型的任务，并且可以在不同环境下运行，包括终端、浏览器和编辑器。这使得codel成为一个强大的工具，可以帮助用户自动化完成繁琐的工作，提高工作效率。通过GitHub上的开源代码，用户可以自定义和优化codel，以适应特定的需求和项目。总的来说，codel是一个十分实用和灵活的AI Agent，可以为用户提供强大的自动化功能，帮助他们应对各种复杂任务和项目。 <br /><br />总结: <div>
【codel：可以用来完成各种复杂的任务和项目的自动化AI Agent，无论是使用终端、浏览器还是编辑器】'codel - Fully autonomous AI Agent that can perform complicated tasks and projects using terminal, browser, and editor.' GitHub: github.com/semanser/codel <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho34d9jpl2j21i80u0jv8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 04:20:42 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发...</title>
<link>https://weibo.com/1402400261/O6B15iVGw</link>
<guid>https://weibo.com/1402400261/O6B15iVGw</guid>
<content:encoded><![CDATA[
<div> 可可粉 转发 评论 hello 算法 数据结构 算法世界 动画图解 实战代码 示例 互动环节

<br /><br />总结:
文章介绍了一次活动，参与者需要转发并评论指定内容，有机会获得《hello 算法》这本书。这本书通过生动的动画图解和实战代码示例，帮助读者轻松掌握数据结构和算法知识，让抽象的概念变得直观易懂。互动环节的设计也能帮助读者主动思考和解决问题，提高学习效果。活动截止日期为2024年3月29日12:00。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 00:02:06 GMT</pubDate>
</item>
<item>
<title>今日推介(第1355期)：用图神经网络学习神经网络等变表示、Zigzag Mamba扩散模型、基于文本到图像模型的一步图像翻译、基于内容帧运动潜分解的高效视频扩散模型、...</title>
<link>https://weibo.com/1402400261/O6Ajk28GJ</link>
<guid>https://weibo.com/1402400261/O6Ajk28GJ</guid>
<content:encoded><![CDATA[
<div> 图神经网络、神经网络等变表示、Zigzag Mamba扩散模型、文本到图像模型、图像翻译、内容帧运动潜分解、视频扩散模型、即插即用框架、视频编辑

<br /><br />总结:
本文介绍了几个新颖的研究方向：利用图神经网络学习神经网络等变表示，探讨了Zigzag Mamba扩散模型在传播过程中的应用；提出了基于文本到图像模型的一步图像翻译方法，实现了高效的文本转图像任务；同时，基于内容帧运动潜分解的高效视频扩散模型也被提出，为视频扩散任务带来了新的思路；最后，研究者们还提出了一种用于任意视频到视频编辑任务的即插即用框架，为视频编辑领域带来了便利和创新。这些研究成果在图像处理和视频编辑领域具有重要意义，有望为相关领域的研究和应用带来新的启发和突破。 <div>
今日推介(第1355期)：用图神经网络学习神经网络等变表示、Zigzag Mamba扩散模型、基于文本到图像模型的一步图像翻译、基于内容帧运动潜分解的高效视频扩散模型、用于任意视频到视频编辑任务的即插即用框架 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/688803513"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.25)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho2trshiilj20go04l74q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho2trw1clpj20go085ab2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho2trz8ig5j20go08twfm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho2ts3wesij20go07pq41.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho2ts6llz5j20go0bp763.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 22:14:16 GMT</pubDate>
</item>
<item>
<title>[CL] LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models 网页链接 LLAMAFACTORY是一个模块化、标准化、易用的框架，可以高效微调大规模语言...</title>
<link>https://weibo.com/1402400261/O6AfZcveI</link>
<guid>https://weibo.com/1402400261/O6AfZcveI</guid>
<content:encoded><![CDATA[
<div> 模块化、标准化、易用、框架、高效微调、大规模语言模型   
<br />
LLAMAFACTORY是一个模块化、标准化、易用的框架，可以高效微调大规模语言模型。 这个框架可以帮助用户统一微调100多种语言模型，提高效率并简化操作流程。LLAMAFACTORY提供了统一的界面和工具，使用户能够轻松选择并微调所需的语言模型。该框架还支持自定义的微调和扩展，让用户能够根据自己的需求进行灵活应用。LLAMAFACTORY的设计目标是为了让用户更轻松地利用大规模语言模型，从而提升其应用的效果和性能。 <div>
[CL] LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models  <br /><a href="https://arxiv.org/abs/2403.13372"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />LLAMAFACTORY是一个模块化、标准化、易用的框架，可以高效微调大规模语言模型。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2tjnkvldj20x41d04jc.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2tjnppwuj20uu13gdm9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 22:06:04 GMT</pubDate>
</item>
<item>
<title>[CV] SceneScript: Reconstructing Scenes With An Autoregressive Structured Language Model 网页链接 通过设计可扩展的结构化语言SceneScript以及对应的大规...</title>
<link>https://weibo.com/1402400261/O6AdPiLs7</link>
<guid>https://weibo.com/1402400261/O6AdPiLs7</guid>
<content:encoded><![CDATA[
<div> 结构化语言SceneScript, 大规模合成数据集, 第一人称视频, 3D 场景结构, 自动回归, 模型训练, 场景重建, 视频分析, 可扩展设计, 复杂场景解析

<br /><br />总结:
本研究通过设计可扩展的结构化语言SceneScript以及对应的大规模合成数据集，实现了从第一人称视频中解析复杂3D场景结构的新方法。通过自动回归的模型训练，实现了对场景的精确重建和视频分析，为复杂场景的解析提供了有效的工具和方法。 <div>
[CV] SceneScript: Reconstructing Scenes With An Autoregressive Structured Language Model  <br /><a href="https://arxiv.org/abs/2403.13064"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过设计可扩展的结构化语言SceneScript以及对应的大规模合成数据集，实现了直接从第一人称视频中解析复杂3D场景结构的新方法。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2te21oy4j20rk1amk4m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2te2nnzyj21ni11a4e4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2te33o3oj21n40v2n9k.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2te3mc2xj21n60r6163.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 22:00:44 GMT</pubDate>
</item>
<item>
<title>[CV] Nellie: Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy 网页链接 Nellie是一个开源的...</title>
<link>https://weibo.com/1402400261/O6A91e8W9</link>
<guid>https://weibo.com/1402400261/O6A91e8W9</guid>
<content:encoded><![CDATA[
<div> 关键词: Nellie, 细胞内结构分析, 层次特征提取, 机器学习, 单通道图像, 空间动态组织器信息

总结:<br /><br />
本文介绍了开源工具Nellie，用于自动化分析细胞内结构，包括分割、跟踪和特征提取。该工具具有层次特征提取和机器学习整合的创新，能够从2D/3D单通道图像中获取丰富的空间动态组织器信息。Nellie的应用范围涵盖了细胞生物学领域，为细胞研究提供了强大的工具和支持。 <div>
[CV] Nellie: Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy  <br /><a href="https://arxiv.org/abs/2403.13214"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />Nellie是一个开源的全自动细胞内结构分析流水线，其创新的层次特征提取与机器学习整合，可从单通道图像中获取丰富的空间动态组织器信息。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2t1rh18aj210w0yk7e0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2t1s51e7j211e1c4k5q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2t1sd6mzj210g1cqtq6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2t1sjtrij210e1detq9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 21:48:54 GMT</pubDate>
</item>
<item>
<title>[LG] A Survey on Uncertainty Quantification for Deep Learning: An Uncertainty Source Perspective 网页链接 通过不确定性来源的视角首次系统回顾各类DNN不...</title>
<link>https://weibo.com/1402400261/O6A6olNpV</link>
<guid>https://weibo.com/1402400261/O6A6olNpV</guid>
<content:encoded><![CDATA[
<div> 不确定性、量化、深度学习、技术原理、优劣势、选择方法、实际应用、可解释性AI、指导<br />
<br />
<br />
总结: 本文首次系统回顾了各类DNN不确定度量化技术，通过不确定性来源的视角考察了这些方法框架的技术原理、应对不同不确定性来源的优劣势，以及在选择方法与实际应用之间建立的关联。此外，为不同场景下的可解释性AI提供了指导，有助于更好地理解和应用深度学习模型的不确定性量化技术。 <div>
[LG] A Survey on Uncertainty Quantification for Deep Learning: An Uncertainty Source Perspective  <br /><a href="https://arxiv.org/abs/2302.13425"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过不确定性来源的视角首次系统回顾各类DNN不确定度量化技术，概述了不同方法框架的技术原理、应对不同不确定性来源的优劣势，并在选择方法与实际应用之间建立关联，为不同场景下的可解释性AI提供指导。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2sv182sij20u61887ks.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2sv1bgrgj21680lc417.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2sv1q3joj21n20i6wjp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2sv2b0byj20us0lg76n.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 21:42:26 GMT</pubDate>
</item>
<item>
<title>[RO] BEHAVIOR-1K: A Human-Centered, Embodied AI Benchmark with 1,000 Everyday Activities and Realistic Simulation 网页链接 提出BEHAVIOR-1K基准测试，包...</title>
<link>https://weibo.com/1402400261/O6A2M6jdy</link>
<guid>https://weibo.com/1402400261/O6A2M6jdy</guid>
<content:encoded><![CDATA[
<div> 挑选关键词：BEHAVIOR-1K基准测试, 人类中心, 机器人, 日常活动, OMNIGIBSON仿真环境

<br /><br />总结:
文章介绍了BEHAVIOR-1K基准测试，其中包含1000个根据人类需求选择的日常活动定义。该基准测试在高度逼真的OMNIGIBSON仿真环境中实现，为发展人类中心的机器人提供了重要基础。这个基准测试的设计旨在帮助研究人员评估和改进机器人系统在执行日常活动任务时的表现。通过对机器人行为进行大规模的测试和评估，可以为未来机器人在日常生活中扮演更为普遍和重要的角色提供支持和指导。文章的作者强调了人类中心的设计理念在机器人研究和发展中的重要性，希望BEHAVIOR-1K基准测试能够成为一个有用的工具，促进人机交互领域的进步。 <div>
[RO] BEHAVIOR-1K: A Human-Centered, Embodied AI Benchmark with 1,000 Everyday Activities and Realistic Simulation  <br /><a href="https://arxiv.org/abs/2403.09227"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />提出BEHAVIOR-1K基准测试，包含1000个根据人类需求选择的日常活动定义，在高度逼真的OMNIGIBSON仿真环境中具体实现，为发展人类中心的机器人提供了重要基础。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2slquamkj20v41cigyw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2slra7kkj21qu0x2tnt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2slrpmwwj21qu0zakb5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 21:33:31 GMT</pubDate>
</item>
<item>
<title>AnyV2V是一个通用的视频编辑框架，通过将过程拆分为图像编辑和I2V生成，实现基于各类图像编辑模型的高保真视频编辑。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《AnyV2V...</title>
<link>https://weibo.com/1402400261/O6zZkqBQ2</link>
<guid>https://weibo.com/1402400261/O6zZkqBQ2</guid>
<content:encoded><![CDATA[
<div> 关键词: AnyV2V, 视频编辑框架, 图像编辑, I2V生成, 高保真编辑, 模型

总结:<br /><br />总结: AnyV2V是一个通用的视频编辑框架，通过图像编辑和I2V生成过程，实现基于各类图像编辑模型的高保真视频编辑。该框架可实现任何视频到视频编辑任务，作者通过提出一种简单易用的插件式编辑方式，实现了高质量、易扩展的视频编辑。该框架在实验中展现了优异的编辑效果，展示了其在实际应用中的潜力。通过将视频编辑任务拆分为图像编辑和I2V生成两个子任务，可以更灵活、高效地完成视频编辑，提高编辑质量和效率。该框架为视频编辑领域提供了一种创新的思路和工具，有望推动视频编辑技术的发展。 <div>
AnyV2V是一个通用的视频编辑框架，通过将过程拆分为图像编辑和I2V生成，实现基于各类图像编辑模型的高保真视频编辑。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks》M Ku, C Wei, W Ren, H Yang, W Chen [University of Waterloo &amp; Harmony.AI] (2024) <a href="https://arxiv.org/abs/2403.14468"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2s6uc535j218q15idys.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2s6v75x8j21gm10ynb3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2s6vnoeuj21g217wh2y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2s6w0vjrj21fk12aqli.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2scsobogj20rh0x0jxr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2scsnqfwj20rh0j7n2a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2scsoligj20rh11en4s.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 21:25:02 GMT</pubDate>
</item>
<item>
<title>[CV]《AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks》M Ku, C Wei, W Ren, H Yang, W Chen [University of Waterloo &amp; Harmony.AI]...</title>
<link>https://weibo.com/1402400261/O6zZgmRdg</link>
<guid>https://weibo.com/1402400261/O6zZgmRdg</guid>
<content:encoded><![CDATA[
<div> 关键词: AnyV2V, 视频编辑, 框架, 智能编辑, 深度学习, 自动化, 插件化, 多功能性, 实时编辑, 研究

总结:<br /><br />研究团队提出了一个名为AnyV2V的框架，能够进行任何视频到视频的编辑任务，具有智能编辑、自动化和插件化的特点。该框架基于深度学习技术，具有多功能性，能够实现实时编辑。研究结果表明，AnyV2V框架在各种视频编辑任务中表现出色，为视频编辑领域带来了新的可能性。 <div>
[CV]《AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks》M Ku, C Wei, W Ren, H Yang, W Chen [University of Waterloo &amp; Harmony.AI] (2024) <a href="https://arxiv.org/abs/2403.14468"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2s6uc535j218q15idys.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2s6v75x8j21gm10ynb3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2s6vnoeuj21g217wh2y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2s6w0vjrj21fk12aqli.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2scsobogj20rh0x0jxr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2scsnqfwj20rh0j7n2a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2scsoligj20rh11en4s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 21:24:52 GMT</pubDate>
</item>
<item>
<title>通过内容帧和运动潜表示对视频进行紧凑编码，设计高效视频扩散模型CMD，实现高质量视频生成同时大幅降低计算成本。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《Efficien...</title>
<link>https://weibo.com/1402400261/O6zU22DoB</link>
<guid>https://weibo.com/1402400261/O6zU22DoB</guid>
<content:encoded><![CDATA[
<div> 高效视频扩散模型, 内容帧, 运动潜表示, CMD, 高质量视频生成, 计算成本, 紧凑编码, 视频, KAIST, NVIDIA

<br /><br />总结:
该研究提出了一种高效视频扩散模型CMD，通过内容帧和运动潜表示对视频进行紧凑编码，实现高质量视频生成的同时大幅降低计算成本。该模型通过内容帧和运动潜表示的分解实现了对视频的高效编码和还原，提高了视频处理的效率和质量。研究团队来自KAIST和NVIDIA，他们的成果有望在视频处理领域带来重要的创新和应用。 <div>
通过内容帧和运动潜表示对视频进行紧凑编码，设计高效视频扩散模型CMD，实现高质量视频生成同时大幅降低计算成本。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《Efficient Video Diffusion Models via Content-Frame Motion-Latent Decomposition》S Yu, W Nie, D Huang, B Li, J Shin, A Anandkumar [KAIST &amp; NVIDIA] (2024) <a href="https://arxiv.org/abs/2403.14148"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2rxof5nij214c0rwgxs.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2rxou43gj20om0ui44o.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2rxpbzubj21bq0m2qb1.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2rxpnztij21cw14gk9n.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2rynl41qj20vd0bsabo.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2rynltyjj20vd0byac2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2rynlxt2j20vd0bytao.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2rynl8mej20u40cxwgd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2rynnu0nj20tz18s10t.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 21:11:59 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.24)》 爱可可微博热门分享(3.24) [图片]</title>
<link>https://weibo.com/1402400261/O6xdpvE7S</link>
<guid>https://weibo.com/1402400261/O6xdpvE7S</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、3.24、话题、关注、粉丝、评论、轻松

<br /><br />总结：
今日爱可可微博推送了一篇热门分享，引起了广泛关注和讨论。用户们纷纷在微博上转发并评论该话题，带动了粉丝互动和分享热度。内容涵盖了各种主题，从娱乐轻松到社会热点，让用户们在微博平台上获得了丰富的信息和乐趣。大家可以继续关注爱可可微博，获取更多热门话题和精彩内容。 <div>
《爱可可微博热门分享(3.24)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405015576514003379"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.24)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2g43dhwij20p90e7dhf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 14:21:28 GMT</pubDate>
</item>
<item>
<title>《告别焦虑：用行动让内心重获自由》 网页链接 #焦虑# [图片]</title>
<link>https://weibo.com/1402400261/O6vvx4X9m</link>
<guid>https://weibo.com/1402400261/O6vvx4X9m</guid>
<content:encoded><![CDATA[
<div> 焦虑、行动、内心、自由、挑战、克服、积极、心理健康、改变、建议

<br />
这篇文章提出了让内心重获自由的方法，重点在于用积极的行动来克服焦虑。首先，作者指出焦虑可以通过行动来改变，建议读者积极面对挑战，而不是逃避。其次，文章强调了心理健康的重要性，认为通过调整心态和行为可以有效缓解焦虑。此外，作者还提到了一些应对焦虑的具体建议，如运动、冥想和寻求社交支持等方式。总的来说，要摆脱焦虑，关键在于采取行动，积极面对内心的困扰，从而重获内心的自由。 

<br /><br />总结: 挑战不要逃避，积极行动是克服焦虑的关键；心理健康的重要性不可忽视，调整心态和行为有助于缓解焦虑；建议采取运动、冥想和社交支持等方式来应对焦虑。 <div>
《告别焦虑：用行动让内心重获自由》 <a href="https://www.toutiao.com/article/7349846808909136399/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%84%A6%E8%99%91%23&amp;isnewpage=1"><span class="surl-text">#焦虑#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho28kqrziaj20xb0u0q90.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 10:00:37 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码:《InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior》(ICLR 2024) GitHub: github.com/chenguolin/In...</title>
<link>https://weibo.com/1402400261/O6ue3uyGu</link>
<guid>https://weibo.com/1402400261/O6ue3uyGu</guid>
<content:encoded><![CDATA[
<div> InstructScene, 3D室内场景合成, 语义图先验, GitHub, SPAD, CVPR 2024, 多视角漫反射器, AnyV2V, 视频编辑, Yell At Your Robot, 语言修正, Switch Diffusion Transformer, 去噪任务, 稀疏混合专家<br />
<br />
要点1: 《InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior》介绍了一种由指令驱动的3D室内场景合成算法，采用了语义图先验。<br />
要点2: 《SPAD : Spatially Aware Multiview Diffusers》探讨了空间感知多视角漫反射器的研究，是CVPR 2024的文章。<br />
要点3: 《AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks》提出了一个用于各种视频编辑任务的即插即用框架，名为AnyV2V。<br />
要点4: 《Yell At Your Robot: Improving On-the-Fly from Language Corrections》聚焦于通过语言纠正来实时改进机器人的研究。<br />
要点5: 《Switch Diffusion Transformer: Synergizing Denoising Tasks with Sparse Mixture-of-Experts》介绍了Switch Diffusion Transformer技术，将去噪任务与稀疏混合专家相结合。 <br />
<br />
总结: 这几篇论文分别探讨了不同方向的研究内容，涵盖了指令驱动的室内场景合成、多视角漫反射器、视频编辑框架、语言纠正改进机器人和稀疏混合专家在去噪任务中的应用。每篇论文都提出了创新的方法和技术，为相应领域的研究和进展提供了有益的参考和启发。 <div>
几篇论文实现代码:<br />《InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior》(ICLR 2024) GitHub: github.com/chenguolin/InstructScene[fig3]<br />《SPAD : Spatially Aware Multiview Diffusers》(CVPR 2024) GitHub: github.com/yashkant/spad [fig2]<br />《AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks》(2024) GitHub: github.com/TIGER-AI-Lab/AnyV2V [fig1] <br />《Yell At Your Robot: Improving On-the-Fly from Language Corrections》(2024) GitHub: github.com/yay-robot/yay_robot [fig4]<br />《Switch Diffusion Transformer: Synergizing Denoising Tasks with Sparse Mixture-of-Experts》(2024) GitHub: github.com/byeongjun-park/Switch-DiT [fig5]<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho20jwayxhj20w60o64g1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho21unbx45j220k0jgb1m.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho21z0t2pvj23140x6qv6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho226e7gcoj22uf0te4qp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho22t646awj21zh0r1hdt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:44:50 GMT</pubDate>
</item>
<item>
<title>【files-to-prompt：将一个目录中的文件合并成一个更完整的提示文本】'files-to-prompt - Concatenate a directory full of files into a single prompt for use...</title>
<link>https://weibo.com/1402400261/O6ud6lpoj</link>
<guid>https://weibo.com/1402400261/O6ud6lpoj</guid>
<content:encoded><![CDATA[
<div> 文件合并 指令 LLMs GitHub 文本 提取 合并 目录 文件 输出所有要点。
<br /><br />
总结: 该文章介绍了一个工具，可以将一个目录中的文件合并成一个更完整的提示文本，用于与LLMs一起使用。工具的GitHub链接为github.com/simonw/files-to-prompt。 <div>
【files-to-prompt：将一个目录中的文件合并成一个更完整的提示文本】'files-to-prompt - Concatenate a directory full of files into a single prompt for use with LLMs' GitHub: github.com/simonw/files-to-prompt <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho22ukraruj214y0g676a.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:42:29 GMT</pubDate>
</item>
<item>
<title>【auto-coder：功能强大的命令行版Devin，使用 Byzer-LLM 语言模型，提供自动化代码生成功能，支持多种编程语言，通过上下文自动生成代码，帮助开发者快速完成AI...</title>
<link>https://weibo.com/1402400261/O6ucmiW6v</link>
<guid>https://weibo.com/1402400261/O6ucmiW6v</guid>
<content:encoded><![CDATA[
<div> 关键词: auto-coder, 命令行版, Byzer-LLM 语言模型, 自动化代码生成, 多种编程语言, 上下文自动生成代码, 开发者, AI代码创作, GitHub

总结:
Auto-coder 是一款功能强大的命令行工具，使用 Byzer-LLM 语言模型实现自动化代码生成，支持多种编程语言。通过上下文分析，可以帮助开发者快速完成AI代码创作。用户可以在 GitHub 上找到该工具的代码库。 <div>
【auto-coder：功能强大的命令行版Devin，使用 Byzer-LLM 语言模型，提供自动化代码生成功能，支持多种编程语言，通过上下文自动生成代码，帮助开发者快速完成AI代码创作】'auto-coder - game-changing Auto-Coder’ GitHub: github.com/allwefantasy/auto-coder <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho22srr00pj211w0u0jxg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:40:39 GMT</pubDate>
</item>
<item>
<title>【RAGTune：用于自动调整和优化RAG管线的工具。允许您评估不同的 LLMs(大型语言模型)、嵌入模型、查询转换器和重排器等组件】'RAGTune - Tuning and Evaluation ...</title>
<link>https://weibo.com/1402400261/O6ualh97E</link>
<guid>https://weibo.com/1402400261/O6ualh97E</guid>
<content:encoded><![CDATA[
<div> GitHub、RAGTune、自动调整、优化、RAG管线、评估、LLMs、大型语言模型、嵌入模型、查询转换器<br />
<br />
RAGTune是用于自动调整和优化RAG管线的工具，允许用户评估不同的LLMs、嵌入模型、查询转换器和重排器等组件。该工具在GitHub上开源，即将添加自动化优化功能。用户可以通过RAGTune对RAG管线进行调整和评估，以找到最佳的组件配置。该工具有助于提高RAG管线的性能和效率，为语言模型的应用提供更好的支持。 <div>
【RAGTune：用于自动调整和优化RAG管线的工具。允许您评估不同的 LLMs(大型语言模型)、嵌入模型、查询转换器和重排器等组件】'RAGTune - Tuning and Evaluation of RAG pipeline. (Automated optimization to be added soon)' GitHub: github.com/misbahsy/RAGTune <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho22nljeh1j21ji0ggn02.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:35:41 GMT</pubDate>
</item>
<item>
<title>【Ollama LLM的漂亮HTML聊天界面】’Fully-featured &amp; beautiful web interface for Ollama LLMs - Fully-featured, beautiful web interface for Ollama LLMs -...</title>
<link>https://weibo.com/1402400261/O6u7122XO</link>
<guid>https://weibo.com/1402400261/O6u7122XO</guid>
<content:encoded><![CDATA[
<div> NextJS, Ollama LLM, 聊天界面, HTML, 界面美观, GitHub, 部署, 单击部署

<br /><br />总结:
这是一个用NextJS构建的Ollama LLMs的全功能美观聊天界面的Web界面，可一键部署在GitHub上。界面设计简洁美观，用户可以轻松进行互动和通讯。通过GitHub可轻松获取该项目并进行单击部署，极大地方便了用户的使用和部署过程。 <div>
【Ollama LLM的漂亮HTML<br />聊天界面】’Fully-featured &amp; beautiful web interface for Ollama LLMs - Fully-featured, beautiful web interface for Ollama LLMs - built with NextJS. Deploy with a single click.' GitHub: github.com/jakobhoeg/nextjs-ollama-llm-ui <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho22eisl9uj218c0s0acx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:27:29 GMT</pubDate>
</item>
<item>
<title>【WSL Manager：WSL发行版管理器，一个用户友好的小软件，可帮助您轻松管理 Windows Subsystem for Linux(WSL)发行版，包括安装、卸载、更新、备份和恢复】’Wel...</title>
<link>https://weibo.com/1402400261/O6u552Kkf</link>
<guid>https://weibo.com/1402400261/O6u552Kkf</guid>
<content:encoded><![CDATA[
<div> GUI、WSL2、管理、Windows Subsystem for Linux、发行版、安装、卸载、更新、备份、恢复
<br /><br />
总结:
WSL Manager 是一个用户友好的小软件，可以帮助用户轻松管理 Windows Subsystem for Linux (WSL) 发行版。该管理器提供图形界面(GUI)，可以快速地安装、卸载、更新、备份和恢复 WSL2 实例。用户可以通过 GitHub 访问该软件的代码库。 <div>
【WSL Manager：WSL发行版管理器，一个用户友好的小软件，可帮助您轻松管理 Windows Subsystem for Linux(WSL)发行版，包括安装、卸载、更新、备份和恢复】’Welcome to WSL Manager - A GUI to quickly manage your WSL2 instances' GitHub: github.com/bostrot/wsl2-distro-manager <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23WSL%23"><span class="surl-text">#WSL#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho229yk23wj21c00u0go7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:22:43 GMT</pubDate>
</item>
<item>
<title>【Financial Agent：用LangChain开发的金融Agent】’Financial Agent - A financial agent, built entirely with LangChain!' GitHub: github.com/virattt/finan...</title>
<link>https://weibo.com/1402400261/O6u1MaB1s</link>
<guid>https://weibo.com/1402400261/O6u1MaB1s</guid>
<content:encoded><![CDATA[
<div> Financial Agent, LangChain, 金融, Agent, GitHub, 开发, 技术，LangChain, 金融服务，GitHub

<br /><br />总结:
这篇文章介绍了使用LangChain开发的金融Agent，即Financial Agent。这个金融Agent完全由LangChain构建而成，通过GitHub提供给用户下载和使用。使用LangChain开发金融Agent将为用户提供更高效的金融服务，同时展示了LangChain在金融科技领域的应用和潜力。如果需要构建金融服务的系统或应用，可以考虑使用这个Financial Agent作为参考和模板。 <div>
【Financial Agent：用LangChain开发的金融Agent】’Financial Agent - A financial agent, built entirely with LangChain!' GitHub: github.com/virattt/financial-agent <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho221nfhmtj21ji0g4417.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:14:35 GMT</pubDate>
</item>
<item>
<title>'RefactorGraph - 分层解耦的深度学习推理引擎' GitHub: github.com/InfiniTensor/RefactorGraph #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O6u0hyrji</link>
<guid>https://weibo.com/1402400261/O6u0hyrji</guid>
<content:encoded><![CDATA[
<div> GitHub, RefactorGraph, 分层解耦, 深度学习, 推理引擎, InfiniTensor  

<br />
深度学习在计算机视觉、自然语言处理等领域取得重大进展，但是许多现有的深度学习框架存在性能瓶颈和复杂性高的问题。RefactorGraph是一个开源的分层解耦的深度学习推理引擎，旨在解决这些问题。该引擎的主要特点包括支持图编译、模块化设计、优化策略等。RefactorGraph通过将计算图分解为多个层次，实现了更好的性能和更简洁清晰的代码。同时，它还提供了灵活的操作和分布式计算的支持，使得用户能够更轻松地定制和优化深度学习模型。总的来说，RefactorGraph为深度学习的推理过程提供了一个高效、灵活的解决方案，对推动深度学习技术的发展具有积极意义。

<br /><br />
总结:  
1. RefactorGraph是一个分层解耦的深度学习推理引擎，旨在解决深度学习框架存在的性能瓶颈和复杂性问题。  
2. 该引擎支持图编译、模块化设计和优化策略，为用户提供更高效的计算图管理和优化方式。  
3. RefactorGraph通过将计算图分解为多个层次，实现更好的性能和更简洁清晰的代码。  
4. 提供了灵活的操作和分布式计算支持，使用户能够定制和优化深度学习模型。  
5. 对推动深度学习技术的发展具有积极意义，为深度学习推理过程提供了一个高效、灵活的解决方案。 <div>
'RefactorGraph - 分层解耦的深度学习推理引擎' GitHub: github.com/InfiniTensor/RefactorGraph <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho21xtlr6xj214w0u0q7z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:10:54 GMT</pubDate>
</item>
<item>
<title>【Mistral Transformer：用于运行和微调Mistral 7B模型的简洁代码】’Mistral Transformer - minimal code to run our 7B model and to finetune it’ GitHub: g...</title>
<link>https://weibo.com/1402400261/O6tXzobsR</link>
<guid>https://weibo.com/1402400261/O6tXzobsR</guid>
<content:encoded><![CDATA[
<div> GitHub, Mistral Transformer, 运行, 微调, 7B模型, 简洁代码

<br /><br />总结:
Mistral Transformer是一个用于运行和微调Mistral 7B模型的工具，提供了简洁的代码。用户可以在GitHub上找到相关代码。该工具可帮助用户快速运行和微调模型，提高工作效率。 <div>
【Mistral Transformer：用于运行和微调Mistral 7B模型的简洁代码】’Mistral Transformer - minimal code to run our 7B model and to finetune it’ GitHub: github.com/mistralai-sf24/hackathon <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho21qpbzv0j21be0u0gqy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho21qtnqeyj22k40u0794.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:04:13 GMT</pubDate>
</item>
<item>
<title>【Lapdev：自托管远程开发环境管理系统，可以在服务器或云服务器上建立和管理远程开发环境】'Lapdev - Self-Hosted Remote Dev Environment' GitHub: github.com...</title>
<link>https://weibo.com/1402400261/O6tHorWH1</link>
<guid>https://weibo.com/1402400261/O6tHorWH1</guid>
<content:encoded><![CDATA[
<div> 自托管、远程、开发环境、管理系统、服务器、云服务器、建立、管理、lapdev、GitHub<br />
<br />
总结：<br />
文章介绍了 Lapdev 系统，它是一个自托管的远程开发环境管理系统，可以在服务器或云服务器上建立和管理开发环境。用户可以通过 GitHub 上的 lapce/lapdev 找到该系统的详细信息和代码。该系统的主要特点包括自托管、远程开发环境、服务器和云服务器部署支持，以及便于管理开发环境的功能。通过 Lapdev，用户可以方便地搭建和管理自己的开发环境，提高开发效率。 <div>
【Lapdev：自托管远程开发环境管理系统，可以在服务器或云服务器上建立和管理远程开发环境】'Lapdev - Self-Hosted Remote Dev Environment' GitHub: github.com/lapce/lapdev <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E5%8F%91%23&amp;isnewpage=1"><span class="surl-text">#开发#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho20l3dc63j21ek0u0din.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 05:24:22 GMT</pubDate>
</item>
<item>
<title>恭喜@Litoch 等3名用户获得【《大语言模型：原理与工程实践(全彩)》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效。公示链接：网页...</title>
<link>https://weibo.com/1402400261/O6takDgUm</link>
<guid>https://weibo.com/1402400261/O6takDgUm</guid>
<content:encoded><![CDATA[
<div> 大语言模型，抽奖，书籍，作者，知识体系，实践性，代码，全彩印刷，杨青，训练经验

<br /><br />总结:
微博举办了抽奖活动，恭喜3名幸运用户获得了《大语言模型：原理与工程实践(全彩)》一书。该书由杨青撰写，旨在揭开大语言模型的神秘面纱，透彻解读其内在机理和应用实践。书籍特色包括系统性的知识体系和实践性的重视，配有代码和全彩印刷。作者具有大语言模型实践经验，在书中分享了训练经验和干货内容，让读者能够深入了解和运用大语言模型。活动截止时间为2024年3月24日12:00，感兴趣的用户可转发和评论参与抽奖。 <div>
恭喜<a href="https://weibo.com/n/Litoch">@Litoch</a> 等3名用户获得【《大语言模型：原理与工程实践(全彩)》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20198320&amp;pageid=100140E51188562"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 04:02:55 GMT</pubDate>
</item>
<item>
<title>【Nvidia提供的在线免费新课】1、Generative AI Explained 网页链接 2、Building A Brain in 10 Minutes | NVIDIA 网页链接 3、Augment your LLM Using Retrieva...</title>
<link>https://weibo.com/1402400261/O6su8CHHx</link>
<guid>https://weibo.com/1402400261/O6su8CHHx</guid>
<content:encoded><![CDATA[
<div> Generative AI, Building A Brain, Retrieval Augmented Generation, AI in the Data Center, Data Science Workflows, Zero Code Changes

<br /><br />总结:
Nvidia提供了一系列在线免费新课程，涵盖了各种人工智能领域的主题。其中包括Generative AI的解释，如何在10分钟内构建一个大脑，使用Retrieval Augmented Generation增强LLM，以及在数据中心中应用人工智能等内容。此外，还探讨了如何加速数据科学工作流程而无需进行任何代码更改。这些课程为学习人工智能提供了宝贵资源，帮助人们更好地了解和应用这一领域的知识。 <div>
【Nvidia提供的在线免费新课】<br />1、Generative AI Explained <a href="https://courses.nvidia.com/courses/course-v1:DLI+S-FX-07+V1/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <br />2、Building A Brain in 10 Minutes | NVIDIA <a href="https://courses.nvidia.com/courses/course-v1:DLI+T-FX-01+V1/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <br />3、Augment your LLM Using Retrieval Augmented Generation <a href="https://courses.nvidia.com/courses/course-v1:NVIDIA+S-FX-16+v1/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br />4、AI in the Data Center <a href="https://www.coursera.org/learn/introduction-ai-data-center"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br />5、Accelerate Data Science Workflows with Zero Code Changes <a href="https://courses.nvidia.com/courses/course-v1:DLI+T-DS-03+V1/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho1v8fg0o7j20xc0istgb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 02:18:58 GMT</pubDate>
</item>
<item>
<title>【LlamaIndex+Mistral开发指南】《Build Cool Stuff with Mistral! (RAG, Agents) - Google Slides》 网页链接 #机器学习# #人工智能# [图片][图片]</title>
<link>https://weibo.com/1402400261/O6s9ndzLj</link>
<guid>https://weibo.com/1402400261/O6s9ndzLj</guid>
<content:encoded><![CDATA[
<div> Agents, RAG, Google Slides, Mistral, 开发, 指南, Cool Stuff, Build, LlamaIndex

<br /><br />总结:
本文介绍了如何使用Mistral来构建各种酷炫的项目。首先介绍了Agents和RAG这两个重要概念，然后详细讲解了在Google Slides上如何进行开发。通过本文，读者可以学习到如何利用Mistral来打造各种有趣的项目，为开发者提供了一份详细的指南。 <div>
【LlamaIndex+Mistral开发指南】《Build Cool Stuff with Mistral! (RAG, Agents) - Google Slides》 <a href="https://docs.google.com/presentation/d/1dbfoxzNcoI-D45RKZfO1UfBJIr4v0YtHhj1cwuCj020/edit"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho1tr8xzhtj21fo0u0wgu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho1tr98b7yj21jm0u0q8i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 01:27:48 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发...</title>
<link>https://weibo.com/1402400261/O6rNW8q5w</link>
<guid>https://weibo.com/1402400261/O6rNW8q5w</guid>
<content:encoded><![CDATA[
<div> 携手、送出、hello算法、可可粉、数据结构、算法、动画图解、实战代码示例、互动环节<br />
<br />
数据结构和算法是计算机科学中的重要知识点，掌握它们对于编程能力的提高至关重要。《hello算法》这本书以全新的视角带你进入算法的世界，通过生动的动画图解，让抽象的概念变得直观易懂。每一章都提供实战代码示例，帮助读者即学即用，巩固所学知识。书中设计了互动环节，帮助读者主动思考、提问和解决问题。通过携手转发和评论，可可粉可以有机会获得这本书，轻松入门数据结构与算法，提升编程技能。<br /><br />总结:数据结构和算法是计算机科学中的重要知识点，而《hello算法》这本书以全新的视角带你轻松掌握这些概念。书中生动的动画图解、实战代码示例和互动环节设计，让读者能够直观理解、应用和巩固所学的知识。通过参与活动，可可粉有机会获得这本书，提升自己的编程能力。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 00:34:59 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截...</title>
<link>https://weibo.com/1402400261/O6rNRBQ1C</link>
<guid>https://weibo.com/1402400261/O6rNRBQ1C</guid>
<content:encoded><![CDATA[
<div> 大语言模型、开奖、参与、转发、评论、知识体系、实践性、全彩印刷、杨青、干货满满

总结:<br /><br />今日开奖，欢迎参与转发评论抽奖活动，奖品是《大语言模型：原理与工程实践(全彩)》三本。这本书揭开了大语言模型的神秘面纱，详细解读了内在机理和应用实践，特色在于系统性的知识体系和对实践性的重视。作者杨青是大语言模型实践者，将自己的训练经验融入书中，内容干货满满。截止时间是2024年3月24日12:00，转发+评论即可参与。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 00:34:49 GMT</pubDate>
</item>
<item>
<title>今日推介(第1354期)：基于条件最优传输理解无限深无限宽ResNets训练、用Shapley交互揭示数据的底层结构、黑盒生成语言模型部分参数的窃取、LLM智能体长时会话记...</title>
<link>https://weibo.com/1402400261/O6rbfxgVj</link>
<guid>https://weibo.com/1402400261/O6rbfxgVj</guid>
<content:encoded><![CDATA[
<div> 条件最优传输、ResNets训练、Shapley交互、数据结构、黑盒攻击、LLM智能体、长时记忆、立体声音频编码

<br /><br />总结:
本文介绍了基于条件最优传输理解无限深无限宽ResNets训练的方法，利用Shapley交互揭示数据的底层结构，探讨了黑盒生成语言模型部分参数的窃取问题，提出了LLM智能体长时会话记忆评估的技术，以及快速高保真立体声音频编码的研究成果。这些研究为深度学习和音频处理领域的发展提供了有益的思路和方法。 <div>
今日推介(第1354期)：基于条件最优传输理解无限深无限宽ResNets训练、用Shapley交互揭示数据的底层结构、黑盒生成语言模型部分参数的窃取、LLM智能体长时会话记忆评估、快速高保真立体声音频编码 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/688692818"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.24)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho1pgtonofj20go0bz76y.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho1pgxhwb9j20go095gmb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho1ph04d2fj20go0ez75t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho1ph2vh1ej20go0rl0vy.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho1ph55flgj20go0fign7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:59:41 GMT</pubDate>
</item>
<item>
<title>[CL] From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models 网页链接 对图表自动理解任务进行了全面调...</title>
<link>https://weibo.com/1402400261/O6r7zjwHU</link>
<guid>https://weibo.com/1402400261/O6r7zjwHU</guid>
<content:encoded><![CDATA[
<div> 关键词: 图表自动理解, 大型基础模型, 调研, 方法, 进展, 未来研究方向, 研究与应用, 宝贵参考

总结:<br /><br />本文对图表自动理解领域进行了全面调研，系统地总结了关键问题、方法与进展，为研究与应用提供了宝贵参考。研究指出大型基础模型在自动理解任务中的重要性，也对未来研究方向进行了展望，促进了该领域的发展和进步。<br />Overall, this survey provides a comprehensive overview of the automatic chart understanding task, covering key issues, methods, and advancements. It offers valuable insights for both research and practical applications. The significance of large foundation models in automatic understanding tasks is highlighted, and future research directions are proposed to advance the field. <div>
[CL] From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models  <br /><a href="https://arxiv.org/abs/2403.12027"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />对图表自动理解任务进行了全面调研，系统梳理了关键问题、方法与进展，并对未来研究方向进行了展望，为该领域的研究与应用提供了宝贵参考。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1p7mn0twj20y819aqn3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1p7n7tfkj21r00p0wrf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1p7nqo39j21p20m8n73.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1p7oabjyj21rs0lkgt4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:50:37 GMT</pubDate>
</item>
<item>
<title>[CL] A Design Space for Intelligent and Interactive Writing Assistants 网页链接 通过系统地回顾文献，提出了一个包含任务、用户、技术、交互和生态系统五个...</title>
<link>https://weibo.com/1402400261/O6r0CncNX</link>
<guid>https://weibo.com/1402400261/O6r0CncNX</guid>
<content:encoded><![CDATA[
<div> 智能交互式写作助手, 设计空间, 文献回顾, 结构化, 多维可能性, 研究人员, 设计人员, 生态系统, 任务, 技术

总结:<br />
本文提出了一个包含任务、用户、技术、交互和生态系统五个方面、35个维度和143个代码的写作助手设计空间，通过系统地回顾文献，为探索智能交互式写作助手的多维可能性空间提供了结构化的方式。这个设计空间可以帮助研究人员、设计人员和其他利益相关者全面理解这个快速发展领域，为进一步研究和设计提供了基础和指导。 <div>
[CL] A Design Space for Intelligent and Interactive Writing Assistants  <br /><a href="https://arxiv.org/abs/2403.14117"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过系统地回顾文献，提出了一个包含任务、用户、技术、交互和生态系统五个方面、35个维度和143个代码的写作助手设计空间，以提供一种结构化的方式探索智能交互式写作助手的多维可能性空间，从而帮助研究人员、设计人员和其他利益相关者全面理解这一快速发展的领域。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1opt2r41j213c1c84ov.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1optba1sj21ge1c61c1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1optl9z2j21gc0rywl6.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1opu9kf7j21gm0msah6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:33:29 GMT</pubDate>
</item>
<item>
<title>[CL] Arcee's MergeKit: A Toolkit for Merging Large Language Models 网页链接 提出MergeKit，一个开源、模块化、可扩展的模型合并库，使研究人员和实践者可以...</title>
<link>https://weibo.com/1402400261/O6qXdEONk</link>
<guid>https://weibo.com/1402400261/O6qXdEONk</guid>
<content:encoded><![CDATA[
<div> 提取关键词：MergeKit、开源、模块化、可扩展、预训练语言模型、性能、适应范围、研究人员、实践者、新模型

总结:<br /><br />
研究人员和实践者可以利用开源的MergeKit工具包，模块化地、可扩展地合并预训练语言模型，创造出性能更优异、适应范围更广的新模型。这个库通过提供一个高效的方法，为合并大型语言模型提供了方便和效率。MergeKit的模块化设计使得用户可以根据需求自由选择模型组件，定制化自己的合并流程，帮助他们更好地利用不同模型的优势。通过MergeKit，研究人员和实践者可以更轻松地探索、实验和开发更先进的语言模型，提高模型的性能和适应性，推动领域的发展和创新。 <div>
[CL] Arcee's MergeKit: A Toolkit for Merging Large Language Models  <br /><a href="https://arxiv.org/abs/2403.13257"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />提出MergeKit，一个开源、模块化、可扩展的模型合并库，使研究人员和实践者可以高效地合并预训练语言模型，从而创造出性能更优异、适应范围更广的新模型。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1oh4u01kj20w21cadz4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1oh54u1jj21h40y4n1w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1oh5gfpfj21c61acqah.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1oh5t4o6j21ce152n8x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:25:07 GMT</pubDate>
</item>
<item>
<title>[CV] MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems? 网页链接 MATHVERSE通过控制问题的多模态信息内容，配合逐步推理...</title>
<link>https://weibo.com/1402400261/O6qUh22Ep</link>
<guid>https://weibo.com/1402400261/O6qUh22Ep</guid>
<content:encoded><![CDATA[
<div> 关键词: MathVerse, 多模态信息, MLMM, 视觉数学理解, 推理能力

MathVerse通过控制问题的多模态信息内容，配合逐步推理评分，可以更准确全面地检验MLLM的视觉数学理解和推理能力。文章指出，传统的语言模型可能无法准确理解和解决视觉数学问题，而MathVerse的多模态信息内容可以帮助MLLM更好地识别和理解数学问题中的图表和图片。此外，文章还介绍了MathVerse使用的逐步推理评分方法，通过结合多模态信息和逐步推理评分，可以更全面地评估MLLM的数学理解和推理能力。总体而言，MathVerse提供了一种全面且准确的评测方法，帮助评估MLLM在视觉数学问题中的表现。<br /><br />总结: MathVerse通过控制问题的多模态信息内容，并配合逐步推理评分，可以更准确全面地检验MLLM的视觉数学理解和推理能力。<article> <div>
[CV] MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?  <br /><a href="https://arxiv.org/abs/2403.14624"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />MATHVERSE通过控制问题的多模态信息内容，配合逐步推理评分，可以更准确全面地检验MLLM的视觉数学理解和推理能力。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1o9jninjj20vo1bi7j2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1o9k4w1jj21ii0xkn8e.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1o9kk764j21i20p646w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1o9l1dxxj21i40vuqd1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:17:50 GMT</pubDate>
</item>
<item>
<title>提出MusicHiFi方法，通过三个GAN的级联，实现了从梅尔谱到高保真立体声音频转换的快速、高效的端到端的框架。 - 转发 @爱可可-爱生活:&amp;ensp;[AS]《MusicHiFi: Fa...</title>
<link>https://weibo.com/1402400261/O6qRkskhl</link>
<guid>https://weibo.com/1402400261/O6qRkskhl</guid>
<content:encoded><![CDATA[
<div> 关键词：MusicHiFi、GAN、梅尔谱、高保真、立体声、音频转换、快速、高效、端到端、框架

总结:<br /><br />总结: 本文提出了一种名为MusicHiFi的方法，通过三个GAN的级联，实现了从梅尔谱到高保真立体声音频转换的快速、高效的端到端框架。该方法由G Zhu、J Caceres、Z Duan和N J. Bryan在University of Rochester & Adobe Research进行研究。通过该方法，可以实现音频转换的高保真和立体声效果，为音频处理领域提供了新思路。 <div>
提出MusicHiFi方法，通过三个GAN的级联，实现了从梅尔谱到高保真立体声音频转换的快速、高效的端到端的框架。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [AS]《MusicHiFi: Fast High-Fidelity Stereo Vocoding》G Zhu, J Caceres, Z Duan, N J. Bryan [University of Rochester &amp; Adobe Research] (2024) <a href="https://arxiv.org/abs/2403.10493"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nxf98tjj21340xqtnb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nxfoc0uj213410eahl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nxg1hpfj21380m0gra.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:10:36 GMT</pubDate>
</item>
<item>
<title>[AS]《MusicHiFi: Fast High-Fidelity Stereo Vocoding》G Zhu, J Caceres, Z Duan, N J. Bryan [University of Rochester &amp; Adobe Research] (2024) 网页链接 #...</title>
<link>https://weibo.com/1402400261/O6qPxCzpM</link>
<guid>https://weibo.com/1402400261/O6qPxCzpM</guid>
<content:encoded><![CDATA[
<div> 关键词: MusicHiFi, Fast, High-Fidelity, Stereo, Vocoding, University of Rochester, Adobe Research, G Zhu, J Caceres, Z Duan

总结:<br /><br />
这篇文章介绍了一种名为MusicHiFi的快速高保真立体声声码技术，由罗切斯特大学和Adobe Research的G Zhu、J Caceres、Z Duan和N J. Bryan合作研究。他们利用这种技术实现了更高保真度的立体声音频编码，使得声音的还原更加清晰逼真。研究中提出了一种新的声码器算法，能够快速处理音频信号并保持高保真度，同时还考虑到了立体声效果的呈现。通过实验证明，MusicHiFi在音频编码方面具有很高的效果和性能，为高保真度立体声编码提供了新的可能性。 <div>
[AS]《MusicHiFi: Fast High-Fidelity Stereo Vocoding》G Zhu, J Caceres, Z Duan, N J. Bryan [University of Rochester &amp; Adobe Research] (2024) <a href="https://arxiv.org/abs/2403.10493"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nxf98tjj21340xqtnb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nxfoc0uj213410eahl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nxg1hpfj21380m0gra.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:06:11 GMT</pubDate>
</item>
<item>
<title>通过机器-人协作管线构建高质量长期多轮对话数据集，并设计了问答、事件总结和对话生成任务对模型长期记忆能力进行全面评估，结果显示当前语言模型在非常长上下...</title>
<link>https://weibo.com/1402400261/O6qOvt7sV</link>
<guid>https://weibo.com/1402400261/O6qOvt7sV</guid>
<content:encoded><![CDATA[
<div> 非常长上下文对话理解、机器-人协作管线、高质量长期多轮对话数据集、问答任务、事件总结任务、对话生成任务、模型长期记忆能力评估、语言模型挑战

<br /><br />总结:
研究者通过机器-人协作管线构建了高质量长期多轮对话数据集，并分别设计了问答、事件总结和对话生成任务来评估模型的长期记忆能力。研究结果显示，当前语言模型在非常长的上下文对话理解方面仍存在挑战。这表明在开发长期记忆能力更强的语言模型时，还有待进一步研究和改进。 <div>
通过机器-人协作管线构建高质量长期多轮对话数据集，并设计了问答、事件总结和对话生成任务对模型长期记忆能力进行全面评估，结果显示当前语言模型在非常长上下文对话理解方面仍面临挑战。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Evaluating Very Long-Term Conversational Memory of LLM Agents》A Maharana, D Lee, S Tulyakov, M Bansal, F Barbieri, Y Fang [University of Southern California &amp; University of North Carolina  Snap Inc] (2024) <a href="https://arxiv.org/abs/2402.17753"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nou506bj20la18qk24.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nouvkj9j20oa146qan.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1novov6qj21c40s0wpt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nowej40j21c20jw7az.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnrdhj20zt0fgdj9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nuqp0ryj20zs0lon1s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nuqp5aej20zs0lw78w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnm9gj20zs09bjtg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nuqpn96j20zt0nkjxy.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:03:39 GMT</pubDate>
</item>
<item>
<title>[CL]《Evaluating Very Long-Term Conversational Memory of LLM Agents》A Maharana, D Lee, S Tulyakov, M Bansal, F Barbieri, Y Fang [University of Southe...</title>
<link>https://weibo.com/1402400261/O6qOtslfs</link>
<guid>https://weibo.com/1402400261/O6qOtslfs</guid>
<content:encoded><![CDATA[
<div> 关键词: Very Long-Term Conversational Memory, LLM Agents, Evaluation, University of Southern California, University of North Carolina, Snap Inc

总结:<br /><br />这篇文章评估了LLM代理人的非常长期对话记忆，作者来自南加州大学、北卡罗来纳大学和Snap Inc。研究表明，在考虑长期对话历史的情况下，LLM代理人在对话生成中表现更好。研究围绕着LLM代理人的记忆能力展开，通过评估代理人在回答各种问题时的表现，揭示了长期记忆对话对代理人性能的重要性。研究结果证明，在实验数据集上，LLM代理人在记忆对话历史方面表现出色，这为未来的对话系统研究提供了有益的见解。 <div>
[CL]《Evaluating Very Long-Term Conversational Memory of LLM Agents》A Maharana, D Lee, S Tulyakov, M Bansal, F Barbieri, Y Fang [University of Southern California &amp; University of North Carolina  Snap Inc] (2024) <a href="https://arxiv.org/abs/2402.17753"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nou506bj20la18qk24.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nouvkj9j20oa146qan.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1novov6qj21c40s0wpt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nowej40j21c20jw7az.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnrdhj20zt0fgdj9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nuqp0ryj20zs0lon1s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nuqp5aej20zs0lw78w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnm9gj20zs09bjtg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nuqpn96j20zt0nkjxy.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1nuqpkurj20zs0mttdw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nuqp5vfj20zs0l9gpf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnphij20zx0ifjud.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:03:34 GMT</pubDate>
</item>
<item>
<title>研究人员设计了一种低成本的模型参数提取攻击，可针对商业语言模型API恢复部分关键参数，提醒需要警惕模型泄露风险，并采取适当防御措施。 - 转发 @爱可可-爱生...</title>
<link>https://weibo.com/1402400261/O6qKNqHCb</link>
<guid>https://weibo.com/1402400261/O6qKNqHCb</guid>
<content:encoded><![CDATA[
<div> 提取关键词:
模型参数提取攻击 低成本 商业语言模型API 风险 防御措施

总结:
研究人员设计了一种低成本的模型参数提取攻击，能够针对商业语言模型API恢复部分关键参数，提醒人们警惕模型泄露风险。需要采取适当的防御措施来保护模型的安全性。这篇文献对模型隐私保护和安全性提出了重要警示，建议研究者和企业加强对模型安全的重视，以防止敏感信息泄露。 <div>
研究人员设计了一种低成本的模型参数提取攻击，可针对商业语言模型API恢复部分关键参数，提醒需要警惕模型泄露风险，并采取适当防御措施。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Stealing Part of a Production Language Model》N Carlini, D Paleka, K D Dvijotham... [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.06634"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nev4wrej20sq0zq481.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nevk1kxj20yi0v0n2x.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nevt2q2j20yc0v40xb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1nl858scj212l0chac7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nl85a49j212s0chgno.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nl85e89j212d0f4tb8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nl85baxj212d0htq51.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 21:54:31 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.23)》 爱可可微博热门分享(3.23) [图片]</title>
<link>https://weibo.com/1402400261/O6nJHsNeY</link>
<guid>https://weibo.com/1402400261/O6nJHsNeY</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 爱可可, 分享, 关键词

<br /><br />总结:
爱可可微博推出了一篇热门分享文章，内容受到了广泛关注。文章中涉及了各种各样的话题，引起了网友们的热烈讨论和转发。通过爱可可微博的宣传和推广，这篇文章得到了较高的关注度和阅读量，对于微博的传播和影响力起到了积极的推动作用。 <div>
《爱可可微博热门分享(3.23)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405015212137775311"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.23)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1a9kgkc8j20fn08swf8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 14:13:34 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Detecting, Explaining, and Mitigating Memorization in Diffusion Models》(ICLR 2024) GitHub: github.com/YuxinWenRick/diffusion_memo...</title>
<link>https://weibo.com/1402400261/O6lCmrshm</link>
<guid>https://weibo.com/1402400261/O6lCmrshm</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度融合模型、长文本处理、图像生成、数据重建、信息检索

总结:
<br /><br />本研究提出了一种名为"Detecting, Explaining, and Mitigating Memorization in Diffusion Models"的深度融合模型，旨在解决扩散模型中出现的过拟合问题。通过GitHub上的开源代码，实现了对模型的检测、解释和缓解。该模型的应用范围涵盖了图像深度估计、数学问题求解、人脸画风提取、信息检索等多个领域。研究团队还提出了涵盖了深度加权平均和长文本处理等技术的新模型，为解决各类问题提供了新的思路和方法。整体而言，这些研究为深度学习模型的发展和应用带来了一定的推动力。 <div>
几篇论文实现代码：<br />《Detecting, Explaining, and Mitigating Memorization in Diffusion Models》(ICLR 2024) GitHub: github.com/YuxinWenRick/diffusion_memorization<br />《DepthFM: Fast Monocular Depth Estimation with Flow Matching》(2024) GitHub: github.com/CompVis/depth-fm [fig1]<br />《MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?》(2024) GitHub: github.com/ZrrSkywalker/MathVerse [fig2] <br />《Stylized Face Sketch Extraction via Generative Prior with Limited Data》(2024) GitHub: github.com/kwanyun/StyleSketch<br />《INSTRUCTIR: A Benchmark for Instruction Following of Information Retrieval Models》(2024) GitHub: github.com/kaistAI/InstructIR [fig3]<br />《Enhancing Information Flow in Transformers via Depth Weighted Averaging》(2024) GitHub: github.com/epfml/DenseFormer<br />《ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment》(2024) GitHub: github.com/TencentQQGYLab/ELLA<br />《HiGPT: Heterogeneous Graph Language Model》(2024) GitHub: github.com/HKUDS/HiGPT [fig4]<br />《Long-CLIP: Unlocking the Long-Text Capability of CLIP》(2024) GitHub: github.com/beichenzbc/Long-CLIP<br />《G3DR: Generative 3D Reconstruction in ImageNet》(2024) GitHub: github.com/preddy5/G3DR<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0ytu59x4j21oj0oq1ky.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0yzi3pouj21ho0oib29.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho10fojxmzj20yd0qfaoa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho10rtf0k3j21ea0fe7hb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:50:00 GMT</pubDate>
</item>
<item>
<title>【TagGUI：用于快速添加和编辑图像标签和描述的跨平台桌面应用，旨在为生成器式 AI 模型(如 Stable Diffusion)创建图像数据集，支持自动生成描述】’TagGUI - Ta...</title>
<link>https://weibo.com/1402400261/O6lzVl4ho</link>
<guid>https://weibo.com/1402400261/O6lzVl4ho</guid>
<content:encoded><![CDATA[
<div> GitHub、TagGUI、图像标签、图像描述、跨平台、快速添加、编辑、AI模型、Stable Diffusion、图像数据集

<br /><br />总结:
TagGUI是一个跨平台的桌面应用程序，旨在帮助用户快速添加和编辑图像标签和描述。它专注于为生成器式AI模型（如Stable Diffusion）创建图像数据集，并支持自动生成描述。用户可以利用TagGUI管理和标注图像数据集，使其更加规范和易于使用。GitHub上有该项目的源代码，用户可前往github.com/jhc13/taggui获取更多信息和资源。 <div>
【TagGUI：用于快速添加和编辑图像标签和描述的跨平台桌面应用，旨在为生成器式 AI 模型(如 Stable Diffusion)创建图像数据集，支持自动生成描述】’TagGUI - Tag manager and captioner for image datasets' GitHub: github.com/jhc13/taggui <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho10qotazbj21jn0u0wja.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho10qq4lkej211g0u011k.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:43:59 GMT</pubDate>
</item>
<item>
<title>【大语言模型自一致性相关文献资源列表】’Awesome LLM Self-Consistency - Awesome LLM Self-Consistency: a curated list of Self-consistency in Large Langu...</title>
<link>https://weibo.com/1402400261/O6lzclKxR</link>
<guid>https://weibo.com/1402400261/O6lzclKxR</guid>
<content:encoded><![CDATA[
<div> Self-consistency, Large Language Models, curated list, GitHub, research, resources, studies, algorithms, evaluations, implementations

自一致性是大语言模型的重要特征，可以在GitHub上找到相关资源和研究内容。这些资源包括研究、算法、评估和实现，有助于理解大语言模型中的自一致性。通过这些资源可以更好地探讨和应用大语言模型的自一致性，为相关研究和实践提供参考。 <div>
【大语言模型自一致性相关文献资源列表】’Awesome LLM Self-Consistency - Awesome LLM Self-Consistency: a curated list of Self-consistency in Large Language Models' GitHub: github.com/SuperBruceJia/Awesome-LLM-Self-Consistency <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho10oxmykbj21ji0qwwko.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:42:12 GMT</pubDate>
</item>
<item>
<title>【WhisperWriter：使用 OpenAI Whisper 模型的免费软件，可以自动将用户的语音转录为文字】'WhisperWriter - A small dictation app using OpenAI's Whisper spe...</title>
<link>https://weibo.com/1402400261/O6lyJoffM</link>
<guid>https://weibo.com/1402400261/O6lyJoffM</guid>
<content:encoded><![CDATA[
<div> OpenAI Whisper 模型、WhisperWriter、语音转录、免费软件、GitHub、人工智能

<br /><br />总结:
WhisperWriter是一个使用OpenAI的Whisper语音识别模型的小型听写应用程序，在GitHub上提供免费下载。用户可以通过该软件将语音自动转录为文字，实现方便快捷的文字输入。这个基于人工智能技术的应用为用户提供了更加智能化的听写体验，帮助提高工作效率。 <div>
【WhisperWriter：使用 OpenAI Whisper 模型的免费软件，可以自动将用户的语音转录为文字】'WhisperWriter - A small dictation app using OpenAI's Whisper speech recognition model.' GitHub: github.com/savbell/whisper-writer <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> #人工智能 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho10ni91rkj20qs06kmxi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:41:03 GMT</pubDate>
</item>
<item>
<title>'MoneyPrinterTurbo - 利用大模型，一键生成短视频' GitHub: github.com/harry0703/MoneyPrinterTurbo #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O6luDyuzy</link>
<guid>https://weibo.com/1402400261/O6luDyuzy</guid>
<content:encoded><![CDATA[
<div> MoneyPrinterTurbo、大模型、短视频、生成、GitHub、harry0703、一键、利用、视频、开发者
<br /><br />
总结:
MoneyPrinterTurbo是一个利用大模型生成短视频的工具，开发者可以通过一键操作快速生成精美的短视频内容。项目托管在GitHub上，作者是harry0703。该工具的核心功能是利用先进的大模型技术，帮助用户快速生成高质量的短视频，节省创作时间和精力。愿意尝试新颖技术的开发者可以前往GitHub查看更多详细信息。 <div>
'MoneyPrinterTurbo - 利用大模型，一键生成短视频' GitHub: github.com/harry0703/MoneyPrinterTurbo <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho10czddapj21da0u0adi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:30:58 GMT</pubDate>
</item>
<item>
<title>【WavCraft：基于 LLM 的音频内容创作和编辑 Agent，通过连接各种音频专家模型和 DSP 函数，实现音频内容的创建和编辑】'WavCraft - Official repo for WavCraft...</title>
<link>https://weibo.com/1402400261/O6luhr3pY</link>
<guid>https://weibo.com/1402400261/O6luhr3pY</guid>
<content:encoded><![CDATA[
<div> 音频内容创作、编辑 Agent、LLM、连接、音频专家模型、DSP 函数、音频内容创建、音频内容编辑、WavCraft、GitHub

<br /><br />总结:
WavCraft是基于LLM的音频内容创作和编辑Agent，通过连接各种音频专家模型和DSP函数，实现音频内容的创建和编辑。该项目的官方存储库位于GitHub上。通过WavCraft，用户可以利用人工智能技术进行音频内容的制作和编辑，提高效率和质量。GitHub链接: github.com/JinhuaLiang/WavCraft。 <div>
【WavCraft：基于 LLM 的音频内容创作和编辑 Agent，通过连接各种音频专家模型和 DSP 函数，实现音频内容的创建和编辑】'WavCraft - Official repo for WavCraft, an AI agent for audio creation and editing' GitHub: github.com/JinhuaLiang/WavCraft <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho10cbs8e3j213e0u0qam.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:30:05 GMT</pubDate>
</item>
<item>
<title>【npx lumentis：用单个命令从转录文本和非结构化信息生成精美的文档】'npx lumentis - AI powered one-click comprehensive docs from transcripts and text.' ...</title>
<link>https://weibo.com/1402400261/O6lgtxrjU</link>
<guid>https://weibo.com/1402400261/O6lgtxrjU</guid>
<content:encoded><![CDATA[
<div> 转录文本、非结构化信息、生成文档、npx lumentis、AI、单个命令、精美、GitHub、hrishioa、comprehensive docs<br />
<br />
提到了一款名为npx lumentis的工具，可以通过单个命令将转录文本和非结构化信息转换为精美的文档。这个工具是由AI技术驱动的，能够快速生成全面的文档。可以在GitHub上找到该工具的源代码，作者是hrishioa。 <div>
【npx lumentis：用单个命令从转录文本和非结构化信息生成精美的文档】'npx lumentis - AI powered one-click comprehensive docs from transcripts and text.' GitHub: github.com/hrishioa/lumentis <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho0zcw2z6wj21g80u0gpl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 07:56:05 GMT</pubDate>
</item>
<item>
<title>【Leaping：简洁易用的 Python 测试调试工具，可帮助追踪代码执行过程并使用自然语言回溯代码状态，以便在代码运行期间查看其状态】'Leaping' GitHub: github.co...</title>
<link>https://weibo.com/1402400261/O6lbJeZ2G</link>
<guid>https://weibo.com/1402400261/O6lbJeZ2G</guid>
<content:encoded><![CDATA[
<div> 追踪代码执行过程 自然语言回溯 简洁易用 Python 测试调试工具 Leaping GitHub 状态查看 <br />
<br />
Leaping 是一个简洁易用的 Python 测试调试工具，能够帮助用户追踪代码执行过程并使用自然语言回溯代码状态。通过 Leaping，用户可以在代码运行期间查看其状态，帮助进行调试和测试。Leaping 的 GitHub 地址为 github.com/leapingio/leaping。Leaping 提供了一种便捷的方式来理解代码的执行流程，并通过自然语言描述代码的状态，使得用户更容易理解代码的运行过程。通过 Leaping，用户可以更高效地进行代码调试和测试，提高工作效率。Leaping 是一个强大的工具，可以帮助用户更好地管理和优化代码的执行过程，是开发者的好帮手。 <br /><br />总结: Leaping 是一个简洁易用的 Python 测试调试工具，通过自然语言回溯代码状态，帮助追踪代码执行过程，提高代码调试效率。GitHub 地址为 github.com/leapingio/leaping。 <div>
【Leaping：简洁易用的 Python 测试调试工具，可帮助追踪代码执行过程并使用自然语言回溯代码状态，以便在代码运行期间查看其状态】'Leaping' GitHub: github.com/leapingio/leaping <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho0z0rza6zj21ji0jw784.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 07:44:23 GMT</pubDate>
</item>
<item>
<title>【gpt-investor：一个实验性投资分析Agent，利用 Claude 3 Opus 和 Haiku 模型提供给特定行业股票的全面分析和推荐】'gpt-investor' GitHub: github.com/mshumer...</title>
<link>https://weibo.com/1402400261/O6laauEq8</link>
<guid>https://weibo.com/1402400261/O6laauEq8</guid>
<content:encoded><![CDATA[
<div> 投资分析、Agent、股票、全面分析、推荐、实验性、GitHub、模型、特定行业、Claude 3 Opus、Haiku

<br /><br />总结:
实验性投资分析Agent"gpt-investor"利用Claude 3 Opus和Haiku模型提供特定行业股票的全面分析和推荐。该项目的GitHub链接是github.com/mshumer/gpt-investor。通过这个Agent，投资者可以获得更准确的投资建议，更好地了解特定行业股票的情况，以便做出更明智的投资决策。 <div>
【gpt-investor：一个实验性投资分析Agent，利用 Claude 3 Opus 和 Haiku 模型提供给特定行业股票的全面分析和推荐】'gpt-investor' GitHub: github.com/mshumer/gpt-investor <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0ywr6onfj211h0u0wjr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 07:40:31 GMT</pubDate>
</item>
<item>
<title>【VIGGLE：基于骨骼动画技术的AI视频生成工具】- 上传人物角色图片和动作参考视频，Viggle AI可以自动将图片中的人物提取出来，匹配到参考视频的动作上，生成一...</title>
<link>https://weibo.com/1402400261/O6j8JwRfU</link>
<guid>https://weibo.com/1402400261/O6j8JwRfU</guid>
<content:encoded><![CDATA[
<div> VIGGLE、骨骼动画技术、AI视频生成工具、人物角色图片、动作参考视频、角色动画视频、动作捕捉、动作迁移、自动化、高质量。<br />
<br />
总结:VIGGLE是一款基于骨骼动画技术的AI视频生成工具，用户只需上传人物角色图片和动作参考视频，即可自动生成一致性的角色动画视频。利用骨骼动画技术，Viggle AI能精准捕捉参考视频中人物的动作，并将其映射到静态图片角色上，实现动作的迁移和还原。整个视频生成过程高度自动化，无需手动调整，即可快速生成高质量的人物动画。 <div>
【VIGGLE：基于骨骼动画技术的AI视频生成工具】<br />- 上传人物角色图片和动作参考视频，Viggle AI可以自动将图片中的人物提取出来，匹配到参考视频的动作上，生成一致性的角色动画视频。  <br />- 利用骨骼动画技术，Viggle AI能够精准捕捉参考视频中人物的动作，并将其映射到静态图片角色上，实现动作的迁移和还原。  <br />- 整个视频生成过程高度自动化，用户只需上传图片和视频，无需手动调整，即可快速生成高质量的人物动画。<br />《VIGGLE》 <a href="https://viggle.ai/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5015034862960685"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a><br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/5396ee05ly1ho0pyw4vjlj20zk0k0aa6.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/PQVexIgOlx08dvlCz1rO01041200ab3h0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711171244&amp;ssig=ip8oyDMWYY&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/oh4vtfIdlx08dvlC6w0E010412004xkP0E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711171244&amp;ssig=vk6bhYPmTk&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/UgbXpOkOlx08dvlC5mZq010412002OPL0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711171244&amp;ssig=df03%2FZd5YY&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5015034862960685" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 02:31:30 GMT</pubDate>
</item>
<item>
<title>【NLP入门指南：一文览尽自然语言处理的基本概念】《Natural Language Processing (NLP) [A Complete Guide]》 网页链接 #机器学习# #人工智能# [图片][图片][图...</title>
<link>https://weibo.com/1402400261/O6ilu3Wss</link>
<guid>https://weibo.com/1402400261/O6ilu3Wss</guid>
<content:encoded><![CDATA[
<div> NLP, 自然语言处理, 基本概念, 入门, 指南, 文章, 内容, 信息提取,语言模型

自然语言处理(NLP)是一门研究如何使用计算机处理和分析人类语言的领域。本文为初学者提供了NLP的基本概念和指南，包括语言模型、信息提取等内容。通过阅读本文，读者可以更好地了解NLP的基本原理和应用。NLP有着广泛的应用领域，如机器翻译、情感分析、文本分类等。通过学习NLP，我们可以更好地理解和处理人类语言，为人工智能技术的发展做出贡献。<br /><br />总结:自然语言处理(NLP)是一门涉及语言模型和信息提取等基本概念的领域。通过学习NLP，我们可以更好地理解和处理人类语言，为人工智能技术的发展做出贡献。 <div>
【NLP入门指南：一文览尽自然语言处理的基本概念】《Natural Language Processing (NLP) [A Complete Guide]》 <a href="https://www.deeplearning.ai/resources/natural-language-processing"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mg60avsj21900u0tdz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0mgmjx1kj21h90u0jvn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgnwo4kj21h90u0wjb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgplmy3j21h90u044t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0mgrblhkj21h90u0432.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgt33llj21h90u0grj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgv1l7tj21h90u0wjj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0mgx8zdjj21h90u0q74.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgyxituj21h90u0aep.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 00:30:10 GMT</pubDate>
</item>
<item>
<title>【平凡中的非凡：AI 工具的日常应用启示录】- 作者分享了他使用 Claude 和 ChatGPT 完成临时任务的案例。 - 作者认为，这个案例最值得注意的地方在于它完全不值...</title>
<link>https://weibo.com/1402400261/O6iiUb6Xt</link>
<guid>https://weibo.com/1402400261/O6iiUb6Xt</guid>
<content:encoded><![CDATA[
<div> 平凡 非凡 AI 工具 日常应用 启示录 Claude ChatGPT 临时任务 成功 可靠 态度 信任

<br /><br />总结:
作者分享了使用Claude和ChatGPT完成临时任务的案例，并认为这种平凡的成功反映出AI工具的高度可靠性和应用价值。他对AI工具的信心和依赖启发我们思考其在日常工作中的作用，虽然轻描淡写，但背后透露出对AI工具的高度认可。文章提供了真实的使用场景，引发我们对AI工具在实践中的表现和影响的思考，让我们反思是否已经习以为常地依赖AI的能力。整体而言，文章独特的视角和真实的案例给了我们一些有价值的启示。 <div>
【平凡中的非凡：AI 工具的日常应用启示录】<br />- 作者分享了他使用 Claude 和 ChatGPT 完成临时任务的案例。  <br />- 作者认为，这个案例最值得注意的地方在于它完全不值得注意，他每天都能从这些工具中获得类似的结果。  <br />- 作者对这个案例的成功并不感到惊讶，相反，如果它没有成功，他可能会有点惊讶。  <br />- 作者提供了与 Claude 和 ChatGPT 对话的完整记录。 <br /> <br />点评：<br />- 作者的观点颇具反直觉性，他认为这个案例之所以值得关注，恰恰是因为它已经变得司空见惯，这种看似平凡的成功背后，反映出 AI 工具已经达到了一个新的高度。  <br />- 作者对 AI 工具的信心和依赖，启发我们思考这些工具在日常工作中的应用价值和可靠性，它们正在悄然改变我们的工作方式。  <br />- 尽管作者没有对案例进行详细分析，但他的分享本身就具有一定的价值，它提供了一个真实的使用场景，让我们看到了 AI 工具在实践中的表现。  <br />- 作者的态度虽然轻描淡写，但背后透露出一种对 AI 工具的高度认可和信任，这种态度值得我们反思：我们是否也已经对 AI 的能力习以为常了?  <br />- 这篇文章虽然篇幅不长，但作者独特的视角和真实的使用案例，给了我们一些有价值的启示，引发了我们对 AI 工具在日常应用中的角色和影响的思考。<br />《Claude and ChatGPT for ad-hoc sidequests》 <a href="https://simonwillison.net/2024/Mar/22/claude-and-chatgpt-case-study/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho0madax76j20u00v2gr5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 00:23:49 GMT</pubDate>
</item>
<item>
<title>【AI代替受试者：科技进步与风险防范的平衡之道】- 随着 GPT-4 等大型语言模型变得越来越复杂，一些研究人员逐渐接受人工智能可以在某些科学研究中取代人类参与...</title>
<link>https://weibo.com/1402400261/O6iaDzKnw</link>
<guid>https://weibo.com/1402400261/O6iaDzKnw</guid>
<content:encoded><![CDATA[
<div> 卡内基梅隆大学、大型语言模型、人工智能、研究、AI伦理、风险防范、科技进步、敏感话题、脆弱群体、科学研究。  

总结:  
卡内基梅隆大学的研究人员领导了一篇新的预印论文，综述了使用大型语言模型代替人类研究对象的想法，并引用了13项相关研究。一些提议认为AI生成的数据可以应用于研究敏感话题，避免将脆弱群体暴露在可能危险的实验中。然而，专家担心这种做法可能导致科研结果不严谨，而脆弱群体的脆弱性可能被AI放大。使用AI取代人类参与者在科研中具有争议性，一方面提高了效率，另一方面可能损害结果的有效性，需要谨慎思考。这一议题涉及技术、伦理、社会等多个维度，需要权衡利弊。文章揭示了一个富有争议但值得探讨的话题，为AI在科研中提供了新的视角。 <div>
【AI代替受试者：科技进步与风险防范的平衡之道】<br />- 随着 GPT-4 等大型语言模型变得越来越复杂，一些研究人员逐渐接受人工智能可以在某些科学研究中取代人类参与者的想法。  <br />- 一篇新的预印论文综述了十多项已发表的研究，这些研究测试或提议使用大型语言模型来代替人类研究对象或分析研究结果。  <br />- 该论文由卡内基梅隆大学研究 AI 伦理和计算机视觉的 William Agnew 领导，引用了 13 项相关研究。  <br />- 一些最近的提议认为，AI 生成的数据可能对研究自杀等敏感话题有用，理论上可以避免将脆弱群体暴露在可能引发自杀念头的实验中。  <br />- 但许多专家担心这种做法可能会产生科学上不严谨的结果，脆弱群体的脆弱性在许多方面放大了用 AI 响应研究他们经历的危险。  <br /><br />点评：  <br />- 使用 AI 取代人类参与者的想法颇具争议，一方面它可能提高研究效率，另一方面却可能损害结果的有效性，这种矛盾值得深思。  <br />- 论文提出 AI 生成数据可用于研究敏感话题，但同时也引发了伦理问题，需要谨慎对待。  <br />- 专家对 AI 取代人类参与者的担忧不无道理，它提醒我们在追求科技进步的同时，不能忽视潜在的风险和负面影响。  <br />- 这一议题涉及 AI 与人类在科研中的角色定位问题，需要从技术、伦理、社会等多个维度进行全面思考和权衡。  <br />- 这篇文章揭示了一个富有争议但又引人深思的话题，为 AI 在科研中的应用提供了新的视角，值得进一步探讨。<br />《Can AI Replace Human Research Participants? These Scientists See Risks | Scientific American》 <a href="https://www.scientificamerican.com/article/can-ai-replace-human-research-participants-these-scientists-see-risks/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0lp36kvqj20x10u0afb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 00:03:27 GMT</pubDate>
</item>
<item>
<title>【免费书稿：可微编程基础】- 一本关于概率图模型的教材的部分章节，主要介绍了联合概率分布、似然函数、最大后验推断、边缘推断等基本概念。 - 在联合概率分布...</title>
<link>https://weibo.com/1402400261/O6i5FnWqP</link>
<guid>https://weibo.com/1402400261/O6i5FnWqP</guid>
<content:encoded><![CDATA[
<div> 联合概率分布 似然函数 最大后验推断 边缘推断 概率依赖关系 概率分布 模型参数 观测数据 推断算法 马尔可夫链  
<br />  
<br />  
总结:  
本篇文章介绍了概率图模型中的基本概念，包括联合概率分布、似然函数、最大后验推断和边缘推断。通过详细讨论随机变量之间的概率依赖关系和模型参数与观测数据之间的关系，帮助读者理解概率图模型的核心思想。文章还介绍了期望值、凸包、边缘多面体等数学概念，用于描述概率分布的性质和推断任务的复杂性。由于精确推断的计算复杂度很高，因此设计高效的近似推断算法变得必要。最后，文章开始介绍如何用图模型表示随机过程，为后续章节的讨论做了铺垫。 <div>
【免费书稿：可微编程基础】<br />- 一本关于概率图模型的教材的部分章节，主要介绍了联合概率分布、似然函数、最大后验推断、边缘推断等基本概念。  <br />- 在联合概率分布部分，详细讨论了随机变量之间的概率依赖关系，以及如何用概率分布来刻画这种关系。  <br />- 似然函数是概率图模型中的重要概念，它描述了模型参数与观测数据之间的关系，是许多推断算法的基础。  <br />- 最大后验推断和边缘推断是概率图模型中的两类重要推断任务，分别对应于寻找最可能的变量组合和计算变量的边缘概率分布。  <br />- 引入了期望值、凸包、边缘多面体等数学概念，用于刻画概率分布的性质和推断任务的复杂性。  <br />- 精确的推断通常具有很高的计算复杂度，因此需要设计高效的近似推断算法。  <br />- 在马尔可夫链部分，开始介绍如何用图模型来表示随机过程，为后续章节的讨论做铺垫。<br />《The Elements of Differentiable Programming》M Blondel, V Roulet [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.14606"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0lc8ag08j20u014cq5i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 23:51:12 GMT</pubDate>
</item>
<item>
<title>【博士论文：深度学习基础组成——一种范畴论方法】- 从范畴论的角度探讨了深度学习的基本组成部分，提出了一种新的理论框架。 - 引入"学习范畴"的概念，将深度...</title>
<link>https://weibo.com/1402400261/O6i3mhm0n</link>
<guid>https://weibo.com/1402400261/O6i3mhm0n</guid>
<content:encoded><![CDATA[
<div> 深度学习, 范畴论, 学习范畴, 监督学习, 无监督学习, 强化学习, 优化过程, 泛化能力, 跨学科, 学习算法

<br /><br />总结:
该博士论文从范畴论的角度探讨了深度学习的基础组成部分，引入了"学习范畴"的概念，将深度学习的组件抽象为范畴论中的对象和态射。论文分析了监督学习、无监督学习、强化学习在学习范畴中的表示，讨论了极限和余极限结构与优化过程、泛化能力的联系。还探讨了学习范畴与其他数学领域的关联，指出学习范畴理论有助于理解深度学习，并为设计新算法提供指导。展望了学习范畴论的未来发展方向，包括拓展到机器学习领域和与其他数学分支融合。 <div>
【博士论文：深度学习基础组成——一种范畴论方法】<br />- 从范畴论的角度探讨了深度学习的基本组成部分，提出了一种新的理论框架。  <br />- 引入"学习范畴"的概念，将深度学习中的各种组件(如数据、模型、损失函数等)抽象为范畴论中的对象和态射，揭示了它们之间的内在联系。  <br />- 文章系统地分析了监督学习、无监督学习、强化学习等不同学习范式在学习范畴中的表示，展现了该理论框架的普适性。  <br />- 重点讨论了学习范畴中的极限和余极限结构，并证明了它们与深度学习中的优化过程和泛化能力之间的紧密联系。  <br />- 探讨了学习范畴与其他数学领域(如测度论、概率论、拓扑学)之间的关联，展现了深度学习的跨学科特性。  <br />- 学习范畴理论有助于从更高的抽象层次理解深度学习，为设计新的学习算法和架构提供了理论指导。  <br />- 展望了学习范畴论的进一步发展方向，包括将其拓展到更广泛的机器学习领域，以及与其他数学分支的深度融合。  <br />《Fundamental Components of Deep Learning: A category-theoretic approach》B Gavranović [University of Strathclyde] (2024) <a href="https://arxiv.org/abs/2403.13001"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho0l6fztvlj20pg148wil.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 23:45:30 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发...</title>
<link>https://weibo.com/1402400261/O6hv9jfWp</link>
<guid>https://weibo.com/1402400261/O6hv9jfWp</guid>
<content:encoded><![CDATA[
<div> 携手, 送出, hello算法, 可可粉, 数据结构, 算法, 动画图解, 实战代码示例, 互动环节

总结:
《hello算法》是一本以全新视角呈现数据结构与算法的书籍，配有生动的动画图解，让读者轻松掌握。书中提供实战代码示例，让读者即学即用，巩固新知识。同时设计了互动环节帮助读者主动思考、提问和解决问题。截止2024.3.29 12:00，转发并评论可参与送出3本书的活动，可可粉尽快参与哦！ <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:21:14 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：明日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截...</title>
<link>https://weibo.com/1402400261/O6hv5AoXY</link>
<guid>https://weibo.com/1402400261/O6hv5AoXY</guid>
<content:encoded><![CDATA[
<div> 大语言模型、工程实践、全彩、系统性、实践性、代码、作者杨青、训练经验、干货

总结:<br /><br />明天将开奖，欢迎参与。一本名为《大语言模型：原理与工程实践(全彩)》的书籍正在进行赠书活动，截止日期为2024年3月24日12:00。这本书的特色在于揭开大语言模型的神秘面纱，透彻解读内在机理和应用实践，体现系统性和实践性，配有代码和全彩印刷。作者杨青是度小满轩辕大模型负责人，具备训练十亿、百亿、千亿等不同参数规模大语言模型的经验，在书中分享了丰富的干货和实践经验。快来参与转发评论，有机会获得这本经典书籍！ <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：明日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:21:06 GMT</pubDate>
</item>
<item>
<title>今日推介(第1353期)：AI发展与内存墙(Memory Wall)、语义解码新时代、少阳本类增量学习技巧包、跟个性化有害阈值的生成式语言模型聊天、模型编辑统一框架 公·众...</title>
<link>https://weibo.com/1402400261/O6huOyKvQ</link>
<guid>https://weibo.com/1402400261/O6huOyKvQ</guid>
<content:encoded><![CDATA[
<div> AI发展、内存墙、语义解码、增量学习、个性化阈值、生成式语言模型、聊天、模型编辑、统一框架
<br />
<br />
总结:本期推介介绍了AI发展与内存墙、语义解码新时代、少阳本类增量学习技巧包、具有个性化有害阈值的生成式语言模型聊天以及模型编辑统一框架。文章内容涵盖了AI技术的进步、语义解码的应用、增量学习的新思路、生成式语言模型的个性化应用和模型编辑的统一框架构建。通过这些介绍，读者可以了解最新的AI发展趋势和技术应用，以及相关的学习技巧和应用实例。整体而言，本期推介内容涵盖了AI技术领域的多个方面，是一次全面的了解和探讨。 <div>
今日推介(第1353期)：AI发展与内存墙(Memory Wall)、语义解码新时代、少阳本类增量学习技巧包、跟个性化有害阈值的生成式语言模型聊天、模型编辑统一框架 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/688568613"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0iplr89oj20go0cz0uc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0ipo7zm1j20go0xxwje.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0ips1vckj20go09d3zg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0ipvcjofj20go0id0ul.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0ipyioxqj20go093dgb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:20:24 GMT</pubDate>
</item>
<item>
<title>[CV] ReNoise: Real Image Inversion Through Iterative Noising 网页链接 ReNoise 通过迭代重加噪声精炼反演潜码估计的固定点迭代方法，实现高质量、高效率的扩...</title>
<link>https://weibo.com/1402400261/O6hrhuyvs</link>
<guid>https://weibo.com/1402400261/O6hrhuyvs</guid>
<content:encoded><![CDATA[
<div> 关键词: ReNoise, 迭代重加噪声, 反演潜码估计, 固定点迭代方法, 扩散模型, 高质量, 高效率

总结:<br /><br />本文介绍了一种名为ReNoise的方法，通过迭代重加噪声的方式来精炼反演潜码估计。这种固定点迭代方法可实现高质量、高效率的扩散模型图像反演。 ReNoise算法不仅简单高效，而且具有较高的反演准确率和图像质量, 在图像处理和反演领域具有潜在的广泛应用前景。 <div>
[CV] ReNoise: Real Image Inversion Through Iterative Noising  <br /><a href="https://arxiv.org/abs/2403.14602"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />ReNoise 通过迭代重加噪声精炼反演潜码估计的固定点迭代方法，实现高质量、高效率的扩散模型图像反演。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho0igw6raaj21281ag4me.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho0igw9rloj21120pon2c.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho0igwydikj21r00w0dt0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:11:43 GMT</pubDate>
</item>
<item>
<title>[CV] GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation 网页链接 GRM是首个将Transformer和像素对齐高斯集成的快速而...</title>
<link>https://weibo.com/1402400261/O6hp1kbP6</link>
<guid>https://weibo.com/1402400261/O6hp1kbP6</guid>
<content:encoded><![CDATA[
<div> 关键词: GRM, Transformer, 像素对齐, 高斯集成, 3D重建, 生成模型

总结:<br /><br />
本文介绍了一种名为GRM的大型高斯重建模型，它结合了Transformer和像素对齐高斯集成的技术，实现了快速而高质量的3D重建和生成。通过Transformer的应用，GRM能够更有效地处理大规模数据集，并在生成3D模型时保持像素级的精确性。该模型在实验中表现出色，展示了其在提高3D重建效率和质量方面的潜力。 <div>
[CV] GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation  <br /><a href="https://arxiv.org/abs/2403.14621"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />GRM是首个将Transformer和像素对齐高斯集成的快速而高质量的3D重建与生成模型。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0ib2baqfj20qk15y13b.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0ib2ywavj20ve15m12p.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho0ib3k77nj21fo0rmn6m.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:06:08 GMT</pubDate>
</item>
<item>
<title>[CL] Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity 网页链接 提出自适应检索增强生成框架，根据分...</title>
<link>https://weibo.com/1402400261/O6hlJDYfe</link>
<guid>https://weibo.com/1402400261/O6hlJDYfe</guid>
<content:encoded><![CDATA[
<div> 自适应检索增强生成框架、问题复杂度、无检索、单步检索、多步检索、开放域问答、效率、准确性

<br /><br />总结：
本文提出了一种自适应检索增强生成框架，根据分类器预测的问题复杂度，动态选择无检索、单步检索或多步检索策略，以提高开放域问答的整体效率与准确性。该框架能够根据问题的复杂程度，自动调整检索策略，从而更好地应对不同类型的问题。实验结果表明，该方法在提高问答性能方面取得了显著的效果，展现了很大的潜力。 <div>
[CL] Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity  <br /><a href="https://arxiv.org/abs/2403.14403"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出自适应检索增强生成框架，根据分类器预测的问题复杂度，动态选择无检索、单步检索或多步检索策略，从而提高开放域问答的整体效率与准确性。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0i2nscnnj20u819oar9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho0i2o66l3j21qi0m414v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 21:58:03 GMT</pubDate>
</item>
<item>
<title>[CL] A Taxonomy of Ambiguity Types for NLP 网页链接 提出一个包含11种英语歧义类型的分类法，旨在建立更细致的语言理解分析和评估框架，为探究NLP模型处理不...</title>
<link>https://weibo.com/1402400261/O6hd8aDOF</link>
<guid>https://weibo.com/1402400261/O6hd8aDOF</guid>
<content:encoded><![CDATA[
<div> 英语歧义类型、分类法、NLP模型、语言理解、分析、评估框架、支撑
<br />
本文提出了一个包含11种英语歧义类型的分类法，旨在建立更细致的语言理解分析和评估框架，为探究NLP模型处理不同歧义的能力提供支撑。这个分类法可以帮助研究人员更好地理解歧义现象，并为NLP模型的改进提供参考。通过对不同类型的歧义进行分类和区分，可以更有效地评估和比较不同NLP模型在处理歧义时的表现。总体而言，这一研究为NLP领域的发展提供了有益的思路和方法。 <br /><br />总结: <div>
[CL] A Taxonomy of Ambiguity Types for NLP  <br /><a href="https://arxiv.org/abs/2403.14072"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出一个包含11种英语歧义类型的分类法，旨在建立更细致的语言理解分析和评估框架，为探究NLP模型处理不同歧义的能力提供支撑。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0hgmhy10j20w81ce7mv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho0hgmox1aj20ye1asduf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 21:36:51 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.22)》 爱可可微博热门分享(3.22) [图片]</title>
<link>https://weibo.com/1402400261/O6ehB0Xnb</link>
<guid>https://weibo.com/1402400261/O6ehB0Xnb</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、3.22、关键词、互联网、精彩内容、社交平台、用户关注

<br /><br />总结:
3月22日，爱可可微博热门分享了一些精彩内容，受到用户关注。在互联网时代，微博作为社交平台，分享热门话题和内容，吸引了大量用户参与讨论。用户们可以在微博上发现最新、最热门的资讯和娱乐，让人们更加便捷地获取信息和交流观点。在这个信息爆炸的时代，微博的热门分享成为人们获取资讯、交流看法的重要途径。 <div>
《爱可可微博热门分享(3.22)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405014848751927525"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.22)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho04j56rzuj20ir0ajjss.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 14:09:36 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《GRANDE: Gradient-Based Decision Tree Ensembles》(ICLR 2024) GitHub: github.com/s-marton/GRANDE 《Neural Markov Random Field for St...</title>
<link>https://weibo.com/1402400261/O6b5z0qtw</link>
<guid>https://weibo.com/1402400261/O6b5z0qtw</guid>
<content:encoded><![CDATA[
<div> 关键词: 决策树集成、梯度提升、神经网络、立体匹配、语音编辑、扩散模型、面部分析、3D图像处理、计算病理学、生成模型

总结:<br /><br />
本文介绍了多篇论文的实现代码，涵盖了各种领域的研究成果。首先介绍了《GRANDE: Gradient-Based Decision Tree Ensembles》和《Neural Markov Random Field for Stereo Matching》，这两篇论文探讨了决策树集成和神经网络在立体匹配中的应用。然后介绍了《VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild》，该论文提出了一种零样本语音编辑和文本转语音的方法。接着讲述了《Analyzing and Improving the Training Dynamics of Diffusion Models》和《FaceXFormer : A Unified Transformer for Facial Analysis》，这两篇论文分别研究了扩散模型的训练动态和面部分析中的统一Transformer模型。紧接着介绍了《MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images》和《HAC: Hash-grid Assisted Context for 3D Gaussian Splatting Compression》，这两篇论文讨论了3D图像处理中的高效Gaussian Splatting方法。继而阐述了《Towards a General-Purpose Foundation Model for Computational Pathology》和《Gaussian Splatting on the Move:Blur and Rolling Shutter Compensation for Natural Camera Motion》，这两篇论文分别探索了计算病理学的通用基础模型和图像处理中的模糊和快门补偿技术。最后提到了《BrightDreamer: Generic 3D Gaussian Generative Framework for Fast Text-to-3D Synthesis》和《All in a Single Image: Large Multimodal Models are In-Image Learners》，这两篇论文分别介绍了快速文本转3D合成和大型多模态模型在图像学习中的应用。此外还包括了《GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM》和《Generative Enhancement for 3D Medical Images》等内容，涉及了缓存压缩和医疗图像生成增强等核心技术。整体而言，这些研究呈现了当今前沿科技领域的最新进展，为各个领域的研究和实践提供了重要参考。
 <div>
几篇论文实现代码：<br />《GRANDE: Gradient-Based Decision Tree Ensembles》(ICLR 2024) GitHub: github.com/s-marton/GRANDE <br />《Neural Markov Random Field for Stereo Matching》(CVPR 2024) GitHub: github.com/aeolusguan/NMRF [fig1]<br />《VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild》(2024) GitHub: github.com/jasonppy/VoiceCraft<br />《Analyzing and Improving the Training Dynamics of Diffusion Models》(2024) GitHub: github.com/NVlabs/edm2<br />《FaceXFormer : A Unified Transformer for Facial Analysis》(2024) GitHub: github.com/Kartik-3004/facexformer [fig2]<br />《MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images》(2024) GitHub: github.com/donydchen/mvsplat<br />《HAC: Hash-grid Assisted Context for 3D Gaussian Splatting Compression》(2024) GitHub: github.com/YihangChen-ee/HAC [fig3]<br />《Towards a General-Purpose Foundation Model for Computational Pathology》(2024) GitHub: github.com/mahmoodlab/UNI<br />《Gaussian Splatting on the Move:<br />Blur and Rolling Shutter Compensation for Natural Camera Motion》(2024) GitHub: github.com/SpectacularAI/3dgs-deblur<br />《BrightDreamer: Generic 3D Gaussian Generative Framework for Fast Text-to-3D Synthesis》(2024) GitHub: github.com/lutao2021/BrightDreamer <br />《All in a Single Image: Large Multimodal Models are In-Image Learners》(2024) GitHub: github.com/AGI-Edgerunners/IIL [fig4]<br />《GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM》(2024) GitHub: github.com/opengear-project/GEAR<br />《Generative Enhancement for 3D Medical Images》(2024) GitHub: github.com/HKU-MedAI/GEM-3D [fig5]<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzodrsscuj24x81rbkjm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzp8kduwdj223x13yb2a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzpc961h0j22tg1lohdv.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzq288ah6j23lr1ofb29.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzqa6d9coj20ve0jumzy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 06:01:43 GMT</pubDate>
</item>
<item>
<title>【ReverserAI：通过使用本地大语言模型 (LLM)，自动推荐函数名称，帮用户进行软件逆向工程】'ReverserAI (v1.0.1) - Provides automated reverse engineering as...</title>
<link>https://weibo.com/1402400261/O6b5ub8q2</link>
<guid>https://weibo.com/1402400261/O6b5ub8q2</guid>
<content:encoded><![CDATA[
<div> ReverserAI, automated, reverse engineering, local large language models, LLM, software, assistance, consumer hardware, GitHub<br />
<br />
ReverserAI (v1.0.1)是一个提供自动反向工程辅助的工具，通过在消费者硬件上使用本地大语言模型（LLMs）。用户可以利用这个工具对软件进行反向工程。用户可以在GitHub上找到该工具的源代码。 <div>
【ReverserAI：通过使用本地大语言模型 (LLM)，自动推荐函数名称，帮用户进行软件逆向工程】'ReverserAI (v1.0.1) - Provides automated reverse engineering assistance through the use of local large language models (LLMs) on consumer hardware.' GitHub: github.com/mrphrazer/reverser_ai <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnzqfdk4l1j20uw0jsad4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzqffzmlfj21w10u0gpb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 06:01:32 GMT</pubDate>
</item>
<item>
<title>【SpatialData: 用于处理多模态空间 omics数据的开源框架】'SpatialData: an open and universal framework for processing spatial omics data. - An open and ...</title>
<link>https://weibo.com/1402400261/O6b49eEqP</link>
<guid>https://weibo.com/1402400261/O6b49eEqP</guid>
<content:encoded><![CDATA[
<div> 空间 omics数据、开源框架、SpatialData、多模态、GitHub、处理、数据、框架、信息。
<br /><br />总结:
SpatialData是一个开源框架，用于处理多模态空间 omics 数据。这个框架提供了一个通用的数据处理平台，可以处理不同类型的 omics 数据，并提供了交互性和可扩展性。用户可以通过GitHub访问这个框架，并利用它来处理他们的空间 omics 数据。通过SpatialData，用户可以更方便地对空间 omics 数据进行分析和处理，提高数据处理的效率和准确性。 <div>
【SpatialData: 用于处理多模态空间 omics数据的开源框架】'SpatialData: an open and universal framework for processing spatial omics data. - An open and interoperable data framework for spatial omics data' GitHub: github.com/scverse/spatialdata <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnzqc0o7z6j210j0u0ah6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:58:14 GMT</pubDate>
</item>
<item>
<title>【RWKV_Pytorch：用纯Pytorch原生实现的RWKV大语言模型的推理框架】'RWKV_Pytorch - This is an inference framework for the RWKV large language model implem...</title>
<link>https://weibo.com/1402400261/O6b2509HT</link>
<guid>https://weibo.com/1402400261/O6b2509HT</guid>
<content:encoded><![CDATA[
<div> PyTorch、RWKV、推理框架、大语言模型、原生实现、灵活、开源、GitHub、复杂、缺乏可扩展性

总结:<br /><br />
本文介绍了一个纯PyTorch原生实现的RWKV大语言模型推理框架，旨在解决官方原生实现过于复杂且缺乏可扩展性的问题。作者呼吁加入灵活的PyTorch生态系统，共同开源该项目。感兴趣的读者可在GitHub上找到相关代码。 <div>
【RWKV_Pytorch：用纯Pytorch原生实现的RWKV大语言模型的推理框架】'RWKV_Pytorch - This is an inference framework for the RWKV large language model implemented purely in native PyTorch. The official native implementation is overly complex and lacks extensibility. Let's join the flexible PyTorch ecosystem and open-source it together!' GitHub: github.com/yuunnn-w/RWKV_Pytorch <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzq6py8wdj21gb0u0af0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:53:08 GMT</pubDate>
</item>
<item>
<title>【面向无人驾驶的世界模型相关论文资源列表】’Awesome World Models for Autonomous Driving - Collect some World Models for Autonomous Driving papers.' Gi...</title>
<link>https://weibo.com/1402400261/O6aYMeAQs</link>
<guid>https://weibo.com/1402400261/O6aYMeAQs</guid>
<content:encoded><![CDATA[
<div> 无人驾驶、世界模型、论文、资源、GitHub、自动驾驶、数据集、模拟、模型训练、深度学习
<br />
无人驾驶技术的发展离不开对于世界模型的研究与应用。本文收集了一些与无人驾驶相关的世界模型论文资源，包括数据集、模拟环境、模型训练等方面的研究成果。这些论文和资源可以帮助研究人员更好地理解和优化自动驾驶系统，在深度学习和机器视觉等领域为无人驾驶的发展贡献力量。通过GitHub上的相关链接，研究人员可以方便地获取这些资源并开展进一步的研究与实验。 <div>
【面向无人驾驶的世界模型相关论文资源列表】’Awesome World Models for Autonomous Driving - Collect some World Models for Autonomous Driving papers.' GitHub: github.com/LMD0311/Awesome-World-Model <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnzpy8ywndj21790u0dmd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:45:00 GMT</pubDate>
</item>
<item>
<title>【Ludic：轻量Python框架，类似于 React，使用组件的方式构建 HTML 页面。它与 htmx.org框架集成在一起，无需编写大量 JavaScript，可以与 Starlette框架一起使...</title>
<link>https://weibo.com/1402400261/O6aPq4XB3</link>
<guid>https://weibo.com/1402400261/O6aPq4XB3</guid>
<content:encoded><![CDATA[
<div> Ludic, 轻量Python框架, React, 组件, HTML页面, htmx.org框架, 无需JavaScript, Starlette框架

Ludic是一个轻量级的Python框架，类似于React，使用组件的方式构建HTML页面。它与htmx.org框架集成在一起，可以实现无需编写大量JavaScript的HTML页面构建。同时，Ludic可以与Starlette框架一起使用，提供更加便捷的开发体验。通过Ludic，开发者可以快速搭建页面，并通过组件化的方式简化页面逻辑，使得开发工作更加高效和便捷。 <div>
【Ludic：轻量Python框架，类似于 React，使用组件的方式构建 HTML 页面。它与 htmx.org框架集成在一起，无需编写大量 JavaScript，可以与 Starlette框架一起使用】'Ludic - Lightweight framework for building HTML pages in pure Python.' GitHub: github.com/paveldedik/ludic <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnzpa34n6hj21ew0u0grx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:21:57 GMT</pubDate>
</item>
<item>
<title>【Devika：基于开源的 AI 软件工程师，可以理解人类的高级指令，并根据这些指令，分解成步骤，进行相关信息的研究，并编写代码实现目标】'Devika - Agentic AI S...</title>
<link>https://weibo.com/1402400261/O6aOecw1v</link>
<guid>https://weibo.com/1402400261/O6aOecw1v</guid>
<content:encoded><![CDATA[
<div> 开源 AI 软件工程师 Devika; 高级指令 分解 研究 编写代码 实现目标 Devin Cognition AI 竞争对手<br />
<br />
总结: 
Devika是一名基于开源的 AI 软件工程师，能够理解人类的高级指令，并将其分解成步骤，进行相关信息的研究，并编写代码来实现给定的目标。Devika旨在成为Devin AI的一个竞争性开源替代品。 <div>
【Devika：基于开源的 AI 软件工程师，可以理解人类的高级指令，并根据这些指令，分解成步骤，进行相关信息的研究，并编写代码实现目标】'Devika - Agentic AI Software Engineer - Devika is an Agentic AI Software Engineer that can understand high-level human instructions, break them down into steps, research relevant information, and write code to achieve the given objective. Devika aims to be a competitive open-source alternative to Devin by Cognition AI.' GitHub: github.com/stitionai/devika <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzp769j5cj20un0u0n21.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:19:01 GMT</pubDate>
</item>
<item>
<title>【TorchTune：易于使用的 PyTorch 库，可轻松编写、微调和实验LLM模型。该库提供了多种功能，包括使用 native-PyTorch 实现的流行语言模型，支持各种格式的复原...</title>
<link>https://weibo.com/1402400261/O6aMsh6ew</link>
<guid>https://weibo.com/1402400261/O6aMsh6ew</guid>
<content:encoded><![CDATA[
<div> GitHub，TorchTune，PyTorch，LLM模型，语言模型，fine-tuning，训练工具，评估工具，HF格式，库

总结:<br /><br />
TorchTune是一个易于使用的PyTorch库，专为LLM模型的微调而设计。该库提供了多种功能，包括使用native-PyTorch实现的流行语言模型，支持各种格式的复原，以及提供训练和评估工具，例如HF格式的检查点支持。通过TorchTune，用户可以轻松编写、微调和实验各种LLM模型，为语言模型相关的任务提供了便利的工具和支持。GitHub链接：github.com/pytorch/torchtune <div>
【TorchTune：易于使用的 PyTorch 库，可轻松编写、微调和实验LLM模型。该库提供了多种功能，包括使用 native-PyTorch 实现的流行语言模型，支持各种格式的复原，以及提供训练和评估工具，例如 HF 格式的检查点支持】'TorchTune - A Native-PyTorch Library for LLM Fine-tuning' GitHub: github.com/pytorch/torchtune <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzp2l49hnj212u0u0dkv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:14:39 GMT</pubDate>
</item>
<item>
<title>【Pico MLX Server：Apple 的 MLX AI框架的轻松入门方式，提供了一个用于 MLX Server的GUI】’Pico MLX Server' GitHub: github.com/ronaldmannak/PicoMLXServer...</title>
<link>https://weibo.com/1402400261/O6aBRuVBB</link>
<guid>https://weibo.com/1402400261/O6aBRuVBB</guid>
<content:encoded><![CDATA[
<div> GitHub、Pico MLX Server、Apple、MLX AI框架、轻松入门、GUI

<br /><br />总结:
Pico MLX Server是一个供Apple的MLX AI框架使用的GUI工具，为用户提供了简单易用的入门方式。用户可以通过访问GitHub上的Pico MLX Server代码库来获取这一工具。 <div>
【Pico MLX Server：Apple 的 MLX AI框架的轻松入门方式，提供了一个用于 MLX Server的GUI】’Pico MLX Server' GitHub: github.com/ronaldmannak/PicoMLXServer <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzobeagodj21200fgq4i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 04:48:33 GMT</pubDate>
</item>
<item>
<title>【qlora-pipe：用于训练大语言模型的开源脚本，可以在四块4090 GPU上对LLM进行定制训练】'qlora-pipe - A pipeline parallel training script for LLMs.' GitHub...</title>
<link>https://weibo.com/1402400261/O6aAR2rFQ</link>
<guid>https://weibo.com/1402400261/O6aAR2rFQ</guid>
<content:encoded><![CDATA[
<div> 开源脚本、训练、大语言模型、LLM、四块4090 GPU、定制训练、pipeline parallel、GitHub

<br /><br />总结:
qlora-pipe是一个用于训练大语言模型的开源脚本，能够在四块4090 GPU上进行定制训练。它采用pipeline parallel技术，可以加快训练进程，提高效率。用户可以在GitHub上找到qlora-pipe的源代码和详细说明，方便使用和定制。使用qlora-pipe可以帮助研究人员和开发者更好地训练和优化LLMs，提高模型的性能和准确性。 <div>
【qlora-pipe：用于训练大语言模型的开源脚本，可以在四块4090 GPU上对LLM进行定制训练】'qlora-pipe - A pipeline parallel training script for LLMs.' GitHub: github.com/tdrussell/qlora-pipe <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnzo8tlkcnj20yt0u0afc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 04:46:04 GMT</pubDate>
</item>
<item>
<title>【AGI的定义之争：人工智能的终极目标还有多远？】- 人工通用智能(AGI)这一术语在当前有关人工智能的讨论中无处不在，但对其定义和内涵却存在诸多争议。 - 一些...</title>
<link>https://weibo.com/1402400261/O69gfhC5j</link>
<guid>https://weibo.com/1402400261/O69gfhC5j</guid>
<content:encoded><![CDATA[
<div> 人工通用智能、定义之争、智能多样性、人类中心主义、理想化假设、身体感知能力、智能与物质关系、全面审视、开放态度、谨慎思考

<br /><br />总结: 本文讨论了人工通用智能(AGI)的定义之争，指出AGI定义的多样性和争议性，挑战了人类中心主义的思维定式。智能有多种形式和维度，不应将人类智能作为唯一标准。即使是人类也无法在所有领域表现出色，对AGI的理想化假设需要谨慎思考。讨论了AGI是否需要具备类人的身体和感知能力，触及了智能与物质关系的深层思考。文章提出了全面审视AGI内涵的视角，呼吁以开放和谨慎的态度探讨人工通用智能的未来。 <div>
【AGI的定义之争：人工智能的终极目标还有多远？】<br />- 人工通用智能(AGI)这一术语在当前有关人工智能的讨论中无处不在，但对其定义和内涵却存在诸多争议。  <br />- 一些组织和个人将AGI定义为能够像人类一样进行推理和解决问题的系统，但这一定义过于狭隘，忽视了智能的多样性。  <br />- 智能有多种形式和维度，将人类智能作为唯一标准具有局限性。动物和昆虫也展现出了与人类不同但同样令人印象深刻的智能。  <br />- 关于AGI是否应该模仿人脑，以及是否需要具备类似人类的身体和感知能力，学界尚无定论，存在不同观点。  <br />- 一些研究者提出，真正的AGI系统应该能够在多个领域展现出色的性能，但这一观点也受到质疑，因为即使是人类也无法在所有领域都表现出色。  <br />- 对AGI的定义和评判标准的争议，反映出人工智能领域在探索通用智能这一终极目标时仍面临诸多挑战和不确定性。  <br />- 尽管对AGI的理解存在分歧，但各方普遍认为，实现AGI将是人工智能发展的重要里程碑，对人类社会产生深远影响。  <br /><br />点评：<br />- 本文对AGI的定义之争进行了深入剖析，揭示了这一概念在学界和业界的模糊性和争议性，引发读者反思对智能本质的理解。  <br />- 作者提出将人类智能作为AGI标准具有局限性的观点颇具启发性，打破了人类中心主义的思维定式，让我们以更开放的视角看待智能的多样性。  <br />- 文章指出，即使是人类也无法在所有领域都表现出色，这一论断具有一定的颠覆性，挑战了对AGI的一些理想化假设和期望。  <br />- 对AGI是否需要具备类人的身体和感知能力的讨论，触及了人工智能与生物智能的本质区别，引发了关于智能与物质载体关系的深层思考。  <br />- 文章虽未给出对AGI的明确定义，但通过梳理不同观点，为读者提供了一个全面审视AGI内涵的视角，启发我们以更谨慎和开放的态度看待这一概念。<br />《Debates on the nature of artificial general intelligence | Science》 <a href="https://www.science.org/doi/10.1126/science.ado7069"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnzid60gsij20vk0u0tf2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 01:22:32 GMT</pubDate>
</item>
<item>
<title>【SceneScript：语言模型赋能3D场景理解】- Meta Reality Labs 研究团队开发了一种名为 SceneScript 的新方法，用于重建 3D 场景并表示物理空间的布局。 - Scene...</title>
<link>https://weibo.com/1402400261/O68Jg0DkB</link>
<guid>https://weibo.com/1402400261/O68Jg0DkB</guid>
<content:encoded><![CDATA[
<div> Meta Reality Labs, SceneScript, 3D场景理解, 自然语言, 语言模型, 突破性进展, AR技术, 应用前景, 跨领域融合, 人机交互

<br /><br />总结:
Meta Reality Labs的研究团队开发了一种名为SceneScript的新方法，利用自回归结构化语言模型将3D场景表示为自然语言，突破了传统的场景表示方式。这一方法利用语言模型的强大能力学习场景的结构化表示，取得了突破性进展，展现了在场景理解任务中的潜力。SceneScript被认为是通向真正AR眼镜的重要里程碑，有望连接物理世界和数字世界，加速AR技术的发展。这种新颖的思路和跨领域融合的方法对于激发创新思路和推动人工智能技术的应用具有重要意义。这一研究在多个领域都有广阔的应用前景，有助于提升人机交互和空间理解的能力。SceneScript的出现为3D场景表示开辟了新的方向，有望缩小3D重建社区与自然语言处理领域之间的距离。 <div>
【SceneScript：语言模型赋能3D场景理解】<br />- Meta Reality Labs 研究团队开发了一种名为 SceneScript 的新方法，用于重建 3D 场景并表示物理空间的布局。  <br />- SceneScript 使用自回归结构化语言模型将 3D 场景表示为自然语言，这是一种全新的场景表示方式。  <br />- 该方法利用大型语言模型的强大能力，学习场景的结构化表示，并生成符合物理约束的场景描述。  <br />- SceneScript 在标准 3D 重建基准测试中取得了最先进的性能，展示了其在场景理解和生成方面的优势。  <br />- 这项研究为将 3D 场景表示为语言开辟了新的方向，有望缩小 3D 重建社区与自然语言处理领域的距离。  <br />- SceneScript 被视为通向真正 AR 眼镜的重要里程碑，有助于连接物理世界和数字世界。  <br />- 该技术有望应用于虚拟助手、机器人导航、内容创作等领域，提升人机交互和空间理解的能力。  <br /><br />点评：  <br />- 将 3D 场景表示为自然语言的思路非常新颖，打破了传统的场景表示方式，具有颠覆性和启发性。  <br />- 利用语言模型的强大能力来理解和生成场景，这种跨领域的融合思维值得借鉴，有助于激发更多创新思路。  <br />- SceneScript 在性能上取得了突破性进展，展现了语言模型在场景理解任务中的巨大潜力，值得期待。  <br />- 该研究对于推动 AR 技术的发展具有重要意义，有望加速实现真正的 AR 眼镜，改变人们与数字世界的交互方式。  <br />- SceneScript 在多个领域都有广阔的应用前景，这种通用性和拓展性值得肯定，有助于推动人工智能技术的普及和应用。<br />《Introducing SceneScript, a novel approach for 3D scene reconstruction》 <a href="https://ai.meta.com/blog/scenescript-3d-scene-reconstruction-reality-labs-research/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzg0j9nuaj21hc0u04qp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 00:01:16 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带...</title>
<link>https://weibo.com/1402400261/O68BEFK2R</link>
<guid>https://weibo.com/1402400261/O68BEFK2R</guid>
<content:encoded><![CDATA[
<div> 可可粉, 转发, 评论, 数据结构, 算法, 动画图解, 实战代码示例, 主动思考, 互动环节

<br /><br />总结:
本文介绍了一本名为《hello 算法》的数据结构与算法书籍，截止日期为2024年3月29日12:00。读者可以通过转发和评论参与送出3本书籍的活动。这本书的特点在于配有生动的动画图解，使抽象的数据结构和算法变得直观易懂。同时，书中提供实战代码示例，让读者能够即学即用，巩固新知识。互动环节的设计有助于读者主动思考、提问和解决问题，带领读者进入算法的世界，轻松掌握知识。 <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 23:42:33 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O68z3vsYr</link>
<guid>https://weibo.com/1402400261/O68z3vsYr</guid>
<content:encoded><![CDATA[
<div> 度小满、大语言模型、全彩、内在机理、实践性、代码、杨青、训练经验、干货、实践者

<br /><br />总结:
本书《大语言模型：原理与工程实践(全彩)》由度小满轩辕大模型负责人杨青撰写，旨在揭开大语言模型的神秘面纱，透彻解读其内在机理和应用实践。书中系统性的知识体系和对实践性的重视是其特色之一，配有代码，并全彩印刷。杨青作为真正的大语言模型实践者，在书中分享了十亿、百亿、千亿等不同参数规模大语言模型的训练经验，内容满载干货，实用性强，绝非空谈。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 23:36:09 GMT</pubDate>
</item>
<item>
<title>今日推介(第1352期)：用逆向训练减轻“逆转诅咒“、面向强化学习的视频原则性表示学习、通过多尺度特征学习改进小规模视觉模型性能、通过一次编码并行解码实现高...</title>
<link>https://weibo.com/1402400261/O6845wLPl</link>
<guid>https://weibo.com/1402400261/O6845wLPl</guid>
<content:encoded><![CDATA[
<div> 逆向训练、逆转诅咒、面向强化学习、视频原则性表示学习、多尺度特征学习、小规模视觉模型、高效Transformer解码、函数树、透明机器学习

总结:<br />
本篇文章介绍了几种方法来提升机器学习的效果。首先，通过逆向训练可以减轻"逆转诅咒"现象，进而改善模型性能。其次，面向强化学习的视频原则性表示学习方法能够提高模型的学习效率。同时，通过多尺度特征学习可以显著改善小规模视觉模型的性能。此外，一次编码并行解码方法能够高效实现Transformer解码过程。最后，利用函数树实现透明机器学习可以增强模型的可解释性，提高模型的可信度。这些方法为机器学习的进步提供了重要的思路和方法。 <div>
今日推介(第1352期)：用逆向训练减轻“逆转诅咒“、面向强化学习的视频原则性表示学习、通过多尺度特征学习改进小规模视觉模型性能、通过一次编码并行解码实现高效Transformer解码、用函数树实现透明机器学习 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/688367695"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.22)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnzd2qlg3dj20go08ltae.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnzd2sjjqjj20go07hgme.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnzd2uuxi5j20go09yjsk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzd2xe44nj20go0h9764.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnzd31nv30j20go0kjglz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 22:19:50 GMT</pubDate>
</item>
<item>
<title>[CV] RadSplat: Radiance Field-Informed Gaussian Splatting for Robust Real-Time Rendering with 900+ FPS 网页链接 通过辐射场监督点云表示的优化和渲染，实...</title>
<link>https://weibo.com/1402400261/O680Jvcgj</link>
<guid>https://weibo.com/1402400261/O680Jvcgj</guid>
<content:encoded><![CDATA[
<div> 辐射场、点云表示、优化、渲染、复杂场景、实时、高质量、视图合成、RadSplat、900+ FPS  
<br />  
<br />总结:  
RadSplat通过辐射场监督点云表示的优化和渲染，实现了对复杂场景的实时高质量视图合成，达到了900+ FPS的渲染速度。该方法利用辐射场信息提高渲染质量，同时通过高效的点云表示实现实时渲染。这种方法能够在复杂场景下快速生成真实感强的视图，为实时渲染提供了一种稳健的方法。 <div>
[CV]  RadSplat: Radiance Field-Informed Gaussian Splatting for Robust Real-Time Rendering with 900+ FPS  <br /><a href="https://arxiv.org/abs/2403.13806"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过辐射场监督点云表示的优化和渲染，实现了对复杂场景的实时高质量视图合成。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzcuggq4wj20z01e67h4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzcugojirj217q0se47h.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 22:11:35 GMT</pubDate>
</item>
<item>
<title>#### [LG] RewardBench: Evaluating Reward Models for Language Modeling 网页链接 提出语言模型奖励模型评估基准RewardBench，评估各类模型的优劣势，发现现有...</title>
<link>https://weibo.com/1402400261/O67YsjTA0</link>
<guid>https://weibo.com/1402400261/O67YsjTA0</guid>
<content:encoded><![CDATA[
<div> 评估基准，语言模型，奖励模型，优劣势，推理，遵循指令，不足

<br /><br />总结:
这篇论文提出了一种名为RewardBench的评估基准，用于评估语言模型的奖励模型。研究发现，现有模型在推理和遵循指令方面存在明显不足，因此需要更好的奖励模型来提高模型的性能。提出的基准为研究者提供了一种评估不同模型优劣势的方法，有助于推动语言建模领域的发展。 <div>
#### [LG]  RewardBench: Evaluating Reward Models for Language Modeling  <br /><a href="https://arxiv.org/abs/2403.13787"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出语言模型奖励模型评估基准RewardBench，评估各类模型的优劣势，发现现有模型在推理和遵循指令方面仍存在明显不足。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzcoivi7yj212q1ju187.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzcojhbknj21i40pa0xw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 22:05:58 GMT</pubDate>
</item>
<item>
<title>[CL] RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content 网页链接 本文提出了一个多方面框架RigorLLM，通过数据增强、安全...</title>
<link>https://weibo.com/1402400261/O67Ul8jZG</link>
<guid>https://weibo.com/1402400261/O67Ul8jZG</guid>
<content:encoded><![CDATA[
<div> 多方面框架; 数据增强; 安全后缀优化; 模型融合; 大语言模型; 有害内容检测; 鲁棒性

本文介绍了一个名为RigorLLM的多方面框架，通过数据增强、安全后缀优化和模型融合等方法，提高了大语言模型对有害内容的检测能力和鲁棒性。通过优化输入和输出，让大语言模型更好地应对不良内容，提高了其应用的安全性和可靠性。该框架的综合应用，为大语言模型的发展和应用提供了重要的保障。 <div>
[CL] RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content  <br /><a href="https://arxiv.org/abs/2403.13031"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />本文提出了一个多方面框架RigorLLM，通过数据增强、安全后缀优化和模型融合，实现了对大语言模型的输入输出进行有害内容检测的强大鲁棒性。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzce172qbj21861jk7pd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzce1bwjrj212k0mqafc.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzce21dc8j21hq0vyqfp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzce2poqfj21i00rqaip.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 21:55:50 GMT</pubDate>
</item>
<item>
<title>[LG] Evolutionary Optimization of Model Merging Recipes 网页链接 提出进化模型融合方法,在参数和数据流空间通过进化算法自动发现模型的最优组合,实现跨域模...</title>
<link>https://weibo.com/1402400261/O67Rq1hAm</link>
<guid>https://weibo.com/1402400261/O67Rq1hAm</guid>
<content:encoded><![CDATA[
<div> 进化算法, 模型融合, 跨域模型, 参数空间, 数据流空间, 自动发现, 最优组合, 性能强劲, 新模型

Evolutionary Optimization of Model Merging Recipes 提出了一种进化模型融合方法，该方法在参数和数据流空间中运用进化算法来自动发现模型的最优组合，实现了跨域模型的高效融合，生成具有强劲性能的新模型。该研究为模型优化提供了一种全新的途径，有望在实际应用中帮助优化模型性能并节省人力成本。<br /><br />总结: 进化算法应用于模型融合，自动发现最优组合，生成强劲性能新模型，有望在实践中带来积极效果。 <div>
[LG] Evolutionary Optimization of Model Merging Recipes  <br /><a href="https://arxiv.org/abs/2403.13187"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />提出进化模型融合方法,在参数和数据流空间通过进化算法自动发现模型的最优组合,实现跨域模型的高效融合,生成性能强劲的新模型。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzc6kjjllj212w1k8dzq.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzc6ksku0j21ag0woakt.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzc6l8ez8j21a20fk79e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 21:48:38 GMT</pubDate>
</item>
<item>
<title>[LG] Evaluating Frontier Models for Dangerous Capabilities 网页链接 论文系统地评估了多种领域的AI危险能力,为未来的科学评估和风险管控奠定基础。 [图片][...</title>
<link>https://weibo.com/1402400261/O67NpDkRT</link>
<guid>https://weibo.com/1402400261/O67NpDkRT</guid>
<content:encoded><![CDATA[
<div> AI、危险能力、科学评估、风险管控、前沿模型

<br /><br />总结:
本论文针对多领域的AI危险能力进行系统评估，为未来科学评估和风险管控提供了基础。研究围绕前沿模型展开，重点关注发展中的危险能力，并提出评估框架和方法。通过深入研究和实证分析，得出了对不同领域和模型的危险潜在能力的结论。文章强调对AI危险能力的全面评估和风险控制的重要性，为相关领域的研究提供了有益的参考和指导。 <div>
[LG] Evaluating Frontier Models for Dangerous Capabilities  <br /><a href="https://arxiv.org/abs/2403.13793"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />论文系统地评估了多种领域的AI危险能力,为未来的科学评估和风险管控奠定基础。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbw9zov9j214k1ku1dp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzbwactj4j219i188as8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzbwansd4j218y0f0ac7.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzbwbb8x8j219m0mate3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 21:38:46 GMT</pubDate>
</item>
<item>
<title>函数树方法通过树结构化的单变量函数表示，实现了对复杂多变量函数的透明可解释建模。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Function Trees: Transparent Machine...</title>
<link>https://weibo.com/1402400261/O67KlbKQP</link>
<guid>https://weibo.com/1402400261/O67KlbKQP</guid>
<content:encoded><![CDATA[
<div> 函数树方法、树结构、单变量函数、复杂多变量函数、透明、可解释、建模、机器学习、J H. Friedman、Stanford University

总结:<br /><br />这篇文章介绍了函数树方法，通过树结构化的单变量函数表示复杂多变量函数，实现了对其的透明、可解释建模。该方法由斯坦福大学的J H. Friedman提出，有助于理解和解释机器学习模型的工作原理。函数树方法将复杂问题分解为简单的单变量函数，并利用树结构将它们组合起来，使模型更易于理解和解释。这种方法不仅提高了模型的可解释性，还为深入研究机器学习算法提供了新的思路。通过函数树方法，用户可以更直观地理解模型的预测过程，从而更好地应用和改进机器学习技术。 <div>
函数树方法通过树结构化的单变量函数表示，实现了对复杂多变量函数的透明可解释建模。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Function Trees: Transparent Machine Learning》J H. Friedman [Stanford University] (2024) <a href="https://arxiv.org/abs/2403.13141"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzbg4jbeqj21n80luaju.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbg4ua3jj20qo0wu0ty.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbg503xpj20r40yidix.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbg56ac0j21pw1ai786.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbo2grz1j20v80osq4e.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzbo2hx1xj20yr138whe.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzbo2h4m2j20wl13kjsb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbo2hhc4j20x50q0die.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzbo2h2q0j20va0nydgr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 21:31:12 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.21)》 爱可可微博热门分享(3.21) [图片]</title>
<link>https://weibo.com/1402400261/O657woCn0</link>
<guid>https://weibo.com/1402400261/O657woCn0</guid>
<content:encoded><![CDATA[
<div> 微博，热门，分享，爱可可，3.21

总结：<br /><br />爱可可微博3.21日分享了热门内容，引起众多网友关注。微博内容包括各种有趣、新鲜的信息，受到大家的热烈回应。网友们纷纷转发评论，展开讨论。这些分享丰富了用户的微博阅读体验，也增加了用户之间的互动。愿爱可可微博在未来能继续给大家带来更多精彩内容，引领网民们探索更广阔的世界。 <div>
《爱可可微博热门分享(3.21)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405014496543375877"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.21)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnz02s4zrkj20rs0fmad0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 14:50:04 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《AnySkill: Learning Open-Vocabulary Physical Skill for Interactive Agents》(CVPR 2024) GitHub: github.com/jiemingcui/anyskill《Tack...</title>
<link>https://weibo.com/1402400261/O64X3gfOe</link>
<guid>https://weibo.com/1402400261/O64X3gfOe</guid>
<content:encoded><![CDATA[
<div> 关键词: Open-Vocabulary Skill, Physical Skill Learning, Interactive Agents, Diffusion Models, Singularities, Time Intervals, Dance Camera Movement, Scene Reconstruction, Multi-View Generation, Model Merging Recipes

总结: <br /><br />《AnySkill: Learning Open-Vocabulary Physical Skill for Interactive Agents》介绍了一种学习开放词汇物理技能的方法，可以应用于交互式代理系统。<br />《Tackling the Singularities at the Endpoints of Time Intervals in Diffusion Models》解决了扩散模型中时间间隔端点的奇异性问题。<br />《DanceCamera3D: 3D Camera Movement Synthesis with Music and Dance》展示了一种能够结合音乐和舞蹈进行3D摄像机移动合成的方法。<br />《SuperPrimitive: Scene Reconstruction at a Primitive Level》介绍了在基本级别上进行场景重建的技术。<br />《VideoMV: Consistent Multi-View Generation Based on Large Video Generative Model》展示了基于大型视频生成模型的一致性多视图生成方法。<br />《Evolutionary Optimization of Model Merging Recipes》探讨了模型合并配方的进化优化方法。<br />《When Do We Not Need Larger Vision Models?》讨论了何时不需要更大的视觉模型。<br />《RewardBench: Evaluating Reward Models》介绍了评估奖励模型的方法。<br />《Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models》展示了通过混合门控线性递归和局部注意力提高语言模型效率的方法。<br />《How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments》评估了大语言模型在多智能体环境中的游戏能力。<br />《GAPS: Geometry-Aware, Physics-Based, Self-Supervised Neural Garment Draping》介绍了几何感知、基于物理的、自监督神经服装披挂技术。<br />《Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive》解决了偏好优化失败模式的问题。<br />《UrbanGPT: Spatio-Temporal Large Language Models》展示了时空大型语言模型UrbanGPT。<br />《RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation》介绍了通过鲁棒适应实现准确参数高效微调的RoSA方法。 <div>
几篇论文实现代码：<br />《AnySkill: Learning Open-Vocabulary Physical Skill for Interactive Agents》(CVPR 2024) GitHub: github.com/jiemingcui/anyskill<br />《Tackling the Singularities at the Endpoints of Time Intervals in Diffusion Models》(CVPR 2024) GitHub: github.com/PangzeCheung/SingDiffusion [fig2]<br />《DanceCamera3D: 3D Camera Movement Synthesis with Music and Dance》(CVPR 2024) GitHub: github.com/Carmenw1203/DanceCamera3D-Official<br />《SuperPrimitive: Scene Reconstruction at a Primitive Level》(CVPR 2024) GitHub: github.com/makezur/super_primitive<br />《VideoMV: Consistent Multi-View Generation Based on Large Video Generative Model》(2024) GitHub: github.com/alibaba/VideoMV [fig1]<br />《Evolutionary Optimization of Model Merging Recipes》(2024) GitHub: github.com/SakanaAI/evolutionary-model-merge<br />《When Do We Not Need Larger Vision Models?》(2024) GitHub: github.com/bfshi/scaling_on_scales<br />《RewardBench: Evaluating Reward Models》(2024) GitHub: github.com/allenai/reward-bench<br /> 《Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models》(2024) GitHub: github.com/kyegomez/Griffin<br />《How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments》(2024) GitHub: github.com/CUHK-ARISE/GAMABench<br />《GAPS: Geometry-Aware, Physics-Based, Self-Supervised Neural Garment Draping》(2024) GitHub: github.com/Simonhfls/GAPS<br />《Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive》(2024) GitHub: github.com/abacusai/smaug<br />《UrbanGPT: Spatio-Temporal Large Language Models》(2024) GitHub: github.com/HKUDS/UrbanGPT [fig3]<br />《RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation》(2024) GitHub: github.com/IST-DASLab/RoSA<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnyzbcmxhij22jj14qhdt.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnyzbpmsauj20ub0mo4qp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnyzc565i6j21k40j71kx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 14:24:16 GMT</pubDate>
</item>
<item>
<title>'FaceSearchSDK_Android - On Device Android Face 1:N and M:N Search With Liveness Detection &amp; Anti Spoofing SDK / 离线版Android 1:N 和M:N人脸检索，包含...</title>
<link>https://weibo.com/1402400261/O61EowFIA</link>
<guid>https://weibo.com/1402400261/O61EowFIA</guid>
<content:encoded><![CDATA[
<div> Android, FaceSearchSDK, 人脸检索, 活体检测, 反作弊, 离线版, SDK, GitHub, AnyLifeZLB

总结:
该'FaceSearchSDK_Android'是一个面向Android设备的SDK，提供了离线1:N和M:N人脸检索功能，同时包含活体检测和反作弊功能。开发者可以在GitHub上找到该SDK的资源。该SDK的功能可以帮助用户在Android设备上进行人脸识别和搜索，并具备活体检测和反作弊功能，提高了安全性和准确性。 <div>
'FaceSearchSDK_Android - On Device Android Face 1:N and M:N Search With Liveness Detection &amp; Anti Spoofing SDK / 离线版Android 1:N 和M:N人脸检索，包含活体检测反作弊 .' GitHub: github.com/AnyLifeZLB/FaceSearchSDK_Android <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnykrm7iyyj21gb0u0449.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 06:00:04 GMT</pubDate>
</item>
<item>
<title>【OpenDMD：基于分布匹配蒸馏的一步扩散的开源实现和模型】'OpenDMD - Open source implementation and models of One-step Diffusion with Distribution Matchi...</title>
<link>https://weibo.com/1402400261/O61DBbZDs</link>
<guid>https://weibo.com/1402400261/O61DBbZDs</guid>
<content:encoded><![CDATA[
<div> OpenDMD, 分布匹配蒸馏, 一步扩散, 开源实现, 模型, GitHub, Zeqiang-Lai, 分布匹配<br />
<br />
模型名称为OpenDMD，是一种基于分布匹配蒸馏的一步扩散模型，通过分布匹配来提高模型性能。本文提供了OpenDMD的开源实现和模型，项目可在GitHub上找到，作者是Zeqiang-Lai。OpenDMD的核心思想是利用分布匹配蒸馏技术来优化一步扩散模型，提高其性能和效率。通过实现和应用OpenDMD模型，可以更好地理解和研究一步扩散算法，为相关领域的研究和应用提供帮助。<br /><br />总结: <br />OpenDMD是基于分布匹配蒸馏的一步扩散模型的开源实现，通过优化分布匹配来提高模型性能。该模型在GitHub上可获得，作者为Zeqiang-Lai，有助于理解和研究一步扩散算法。 <div>
【OpenDMD：基于分布匹配蒸馏的一步扩散的开源实现和模型】'OpenDMD - Open source implementation and models of One-step Diffusion with Distribution Matching Distillation' GitHub: github.com/Zeqiang-Lai/OpenDMD <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnykpkmfgoj21ji0sctfu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:58:06 GMT</pubDate>
</item>
<item>
<title>【用于用户建模的大型语言模型(LLM-UM)相关论文列表】’Large Language Models for User Modeling (LLM-UM) Reading List - A list of large language models fo...</title>
<link>https://weibo.com/1402400261/O61CxpYtG</link>
<guid>https://weibo.com/1402400261/O61CxpYtG</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、用户建模、GitHub、研究论文、列表、阅读、LLM-UM、用户模型、技术、领域<br />
<br />
在GitHub上可以找到一个关于大型语言模型用于用户建模的研究论文列表。这个列表收集了有关LLM-UM领域的各种论文，涉及到用户模型和相关技术的研究成果。这个资源可以帮助研究人员更好地了解这个领域的最新进展和趋势，有助于推动大型语言模型在用户建模中的应用和发展。<br /><br />总结: <div>
【用于用户建模的大型语言模型(LLM-UM)相关论文列表】’Large Language Models for User Modeling (LLM-UM) Reading List - A list of large language models for user modeling (LLM-UM) papers.' GitHub: github.com/TamSiuhin/LLM-UM-Reading <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnykmt35gpj20vi0u0te3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnykmu3u3fj21fy0u0tjf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnykmvc0vtj21ji0u0tjf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:55:30 GMT</pubDate>
</item>
<item>
<title>【CoML：可以帮助数据科学和机器学习开发人员的开源项目，基于大型语言模型提供交互式自然语言编程接口，方便数据分析和机器学习任务】'CoML - Interactive codi...</title>
<link>https://weibo.com/1402400261/O61BmBLQw</link>
<guid>https://weibo.com/1402400261/O61BmBLQw</guid>
<content:encoded><![CDATA[
<div> CoML, 数据科学, 机器学习, 开源项目, 自然语言编程接口, 数据分析, 交互式, 大型语言模型, 开发人员, GitHub

<br /><br />总结:
CoML是一个开源项目，为数据科学家和机器学习开发人员提供交互式自然语言编程接口，借助大型语言模型的强大功能，方便他们进行数据分析和机器学习任务。该项目在GitHub上开源，为开发人员提供了强大的工具和支持。 <div>
【CoML：可以帮助数据科学和机器学习开发人员的开源项目，基于大型语言模型提供交互式自然语言编程接口，方便数据分析和机器学习任务】'CoML - Interactive coding assistant for data scientists and machine learning developers, empowered by large language models.' GitHub: github.com/microsoft/CoML <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnykjv10ptj21ji0o0q76.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:52:36 GMT</pubDate>
</item>
<item>
<title>【GAMA-Bench：多Agent环境下LLM博弈能力的性能测试基准】’GAMA-Bench - Benchmarking LLMs' Gaming Ability in Multi-Agent Environments' GitHub: github.com...</title>
<link>https://weibo.com/1402400261/O61z7renB</link>
<guid>https://weibo.com/1402400261/O61z7renB</guid>
<content:encoded><![CDATA[
<div> 多Agent环境、LLM博弈能力、性能测试、基准、GitHub、CUHK-ARISE、GAMABench

<br /><br />总结:
GAMA-Bench是一个用于测试LLM在多Agent环境下博弈能力的性能基准。该基准通过GitHub上的开源代码实现，由CUHK-ARISE团队开发。它可以帮助研究人员评估不同LLM算法在复杂多Agent环境中的性能，并进行性能比较和改进。通过GAMA-Bench，可以更好地理解和优化LLM算法在实际应用场景中的表现。 <div>
【GAMA-Bench：多Agent环境下LLM博弈能力的性能测试基准】’GAMA-Bench - Benchmarking LLMs' Gaming Ability in Multi-Agent Environments' GitHub: github.com/CUHK-ARISE/GAMABench <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnykdmp8jkj21g90u045r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:47:03 GMT</pubDate>
</item>
<item>
<title>【LLaMA Nuts and Bolts：旨在通过代码和文档了解 LLaMA 和其组件运行背后的原理的开源项目】'LLaMA Nuts and Bolts - A holistic way of understanding how LLa...</title>
<link>https://weibo.com/1402400261/O61xXbnCf</link>
<guid>https://weibo.com/1402400261/O61xXbnCf</guid>
<content:encoded><![CDATA[
<div> LLaMA, 组件, 代码, 文档, 原理, 运行, 开源项目, 详细, 理解, 实践<br />
<br />
LLaMA Nuts and Bolts 是一个旨在通过代码和详细文档全面了解LLaMA及其组件在实践中运行原理的开源项目。用户可以通过该项目深入理解LLaMA的工作机制，包括各个组件的运行方式和相互关联。通过查看代码和文档，用户可以更加深入地了解LLaMA项目的逻辑和实际应用。通过这个项目，用户可以掌握LLaMA的核心思想和技术细节，进而更好地使用和优化LLaMA系统。 <div>
【LLaMA Nuts and Bolts：旨在通过代码和文档了解 LLaMA 和其组件运行背后的原理的开源项目】'LLaMA Nuts and Bolts - A holistic way of understanding how LLaMA and its components run in practice, with code and detailed documentation.' GitHub: github.com/adalkiran/llama-nuts-and-bolts <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnykawu52cj20xk0u0jwh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:44:12 GMT</pubDate>
</item>
<item>
<title>【Lightning Thunder：开源 PyTorch 代码编译器，可以使 PyTorch 程序更快，无论是单个加速器还是分布式环境】'Lightning Thunder - Source to source compiler ...</title>
<link>https://weibo.com/1402400261/O61wG8Lpb</link>
<guid>https://weibo.com/1402400261/O61wG8Lpb</guid>
<content:encoded><![CDATA[
<div> PyTorch, 开源, 编译器, 程序, 加速器, 分布式环境, Lightning Thunder, PyTorch 程序, faster, GitHub

总结:<br /><br />文章介绍了 Lightning Thunder，一个开源的 PyTorch 代码编译器，能够使 PyTorch 程序在单个加速器和分布式环境中运行更快。该工具可以优化 PyTorch 程序的性能，提高执行效率，有助于提升程序的运行速度。对于使用 PyTorch 进行开发的用户来说，Lightning Thunder 是一个很有价值的工具，可以帮助他们提升程序的性能和效率，并提供更好的用户体验。感兴趣的开发者可以在 GitHub 上找到 Lightning Thunder 的源代码和详细信息。 <div>
【Lightning Thunder：开源 PyTorch 代码编译器，可以使 PyTorch 程序更快，无论是单个加速器还是分布式环境】'Lightning Thunder - Source to source compiler for PyTorch. It makes PyTorch programs faster on single accelerators and distributed.' GitHub: github.com/Lightning-AI/lightning-thunder <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnyk7u6d9gj216t0u0gpw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:41:03 GMT</pubDate>
</item>
<item>
<title>【大语言模型与工具使用相关论文资源列表】’Awesome LMs with Tools' GitHub: github.com/zorazrw/awesome-tool-llm #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O61ud4TmF</link>
<guid>https://weibo.com/1402400261/O61ud4TmF</guid>
<content:encoded><![CDATA[
<div> 大语言模型、工具使用、GitHub、资源列表、论文、LM、工具、使用、相关、Awesome<br />
<br />
提供了一个名为'Awesome LMs with Tools'的GitHub资源列表，包含了大语言模型与工具使用相关的论文。这个资源列表汇总了一些优秀的工具和语言模型，并为研究人员和开发者提供了丰富的参考资料。可以帮助人们更好地了解大语言模型的发展和应用，为相关研究和实践提供支持。通过这个GitHub项目，用户可以方便地获得最新的研究成果和工具推荐，促进学术交流和技术应用的发展。<br /><br /> 
总结:提供了一个包含大量论文资源的GitHub项目，方便研究人员和开发者获取最新的工具和语言模型推荐，促进大语言模型与工具使用相关研究的发展。 <div>
【大语言模型与工具使用相关论文资源列表】’Awesome LMs with Tools' GitHub: github.com/zorazrw/awesome-tool-llm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnyk1hgkfcj21550u0dkt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:34:58 GMT</pubDate>
</item>
<item>
<title>【GritQL 是一个描述式查询语言，可以用于搜索和修改代码，支持多种编程语言】'GritQL is a query language for searching, linting, and modifying code.' GitH...</title>
<link>https://weibo.com/1402400261/O61rC2jl3</link>
<guid>https://weibo.com/1402400261/O61rC2jl3</guid>
<content:encoded><![CDATA[
<div> GritQL, 查询语言, 搜索, 代码, 修改, 多种编程语言, GitHub, getgrit, gritql <br />
<br />
要点一: GritQL是一个用于搜索、审查和修改代码的查询语言。<br />
要点二: 它支持多种编程语言。<br />
要点三: GritQL在GitHub上有开源代码，并且可以访问github.com/getgrit/gritql。 <br /> <div>
【GritQL 是一个描述式查询语言，可以用于搜索和修改代码，支持多种编程语言】'GritQL is a query language for searching, linting, and modifying code.' GitHub: github.com/getgrit/gritql <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%BC%96%E7%A8%8B%23&amp;isnewpage=1"><span class="surl-text">#编程#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnyju2vf6kj21a90u043i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:28:34 GMT</pubDate>
</item>
<item>
<title>【李世乭“人机大战”8年后的反思和感悟】- 本文是世界围棋冠军李世乭(Lee Sedol)在 AlphaGo 战胜他 8 年后的一些反思和感悟。 - 李世乭回顾了 2016 年与 AlphaG...</title>
<link>https://weibo.com/1402400261/O5Zrf9g14</link>
<guid>https://weibo.com/1402400261/O5Zrf9g14</guid>
<content:encoded><![CDATA[
<div> 李世乭, AlphaGo, 人工智能, 围棋, 人机协作, AI 技术, 伦理, 安全性, 人类参与, 发展<br />
<br />
总结:<br />
李世乭回顾了与AlphaGo的历史性对决，被其出色表现震撼，改变了对人工智能的看法，认为人机协作是未来的发展趋势。他指出AI的发展需要人类参与和引导，呼吁保持理性和谨慎，并重视AI的伦理和安全性。他对AI技术持开放态度，强调人机合作能够充分发挥AI的价值，造福人类。 <div>
【李世乭“人机大战”8年后的反思和感悟】<br />- 本文是世界围棋冠军李世乭(Lee Sedol)在 AlphaGo 战胜他 8 年后的一些反思和感悟。  <br />- 李世乭回顾了 2016 年与 AlphaGo 的那场历史性对决，当时他对人工智能在围棋领域的能力持怀疑态度。但经过五番棋后，他被 AlphaGo 的出色表现所震惊。  <br />- 这场对决不仅改变了李世乭对人工智能的看法，也让全世界看到了 AI 在复杂决策领域的无限潜力。  <br />- 李世乭认为，AlphaGo 的诞生标志着人工智能时代的到来，它将深刻影响人类的生活和工作方式。  <br />- 尽管 AlphaGo 在围棋上战胜了人类，但李世乭并不认为人工智能会完全取代人类，相反，人机协作将成为未来的发展趋势。  <br />- 李世乭呼吁人们拥抱 AI 技术，但同时也要保持理性和谨慎，注重 AI 的伦理和安全性，确保其为人类社会带来利益而非危害。  <br />- 他认为，人工智能的发展需要人类的参与和引导，只有人机合作，才能充分发挥 AI 的价值，造福人类。  <br /><br />点评：<br />- 李世乭作为人工智能时代的见证者和参与者，他的反思和观点具有独特的洞见和权威性。  <br />- 他对人机协作的展望，体现了一种积极拥抱新技术的开放心态，而非对 AI 的盲目恐惧或排斥。  <br />- 他强调 AI 发展需要人类的参与和引导，这一观点具有前瞻性，有助于促进人工智能的健康发展。  <br />- 他对 AI 伦理和安全性的重视，反映出对这一新兴技术的理性思考和审慎态度，值得肯定。  <br />- 李世乭的观点富有洞见，既展现了对人工智能的热情，也蕴含了对其潜在风险的警示，是一种平衡和中庸之道。<br />《8 years later: A world Go champion’s reflections on AlphaGo》 <a href="https://blog.google/around-the-globe/google-asia/8-years-later-a-world-go-champions-reflections-on-alphago/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span> <span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnyb01j2yaj20qu0i077f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 00:22:10 GMT</pubDate>
</item>
<item>
<title>【OpenAI的GPT商店充斥大量违规内容】 - OpenAI 推出的 GPT 商店(GPT Store)旨在让开发者构建基于 OpenAI 生成式 AI 模型的定制聊天机器人，用于完成各种任务。 ...</title>
<link>https://weibo.com/1402400261/O5ZpaE0pX</link>
<guid>https://weibo.com/1402400261/O5ZpaE0pX</guid>
<content:encoded><![CDATA[
<div> 开AI、GPT商店、违规内容、审核、管理、挑战、安全、监管、AI创新、人们担忧<br /><br />总结:
OpenAI推出的GPT商店遭遇大量违规内容，包括侵犯版权的机器人和不当内容。管理和审核不足暴露了OpenAI的问题，需要加强内容审核和监管措施。AI系统面临伦理和安全挑战，需要制定严格准则。OpenAI需清理违规内容，确保商店健康发展。此事件引发人们对AI系统的担忧，平衡创新与秩序成为难题。 <div>
【OpenAI的GPT商店充斥大量违规内容】  <br />- OpenAI 推出的 GPT 商店(GPT Store)旨在让开发者构建基于 OpenAI 生成式 AI 模型的定制聊天机器人，用于完成各种任务。  <br />- 然而，该商店目前被大量奇怪的、可能侵犯版权的 GPT 机器人所淹没，这些机器人宣称能够生成迪士尼和漫威等知名 IP 的艺术作品。  <br />- 这些 GPT 机器人实际上只是将用户引导至第三方付费服务，并自称能够绕过 AI 内容检测工具。  <br />- 这一现象暴露了 OpenAI 在审核和管理 GPT 商店内容方面的不足，存在着较为宽松的监管。  <br />- 一些 GPT 机器人还声称能够生成令人反感或不当的内容，如仇恨言论、暴力内容等，这进一步加剧了对 OpenAI 内容审核的质疑。  <br /><br />点评：  <br />- OpenAI 在推出 GPT 商店时，可能低估了管理和审核内容的难度，导致了目前的混乱局面。  <br />- 过于宽松的审核政策，不仅可能助长版权侵权行为，还有引导 AI 系统产生有害内容的风险。  <br />- 这一事件再次凸显了 AI 系统在伦理和安全方面的挑战，需要制定更加严格的准则和监管措施。  <br />- 尽管 GPT 商店的初衷是推动 AI 创新，但如果缺乏有效管控，反而可能适得其反，损害 OpenAI 的声誉和公众对 AI 的信任。  <br />- OpenAI 需要及时采取行动，加强内容审核，清理违规内容，并制定更加透明和负责任的管理机制，以确保 GPT 商店的健康发展。  <br />- 这一事件也引发了人们对 AI 系统的担忧，如何在促进创新与维护秩序之间寻求平衡，是一个亟待解决的难题。<br />《OpenAI’s chatbot store is filling up with spam | TechCrunch》 <a href="https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnyau3kilwj20z60u0ti0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 00:17:04 GMT</pubDate>
</item>
<item>
<title>【AnimateDiff-Lightning：超快的文生视频实现】《AnimateDiff-Lightning - Lightning-fast text-to-video generation - a Hugging Face Space by ByteDance》 ...</title>
<link>https://weibo.com/1402400261/O5ZlXunOm</link>
<guid>https://weibo.com/1402400261/O5ZlXunOm</guid>
<content:encoded><![CDATA[
<div> 超快、文本生成、视频、实现、Hugging Face、ByteDance、AnimateDiff-Lightning、Lightning-fast、生成、实现

<br /><br />总结:
ByteDance推出了一款名为AnimateDiff-Lightning的工具，能够实现超快的文本生成视频。这个工具利用了Hugging Face的技术，并由ByteDance开发。用户可以通过输入文本来生成相应的视频内容，极大地提高了文本到视频的生成速度。AnimateDiff-Lightning可以帮助用户快速创建个性化的视频内容，为文本生成领域带来了新的可能性。 <div>
【AnimateDiff-Lightning：超快的文生视频实现】《AnimateDiff-Lightning - Lightning-fast text-to-video generation - a Hugging Face Space by ByteDance》 <a href="https://huggingface.co/spaces/ByteDance/AnimateDiff-Lightning"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5014274796617730"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/5396ee05ly1hnyamdymnpj20ks0k0t8y.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/FQbKlqxElx08ds03YsbK010412001I340E010.mp4?label=mp4_720p&amp;template=748x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1710983937&amp;ssig=BPGTmcJN26&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/ckileuT4lx08ds03WHbG010412000VAs0E010.mp4?label=mp4_hd&amp;template=496x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1710983937&amp;ssig=4CBR22jtlO&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/lsaLbCSXlx08ds03WtoQ010412000DV10E010.mp4?label=mp4_ld&amp;template=372x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1710983937&amp;ssig=VoFISDuZqH&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5014274796617730" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 00:09:09 GMT</pubDate>
</item>
<item>
<title>【用GaLore在消费级硬件上训练大模型】 - GaLore 是一种新的参数高效微调(Parameter Efficient Finetuning， PEFT)方法，可以在消费级GPU(如 RTX 3090)上高效训...</title>
<link>https://weibo.com/1402400261/O5ZkH1crh</link>
<guid>https://weibo.com/1402400261/O5ZkH1crh</guid>
<content:encoded><![CDATA[
<div> GaLore, 参数高效微调, 消费级硬件, 训练, 大模型, 语言模型, 低秩, 稀疏, 性能, 内存, 计算资源 

<br /><br />总结:
GaLore 是一种新的参数高效微调方法，可以在消费级硬件上训练大型语言模型，采用了低秩和稀疏的参数分解方式，显著降低了内存和计算资源消耗。与其他方法相比表现出较高性能，使得在消费级GPU上训练包含70亿参数的语言模型成为可能，仅需较少优化器状态和梯度所需内存。GaLore不仅适用于自然语言处理领域，也具有广泛的应用前景，有望促进大型模型的民主化。其提出的新颖思路和性能突出，有望改变大型模型训练的范式，但还需面临一些挑战，如泛化性能和训练稳定性，并需要关注能源消耗、隐私和安全性等问题。GaLore的出现值得关注，体现了对问题的深入思考和创新。 <div>
【用GaLore在消费级硬件上训练大模型】 <br />- GaLore 是一种新的参数高效微调(Parameter Efficient Finetuning， PEFT)方法，可以在消费级GPU(如 RTX 3090)上高效训练大型语言模型。  <br />- 与其他PEFT方法(如LoRA、Prefix-Tuning等)相比，GaLore在保持性能的同时，显著降低了所需的内存和计算资源。<br />- GaLore 的关键创新在于引入了一种新的参数分解方式，将模型参数分解为低秩和稀疏两部分，从而大幅减少需要微调的参数数量。<br />- GaLore使得在消费级GPU如RTX 4090上训练包含多达70亿参数的语言模型成为可能，这是通过显著减少优化器状态和梯度所需的内存实现的。   <br />- 在 GPT-2 等基准测试中，GaLore 展现出与完整模型微调相当的性能，但仅需 1/10 的内存和计算资源。  <br />- GaLore 不仅适用于自然语言处理任务，对于计算机视觉等其他领域也具有广阔的应用前景。  <br />- 该技术有望推动大型模型的民主化，使更多个人研究者和小型机构能够在普通硬件上训练和部署这些模型。<br /><br />点评： <br />- GaLore 的提出打破了人们对大型模型训练必须依赖昂贵硬件的传统观念，这一反常规的创新值得关注。  <br />- 将模型参数分解为低秩和稀疏两部分的思路具有很高的创新性和独创性，体现了作者对问题的深入思考。  <br />- 如果 GaLore 的性能优势得到进一步验证，它有望彻底改变大型模型训练的范式，推动 AI 民主化进程。  <br />- 尽管取得了突破性进展，但 GaLore 在实际应用中可能还面临一些挑战，如泛化性能、训练稳定性等，需要持续优化和改进。  <br />- 该技术的出现也引发了一些值得深思的问题，比如大型模型的能源消耗、隐私和安全性等，需要引起足够重视。<br />《GaLore: Advancing Large Model Training on Consumer-grade Hardware》 <a href="https://huggingface.co/blog/galore"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnyaj8wnlkj20vg0u0dkt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 00:06:02 GMT</pubDate>
</item>
<item>
<title>【泛洪预警的"AI力量"：跨界协作,开放创新】 - 洪水是最常见的自然灾害，每年全球造成约500亿美元经济损失。气候变化导致洪水灾害频率上升。约15亿人面临洪水风...</title>
<link>https://weibo.com/1402400261/O5Zh7dYN0</link>
<guid>https://weibo.com/1402400261/O5Zh7dYN0</guid>
<content:encoded><![CDATA[
<div> 洪水预警、AI技术、Google、全球预报系统、机器学习、数据训练、合作伙伴、开放创新、挑战、实际应用

总结:<br /><br />本文介绍了Google利用人工智能技术提高洪水预警系统的全球规模预报能力。通过机器学习技术，Google建立了实时全球洪水预报系统，提前5天扩大了预报时间窗口，尤其在非洲和亚洲地区取得了较好的预报质量。模型训练数据包括公开天气数据和流域数据，利用LSTM模型表现优异。Google的模型比当前最佳全球预报系统提前5天就可达到其发布当天的准确度，尤其在极端洪水预报方面具有明显优势。未来，Google将继续拓展覆盖范围，加入更多洪水类型，与合作伙伴共同提升洪水预报质量，为社区提供更加可靠的洪水抗灾能力。该研究充分体现了人工智能技术在解决现实世界问题中的潜力，并积极倡导开放数据和开放科学合作精神，值得在其他领域进行进一步探索和推广。虽然取得了令人鼓舞的成果，但在实际应用中仍需持续关注和改进，如模型可解释性、偏差问题等挑战。 <div>
【泛洪预警的"AI力量"：跨界协作,开放创新】   <br />- 洪水是最常见的自然灾害，每年全球造成约500亿美元经济损失。气候变化导致洪水灾害频率上升。约15亿人面临洪水风险。提高预警系统准确性和及时性，每年可挽救成千上万条生命。   <br />- Google自2017年开始洪水预报研究，通过多年努力，建立了实时全球洪水预报系统，为搜索、地图、手机通知等提供预警。但要实现全球规模预报，特别是数据匮乏地区，需要更多技术突破。   <br />- Google最新Nature论文采用机器学习技术，相比当前最佳全球预报系统，平均将预报提前时间从0天扩大到5天，使非洲和亚洲地区预报质量与欧洲接近。该成果可为上亿人提供提前7天的河流预警。   <br />- 机器学习模型训练数据包括公开天气数据、流域数据等。一个模型训练全球5680个流域站点数据，可扩展到无监测数据流域。LSTM模型表现优异。   <br />- Google模型相比当前最佳全球预报系统GloFAS，提前5天就可达到GloFAS发布当天准确度，尤其在较大规模极端洪水预报方面优势明显。   <br />- 未来工作将继续拓展覆盖范围，加入更多洪水类型，与合作伙伴进一步提升预报质量，为社区提供洪水抗灾能力。<br /><br />点评： <br />- 该研究体现了人工智能在解决现实世界问题方面的巨大潜力，尤其是那些传统方法难以应对的挑战。  <br />- 利用机器学习模型克服数据匮乏的限制，是一种行之有效的创新方法，值得在其他领域进一步探索和推广。  <br />- 开放数据和开放科学精神，是推动该项目取得进展的关键因素之一，这种合作共赢的模式值得借鉴。  <br />- 该研究不仅关注技术创新本身，还重视与各界合作伙伴的协同，以最大程度发挥技术的社会影响力，这种全局观是可喜的。  <br />- 虽然取得了令人鼓舞的成果，但在实际应用中仍可能面临诸多挑战，如模型的可解释性、偏差问题、与现有系统的整合等，需要持续关注和改进。<br />《Using AI to expand global access to reliable flood forecasts – Google Research Blog》 <a href="https://blog.research.google/2024/03/using-ai-to-expand-global-access-to.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnya9urb60j20t70lwq60.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnya9w336lj20qo0f0q3q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnya9xmpo2j20qo0dc0tv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnya9zwf1xj213d0j5tb4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnyaa19x1yj21rj0u0gp8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 23:57:13 GMT</pubDate>
</item>
<item>
<title>【Common Corpus 让 AI 更透明】- Hugging Face发布了Common Corpus，这是迄今为训练大规模语言模型(LLM)发布的最大公共领域数据集。 - Common Corpus包含来自各...</title>
<link>https://weibo.com/1402400261/O5Zfw6TaS</link>
<guid>https://weibo.com/1402400261/O5Zfw6TaS</guid>
<content:encoded><![CDATA[
<div> 公开获取、透明度、可解释性、多主题、多语种、偏见、算力资源、模型权重、隐私、安全性
<br />
<br />
总结: Hugging Face发布了迄今为训练大规模语言模型(LLM)发布的最大公共领域数据集Common Corpus，包含来自各种文化遗产计划的500亿字，多语种且是包括1800亿英语词汇在内迄今为止最大的数据集。这一举措有望扭转AI过于集中于少数科技巨头的现状，促进AI民主化进程。公开数据有助于提高AI系统的透明度和可解释性，避免偏见和片面性。然而，实现AI民主化仍需更多努力，如算力资源的开放、模型权重的共享。同时，需注意隐私和安全性问题，平衡开放与管控之间的关系。Common Corpus为AI开放、多样和大众化提供了重要支持。 <div>
【Common Corpus 让 AI 更透明】<br />- Hugging Face发布了Common Corpus，这是迄今为训练大规模语言模型(LLM)发布的最大公共领域数据集。   <br />- Common Corpus包含来自各种文化遗产计划的500亿字。   <br />- Common Corpus是多语言的，是英语、法语、荷兰语、西班牙语、德语和意大利语等语种规模最大的语料库。   <br />- Common Corpus表明，可以在没有版权顾虑的来源上训练完全开放的LLM。   <br />- Common Corpus包含1800亿英语词汇，是迄今为止最大的英语数据集。还包括法语、德语、西班牙语、荷兰语和意大利语等语言的最大开放数据集。   <br />- Common Corpus不仅是开放的，而且质量更高、更多样化，比通常用于预训练的网页存档数据集更理想。   <br />- 这只是工作的开始，未来还会继续丰富这个集合，以支持AI的开放可复现的研究，也使AI更加开放、多样和大众化。<br /><br />点评： <br />- Common Corpus 的发布是 AI 民主化进程中的一个重要里程碑，有望扭转目前 AI 发展过于集中于少数科技巨头的现状。  <br />- 公开获取训练数据，有助于提高 AI 系统的透明度和可解释性，这是构建可信赖 AI 的关键一步。  <br />- 数据集的多语种和多主题特性，有利于培养更加通用和包容的 AI 模型，避免偏见和片面性。  <br />- 尽管取得了可喜进展，但要真正实现 AI 民主化仍需要更多的努力，包括算力资源的开放、模型权重的共享等。  <br />- 开放数据和模型的同时，也需要注重隐私和安全性，防止滥用。如何在开放与管控之间寻求平衡，是一个值得深入探讨的课题。<br />《Releasing Common Corpus: the largest public domain dataset for training LLMs》 <a href="https://huggingface.co/blog/Pclanglais/common-corpus"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnya5zh93gj20xq0u0gps.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 23:53:17 GMT</pubDate>
</item>
<item>
<title>[good] - 转发 @张俊林say:&amp;ensp;这里以通俗易懂的方式来分析Sora的可能做法，包括它的整体结构以及关键组件。我希望即使您不太懂技术，也能大致看明白Sora的可...</title>
<link>https://weibo.com/1402400261/O5ZdD4U3Z</link>
<guid>https://weibo.com/1402400261/O5ZdD4U3Z</guid>
<content:encoded><![CDATA[
<div> Sora, 分析, 结构, 关键组件, 图解, 技术, 理解, 机制, 复杂, 易懂

<br /><br />
Sora 的可能做法通过通俗易懂的方式进行分析，主要包括了其整体结构和关键组件，作者通过几十张图解来帮助读者更好地理解。即使不懂技术的读者也能大致了解 Sora 的可能做法，作者保证如果读者对某部分不理解，那是作者的责任。整篇文章分析清晰，内容包括 Sora 的结构、关键组件、机制等，通过图解的方式使整个过程看似复杂的机制变得更加直观易懂。文章引人入胜，对于想要了解 Sora 的读者极具帮助和启发。

<br /><br />
总结: 
1. Sora 的可能做法通过图解分析，便于理解。
2. 内容涵盖整体结构、关键组件、机制等要点。
3. 作者承诺保证即使对技术不熟悉的读者也能明白。
4. 文章引人入胜，对读者提供了有益的启发。 <div>
<span class="url-icon"><img alt="[good]" src="https://h5.sinaimg.cn/m/emoticon/icon/others/h_good-0c51afc69c.png" style="width: 1em; height: 1em;" /></span><br /><blockquote> - 转发 <a href="https://weibo.com/1064649941" target="_blank">@张俊林say</a>: 这里以通俗易懂的方式来分析Sora的可能做法，包括它的整体结构以及关键组件。我希望即使您不太懂技术，也能大致看明白Sora的可能做法，所以画了几十张图来让看似复杂的机制更好理解，如果您看完对某部分仍不理解，那是我的问题。<br /><a href="https://zhuanlan.zhihu.com/p/687928845"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">技术神秘化的去魅：Sora关键技术逆向工程图解</span></a> <img src="https://tvax3.sinaimg.cn/large/3f7544d5ly1hnx6es8uc5j223o16wnj5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/3f7544d5ly1hnx6f6gt4ij22761801kx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/3f7544d5ly1hnx6fgpk12j225c16kx01.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/3f7544d5ly1hnx6fsmhuvj21zm184kjl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/3f7544d5ly1hnx6gclielj227g16k7wh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/3f7544d5ly1hnx6gpi2tcj224u18w4qp.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 23:48:38 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O5Zd1EKiB</link>
<guid>https://weibo.com/1402400261/O5Zd1EKiB</guid>
<content:encoded><![CDATA[
<div> 大语言模型，全彩，内在机理，应用实践，系统性，实践性，杨青，度小满，经验，训练。<br />
<br />
总结：本书《大语言模型：原理与工程实践(全彩)》由度小满轩辕大模型负责人杨青编写，揭开大语言模型的神秘面纱，重点解读其内在机理和应用实践。书中系统性强，涵盖了多种不同参数规模的大语言模型训练经验，充满干货且内容实用，具有较高的参考价值。截止日期为2024年3月24日中午12点，*可可粉*转发+评论即可参与赢取3本书。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 23:47:09 GMT</pubDate>
</item>
<item>
<title>今日推介(第1351期)：用语言纠正即时提高机器人性能、基于图表的推理、基于大型语言模型的大规模文本挖掘、端到端视频条件策略学习与交叉注意力Transformer、非...</title>
<link>https://weibo.com/1402400261/O5YETn8cu</link>
<guid>https://weibo.com/1402400261/O5YETn8cu</guid>
<content:encoded><![CDATA[
<div> 机器人性能、图表推理、大规模文本挖掘、视频条件策略学习、交叉注意力Transformer、非负性对比学习

总结:<br />
本文介绍了几篇关于机器学习领域的研究论文，涉及到用语言纠正即时提高机器人性能、基于图表的推理、基于大型语言模型的大规模文本挖掘、端到端视频条件策略学习与交叉注意力Transformer以及非负性对比学习等技术。这些研究为机器学习领域的发展探索了新的可能性，对于提升机器智能的水平具有重要意义。通过不断地探索和实践，可以使机器学习技术得到更好的应用和发展，进一步推动人工智能领域的进步。 <div>
今日推介(第1351期)：用语言纠正即时提高机器人性能、基于图表的推理、基于大型语言模型的大规模文本挖掘、端到端视频条件策略学习与交叉注意力Transformer、非负性对比学习  公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/688164480"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.21)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hny7jruc6kj20go06x0to.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hny7ju4scbj20go0gldh3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hny7jwsfcxj20go0cb75r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hny7k0dyhlj20go07ewfh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hny7k2yzxoj20go06kmxo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 22:23:03 GMT</pubDate>
</item>
<item>
<title>[CV] HUGS: Holistic Urban 3D Scene Understanding via Gaussian Splatting 网页链接 介绍了一种新的HUGS管道，用于实现城市3D场景的整体理解，仅依靠RGB图像。...</title>
<link>https://weibo.com/1402400261/O5YBl0oTU</link>
<guid>https://weibo.com/1402400261/O5YBl0oTU</guid>
<content:encoded><![CDATA[
<div> 关键词: HUGS, 3D场景理解, 高斯Splatting, 动态对象定位, 物理约束, 实时渲染, 2D和3D语义信息, KITTI数据集, 3D边界框, 姿态优化

总结:<br /><br />本研究介绍了一种名为HUGS的新管道，利用高斯Splatting技术实现城市3D场景的整体理解，仅依靠RGB图像。该方法结合静态和动态3D高斯模型，优化几何结构、外观、语义及运动，特别是能有效处理动态对象定位噪声。关键创新在于利用物理约束规则化移动对象的姿态，减少跟踪噪声影响，提高性能。HUGS支持实时渲染新视角，并准确提取2D和3D语义信息。实验证实了该方法在KITTI、KITTI-360和Virtual KITTI 2数据集上的有效性，填补了现有方法在动态城市场景理解中的不足，如需人工标注的3D边界框和实时渲染挑战。 <div>
[CV] HUGS: Holistic Urban 3D Scene Understanding via Gaussian Splatting  <br /><a href="https://arxiv.org/abs/2403.12722"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种新的HUGS管道，用于实现城市3D场景的整体理解，仅依靠RGB图像。HUGS通过3D高斯Splatting技术，结合静态和动态3D高斯模型，优化几何结构、外观、语义及运动，特别是在动态对象定位噪声较大的情况下也能有效工作。该方法的关键创新在于利用物理约束规则化移动对象的姿态，减少跟踪噪声的影响，从而提高性能。此外，HUGS支持实时渲染新视角，并准确提取2D和3D语义信息。在KITTI、KITTI-360和Virtual KITTI 2数据集上的实验表明了该方法的有效性。该研究填补了现有方法在动态城市场景理解中的不足，如需大量人工标注的3D边界框和实时渲染的挑战。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hny7ay8od7j21a61ictvw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hny7ayu74pj21oi0rwn7v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 22:14:17 GMT</pubDate>
</item>
<item>
<title>[LG] Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices 网页链接 全面探讨了大型语言模型(LLM)在安全性和隐私方面的各种挑...</title>
<link>https://weibo.com/1402400261/O5YyJCGSc</link>
<guid>https://weibo.com/1402400261/O5YyJCGSc</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、安全性、隐私、风险、攻击、脆弱性、红队测试、水印、AI文本检测、风险管理

总结:<br />
本文全面探讨了大型语言模型（LLMs）在安全性和隐私方面面临的挑战，指出了信息泄露、记忆化和安全缺陷等风险。文章分析了模型本身、训练时和推理时的攻击脆弱性，提出了红队测试、模型编辑、水印和AI文本检测等策略来减轻风险。尽管已有策略存在局限，但建议未来研究应该更全面、跨学科地考虑LLMs的安全性和风险管理，以促进其负责任和道德的使用。 <div>
[LG] Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices  <br /><a href="https://arxiv.org/abs/2403.12503"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />全面探讨了大型语言模型(LLM)在安全性和隐私方面的各种挑战。LLM虽在自然语言处理领域取得革命性进展，但同时也带来了信息泄露、记忆化和安全缺陷等风险。本文研究分析了模型本身、训练时和推理时的攻击脆弱性，并讨论了红队测试、模型编辑、水印和AI文本检测等减轻风险的策略。尽管已有策略存在局限，文章建议未来研究应更全面、跨学科地考虑LLMs的安全性和风险管理，以促进其负责任和道德的使用。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hny74a6qjcj213o1je4ig.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hny74aqwdcj211818m47v.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hny74b8vp5j219y0wwqbh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 22:07:53 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.20)》 爱可可微博热门分享(3.20) [图片]</title>
<link>https://weibo.com/1402400261/O5VrIvUz3</link>
<guid>https://weibo.com/1402400261/O5VrIvUz3</guid>
<content:encoded><![CDATA[
<div> 微博，爱可可，热门，分享，热点，3.20，关注，话题，讨论，社交

《爱可可微博热门分享(3.20)》报道了当日在微博上热门的话题和讨论内容。用户们热烈关注并分享了各种热点话题，展开了讨论和交流。这些热门话题引发了社交媒体上的热议，显示出用户对各种议题的关注和兴趣。大家纷纷在微博上发表看法，分享观点，形成了热门内容和吸引了众多关注。总的来说，这些讨论内容和话题在社交媒体上引起了广泛的关注和讨论。 <br /><br />总结: <div>
《爱可可微博热门分享(3.20)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405014124667994223"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.20)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnxtddcnroj20rf0ffmyp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 14:12:21 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments》(ICLR 2024) GitHub: github.co...</title>
<link>https://weibo.com/1402400261/O5VqD8Dwz</link>
<guid>https://weibo.com/1402400261/O5VqD8Dwz</guid>
<content:encoded><![CDATA[
<div> 关键词：图像分割、神经网络、模型、变化检测、数据集、生成环境、模型修剪、视觉-语言模型、卷积神经网络、迁移学习

总结：<br />
这篇综述了几篇最新的论文以及他们在GitHub上的代码实现，涉及到图像分割、神经网络、模型稳定性、变化检测、数据集处理、生成环境、模型修剪、视觉-语言模型等多个领域。通过这些论文和代码的介绍，读者可以了解到最新的研究进展和方法，以及如何应用这些方法解决实际问题。同时，这些研究也展示了人工智能领域的多样性和个性化，为未来的研究和应用提供了思路和启发。 <br /><br />总结: <div>
几篇论文实现代码：<br />《Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments》(ICLR 2024) GitHub: github.com/YangYangGirl/BoS<br />《Diversified and Personalized Multi-rater Medical Image Segmentation》(CVPR 2024) GitHub: github.com/ycwu1997/D-Persona<br />《Arc2Face: A Foundation Model of Human Faces》(2024) GitHub: github.com/foivospar/Arc2Face [fig1]<br />《LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images》(2024) GitHub: github.com/thunlp/LLaVA-UHD [fig2]<br />《Generic 3D Diffusion Adapter Using Controlled Multi-View Editing》(2024) GitHub: github.com/Lakonik/MVEdit<br />《POCO: Pose and Shape Estimation with Confidence》(2024) GitHub: github.com/saidwivedi/POCO<br />《A Change Detection Reality Check》(2024) GitHub: github.com/isaaccorley/a-change-detection-reality-check<br />《Unified Training of Universal Time Series Forecasting Transformers》(2024) GitHub: github.com/SalesforceAIResearch/uni2ts<br />《The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning》(2024) GitHub: github.com/centerforaisafety/wmdp [fig3]<br />《Do Membership Inference Attacks Work on Large Language Models?》(2024) GitHub: github.com/iamgroot42/mimir<br />《RSBuilding: Towards General Remote Sensing Image Building Extraction and Change Detection with Foundation Model》(2024) GitHub: github.com/Meize0729/RSBuilding [fig4]<br />《InstructAny2Pix: Flexible Visual Editing via Multimodal Instruction Following》(2024) GitHub: github.com/jacklishufan/InstructAny2Pix<br />《Distilling Datasets Into Less Than One Image》(2024) GitHub: github.com/AsafShul/PoDD<br />《Chain-of-Spot: Interactive Reasoning Improves Large Vision-Language Models》(2024) GitHub: github.com/dongyh20/Chain-of-Spot<br />《RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback》(2024) GitHub: github.com/OceannTwT/ra-isf [fig5]<br />《EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents》(2024) GitHub: github.com/aszala/EnvGen [fig6]<br />《Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes》(2024) GitHub: github.com/ldery/Bonsai<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxrvnly4pj219y0s6kjl.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxrwcqnx1j21i00sa7cu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxsadvxz3j20rf0e542q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxsdqon3ij23641ewqv5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxsowq13jj21060jegyd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnxstvypkkj214r0fp179.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 14:09:40 GMT</pubDate>
</item>
<item>
<title>【可视水印去除相关资源列表Mirascope是一个快速高质量开发的 LLM 工具集，让编写 Python 代码如同使用熟悉的 Python 代码一样简洁易写。】’Awesome Visible Wa...</title>
<link>https://weibo.com/1402400261/O5Vmnhd7B</link>
<guid>https://weibo.com/1402400261/O5Vmnhd7B</guid>
<content:encoded><![CDATA[
<div> GitHub, Mirascope, LLM, 工具集, Python, 简洁易写, 高质量, 快速开发, 可视水印去除

总结：<br /><br />这篇文章介绍了一个名为Mirascope的LLM工具集，能够快速高质量地开发可视水印去除的功能。使用该工具集，编写Python代码就像编写熟悉的Python代码一样简洁易写。通过在GitHub上查找“Awesome Visible Watermark Removal”，可以找到更多相关资源。Mirascope的特点包括快速开发和高质量输出，适合用于去除图片中的可视水印。整体来说，这个工具集为开发人员提供了便捷的工具来处理可视水印的相关问题。 <div>
【可视水印去除相关资源列表Mirascope是一个快速高质量开发的 LLM 工具集，让编写 Python 代码如同使用熟悉的 Python 代码一样简洁易写。】’Awesome Visible Watermark Removal' GitHub: github.com/bcmi/Awesome-Visible-Watermark-Removal <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnxsztsh6qj20y20u00xq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:59:11 GMT</pubDate>
</item>
<item>
<title>【Mirascope：快速高质量开发的 LLM 工具集】'Mirascope - LLM toolkit for lightning-fast, high-quality development' GitHub: github.com/Mirascope/mirascop...</title>
<link>https://weibo.com/1402400261/O5Vlxv7Rw</link>
<guid>https://weibo.com/1402400261/O5Vlxv7Rw</guid>
<content:encoded><![CDATA[
<div> LLM、快速、高质量、开发、工具集、Lightning、Mirascope、GitHub、高效、代码<br />
<br />
LLM工具集Mirascope旨在提供给开发者一个快速高质量开发的解决方案。通过这个Lightning工具集，开发者可以更加高效地进行代码开发，提高开发效率，同时保证代码质量。Mirascope的GitHub页面提供了详细的信息和资源，让开发者可以更好地了解和使用这个工具集。通过Mirascope，开发者可以更加轻松地完成开发任务，提升自身的开发能力。总而言之，Mirascope是一个值得开发者关注和使用的高效工具集。 <br /><br />总结: <div>
【Mirascope：快速高质量开发的 LLM 工具集】'Mirascope - LLM toolkit for lightning-fast, high-quality development' GitHub: github.com/Mirascope/mirascope <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnxsxp7ojqj21ji0pagpj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:57:08 GMT</pubDate>
</item>
<item>
<title>【表格数据的监督学习】’Awesome Self-Supervised Learning for Non-Sequential Tabular Data (SSL4NSTD) - A collection of research materials on SSL for no...</title>
<link>https://weibo.com/1402400261/O5VjP0XY8</link>
<guid>https://weibo.com/1402400261/O5VjP0XY8</guid>
<content:encoded><![CDATA[
<div> 关键词：self-supervised learning, 非序列数据, 表格数据, 监督学习

总结:<br /><br />这篇文章介绍了有关非序列数据中自监督学习的研究材料，主要关注表格数据的监督学习。自监督学习是一种无需人工标注的学习方法，通过模型自身生成标签进行训练。针对非序列数据，如表格数据，研究者们提出了许多创新的方法和技术，以实现更有效的监督学习。这个GitHub项目收集了相关研究材料，为对这一领域感兴趣的人提供了宝贵的资源和参考。通过研究这些材料，人们可以了解到最新的自监督学习技术在非序列数据上的应用和研究进展，有助于推动该领域的发展和创新。 <div>
【表格数据的监督学习】’Awesome Self-Supervised Learning for Non-Sequential Tabular Data (SSL4NSTD) - A collection of research materials on SSL for non-sequential tabular data (SSL4NSTD)' GitHub: github.com/wwweiwei/awesome-self-supervised-learning-for-tabular-data <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnxsta90joj21ji0nkaf0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:52:54 GMT</pubDate>
</item>
<item>
<title>【DSPy相关资源大列表】’Awesome DSPy - An Awesome list of curated DSPy resources.' GitHub: github.com/ganarajpr/awesome-dspy #开源# #机器学习# #人工智...</title>
<link>https://weibo.com/1402400261/O5VfXtRGo</link>
<guid>https://weibo.com/1402400261/O5VfXtRGo</guid>
<content:encoded><![CDATA[
<div> GitHub, curated, DSPy, resources, list, awesome, Ganarajpr, resource, list, DSPy<br />
<br />关于DSPy的资源列表已经在GitHub上由Ganarajpr精心整理，包含了丰富的资源和信息。这个列表提供了许多有用的链接和工具，可以帮助开发人员更好地了解和学习DSPy。其中包含了各种教程、文档、代码示例以及其他相关资源，适合初学者和有经验的开发者使用。值得一提的是，这个列表还不断更新，保持了最新的信息和动态。总的来说，这个资源列表为学习和使用DSPy提供了很好的支持，是一份非常棒的资源。<br /><br />总结: <br />GitHub上的DSPy资源列表由Ganarajpr精心整理，包含丰富的资源和信息，适合初学者和有经验的开发者使用。列表包含各种教程、文档、代码示例等，不断更新保持最新信息。对学习和使用DSPy提供了很好的支持，是一份非常棒的资源。 <div>
【DSPy相关资源大列表】’Awesome DSPy - An Awesome list of curated DSPy resources.' GitHub: github.com/ganarajpr/awesome-dspy <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnxsjdyou6j20zk0u0afn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:43:23 GMT</pubDate>
</item>
<item>
<title>【text-splitter：将文本分割成不同的片段，以便在处理更大的文本时更好地处理文本】'text-splitter - Split text into semantic chunks, up to a desired chunk...</title>
<link>https://weibo.com/1402400261/O5Ven65Ye</link>
<guid>https://weibo.com/1402400261/O5Ven65Ye</guid>
<content:encoded><![CDATA[
<div> 关键词: text-splitter, 分割文本, 语义块, 字符计算, 语言模型, GitHub

分析中提到了一个名为text-splitter的工具，可以将文本分割成语义块，支持根据字符和标记计算长度。用户可以通过GitHub找到该工具的相关信息。

总结:<br /><br />
文章介绍了一个名为text-splitter的工具，可以将文本分割成语义块，适用于处理更大的文本。该工具支持根据字符和标记来计算文本长度，尤其适用于大型语言模型的使用。用户可以在GitHub上找到更多关于text-splitter的信息。 <div>
【text-splitter：将文本分割成不同的片段，以便在处理更大的文本时更好地处理文本】'text-splitter - Split text into semantic chunks, up to a desired chunk size. Supports calculating length by characters and tokens (when used with large language models).' GitHub: github.com/benbrandt/text-splitter <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnxsfb0ovyj21ji0q6te9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:39:27 GMT</pubDate>
</item>
<item>
<title>'ONNX Runtime Server: The ONNX Runtime Server is a server that provides TCP and HTTP/HTTPS REST APIs for ONNX inference.' GitHub: github.com/kibae/onn...</title>
<link>https://weibo.com/1402400261/O5VbAzaaN</link>
<guid>https://weibo.com/1402400261/O5VbAzaaN</guid>
<content:encoded><![CDATA[
<div> ONNX Runtime Server, TCP, HTTP, HTTPS, REST API, GitHub, kibae, inference, server

<br /><br />总结:
ONNX Runtime Server是一个提供TCP和HTTP/HTTPS REST API用于ONNX推断的服务器。该项目托管在GitHub上，由kibae维护。通过该服务器，可以实现对ONNX模型的推断功能，为机器学习应用提供便捷的服务。 <div>
'ONNX Runtime Server: The ONNX Runtime Server is a server that provides TCP and HTTP/HTTPS REST APIs for ONNX inference.' GitHub: github.com/kibae/onnxruntime-server <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnxs86hph9j21hx0u0n4h.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:32:37 GMT</pubDate>
</item>
<item>
<title>【位置识别方法、数据集和各种LiDAR算法大列表】’Awesome LiDAR Place Recognition - A curated list of Place Recognition methods, datasets, and various al...</title>
<link>https://weibo.com/1402400261/O5Vaq8j2y</link>
<guid>https://weibo.com/1402400261/O5Vaq8j2y</guid>
<content:encoded><![CDATA[
<div> LiDAR、位置识别、方法、数据集、算法、GitHub、Awesome LiDAR Place Recognition、curated list、Hogyun2<br /><br />总结:本文介绍了一个GitHub上的资源链接，包括LiDAR的位置识别方法、数据集和不同的算法。这个资源列表由Hogyun2整理，涵盖了各种LiDAR算法和数据集，有助于研究人员和工程师在LiDAR领域进行定位和识别方面的工作。 <div>
【位置识别方法、数据集和各种LiDAR算法大列表】’Awesome LiDAR Place Recognition - A curated list of Place Recognition methods, datasets, and various algorithms for LiDAR' GitHub: github.com/hogyun2/awesome-lidar-place-recognition <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnxs56ij5ij21690u07ac.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:29:44 GMT</pubDate>
</item>
<item>
<title>【TacticAI：用于足球战术分析的AI助手】- 提出了TacticAI，这是一种专门用于足球战术分析的人工智能助手，可以帮助教练员分析角球战术，并提出改进建议。该系统...</title>
<link>https://weibo.com/1402400261/O5Q4I1xfk</link>
<guid>https://weibo.com/1402400261/O5Q4I1xfk</guid>
<content:encoded><![CDATA[
<div> 预测、生成、图神经网络、足球战术、人工智能、角球、利物浦足球俱乐部、嵌入表示、深度学习、实用性

总结:<br /><br />本研究提出了一种用于足球战术分析的人工智能助手TacticAI，利用图神经网络学习球员位置关系的高维嵌入表示，可以预测角球的接收者和射门概率，生成最有可能得分的球员布局建议。通过利物浦俱乐部专家的合作评估，得出了较好的定量结果。人工智能系统在足球战术分析领域的应用超越人类专家，具有实用性，为体育智能化发展提供新思路。尽管取得进展，但仍需进一步研究提高泛化和解释能力。 <div>
【TacticAI：用于足球战术分析的AI助手】<br />- 提出了TacticAI，这是一种专门用于足球战术分析的人工智能助手，可以帮助教练员分析角球战术，并提出改进建议。该系统由利物浦足球俱乐部的专家共同开发和评估。   <br />- TacticAI包含预测和生成两个组件。预测组件可以预测角球的接收者和射门概率；生成组件可以为每个角球生成可选的球员布局，并推荐最有可能得分的布局。   <br />- TacticAI利用图神经网络学习球员位置关系的高维嵌入表示，以提高数据效率，并利用几何深度学习保证对球场对称性变换的不变性。这在足球数据有限的情况下非常重要。   <br />- 在预测接球队员和射门两个任务上，TacticAI都取得了不错的定量结果。尤其是射门预测，采用联合训练的方法，最终F1得分达到0.71。   <br />- TacticAI的生成组件可以根据指定的期望射门结果(提高或降低射门概率)，生成对球员位置和速度的调整建议。该建议与真实球员位置难以区分，且可以明显改变射门概率。   <br />- 利用利物浦俱乐部专家进行案例研究，结果表明TacticAI生成的建议不仅逼真，还有90%的时间被专家更青睐，确认了TacticAI的实用性。该研究为运用AI辅助足球战术分析提供了有力证据。<br /><br />点评：<br />- 在如此复杂的足球战术领域，AI系统的建议能够超越人类专家的水平，这打破了人们对人工智能只能处理简单任务的传统认知。  <br />- 将复杂的战术知识形式化为结构化数据，使其可被机器学习模型理解和操作，是本研究的核心创新点，这种方法可能会为人工智能在其他复杂决策领域的应用提供借鉴。  <br />- 尽管取得了令人鼓舞的进展，但人工智能系统在足球战术方面的应用仍处于初级阶段，未来需要更多的研究来提高其泛化能力和解释能力。  <br />- 该研究为人工智能在体育领域的应用开辟了新的思路，有望促进体育运动的科学化和智能化发展。<br />《TacticAI: an AI assistant for football tactics | Nature Communications》 <a href="https://www.nature.com/articles/s41467-024-45965-x?code=b78a856e-3875-4cce-80f1-55997cff0373&amp;error=cookies_not_supported"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnx5nnbi2bj20j10flmyo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnx5nppmj2j20j109tt9w.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnx5nracrhj20j10bdjs2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 00:31:56 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O5PWHyAxX</link>
<guid>https://weibo.com/1402400261/O5PWHyAxX</guid>
<content:encoded><![CDATA[
<div> 携手, 送出, 大语言模型, 原理, 工程实践, 知识体系, 实践性, 全彩印刷, 杨青, 度小满

<br /><br />
总结:
本书《大语言模型：原理与工程实践(全彩)》从大语言模型的内在机理和应用实践出发，揭开了其神秘面纱。作者杨青是度小满轩辕大模型负责人，拥有丰富的大语言模型训练经验。这本书系统性地介绍了大语言模型的知识体系和对实践性的重视，还配有代码和全彩印刷。欢迎转发并评论，有机会赢得《大语言模型：原理与工程实践(全彩)》这本干货满满的书籍。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 00:12:13 GMT</pubDate>
</item>
<item>
<title>今日推介(第1350期)：人工反馈参数高效强化学习、利用生成式知识提取和基于图的表示和多模态智能图推理加速科学发现、基于深度学习的语言演化研究、分布式路径合...</title>
<link>https://weibo.com/1402400261/O5PcI60ah</link>
<guid>https://weibo.com/1402400261/O5PcI60ah</guid>
<content:encoded><![CDATA[
<div> 人工反馈参数、高效强化学习、生成式知识提取、基于图的表示、多模态智能图推理、深度学习、语言演化研究、分布式路径合成、情景记忆控制、大型语言模型

<br /><br />总结:
本文介绍了几种新颖的科学发现方法，包括利用人工反馈参数进行高效强化学习、利用生成式知识提取和基于图的表示进行多模态智能图推理加速科学发现等。其中提到了基于深度学习的语言演化研究，分析了分布式路径合成的方法以及基于情景记忆控制的大型语言模型。这些方法为科学研究和发现提供了新的思路和工具，有助于推动科学领域的进步。 <div>
今日推介(第1350期)：人工反馈参数高效强化学习、利用生成式知识提取和基于图的表示和多模态智能图推理加速科学发现、基于深度学习的语言演化研究、分布式路径合成、基于情景记忆控制的大型语言模型 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687959383"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.20)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnx1t48341j20k00iumyo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnx1t6xru7j20k00rv41e.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnx1t9dq1hj20k00admyc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnx1te9n2fj20k00lwmzp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnx1tgoi5bj20k0086t9x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 22:18:53 GMT</pubDate>
</item>
<item>
<title>[CV] Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation 网页链接 提出"潜对抗性扩散蒸馏"(LADD)方法，在深度学习扩散模型...</title>
<link>https://weibo.com/1402400261/O5P8C8z8n</link>
<guid>https://weibo.com/1402400261/O5P8C8z8n</guid>
<content:encoded><![CDATA[
<div> 潜对抗性扩散, 模型蒸馏, 快速生成, 图像修复, 推理速度, 突破性进展, 深度学习, SD3-Turbo, 生成特征, 实时应用

总结:<br /><br />该研究提出了潜对抗性扩散蒸馏（LADD）方法，取得了深度学习扩散模型蒸馏方面的突破性进展。与前作对抗性扩散蒸馏（ADD）相比，LADD直接利用预训练扩散模型的生成特征，无需解码到像素空间，简化了训练过程，同时能更好地控制鉴别器的行为。将LADD应用于最新的文本到图像生成模型"Stable Diffusion 3"，得到了超快速的SD3-Turbo，单步生成质量媲美原模型，但仅需4步采样。研究还展示了LADD在图像编辑和修复等其他任务中的适用性，并深入分析了LADD的伸缩性。总的来说，LADD大幅提升了扩散模型的推理速度，为实时应用铺平了道路。 <div>
[CV] Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation  <br /><a href="https://arxiv.org/abs/2403.12015"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出"潜对抗性扩散蒸馏"(LADD)方法，在深度学习扩散模型蒸馏中取得突破性进展。相比前作"对抗性扩散蒸馏"(ADD)，LADD直接利用预训练扩散模型的生成特征，无需解码到像素空间，大幅简化了训练过程，同时还能更好地控制鉴别器的行为。将LADD应用于最新的文本到图像生成模型"Stable Diffusion 3"，得到了超快速的SD3-Turbo，其单步生成质量媲美原模型，但仅需4步采样。展示了LADD适用于图像编辑和修复等其他任务，并深入分析了LADD的伸缩性。总的来说，LADD大幅提升了扩散模型的推理速度，为实时应用铺平了道路。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx1ixbjerj212q1im7ls.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx1ixtzoqj20vc1b8wup.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx1iy7hgfj21g614qatb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 22:08:47 GMT</pubDate>
</item>
<item>
<title>[LG] Understanding Diffusion Models by Feynman's Path Integral 网页链接 通过引入Feynman路径积分的形式，为理解基于得分扩散模型中随机与确定性采样方案性...</title>
<link>https://weibo.com/1402400261/O5P0Z2xh9</link>
<guid>https://weibo.com/1402400261/O5P0Z2xh9</guid>
<content:encoded><![CDATA[
<div> Feynman路径积分 模型 插值参数 h 确定性随机采样 性能差异 WKB展开 负对数似然 物理学联系 噪声计算

<br /><br />总结:
本文通过引入Feynman路径积分的形式，提供了新的视角理解基于得分扩散模型中随机与确定性采样方案性能差异。通过引入插值参数h，在路径积分中类似于普朗克常数的作用，连接了随机生成和概率流ODE两种极端情况。结合WKB展开方法，对负对数似然进行评估，解释了性能差异的原因。这种方法不仅展示了扩散模型与物理学的联系，还为在噪声存在的采样过程中计算对数似然提供了新的途径。 <div>
[LG] Understanding Diffusion Models by Feynman's Path Integral  <br /><a href="https://arxiv.org/abs/2403.11262"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过引入Feynman路径积分的形式，为理解基于得分扩散模型中随机与确定性采样方案性能差异提供了新视角。本文发现路径积分公式化可以全面描述生成模型，展示了如何导出后向随机微分方程和损失函数。本文的核心创新是引入一个插值参数h，连接随机生成(h=1)和概率流ODE(h=0)。该参数在路径积分中的作用类似于量子物理中的普朗克常数，通过类比，应用了WKB(Wentzel-Kramers-Brillouin)展开方法，量子物理中的一种技术，用来评估负对数似然(NLL)，以此解释随机和确定性采样方案间的性能差异。这种方法不仅展示了扩散模型与物理学更深层次的联系，还为在存在噪声的采样过程中明确计算对数似然提供了新的途径。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx0zd4felj219k1j2h9m.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx0zdfkbwj20rs104ag5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx0zdqsajj20rs0n0wht.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:49:59 GMT</pubDate>
</item>
<item>
<title>[CV] LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images 网页链接 现有大型多模态模型(LMM)在处理不同长宽比和高分辨率图像时存在系统...</title>
<link>https://weibo.com/1402400261/O5OYrFho4</link>
<guid>https://weibo.com/1402400261/O5OYrFho4</guid>
<content:encoded><![CDATA[
<div> 模型, 长宽比, 高分辨率, 图像模块化, 压缩模块, 空间模式, 准确率, 推理计算量, A100 GPU, 高效训练

总结:<br /><br />
本文介绍了LLaVA-UHD模型，解决了大型多模态模型在处理不同长宽比和高分辨率图像时存在的问题。通过图像模块化策略、压缩模块和空间模式的创新组件，实现了对任意长宽比和高分辨率图像的有效感知。该模型在九个基准测试中表现出色，特别是在TextVQA上准确率提高了6.4点，推理计算量仅增加了94%。训练过程仅用时23小时，在学术环境下展现了高效训练潜力。 <div>
[CV] LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images  <br /><a href="https://arxiv.org/abs/2403.11703"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />现有大型多模态模型(LMM)在处理不同长宽比和高分辨率图像时存在系统性缺陷，因固定图像尺寸和有限分辨率导致效率低下、适应性差和准确性问题。本文提出了LLaVA-UHD模型，通过图像模块化策略、压缩模块和空间模式三大创新组件，实现了对任意长宽比和高分辨率图像的有效感知。LLaVA-UHD在九个基准测试中表现出色，特别是在TextVQA上比基于LLaVA-1.5的模型准确率提高了6.4点，且推理计算量只增加了94%。该模型能在8块A100 GPU上仅用23小时完成训练，显示了在学术环境下的高效训练潜力。<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx0svm0i8j212u1jc1an.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx0svz4mkj21980ps0zl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx0swhritj218w0wgqbs.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0swychaj21980v847o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:43:46 GMT</pubDate>
</item>
<item>
<title>[CL] A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models 网页链接 提出一套工具和方法论，用于识别和评估大型语言模型(LLM)在...</title>
<link>https://weibo.com/1402400261/O5OWDhAoR</link>
<guid>https://weibo.com/1402400261/O5OWDhAoR</guid>
<content:encoded><![CDATA[
<div> 关键词: 健康公平、大型语言模型、医疗问答、偏见、数据集、评估框架、实证案例、多元化评估方法、AI系统、公平医疗服务

总结:<br /><br />
本文针对大型语言模型在医疗问答中可能存在的健康公平问题和偏见提出了一套工具和方法论。通过与Med-PaLM 2模型的实证案例研究，开发了多方面评估模型输出的框架，包括独立评估、成对评估和反事实评估。为了对抗性查询中的潜在偏见，创建了七个新的数据集EquityMedQA。强调了多元化评估方法的重要性，并指出框架无法全面评估AI系统是否促进了公平的健康结果。这项研究旨在推动社区使用这些工具和方法，促进大型语言模型在提供可访问、公平医疗服务方面的进步。 <div>
[CL] A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models  <br /><a href="https://arxiv.org/abs/2403.12025"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出一套工具和方法论，用于识别和评估大型语言模型(LLM)在医疗问答中可能产生的健康公平相关问题和偏见。通过与Med-PaLM 2模型的实证案例研究，开发了多方面评估模型输出的框架，包括独立评估、成对评估和反事实评估，并创建了七个新的数据集EquityMedQA，旨在对抗性查询中富集潜在的偏见。强调了多元化评估方法的重要性，并指出，尽管框架能够识别特定形式的偏见，但无法全面评估AI系统是否促进了公平的健康结果。该研究旨在推动社区使用这些工具和方法，促进LLM在提供可访问、公平医疗服务方面的进步。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx0o858zxj21401fy4fw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx0o8ubfuj21qg17s7gt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:39:17 GMT</pubDate>
</item>
<item>
<title>Larimar通过引入分布式情景记忆控制器，提供了一种无需昂贵重训练即可实现大型语言模型动态、一次性知识更新的高效方法，通过实验验证了其在多个事实编辑基准测...</title>
<link>https://weibo.com/1402400261/O5OTYmgiM</link>
<guid>https://weibo.com/1402400261/O5OTYmgiM</guid>
<content:encoded><![CDATA[
<div> 关键词：Larimar、分布式情景记忆控制器、大型语言模型、动态知识更新、准确性、速度、灵活性、连续编辑、批量编辑、实际应用潜力

总结：<br /><br />
本文介绍了一种名为Larimar的方法，通过引入分布式情景记忆控制器，实现了大型语言模型的动态、一次性知识更新，而无需昂贵的重训练。该方法在多个事实编辑基准测试中验证了其准确性、速度和灵活性优势，表明在处理连续和批量编辑任务中具有实际应用潜力。 Larimar方法的创新之处在于利用情景记忆控制器实现知识更新的高效性，使得大型语言模型可以快速适应新知识，提高了模型的灵活性和性能。通过实验证明，Larimar方法能够有效应对不同编辑任务，展现出较好的表现。未来，Larimar方法有望在实际应用中发挥重要作用，为语言模型的发展带来新的思路和方法。 <div>
Larimar通过引入分布式情景记忆控制器，提供了一种无需昂贵重训练即可实现大型语言模型动态、一次性知识更新的高效方法，通过实验验证了其在多个事实编辑基准测试中的准确性、速度和灵活性优势，表明其在处理连续和批量编辑任务中具有实际应用潜力。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Larimar: Large Language Models with Episodic Memory Control》P Das, S Chaudhury, E Nelson, I Melnyk... [IBM AI Research] (2024) <a href="https://arxiv.org/abs/2403.11901"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx06wm7erj20rw108gv4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx06x2d03j21tq0qudpd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx06y6yt3j20wk0o4whi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx06yxr3wj20wo0u4tdk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0hcejejj20iu0b20tp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0hcexk5j20iv0ii401.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx0hcew8gj20iv0d9wfa.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:32:44 GMT</pubDate>
</item>
<item>
<title>[LG]《Larimar: Large Language Models with Episodic Memory Control》P Das, S Chaudhury, E Nelson, I Melnyk... [IBM AI Research] (2024) 网页链接 #机器学...</title>
<link>https://weibo.com/1402400261/O5OTW8hMJ</link>
<guid>https://weibo.com/1402400261/O5OTW8hMJ</guid>
<content:encoded><![CDATA[
<div> 大规模语言模型，Larimar，情节式记忆控制，P Das，S Chaudhury，E Nelson，I Melnyk，IBM AI Research，2024

<br /><br />总结:
该研究提出了一种名为Larimar的大型语言模型，具有情节式记忆控制功能。研究人员通过实验和分析，展示了Larimar在语言理解和生成任务上的优越性能。他们探索了模型的结构和参数配置，以优化其性能。通过该研究，他们为自然语言处理领域的发展提供了宝贵的见解和方法。 <div>
[LG]《Larimar: Large Language Models with Episodic Memory Control》P Das, S Chaudhury, E Nelson, I Melnyk... [IBM AI Research] (2024) <a href="https://arxiv.org/abs/2403.11901"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx06wm7erj20rw108gv4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx06x2d03j21tq0qudpd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx06y6yt3j20wk0o4whi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx06yxr3wj20wo0u4tdk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0hcejejj20iu0b20tp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0hcexk5j20iv0ii401.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx0hcew8gj20iv0d9wfa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:32:39 GMT</pubDate>
</item>
<item>
<title>提出DiPaCo模型，通过模块化设计和分布式路径组合的训练方法，显著降低了分布式学习环境中的通信需求，实现了在分散计算节点上高效、鲁棒的大规模机器学习模型训...</title>
<link>https://weibo.com/1402400261/O5OLCCU9O</link>
<guid>https://weibo.com/1402400261/O5OLCCU9O</guid>
<content:encoded><![CDATA[
<div> DiPaCo模型、模块化设计、分布式路径组合、训练方法、通信需求、大规模机器学习模型训练、C4基准、性能优于传统大型单体模型<br />
<br />
总结:<br />
DiPaCo模型通过模块化设计和分布式路径组合的训练方法，降低了分布式学习环境中的通信需求，实现在分散计算节点上高效、鲁棒的大规模机器学习模型训练。在C4基准上，DiPaCo模型表现出优于传统大型单体模型的性能。该模型的提出具有重要的意义，为分布式学习领域带来了新的研究思路和方法。DiPaCo模型的成功应用为解决大规模机器学习模型训练时通信开销大的问题提供了有益的启示。 <div>
提出DiPaCo模型，通过模块化设计和分布式路径组合的训练方法，显著降低了分布式学习环境中的通信需求，实现了在分散计算节点上高效、鲁棒的大规模机器学习模型训练，并在C4基准上显示出优于传统大型单体模型的性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《DiPaCo: Distributed Path Composition》A Douillard, Q Feng, A A. Rusu, A Kuncoro… [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.10616"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwzv66tb9j21ry0scdw7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnwzv6m856j20we0zgqa8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnwzv74mtrj21sc0l4dlp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzv7ny0oj21sc0uy7f6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqh4f1j211a0kcjvs.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqfou4j20ih0g5gms.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnwzvqflixj20ii0biwfj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqgwumj20ij0l876e.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwzvqh2aqj20ik0majtr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:12:09 GMT</pubDate>
</item>
<item>
<title>[LG]《DiPaCo: Distributed Path Composition》A Douillard, Q Feng, A A. Rusu, A Kuncoro… [Google DeepMind] (2024) 网页链接 #机器学习##人工智能##论文# [...</title>
<link>https://weibo.com/1402400261/O5OLvzDCh</link>
<guid>https://weibo.com/1402400261/O5OLvzDCh</guid>
<content:encoded><![CDATA[
<div> DiPaCo, Distributed Path Composition, A Douillard, Q Feng, A A. Rusu, A Kuncoro, Google DeepMind, 2024<br />
<br />
总结:<br />
文章介绍了DiPaCo，这是一个由Google DeepMind团队提出的分布式路径组合方法。该方法可以在分布式系统中实现路径组合，具有高效性和可扩展性。研究表明，DiPaCo可以有效解决传统路径组合方法中的性能瓶颈和可扩展性问题。研究人员通过仿真实验证明了DiPaCo的有效性和性能优势。这一方法对于处理大规模数据和复杂任务具有重要意义，为分布式系统的发展和应用提供了新的思路。 <div>
[LG]《DiPaCo: Distributed Path Composition》A Douillard, Q Feng, A A. Rusu, A Kuncoro… [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.10616"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwzv66tb9j21ry0scdw7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnwzv6m856j20we0zgqa8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnwzv74mtrj21sc0l4dlp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzv7ny0oj21sc0uy7f6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqh4f1j211a0kcjvs.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqfou4j20ih0g5gms.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnwzvqflixj20ii0biwfj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqgwumj20ij0l876e.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwzvqh2aqj20ik0majtr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqhb3oj21150k6mzy.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnwzvqi16uj211b0gymyz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:11:53 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.19)》 爱可可微博热门分享(3.19) [图片]</title>
<link>https://weibo.com/1402400261/O5M25EV5o</link>
<guid>https://weibo.com/1402400261/O5M25EV5o</guid>
<content:encoded><![CDATA[
<div> 微博、爱可可、热门、分享、3.19、关键词

<br /><br />总结:
3月19日，爱可可微博发布了一篇热门分享的文章，引起了广泛关注。该篇文章内容丰富，涵盖了各种热门话题，吸引了众多网友转发和评论。其中提到了关于时事新闻、娱乐八卦、美食文化等多个方面的内容，让人目不暇接。网友们纷纷表示对这篇文章的关注和喜爱，展示了对爱可可微博的支持和热情。文章内容引发了热烈讨论，让大家更加了解和关注各种热门话题。愿爱可可微博持续分享更多有趣、有价值的内容，与网友们共同成长。 <div>
《爱可可微博热门分享(3.19)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405013762816999689"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.19)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwnt7oxfzj20rs0fmmz5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 14:14:29 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《FeatUp: A Model-Agnostic Frameworkfor Features at Any Resolution》(ICLR 2024) GitHub: github.com/mhamilton723/FeatUp《Lodge: A Coa...</title>
<link>https://weibo.com/1402400261/O5LEL1Uki</link>
<guid>https://weibo.com/1402400261/O5LEL1Uki</guid>
<content:encoded><![CDATA[
<div> 特征，分辨率，模型，框架，匹配，图像生成，深度学习，模糊，文本生成，benchmark

总结: 
《FeatUp: A Model-Agnostic Framework for Features at Any Resolution》提出了FeatUp框架，旨在实现模型之间特征的无缝转换，无论分辨率如何。该框架实现了特征的匹配，能够在不同分辨率下生成高质量的图像。研究使用深度学习技术，提出了在图像生成过程中进行特征匹配和转换的方法，从而实现模型的复杂度和性能的提升。此外，研究还关注模型的抗干扰能力，能够应对模糊或不清晰的数据输入。同时，研究在文本生成和benchmark方面也取得了显著的进展。FeatUp框架为将不同模型的特征无缝整合提供了新的思路，并在多个应用场景中展现了广阔的应用前景。 <div>
几篇论文实现代码：<br />《FeatUp: A Model-Agnostic Frameworkfor Features at Any Resolution》(ICLR 2024) GitHub: github.com/mhamilton723/FeatUp<br />《Lodge: A Coarse to Fine Diffusion Network for Long Dance Generation Guided by the Characteristic Dance Primitives》(CVPR 2024) GitHub: github.com/li-ronghui/LODGE<br />《FastMAC: Stochastic Spectral Sampling of Correspondence Graph》(CVPR 2024) GitHub: github.com/Forrest-110/FastMAC<br />《Desigen: A Pipeline for Controllable Design Template Generation》(2024) GitHub: github.com/whaohan/desigen [fig1]<br />《InTeX: Interactive Text-to-Texture Synthesis via Unified Depth-aware Inpainting》(2024) GitHub: github.com/ashawkey/InTeX<br />《Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking》(2024) GitHub: github.com/ezelikman/quiet-star<br />《NICER-SLAM: Neural Implicit Scene Encoding for RGB SLAM》(2024) GitHub: github.com/cvg/nicer-slam<br />《OMG: Occlusion-friendly Personalized Multi-concept Generation In Diffusion Models》(2024) GitHub: github.com/kongzhecn/OMG<br />《Controllable Text-to-3D Generation via Surface-Aligned Gaussian Splatting》(2024) GitHub: github.com/WU-CVGL/MVControl-threestudio<br />《RAGGED: Towards Informed Design of Retrieval Augmented Generation Systems》(2024) GitHub: github.com/neulab/ragged<br />《SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis》(2024) GitHub: github.com/sci-assess/SciAssess<br />《Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding》(2024) GitHub: github.com/pkunliu/Isotropic3D<br />《HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation》(2024) GitHub: github.com/carlosferrazza/humanoid-bench<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwlpqeq7hj21fs0dy1kx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 13:17:00 GMT</pubDate>
</item>
<item>
<title>【大模型安全相关阅读列表】’Awesome-LM-SSP - A reading list for large models safety, security, and privacy.' GitHub: github.com/ThuCCSLab/Awesome-LM-S...</title>
<link>https://weibo.com/1402400261/O5LCjCzTu</link>
<guid>https://weibo.com/1402400261/O5LCjCzTu</guid>
<content:encoded><![CDATA[
<div> 安全、大模型、隐私、阅读列表、GitHub、SSP、ThuCCSLab、模型、安全性、保密性

<br /><br />总结:
这是一个关于大型模型安全、安全性和隐私方面的阅读列表，包含了有关这些主题的各种资源和研究。在GitHub上可以找到这个令人印象深刻的资源列表，来自ThuCCSLab团队。研究人员和专业人士可以通过这个列表找到与大型模型安全性、安全方面和隐私相关的资料和信息，帮助他们更好地了解如何保护和管理大型模型的安全性和隐私。 <div>
【大模型安全相关阅读列表】’Awesome-LM-SSP - A reading list for large models safety, security, and privacy.' GitHub: github.com/ThuCCSLab/Awesome-LM-SSP <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnwlze5e62j20xz0u078j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 13:11:00 GMT</pubDate>
</item>
<item>
<title>【onefilellm: 面向大型语言模型(LLM)的命令行数据聚合工具】'onefilellm: Command Line Data Aggregation Tool for LLM Ingestion - Specify a github or local...</title>
<link>https://weibo.com/1402400261/O5Ly9EGb6</link>
<guid>https://weibo.com/1402400261/O5Ly9EGb6</guid>
<content:encoded><![CDATA[
<div> 聚合工具, 命令行, 数据, 大型语言模型, LLM, 网址, 抓取, 文本文件, 剪贴板, 摘要

面向大型语言模型（LLM）的命令行数据聚合工具"onefilellm"，是一个能够从GitHub、arXiv、Sci-Hub等提供的网址中提取信息并将其聚合到文本文件和剪贴板中的工具。用户只需指定相应的网址链接，就能够快速抓取相关数据，方便直接导入到LLM中进行处理。这个工具的使用方法简单快捷，适用于需要大量文本数据的用户群体。总结: <br /><br />onefilellm是一个面向LLM的命令行数据聚合工具，可以从指定网址中抓取信息并存储到文本文件和剪贴板中，方便用户进行数据处理和分析。 <div>
【onefilellm: 面向大型语言模型(LLM)的命令行数据聚合工具】'onefilellm: Command Line Data Aggregation Tool for LLM Ingestion - Specify a github or local repo, arXiv or Sci-Hub paper, Youtube transcript or documentation URL on the web and scrape into a text file and clipboard for easier LLM ingestion' GitHub: github.com/jimmc414/1filellm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnwlod1xduj21aj0u0grz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 13:00:45 GMT</pubDate>
</item>
<item>
<title>“Let's Build AI - A community-driven platform for AI enthusiasts” 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5Lxmw6fC</link>
<guid>https://weibo.com/1402400261/O5Lxmw6fC</guid>
<content:encoded><![CDATA[
<div> AI enthusiasts, community-driven platform, Let's Build AI

总结：<br /><br />这篇文章介绍了一个面向AI爱好者的社区驱动平台“Let's Build AI”。该平台旨在为AI爱好者提供一个共享和交流的空间，让他们共同探讨AI技术的发展和应用。通过这个平台，用户可以互相分享经验、学习最新的AI技术知识，并参与到AI项目的建设中。平台的主要目的是促进AI技术的发展，让更多人了解和参与到AI领域的创新中。 <div>
“Let's Build AI - A community-driven platform for AI enthusiasts” <a href="https://letsbuild.ai/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnwlmdlt9lj20vo0u0djh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 12:58:47 GMT</pubDate>
</item>
<item>
<title>【LLM-RLHF-Tuning：用于AI训练的开源工具包，提供PPO/DPO等算法】’LLM-RLHF-Tuning - Comprehensive toolkit for Reinforcement Learning from Human Feedback...</title>
<link>https://weibo.com/1402400261/O5IPUvXAm</link>
<guid>https://weibo.com/1402400261/O5IPUvXAm</guid>
<content:encoded><![CDATA[
<div> RLHF, 开源工具包, AI训练, PPO, DPO, 算法, 指导微调, 奖励模型训练, 配置, Alpaca, LLaMA

<br /><br />总结:
LLM-RLHF-Tuning是一个用于AI训练的开源工具包，提供了PPO和DPO等算法，支持指导微调和奖励模型训练。该工具包适用于Alpaca、LLaMA和LLaMA2模型，可以进行各种配置。通过使用LLM-RLHF-Tuning，用户可以更有效地进行强化学习训练，提高模型性能和表现。GitHub链接：github.com/raghavc/LLM-RLHF-Tuning-with-PPO-and-DPO <div>
【LLM-RLHF-Tuning：用于AI训练的开源工具包，提供PPO/DPO等算法】’LLM-RLHF-Tuning - Comprehensive toolkit for Reinforcement Learning from Human Feedback (RLHF) training, featuring instruction fine-tuning, reward model training, and support for PPO and DPO algorithms with various configurations for the Alpaca, LLaMA, and LLaMA2 models.' GitHub: github.com/raghavc/LLM-RLHF-Tuning-with-PPO-and-DPO <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnw9pflkjaj21d20u00z3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 06:06:15 GMT</pubDate>
</item>
<item>
<title>【LitServe：开源AI模型推理服务器，其目的是简洁且可扩展，可用于各种 GPU 上运行 ML 模型】'LitServe - Inference server for AI/ML models that is minimal a...</title>
<link>https://weibo.com/1402400261/O5IP2c64C</link>
<guid>https://weibo.com/1402400261/O5IP2c64C</guid>
<content:encoded><![CDATA[
<div> LitServe, 开源, AI模型, 推理服务器, 简洁, 可扩展, GPU, ML模型

LitServe是一个开源AI/ML模型推理服务器，目的是提供一个简洁且可扩展的解决方案，适用于各种GPU上运行ML模型。该项目在GitHub上有开源代码。

总结:<br /><br />
LitServe是一个推理服务器，专为AI/ML模型设计。它被设计为简洁且高度可扩展，适用于在各种GPU上运行ML模型。LitServe的目标是提供一个高效的解决方案，帮助开发人员轻松部署和运行他们的模型。LitServe的开源代码可以在GitHub上找到，有兴趣的人可以查看并参与其中。 <div>
【LitServe：开源AI模型推理服务器，其目的是简洁且可扩展，可用于各种 GPU 上运行 ML 模型】'LitServe - Inference server for AI/ML models that is minimal and highly scalable.' GitHub: github.com/Lightning-AI/litserve <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnw9n6ltoaj21cl0u0dk4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 06:04:05 GMT</pubDate>
</item>
<item>
<title>'Fin-Eva Version 1.0 金融领域中文语言专业数据评测集' GitHub: github.com/alipay/financial_evaluation_dataset #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5IOogmaT</link>
<guid>https://weibo.com/1402400261/O5IOogmaT</guid>
<content:encoded><![CDATA[
<div> 关键词: 金融领域、中文语言、数据评测集、GitHub、Alipay、版本、专业、数据、评测、金融

总结:<br /><br />
文章介绍了Alipay开发的金融领域中文语言专业数据评测集——Fin-Eva Version 1.0。该数据集旨在为金融领域的研究者和开发者提供一个可靠的数据源，帮助他们进行评测和研究工作。数据集包含了丰富的金融领域数据，并在GitHub上开放下载，方便用户获取和使用。用户可以在GitHub上找到相关信息，并了解数据集的具体内容和版本信息。通过使用该数据集，研究者和开发者可以从中获取有价值的信息，用于进行金融领域的研究和分析工作。 Fin-Eva Version 1.0标志着Alipay在金融领域数据开放方面的贡献，并为相关领域的学术研究和技术开发提供了重要支持。 <div>
'Fin-Eva Version 1.0 金融领域中文语言专业数据评测集' GitHub: github.com/alipay/financial_evaluation_dataset <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnw9lj7nzgj216y0u0wkq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 06:02:30 GMT</pubDate>
</item>
<item>
<title>【文本到图像扩散模型可控生成相关文献资源列表】’Awesome Controllable T2I Diffusion Models - A collection of resources on controllable generation with ...</title>
<link>https://weibo.com/1402400261/O5IKZstEp</link>
<guid>https://weibo.com/1402400261/O5IKZstEp</guid>
<content:encoded><![CDATA[
<div> GitHub, Controllable generation, Text-to-image diffusion models, Resources, Collection, Awesome, Priv-Creation, Controllable T2I Diffusion Models

<br /><br />总结:
本文资源集合了一些关于文本到图像扩散模型可控生成的资源。GitHub中包含了多种有关可控生成的信息。这些资源涵盖了文本到图像扩散模型的多个方面，对于研究和实践都具有重要价值。特别是对于那些对文本到图像生成感兴趣的研究者和开发人员，这些资源将提供丰富的参考资料和工具，有助于在这一领域取得进展。GitHub链接为github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models。 <div>
【文本到图像扩散模型可控生成相关文献资源列表】’Awesome Controllable T2I Diffusion Models - A collection of resources on controllable generation with text-to-image diffusion models.' GitHub: github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models?continueFlag=92653a077e6b01a49a5f05f9aa55a3e7 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnw9cn6stmj216s0lwgox.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:54:08 GMT</pubDate>
</item>
<item>
<title>【基于 Nextjs、React、Drizzle和Stripe 的Duolingo全栈克隆项目】'Build a Duolingo Clone With Nextjs, React, Drizzle, Stripe (2024)' GitHub: github.com/A...</title>
<link>https://weibo.com/1402400261/O5IKkvNsI</link>
<guid>https://weibo.com/1402400261/O5IKkvNsI</guid>
<content:encoded><![CDATA[
<div> Nextjs、React、Drizzle、Stripe、全栈、克隆项目、Duolingo、GitHub、AntonioErdeljac
本文介绍了一个基于Nextjs、React、Drizzle和Stripe的Duolingo全栈克隆项目，作者是AntonioErdeljac，并提供了GitHub链接。项目的目标是构建一个类似于Duolingo的学习平台，通过使用React库来构建用户界面，Nextjs作为应用程序框架，Drizzle作为以太坊区块链的项目开发工具，Stripe用于实现支付功能。项目的实现可以帮助开发人员学习如何使用这些技术和工具来构建现代Web应用程序。 <div>
【基于 Nextjs、React、Drizzle和Stripe 的Duolingo全栈克隆项目】'Build a Duolingo Clone With Nextjs, React, Drizzle, Stripe (2024)' GitHub: github.com/AntonioErdeljac/next14-duolingo-clone <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnw9az1oeoj20zk0k00vb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:52:30 GMT</pubDate>
</item>
<item>
<title>【LlamaGym：用来简化基于语言模型的强化学习环境的开源项目，包含通用抽象类，帮助用户快速地尝试和探索各种 基于LLM的强化学习环境】'LlamaGym - Fine-tune LL...</title>
<link>https://weibo.com/1402400261/O5IJsqeyl</link>
<guid>https://weibo.com/1402400261/O5IJsqeyl</guid>
<content:encoded><![CDATA[
<div> LLamaGym, 开源项目, 强化学习环境, 基于语言模型, 抽象类, 探索, Fine-tune, LLM agents, 在线强化学习

总结:<br /><br />LLamaGym是一个开源项目，用于简化基于语言模型的强化学习环境，包含通用抽象类，帮助用户快速尝试和探索各种基于LLM的强化学习环境。用户可以通过这个项目来调优LLM代理并进行在线强化学习。GitHub链接：github.com/KhoomeiK/LlamaGym。 <div>
【LlamaGym：用来简化基于语言模型的强化学习环境的开源项目，包含通用抽象类，帮助用户快速地尝试和探索各种 基于LLM的强化学习环境】'LlamaGym - Fine-tune LLM agents with online reinforcement learning' GitHub: github.com/KhoomeiK/LlamaGym <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnw98vz3zjj20xz0u0tdc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:50:21 GMT</pubDate>
</item>
<item>
<title>【3DGS.cpp：跨平台、高性能的Gaussian Splatting渲染器，支持 Windows、Linux、macOS、iOS和visionOS】'3DGS.cpp - A cross-platform, high performance render...</title>
<link>https://weibo.com/1402400261/O5IIYiYZA</link>
<guid>https://weibo.com/1402400261/O5IIYiYZA</guid>
<content:encoded><![CDATA[
<div> 高性能、跨平台、Gaussian Splatting、渲染器、Vulkan Compute、Windows、Linux、macOS、iOS、visionOS
<br /><br />总结:
3DGS.cpp是一个跨平台、高性能的渲染器，使用Vulkan Compute技术实现Gaussian Splatting。支持多种操作系统，包括Windows、Linux、macOS、iOS和visionOS。项目托管在GitHub上，网址为github.com/shg8/3DGS.cpp。 <div>
【3DGS.cpp：跨平台、高性能的Gaussian Splatting渲染器，支持 Windows、Linux、macOS、iOS和visionOS】'3DGS.cpp - A cross-platform, high performance renderer for Gaussian Splatting using Vulkan Compute. Supports Windows, Linux, macOS, iOS, and visionOS' GitHub: github.com/shg8/3DGS.cpp <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnw97nb7o7j20u00uj44e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:49:09 GMT</pubDate>
</item>
<item>
<title>【Garnet：微软研究团队开发的远程缓存-存储项目，具有强性能(吞吐量和延迟)， 可扩展性，存储、恢复，集群分片，密钥迁移和复制等功能】'Garnet - Garnet is a ...</title>
<link>https://weibo.com/1402400261/O5IIimt1C</link>
<guid>https://weibo.com/1402400261/O5IIimt1C</guid>
<content:encoded><![CDATA[
<div> 远程缓存-存储、微软研究团队、强性能、吞吐量、延迟、可扩展性、存储恢复、集群分片、密钥迁移、复制

<br /><br />
总结:
微软研究团队开发了远程缓存-存储项目Garnet，具备强大的性能表现，包括高吞吐量和低延迟。该项目具有良好的可扩展性，支持存储、恢复、集群分片、密钥迁移和复制等功能。此外，Garnet可以与现有的Redis客户端兼容，为用户提供更好的使用体验。 <div>
【Garnet：微软研究团队开发的远程缓存-存储项目，具有强性能(吞吐量和延迟)， 可扩展性，存储、恢复，集群分片，密钥迁移和复制等功能】'Garnet - Garnet is a remote cache-store from Microsoft Research that offers strong performance (throughput and latency), scalability, storage, recovery, cluster sharding, key migration, and replication features. Garnet can work with existing Redis clients.' GitHub: github.com/microsoft/garnet <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnw95wf41dj218m0u0jyi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:47:29 GMT</pubDate>
</item>
<item>
<title>【Pointrix：可微点渲染库，支持3D Gaussian Splatting等的渲染】'Pointrix: a differentiable point-based rendering libraries supporting 3D Gaussian Splatt...</title>
<link>https://weibo.com/1402400261/O5IGMqG5k</link>
<guid>https://weibo.com/1402400261/O5IGMqG5k</guid>
<content:encoded><![CDATA[
<div> Point-based rendering, differentiable, 3D Gaussian Splatting, library, Pointrix, GitHub, support <br />
<br />
要点一：Pointrix是一个可微的点渲染库，支持3D Gaussian Splatting等技术。<br />
要点二：该库的GitHub链接为github.com/pointrix-project/pointrix。 <br />
要点三：Pointrix提供了高效的点渲染和处理功能，可用于各种3D图形应用中。<br />
要点四：库支持不同的渲染技术，包括3D Gaussian Splatting等，可以实现更加逼真的渲染效果。<br /> 
总结: Pointrix是一个支持3D Gaussian Splatting等渲染技术的可微点渲染库，在GitHub上可以找到该项目。这个库提供了高效的点渲染和处理功能，适用于各种3D图形应用，并可以实现更加逼真的渲染效果。 <div>
【Pointrix：可微点渲染库，支持3D Gaussian Splatting等的渲染】'Pointrix: a differentiable point-based rendering libraries supporting 3D Gaussian Splatting and beyond' GitHub: github.com/pointrix-project/pointrix <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnw91zmhtsj20v70u0dk5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:43:45 GMT</pubDate>
</item>
<item>
<title>【专家混合(MoE)模型详解】 - MoE通过使用稀疏的MoE层来替换稠密的前馈网络层，从而实现更高效的预训练。MoE层包含多个“专家”(通常是FFN)，以及一个门控网络来...</title>
<link>https://weibo.com/1402400261/O5Guy1JXq</link>
<guid>https://weibo.com/1402400261/O5Guy1JXq</guid>
<content:encoded><![CDATA[
<div> 稀疏、MoE层、专家、门控网络、计算预算、预训练、参数数量、训练效率、知识蒸馏、开源实现

<br /><br />总结:
MoE是一种通过稀疏的MoE层来取代稠密的前馈网络层，实现更高效预训练的模型。MoE包含多个专家和门控网络，能在相同计算预算下训练更大规模的模型，且在预训练过程中速度更快且质量相当。MoE在推理速度更快但内存需求高，微调困难且容易过拟合，但可通过多任务提示调优和单任务微调改善效果。选择MoE还是稠密模型取决于具体场景，可调整门控网络、专家容量等提高效率，也可通过知识蒸馏将MoE模型蒸馏为稠密模型。开源实现有Megablocks、Fairseq、OpenMoE等，模型包括Switch Transformers、NLLB MoE、OpenMoE等。未来MoE研究方向包括知识蒸馏、模型合并、量化等。 <div>
【专家混合(MoE)模型详解】  <br />- MoE通过使用稀疏的MoE层来替换稠密的前馈网络层，从而实现更高效的预训练。MoE层包含多个“专家”(通常是FFN)，以及一个门控网络来确定哪些tokens被送到哪个专家。   <br />- MoE可以在相同的计算预算下预训练出更大规模的模型。与稠密模型相比，MoE模型可以在预训练过程中以更快的速度达到相同的质量。   <br />- MoE模型推理速度更快，但需要加载全部参数到内存，所以内存需求高。   <br />- MoE模型微调较难，容易过拟合，但最近的工作显示先进行多任务提示调优然后再单任务微调可以改善效果。   <br />- 与稠密模型直接比较参数数量是错误的，因为它们表示不同的意义。选择MoE还是稠密模型取决于具体场景。   <br />- 为提高训练和推理效率，可调整门控网络、专家容量、精度等。还可通过知识蒸馏将MoE模型蒸馏为稠密模型。   <br />- 一些开源的MoE实现包括Megablocks、Fairseq、OpenMoE等。已发布的开源MoE模型有Switch Transformers、NLLB MoE、OpenMoE等。   <br />- MoE模型的一些激动人心的研究方向包括知识蒸馏、模型合并、量化等。<br />《Mixture of Experts Explained》 <a href="https://huggingface.co/blog/moe"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnvzcsvvqoj210r0u0td2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 00:08:07 GMT</pubDate>
</item>
<item>
<title>【Quanto：pytorch量化工具包】1. quanto是一个灵活的pytorch量化工具包,提供了独特的功能:- 支持eager模式(可用于非可trace的模型)- 量化后的模型可在任意设备...</title>
<link>https://weibo.com/1402400261/O5GtgpFzZ</link>
<guid>https://weibo.com/1402400261/O5GtgpFzZ</guid>
<content:encoded><![CDATA[
<div> 量化工具包 PyTorch CUDA MPS QLinear QConv2d 动态 静态 int8 int2 int4 Transformers 模型 流程 校准 调优 冻结 性能 准确率 加速比 实现细节 dispatch PTQ 优化算法<br />
<br />
总结:<br />
1. quanto是一个灵活的pytorch量化工具包，支持eager模式和量化后模型在任意设备上运行。<br />
2. 典型的量化流程包括量化、校准、调优和冻结。<br />
3. quanto与huggingface transformers库深度集成，可通过QuantoConfig来量化任意模型。<br />
4. quanto的实现细节包括定制Tensor子类、量化模块和针对常见函数的量化版本。<br />
5. quanto的性能展示了不同量化配置的准确率以及量化带来的加速比。 <div>
【Quanto：pytorch量化工具包】<br />1. quanto是一个灵活的pytorch量化工具包,提供了独特的功能:<br />- 支持eager模式(可用于非可trace的模型)<br />- 量化后的模型可在任意设备上运行(包括CUDA和MPS)  <br />- 自动插入量化和反量化代码<br />- 自动插入量化的函数操作<br />- 自动插入量化的模块(如QLinear、QConv2d等)<br />- 提供从动态到静态量化的流程  <br />- 支持量化模型的状态字典序列化<br />- 不仅支持int8权重,还支持int2和int4<br />- 不仅支持int8激活,还支持float8<br />2. 典型的量化流程包括:量化、校准、调优和冻结。<br />3. quanto与huggingface transformers库深度集成,可通过QuantoConfig来量化任意模型。<br />4. quanto的实现细节:<br />- 提供了针对不同量化类型的定制Tensor子类<br />- 提供了可处理quanto tensor的量化模块,如QLinear、QConv2d等<br />- 通过pytorch dispatch机制,实现了常见函数的量化版本<br />- 计划集成各种PTQ优化算法<br />5. quanto的性能:<br />- 在多个模型上展示了不同量化配置的准确率<br />- 展示了相比全精度,量化带来的加速比<br />《Quanto: a pytorch quantization toolkit》 <a href="https://huggingface.co/blog/quanto-introduction"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnvz9gsvxfj20u00v7q7c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 00:04:58 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O5GrXa9Og</link>
<guid>https://weibo.com/1402400261/O5GrXa9Og</guid>
<content:encoded><![CDATA[
<div> 知识体系、实践性、全彩印刷、杨青、度小满、轩辕大模型、十亿、百亿、千亿、训练经验
<br />
<br />
总结:<br />
本书《大语言模型：原理与工程实践(全彩)》由度小满轩辕大模型负责人杨青撰写，旨在揭开大语言模型的神秘面纱，深入解读内在机理和应用实践。书中系统性的知识体系和对实践性的重视是其特色之一，同时作者结合自己在不同参数规模大语言模型训练经验，将实践经验融入书中，内容干货十足，非空谈。书籍全彩印刷，配有代码，适合想要深入了解大语言模型的读者阅读。欢迎转发评论参与赢取《大语言模型：原理与工程实践(全彩)》。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 00:01:44 GMT</pubDate>
</item>
<item>
<title>【解密Meta的GenAI基础设施】- Meta宣布投资建设了两座规模为24k GPU的AI集群，用于支持公司当前和未来的AI模型研发，包括下一代语言模型Llama 3。 - 详细介绍了...</title>
<link>https://weibo.com/1402400261/O5Gn8yily</link>
<guid>https://weibo.com/1402400261/O5Gn8yily</guid>
<content:encoded><![CDATA[
<div> 存储部署、网络、AI集群、GenAI基础设施、Meta、Grand Teton、RDMA over RoCE、InfiniBand、NVIDIA H100 GPU、Llama 3

总结:<br /><br />Meta宣布投资建设了两座规模为24k GPU的AI集群，用于支持公司当前和未来的AI模型研发，包括下一代语言模型Llama 3。这两座AI集群基于自研的开源硬件Grand Teton，拥有优化的网络部署和存储系统。通过软硬件协同设计，Meta在大规模集群上高效运行复杂的AI工作负载，并计划继续扩张基础设施，部署35万块NVIDIA H100 GPU，确保其AI基础设施灵活可靠地支持快速发展的AI模型和研究。Meta致力于开放的AI创新，贡献开源硬件和软件项目，为整个行业解决大规模AI的挑战。在AI系统日益复杂的今天，基础设施的重要性不容忽视，需要与算法同步优化和创新。文章着重介绍了Meta在GenAI基础设施的存储部署方面的定制化工作，呈现了一个不同的视角，强调了基础设施细节对支撑AI系统的重要性。人们对Meta采用两种不同的存储部署方式表示好奇，也有人质疑定制化基础设施是否真的有必要，是否会带来过高的成本和复杂性。Meta通过自研硬件、持续优化软件框架等方式，确保其AI基础设施能够始终满足快速发展的需求。 <div>
【解密Meta的GenAI基础设施】<br />- Meta宣布投资建设了两座规模为24k GPU的AI集群，用于支持公司当前和未来的AI模型研发，包括下一代语言模型Llama 3。   <br />- 详细介绍了这两座AI集群的硬件配置，包括网络、存储、计算单元等。两者都使用了自研的开源硬件Grand Teton作为基础。   <br />- AI集群的网络部分采用了RDMA over RoCE和InfiniBand两种解决方案，用于评估不同互联方式的可扩展性。存储部分则自研了优化过的分布式存储系统。   <br />- 通过软硬件协同设计，Meta能够在这样的大规模集群上高效运行复杂的AI工作负载，并取得很好的性能。文章给出了优化前后集群性能对比的数据。   <br />- Meta致力于开放的AI创新，持续贡献开源硬件和软件项目。此举有助于整个行业解决大规模AI的挑战。   <br />- 到2024年底，Meta计划继续扩张基础设施，部署35万块NVIDIA H100 GPU，计算能力将达到近60万块H100的规模。   <br />- Meta正通过自研硬件、持续优化软件框架等方式，确保其AI基础设施能够灵活可靠地支持快速发展的AI模型和研究。<br /><br />思考：  <br />- 文章着重介绍了Meta在GenAI基础设施的存储部署方面所做的定制化工作。  <br />- 通常人们更关注AI模型和算法本身，而较少关注支撑AI系统的基础设施细节，文章提供了一个不同的视角。  <br />- 有人会对Meta采用两种不同的存储部署方式表示好奇，也有人质疑定制化基础设施是否真的有必要，是否会带来过高的成本和复杂性。  <br />- 在AI系统日益复杂的今天，基础设施的重要性不容忽视，需要与算法同步优化和创新。<br />《Building Meta’s GenAI Infrastructure - Engineering at Meta》 <a href="https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnvytnizjsj215w0u0q9s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnvytpx4yjj21400u0jt3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 23:49:52 GMT</pubDate>
</item>
<item>
<title>今日推介(第1349期)：面向推测译码加速的最优块级草稿验证、基于冻结特征增强的少样本图像分类、用RAG提高LLM事实准确性以对抗幻觉、适应特定域RAG的语言模型、...</title>
<link>https://weibo.com/1402400261/O5FPKcyln</link>
<guid>https://weibo.com/1402400261/O5FPKcyln</guid>
<content:encoded><![CDATA[
<div> 面向推测译码加速、块级草稿验证、冻结特征增强、少样本图像分类、RAG、LLM、事实准确性、适应特定域、语言模型、大型语言模型

<br /><br />总结:
本文提出了面向推测译码加速的最优块级草稿验证方法，在图像分类任务中使用冻结特征增强来处理少样本情况，同时利用RAG提高LLM事实准确性以对抗幻觉。文章还探讨了适应特定域RAG的语言模型，并提出了面向大型语言模型快速推测解码的循环起草器。这些方法有望在加速推测译码和提高语言模型准确性方面发挥重要作用。 <div>
今日推介(第1349期)：面向推测译码加速的最优块级草稿验证、基于冻结特征增强的少样本图像分类、用RAG提高LLM事实准确性以对抗幻觉、适应特定域RAG的语言模型、面向大型语言模型快速推测解码的循环起草器 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687756478"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.19)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnvwfx7dt5j20k0089dgm.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnvwfzaly2j20k00q2n0h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnvwg1j2dmj20k00edace.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnvwg40ht4j20k009ygmx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnvwg5x3qrj20k00cmjtc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:27:35 GMT</pubDate>
</item>
<item>
<title>[CV] FDGaussian: Fast Gaussian Splatting from Single Image via Geometric-aware Diffusion Model 网页链接 介绍了FDGaussian，一个基于单张图片的3D重建新框...</title>
<link>https://weibo.com/1402400261/O5FLgxilx</link>
<guid>https://weibo.com/1402400261/O5FLgxilx</guid>
<content:encoded><![CDATA[
<div> 关键词: FDGaussian, 单张图片, 3D重建, 正交平面分解, 扩散模型, 极线注意力, 高斯Splatting, 高斯散度显著性, 多视角一致性, 文本到3D应用

总结:<br /><br />
该篇文章介绍了一种名为FDGaussian的新框架，用于基于单张图片进行3D重建。传统方法在多视角一致性和几何真实性方面存在一些问题，而FDGaussian则通过正交平面分解提取3D特征，利用扩散模型生成一致的多视角图像。此外，还引入了基于极线注意力的高斯Splatting技术，能加速不同视点图像的融合。通过提出的高斯散度显著性(GDS)指标，可以减少优化过程中不必要的拆分和克隆操作。实验表明，FDGaussian不仅可以保持多视角一致性，还能重建出具有详细几何信息的高质量3D对象，并且能够无缝集成到文本到3D应用中。 <div>
[CV]  FDGaussian: Fast Gaussian Splatting from Single Image via Geometric-aware Diffusion Model  <br /><a href="https://arxiv.org/abs/2403.10242"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了FDGaussian，一个基于单张图片的3D重建新框架。传统的方法在多视角一致性和几何真实性上存在缺陷。FDGaussian通过正交平面分解提取3D特征，使用扩散模型生成一致的多视角图像。此外，引入了基于极线注意力的高斯Splatting，加速了不同视点图像融合，以及提出了高斯散度显著性(GDS)指标，减少了优化过程中不必要的拆分和克隆操作。实验表明，FDGaussian在保持多视角一致性的同时，能够重建出具有详细几何信息的高质量3D对象，并且能与文本到图像模型无缝集成，用于文本到3D应用。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvw4o40iqj21261jyanf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvw4oln6nj213e0z6k01.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvw4oso0fj213m0g4n0j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:16:33 GMT</pubDate>
</item>
<item>
<title>[CV] SWAG: Splatting in the Wild images with Appearance-conditioned Gaussians 网页链接 介绍了SWAG模型，首个用于3D高斯Splatting(3DGS)技术在野外场景中扩...</title>
<link>https://weibo.com/1402400261/O5FJpsMWG</link>
<guid>https://weibo.com/1402400261/O5FJpsMWG</guid>
<content:encoded><![CDATA[
<div> 关键词: SWAG模型, 3D高斯Splatting, 图像外观, 高光照条件, 无监督学习, 瞬时高斯, 遮挡物移除, 训练速度提升, 渲染速度提升, 高质量重建

总结:<br /><br />本文介绍了SWAG模型，其为首个将3D高斯Splatting技术应用于野外场景中的模型。SWAG通过学习嵌入空间捕捉图像外观的变化，并对3D高斯的颜色进行调制，实现对不同光照条件下场景的建模。模型引入了无监督学习处理瞬时高斯的新机制，从而移除场景中的遮挡物。SWAG在野外数据集上表现出色，训练和渲染速度也大幅提升，达到最新的行业标准。文章展示了如何通过模型对外观进行建模和处理瞬时对象，实现对复杂真实世界场景的高效高质量重建。 <div>
[CV] SWAG: Splatting in the Wild images with Appearance-conditioned Gaussians  <br /><a href="https://arxiv.org/abs/2403.10427"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了SWAG模型，首个用于3D高斯Splatting(3DGS)技术在野外场景中扩展的应用。SWAG模型通过学习嵌入空间捕捉图像外观的变化，并对3D高斯的颜色进行调制，实现对不同光照条件下场景的建模。此外，模型还引入了一种新机制，通过无监督学习处理瞬时高斯，从而在没有前置条件的情况下移除场景中的遮挡物。相比先前的方法，SWAG不仅提升了3DGS在野外数据集上的表现，而且在训练和渲染速度上都有显著提高，达到了最新的行业标准。文章展示了如何在没有精确结构信息的状况下，通过对外观的建模和瞬时对象的处理，实现对复杂真实世界场景的高效和高质量重建。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvzxxa0vj20yi1e4n8l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvzym8ygj21oo15igzh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvvzz4ojjj21oo100tk6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:12:00 GMT</pubDate>
</item>
<item>
<title>[CV] FeatUp: A Model-Agnostic Framework for Features at Any Resolution 网页链接 介绍了FeatUp，一个模型和任务不可知的框架，用于提高任意视觉模型特征的分...</title>
<link>https://weibo.com/1402400261/O5FHrfw0x</link>
<guid>https://weibo.com/1402400261/O5FHrfw0x</guid>
<content:encoded><![CDATA[
<div> FeatUp, 特征, 分辨率, 模型不可知, 多视角一致性, 上采样网络, 密集预测任务, 可解释性, NeRF, CUDA实现

<br /><br />总结:
文章介绍了FeatUp，一个模型和任务不可知的框架，用于提高任意视觉模型特征的分辨率，同时保持原有语义。FeatUp使用多视角一致性损失来聚合低分辨率视图信息，学习高分辨率信息，有通用的前馈上采样网络和过拟合单个图像隐式表示两种体系结构。该框架提高了密集预测任务的性能，增强了模型可解释性，并采用了类似于NeRF的多视角一致性方法，具有高效的CUDA实现。FeatUp为提高特征分辨率和模型解释性提供了新的可能性。 <div>
[CV] FeatUp: A Model-Agnostic Framework for Features at Any Resolution  <br /><a href="https://arxiv.org/abs/2403.10516"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了FeatUp，一个模型和任务不可知的框架，用于提高任意视觉模型特征的分辨率，同时保持原有语义，通过多视角一致性损失来聚合从模型输出中经过轻微变换图像得到的低分辨率视图信息，从而学习高分辨率信息。FeatUp有两种体系结构：一种是通用的前馈上采样网络，另一种是过拟合单个图像的隐式表示。该框架能够提高语义分割和深度预测等密集预测任务的性能，并增强模型可解释性。值得注意的是，FeatUp采用了类似于NeRF的多视角一致性方法，并且其高效的CUDA实现显著优于现有技术。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvux0wnij214m1m2nfo.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvuvmrjaj21mw0qownc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvvuvlqhgj21nm0jgahb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvvuvky7pj21nk0f20yk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:07:08 GMT</pubDate>
</item>
<item>
<title>[CV] VideoAgent: Long-form Video Understanding with Large Language Model as Agent 网页链接 提出了一种新的基于Agent的系统VideoAgent，用于长视频理解。该...</title>
<link>https://weibo.com/1402400261/O5FFDAV2O</link>
<guid>https://weibo.com/1402400261/O5FFDAV2O</guid>
<content:encoded><![CDATA[
<div> 大型语言模型(LLM)、视觉语言模型(VLM)、对比语言-图像模型(CLIP)、长视频理解、Agent、交互式推理、零样本准确率、EgoSchema、NExT-QA、效率。

总结:<br /><br />
研究提出了基于Agent的VideoAgent系统，以大型语言模型(LLM)为中心Agent，通过交互式推理和规划来理解长视频。利用视觉语言模型(VLM)和对比语言-图像模型(CLIP)来提取和转换视觉信息。实验结果显示，VideoAgent在EgoSchema和NExT-QA基准测试中表现出色，零样本准确率分别达到54.1%和71.3%，同时仅平均使用8.4和8.2帧。这表明以Agent为基础的方法在长视频理解领域具有潜在的潜力，效率和效果优于现有方法。 <div>
[CV] VideoAgent: Long-form Video Understanding with Large Language Model as Agent  <br /><a href="https://arxiv.org/abs/2403.10517"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出了一种新的基于Agent的系统VideoAgent，用于长视频理解。该系统以大型语言模型(LLM)作为中心Agent，通过迭代式识别和汇总关键信息以回答问题，利用视觉语言模型(VLM)和对比语言-图像模型(CLIP)作为工具提取和转换视觉信息。该方法模仿人类理解长视频的认知过程，重在交互式推理和规划而非直接处理长期视觉输入。实验结果显示，VideoAgent在EgoSchema和NExT-QA基准测试中分别取得了54.1%和71.3%的零样本准确率，仅平均使用8.4和8.2帧，效率和效果均优于现有最先进方法。本研究突显了以Agent为基础的方法在推进长视频理解方面的潜力。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvvq9ed7qj214o1m0dxb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvvq9rvh2j21ck0t612p.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvvqaegkpj21c80nuqaz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvvqb1w9ij21c81c4x0m.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:02:42 GMT</pubDate>
</item>
<item>
<title>[LG] Understanding the Double Descent Phenomenon in Deep Learning 网页链接 解析了深度学习中的“双重下降”现象，这一现象与传统机器学习理论相悖，即超参...</title>
<link>https://weibo.com/1402400261/O5FCWiOLD</link>
<guid>https://weibo.com/1402400261/O5FCWiOLD</guid>
<content:encoded><![CDATA[
<div> 关键词: 双重下降现象, 深度学习, 统计学习, 泛化误差, 归纳偏差, 梯度下降, 超参数化模型, 线性模型, 超参数化优化, 神经网络

总结:<br /><br />
本文解析了深度学习中的双重下降现象，即超参数化模型在数据插值点之后继续增加复杂度，测试误差反而降低。文章首先梳理了经典统计学习中的泛化误差概念，引入了双重下降现象。接着讨论了归纳偏差在选择平滑经验风险最小化解中的关键作用，特别是梯度下降在有多个解的情形下偏向于某些解的隐性特性。进一步通过两个线性模型具体探讨了双重下降的原因，并回顾了相关研究，如超参数化优化和神经网络中的拥塞转换现象。文章深入剖析了深度学习中的泛化行为，为理解深度学习提供了重要见解。 <div>
[LG] Understanding the Double Descent Phenomenon in Deep Learning  <br /><a href="https://arxiv.org/abs/2403.10459"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />解析了深度学习中的“双重下降”现象，这一现象与传统机器学习理论相悖，即超参数化模型在数据插值点之后继续增加复杂度，测试误差反而降低。文中首先梳理了经典统计学习中的泛化误差概念，并以此引入双重下降现象。接着，讨论了归纳偏差在选择平滑经验风险最小化解中的关键作用，特别是梯度下降在有多个解的情形下偏向于某些解的隐性特性。最后，文章通过两个线性模型具体探讨了双重下降的原因，并回顾了相关研究，如超参数化优化和作为物理系统的神经网络中的拥塞转换(jamming transition)现象。本文对于理解深度学习中的泛化行为提供了深刻见解。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvjbzd2yj212s1ie14m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvvjcgs1sj21640dywh6.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvvjcwillj216m0imjvr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvvjdc28rj21680fu0vf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:56:03 GMT</pubDate>
</item>
<item>
<title>通过结合经典推测性解码与Medusa方法的优势，提出一种新的单模型推测性解码策略“循环起草器”(ReDrafter)，采用循环依赖设计的轻量级草稿头和动态树注意力算法...</title>
<link>https://weibo.com/1402400261/O5Ftyf0Gw</link>
<guid>https://weibo.com/1402400261/O5Ftyf0Gw</guid>
<content:encoded><![CDATA[
<div> 关键词：推测性解码，Medusa方法，单模型，循环起草器，循环依赖设计，轻量级草稿头，动态树注意力算法，推断延迟，模型部署，优势

<br /><br />总结:
本文提出了一种新的单模型推测性解码策略“循环起草器”(ReDrafter)，结合经典推测性解码与Medusa方法，采用循环依赖设计的轻量级草稿头和动态树注意力算法。该方法有效降低了大型语言模型的推断延迟，简化了模型部署，具有显著优势。研究结果表明，“循环起草器”能够在大型语言模型中表现出色，为实际应用提供了新的思路和可能性。 <div>
通过结合经典推测性解码与Medusa方法的优势，提出一种新的单模型推测性解码策略“循环起草器”(ReDrafter)，采用循环依赖设计的轻量级草稿头和动态树注意力算法，有效降低了大型语言模型的推断延迟，简化了模型部署，具有实际应用中的显著优势。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Recurrent Drafter for Fast Speculative Decoding in Large Language Models》A Zhang, C Wang, Y Wang, X Zhang, Y Cheng [Apple] (2024) <a href="https://arxiv.org/abs/2403.09919"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvulnyqnwj218k0tqang.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvuloc2kcj21gq12edl5.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvuloksbtj21ho0xu4a2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvulons0hj21hc0o2n4k.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvuv4qsh0j21gy0mcjyf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvuumqosxj20vh0k7diu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvuv5fakoj21hg0tiqbd.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:32:55 GMT</pubDate>
</item>
<item>
<title>[CL]《Recurrent Drafter for Fast Speculative Decoding in Large Language Models》A Zhang, C Wang, Y Wang, X Zhang, Y Cheng [Apple] (2024) 网页链接 #机...</title>
<link>https://weibo.com/1402400261/O5FtvAoqi</link>
<guid>https://weibo.com/1402400261/O5FtvAoqi</guid>
<content:encoded><![CDATA[
<div> 大语言模型，高效解码，快速推测，反复草案，苹果，研究，技术，人工智能，科技，语言处理

<br /><br />总结:
本文介绍了一种在大型语言模型中进行快速推测解码的方法，称为“Recurrent Drafter”。该方法通过反复草案的方式，利用循环神经网络来提高解码效率和速度。研究是由苹果公司的张、王和程等人共同完成的，对人工智能和语言处理技术领域具有重要意义。通过该方法，可以在大语言模型中实现高效的快速推测，为科技领域带来新的突破。 <div>
[CL]《Recurrent Drafter for Fast Speculative Decoding in Large Language Models》A Zhang, C Wang, Y Wang, X Zhang, Y Cheng [Apple] (2024) <a href="https://arxiv.org/abs/2403.09919"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvulnyqnwj218k0tqang.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvuloc2kcj21gq12edl5.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvuloksbtj21ho0xu4a2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvulons0hj21hc0o2n4k.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvuv4qsh0j21gy0mcjyf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvuumqosxj20vh0k7diu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvuv5fakoj21hg0tiqbd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:32:48 GMT</pubDate>
</item>
<item>
<title>论文提出检索增强微调(RAFT)策略，通过训练大型语言模型区分并利用相关文档来提升特定领域内的问题回答能力，创新地解决了模型在面对分心文档时的适应性问题，并...</title>
<link>https://weibo.com/1402400261/O5FmW7B1p</link>
<guid>https://weibo.com/1402400261/O5FmW7B1p</guid>
<content:encoded><![CDATA[
<div> 增强微调, 检索, 大型语言模型, 问题回答, 领域特定, 适应性问题, 数据集, 有效性, 传统微调方法

<br /><br />总结:
本论文提出了检索增强微调（RAFT）策略，该策略通过训练大型语言模型，在特定领域内区分并利用相关文档，提升问题回答能力。研究创新地解决了模型在面对分心文档时的适应性问题，经多个数据集验证，RAFT策略优于传统微调方法，具有更好的有效性。这一研究结果对语言模型领域具有重要意义，为解决领域特定问题提供了一种新的探索思路。 <div>
论文提出检索增强微调(RAFT)策略，通过训练大型语言模型区分并利用相关文档来提升特定领域内的问题回答能力，创新地解决了模型在面对分心文档时的适应性问题，并在多个数据集上验证了其优于传统微调方法的有效性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《RAFT: Adapting Language Model to Domain Specific RAG》T Zhang, S G. Patil, N Jain, S Shen, M Zaharia, I Stoica, J E. Gonzalez [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2403.10131"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvud0zq50j20ma13eqcp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvud1htzhj21p60mgdpq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvud1p1qfj21oq0u8k08.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvud1v4naj21p010cqhm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvudzt6mpj212b0ckgo5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvudztbeqj212c0hewhu.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:16:37 GMT</pubDate>
</item>
<item>
<title>[CL]《RAFT: Adapting Language Model to Domain Specific RAG》T Zhang, S G. Patil, N Jain, S Shen, M Zaharia, I Stoica, J E. Gonzalez [UC Berkeley] (202...</title>
<link>https://weibo.com/1402400261/O5FmNEWOr</link>
<guid>https://weibo.com/1402400261/O5FmNEWOr</guid>
<content:encoded><![CDATA[
<div> 领域自适应语言模型，RAFT，特定领域RAG，UC Berkeley，语言模型

总结:<br /><br />本文介绍了一种新颖的方法，称为RAFT，用于将通用语言模型适应到特定领域的RAG中。研究人员提出了一种新颖的自适应机制，以提高领域特定问答生成的性能。他们在UC Berkeley进行了实验，并展示了该方法的有效性。这项工作对于提高领域特定语言模型的性能具有重要意义。 <div>
[CL]《RAFT: Adapting Language Model to Domain Specific RAG》T Zhang, S G. Patil, N Jain, S Shen, M Zaharia, I Stoica, J E. Gonzalez [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2403.10131"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvud0zq50j20ma13eqcp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvud1htzhj21p60mgdpq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvud1p1qfj21oq0u8k08.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvud1v4naj21p010cqhm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvudzt6mpj212b0ckgo5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvudztbeqj212c0hewhu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:16:18 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.18)》 爱可可微博热门分享(3.18) [图片]</title>
<link>https://weibo.com/1402400261/O5CuSxxnf</link>
<guid>https://weibo.com/1402400261/O5CuSxxnf</guid>
<content:encoded><![CDATA[
<div> 微博, 热门分享, 爱可可, 3.18, 热门话题, 社交媒体, 网络流行, 网友讨论, 最新动态

<br /><br />总结:
3月18日，爱可可的微博帖子成为了热门分享内容，引发了广泛讨论。网友们热烈讨论了该话题，纷纷在社交媒体上分享并转发。这反映了爱可可在网络流行中的重要地位，也展示了热门话题如何在网上引起轰动。 <div>
《爱可可微博热门分享(3.18)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405013396264190226"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.18)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvhpqexuoj20og0drabu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 13:57:57 GMT</pubDate>
</item>
<item>
<title>【Mistral-7b模型DPO微调实战】《Fine-tune a Mistral-7b model with Direct Preference Optimization | by Maxime Labonne | Towards Data Science》 网页链接 ...</title>
<link>https://weibo.com/1402400261/O5zuA01tt</link>
<guid>https://weibo.com/1402400261/O5zuA01tt</guid>
<content:encoded><![CDATA[
<div> 模型微调、Mistral-7b、DPO、实战、Direct Preference Optimization、Maxime Labonne、Towards Data Science  

<br />总结: 本文介绍了如何使用Direct Preference Optimization (DPO)技术对Mistral-7b模型进行微调。作者详细讲解了DPO的原理和操作步骤，以及如何在实战中应用这一技术来提高模型性能。通过对模型进行微调，可以更好地适应特定任务需求，提升模型的表现效果。文章为想要了解和应用DPO微调的人提供了有用的指导和思路。 <div>
【Mistral-7b模型DPO微调实战】《Fine-tune a Mistral-7b model with Direct Preference Optimization | by Maxime Labonne | Towards Data Science》 <a href="https://towardsdatascience.com/fine-tune-a-mistral-7b-model-with-direct-preference-optimization-708042745aac"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnv4fpp48tj20u00vqn3w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnv4g7mtn0j212w0ecac3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 06:18:58 GMT</pubDate>
</item>
<item>
<title>【Grok-1开源：Musk的AI大众化还是对OpenAI的"报复"?】- Grok-1是由Elon Musk的xAI公司开发的大型语言模型，具有3140亿个参数。 - xAI决定以Apache 2.0许可证的...</title>
<link>https://weibo.com/1402400261/O5zt6FiHP</link>
<guid>https://weibo.com/1402400261/O5zt6FiHP</guid>
<content:encoded><![CDATA[
<div> 关键词: Grok-1, Elon Musk, xAI, 开源, Apache 2.0, Mixture-of-Experts, AI技术, 创新, OpenAI, 大众化

总结:<br /><br />Elon Musk的xAI公司开发了3140亿参数的大型语言模型Grok-1，并以Apache 2.0许可证开源发布其基础模型权重和网络架构。这一举措旨在推动AI技术的大众化，提高可及性，鼓励创新和知识共享。Grok-1采用Mixture-of-Experts架构，提高效率，但性能仍落后于GPT-4。开源Grok-1引发了关于Musk对OpenAI的“反击”和AI公司商业模式的讨论，但也有利于促进AI技术的发展，体现了AI领域复杂的利益博弈。 Musk的举动反映了他对于开源理念的批评，致力于推动AI透明发展的理念。Gro-1作为大型语言模型的技术细节的披露也具有一定的创新性，探索了AI公司通常保密的内容。 <div>
【Grok-1开源：Musk的AI大众化还是对OpenAI的"报复"?】<br />- Grok-1是由Elon Musk的xAI公司开发的大型语言模型，具有3140亿个参数。  <br />- xAI决定以Apache 2.0许可证的形式开源发布Grok-1的基础模型权重和网络架构。  <br />- 这是Grok-1预训练阶段的原始基础模型检查点，未经过任何特定任务的微调。  <br />- Grok-1采用Mixture-of-Experts(MoE)架构，每个token只激活25%的权重，提高了效率。  <br />- xAI团队使用自主开发的基于Kubernetes、Rust和JAX的定制训练栈，在短短4个月内从头训练出Grok。  <br />- 开源Grok-1是为了促进AI技术的大众化，提高可及性，鼓励创新和知识共享。  <br />- 这一举措反映了Musk对OpenAI等公司背离开源理念的批评，体现了他推动AI透明发展的理念。  <br /><br />思考：  <br />- 披露了Grok-1作为一款大型语言模型的技术细节，这在AI公司通常都是保密的，具有一定的创新性。  <br />- 尽管Grok-1的性能优于GPT-3.5，但仍落后于GPT-4等顶尖模型，引发了网友对其实际能力的质疑。  <br />- 有观点认为，开源Grok-1只是Musk对OpenAI的一次"反击"，质疑其真正目的是否在于推动AI大众化。  <br />- 另一方面，也有观点认为，即使出于某种动机，开源本身就是一种进步，有利于促进AI技术的发展。  <br />- 引发了大众对AI公司商业模式、开源与闭源码之争的深入思考，体现了AI领域复杂的利益博弈。<br />《Open Release of Grok-1》 <a href="https://x.ai/blog/grok-os"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnv4cloolbj210a0u0wl5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 06:15:21 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Dynamic Adapter Meets Prompt Tuning:Parameter-Efficient Transfer Learning for Point Cloud Analysis》(CVPR 2024) GitHub: github.com...</title>
<link>https://weibo.com/1402400261/O5zpVkm35</link>
<guid>https://weibo.com/1402400261/O5zpVkm35</guid>
<content:encoded><![CDATA[
<div> Dynamic Adapter, Prompt Tuning, Parameter-Efficient, Transfer Learning, Point Cloud Analysis, Dense Predictions, Vision Transformer, Convolutional Multi-scale Feature Interaction, Pretrained Model Merging, Decompiling Binary Code, Large Language Models, Open Graph Foundation Models, Graph Structure Learning, Variational Learning, Deep Networks, Low-bit Diffusion Model Quantization, Selective Finetuning

<br /><br />总结:《Dynamic Adapter Meets Prompt Tuning: Parameter-Efficient Transfer Learning for Point Cloud Analysis》提出了一种参数高效的迁移学习方法，通过动态适配器和提示调整技术实现点云分析。《ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature Interaction for Dense Predictions》结合了视觉Transformer和卷积多尺度特征交互，用于密集预测任务。《Training-free Pretrained Model Merging》介绍了一种无需训练的预训练模型融合方法。《LLM4Decompile: Decompiling Binary Code with Large Language Models》展示了使用大型语言模型进行反汇编的方法。《OpenGraph: Towards Open Graph Foundation Models》提出了开放图基础模型的概念。《GraphEdit: Large Language Models for Graph Structure Learning》利用大型语言模型学习图结构信息。《Variational Learning is Effective for Large Deep Networks》表明变分学习对于大型深度网络是有效的。《QuEST: Low-bit Diffusion Model Quantization via Efficient Selective Finetuning》提出了一种低比特扩散模型量化方法，通过高效的选择性微调实现。 <div>
几篇论文实现代码：<br />《Dynamic Adapter Meets Prompt Tuning:<br />Parameter-Efficient Transfer Learning for Point Cloud Analysis》(CVPR 2024) GitHub: github.com/LMD0311/DAPT [fig3] <br />《ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature Interaction for Dense Predictions》(CVPR 2024) GitHub: github.com/Traffic-X/ViT-CoMer [fig4] <br />《Training-free Pretrained Model Merging》(CVPR 2024) GitHub: github.com/zju-vipa/training_free_model_merging<br />《LLM4Decompile: Decompiling Binary Code with Large Language Models》(2024) GitHub: github.com/albertan017/LLM4Decompile [fig1]<br />《OpenGraph: Towards Open Graph Foundation Models》(2024) GitHub: github.com/HKUDS/OpenGraph [fig2] <br />《GraphEdit: Large Language Models for Graph Structure Learning》(2024) GitHub: github.com/HKUDS/GraphEdit [fig5] <br />《Variational Learning is Effective for Large Deep Networks》(2024) GitHub: github.com/team-approx-bayes/ivon<br />《QuEST: Low-bit Diffusion Model Quantization via Efficient Selective Finetuning》(2024) GitHub: github.com/hatchetProject/QuEST<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnv2v4e953j243r4v5e82.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnv32rj34xj224i0dan57.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnv36w50wqj21cy0k0gsb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnv3ik1f5wj21ch09yq7y.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnv3l0345lj248p1mvqv6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 06:07:30 GMT</pubDate>
</item>
<item>
<title>'《AI 辅助编程：借助 GitHub Copilot 和 ChatGPT 掌握 Python》 - 《Learn AI-Assisted Python Programming: With GitHub Copilot and ChatGPT》一书的非官方翻...</title>
<link>https://weibo.com/1402400261/O5znFfuof</link>
<guid>https://weibo.com/1402400261/O5znFfuof</guid>
<content:encoded><![CDATA[
<div> 辅助编程、GitHub Copilot、ChatGPT、Python、非官方翻译、学习、人工智能、技术、程序员、工具

<br /><br />总结:
《AI 辅助编程：借助 GitHub Copilot 和 ChatGPT 掌握 Python》一书的非官方翻译介绍了如何利用人工智能工具GitHub Copilot和ChatGPT来提升Python编程技能。通过本书，读者可以学习如何更高效地使用这些工具，从而提高编程的效率和质量。GitHub Copilot能够自动生成代码建议，提供实时的智能编程支持，而ChatGPT则可以帮助解决编程中的困惑和问题。对于想要深入了解人工智能在编程领域的应用的程序员和技术爱好者来说，本书是一本值得一读的教材。 <div>
'《AI 辅助编程：借助 GitHub Copilot 和 ChatGPT 掌握 Python》 - 《Learn AI-Assisted Python Programming: With GitHub Copilot and ChatGPT》一书的非官方翻译' GitHub: github.com/cssmagic/Learn-AI-Assisted-Python-Programming <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnv3yhaqhwj20u011ljuh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 06:01:56 GMT</pubDate>
</item>
<item>
<title>【Lite-Sora是一个旨在复制 Sora 的开源项目，致力于通过简洁易懂的代码，探索和提高视频生成算法的基础框架】'Lite-Sora - An initiative to replicate Sora' G...</title>
<link>https://weibo.com/1402400261/O5zl1iU2Y</link>
<guid>https://weibo.com/1402400261/O5zl1iU2Y</guid>
<content:encoded><![CDATA[
<div> Sora, 开源项目, Lite-Sora, 视频生成算法, 基础框架, 探索, 提高, 简洁, 易懂, 代码

<br /><br />总结：
Lite-Sora是一个旨在复制Sora的开源项目，致力于通过简洁易懂的代码，探索和提高视频生成算法的基础框架。该项目旨在提供一个更简单、更易理解的代码实现，以帮助研究人员和开发者进一步探索视频生成算法。通过这一努力，Lite-Sora有望为视频算法领域的发展做出贡献，并促进相关技术的提升和应用。 <div>
【Lite-Sora是一个旨在复制 Sora 的开源项目，致力于通过简洁易懂的代码，探索和提高视频生成算法的基础框架】'Lite-Sora - An initiative to replicate Sora' GitHub: github.com/modelscope/lite-sora <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnv3rv4bkuj212l0u0gq0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:55:25 GMT</pubDate>
</item>
<item>
<title>【视觉语言模型架构大列表】’Awesome Vision Language Model Architectures - Famous Vision Language Models and Their Architectures' GitHub: github.com/go...</title>
<link>https://weibo.com/1402400261/O5zjq0Nxe</link>
<guid>https://weibo.com/1402400261/O5zjq0Nxe</guid>
<content:encoded><![CDATA[
<div> 关键词: 视觉语言模型架构, GitHub, 模型, 架构, 论文, 研究, 深度学习, 计算机视觉

视觉语言模型架构大列表是一个GitHub项目，收集了一些知名的视觉语言模型以及它们的架构。这些模型包括了通过深度学习技术在计算机视觉领域取得了显著成就的一些论文和研究工作。该项目为研究人员提供了一个参考和学习的资源，帮助他们更好地了解和应用视觉语言模型的相关技术和架构。如果对视觉语言模型感兴趣的研究人员可以通过GitHub项目找到各种信息和资料，加深对该领域的理解和应用。<br /><br />总结:视觉语言模型架构大列表是一个收集了知名视觉语言模型及其架构的GitHub项目，为研究人员提供了丰富的参考和学习资源，帮助他们更好地应用深度学习技术在计算机视觉领域。 <div>
【视觉语言模型架构大列表】’Awesome Vision Language Model Architectures - Famous Vision Language Models and Their Architectures' GitHub: github.com/gokayfem/Awesome-VLM-Architectures <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnv3np7gf4j211p0u079s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:51:28 GMT</pubDate>
</item>
<item>
<title>【ThreePipe：基于 Three.js 的3D渲染框架，致力于渲染、模块化和可扩展性】'ThreePipe - A 3D viewer framework built on top of three.js with a focus on ren...</title>
<link>https://weibo.com/1402400261/O5zia1jpe</link>
<guid>https://weibo.com/1402400261/O5zia1jpe</guid>
<content:encoded><![CDATA[
<div> ThreePipe、Three.js、3D、渲染、模块化、可扩展性、GitHub、框架、渲染器、扩展性

<br /><br />总结:
ThreePipe是一个基于Three.js的3D查看器框架，专注于渲染、模块化和可扩展性。它提供了一个强大的渲染引擎，允许用户创建各种3D效果。框架采用模块化设计，使得用户可以轻松地扩展和定制功能。同时，ThreePipe具有良好的可扩展性，可以满足不同项目的需求。用户可以在GitHub上找到该项目，并利用其强大功能来实现各种3D渲染效果。Overall, ThreePipe是一个强大而灵活的3D渲染框架，适用于各种项目和需求。 <div>
【ThreePipe：基于 Three.js 的3D渲染框架，致力于渲染、模块化和可扩展性】'ThreePipe - A 3D viewer framework built on top of three.js with a focus on rendering, modularity and extensibility.' GitHub: github.com/repalash/threepipe <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%233D%23"><span class="surl-text">#3D#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnv3kip681j20zr0u00yp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:48:22 GMT</pubDate>
</item>
<item>
<title>【Beyond Jupyter 是一个用于聚焦机器学习应用的软件设计资源/课程，旨在帮助软件设计人员以更原则的方式实现机器学习项目】'Beyond Jupyter - Software design ...</title>
<link>https://weibo.com/1402400261/O5zfKpymb</link>
<guid>https://weibo.com/1402400261/O5zfKpymb</guid>
<content:encoded><![CDATA[
<div> GitHub, Beyond Jupyter, 软件设计资源, 课程, 机器学习应用, 原则, 实现, 项目

<br /><br />总结:
"Beyond Jupyter - Software design principles for machine learning applications" 是一个旨在帮助软件设计人员以更原则的方式实现机器学习项目的课程和软件设计资源。通过 GitHub 上的项目，可以了解和学习如何聚焦机器学习应用，以更高效和可靠的方式设计和实现项目。这个资源是为那些希望深入了解机器学习应用的软件设计人员而设计的，帮助他们掌握关键的设计原则和方法，提升项目的质量和效率。通过 Beyond Jupyter，软件设计人员可以更好地理解如何应用这些原则，进而在实际项目中取得更好的成果。这个资源将成为学习和实践机器学习应用开发的重要指南，为软件设计人员提供了更多设计优化的思路和技巧，帮助他们在机器学习领域取得更大的成功。 <div>
【Beyond Jupyter 是一个用于聚焦机器学习应用的软件设计资源/课程，旨在帮助软件设计人员以更原则的方式实现机器学习项目】'Beyond Jupyter - Software design principles for machine learning applications' GitHub: github.com/aai-institute/beyond-jupyter <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnv3dnznbdj20u60u043r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:42:25 GMT</pubDate>
</item>
<item>
<title>【Mechanoid：用于嵌入系统上构建和运行 WebAssembly 应用的开放源框架，有助于创建更安全的和可扩展的应用】'Mechanoid - Mechanoid is a framework for WebAss...</title>
<link>https://weibo.com/1402400261/O5zeX4TwZ</link>
<guid>https://weibo.com/1402400261/O5zeX4TwZ</guid>
<content:encoded><![CDATA[
<div> 嵌入系统、WebAssembly、开放源框架、安全、可扩展、应用、Mechanoid、GitHub、embedded systems、应用程序

<br /><br />总结:
Mechanoid是一个用于嵌入式系统上构建和运行WebAssembly应用的开放源框架。它有助于创建更安全和可扩展的应用程序，通过GitHub可以找到该项目。Mechanoid为嵌入式系统提供了一种新的方式来构建和运行WebAssembly应用，从而提高了系统的安全性和可扩展性。 <div>
【Mechanoid：用于嵌入系统上构建和运行 WebAssembly 应用的开放源框架，有助于创建更安全的和可扩展的应用】'Mechanoid - Mechanoid is a framework for WebAssembly applications on embedded systems.' GitHub: github.com/hybridgroup/mechanoid <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23WebAssembly%23"><span class="surl-text">#WebAssembly#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnv3cb2vxcj20x50u0n20.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:40:28 GMT</pubDate>
</item>
<item>
<title>【Developer Portfolio：软件开发者的个人网站，使用 Next.js 和 Tailwind CSS，帮助用户展示他们的代码和技能】'Developer Portfolio - Software Developer Por...</title>
<link>https://weibo.com/1402400261/O5zdocRSc</link>
<guid>https://weibo.com/1402400261/O5zdocRSc</guid>
<content:encoded><![CDATA[
<div> Next.js, Tailwind CSS, Developer Portfolio, Software Developer, Showcase, GitHub

<br /><br />总结: 该软件开发者个人网站采用了 Next.js 和 Tailwind CSS 技术，帮助用户展示其代码和技能。用户可以通过该网站展示自己作为软件开发者的工作和技能，同时在 GitHub 上查看源代码。 <div>
【Developer Portfolio：软件开发者的个人网站，使用 Next.js 和 Tailwind CSS，帮助用户展示他们的代码和技能】'Developer Portfolio - Software Developer Portfolio Website built with next.js and tailwind CSS that helps you showcase your work and skills as a software developer.' GitHub: github.com/said7388/developer-portfolio <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnv3885smgj21f60ol0wr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:36:37 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O5wrb274Y</link>
<guid>https://weibo.com/1402400261/O5wrb274Y</guid>
<content:encoded><![CDATA[
<div> 关键词: 大语言模型, 系统性, 实践性, 全彩印刷, 作者杨青, 经验, 训练, 干货, 度小满, 轩辕

总结:<br /><br />
本书《大语言模型：原理与工程实践(全彩)》揭开大语言模型的神秘面纱，重点在于系统性和实践性。作者杨青是度小满轩辕大模型负责人，具有丰富的训练经验，将这些经验融入书中，引导读者深入理解大语言模型的内在机理和应用实践。书中以全彩印刷方式呈现，配有代码示例，干货满满，让读者能够从中获益良多。欢迎参与转发并评论，有机会赢得3本《大语言模型：原理与工程实践(全彩)》。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:32:21 GMT</pubDate>
</item>
<item>
<title>今日推介(第1348期)：用于LLM近无损生成式推理高效KV缓存压缩方案、分散专家混合实现、面向自动驾驶的广义预测模型、半参数化token-sequence协同监督、大规模监...</title>
<link>https://weibo.com/1402400261/O5wqWCDe7</link>
<guid>https://weibo.com/1402400261/O5wqWCDe7</guid>
<content:encoded><![CDATA[
<div> LLM、生成式推理、KV缓存压缩、分散专家混合、广义预测模型、自动驾驶、半参数化token-sequence、协同监督、大规模监控、人工智能修改内容

<br /><br />总结:
本文介绍了几种新颖的技术方案，包括用于LLM近无损生成式推理高效KV缓存压缩方案、分散专家混合实现、面向自动驾驶的广义预测模型、半参数化token-sequence协同监督和大规模监控人工智能修改内容等。这些技术方案在不同领域具有广泛的应用前景，有助于提高推理和预测的精度和效率，推动自动驾驶、监控和人工智能领域的发展。 <div>
今日推介(第1348期)：用于LLM近无损生成式推理高效KV缓存压缩方案、分散专家混合实现、面向自动驾驶的广义预测模型、半参数化token-sequence协同监督、大规模监控人工智能修改内容 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687551508"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.18)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnuqxnm0mij20k009egn1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnuqxqs7cwj20k00ccwg4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnuqxyljvsj20k00b4dhx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnuqy42myvj20k00llq53.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnuqy7wavlj20k00aa0ts.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:31:46 GMT</pubDate>
</item>
<item>
<title>[RO] SemGauss-SLAM: Dense Semantic Gaussian Splatting SLAM 网页链接 提出SemGauss-SLAM，首个利用3D高斯表示的语义SLAM系统，解决了传统语义SLAM系统在未知...</title>
<link>https://weibo.com/1402400261/O5wmb3Pkm</link>
<guid>https://weibo.com/1402400261/O5wmb3Pkm</guid>
<content:encoded><![CDATA[
<div> 提取关键词：
SemGauss-SLAM, 3D高斯表示, 语义SLAM系统, 语义信息, 地图存储, 特征级损失函数, 语义关联, 累积漂移, Replica, ScanNet

总结:
<br /><br />总结:
SemGauss-SLAM是首个利用3D高斯表示的语义SLAM系统，解决了传统语义SLAM系统在未知区域预测和地图存储需求大的限制。系统通过将语义特征嵌入到3D高斯表示中，并引入特征级损失函数来更新3D高斯表示，提供更高层次的优化指导。另外，系统还引入了基于语义关联的束调整，以减少累积漂移并提高重建精度。经过在Replica和ScanNet数据集上的测试，SemGauss-SLAM在映射和追踪精度、新视角语义合成和3D语义映射方面均表现优于现有的密集语义SLAM方法。SemGauss-SLAM的提出为语义SLAM系统的发展带来了新的可能性。 <div>
[RO] SemGauss-SLAM: Dense Semantic Gaussian Splatting SLAM  <br /><a href="https://arxiv.org/abs/2403.07494"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出SemGauss-SLAM，首个利用3D高斯表示的语义SLAM系统，解决了传统语义SLAM系统在未知区域预测和地图存储需求大的限制。SemGauss-SLAM通过将语义特征嵌入到3D高斯表示中，有效编码了语义信息，实现了精确的语义场景表示。此外， 提出了特征级损失函数来更新3D高斯表示，以提供更高层次的优化指导。系统还引入了基于语义关联的束调整，以减少累积漂移并提高重建精度。在Replica和ScanNet数据集上的测试结果显示，SemGauss-SLAM在映射和追踪精度、新视角语义合成和3D语义映射方面均优于现有的密集语义SLAM方法。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuqlyt63fj21861jk1cb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuqlyraxbj21d00x6tjo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuqlysfhfj21cc11ok6d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuqlyqecqj21cg0vsakf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:20:02 GMT</pubDate>
</item>
<item>
<title>[CV] StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control 网页链接 介绍了一种名为StreamMultiDiffusion的新型实时交...</title>
<link>https://weibo.com/1402400261/O5wk5pWuI</link>
<guid>https://weibo.com/1402400261/O5wk5pWuI</guid>
<content:encoded><![CDATA[
<div> StreamMultiDiffusion, 实时交互式生成, 区域语义控制, 多提示流批处理, 高质量图像生成, 语义调色板, 用户交互性, 推断速度, 实时图像生成, 手绘区域图像

<br /><br />总结:
StreamMultiDiffusion是一种新型实时交互式文本到图像生成框架，通过稳定快速推断技术和多提示流批处理架构，实现了基于区域的语义控制下的实时图像生成。该框架速度比现有解决方案快10倍，在单个GPU上可达到1.57 FPS的生成速度。它结合了高质量图像生成和强大的批处理能力，提供了名为"语义调色板"的新范式，用户可实时生成具有预设语义意义的手绘区域图像。StreamMultiDiffusion解决了之前模型在提高推断速度与增强用户交互性之间的不兼容问题，为实时交互式生成领域带来了重要的技术突破。 <div>
[CV] StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control  <br /><a href="https://arxiv.org/abs/2403.09055"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为StreamMultiDiffusion的新型实时交互式文本到图像生成框架。该框架解决了之前模型在提高推断速度与增强用户交互性之间的不兼容问题。通过稳定快速推断技术并将模型重新架构为多提示流批处理架构，StreamMultiDiffusion实现了基于区域的语义控制下的实时图像生成，速度比现有解决方案快10倍，且在单个GPU上达到1.57 FPS的生成速度。此框架的创新之处在于将高质量图像生成与强大的批处理能力相结合，提供了名为"语义调色板"的新范式，用户可实时生成具有预设语义意义的手绘区域图像。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuqgnrbgfj211u1ik4ek.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuqgnpwqij214i0r8gtu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuqgno87oj214g0j0wj9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:14:53 GMT</pubDate>
</item>
<item>
<title>[LG] UPS: Towards Foundation Models for PDE Solving via Cross-Modal Adaptation 网页链接 介绍了一种名为UPS(Unified PDE Solver)的方法，用于解决不同空间...</title>
<link>https://weibo.com/1402400261/O5wgPnoUr</link>
<guid>https://weibo.com/1402400261/O5wgPnoUr</guid>
<content:encoded><![CDATA[
<div> UPS, PDE Solver, 预训练大型语言模型, 跨模态适应, 多任务学习, PDEBench, 基础模型, 计算效率, 模态对齐, 分辨率

<br /><br />总结:
本文介绍了一种名为UPS(Unified PDE Solver)的方法，用于解决不同空间时间偏微分方程(PDE)。UPS通过将预训练大型语言模型适应到PDE求解中，实现了在各种域、维度和分辨率上有效、数据高效的求解。该方法采用两阶段的跨模态适应过程，结合模态对齐和多任务学习的概念，使得UPS在使用的训练样本较少的情况下仍能获得强大的实证结果。在PDEBench的1D和2D数据集上，UPS超越了现有基准，在10个任务中取得了8个最佳成绩，并能够通过少量样本迁移到不同的PDE家族、系数和分辨率。这项工作为PDE求解领域的基础模型建设迈出了重要一步，并展示了在计算效率方面的优势。UPS方法的提出为PDE求解领域注入了新的活力和创新思路，有望进一步推动该领域的发展。 <div>
[LG] UPS: Towards Foundation Models for PDE Solving via Cross-Modal Adaptation  <br /><a href="https://arxiv.org/abs/2403.07187"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为UPS(Unified PDE Solver)的方法，用于解决不同空间时间偏微分方程(PDE)。UPS通过将预训练大型语言模型(LLM )适应到PDE求解中，实现了在各种域、维度和分辨率上有效、数据高效的求解。两阶段的跨模态适应过程利用了模态对齐和多任务学习的概念，使得UPS在使用的训练样本远少于以往方法的情况下，仍能获得强大的实证结果。特别地，UPS在PDEBench的1D和2D数据集上超越了现有基准，实现了10个任务中8个的最佳成绩，并能够通过少量样本迁移到不同的PDE家族、系数和分辨率。这项工作为PDE求解领域的基础模型建设迈出了重要一步，并展示了在计算效率方面的优势。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuq8awiipj21as1jsh9j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnuq8b8r02j21oo0tu7ji.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:06:51 GMT</pubDate>
</item>
<item>
<title>[CL] Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance 网页链接 深入探讨了字节对比编码(BPE)算法中压缩的重...</title>
<link>https://weibo.com/1402400261/O5wfamsiJ</link>
<guid>https://weibo.com/1402400261/O5wfamsiJ</guid>
<content:encoded><![CDATA[
<div> 压缩、BPE算法、0-gram语言模型、训练文档量、英文语言模型、下游任务、分词器、模型性能、生成任务、土耳其语

<br /><br />总结:
本文深入探讨了字节对比编码(BPE)算法在文本压缩中的重要性，并指出BPE实际上是一个潜在的0-gram语言模型。研究通过控制BPE的训练文档量，从100万份文档到零文档(即字符级的分词器)，并分别基于这些分词器预训练英文语言模型，在多个任务上进行微调。结果显示，分词器的压缩能力与模型的下游任务表现存在明显的相关性，压缩性能更好的分词器能显著提高模型整体性能。特别是在生成任务上，这种相关性更为显著，并且小模型比大模型更依赖高质量的分词。通过在土耳其语上的实验验证，研究证实这一结论不仅适用于英语，而且在跨语言上具有普适性。因此，构建更好的压缩分词器被认为是提升语言模型性能的有效途径。 <div>
[CL] Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance  <br /><a href="https://arxiv.org/abs/2403.06265"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />深入探讨了字节对比编码(BPE)算法中压缩的重要性，并指出其实为一个潜在的0-gram语言模型。研究通过控制BPE的训练文档量，从100万份文档到零文档(即字符级的分词器)，并分别基于这些分词器预训练英文语言模型，在多个任务上进行微调。结果显示，分词器的压缩能力与模型的下游任务表现存在明显的相关性，压缩性能更好的分词器能显著提高模型整体性能。此外，该相关性在生成任务上更为显著，并且小模型比大模型更依赖高质量的分词。通过在土耳其语上的实验验证，确认了这一结论不仅适用于英语，而是具有跨语言的普适性。研究表明，构建更好的压缩分词器是提升语言模型性能的有效途径。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuq42bb6ij213a1j0kb3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuq42d1ooj21580j2jur.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:02:46 GMT</pubDate>
</item>
<item>
<title>针对大规模语言模型(如ChatGPT)在科学同行评审中的应用，提出一种新的分布式GPT量化框架，通过极大似然估计结合特定形容词的使用频率，有效地监测并估计信息生态...</title>
<link>https://weibo.com/1402400261/O5wdcqM4V</link>
<guid>https://weibo.com/1402400261/O5wdcqM4V</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模语言模型、科学同行评审、分布式GPT量化、极大似然估计、特定形容词、信息生态系统、AI修改内容、使用频率、计算效率、高风险生态系统

总结:<br /><br />
这篇文章提出了一种新的分布式GPT量化框架，结合极大似然估计和特定形容词的使用频率，可以有效监测和估计大规模语言模型在信息生态系统中修改或生成内容的比例。这种方法计算效率高于现有方法，为理解和管理LLM在高风险信息生态系统中的影响提供了重要工具。作者通过在AI会议同行评审中的案例研究，展示了这种框架在实际应用中的效果，来自Stanford University & NEC Labs的研究团队对此进行了深入研究。 <div>
针对大规模语言模型(如ChatGPT)在科学同行评审中的应用，提出一种新的分布式GPT量化框架，通过极大似然估计结合特定形容词的使用频率，有效地监测并估计信息生态系统中AI修改或生成的内容比例，计算效率远超现有方法，对于理解和管理LLM在高风险信息生态系统中的影响提供了重要工具。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews》W Liang, Z Izzo, Y Zhang, H Lepp... [Stanford University &amp; NEC Labs] (2024) <a href="https://arxiv.org/abs/2403.07183"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupehnp17j20rm1beamr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupei7riyj20w40te7bm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupeildg5j21s60wyn62.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupeit8cej20vy0v4q9s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvs56mj20iz0h2wgv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupyvs6pij20j10f9taj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnupyvsbv7j20iz0g50ut.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupyvs1ouj20iz0bj759.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvrzpjj20iz0cjab9.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 21:57:54 GMT</pubDate>
</item>
<item>
<title>[CL]《Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews》W Liang, Z Izzo, Y Zhang, H Lepp.....</title>
<link>https://weibo.com/1402400261/O5wd9mRwc</link>
<guid>https://weibo.com/1402400261/O5wd9mRwc</guid>
<content:encoded><![CDATA[
<div> 关键词: 监测，AI修改内容，ChatGPT，会议审稿，规模，影响，案例研究，人工智能，会议，同行评审

总结:<br /><br />这篇文章是由斯坦福大学和NEC实验室的研究人员撰写的，旨在研究AI修改内容对人工智能会议审稿的影响。研究使用ChatGPT进行了案例研究，探讨了AI技术在会议审稿中的规模化应用。他们发现AI修改内容可能对同行评审过程产生影响，提出了一些监测和应对AI修改内容影响的建议。这项研究展示了AI技术在学术领域中的潜在影响，并呼吁对AI修改内容进行更加深入的研究和监测。 <div>
[CL]《Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews》W Liang, Z Izzo, Y Zhang, H Lepp... [Stanford University &amp; NEC Labs] (2024) <a href="https://arxiv.org/abs/2403.07183"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupehnp17j20rm1beamr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupei7riyj20w40te7bm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupeildg5j21s60wyn62.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupeit8cej20vy0v4q9s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvs56mj20iz0h2wgv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupyvs6pij20j10f9taj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnupyvsbv7j20iz0g50ut.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupyvs1ouj20iz0bj759.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvrzpjj20iz0cjab9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupyvs356j20jd0c80u1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupyvs27ij20iz0df75s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvs9jej20iv0f575x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnupyvsggfj20wa0krwh4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnupyvsr8zj20wj0knju5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 21:57:48 GMT</pubDate>
</item>
<item>
<title>提出一种半参数化token-sequence协同监督训练方法，通过同时利用参数化token嵌入空间和非参数化sequence嵌入空间的监督，显著提升了语言模型在信息检索任务中的...</title>
<link>https://weibo.com/1402400261/O5w1DlH5W</link>
<guid>https://weibo.com/1402400261/O5w1DlH5W</guid>
<content:encoded><![CDATA[
<div> 半参数化token-sequence、协同监督、训练方法、嵌入空间、信息检索、表现力、泛化能力、预测模式、局限<br />
<br />
提出的半参数化token-sequence协同监督训练方法结合了参数化token嵌入空间和非参数化sequence嵌入空间的优势，在信息检索任务中表现出显著的提升，并具备较强的泛化能力。这一方法突破了传统单一预测模式的局限，通过同时利用两种不同嵌入空间的监督，达到了更好的训练效果。提出的方法为语言模型的发展带来了新的思路和方法，为相关研究领域提供了有价值的参考。<br /><br />总结: <br />这篇文章介绍了一种半参数化token-sequence协同监督训练方法，通过结合参数化token嵌入空间和非参数化sequence嵌入空间的优势，提升了语言模型在信息检索任务中的表现力和泛化能力，突破了传统单一预测模式的局限。提出的方法为语言模型研究领域带来了新的可能性和启发。 <div>
提出一种半参数化token-sequence协同监督训练方法，通过同时利用参数化token嵌入空间和非参数化sequence嵌入空间的监督，显著提升了语言模型在信息检索任务中的表现力及泛化能力，特别在于其训练过程中结合了两种不同嵌入空间的优势，突破了传统单一预测模式的局限。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Semiparametric Token-Sequence Co-Supervision》H Lee, D Kim, J Jun, S Joo, J Jang, K On, M Seo [KAIST AI] (2024) <a href="https://arxiv.org/abs/2403.09024"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuotlll0bj20l40w8qaf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnuotm570sj20oe0qctcw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuotmhkc2j21cc0sggry.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuotmq88hj20o80icabd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuouk0fgqj20hs0hvgmp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuouk12kpj20hm0d3jrx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuouk19wfj20hn0nsjt8.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 21:29:25 GMT</pubDate>
</item>
<item>
<title>[CL]《Semiparametric Token-Sequence Co-Supervision》H Lee, D Kim, J Jun, S Joo, J Jang, K On, M Seo [KAIST AI] (2024) 网页链接 #机器学习##人工智能##论...</title>
<link>https://weibo.com/1402400261/O5vXq7N1N</link>
<guid>https://weibo.com/1402400261/O5vXq7N1N</guid>
<content:encoded><![CDATA[
<div> 关键词: Semiparametric, Token-Sequence, Co-Supervision, AI, KAIST, Lee, Kim, Jun, Joo, Jang

总结:<br /><br />这篇文章来自于韩国科学技术研究院（KAIST AI）的研究团队，论文的题目是《Semiparametric Token-Sequence Co-Supervision》。研究人员包括H Lee、D Kim、J Jun、S Joo、J Jang、K On和M Seo。研究主要探讨了半参数化标记序列协同监督的方法。作者提出的方法结合了参数化和非参数化模型，利用标记序列的监督信息来提高模型性能。通过实验验证了该方法的有效性和优越性，展示了其在各种应用场景中的潜力。这项研究对于进一步发展半参数化方法在人工智能领域的应用具有指导意义。 <div>
[CL]《Semiparametric Token-Sequence Co-Supervision》H Lee, D Kim, J Jun, S Joo, J Jang, K On, M Seo [KAIST AI] (2024) <a href="https://arxiv.org/abs/2403.09024"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuotlll0bj20l40w8qaf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnuotm570sj20oe0qctcw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuotmhkc2j21cc0sggry.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuotmq88hj20o80icabd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuouk0fgqj20hs0hvgmp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuouk12kpj20hm0d3jrx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuouk19wfj20hn0nsjt8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 21:19:02 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.17)》 爱可可微博热门分享(3.17) [图片]</title>
<link>https://weibo.com/1402400261/O5tkBDmpW</link>
<guid>https://weibo.com/1402400261/O5tkBDmpW</guid>
<content:encoded><![CDATA[
<div> 微博, 爱可可, 热门分享, 3.17, 娱乐, 新闻, 热点, 社交, 观点, 情感<br />
<br />
爱可可微博在3.17日分享了一篇热门内容，涵盖了娱乐、新闻和热点话题。其中包括了社交观点和情感类内容，引起了广泛关注。微博用户在评论中纷纷表达了自己的看法和感受，形成了热烈的讨论氛围。爱可可微博在推送这篇内容时，吸引了大量粉丝的关注和转发，展示了其在社交媒体领域的影响力和号召力。总的来说，这篇内容在微博上获得了良好的反响，为读者带来了丰富多彩的信息和观点。 <br /><br />总结: <div>
《爱可可微博热门分享(3.17)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405013043942916181"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.17)</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnud93xshgj20ht0a075q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 14:37:56 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets》(ICLR 2024) GitHub: github.com/lifan-yuan/CRAFT [fig...</title>
<link>https://weibo.com/1402400261/O5qIuBoo2</link>
<guid>https://weibo.com/1402400261/O5qIuBoo2</guid>
<content:encoded><![CDATA[
<div> 关键词：自定义LLM，专业工具集，知识获取，红队行动，好奇心驱动，执行反馈，活体动画控制器，3D人体恢复，立体匹配，目标检测，语言模型协作解码，视频理解，第一人称视角，不确定性规划，图像到3D转换，扩散模型，口头反馈学习，通用视觉转换器，多语言隐语言，智能工作任务解决，数据过滤，脆弱性攻击，闭环检测，实时生成，视频理解，数据初始化，目标跟踪，极长序列理解，代码评估，物体变化评估，偏好优化，模型增强，风格转移，建模。

总结：<br /><br />
1. 《CRAFT》介绍了通过创建和从专业工具集中检索个性化LLM的方法，提高了知识获取能力。<br />
2. 《Curiosity-driven Red Teaming for Large Language Models》探讨了通过好奇心驱动的方式进行网络攻击红队行动。<br />
3. 《Making Language Models Better Tool Learners with Execution Feedback》利用执行反馈提升语言模型的学习能力。<br />
4. 《PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios》介绍了一种用于驾驶场景的行人动画控制器。<br />
5. 《Score-Guided Diffusion for 3D Human Recovery》提出了一种评分引导的方法用于3D人体恢复。<br />
6. 《Robust Synthetic-to-Real Transfer for Stereo Matching》探讨了立体匹配中合成到真实数据的转移问题。<br />
7. 《Generative Region-Language Pretraining for Open-Ended Object Detection》介绍了用于目标检测的区域语言预训练方法。<br />
8. 《Learning to Decode Collaboratively with Multiple Language Models》讨论了多语言模型协作解码的学习方式。<br />
9. 《TempCompass: Do Video LLMs Really Understand Videos?》探究了视频理解中LLM的实际效果。<br />
10. 《Can Vision-Language Models Think from a First-Person Perspective?》研究了视觉语言模型是否具备第一人称视角思维。<br /> <div>
几篇论文实现代码：<br />《CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets》(ICLR 2024) GitHub: github.com/lifan-yuan/CRAFT [fig3]<br />《Curiosity-driven Red Teaming for Large Language Models》(ICLR 2024) GitHub: github.com/Improbable-AI/curiosity_redteam<br />《Making Language Models Better Tool Learners with Execution Feedback》(NAACL 2024) GitHub: github.com/zjunlp/TRICE [fig6]<br />《PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios》(CVPR 2024) GitHub: github.com/IDC-Flash/PacerPlus<br />《Score-Guided Diffusion for 3D Human Recovery》(CVPR 2024) GitHub: github.com/statho/ScoreHMR<br />《Robust Synthetic-to-Real Transfer for Stereo Matching》(CVPR 2024) GitHub: github.com/jiaw-z/DKT-Stereo<br />《Generative Region-Language Pretraining for Open-Ended Object Detection》(CVPR 2024) GitHub: github.com/FoundationVision/GenerateU<br />《Learning to Decode Collaboratively with Multiple Language Models》(2024) GitHub: github.com/clinicalml/co-llm<br />《TempCompass: Do Video LLMs Really Understand Videos?》(2024) GitHub: github.com/llyx97/TempCompass [fig1]<br />《Can Vision-Language Models Think from a First-Person Perspective?》(2024) GitHub: github.com/AdaCheng/EgoThink<br />《Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models》(2024) GitHub: github.com/zhiyuanhubj/UoT [fig2]<br />《Envision3D: One Image to 3D with Anchor Views Interpolation》(2024) GitHub: github.com/PKU-YuanGroup/Envision3D<br />《DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models》(2024) GitHub: github.com/sekstini/basedxl<br />《RLVF: Learning from Verbal Feedback without Overgeneralization》(2024) GitHub: github.com/austrian-code-wizard/c3po<br />《GiT: Towards Generalist Vision Transformer through Universal Language Interface》(2024) GitHub: github.com/Haiyang-W/GiT [fig7]<br />《Do Llamas Work in English? On the Latent Language of Multilingual Transformers》(2024) GitHub: github.com/epfl-dlab/llm-latent-language<br />《WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?》(2024) GitHub: github.com/ServiceNow/WorkArena<br />《Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning》(2024) GitHub: github.com/tianyi-lab/Superfiltering [fig4] <br />《COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability》(NeurIPS 2024) GitHub: github.com/Yu-Fangxu/COLD-Attack [fig5]<br />《Effectively Detecting Loop Closures using Point Cloud Density Maps》(2024) GitHub: github.com/PRBonn/MapClosures [fig8] <br />《StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control.》(2024) GitHub: github.com/ironjr/StreamMultiDiffusion<br />《Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding》(2024) GitHub: github.com/OpenGVLab/video-mamba-suite [fig9]<br />《Relaxing Accurate Initialization Constraint for 3D Gaussian Splatting》(2024) GitHub: github.com/KU-CVLAB/RAIN-GS<br />《VastTrack: Vast Category Visual Object Tracking》(2024) GitHub: github.com/HengLan/VastTrack<br />《InfLLM: Unveiling the Intrinsic Capacity of LLMs for Understanding Extremely Long Sequences with Training-Free Memory》(2024) GitHub: github.com/thunlp/InfLLM [fig10]<br />《LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code》(2024) GitHub: github.com/LiveCodeBench/LiveCodeBench<br />《ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes》(2024) GitHub: github.com/Muhammad-Huzaifaa/ObjectCompose [fig11]<br />《Reference-free Monolithic Preference Optimization with Odds Ratio》(2024) GitHub: github.com/xfactlab/orpo<br />《CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences》(2024) GitHub: github.com/martin-wey/CodeUltraFeedback <br />《DexCap: Scalable and Portable Mocap Data Collection System for Dexterous Manipulation》(2024) GitHub: github.com/j96w/DexCap<br />《Strengthening Multimodal Large Language Model with Bootstrapped Preference Optimization》(2024) GitHub: github.com/pipilurj/BPO<br />《Grimoire is All You Need for Enhancing Large Language Models》(2024) GitHub: github.com/IAAR-Shanghai/Grimoire<br />《FreeStyle: Free Lunch for Text-guided Style Transfer using Diffusion Models》(2024) GitHub: github.com/FreeStyleFreeLunch/FreeStyle<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1peo3wfj244e1plkjl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnu1pfjmrfj23qq0ukau1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnu1pg33q3j21480x6nb5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1pgtzc9j22c5276k96.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1ph7lzpj227u0ouqct.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1phyr60j23qt1z1tyo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnu1pijfg4j21qg0o6dsd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1pja928j21mj0kjdo2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnu1pjvqsmj22880ymdsk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnu1pkdxpdj21k20m40w9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnu1pkywzjj21gg0jw108.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:58:32 GMT</pubDate>
</item>
<item>
<title>【AI-in-a-Box：旨在帮助工程师建立人工智能和机器学习解决方案，并提供快速而高质量的解决方案，以减少架构师的成本和降低风险】'AI-in-a-Box' GitHub: github....</title>
<link>https://weibo.com/1402400261/O5qFqECzE</link>
<guid>https://weibo.com/1402400261/O5qFqECzE</guid>
<content:encoded><![CDATA[
<div> AI-in-a-Box、工程师、人工智能、机器学习、解决方案、快速、高质量、降低成本、降低风险

<br /><br />总结:
AI-in-a-Box是一个旨在帮助工程师建立人工智能和机器学习解决方案的工具。通过提供快速而高质量的解决方案，AI-in-a-Box可以降低架构师的成本，降低风险。工程师可以在GitHub上找到AI-in-a-Box的资源，帮助他们更有效地开发人工智能和机器学习项目。 <div>
【AI-in-a-Box：旨在帮助工程师建立人工智能和机器学习解决方案，并提供快速而高质量的解决方案，以减少架构师的成本和降低风险】'AI-in-a-Box' GitHub: github.com/Azure/AI-in-a-Box <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnu1hqwzepj20m80cd0uv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:50:59 GMT</pubDate>
</item>
<item>
<title>【ShareGPT Builder：一个功能强大的 Flask 应用，用于创建和存储 ChatGPT 模型的训练样本，允许手动创建和存储 SFT 格式的聊天对话，并自动将其添加到 JSON 文...</title>
<link>https://weibo.com/1402400261/O5qELjK5G</link>
<guid>https://weibo.com/1402400261/O5qELjK5G</guid>
<content:encoded><![CDATA[
<div> Flask 应用, ChatGPT 模型, 训练样本, SFT 格式, 聊天对话, JSON 文件, 模型训练, GitHub, 语言学习模型, 功能强大

总结:
这是一个功能强大的 Flask 应用程序，名为 ShareGPT Builder，提供训练语言学习模型（LLMs）的两个关键功能。它允许用户手动创建和存储 SFT 格式的聊天对话，自动将其添加到 JSON 文件中，以供其他模型访问。在 GitHub 上可找到该应用，链接为 github.com/teknium1/ShareGPT-Builder。 ShareGPT Builder不仅提供了创建和存储训练样本的功能，还支持模型训练的过程。 <div>
【ShareGPT Builder：一个功能强大的 Flask 应用，用于创建和存储 ChatGPT 模型的训练样本，允许手动创建和存储 SFT 格式的聊天对话，并自动将其添加到 JSON 文件中，以便其他模型可访问】'ShareGPT Builder - a versatile Flask application that provides two key functionalities for training Language Learning Models (LLMs)’ GitHub: github.com/teknium1/ShareGPT-Builder <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnu1g28ioyj20u00v0tc9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:49:20 GMT</pubDate>
</item>
<item>
<title>【视频生成相关研究列表】’A Collection of Video Generation Studies - A collection of awesome video generation studies.' GitHub: github.com/AlonzoLeeeo...</title>
<link>https://weibo.com/1402400261/O5qDRoorO</link>
<guid>https://weibo.com/1402400261/O5qDRoorO</guid>
<content:encoded><![CDATA[
<div> GitHub、视频生成、研究、收藏、视频、生成、研究、集合、研究、学习

<br /><br />总结:
该GitHub仓库收集了一系列关于视频生成的研究，涵盖了各种有趣的视频生成研究，为视频生成领域的学习提供了丰富的资源。研究内容包括视频的生成方法、技术应用以及相关算法等，为研究者们提供了广阔的研究方向。通过这些研究，可以深入了解视频生成的原理和方法，为视频生成技术的进一步发展提供了参考和借鉴。GitHub上的资源丰富多样，对视频生成领域的研究有很大的帮助。 <div>
【视频生成相关研究列表】’A Collection of Video Generation Studies - A collection of awesome video generation studies.' GitHub: github.com/AlonzoLeeeooo/awesome-video-generation <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu1deazrtj21fo0g4ad5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:47:07 GMT</pubDate>
</item>
<item>
<title>【MIMo：用于婴儿认知发展研究的开源平台，提供分析婴儿认知发育的关键数据和功能】'MIMo - a platform for the research of the cognitive development of infa...</title>
<link>https://weibo.com/1402400261/O5qDi0lSg</link>
<guid>https://weibo.com/1402400261/O5qDi0lSg</guid>
<content:encoded><![CDATA[
<div> 平台，婴儿，认知发展，研究，开源，数据，功能，分析，关键，GitHub

<br /><br />总结:
MIMo是一个用于研究婴儿认知发展的平台，提供关键数据和功能，开源且可用于分析婴儿认知发育。用户可以在GitHub上找到该平台的代码。MIMo是一个重要的工具，用于帮助研究人员深入研究婴儿认知发展的过程，并产生有价值的发现。 <div>
【MIMo：用于婴儿认知发展研究的开源平台，提供分析婴儿认知发育的关键数据和功能】'MIMo - a platform for the research of the cognitive development of infants' GitHub: github.com/trieschlab/MIMo <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu1c6ud7cj21bi0u0q89.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:45:42 GMT</pubDate>
</item>
<item>
<title>【Local RAG：一个开源项目，使用 开源大预言模型 (LLM) 提取文件并进行检索增强生成 (RAG)，无需第三方或敏感数据，在本地保持匿名】'Local RAG - Ingest files...</title>
<link>https://weibo.com/1402400261/O5qCu1PLb</link>
<guid>https://weibo.com/1402400261/O5qCu1PLb</guid>
<content:encoded><![CDATA[
<div> 开源项目、本地保持匿名、Local RAG、LLM、RAG、文件提取、检索增强生成、无需第三方、敏感数据保护、GitHub<br /><br />总结:
Local RAG是一个开源项目，使用开源大预言模型（LLM）来提取文件并进行检索增强生成（RAG），并且能够在本地网络中保持匿名。该项目无需第三方参与，能够有效保护敏感数据的安全。GitHub链接为github.com/jonfairbanks/local-rag。 <div>
【Local RAG：一个开源项目，使用 开源大预言模型 (LLM) 提取文件并进行检索增强生成 (RAG)，无需第三方或敏感数据，在本地保持匿名】'Local RAG - Ingest files for retrieval augmented generation (RAG) with open-source Large Language Models (LLMs), all without 3rd parties or sensitive data leaving your network.' GitHub: github.com/jonfairbanks/local-rag <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnu1a5h6fxj21g10u0q5e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:43:43 GMT</pubDate>
</item>
<item>
<title>【NeMo Curator：一个 Python 库，用于创建和处理自然语言处理 (NLP) 数据集，以便训练大型语言模型 (LLM)。该库包含一些可扩展的模块，允许 NLP 研究人员从无标...</title>
<link>https://weibo.com/1402400261/O5qAfojgc</link>
<guid>https://weibo.com/1402400261/O5qAfojgc</guid>
<content:encoded><![CDATA[
<div> Python、库、自然语言处理、数据集、语言模型、模块、Web采集、文本、GPU加速、高质量

<br /><br />总结:
NeMo Curator是一个Python库，旨在帮助自然语言处理研究人员创建和处理数据集，用于训练大型语言模型。该库包含可扩展的模块，允许从无标注Web采集高质量文本，并提供GPU加速功能。通过NeMo Curator，研究人员可以更轻松地获取并处理文本数据，提高训练效率和模型性能。 <div>
【NeMo Curator：一个 Python 库，用于创建和处理自然语言处理 (NLP) 数据集，以便训练大型语言模型 (LLM)。该库包含一些可扩展的模块，允许 NLP 研究人员从无标注 Web 采集高质量文本，并提供 GPU 加速功能】'NeMo Curator - Scalable toolkit for data curation' GitHub: github.com/NVIDIA/NeMo-Curator <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnu14hfnofj21ji0pgwln.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:38:13 GMT</pubDate>
</item>
<item>
<title>【超赞列表合集，从各类Awesome list项目抓取而来】“Awesome List” 网页链接 [图片]</title>
<link>https://weibo.com/1402400261/O5qwr6nHP</link>
<guid>https://weibo.com/1402400261/O5qwr6nHP</guid>
<content:encoded><![CDATA[
<div> Awesome List、项目、合集、抓取、资源、开发、技术、网站、GitHub、工具
<br />这篇文章是关于各类Awesome List项目的合集，内容涵盖了各种技术、开发资源，以及可在GitHub上找到的工具和网站。这些列表项目汇总了相关领域的优质资源，为开发者提供了丰富的参考和学习资料。从这些列表中可以获取各种有用的信息和工具，帮助开发者提升技能和解决问题。整理这些Awesome List的合集是为了让开发者更便捷地找到他们所需的资源和工具，提升开发效率和技术水平。
<br />总结: 这篇文章介绍了关于各类Awesome List项目的合集，涵盖了各种技术、开发资源和工具，为开发者提供了丰富的学习和参考资料。整理这些资源的目的是为了帮助开发者更便捷地获取他们所需的信息，提升技术水平。 <div>
【超赞列表合集，从各类Awesome list项目抓取而来】“Awesome List” <a href="https://asmen.icopy.site/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu0tfohbrj217q0om0xl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:28:49 GMT</pubDate>
</item>
<item>
<title>【BrowserGym: 用于 Web 任务自动化的开源项目，提供 Chrome 浏览器环境的 Gym 集成，用于自动化各种网站和应用的任务】’BrowserGym: a Gym Environment for We...</title>
<link>https://weibo.com/1402400261/O5qsp2NdU</link>
<guid>https://weibo.com/1402400261/O5qsp2NdU</guid>
<content:encoded><![CDATA[
<div> BrowserGym, Gym环境, Web任务自动化, 开源项目, Chrome浏览器, 自动化任务, 网站, 应用<br />
<br />
总结:<br />
BrowserGym是一个开源项目，提供了一个基于Chrome浏览器的Gym环境，用于自动化各种网站和应用的任务。用户可以通过BrowserGym在Chromium浏览器中进行Web任务自动化，提高效率并简化操作。这个项目在GitHub上有源代码，帮助用户更好地进行Web任务自动化。 <div>
【BrowserGym: 用于 Web 任务自动化的开源项目，提供 Chrome 浏览器环境的 Gym 集成，用于自动化各种网站和应用的任务】’BrowserGym: a Gym Environment for Web Task Automation - BrowserGym, a gym environment for web task automation in the Chromium browser.' GitHub: github.com/ServiceNow/BrowserGym <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnu0kdzmk6j20yy0u0gp3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:18:53 GMT</pubDate>
</item>
<item>
<title>【flybody是一个用于 MuJoCo 物理模拟和强化学习应用的果蝇模型，基于 Google DeepMind 和 HHMI Janelia 研究中心的相结合的作品，旨在建立果蝇体系生物物理模拟...</title>
<link>https://weibo.com/1402400261/O5qqjDbVj</link>
<guid>https://weibo.com/1402400261/O5qqjDbVj</guid>
<content:encoded><![CDATA[
<div> 果蝇模型, MuJoCo 物理模拟, 强化学习, Google DeepMind, HHMI Janelia, 生物物理模拟平台, GitHub, TuragaLab, reinforcement learning, 任务<br />
<br />
总结:<br />
该项目将果蝇模型应用于 MuJoCo 物理模拟和强化学习任务，结合了 Google DeepMind 和 HHMI Janelia 的研究成果，旨在建立果蝇体系生物物理模拟平台。该项目的代码存储在 GitHub 上的 TuragaLab/flybody 项目中。通过这个模型，研究人员可以在仿真环境中进行果蝇的生物物理模拟和强化学习，为研究果蝇行为和神经系统提供了新的工具和资源。 <div>
【flybody是一个用于 MuJoCo 物理模拟和强化学习应用的果蝇模型，基于 Google DeepMind 和 HHMI Janelia 研究中心的相结合的作品，旨在建立果蝇体系生物物理模拟平台】'flybody: fruit fly body model for MuJoCo physics - MuJoCo fruit fly body model and reinforcement learning tasks' GitHub: github.com/TuragaLab/flybody <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu0elerekj219u0u00y4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:13:44 GMT</pubDate>
</item>
<item>
<title>【Magix 是一个用于训练大规模语言模型的轻量工具，具有灵活的数据和模型平行功能】'Magix - Supercharge huggingface transformers with model parallelism.' G...</title>
<link>https://weibo.com/1402400261/O5q959sOY</link>
<guid>https://weibo.com/1402400261/O5q959sOY</guid>
<content:encoded><![CDATA[
<div> Magix, huggingface, transformers, model parallelism, GitHub, 训练大规模语言模型, 轻量工具, 灵活的数据, 模型平行功能

<br /><br />总结:
Magix 是一个用于训练大规模语言模型的轻量工具，能够有效地利用模型并行性，并具有灵活的数据和模型平行功能。通过 Magix，用户可以在 GitHub 上找到支持 model parallelism 的 huggingface transformers。Magix 的出现为训练大规模语言模型提供了更加高效和灵活的选择。 <div>
【Magix 是一个用于训练大规模语言模型的轻量工具，具有灵活的数据和模型平行功能】'Magix - Supercharge huggingface transformers with model parallelism.' GitHub: github.com/luyug/magix <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntz6t5nagj21e00pqjvg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 06:31:17 GMT</pubDate>
</item>
<item>
<title>【ArXiv Paper Reader：旨在简化和流利的arXiv论文阅读，使用 LaTeX 代码转换为 HTML 页面，然后提取文本和公式，将其转换为视频，并创建与 PDF 文档匹配的图，...</title>
<link>https://weibo.com/1402400261/O5q2nDkz5</link>
<guid>https://weibo.com/1402400261/O5q2nDkz5</guid>
<content:encoded><![CDATA[
<div> 简化、流利、arXiv论文、LaTeX代码、HTML页面、提取文本、公式、视频、PDF文档、图像<br />
<br />
提供了一个名为ArXiv Paper Reader的工具，旨在简化和流利地阅读arXiv论文。该工具首先将LaTeX代码转换为HTML页面，然后提取文本、公式，并将其转换为视频。接着创建与PDF文档匹配的图像，并将文本分段并转换为音频。通过这种方式，用户可以更方便地理解和阅读arXiv论文，提高阅读效率。总的来说，这个工具为阅读arXiv论文提供了更加便捷的方式，使得用户可以更加愉快地进行学术阅读。<br /><br />总结: <div>
【ArXiv Paper Reader：旨在简化和流利的arXiv论文阅读，使用 LaTeX 代码转换为 HTML 页面，然后提取文本和公式，将其转换为视频，并创建与 PDF 文档匹配的图，以及文本分段并将其转换为音频】'ArXiv Paper Reader - Code behind Arxiv Papers' GitHub: github.com/imelnyk/ArxivPapers <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntypo9wd3j221b0u0n1i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 06:14:47 GMT</pubDate>
</item>
<item>
<title>【Skyvern 利用 LLM 和计算机视觉，自动化浏览器基础工作流。它提供一个简洁的 API 端点，允许完全自动化手动工作流，取代难以维护或易于故障的自动化解决方案】...</title>
<link>https://weibo.com/1402400261/O5pYY8wLP</link>
<guid>https://weibo.com/1402400261/O5pYY8wLP</guid>
<content:encoded><![CDATA[
<div> LLMs, 计算机视觉, 自动化, 浏览器, API, 手动工作流, 维护, 故障, 解决方案, GitHub<br /><br />总结: Skyvern利用LLM和计算机视觉技术，自动化浏览器基础工作流。其提供了一个简洁的API端点，允许完全自动化手动工作流，取代难以维护或易于故障的自动化解决方案。该项目的GitHub链接为github.com/Skyvern-AI/skyvern。 <div>
【Skyvern 利用 LLM 和计算机视觉，自动化浏览器基础工作流。它提供一个简洁的 API 端点，允许完全自动化手动工作流，取代难以维护或易于故障的自动化解决方案】'Skyvern - Automate browser-based workflows with LLMs and Computer Vision' GitHub: github.com/Skyvern-AI/skyvern <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntygovm8aj213t0u0wgj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 06:06:22 GMT</pubDate>
</item>
<item>
<title>【Pretzel是一个开源，在线浏览器式数据探索和可视化的工具，提供快速便捷的数据分析和可视化功能。它无需后台设置，可在浏览器中实时运行，无需任何服务器连接...</title>
<link>https://weibo.com/1402400261/O5pPCFNVf</link>
<guid>https://weibo.com/1402400261/O5pPCFNVf</guid>
<content:encoded><![CDATA[
<div> Pretzel, 开源, 在线浏览器, 数据探索, 可视化, 数据分析, 数据变换, 实时更新, DuckDB-Wasm, PRQL

<br /><br />总结:
Pretzel是一个开源的在线浏览器式数据探索和可视化工具，无需后台设置，可实时在浏览器中运行，提供快速便捷的数据分析和可视化功能。用户可以通过视觉化的数据变换区块轻松操控数据，并实时更新所有与变换区块和图表相关的内容，使用了DuckDB-Wasm和PRQL技术。 <div>
【Pretzel是一个开源，在线浏览器式数据探索和可视化的工具，提供快速便捷的数据分析和可视化功能。它无需后台设置，可在浏览器中实时运行，无需任何服务器连接。Pretzel通过视觉化的数据变换区块轻松操控数据，并实时更新所有与变换区块和图表相关的区块和图表】'Pretzel - Open-source, browser-local data exploration using DuckDB-Wasm and PRQL' GitHub: github.com/pretzelai/pretzelai <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntxt0cgs0j21bz0u0qa8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:43:21 GMT</pubDate>
</item>
<item>
<title>【扩散蒸馏相关论文资源列表】’Awesome-Diffusion-Distillation - A list of papers, docs, codes about diffusion distillation.This repo collects various d...</title>
<link>https://weibo.com/1402400261/O5pF46IZu</link>
<guid>https://weibo.com/1402400261/O5pF46IZu</guid>
<content:encoded><![CDATA[
<div> GitHub, papers, docs, codes, diffusion distillation, distillation methods<br />
<br />
总结：<br />
这个GitHub仓库收集了关于扩散模型的各种蒸馏方法，欢迎贡献未被收录的相关作品（论文、代码库）。扩散蒸馏是一个重要的研究领域，通过这个仓库可以找到多种不同的蒸馏方法和资源。希望这个仓库可以帮助研究人员更好地了解和应用扩散蒸馏技术。 <div>
【扩散蒸馏相关论文资源列表】’Awesome-Diffusion-Distillation - A list of papers, docs, codes about diffusion distillation.This repo collects various distillation methods for the Diffusion model. Welcome to PR the works (papers, repositories) missed by the repo.' GitHub: github.com/cantbebetter2/Awesome-Diffusion-Distillation <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntwv7uq2gj20u80u0wj8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:17:19 GMT</pubDate>
</item>
<item>
<title>【Recommender AI Agent: 使用大语言模型提供交互式推荐功能的agent】’Recommender AI Agent: Integrating Large Language Models for Interactive Recommendat...</title>
<link>https://weibo.com/1402400261/O5pAps9gS</link>
<guid>https://weibo.com/1402400261/O5pAps9gS</guid>
<content:encoded><![CDATA[
<div> 关键词: Recommender AI Agent, 大语言模型, 交互式推荐, GitHub, Microsoft

总结:<br /><br />
这篇文章介绍了一个名为'Recommender AI Agent'的项目，该项目利用大语言模型来提供交互式推荐功能。通过GitHub上的链接github.com/microsoft/RecAI 可以找到该项目的代码和资源。这个项目的目标是整合大语言模型，通过与用户的交互，为他们提供更加个性化的推荐服务。这种推荐代理的技术可以被应用到各种领域，帮助用户更快地找到他们感兴趣的内容。Microsoft是这个项目的背后支持者，展示了他们在人工智能和数据科学领域的实力和创新能力。通过这种新型推荐技术，用户可以享受到更加智能化和高效的推荐体验，提升用户体验和满意度。 <div>
【Recommender AI Agent: 使用大语言模型提供交互式推荐功能的agent】’Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations' GitHub: github.com/microsoft/RecAI <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntwpyjejsj21b70glgp4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:05:52 GMT</pubDate>
</item>
<item>
<title>'Campus2025 - 2025届互联网校招信息汇总' GitHub: github.com/NAOSI-DLUT/Campus2025 #开源# #校招# [图片]</title>
<link>https://weibo.com/1402400261/O5pyCbZZ7</link>
<guid>https://weibo.com/1402400261/O5pyCbZZ7</guid>
<content:encoded><![CDATA[
<div> GitHub, Campus2025, 2025届, 互联网, 校招, 信息, 汇总

<br /><br />总结:
GitHub上有一个名为Campus2025的项目，汇总了2025届互联网校园招聘的信息。这个项目提供了一个集中查找各种互联网公司校招信息的平台，帮助学生更方便地了解招聘信息和机会。对于即将步入社会的2025届学生来说，这个项目提供了一个很好的资源，可以帮助他们更好地规划自己的职业发展方向。通过这个项目，学生可以及时了解各个互联网公司的招聘信息，选择最适合自己的发展方向和机会。整合了各种互联网公司的招聘信息，让学生可以更方便地比较和选择自己感兴趣的企业和岗位。建议2025届的学生多关注这个项目，及时了解就业信息，为自己的职业发展做好准备。 <div>
'Campus2025 - 2025届互联网校招信息汇总' GitHub: github.com/NAOSI-DLUT/Campus2025 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%A0%A1%E6%8B%9B%23&amp;isnewpage=1"><span class="surl-text">#校招#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntwle8h77j20un0u00wu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:01:27 GMT</pubDate>
</item>
<item>
<title>【大模型数据增强相关文献资源列表】’Papers and resources on data augmentation using large models - The official GitHub page for the survey paper "A Su...</title>
<link>https://weibo.com/1402400261/O5pxswqTp</link>
<guid>https://weibo.com/1402400261/O5pxswqTp</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据增强, 大模型, 调查论文, GitHub, 资源, 机器学习, 深度学习

总结:<br /><br />
这篇文章是关于在大模型时代中使用数据增强的调查论文。GitHub上有一份关于数据增强的官方调查论文页面，提供了大模型数据增强相关的论文和资源列表。该调查论文涵盖了数据增强在机器学习和深度学习中的应用，以及大模型时代如何利用数据增强来提升模型性能。通过研究论文和资源，我们可以更好地了解数据增强在大模型领域的应用和重要性，为我们在实践中更好地利用数据增强提供了指导和参考。 <div>
【大模型数据增强相关文献资源列表】’Papers and resources on data augmentation using large models - The official GitHub page for the survey paper "A Survey on Data Augmentation in Large Model Era"' GitHub: github.com/MLGroup-JLU/LLM-data-aug-survey <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntwi7n59vj210s0u0jxn.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntwidk0cgj21480u0jwj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:58:36 GMT</pubDate>
</item>
<item>
<title>【DRL-Based Trajectory Tracking (DRLTT) 是一个用于自动驾驶轨迹跟踪的开源项目，它结合深度强化学习(DRL)技术，并具有高效性和准确性的功能，可用于轨迹跟踪...</title>
<link>https://weibo.com/1402400261/O5pshzWGg</link>
<guid>https://weibo.com/1402400261/O5pshzWGg</guid>
<content:encoded><![CDATA[
<div> GitHub, DRL-Based Trajectory Tracking, 深度强化学习, 轨迹跟踪, 自动驾驶, 开源项目, 高效性, 准确性, 任务

<br /><br />总结:
DRL-Based Trajectory Tracking (DRLTT) 是一个开源项目，采用深度强化学习技术，旨在实现自动驾驶轨迹跟踪任务。该项目结合了高效性和准确性的特点，提供了一个有效的解决方案。通过 GitHub 平台展示和分享，用户可以了解和参与该项目，促进自动驾驶技术的发展。 <div>
【DRL-Based Trajectory Tracking (DRLTT) 是一个用于自动驾驶轨迹跟踪的开源项目，它结合深度强化学习(DRL)技术，并具有高效性和准确性的功能，可用于轨迹跟踪任务】'DRL-Based Trajectory Tracking (DRLTT) - DRL-based trajectory tracking.' GitHub: github.com/MARMOTatZJU/drl-based-trajectory-tracking <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntw56a5v2j215e0u079l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:45:51 GMT</pubDate>
</item>
<item>
<title>【Cpptrace：一个简洁、可移植和自建的 C++ stacktracker 库，支持 C++11 及更高版本的 Linux、macOS 和 Windows 运行环境，包括 MinGW 和 Cygwingwin。其目的是...</title>
<link>https://weibo.com/1402400261/O5prI8BI3</link>
<guid>https://weibo.com/1402400261/O5prI8BI3</guid>
<content:encoded><![CDATA[
<div> 简洁 可移植 自建 C++ stacktracker 库 C++11 Linux macOS Windows MinGW Cygwinwin<br />
<br />总结:<br />Cpptrace是一个简洁、可移植和自建的 C++ stacktracker 库，支持C++11及更高版本，在Linux、macOS和Windows运行环境下可使用，包括MinGW和Cygwingwin。它的目的是简化堆栈追踪，使其变得更容易。Cpptrace库的GitHub地址为github.com/jeremy-rifkin/cpptrace。 <div>
【Cpptrace：一个简洁、可移植和自建的 C++ stacktracker 库，支持 C++11 及更高版本的 Linux、macOS 和 Windows 运行环境，包括 MinGW 和 Cygwingwin。其目的是简化堆栈追踪，使其变得更容易】'Cpptrace - Simple, portable, and self-contained stacktrace library for C++11 and newer' GitHub: github.com/jeremy-rifkin/cpptrace <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23C%2B%2B%23"><span class="surl-text">#C++#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntw3ow5brj20xc0u0tce.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:44:26 GMT</pubDate>
</item>
<item>
<title>'Transformers 库快速入门教程' GitHub: github.com/jsksxs360/How-to-use-Transformers #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5pcFy2Gb</link>
<guid>https://weibo.com/1402400261/O5pcFy2Gb</guid>
<content:encoded><![CDATA[
<div> Transformers, 库, 快速, 入门, 教程, GitHub, 使用, 教程, 详细

<br /><br />总结: 该GitHub仓库提供了一个关于如何快速入门使用Transformers库的教程，详细介绍了如何利用这个功能强大的库来进行自然语言处理和其他机器学习任务。通过阅读这篇教程，你能够了解Transformers库的基本功能和使用方法，帮助你更快地上手并应用于实际项目中。如果你对自然语言处理或机器学习感兴趣，不妨花一些时间学习这篇教程，会受益匪浅。 <div>
'Transformers 库快速入门教程' GitHub: github.com/jsksxs360/How-to-use-Transformers <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntv14tvcoj21ii0u042p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:07:23 GMT</pubDate>
</item>
<item>
<title>【Flux 是一个 C++20 库，提供一系列用于序列处理的算法和适配器，类似于 C++20 ranges、Python itertools 和 Rust iterators】'Flux - A C++20 library for seq...</title>
<link>https://weibo.com/1402400261/O5p6WDJDd</link>
<guid>https://weibo.com/1402400261/O5p6WDJDd</guid>
<content:encoded><![CDATA[
<div> C++20, 库, Flux, 序列处理, 算法, 适配器, ranges, Python itertools, Rust iterators  
<br /><br />总结:  
Flux 是一个 C++20 库，提供一系列用于序列处理的算法和适配器，类似于 C++20 ranges、Python itertools 和 Rust iterators。这个库可以让开发者更加方便地处理序列数据，提供了丰富的功能和工具。通过 Flux，开发者可以更高效地进行序列处理，实现更加复杂和灵活的操作。它为 C++ 程序员提供了一种简洁而强大的方式来处理序列数据，帮助他们提高代码的可读性和性能。Flux 库的开发者在 GitHub 上持续维护和更新，为广大开发者提供了一个优秀的序列处理工具。 <div>
【Flux 是一个 C++20 库，提供一系列用于序列处理的算法和适配器，类似于 C++20 ranges、Python itertools 和 Rust iterators】'Flux - A C++20 library for sequence-orientated programming' GitHub: github.com/tcbrindle/flux <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntumcqwwaj21ji0puq7x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 03:53:17 GMT</pubDate>
</item>
<item>
<title>【StyleTTS 2: 可通过pip安装的Python包，用于实现人类水平的文本转语音和语音克隆】'StyleTTS 2: The Python Package - Pip installable package for StyleTTS ...</title>
<link>https://weibo.com/1402400261/O5oQCmWh7</link>
<guid>https://weibo.com/1402400261/O5oQCmWh7</guid>
<content:encoded><![CDATA[
<div> StyleTTS 2, Python包, pip安装, 文本转语音, 语音克隆, GitHub, sidharthrajaram, 人类水平, 实现, 

总结:<br /><br />
这篇文章介绍了StyleTTS 2，一个Python包，可以通过pip安装，用于实现人类水平的文本转语音和语音克隆。该包提供了一种简单而有效的方法来实现高质量的语音合成和克隆，让用户能够快速轻松地创建自然流畅的语音内容。GitHub上有相关资源和文档，使用户可以更方便地了解和使用这个工具。如果你想要实现人类水平的文本转语音和语音克隆，不妨尝试使用StyleTTS 2这一方便易用的工具。 <div>
【StyleTTS 2: 可通过pip安装的Python包，用于实现人类水平的文本转语音和语音克隆】'StyleTTS 2: The Python Package - Pip installable package for StyleTTS 2 human-level text-to-speech and voice cloning' GitHub: github.com/sidharthrajaram/StyleTTS2 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnttgd54x5j21ki0gu41j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 03:13:03 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模...</title>
<link>https://weibo.com/1402400261/O5oJlsK39</link>
<guid>https://weibo.com/1402400261/O5oJlsK39</guid>
<content:encoded><![CDATA[
<div> 度小满、大语言模型、杨青、全彩印刷、实践性、知识体系、训练经验、干货满满、系统性、神秘面纱

总结:<br /><br />本书《大语言模型：原理与工程实践(全彩)》由度小满的杨青负责编写，深入解读大语言模型的内在机理和应用实践。书籍的特色在于系统性的知识体系和对实践性的重视，配有代码并采用全彩印刷，内容充实且实用。作者作为大语言模型实践者，分享了他在十亿、百亿、千亿参数规模大语言模型训练方面的丰富经验，这些经验都被真诚而详尽地呈现在书中。通过本书，读者能够全面了解大语言模型的运作原理和实际应用，深入学习大模型的构建和训练方法，是一本值得一读的权威指南。 <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 02:55:08 GMT</pubDate>
</item>
<item>
<title>【对开源AI工具的观察总结】数据来源:- 通过GitHub搜索GPT、LLM和generative ai等关键词,结果分别为118K、590个、531个和38个。- 限定stars大于500的仓库,最终获...</title>
<link>https://weibo.com/1402400261/O5o4KnaXm</link>
<guid>https://weibo.com/1402400261/O5o4KnaXm</guid>
<content:encoded><![CDATA[
<div> GPT、LLM、generative ai、GitHub、技术栈、趋势、开发者、中国开源、短命项目、点子 <br />
<br />
总结：<br />
通过GitHub搜索了GPT、LLM和generative ai等关键词，共筛选出845个stars大于500的开源AI工具。AI技术栈分为基础设施层、模型开发层、应用开发层和应用层。2023年预计应用和应用开发层将迎来快速增长，特别是提示工程、人机界面和推理优化等领域。开发者中有20个账号贡献了23%的项目，80%为组织账号，个人账号如lucidrains也积极贡献了许多项目。中国开源生态活跃在GitHub上，有不少针对中文用户的工具和模型。许多项目虽然发展迅速但很快衰退，但对社区仍有一定价值。作者对批量推理优化、更快的解码器、模型融合和受约束采样等点子颇感兴趣，认为专注解决一个问题的项目也非常有价值。 <div>
【对开源AI工具的观察总结】<br />数据来源:<br />- 通过GitHub搜索GPT、LLM和generative ai等关键词,结果分别为118K、590个、531个和38个。<br />- 限定stars大于500的仓库,最终获得了845个软件仓库。<br />- 51个是教程和汇总列表,794个是软件项目。<br /><br />AI技术栈:<br />- 基础设施层:模型部署、计算管理、向量搜索数据库等。<br />- 模型开发层:框架、推理优化、数据集、评估等。<br />- 应用开发层:提示工程、人机界面、Agent、AIE框架等。 <br />- 应用层:编码、聊天机器人、信息聚合等。<br /><br />变化趋势:<br />- 2023年应用和应用开发层增长迅速。基础设施层变化不大。<br />- 提示工程、人机界面、推理优化最热门。<br /><br />开发者分布:<br />- 20个账号贡献了23%的项目,80%是组织账号。<br />- 个人账号如lucidrains等也贡献了很多项目,尤其是应用层。<br />- 超过2万开发者贡献了近100万次commit。<br /><br />中国开源生态:<br />- 中文社区也活跃在GitHub上,有针对中文及中英混合的模型。<br />- 也有面向中文用户的工具和模型应用。<br /><br />短命项目:<br />- 许多项目快速发展后也快速衰退,但对社区仍有价值。<br /><br />个人最喜欢的点子:<br />- 批量推理优化、更快的解码器、模型融合、受约束采样等。<br />- 专注解决一个问题的项目也很有价值。<br /><br />《What I learned from looking at 900 most popular open source AI tools》 <a href="https://huyenchip.com//2024/03/14/ai-oss.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntq1dgmbnj20xa0u0gqa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntq1h4v66j21jj0kagq0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1iybm0j21hb0u0gp7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntq1jt6qbj20y40t83zz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntq1lnbjkj21jj0kj79q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1p6tj6j21jj0tywh4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntq1rc7nej21760t6mzr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1s9iy7j21530u0tbb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1u96xqj21ex0u0gnq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 01:15:07 GMT</pubDate>
</item>
<item>
<title>【Deepfakes：从数字现实到虚假现实】1. 深度伪造(Deepfakes)利用先进的人工智能技术,生成逼真的虚假图像、视频和音频。 - 利用游戏引擎(如Unreal Engine 5)模拟...</title>
<link>https://weibo.com/1402400261/O5nUy4lA5</link>
<guid>https://weibo.com/1402400261/O5nUy4lA5</guid>
<content:encoded><![CDATA[
<div> 深度伪造 技术 人工智能 欺骗性质 安全隐患 伦理问题 检测防御 深思 认知 

总结:<br /><br />这篇文章介绍了深度伪造技术利用人工智能生成逼真虚假图像、视频和音频的现状，以及其潜在的伦理和安全隐患，引起了人们的深刻思考。技术能够精确模仿人物特征，但也可能被滥用用于制造虚假信息和诽谤。一些公司和研究人员正在研发新技术用于检测和防御深度伪造，但是人们对于是否应该限制或禁止这种技术的发展看法不一。文章唤起人们对于技术快速发展下如何保持理性和警惕的思考。 <div>
【Deepfakes：从数字现实到虚假现实】<br />1. 深度伪造(Deepfakes)利用先进的人工智能技术,生成逼真的虚假图像、视频和音频。<br />   - 利用游戏引擎(如Unreal Engine 5)模拟细致的光线和物理效果,创造出逼真的数字场景。<br />   - 使用生成对抗网络(GAN)等生成AI模型(如DeepMind的Sora),根据文本提示生成逼真的视频。<br />2. 深度伪造技术能够精确模仿人物的脸部特征、表情、声音和动作细节。<br />3. 虽然深度伪造在游戏、娱乐等领域具有创意应用潜力,但其欺骗性质也引发了严重的伦理和安全隐患。<br />   - 可能被滥用于制造虚假信息、诽谤等违法行为。<br />4. 一些公司和研究人员正在开发新技术,以检测和防御深度伪造。<br />5. 深度伪造技术的发展将继续模糊数字与现实世界的界限,引发人们对"真实"的重新思考。<br /><br />点评:<br />1. 文章揭示了深度伪造技术的发展现状和潜在风险,引发读者对技术伦理的深思。<br />2. 深度伪造不仅挑战了人们对"真实"的认知,也可能对社会造成严重的不实信息危害。<br />3. 一些读者质疑,是否应该限制或禁止这种技术的发展,以防被滥用。<br />4. 另一种观点认为,深度伪造只是一种工具,关键在于如何正确使用和管控。<br />5. 文章启发人们思考,在技术快速发展的今天,我们如何保持理性和警惕。<br /><br />《Deepfakes: From Digital Reality to Fake Reality | Datafloq》 <a href="https://datafloq.com/read/deepfakes-digital-reality-fake-reality/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntpbqv5atj213j0u0n3d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:49:59 GMT</pubDate>
</item>
<item>
<title>【大型语言模型(LLM)文本生成的理论速度极限】- LLM文本生成是一个按词(token)顺序进行的过程，当前词生成时依赖之前的所有词的状态，不存在并行的可能。 - LLM...</title>
<link>https://weibo.com/1402400261/O5nRLvdhX</link>
<guid>https://weibo.com/1402400261/O5nRLvdhX</guid>
<content:encoded><![CDATA[
<div> LLM 文本生成、速度极限、矩阵向量乘法、注意力计算、内存带宽限制、Mistral 7B模型、RTX 4090、理论速度极限分析、性能优化、推理性能

总结：<br /><br />本文从理论角度分析了LLM推理速度的极限，提出了计算最大FLOPS利用率和最小延迟时间的方法，为推理性能的衡量和优化提供了新思路。同时指出了影响实际推理速度的多个因素，启示我们在性能优化时需要全面考虑，不仅局限于计算本身。虽然理论极限难以达到，但仍是一个有意义的目标。文章专业性强，但对理解LLM推理性能优化具有重要指导意义。 <div>
【大型语言模型(LLM)文本生成的理论速度极限】<br />- LLM文本生成是一个按词(token)顺序进行的过程，当前词生成时依赖之前的所有词的状态，不存在并行的可能。   <br />- LLM主要包含两个运算：矩阵向量乘法和注意力计算，这两种运算都只需要对每个元素进行很少的浮点运算。   <br />- 现代CPU和GPU的算术运算速度远高于内存读取速度。因此LLM生成这类只需要对每个元素做少量运算的任务，其速度主要受内存带宽限制。   <br />- 以Mistral 7B模型为例，矩阵中的参数数量约为71亿，使用FP16时需要读取14.2GB数据。在RTX 4090(1008GB/s带宽)上理论最小生成时间是14.1ms/词。   <br />- 对比不同架构的实际速度与理论速度极限，可以评估软硬件实现的效率，并给进一步优化提供指导。   <br />- 矩阵向量乘法易受内存带宽限制，而注意力计算对内存大小也有严重影响。使用分组查询注意力(GQA)可以大幅减少注意力计算的内存需求。   <br />- 对于单用户单请求场景，理论速度极限是一个常数，可用于跨模型和设备评估预期性能，但多用户并发请求时，情况会改变。   <br />- 理论速度极限分析对于理解和优化LLM生成性能至关重要。<br /><br />点评：  <br />- 文章从理论角度分析了LLM推理速度的极限，这一视角有别于一般的性能优化讨论，具有独到之处。  <br />- 作者提出了计算理论最大FLOPS利用率和最小延迟时间的方法，为衡量和优化推理性能提供了新的思路。  <br />- 文章指出了影响实际推理速度的诸多因素，这启示我们在性能优化时需要全面考虑，而不仅仅局限于计算本身。  <br />- 尽管理论极限难以达到，但作者认为它仍然是一个有意义的目标，这一观点值得深思。  <br />- 文章虽然专业性强，但对于理解LLM推理性能优化具有重要指导意义。<br /><br />《zeux.io - LLM inference speed of light》 <a href="https://zeux.io/2024/03/15/llm-inference-sol/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntp4m8oolj20u00ubtek.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:43:08 GMT</pubDate>
</item>
<item>
<title>【整数标记化(tokenization)：语言模型数字处理的”bug"?】- GPT模型的整数标记化(tokenize)方式存在很大问题，这让模型学习数学知识和表示数学事实变得非常困难...</title>
<link>https://weibo.com/1402400261/O5nMx2bXx</link>
<guid>https://weibo.com/1402400261/O5nMx2bXx</guid>
<content:encoded><![CDATA[
<div> 整数标记化, 语言模型, GPT模型, 十进制系统, 数学知识, 数学运算, 数字处理, 算法, 问题

<br /><br />总结: 
作者对GPT模型的整数标记化方式存在的问题提出了质疑，表示现有方法可能影响模型对数学知识的学习和运用。理想的数字系统应该遵循十进制系统，对0-9的整数使用唯一的token，而更大的整数则用这些token的组合表示。然而，GPT在处理整数时为大量整数分配了独立的token，导致模型无法应用通用数学运算算法，只能依赖记忆特殊情况出现的结果。这种不一致的整数分块标记化方式影响了模型的推理能力，对其理解和应用数学运算与算法的提高具有重要意义。整数tokenize的改进是关键所在，有望让GPT模型在数学能力上取得进步。 <div>
【整数标记化(tokenization)：语言模型数字处理的”bug"?】<br />- GPT模型的整数标记化(tokenize)方式存在很大问题，这让模型学习数学知识和表示数学事实变得非常困难。   <br />- 理想的数字系统应该对0-9的整数使用唯一的token，而更大的整数则用这些token的组合表示，以体现十进制系统。   <br />- 但GPT的tokenize方式并未遵循十进制系统，而是为大量整数独立分配了唯一的token。这导致模型无法应用通用的数学运算算法，只能依赖大量模式匹配记忆。   <br />- 不仅小整数受影响，在较大的整数中也存在大量独立token的情况，这同样导致了无法应用通用算法的问题。   <br />- 即使在非独立token的整数中，分割整数的方式也不一致，导致模型同样无法应用统一的运算逻辑。   <br />- 这让模型进行数字运算时必须记忆大量特殊情况下的结果，而非应用通用算法，增加了学习和推理的难度。   <br />- 整数tokenize的这些问题说明，GPT模型距离真正理解和应用数学运算与算法还有很长的路要走。tokenize方式的改进是模型在数学能力上提高的关键。<br /><br />点评:<br />1. 作者对现有的整数标记化方法提出质疑,认为其存在不合理之处。<br />2. 揭示了语言模型在处理数字时的特殊机制可能影响模型对数字的理解和运算能力。<br />3. 举例说明了整数分块标记化的不一致性,这一发现对优化语言模型的数字处理方式具有启发意义。<br /><br />《Integer tokenization is insane》 <a href="https://www.beren.io/2023-02-04-Integer-tokenization-is-insane/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntor0oe8lj20hs0dcwet.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntor291rsj20hs0dcgn3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:30:14 GMT</pubDate>
</item>
<item>
<title>【开源路上，别让心理健康成了绊脚石】1. 开源维护者面临的心理健康挑战: - 工作与生活平衡 - 来自社区的期望和压力 - 个人对完美的追求2. 作者的应对方式: - 放...</title>
<link>https://weibo.com/1402400261/O5nGUCOBu</link>
<guid>https://weibo.com/1402400261/O5nGUCOBu</guid>
<content:encoded><![CDATA[
<div> 心理健康, 开源维护者, 压力, 应对方式, 社区, 建议, 展望, 资源, 可持续发展, 平衡

总结:<br /><br />本文探讨了开源维护者在面临心理健康挑战时的困境，包括工作与生活平衡、社区压力、追求完美等问题。作者提出了应对方式，如放慢节奏、写博客宣泄情绪、与社区沟通，以及对开源贡献者的建议，如设定合理预期、寻求帮助、关注自我等。同时，指出开源社区应营造友善氛围、关注心理健康、提供支持资源。关键在于不断学习调整，找到适合自己的方式，平衡投入和自我保护。 <div>
【开源路上，别让心理健康成了绊脚石】<br />1. 开源维护者面临的心理健康挑战:<br />   - 工作与生活平衡<br />   - 来自社区的期望和压力<br />   - 个人对完美的追求<br />2. 作者的应对方式:<br />   - 放慢节奏,享受过程而非执着于立竿见影的结果<br />   - 写博客梳理思路,宣泄负面情绪<br />   - 与社区保持开诚布公的沟通<br />3. 作者对开源贡献者的建议:<br />   - 设定合理预期,接纳"够好"的结果<br />   - 必要时寻求帮助,与他人分享感受<br />   - 关注自我,投入个人生活与兴趣爱好<br />4. 作者对开源社区的展望:<br />   - 营造友善、包容的氛围<br />   - 关注贡献者的心理健康<br />   - 提供更多帮助和支持资源<br />5. 开源之路没有完美的解决方案,关键是不断学习、调整,找到适合自己的方式。<br /><br />点评:<br />1. 开源工作获得回报的周期较长,需要贡献者保持耐心和动力。<br />2. 部分评论质疑开源是否必然导致心理压力,认为关键在于自我管理。<br />3. 有建议指出,参与者应主动控制参与度,必要时"说不"以保障个人生活。<br />4. 开源社区应提供更多支持资源,如心理健康指南、互助小组等。<br />5. 开源项目的可持续发展,需要在贡献者投入和自我保护间找到平衡。<br /><br />《Mental Health in Open Source》 <a href="https://antfu.me/posts/mental-health-oss"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntocrscepj20x00u0n1p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:16:24 GMT</pubDate>
</item>
<item>
<title>今日推介(第1347期)：语言模型算法带来的改进速率评估、用合成数据进行模型高效评估、检索增强思维在长程生成中实现上下文感知推理、面向向量嵌入和结构化数据的...</title>
<link>https://weibo.com/1402400261/O5nfJ9Pv8</link>
<guid>https://weibo.com/1402400261/O5nfJ9Pv8</guid>
<content:encoded><![CDATA[
<div> 语言模型算法、改进速率评估、合成数据、模型高效评估、检索增强思维、长程生成、上下文感知推理、面向向量嵌入、结构化数据、高性能、谓词不可知搜索方法、持续学习、灾难性遗忘

总结:<br /><br />本文分析了语言模型算法带来的改进速率评估以及使用合成数据进行模型高效评估的方法。进一步讨论了检索增强思维在长程生成中实现上下文感知推理的重要性。同时介绍了面向向量嵌入和结构化数据的高性能和谓词不可知搜索方法的应用。最后，探讨了持续学习与灾难性遗忘的问题，为相关领域的研究提供了启示。 <div>
今日推介(第1347期)：语言模型算法带来的改进速率评估、用合成数据进行模型高效评估、检索增强思维在长程生成中实现上下文感知推理、面向向量嵌入和结构化数据的高性能和谓词不可知搜索方法、持续学习与灾难性遗忘  公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687438947"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.17)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntmepeyz2j20k0094jsj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntmet15vnj20k00g50us.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntmevbeezj20k00eptaq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntmezj2v6j20k00bfjs2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntmf23pboj20k006v0ty.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 23:09:24 GMT</pubDate>
</item>
<item>
<title>[LG] Poly-View Contrastive Learning 网页链接 展示了一种名为多视对比学习(Poly-View Contrastive Learning)的新框架，挑战了传统对比学习中常见的观点，即需...</title>
<link>https://weibo.com/1402400261/O5nbmvDDn</link>
<guid>https://weibo.com/1402400261/O5nbmvDDn</guid>
<content:encoded><![CDATA[
<div> 对比学习、多视对比学习、视角数量、样本总量、计算资源、训练周期、批次数量、表现优势、图像表示学习、高效性
<br /><br />总结:
研究展示了一种新框架——多视对比学习，挑战了传统对比学习观点，证明增加单个样本的视角数量而非样本总量可以获得更好的表现。使用多视角对比模型，在限定的训练周期和批次设置下，可以超越传统对比学习模型的效果。这一研究改变了对大批量和长周期训练需求的传统看法，为图像表示学习提供了新方向，突显了高效性。 <div>
[LG] Poly-View Contrastive Learning  <br /><a href="https://arxiv.org/abs/2403.05490"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />展示了一种名为多视对比学习(Poly-View Contrastive Learning)的新框架，挑战了传统对比学习中常见的观点，即需要大量样本和多个训练周期来提高性能。研究表明，通过增加单个样本的视角数量而非样本总量，可以在有限的计算资源下获得更优的表现。具体来说，使用多视角对比模型，在128个训练周期、每批次256个样本的设置下，就能超越标准对比学习模型SimCLR在1024个周期、每批次4096个样本的训练效果。该研究改变了对大批量和长周期训练需求的传统看法，为高效的图像表示学习指明了新方向。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntm3w9ye2j213u1m2qoj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntm3wx3pxj21ui10awtc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:58:40 GMT</pubDate>
</item>
<item>
<title>[CV] Score-Guided Diffusion for 3D Human Recovery 网页链接 介绍了一种名为Score-Guided Human Mesh Recovery(ScoreHMR)的新方法，用于解决3D人体姿态和形状...</title>
<link>https://weibo.com/1402400261/O5n8ZBO7k</link>
<guid>https://weibo.com/1402400261/O5n8ZBO7k</guid>
<content:encoded><![CDATA[
<div> Score-Guided Human Mesh Recovery, 3D人体姿态和形状重建, 扩散模型, 得分引导, 图像观测, 单帧模型拟合, 多视角重建, 视频序列, 基准测试

<br /><br />总结:
本文介绍了一种新方法Score-Guided Human Mesh Recovery (ScoreHMR) 用于解决3D人体姿态和形状重建的逆问题。与传统方法不同，该方法利用扩散模型的潜空间并通过得分引导实现与图像观测的对齐。该方法在多项基准测试中展现出较高的准确性，有效提高了单帧模型拟合、多视角重建和视频序列中人体动作的精度，超越了所有优化基准模型。ScoreHMR不需要特定任务的扩散模型再训练，具有较高的实用性。 <div>
[CV] Score-Guided Diffusion for 3D Human Recovery  <br /><a href="https://arxiv.org/abs/2403.09623"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为Score-Guided Human Mesh Recovery(ScoreHMR)的新方法，用于解决3D人体姿态和形状重建的逆问题。与传统优化或回归方法不同，ScoreHMR利用扩散模型的潜空间并通过得分引导来实现与图像观测的对齐。这种方法不需要对无依赖任务的扩散模型进行特定任务的再训练，有效地提高了单帧模型拟合、多视角重建和视频序列中人体动作的准确性，并在多项基准测试中超越了所有优化基准模型。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntlxtzz9ij21a81ich9h.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntlxunm8nj21qa0y8dt3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:52:50 GMT</pubDate>
</item>
<item>
<title>[LG] Defending Against Unforeseen Failure Modes with Latent Adversarial Training 网页链接 深入探讨了AI系统部署后出现的意外行为，并提出一种新的防御手段...</title>
<link>https://weibo.com/1402400261/O5n6f85Bk</link>
<guid>https://weibo.com/1402400261/O5n6f85Bk</guid>
<content:encoded><![CDATA[
<div> 潜对抗训练, 意外行为, 防御手段, 潜表示层, 压缩, 抽象, 结构化, 图像分类, 文本分类, 文本生成

<br /><br />

总结: 本文深入探讨了AI系统部署后可能出现的意外行为，并提出了一种新的防御手段——潜对抗训练（LAT）。LAT通过在模型的潜表示层面干预，利用更加压缩、抽象和结构化的概念表示来防御未知的失败模式。实验证明，LAT在图像分类、文本分类和文本生成任务中，相比传统的对抗训练（AT），能提高模型对未知对抗样本类别的鲁棒性，同时移除特洛伊木马。这一发现显示LAT的潜力，为防御开发者无法明确识别的失败模式提供了可能的解决方案。 <div>
[LG] Defending Against Unforeseen Failure Modes with Latent Adversarial Training  <br /><a href="https://arxiv.org/abs/2403.05030"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />深入探讨了AI系统部署后出现的意外行为，并提出一种新的防御手段：潜对抗训练(LAT)。LAT区别于传统的对抗训练(AT)，它不通过生成触发模型失败的输入，而是在模型的潜表示层面进行干预，利用网络对信息进行处理时构建的更加压缩、抽象和结构化的概念表示。通过在图像分类、文本分类和文本生成任务中的实验表明，与AT相比，LAT通常能在不损害干净数据性能的同时，提高模型对未见过的对抗样本类别的鲁棒性，并能移除特洛伊木马。这一发现表明LAT可以成为一种有前景的工具，用于防御开发者无法显式识别的失败模式。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntlqrmnlzj212u1jctr6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntlqql6xrj21hi1cudyi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:46:03 GMT</pubDate>
</item>
<item>
<title>[LG] ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training 网页链接 提出PROTLLM，一个能同时处理蛋白质中心和蛋白质-语言任务的...</title>
<link>https://weibo.com/1402400261/O5n3Awz5o</link>
<guid>https://weibo.com/1402400261/O5n3Awz5o</guid>
<content:encoded><![CDATA[
<div> PROTLLM、蛋白质挂载机制、蛋白质词表、InterPT、跨模态大型语言模型、零样本学习、上下文学习、蛋白质中心任务、蛋白质-语言任务、预训练数据集

<br /><br />总结:
PROTLLM是一个跨模态大型语言模型，具有动态蛋白质挂载机制，可以处理复杂输入中的任意数量蛋白质。通过专门的蛋白质词表，模型能够同时预测自然语言和蛋白质。研究构建了大规模的蛋白质-文本数据集InterPT用于预训练，融合了结构化和非结构化数据源。PROTLLM在蛋白质中心任务上表现优于基线模型，并展现出零样本学习和上下文学习的能力。这项研究为蛋白质-语言任务提供了新的解决方案，并为蛋白质研究领域带来了创新的进展。 <div>
[LG] ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training  <br /><a href="https://arxiv.org/abs/2403.07920"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出PROTLLM，一个能同时处理蛋白质中心和蛋白质-语言任务的跨模态大型语言模型(LLM)。其特色是动态蛋白质挂载机制，使模型能够处理含有任意数量蛋白质的复杂输入。通过开发专门的蛋白质词表，模型能够从大量候选者中预测自然语言和蛋白质。构建了一个大规模交错的蛋白质-文本数据集InterPT用于预训练，融合了结构化和非结构化数据源。PROTLLM在蛋白质中心任务上优于专门的基线，并且在蛋白质-语言任务上展示了零样本和上下文学习能力。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntljyrwk6j213a1je7nq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntljzjjocj21fu11kakh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:39:31 GMT</pubDate>
</item>
<item>
<title>[CL] CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences 网页链接 介绍了CodeUltraFeedback和CODAL-Ben...</title>
<link>https://weibo.com/1402400261/O5n0v593n</link>
<guid>https://weibo.com/1402400261/O5n0v593n</guid>
<content:encoded><![CDATA[
<div> CodeUltraFeedback, CODAL-Bench, 数据集, 大型语言模型, 编程偏好, AI反馈, LLM-as-a-Judge方法, 偏好优化, 微调, RLAIF, 功能正确性, CodeLlama-7B-Instruct模型, SFT, DPO

总结:<br /><br />本文介绍了CodeUltraFeedback和CODAL-Bench，提供了一套用于微调和评估大型语言模型(LLM)以符合编程偏好的数据集和基准。CodeUltraFeedback包含复杂指令，通过AI反馈调整LLM偏好，反映了五种编程偏好。利用LLM-as-a-Judge方法对LLM的响应进行了标注，包括数值评分和文本反馈。研究表明经过微调的CodeLlama-7B-Instruct模型在功能正确性和偏好对齐方面表现优于基础模型和更大的34B LLM。这证明了CodeUltraFeedback在偏好调整中的实用性，以及SFT和DPO在提升LLM与人类编程偏好对齐方面的潜力。 <div>
[CL] CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences  <br /><a href="https://arxiv.org/abs/2403.09032"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了CodeUltraFeedback和CODAL-Bench，一套用于微调和评估大型语言模型(LLM)以符合编程偏好的数据集和基准。CodeUltraFeedback包含10000条复杂指令，用于通过AI反馈调整LLM偏好，反映了五种编程偏好。利用来自GPT-3.5的LLM-as-a-Judge方法，对LLM的响应进行了标注，包括数值评分和文本反馈。通过直接偏好优化(DPO)和AI反馈强化学习(RLAIF)的研究表明，经过微调的CodeLlama-7B-Instruct模型在功能正确性和偏好对齐方面均优于未微调的基础模型和更大的34B LLM。这证明了CodeUltraFeedback在偏好调整中的实用性，以及SFT和DPO在提升LLM与人类编程偏好对齐方面的潜力。<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntlc1minqj218a1ic4nd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntlc27482j21b01c2du8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntlc2bylej20y019cjyn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:31:54 GMT</pubDate>
</item>
<item>
<title>详尽分析了人工神经网络在持续学习过程中面临的灾难性遗忘挑战，探讨了六种主要的计算方法来提高持续学习能力，强调了在深度学习与认知科学之间建立联系的重要性...</title>
<link>https://weibo.com/1402400261/O5mVI6XCv</link>
<guid>https://weibo.com/1402400261/O5mVI6XCv</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工神经网络，持续学习，灾难性遗忘，深度学习，认知科学，计算方法，互相启发，发展，联系，挑战

总结:<br /><br />
本文详细分析了人工神经网络在持续学习过程中所面临的灾难性遗忘挑战，并通过探讨六种主要的计算方法来提高持续学习能力。作者强调了在深度学习与认知科学之间建立联系的重要性，旨在促进两个领域之间的互相启发和发展。文章指出，在人工智能领域持续学习是一个关键的问题，因为传统神经网络容易忘记之前学到的知识，导致新知识的学习会覆盖旧知识。为解决这一问题，提出了六种方法，包括反向传播、重放缓冲区、正交正则化、动态权重、增量学习和任务分解等。这些方法在一定程度上提高了人工神经网络的持续学习能力。同时，文章呼吁深度学习与认知科学之间建立更多的联系，通过相互启发和发展推动这两个领域的进步。这种综合性的研究方法可以为人工智能领域的持续学习问题带来新的突破。通过深入探讨人工神经网络如何应对灾难性遗忘挑战，可以不断提升其在持续学习任务中的表现，推动人工智能技术的发展。 <div>
详尽分析了人工神经网络在持续学习过程中面临的灾难性遗忘挑战，探讨了六种主要的计算方法来提高持续学习能力，强调了在深度学习与认知科学之间建立联系的重要性，旨在推动两领域的互相启发和发展。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Continual Learning and Catastrophic Forgetting》G M. v d Ven, N Soures, D Kudithipudi [KU Leuve &amp; University of Texas at San Antonio] (2024) <a href="https://arxiv.org/abs/2403.05175"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklqwed9j21eo0dwgs1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntklrqmumj21na0motf2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsa9x2j21n40kaaj9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsujzaj21n20nk7cy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntkznz89nj21120o7439.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:20:06 GMT</pubDate>
</item>
<item>
<title>[LG]《Continual Learning and Catastrophic Forgetting》G M. v d Ven, N Soures, D Kudithipudi [KU Leuve &amp; University of Texas at San Antonio] (2024) 网...</title>
<link>https://weibo.com/1402400261/O5mVF0Qpu</link>
<guid>https://weibo.com/1402400261/O5mVF0Qpu</guid>
<content:encoded><![CDATA[
<div> 学习，持续学习，灾难性遗忘，机器学习，人工智能，神经网络，模型，挑战，解决方案，实验<br />
<br />
总结:<br />
本文讨论了持续学习和灾难性遗忘的问题，提出了一种解决方案来解决这一挑战。研究人员指出，传统的机器学习算法在面对持续学习任务时会出现灾难性遗忘的情况，导致已学习过的知识被遗忘。为了克服这一问题，他们提出了一种基于神经网络的方法，通过对模型进行增量学习和保留重要信息的方式来解决灾难性遗忘。研究人员进行了一系列实验来验证他们的方法的有效性，结果表明他们的方法在持续学习任务中具有较好的性能表现。这项研究为解决持续学习和灾难性遗忘问题提供了新的思路和方法。 <div>
[LG]《Continual Learning and Catastrophic Forgetting》G M. v d Ven, N Soures, D Kudithipudi [KU Leuve &amp; University of Texas at San Antonio] (2024) <a href="https://arxiv.org/abs/2403.05175"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklqwed9j21eo0dwgs1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntklrqmumj21na0motf2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsa9x2j21n40kaaj9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsujzaj21n20nk7cy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntkznz89nj21120o7439.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:19:59 GMT</pubDate>
</item>
<item>
<title>ACORN是一种新的、性能优异且不限制谓词类型的混合搜索方法，通过改良HNSW索引和引入谓词子图遍历来同时高效处理向量和结构化数据，克服了传统方法在性能和搜索...</title>
<link>https://weibo.com/1402400261/O5mPdmC1P</link>
<guid>https://weibo.com/1402400261/O5mPdmC1P</guid>
<content:encoded><![CDATA[
<div> ACORN, HNSW索引, 混合搜索方法, 向量数据, 结构化数据, 高性能, 不限制谓词类型, 复杂多模态数据集, 高查询吞吐量, 低构建开销

<br /><br />总结:
研究介绍了一种新的混合搜索方法ACORN，它通过改良HNSW索引和引入谓词子图遍历来同时处理向量数据和结构化数据。ACORN能够高效处理复杂多模态数据集，克服了传统方法在性能和搜索谓词表达式上的限制。研究表明，ACORN实现了高查询吞吐量和低构建开销的优异性能，为搜索领域带来了新的可能性。 <div>
ACORN是一种新的、性能优异且不限制谓词类型的混合搜索方法，通过改良HNSW索引和引入谓词子图遍历来同时高效处理向量和结构化数据，克服了传统方法在性能和搜索谓词表达式上的限制，实现了在复杂多模态数据集上的高查询吞吐量和低构建开销。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [IR]《ACORN: Performant and Predicate-Agnostic Search Over Vector Embeddings and Structured Data》L Patel, P Kraft, C Guestrin, M Zaharia [Stanford University &amp; DBOS, Inc &amp; UC Berkeley] (2024) <a href="https://arxiv.org/abs/2403.04871"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkivhxhvj211e11eao2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkivwjjlj210y0l4wh3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkiwh65wj211a0tyjws.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntkiwpg9jj21160jetb3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkiy3hepj213s0e2gnl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkiy2ugdj20jg0d33zo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkiy3nidj213r0csgob.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkiy2z5dj213m08qgn0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkiy3nxyj20jg0f175q.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:04:06 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》(CVPR 2024) GitHub: github.c...</title>
<link>https://weibo.com/1402400261/O5jwVne0V</link>
<guid>https://weibo.com/1402400261/O5jwVne0V</guid>
<content:encoded><![CDATA[
<div> DNGaussian, 优化, 稀疏视图, 3D, 高斯辐射场, 全局局部深度规范化, GitHub, Pix2Gif, 运动引导扩散, GIF 生成, SSM, 视频扩散模型, 有效视频生成, 结构化状态空间, 语言模型, 可靠性, 过度训练, 下游任务

<br /><br />总结: 《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》提出了一种优化稀疏视图3D高斯辐射场的方法，通过全局局部深度规范化来改善渲染效果，代码可在GitHub上找到。《Pix2Gif: Motion-Guided Diffusion for GIF Generation》介绍了Pix2Gif，一种运动引导扩散技术，用于生成GIF图像。《SSM Meets Video Diffusion Models: Efficient Video Generation with Structured State Spaces》展示了SSM与视频扩散模型相结合，实现了有效的视频生成，采用了结构化状态空间。《Language models scale reliably with over-training and on downstream tasks》研究表明，语言模型在过度训练和下游任务中表现出可靠的扩展性，相关代码可在GitHub上获取。 <div>
几篇论文实现代码：<br />《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》(CVPR 2024) GitHub: github.com/Fictionarry/DNGaussian [fig1]<br />《Pix2Gif: Motion-Guided Diffusion for GIF Generation》(2024) GitHub: github.com/hiteshK03/Pix2Gif<br />《SSM Meets Video Diffusion Models: Efficient Video Generation with Structured State Spaces》(2024) GitHub: github.com/shim0114/SSM-Meets-Video-Diffusion-Models [fig2]<br />《Language models scale reliably with over-training and on downstream tasks》(2024) GitHub: github.com/mlfoundations/scaling<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnt3oac1q5j21iu0jiasp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnt3p0dq0hj22801904ns.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 13:40:48 GMT</pubDate>
</item>
<item>
<title>'Awesome-AISourceHub - AI科技领域高质量信息源列表’ GitHub: github.com/AmbroseX/Awesome-AISourceHub #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5jwP9UrG</link>
<guid>https://weibo.com/1402400261/O5jwP9UrG</guid>
<content:encoded><![CDATA[
<div> GitHub, AI, 科技, 高质量, 信息源, 列表, 开源项目, AmbroseX, Awesome-AISourceHub

总结:<br /><br />这是一个收集AI科技领域高质量信息源的开源项目，其中包括了各种资源列表和信息源，可以帮助人们更好地了解和学习关于人工智能的知识。由AmbroseX创建并维护，项目地址为github.com/AmbroseX/Awesome-AISourceHub。欢迎大家积极参与和贡献，共同打造一个强大的AI资源集合。 <div>
'Awesome-AISourceHub - AI科技领域高质量信息源列表’ GitHub: github.com/AmbroseX/Awesome-AISourceHub <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnt5z3jp2mj20y40u00y9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 13:40:33 GMT</pubDate>
</item>
<item>
<title>【EasyDetect：易于使用的多模态幻觉检测框架，用于多模态大型语言模型(MLLMs)如GPT-4V、Gemini、LlaVA的研究实验，通过统一的视角对多模态幻觉进行检测，包括模...</title>
<link>https://weibo.com/1402400261/O5j2octGD</link>
<guid>https://weibo.com/1402400261/O5j2octGD</guid>
<content:encoded><![CDATA[
<div> 多模态 幻觉检测框架 GPT-4V Gemini LlaVA 研究实验 统一视角 模态冲突 幻觉 事实冲突 幻觉

<br /><br />总结:
EasyDetect是一个易于使用的多模态幻觉检测框架，专为大型语言模型如GPT-4V、Gemini和LlaVA的研究实验而设计。该框架通过统一的视角对多模态幻觉进行检测，包括模态冲突幻觉和事实冲突幻觉。通过EasyDetect，研究人员可以更方便地进行多模态幻觉的实验和研究，从而深入探讨语言模型的表现和特性。 <div>
【EasyDetect：易于使用的多模态幻觉检测框架，用于多模态大型语言模型(MLLMs)如GPT-4V、Gemini、LlaVA的研究实验，通过统一的视角对多模态幻觉进行检测，包括模态冲突幻觉和事实冲突幻觉】’EasyDetect - An Easy-to-use Hallucination Detection Framework for LLMs.' GitHub: github.com/OpenKG-ORG/EasyDetect <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnt3t2xe1zj20i60fbdj0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnt3t5cqj1j20pp0gegqn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 12:25:34 GMT</pubDate>
</item>
<item>
<title>【ChatOllama：基于Nuxt 3和Ollama的聊天Web应用】'ChatOllama - a Nuxt 3 + Ollama web application. It's an example of Ollama Javascript library’ GitHub:...</title>
<link>https://weibo.com/1402400261/O5j0hzQkC</link>
<guid>https://weibo.com/1402400261/O5j0hzQkC</guid>
<content:encoded><![CDATA[
<div> ChatOllama、Nuxt 3、Ollama、web应用、GitHub、Javascript库、聊天应用、示例、开发、实现<br />
<br />总结:
ChatOllama是基于Nuxt 3和Ollama的聊天Web应用示例，使用Ollama Javascript库开发，代码托管在GitHub上，展示了如何开发和实现一个聊天应用。 <div>
【ChatOllama：基于Nuxt 3和Ollama的聊天Web应用】'ChatOllama - a Nuxt 3 + Ollama web application. It's an example of Ollama Javascript library’ GitHub: github.com/sugarforever/chat-ollama <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnt3ns8meej219c0jogny.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 12:20:23 GMT</pubDate>
</item>
<item>
<title>【Data is Better Together：由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。目前，该项目已经创...</title>
<link>https://weibo.com/1402400261/O5ihKbqgZ</link>
<guid>https://weibo.com/1402400261/O5ihKbqgZ</guid>
<content:encoded><![CDATA[
<div> Hugging Face, Argilla, 开源机器学习社区, 数据集, 合作, 提示, 排名, 10,000个, 质量

<br /><br />总结:
Data is Better Together是一个由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。该项目已经创建了一个由10,000个提示组成的数据集，并按照质量进行了排名。这个项目的目标是让开源社区共同努力，创造更好的数据集，为机器学习研究和实践提供更丰富的资源和支持。通过协作和合作，我们可以共同构建更具影响力和实用性的数据集，推动机器学习领域的发展和创新。 <div>
【Data is Better Together：由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。目前，该项目已经创建了一个由10,000个提示组成的数据集，按质量进行了排名】'Data is Better Together - Let's build better datasets, together!' GitHub: github.com/huggingface/data-is-better-together <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnt0hi5cbfj211y0lc78w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 10:30:39 GMT</pubDate>
</item>
<item>
<title>【OPEN TEACH: 多功能遥操作框架，使用Meta Quest3进行机器人操作，具有灵活性和多样性，包括VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，支持在各种...</title>
<link>https://weibo.com/1402400261/O5ih2p7R0</link>
<guid>https://weibo.com/1402400261/O5ih2p7R0</guid>
<content:encoded><![CDATA[
<div> 多功能遥操作框架, Meta Quest3, 机器人操作, 灵活性, 多样性, Unity脚本, 遥操作流程, 数据收集流程, 策略训练, GitHub  

<br /><br />总结:  
这篇文章介绍了一个名为"OPEN TEACH"的多功能遥操作框架，使用Meta Quest3进行机器人操作，并具有灵活性和多样性。该框架包括了VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，能够支持在各种机器人和仿真环境下进行遥操作和数据收集，并针对不同机器人和仿真进行策略训练。该框架的GitHub链接为github.com/aadhithya14/Open-Teach。 <div>
【OPEN TEACH: 多功能遥操作框架，使用Meta Quest3进行机器人操作，具有灵活性和多样性，包括VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，支持在各种机器人和仿真环境下进行遥操作和数据收集，并针对不同机器人和仿真进行策略训练】'OPEN TEACH: A Versatile Teleoperation System for Robotic Manipulation - A Versatile Teleoperation framework for Robotic Manipulation using Meta Quest3' GitHub: github.com/aadhithya14/Open-Teach <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnt0fre8fpj21ji0twwkh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 10:28:54 GMT</pubDate>
</item>
<item>
<title>今日推介(第1346期)：让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、用Moment Pooling简化机器学习...</title>
<link>https://weibo.com/1402400261/O5dqgdQEc</link>
<guid>https://weibo.com/1402400261/O5dqgdQEc</guid>
<content:encoded><![CDATA[
<div> 语言模型、结构化训练、灾难性遗忘、预期性恢复、马尔可夫决策过程、学习算法、Moment Pooling、机器学习潜空间、API保护、LLM的Logits

<br /><br />总结:
本文介绍了几个关键的技术和方法，包括让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、以及用Moment Pooling简化机器学习潜空间。另外，还提到了API保护LLM的Logits会泄漏模型专有信息的问题。这些方法和技术对于改进语言模型的能力，提高机器学习算法的效率和精确度都具有重要意义。通过不断探索和应用这些新技术，我们可以进一步推动人工智能领域的发展，为未来带来更多可能性。 <div>
今日推介(第1346期)：让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、用Moment Pooling简化机器学习潜空间、API保护LLM的Logits会泄漏模型专有信息 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687311397"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.16)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnsf0htg36j20k00b9gn7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnsf0k1lqgj20k006m751.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnsf0ml60tj20k007d0t5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnsf0p0i2ij20k00kq762.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnsf0repglj20k008pwfi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 22:07:54 GMT</pubDate>
</item>
<item>
<title>[RO] GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping 网页链接 提出一种名为GaussianGrasper的开放词表机器人抓取技术...</title>
<link>https://weibo.com/1402400261/O5dn86Ikc</link>
<guid>https://weibo.com/1402400261/O5dn86Ikc</guid>
<content:encoded><![CDATA[
<div> 高斯Splatting、机器人抓取技术、3D构建、视角输入、推理效率、特征蒸馏、对比学习、抓取姿态、语言指令、场景更新
<br /><br />总结:
提出了一种名为GaussianGrasper的开放词表机器人抓取技术，通过3D高斯Splatting构建场景，解决了传统隐式场景表达的问题。利用有限的RGB-D视角和高效特征蒸馏模块，结合对比学习来准确提取语言嵌入，使得预训练的抓取模型可以生成无碰撞的抓取姿态候选。通过法向引导的抓取模块选取最佳姿态。实验证明，该系统能准确响应语言指令，执行抓取任务，并实现快速场景更新。提供了新的解决方案用于语言引导操作任务，并公开了数据和代码资源。 <div>
[RO] GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping  <br /><a href="https://arxiv.org/abs/2403.09637"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出一种名为GaussianGrasper的开放词表机器人抓取技术，它通过3D高斯Splatting显式构建场景，解决了传统隐式场景表达(例如NeRF)需要大量视角输入和推理效率低下的问题。GaussianGrasper利用有限的RGB-D视角并通过一种高效特征蒸馏(EFD)模块，结合对比学习来准确提取语言嵌入。这使得其预训练的抓取模型能生成无碰撞的抓取姿态候选，并通过法向引导的抓取模块选取最佳姿态。实验表明，该系统能准确响应语言指令，执行抓取任务，并实现快速场景更新。此外，提供了用于语言引导操作任务的新解决方案，并公开了数据和代码资源。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsesr3i0dj219w1kc1kx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsesrglfpj21hq17uqlw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsesrlyxgj21h40uqqif.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 22:00:11 GMT</pubDate>
</item>
<item>
<title>[CV] Reconstruction and Simulation of Elastic Objects with Spring-Mass 3D Gaussians 网页链接 提出了Spring-Gaus框架，一个整合物理仿真和3D高斯模型的新方...</title>
<link>https://weibo.com/1402400261/O5difnNAc</link>
<guid>https://weibo.com/1402400261/O5difnNAc</guid>
<content:encoded><![CDATA[
<div> Spring-Gaus, 物理仿真, 3D高斯模型, 弹性物体, 多视角视频, 参数优化, 模拟粒子, 样本效率, 泛化能力, 形变预测

<br /><br />总结:
本文提出了Spring-Gaus框架，结合了物理仿真和3D高斯模型，用于重建和模拟弹性物体。通过3D弹簧-质点模型在个体点级别优化物理参数，解决了物理和外观学习的问题，提高了样本效率和泛化能力。Spring-Gaus在合成和真实数据集上证明了有效性，特别是在形变预测和不同环境参数下的模拟中表现出色。这一研究突破了物理参数优化和异质物体建模的限制，为预测视觉感知和沉浸式体验的应用提供了新的可能性。 <div>
[CV] Reconstruction and Simulation of Elastic Objects with Spring-Mass 3D Gaussians  <br /><a href="https://arxiv.org/abs/2403.09434"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出了Spring-Gaus框架，一个整合物理仿真和3D高斯模型的新方法，用于从多视角视频重建和模拟弹性物体。与传统的3D高斯方法相比，Spring-Gaus通过3D弹簧-质点模型在个体点级别优化物理参数，有效解缠物理和外观学习。这种方法提高了样本效率，增强了泛化能力，并减少了对仿真粒子分布的敏感性。在合成和真实世界数据集上的评估证明了Spring-Gaus在准确重建和模拟弹性物体方面的有效性，尤其是在进行未来形变预测和不同初始状态及环境参数下的模拟时。该研究突破了物理参数优化和异质物体建模的限制，为预测视觉感知和沉浸式体验的应用开辟了可能。<img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnseg8bri1j20z41e6wrp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnseg8nm5cj21fa0wstjg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnseg9gk2gj21fa1au18j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:48:10 GMT</pubDate>
</item>
<item>
<title>[LG] Majority-of-Three: The Simplest Optimal Learner? 网页链接 讨论了PAC学习中的一个开放问题：在实现环境下，寻找最简单的最优学习算法。分析了一个简单的...</title>
<link>https://weibo.com/1402400261/O5deGfwNR</link>
<guid>https://weibo.com/1402400261/O5deGfwNR</guid>
<content:encoded><![CDATA[
<div> 多数投票法, 最优学习算法, PAC学习, 期望误差, 高概率误差, Bagging算法, ERM分类器, 最优误差界, one-inclusion graph算法, 简化算法结构

<br /><br />总结:
本文讨论了在实现环境下寻找最简单的最优学习算法的问题，并提出了多数投票法可能是一个简单且最优的解决方案。该算法使用三个ERM分类器，在期望误差上达到了最优，并且在高概率误差上也接近最优。该发现挑战了之前认为ERM分类器无法独自实现最优误差界的观点。文章还提出了改进的Bagging算法，简化了之前复杂的算法结构。另外，研究指出了one-inclusion graph算法在高概率误差上的局限性，与之前的猜想相反。通过进一步分析，多数投票法可能在高概率误差上也是最优的。整体而言，本文为最简单有效的学习算法提供了新的思路，并拓展了对学习算法的理解。 <div>
[LG] Majority-of-Three: The Simplest Optimal Learner?  <br /><a href="https://arxiv.org/abs/2403.08831"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />讨论了PAC学习中的一个开放问题：在实现环境下，寻找最简单的最优学习算法。分析了一个简单的算法——多数投票法，其中只使用三个ERM分类器。文章的核心是这个算法在期望误差上达到了最优，并且近似于高概率误差上的最优。这一发现挑战了之前的认知，即ERM分类器无法独自实现最优误差界。本文还提出一种改进的Bagging算法，简化了之前复杂的算法结构，但分析过程仍然复杂。此外，一项新的研究揭示了one-inclusion graph算法在高概率误差上的局限性，这与之前Warmuth的猜想相反。本文认为，通过进一步分析，上述多数投票法可能在高概率误差上也是最优的。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnse738777j21841gmh1p.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnse73lpebj21co0zoqa5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:39:22 GMT</pubDate>
</item>
<item>
<title>[CV] MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training 网页链接 介绍了多模态大型语言模型(MLLM)的构建，重点在于体系结构组件和数据选择...</title>
<link>https://weibo.com/1402400261/O5dbMeVyI</link>
<guid>https://weibo.com/1402400261/O5dbMeVyI</guid>
<content:encoded><![CDATA[
<div> 模态语言模型 构建 组件 数据 体系结构 图像编码器 视觉语言连接器 预训练数据<br />
<br />
总结: 本文介绍了多模态大型语言模型(MLLM)的构建方法和分析，强调了体系结构组件和数据选择的重要性。研究发现，混合使用图像-文字、交错图像-文字和纯文字数据对实现少样本最先进结果(SOTA)至关重要。此外，图像编码器、图像分辨率和图像标记数量对结果有显著影响。作者构建了一个最高达30B参数的模型族MM1，通过大规模预训练实现了竞争性性能，并展现了吸引人的特性，能够实现少样本的连锁思维提示。 <div>
[CV] MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training  <br /><a href="https://arxiv.org/abs/2403.09611"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了多模态大型语言模型(MLLM)的构建，重点在于体系结构组件和数据选择的重要性。通过对图像编码器、视觉语言连接器和不同预训练数据选项的详尽剖析，揭示了几个关键设计经验。研究表明，混合使用图像-文字、交错图像-文字和纯文字数据对于实现多项基准测试中的少样本最先进结果(SOTA)至关重要。此外，图像编码器、图像分辨率和图像标记数量对结果有显著影响，而视觉-语言连接器设计的影响相对较小。作者通过扩大模型规模，构建了一个最高达30B参数的模型族MM1，包括密集型模型和专家混合型变体，这些模型在预训练度量上表现出色，并在一系列多模态基准测试中经过监督微调后获得了竞争性性能。MM1的大规模预训练赋予了它如上下文预测、多图像推理等吸引人的特性，使其能够实现少样本的连锁思维提示。<img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdzmld2pj21201iuapu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdzn0s90j21hk13aaq5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdznf268j21hk0tytm5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdznnj32j21hm0qiaiy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:32:13 GMT</pubDate>
</item>
<item>
<title>揭示了通过分析LLM API的输出，即便是在API保护下，仍能通过较少的成本就能获取大量关于大型语言模型(如OpenAI gpt-3.5-turbo)的私有参数和结构信息，强调了这种...</title>
<link>https://weibo.com/1402400261/O5d99bA9M</link>
<guid>https://weibo.com/1402400261/O5d99bA9M</guid>
<content:encoded><![CDATA[
<div> API保护、LLM、私有参数、结构信息、模型透明度、问责性、信息泄露、特性、分析、有效性<br />
<br />
提到了一种通过分析LLM API输出获取私有参数和结构信息的方法，即使在API保护下也能实现。强调了这种方法的有效性，指出可以将其作为一种特性来提高模型的透明度和问责性。文章的研究结果揭示了重要的信息泄露问题，也提示了提高模型透明度的重要性。这种方法对于模型的安全性和隐私保护具有重要影响，值得深入研究和思考。<br /><br />总结: 提出了一种通过分析LLM API输出泄露私有信息的方法，并强调了其有效性以及作为提高模型透明度和问责性的特性。 <div>
揭示了通过分析LLM API的输出，即便是在API保护下，仍能通过较少的成本就能获取大量关于大型语言模型(如OpenAI gpt-3.5-turbo)的私有参数和结构信息，强调了这种获取信息方法的有效性，指出如何将此作为一种特性来提高模型的透明度和问责性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) <a href="https://arxiv.org/abs/2403.09539"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdhz8pyhj21oc15s7p2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdhzlf91j21ks0w4wqg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdhzq3auj21ke0oigsg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdi02jdij21l80pe118.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdsgpg07j20ve0dy764.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdsgoh8fj20vg0dqq55.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdsgpg6xj20vd090aar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:25:44 GMT</pubDate>
</item>
<item>
<title>[CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) 网页链接...</title>
<link>https://weibo.com/1402400261/O5d8YfyGJ</link>
<guid>https://weibo.com/1402400261/O5d8YfyGJ</guid>
<content:encoded><![CDATA[
<div> API-Protected LLMs, Logits, Leakage, Proprietary Information, Privacy, Data Security, Machine Learning, Information Disclosure

总结:<br /><br />本文研究了API保护的语言模型（LLMs）的Logits可能泄漏专有信息的问题。研究人员发现，即使在API保护的情况下，LLMs的输出Logits也可能包含公司的机密信息。这种信息泄漏可能导致数据隐私和安全方面的问题。因此，需要采取相应的措施来确保机器学习模型不会泄露敏感信息，保障数据安全。 <div>
[CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) <a href="https://arxiv.org/abs/2403.09539"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdhz8pyhj21oc15s7p2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdhzlf91j21ks0w4wqg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdhzq3auj21ke0oigsg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdi02jdij21l80pe118.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdsgpg07j20ve0dy764.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdsgoh8fj20vg0dqq55.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdsgpg6xj20vd090aar.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:25:18 GMT</pubDate>
</item>
<item>
<title>提出一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来显著降低潜空间维数，同时保持或提升模型性能，并以更少的基函数构建相同的机器学习...</title>
<link>https://weibo.com/1402400261/O5d3xurjA</link>
<guid>https://weibo.com/1402400261/O5d3xurjA</guid>
<content:encoded><![CDATA[
<div> 关键词: Moment Pooling, 深度集网络, 多变量矩, 潜空间维数, 模型性能, 基函数, 机器学习观测值, 可视化, 解释.

总结:<br /><br />本文提出了一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来降低潜空间维数，以提升模型性能。这一方法能够在更少的基函数下构建相同的机器学习观测值，使得模型内部表示可以更简单地进行可视化和解释。 Moment Pooling 的应用可以显著简化潜在空间的维数，帮助提升模型的性能，并且使得模型更容易解释和理解。通过对多变量矩的运用，Moment Pooling 可以在保持甚至提升模型性能的同时，降低所需的基函数数量，从而简化模型构建和解释过程。这一方法有望为机器学习领域带来更高效和可解释的模型设计。 <div>
提出一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来显著降低潜空间维数，同时保持或提升模型性能，并以更少的基函数构建相同的机器学习观测值，使得模型内部表示的可视化和解释变得更加简单。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) <a href="https://arxiv.org/abs/2403.08854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdd9vs67j21is0gyk1g.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsddafjn1j21mo0w2472.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddapji1j21901amtg7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddav53cj20vi10c79w.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c6wmj20jp0o3q5d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6f420j2140147afj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6bkxyj20jp0litak.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsde6g62dj2140156dpr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6drm7j2140156jva.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:11:56 GMT</pubDate>
</item>
<item>
<title>[LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) 网页链接 ...</title>
<link>https://weibo.com/1402400261/O5d3oBouU</link>
<guid>https://weibo.com/1402400261/O5d3oBouU</guid>
<content:encoded><![CDATA[
<div> Streamlining, Latent Spaces, Machine Learning, Moment Pooling, MIT, Gambhir, Osathapan, Thaler, 2024

<br /><br />总结:
本文探讨了在机器学习中利用矩阵池化来简化潜在空间的方法。研究人员提出了一种称为Moment Pooling的新技术，通过将不同阶数的矩阵进行池化，从而提高了模型在学习高阶统计特性方面的能力。这种技术不仅能够提高模型的效率，还能够减少模型对大规模数据集的需求。研究还表明，Moment Pooling技术在训练时间和模型性能之间取得了良好的平衡，为机器学习领域的实践带来了新的启示。MIT的研究人员Gambhir、Osathapan和Thaler的工作为机器学习领域的发展提供了有益的思路和方法。 <div>
[LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) <a href="https://arxiv.org/abs/2403.08854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdd9vs67j21is0gyk1g.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsddafjn1j21mo0w2472.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddapji1j21901amtg7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddav53cj20vi10c79w.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c6wmj20jp0o3q5d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6f420j2140147afj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6bkxyj20jp0litak.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsde6g62dj2140156dpr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6drm7j2140156jva.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6ceorj20jp0l1dhh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6d31vj21400ki77c.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c36cj20jp0khgn1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6d5zdj20z20jpgny.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6dr66j20zc0jqtb4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:11:35 GMT</pubDate>
</item>
<item>
<title>创新性地提出了一个学习算法框架，用于在完全和部分知识情况下进行马尔可夫决策过程的验证，特别是在不需要MDP结构特性假设和时间界限的情况下，通过启发式方法...</title>
<link>https://weibo.com/1402400261/O5d2K9Lno</link>
<guid>https://weibo.com/1402400261/O5d2K9Lno</guid>
<content:encoded><![CDATA[
<div> 马尔可夫决策过程、学习算法、验证、完全知识、部分知识、MDP结构、时间界限、概率可达性、启发式方法、停止准则

<br /><br />总结:
该研究提出了一个学习算法框架，可用于验证马尔可夫决策过程，在完全和部分知识情况下，无需MDP结构特性假设和时间界限。通过启发式方法提供了概率可达性的精确和概率界，同时提出了适应性强的停止准则。这一创新性方法有望在解决复杂决策问题中发挥重要作用。 <div>
创新性地提出了一个学习算法框架，用于在完全和部分知识情况下进行马尔可夫决策过程的验证，特别是在不需要MDP结构特性假设和时间界限的情况下，通过启发式方法提供了概率可达性的精确和概率界，同时提出了适应性强的停止准则。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Learning Algorithms for Verification of Markov Decision Processes》T Brázdil, K Chatterjee, M Chmelik, V Forejt, J Křetínský, M Kwiatkowska, T Meggendorfer, D Parker, M Ujma [Google LLC &amp; IST Austria &amp; Lancaster University Leipzig] (2024) <a href="https://arxiv.org/abs/2403.09184"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdb2ek9bj210m0mb12q.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdb2s9l9j21ce0pwtbu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdb38x14j21n20lqq6c.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdb3sanvj21rg0ecwgs.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:09:58 GMT</pubDate>
</item>
<item>
<title>恭喜@sayfh_wu-wuy_su私人领域-_- 等3名用户获得【《SPSSAU科研数据分析方法与应用》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效...</title>
<link>https://weibo.com/1402400261/O56k4DmCh</link>
<guid>https://weibo.com/1402400261/O56k4DmCh</guid>
<content:encoded><![CDATA[
<div> SPSSAU, 数据分析, 科研, 应用, 抽奖, 微博, 研究方法, 问卷数据, 医学数据, 视频讲解

<br /><br />总结:
微博举办了一次抽奖活动，三名幸运用户将获得《SPSSAU科研数据分析方法与应用》。这本书系统介绍了科研数据分析方法，适合研究者快速学习和掌握。活动截止时间是2024年3月15日12:00，感兴趣的用户需要转发和评论才能参与。活动结果将通过微博官方唯一抽奖工具监督，公正有效。该书涵盖了数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等方面，并配有171集视频讲解，帮助研究者更好地理解科研数据分析方法。 <div>
恭喜<a href="https://weibo.com/n/sayfh_wu-wuy_su%E7%A7%81%E4%BA%BA%E9%A2%86%E5%9F%9F-_-">@sayfh_wu-wuy_su私人领域-_-</a> 等3名用户获得【《SPSSAU科研数据分析方法与应用》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20117566&amp;pageid=100140E51183068"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00，*可可粉*转发+评论即可参与。近万篇研究论文选用SPSSAU快速入门，本书从数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等五个方面系统地介绍科研数据的分析方法，涉及13项知识类应用（如影响关系、权重关系、数据预测、问卷研究）附赠171集配套视频讲解，适合研究者快速学习和掌握科研数据分析方法。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5009557898134749"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnj8n91y6bj20m80m8n19.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnj8n9h45kj20m80m8mzs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9rlbnj20m80m8tbk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9wj7pj20m80m80vr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 04:03:26 GMT</pubDate>
</item>
<item>
<title>【艺术成功之路：声誉与网络的量化分析】- 研究人员重建了50万名艺术家的展览历史，绘制出反映艺术在机构之间流动的共同展览网络。 - 在这个网络中的中心性捕捉...</title>
<link>https://weibo.com/1402400261/O54JlkeLD</link>
<guid>https://weibo.com/1402400261/O54JlkeLD</guid>
<content:encoded><![CDATA[
<div> 艺术家、声誉、网络、展览历史、职业轨迹、早期进入高声望机构、马尔可夫模型、原籍国、潜在政策、彩票系统

<br /><br />总结:研究人员通过重建艺术家展览历史，揭示了艺术界展览网络结构和声誉对艺术家职业成功的影响。进入声誉高的机构能提供终身影响，早期选择机构会影响职业轨迹。原籍国可影响艺术家初始声誉和职业发展，建议实施彩票系统以提高公平竞争。研究虽然量化了准入壁垒，但仍需关注艺术评估的主观性和非实物艺术形式。艺术家应在更广泛机构展出，挑战传统观点，同时要面对可能的阻力。不同原籍国在全球化艺术世界中仍对艺术家有影响，呼吁更多关注多维度的审视。 <div>
【艺术成功之路：声誉与网络的量化分析】<br />- 研究人员重建了50万名艺术家的展览历史，绘制出反映艺术在机构之间流动的共同展览网络。  <br />- 在这个网络中的中心性捕捉了机构的声望，允许分析单个艺术家在获取理想机构方面的职业轨迹。  <br />- 早期进入声望高、处于中心位置的机构，可以为艺术家提供终身进入高声望场所的机会，并降低退出率。  <br />- 从网络边缘开始职业生涯会导致高退出率，限制进入中心机构的机会。  <br />- 一个马尔可夫模型可以预测艺术家的职业轨迹，记录了艺术价值评估中强烈的路径依赖和历史依赖。  <br />- 艺术家最初声望(前五次展览)的分布因其原籍国而异，影响他们职业成功的机会。  <br />- 该研究量化了艺术界的分层和准入壁垒，提出了潜在的政策，如彩票系统，以营造公平的竞争环境。  <br /><br />思考：  <br />- 该研究提供了声誉和网络在主观领域(如艺术)中决定资源和回报获取的量化见解，在这些领域中很难客观衡量表现。  <br />- 早期进入声望高的机构会产生终身影响，这一发现挑战了精英制的概念，凸显了初始机会的重要性。  <br />- 该研究关注机构准入和经济价值，可能忽略了艺术丰富社会的其他维度，如文化和情感价值。  <br />- 艺术家原籍国影响其初始声望和职业轨迹，这一观察结果引发了对艺术界系统性偏见和不平等的质疑。  <br />- 建议在艺术界实施彩票系统或盲选程序以提高代表性不足艺术家的包容性，可能面临既得利益机构和艺术界的阻力。  <br />- 尽管该研究量化了准入壁垒，但并未直接解决艺术评估的主观性质以及评估过程中固有的潜在偏见。  <br />- 该研究依赖展览和拍卖数据，可能低估了非实物艺术形式，如行为艺术，因为这些艺术形式无法通过这些渠道捕捉。   <br />- 研究发现，在职业生涯早期在更广泛的机构展出可以提高突破的机会，这挑战了专注于特定领域或风格的传统观点。  <br />- 该研究建议在艺术界实施彩票系统或盲选程序，这些做法更常见于就业或音乐试演等领域。  <br />- 观察到艺术家的原籍国影响其初始声望和职业轨迹，这一点有悖常理，因为在全球化的艺术世界中，人们可能认为天赋与地理因素无关。<br />《Quantifying reputation and success in art | Science》 <a href="https://www.science.org/doi/10.1126/science.aau7224"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnrcnblrptj20u00x113j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 00:00:12 GMT</pubDate>
</item>
<item>
<title>【Cappy：用小型评分器提升大型语言模型性能】 - Google研究人员提出了一种名为Cappy的新方法，可以通过一个小型评分器(scorer)来提升和增强大型多任务语言模型...</title>
<link>https://weibo.com/1402400261/O54Dc9dTt</link>
<guid>https://weibo.com/1402400261/O54Dc9dTt</guid>
<content:encoded><![CDATA[
<div> Cappy, 小型评分器, 大型语言模型, 性能提升, 多任务, 输出质量, 灵活性, 高效性, 实际应用, 可扩展性

<br /><br />总结: 
Google研究人员提出了一种名为Cappy的新方法，通过引入一个小型评分器来提升和增强大型多任务语言模型的性能。Cappy利用评分器重新排序生成的候选输出，提高输出质量。评分器是一个轻量级神经网络模型，专门用于评估候选输出质量，并与大型语言模型结合。Cappy在多个基准测试中展现出优异性能，提高大型模型表现。该方法灵活性强，可与各种大型语言模型结合，适用于不同任务。尽管在基准测试中表现出色，实际应用场景中的效果和可扩展性还需进一步验证。Cappy的高效性和轻量设计或将受益于未来硬件发展，如专用AI加速器。然而，引入新的偏差和不确定性也需进一步研究和优化。Cappy为提高大型语言模型性能提供了新的范式。 <div>
【Cappy：用小型评分器提升大型语言模型性能】  <br />- Google研究人员提出了一种名为Cappy的新方法，可以通过一个小型评分器(scorer)来提升和增强大型多任务语言模型的性能。  <br />- Cappy利用一个小型评分器来重新排序大型语言模型生成的候选输出，从而提高输出质量。  <br />- 评分器是一个轻量级的神经网络模型，专门用于评估候选输出的质量，而不负责生成输出。  <br />- 在多个基准测试中，Cappy展现出优于大型语言模型的性能，同时也能够提升这些大型模型的表现。  <br />- Cappy的优势在于其高效性和灵活性，可以与各种大型语言模型相结合，并在不同任务上发挥作用。  <br />- 研究人员认为，Cappy为提高大型语言模型的性能和效率提供了一种新的范式。  <br /><br />思考：  <br />- Cappy的提出解决了大型语言模型在某些任务上表现不佳的问题，通过引入一个小型评分器来提升整体性能，这种思路值得关注。  <br />- 将生成和评估分离的方法使Cappy具有灵活性，可以与不同的大型模型相结合，提高了其适用范围。  <br />- 尽管Cappy在基准测试中表现出色，但其在实际应用场景中的效果和可扩展性仍有待进一步验证。  <br />- Cappy的高效性和轻量设计可能会受益于未来硬件的发展，如专用AI加速器等，从而进一步提升其性能。  <br />- 虽然Cappy旨在提高大型语言模型的性能，但其本身也可能引入新的偏差和不确定性，需要进一步研究和优化。<br />《Cappy: Outperforming and boosting large multi-task language models with a small scorer – Google Research Blog》 <a href="https://blog.research.google/2024/03/cappy-outperforming-and-boosting-large.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnrc7chdqkj21780go75q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc7csa3qj21jj0r3q63.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnrc7dkpzrj21jj0c6jv0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc7ffs7jj21jj0sw42p.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnrc7fyfiuj21hb0u0goi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:45:03 GMT</pubDate>
</item>
<item>
<title>【聊天机器人变身生产力助手：Command-R用Tool Use功能重塑业务工作流】- Cohere推出了Command-R模型的Tool Use功能，使语言模型能够与用户定义的工具交互，实现...</title>
<link>https://weibo.com/1402400261/O54B6h2pa</link>
<guid>https://weibo.com/1402400261/O54B6h2pa</guid>
<content:encoded><![CDATA[
<div> Command-R, Tool Use, 应用示例, 生产力助手, 跨平台, 自动化工作流程, 部署灵活性, 实施过程, AI应用, 语言模型

<br /><br />总结: 
Command-R推出了Tool Use功能，使语言模型能够与外部工具交互，执行复杂任务，提升生产力。该功能连接不同应用程序和系统，实现跨平台的自动化工作流程。结合Tool Use，Command-R从聊天机器人发展为强大的生产力助手和研究工具，可能改变AI交互方式。平衡了性能、效率和部署灵活性，适用于构建AI应用，突破了单一云环境的限制。企业实施Tool Use的简化四步过程降低了门槛，加速了应用，但需评估具体需求和系统兼容性。 <div>
【聊天机器人变身生产力助手：Command-R用Tool Use功能重塑业务工作流】<br />- Cohere推出了Command-R模型的Tool Use功能，使语言模型能够与用户定义的工具交互，实现高度复杂任务的自动化。  <br />- Command-R在Tool Use模式下可以根据用户交互和对话历史创建API负载(包含特定参数的JSON)，用于指示其他应用程序或工具。  <br />- Tool Use的应用示例包括自动分类和路由支持凭证、更新客户关系管理软件(CRM)中的状态，以及从向量数据库中检索相关片段。  <br />- 应用的输出会反馈给Command-R，用于生成最终响应。响应中包含引用，便于用户从源数据或工具结果中追溯声明。  <br />- Tool Use使Command-R的应用从简单的聊天机器人发展为强大的代理和研究工具，提高了生产力。  <br />- Command-R在高效率、强大性能和跨主要云提供商的灵活部署之间取得了平衡，是构建依赖Tool Use的AI应用的有竞争力的解决方案。  <br />- 在企业中实施Tool Use对开发人员来说是一个简单的四步过程。  <br /><br />思考：  <br />- Tool Use功能突破了语言模型仅限于自然语言处理的边界，使其能够与外部工具交互，执行复杂的任务和工作流程，开辟了语言模型应用的新领域。  <br />- Command-R与Tool Use的结合，使聊天机器人从简单的对话工具转变为强大的生产力助手和研究辅助工具，这可能改变我们与AI交互和协作的方式。  <br />- Tool Use通过自然语言交互连接不同的应用程序和系统，实现了跨平台的自动化工作流程，这种方法简化了复杂任务的自动化过程，提高了效率。  <br />- Command-R在性能、效率和部署灵活性方面的平衡，使其成为构建基于Tool Use的AI应用的理想选择，这表明语言模型的应用不再局限于单一的云环境。  <br />- 简化的四步实施过程降低了企业采用Tool Use的门槛，有望加速其在实际业务场景中的应用，但企业仍需评估其具体需求和现有系统的兼容性。<br />《Introducing Tool Use With Command-R: Seamlessly Automate Business Workflows》 <a href="https://txt.cohere.com/tool-use-with-command-r/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnrc23fa5bj20v40l83zo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc23o7u5j20qo0f00ue.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:39:53 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;携手@博文视点Broadview 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00...</title>
<link>https://weibo.com/1402400261/O54zSFqzU</link>
<guid>https://weibo.com/1402400261/O54zSFqzU</guid>
<content:encoded><![CDATA[
<div> SPSSAU、数据分析、研究方法、应用、科研、快速入门、知识类、视频讲解、研究者、学习

总结:<br /><br />今天开奖活动欢迎大家参与，“可可粉”转发+评论即可参与赢取《SPSSAU科研数据分析方法与应用》这本书。该书系统介绍了科研数据分析方法，包括数据分析入门、常用研究方法应用、数据综合评价与预测、问卷数据分析、医学数据分析等五个方面，涵盖了13个知识类应用，同时还附赠了171集配套视频讲解。这本书适合研究者快速学习和掌握科研数据分析方法，近万篇研究论文选择SPSSAU作为快速入门工具。截止日期为2024年3月15日。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00，*可可粉*转发+评论即可参与。近万篇研究论文选用SPSSAU快速入门，本书从数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等五个方面系统地介绍科研数据的分析方法，涉及13项知识类应用（如影响关系、权重关系、数据预测、问卷研究）附赠171集配套视频讲解，适合研究者快速学习和掌握科研数据分析方法。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5009557898134749"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnj8n91y6bj20m80m8n19.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnj8n9h45kj20m80m8mzs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9rlbnj20m80m8tbk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9wj7pj20m80m80vr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:36:53 GMT</pubDate>
</item>
<item>
<title>今日推介(第1345期)：基于在线偏好优化的大型语言模型与人类偏好对齐、自注意力的下一token预测机制 、持续预训练大型语言模型的简单可扩展策略、现代大规模数据...</title>
<link>https://weibo.com/1402400261/O548I0b8m</link>
<guid>https://weibo.com/1402400261/O548I0b8m</guid>
<content:encoded><![CDATA[
<div> 在线偏好优化、大型语言模型、人类偏好对齐、自注意力、下一token预测机制、持续预训练、简单可扩展策略、现代大规模数据集、偏差问题、过训练语言模型

总结:<br />
本篇文章介绍了基于在线偏好优化的大型语言模型与人类偏好对齐的方法，通过自注意力的下一token预测机制实现了优化。同时提出了一种简单可扩展的持续预训练大型语言模型的策略，探讨了现代大规模数据集是否还存在偏差问题，并研究了过训练语言模型在下游任务中的可靠性扩展。这些研究对于优化大型语言模型的训练方法和应用具有重要意义。 <div>
今日推介(第1345期)：基于在线偏好优化的大型语言模型与人类偏好对齐、自注意力的下一token预测机制 、持续预训练大型语言模型的简单可扩展策略、现代大规模数据集是否还存在偏差问题、过训练语言模型在下游任务中的可靠扩展 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687109258"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.15)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra0zsf8qj20k00aawf0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra126v1dj20k008gjsd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnra15w1cdj20k00c3mzg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra1b1fw5j20k00hsad3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra1dmuy3j20k00e1q56.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:29:56 GMT</pubDate>
</item>
<item>
<title>[CV] DAM: Dynamic Adapter Merging for Continual Video QA Learning 网页链接 介绍了一种名为DAM的视频问答(VidQA)持续学习方法，以解决灾难性遗忘问题、适应...</title>
<link>https://weibo.com/1402400261/O544i5YCV</link>
<guid>https://weibo.com/1402400261/O544i5YCV</guid>
<content:encoded><![CDATA[
<div> 动态适配器合并, 持续学习, VidQA, 适配器训练, 路由器函数, 跨域知识共享, 性能优于当前方法, 图像分类, 图像问答

总结:<br /><br />
这篇文章介绍了一种名为DAM的视频问答持续学习方法，旨在解决灾难性遗忘、适应新数据集、处理未知数据集输入以及促进跨域知识共享等挑战。DAM通过动态适配器合并，在训练过程中训练特定数据集的适配器并冻结预训练的视频语言骨干网络。在推理过程中，利用非参数路由器函数计算适配器相关性概率，动态合并适配器权重定制新的适配器实例进行VidQA预测，从而降低路由器预测不准确的影响并提升跨域知识共享。DAM在多个VidQA数据集上的表现优于当前持续学习方法，并在图像分类和图像问答任务上也具有明显优势。 <div>
[CV] DAM: Dynamic Adapter Merging for Continual Video QA Learning  <br /><a href="https://arxiv.org/abs/2403.08755"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为DAM的视频问答(VidQA)持续学习方法，以解决灾难性遗忘问题、适应持续到来的数据集、处理未知数据集的输入以及跨相似数据集域共享知识等挑战。DAM通过动态适配器合并，训练特定数据集的适配器并冻结预训练的视频语言骨干网络。推理时，DAM使用非参数路由器函数计算每个适配器的相关性概率，随后动态合并适配器权重，以定制新的适配器实例进行VidQA预测，从而降低路由器预测不准确的影响并促进跨域知识共享。DAM在多个VidQA数据集上的性能超过了当前最先进的持续学习方法，并且在图像分类和图像问答任务上也展现出显著优势。<img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9q1w748j212s1lm4i4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9q2da9lj21pc0zitl9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9q2wsp9j21pa1b6nc5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:19:03 GMT</pubDate>
</item>
<item>
<title>[CV] GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting 网页链接 介绍了一种名为GaussianImage的新的图像表示和压缩方...</title>
<link>https://weibo.com/1402400261/O541SxwIU</link>
<guid>https://weibo.com/1402400261/O541SxwIU</guid>
<content:encoded><![CDATA[
<div> GaussianImage, 2D高斯Splatting, GPU资源, 隐式神经表示, INR, 渲染算法, GPU内存占用, 拟合时间, 渲染速度, 向量量化技术

总结:<br /><br />该文章介绍了一种名为GaussianImage的新的图像表示和压缩方法，基于2D高斯Splatting技术。与依赖GPU资源且训练时间长的隐式神经表示(INR)不同，GaussianImage通过每个2D高斯的8个参数来表示图像，使用累积求和的新渲染算法。这一方法显著减少了GPU内存占用和拟合时间，同时提供了与INR相当的表示性能和更快的渲染速度。该方法配合现有向量量化技术的编解码器在实验中表现出与基于压缩的INR（如COIN和COIN++）相当的速率失真性能，同时实现了约1000 FPS的解码速度。初步概念验证显示，在使用部分比特回传编码时，该编解码器的性能超过了COIN和COIN++。 <div>
[CV] GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting  <br /><a href="https://arxiv.org/abs/2403.08551"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为GaussianImage的新的图像表示和压缩方法，基于2D高斯Splatting技术。不同于依赖GPU资源且训练时间长的隐式神经表示(INR)，GaussianImage通过每个2D高斯的8个参数来表示图像，用累积求和的新渲染算法。这一方法显著减少了GPU内存占用(至少减少3倍)和拟合时间(加快5倍)，同时提供了与INR相当的表示性能和更快的渲染速度(1500-2000 FPS)。此外，集成了现有向量量化技术的图像编解码器在实验中展现出了与基于压缩的INR(如COIN和COIN++)相当的速率失真性能，并实现了约1000 FPS的解码速度。初步概念验证还表明，使用部分比特回传编码时，该编解码器的性能超过了COIN和COIN++。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9jwd3olj213i1kw18a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9jwqeu2j21hq0t0qay.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr9jwv8uyj21hc0gudmi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr9jx0572j21ha0mi7a8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:13:07 GMT</pubDate>
</item>
<item>
<title>[CL] Gemma: Open Models Based on Gemini Research and Technology 网页链接 介绍了Google DeepMind团队开发的Gemma模型，这是一组基于Gemini研究和技术构建的...</title>
<link>https://weibo.com/1402400261/O53Z1zK3Y</link>
<guid>https://weibo.com/1402400261/O53Z1zK3Y</guid>
<content:encoded><![CDATA[
<div> Google DeepMind, Gemma, Gemini, 轻量, 开放, 性能, 安全性, Transformer, TPUv5e, 负责任
<br />
<br />
总结: 
Google DeepMind团队开发了基于Gemini研究和技术的Gemma模型，是一组轻量、开放的最新模型。Gemma在语言理解、推理和安全性方面表现出强大性能，在18项文本任务中有11项超越同等规模的开放模型。该模型使用了基于Transformer的架构，优化了多查询注意力、RoPE嵌入、GeGLU激活函数和RMSNorm等技术，并使用TPUv5e硬件和分布式系统技术进行训练。发布了规模为20亿和70亿参数的两种模型，提供了预训练和微调检查点。强调了负责任发布大型语言模型对提升安全性、促进技术公平获取和驱动创新的重要性。对模型的安全性和负责任也进行了全面评估。 <div>
[CL] Gemma: Open Models Based on Gemini Research and Technology  <br /><a href="https://arxiv.org/abs/2403.08295"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了Google DeepMind团队开发的Gemma模型，这是一组基于Gemini研究和技术构建的轻量、开放的最新模型。Gemma在语言理解、推理和安全性方面在学术基准测试中展现出强大的性能。发布了两种规模的模型(20亿和70亿参数)，提供了预训练和微调的检查点。Gemma在18项文本任务中的11项上超越了同等规模的开放模型，并对模型的安全性和负责任进行了全面评估。Gemma利用了基于Transformer的架构，优化了多查询注意力、RoPE嵌入、GeGLU激活函数和RMSNorm等技术。训练使用了TPUv5e硬件和先进的分布式系统技术。强调了负责任发布大型语言模型(LLM)对于提升前沿模型安全性、促进技术公平获取、严格评估现有技术和驱动创新的重要性。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9ckrwzaj215e1ia7qg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9cl1imxj21ee0suwjs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9clc1n5j20p40n6adb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9clj4cfj20pc0ksgoa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:06:05 GMT</pubDate>
</item>
<item>
<title>创新地研究了在过训练情况下的语言模型扩展律，并建立了模型困惑度与其在下游任务表现之间的关联，提供了在减少计算成本的同时有效预测模型表现的方法，挑战了只...</title>
<link>https://weibo.com/1402400261/O53WGwMw8</link>
<guid>https://weibo.com/1402400261/O53WGwMw8</guid>
<content:encoded><![CDATA[
<div> 扩展律、语言模型、过训练、模型困惑度、下游任务、关联、计算成本、预测、模型表现、传统观点

<br /><br />总结：
该研究创新地研究了语言模型在过训练情况下的扩展律，并建立了模型困惑度与在下游任务表现之间的关联。提供了一种方法，在减少计算成本的同时有效预测模型表现，挑战了传统观点认为只有在计算最优训练阶段才能应用扩展律的观点。Researchers在此研究中展示了语言模型在过训练时表现稳定，并且其性能与下游任务的表现存在关联。他们的研究结果具有实践意义，可以帮助在研究领域中更有效地运用语言模型。 <div>
创新地研究了在过训练情况下的语言模型扩展律，并建立了模型困惑度与其在下游任务表现之间的关联，提供了在减少计算成本的同时有效预测模型表现的方法，挑战了只有在计算最优训练阶段才能应用扩展律的传统观点。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University &amp; UT Austin &amp; Apple] (2024) <a href="https://arxiv.org/abs/2403.08540"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96ao77pj21ga0qanai.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96b57p7j21my15caoy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96bitojj21n61167jj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96c1k8zj21mi0xo49l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyggij210z0ken19.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz8taj21120ir78f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gyotij21120lln0l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gz5nqj21170oktd1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz9y5j21110fkacs.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:00:19 GMT</pubDate>
</item>
<item>
<title>[CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University...</title>
<link>https://weibo.com/1402400261/O53WE06Ly</link>
<guid>https://weibo.com/1402400261/O53WE06Ly</guid>
<content:encoded><![CDATA[
<div> Language models, scale, over-training, downstream tasks, reliability, Columbia University, UT Austin, Apple

<br /><br />总结:
这篇文章研究了语言模型在超过训练规模以及在下游任务中的表现，发现语言模型在这些情况下能够可靠地扩展，通过在哥伦比亚大学、德克萨斯大学奥斯汀分校和苹果公司的合作进行了实验。他们的研究结果为语言模型的发展提供了有益的参考，为今后的研究和应用提供了新的思路。 <div>
[CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University &amp; UT Austin &amp; Apple] (2024) <a href="https://arxiv.org/abs/2403.08540"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96ao77pj21ga0qanai.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96b57p7j21my15caoy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96bitojj21n61167jj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96c1k8zj21mi0xo49l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyggij210z0ken19.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz8taj21120ir78f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gyotij21120lln0l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gz5nqj21170oktd1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz9y5j21110fkacs.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gypmlj210y0hg42h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96h0bszj210z0umjxf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gzuksj21120pbafd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gzkggj21110j1whm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gypocj21110j1who.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyc00j21120domzf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96h0emmj21131blqc1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:00:13 GMT</pubDate>
</item>
</channel>
</rss>