<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>爱可可-爱生活的微博</title>
<link>https://weibo.com/1402400261/</link>


<item>
<title>几篇论文实现代码：《CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets》(ICLR 2024) GitHub: github.com/lifan-yuan/CRAFT [fig...</title>
<link>https://weibo.com/1402400261/O5qIuBoo2</link>
<guid>https://weibo.com/1402400261/O5qIuBoo2</guid>
<content:encoded><![CDATA[
<div> 关键词：自定义LLM，专业工具集，知识获取，红队行动，好奇心驱动，执行反馈，活体动画控制器，3D人体恢复，立体匹配，目标检测，语言模型协作解码，视频理解，第一人称视角，不确定性规划，图像到3D转换，扩散模型，口头反馈学习，通用视觉转换器，多语言隐语言，智能工作任务解决，数据过滤，脆弱性攻击，闭环检测，实时生成，视频理解，数据初始化，目标跟踪，极长序列理解，代码评估，物体变化评估，偏好优化，模型增强，风格转移，建模。

总结：<br /><br />
1. 《CRAFT》介绍了通过创建和从专业工具集中检索个性化LLM的方法，提高了知识获取能力。<br />
2. 《Curiosity-driven Red Teaming for Large Language Models》探讨了通过好奇心驱动的方式进行网络攻击红队行动。<br />
3. 《Making Language Models Better Tool Learners with Execution Feedback》利用执行反馈提升语言模型的学习能力。<br />
4. 《PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios》介绍了一种用于驾驶场景的行人动画控制器。<br />
5. 《Score-Guided Diffusion for 3D Human Recovery》提出了一种评分引导的方法用于3D人体恢复。<br />
6. 《Robust Synthetic-to-Real Transfer for Stereo Matching》探讨了立体匹配中合成到真实数据的转移问题。<br />
7. 《Generative Region-Language Pretraining for Open-Ended Object Detection》介绍了用于目标检测的区域语言预训练方法。<br />
8. 《Learning to Decode Collaboratively with Multiple Language Models》讨论了多语言模型协作解码的学习方式。<br />
9. 《TempCompass: Do Video LLMs Really Understand Videos?》探究了视频理解中LLM的实际效果。<br />
10. 《Can Vision-Language Models Think from a First-Person Perspective?》研究了视觉语言模型是否具备第一人称视角思维。<br /> <div>
几篇论文实现代码：<br />《CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets》(ICLR 2024) GitHub: github.com/lifan-yuan/CRAFT [fig3]<br />《Curiosity-driven Red Teaming for Large Language Models》(ICLR 2024) GitHub: github.com/Improbable-AI/curiosity_redteam<br />《Making Language Models Better Tool Learners with Execution Feedback》(NAACL 2024) GitHub: github.com/zjunlp/TRICE [fig6]<br />《PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios》(CVPR 2024) GitHub: github.com/IDC-Flash/PacerPlus<br />《Score-Guided Diffusion for 3D Human Recovery》(CVPR 2024) GitHub: github.com/statho/ScoreHMR<br />《Robust Synthetic-to-Real Transfer for Stereo Matching》(CVPR 2024) GitHub: github.com/jiaw-z/DKT-Stereo<br />《Generative Region-Language Pretraining for Open-Ended Object Detection》(CVPR 2024) GitHub: github.com/FoundationVision/GenerateU<br />《Learning to Decode Collaboratively with Multiple Language Models》(2024) GitHub: github.com/clinicalml/co-llm<br />《TempCompass: Do Video LLMs Really Understand Videos?》(2024) GitHub: github.com/llyx97/TempCompass [fig1]<br />《Can Vision-Language Models Think from a First-Person Perspective?》(2024) GitHub: github.com/AdaCheng/EgoThink<br />《Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models》(2024) GitHub: github.com/zhiyuanhubj/UoT [fig2]<br />《Envision3D: One Image to 3D with Anchor Views Interpolation》(2024) GitHub: github.com/PKU-YuanGroup/Envision3D<br />《DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models》(2024) GitHub: github.com/sekstini/basedxl<br />《RLVF: Learning from Verbal Feedback without Overgeneralization》(2024) GitHub: github.com/austrian-code-wizard/c3po<br />《GiT: Towards Generalist Vision Transformer through Universal Language Interface》(2024) GitHub: github.com/Haiyang-W/GiT [fig7]<br />《Do Llamas Work in English? On the Latent Language of Multilingual Transformers》(2024) GitHub: github.com/epfl-dlab/llm-latent-language<br />《WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?》(2024) GitHub: github.com/ServiceNow/WorkArena<br />《Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning》(2024) GitHub: github.com/tianyi-lab/Superfiltering [fig4] <br />《COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability》(NeurIPS 2024) GitHub: github.com/Yu-Fangxu/COLD-Attack [fig5]<br />《Effectively Detecting Loop Closures using Point Cloud Density Maps》(2024) GitHub: github.com/PRBonn/MapClosures [fig8] <br />《StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control.》(2024) GitHub: github.com/ironjr/StreamMultiDiffusion<br />《Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding》(2024) GitHub: github.com/OpenGVLab/video-mamba-suite [fig9]<br />《Relaxing Accurate Initialization Constraint for 3D Gaussian Splatting》(2024) GitHub: github.com/KU-CVLAB/RAIN-GS<br />《VastTrack: Vast Category Visual Object Tracking》(2024) GitHub: github.com/HengLan/VastTrack<br />《InfLLM: Unveiling the Intrinsic Capacity of LLMs for Understanding Extremely Long Sequences with Training-Free Memory》(2024) GitHub: github.com/thunlp/InfLLM [fig10]<br />《LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code》(2024) GitHub: github.com/LiveCodeBench/LiveCodeBench<br />《ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes》(2024) GitHub: github.com/Muhammad-Huzaifaa/ObjectCompose [fig11]<br />《Reference-free Monolithic Preference Optimization with Odds Ratio》(2024) GitHub: github.com/xfactlab/orpo<br />《CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences》(2024) GitHub: github.com/martin-wey/CodeUltraFeedback <br />《DexCap: Scalable and Portable Mocap Data Collection System for Dexterous Manipulation》(2024) GitHub: github.com/j96w/DexCap<br />《Strengthening Multimodal Large Language Model with Bootstrapped Preference Optimization》(2024) GitHub: github.com/pipilurj/BPO<br />《Grimoire is All You Need for Enhancing Large Language Models》(2024) GitHub: github.com/IAAR-Shanghai/Grimoire<br />《FreeStyle: Free Lunch for Text-guided Style Transfer using Diffusion Models》(2024) GitHub: github.com/FreeStyleFreeLunch/FreeStyle<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1peo3wfj244e1plkjl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnu1pfjmrfj23qq0ukau1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnu1pg33q3j21480x6nb5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1pgtzc9j22c5276k96.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1ph7lzpj227u0ouqct.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1phyr60j23qt1z1tyo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnu1pijfg4j21qg0o6dsd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1pja928j21mj0kjdo2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnu1pjvqsmj22880ymdsk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnu1pkdxpdj21k20m40w9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnu1pkywzjj21gg0jw108.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:58:32 GMT</pubDate>
</item>
<item>
<title>【AI-in-a-Box：旨在帮助工程师建立人工智能和机器学习解决方案，并提供快速而高质量的解决方案，以减少架构师的成本和降低风险】'AI-in-a-Box' GitHub: github....</title>
<link>https://weibo.com/1402400261/O5qFqECzE</link>
<guid>https://weibo.com/1402400261/O5qFqECzE</guid>
<content:encoded><![CDATA[
<div> AI-in-a-Box、工程师、人工智能、机器学习、解决方案、快速、高质量、降低成本、降低风险

<br /><br />总结:
AI-in-a-Box是一个旨在帮助工程师建立人工智能和机器学习解决方案的工具。通过提供快速而高质量的解决方案，AI-in-a-Box可以降低架构师的成本，降低风险。工程师可以在GitHub上找到AI-in-a-Box的资源，帮助他们更有效地开发人工智能和机器学习项目。 <div>
【AI-in-a-Box：旨在帮助工程师建立人工智能和机器学习解决方案，并提供快速而高质量的解决方案，以减少架构师的成本和降低风险】'AI-in-a-Box' GitHub: github.com/Azure/AI-in-a-Box <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnu1hqwzepj20m80cd0uv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:50:59 GMT</pubDate>
</item>
<item>
<title>【ShareGPT Builder：一个功能强大的 Flask 应用，用于创建和存储 ChatGPT 模型的训练样本，允许手动创建和存储 SFT 格式的聊天对话，并自动将其添加到 JSON 文...</title>
<link>https://weibo.com/1402400261/O5qELjK5G</link>
<guid>https://weibo.com/1402400261/O5qELjK5G</guid>
<content:encoded><![CDATA[
<div> Flask 应用, ChatGPT 模型, 训练样本, SFT 格式, 聊天对话, JSON 文件, 模型训练, GitHub, 语言学习模型, 功能强大

总结:
这是一个功能强大的 Flask 应用程序，名为 ShareGPT Builder，提供训练语言学习模型（LLMs）的两个关键功能。它允许用户手动创建和存储 SFT 格式的聊天对话，自动将其添加到 JSON 文件中，以供其他模型访问。在 GitHub 上可找到该应用，链接为 github.com/teknium1/ShareGPT-Builder。 ShareGPT Builder不仅提供了创建和存储训练样本的功能，还支持模型训练的过程。 <div>
【ShareGPT Builder：一个功能强大的 Flask 应用，用于创建和存储 ChatGPT 模型的训练样本，允许手动创建和存储 SFT 格式的聊天对话，并自动将其添加到 JSON 文件中，以便其他模型可访问】'ShareGPT Builder - a versatile Flask application that provides two key functionalities for training Language Learning Models (LLMs)’ GitHub: github.com/teknium1/ShareGPT-Builder <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnu1g28ioyj20u00v0tc9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:49:20 GMT</pubDate>
</item>
<item>
<title>【视频生成相关研究列表】’A Collection of Video Generation Studies - A collection of awesome video generation studies.' GitHub: github.com/AlonzoLeeeo...</title>
<link>https://weibo.com/1402400261/O5qDRoorO</link>
<guid>https://weibo.com/1402400261/O5qDRoorO</guid>
<content:encoded><![CDATA[
<div> GitHub、视频生成、研究、收藏、视频、生成、研究、集合、研究、学习

<br /><br />总结:
该GitHub仓库收集了一系列关于视频生成的研究，涵盖了各种有趣的视频生成研究，为视频生成领域的学习提供了丰富的资源。研究内容包括视频的生成方法、技术应用以及相关算法等，为研究者们提供了广阔的研究方向。通过这些研究，可以深入了解视频生成的原理和方法，为视频生成技术的进一步发展提供了参考和借鉴。GitHub上的资源丰富多样，对视频生成领域的研究有很大的帮助。 <div>
【视频生成相关研究列表】’A Collection of Video Generation Studies - A collection of awesome video generation studies.' GitHub: github.com/AlonzoLeeeooo/awesome-video-generation <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu1deazrtj21fo0g4ad5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:47:07 GMT</pubDate>
</item>
<item>
<title>【MIMo：用于婴儿认知发展研究的开源平台，提供分析婴儿认知发育的关键数据和功能】'MIMo - a platform for the research of the cognitive development of infa...</title>
<link>https://weibo.com/1402400261/O5qDi0lSg</link>
<guid>https://weibo.com/1402400261/O5qDi0lSg</guid>
<content:encoded><![CDATA[
<div> 平台，婴儿，认知发展，研究，开源，数据，功能，分析，关键，GitHub

<br /><br />总结:
MIMo是一个用于研究婴儿认知发展的平台，提供关键数据和功能，开源且可用于分析婴儿认知发育。用户可以在GitHub上找到该平台的代码。MIMo是一个重要的工具，用于帮助研究人员深入研究婴儿认知发展的过程，并产生有价值的发现。 <div>
【MIMo：用于婴儿认知发展研究的开源平台，提供分析婴儿认知发育的关键数据和功能】'MIMo - a platform for the research of the cognitive development of infants' GitHub: github.com/trieschlab/MIMo <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu1c6ud7cj21bi0u0q89.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:45:42 GMT</pubDate>
</item>
<item>
<title>【Local RAG：一个开源项目，使用 开源大预言模型 (LLM) 提取文件并进行检索增强生成 (RAG)，无需第三方或敏感数据，在本地保持匿名】'Local RAG - Ingest files...</title>
<link>https://weibo.com/1402400261/O5qCu1PLb</link>
<guid>https://weibo.com/1402400261/O5qCu1PLb</guid>
<content:encoded><![CDATA[
<div> 开源项目、本地保持匿名、Local RAG、LLM、RAG、文件提取、检索增强生成、无需第三方、敏感数据保护、GitHub<br /><br />总结:
Local RAG是一个开源项目，使用开源大预言模型（LLM）来提取文件并进行检索增强生成（RAG），并且能够在本地网络中保持匿名。该项目无需第三方参与，能够有效保护敏感数据的安全。GitHub链接为github.com/jonfairbanks/local-rag。 <div>
【Local RAG：一个开源项目，使用 开源大预言模型 (LLM) 提取文件并进行检索增强生成 (RAG)，无需第三方或敏感数据，在本地保持匿名】'Local RAG - Ingest files for retrieval augmented generation (RAG) with open-source Large Language Models (LLMs), all without 3rd parties or sensitive data leaving your network.' GitHub: github.com/jonfairbanks/local-rag <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnu1a5h6fxj21g10u0q5e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:43:43 GMT</pubDate>
</item>
<item>
<title>【NeMo Curator：一个 Python 库，用于创建和处理自然语言处理 (NLP) 数据集，以便训练大型语言模型 (LLM)。该库包含一些可扩展的模块，允许 NLP 研究人员从无标...</title>
<link>https://weibo.com/1402400261/O5qAfojgc</link>
<guid>https://weibo.com/1402400261/O5qAfojgc</guid>
<content:encoded><![CDATA[
<div> Python、库、自然语言处理、数据集、语言模型、模块、Web采集、文本、GPU加速、高质量

<br /><br />总结:
NeMo Curator是一个Python库，旨在帮助自然语言处理研究人员创建和处理数据集，用于训练大型语言模型。该库包含可扩展的模块，允许从无标注Web采集高质量文本，并提供GPU加速功能。通过NeMo Curator，研究人员可以更轻松地获取并处理文本数据，提高训练效率和模型性能。 <div>
【NeMo Curator：一个 Python 库，用于创建和处理自然语言处理 (NLP) 数据集，以便训练大型语言模型 (LLM)。该库包含一些可扩展的模块，允许 NLP 研究人员从无标注 Web 采集高质量文本，并提供 GPU 加速功能】'NeMo Curator - Scalable toolkit for data curation' GitHub: github.com/NVIDIA/NeMo-Curator <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnu14hfnofj21ji0pgwln.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:38:13 GMT</pubDate>
</item>
<item>
<title>【超赞列表合集，从各类Awesome list项目抓取而来】“Awesome List” 网页链接 [图片]</title>
<link>https://weibo.com/1402400261/O5qwr6nHP</link>
<guid>https://weibo.com/1402400261/O5qwr6nHP</guid>
<content:encoded><![CDATA[
<div> Awesome List、项目、合集、抓取、资源、开发、技术、网站、GitHub、工具
<br />这篇文章是关于各类Awesome List项目的合集，内容涵盖了各种技术、开发资源，以及可在GitHub上找到的工具和网站。这些列表项目汇总了相关领域的优质资源，为开发者提供了丰富的参考和学习资料。从这些列表中可以获取各种有用的信息和工具，帮助开发者提升技能和解决问题。整理这些Awesome List的合集是为了让开发者更便捷地找到他们所需的资源和工具，提升开发效率和技术水平。
<br />总结: 这篇文章介绍了关于各类Awesome List项目的合集，涵盖了各种技术、开发资源和工具，为开发者提供了丰富的学习和参考资料。整理这些资源的目的是为了帮助开发者更便捷地获取他们所需的信息，提升技术水平。 <div>
【超赞列表合集，从各类Awesome list项目抓取而来】“Awesome List” <a href="https://asmen.icopy.site/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu0tfohbrj217q0om0xl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:28:49 GMT</pubDate>
</item>
<item>
<title>【BrowserGym: 用于 Web 任务自动化的开源项目，提供 Chrome 浏览器环境的 Gym 集成，用于自动化各种网站和应用的任务】’BrowserGym: a Gym Environment for We...</title>
<link>https://weibo.com/1402400261/O5qsp2NdU</link>
<guid>https://weibo.com/1402400261/O5qsp2NdU</guid>
<content:encoded><![CDATA[
<div> BrowserGym, Gym环境, Web任务自动化, 开源项目, Chrome浏览器, 自动化任务, 网站, 应用<br />
<br />
总结:<br />
BrowserGym是一个开源项目，提供了一个基于Chrome浏览器的Gym环境，用于自动化各种网站和应用的任务。用户可以通过BrowserGym在Chromium浏览器中进行Web任务自动化，提高效率并简化操作。这个项目在GitHub上有源代码，帮助用户更好地进行Web任务自动化。 <div>
【BrowserGym: 用于 Web 任务自动化的开源项目，提供 Chrome 浏览器环境的 Gym 集成，用于自动化各种网站和应用的任务】’BrowserGym: a Gym Environment for Web Task Automation - BrowserGym, a gym environment for web task automation in the Chromium browser.' GitHub: github.com/ServiceNow/BrowserGym <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnu0kdzmk6j20yy0u0gp3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:18:53 GMT</pubDate>
</item>
<item>
<title>【flybody是一个用于 MuJoCo 物理模拟和强化学习应用的果蝇模型，基于 Google DeepMind 和 HHMI Janelia 研究中心的相结合的作品，旨在建立果蝇体系生物物理模拟...</title>
<link>https://weibo.com/1402400261/O5qqjDbVj</link>
<guid>https://weibo.com/1402400261/O5qqjDbVj</guid>
<content:encoded><![CDATA[
<div> 果蝇模型, MuJoCo 物理模拟, 强化学习, Google DeepMind, HHMI Janelia, 生物物理模拟平台, GitHub, TuragaLab, reinforcement learning, 任务<br />
<br />
总结:<br />
该项目将果蝇模型应用于 MuJoCo 物理模拟和强化学习任务，结合了 Google DeepMind 和 HHMI Janelia 的研究成果，旨在建立果蝇体系生物物理模拟平台。该项目的代码存储在 GitHub 上的 TuragaLab/flybody 项目中。通过这个模型，研究人员可以在仿真环境中进行果蝇的生物物理模拟和强化学习，为研究果蝇行为和神经系统提供了新的工具和资源。 <div>
【flybody是一个用于 MuJoCo 物理模拟和强化学习应用的果蝇模型，基于 Google DeepMind 和 HHMI Janelia 研究中心的相结合的作品，旨在建立果蝇体系生物物理模拟平台】'flybody: fruit fly body model for MuJoCo physics - MuJoCo fruit fly body model and reinforcement learning tasks' GitHub: github.com/TuragaLab/flybody <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu0elerekj219u0u00y4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:13:44 GMT</pubDate>
</item>
<item>
<title>【Magix 是一个用于训练大规模语言模型的轻量工具，具有灵活的数据和模型平行功能】'Magix - Supercharge huggingface transformers with model parallelism.' G...</title>
<link>https://weibo.com/1402400261/O5q959sOY</link>
<guid>https://weibo.com/1402400261/O5q959sOY</guid>
<content:encoded><![CDATA[
<div> Magix, huggingface, transformers, model parallelism, GitHub, 训练大规模语言模型, 轻量工具, 灵活的数据, 模型平行功能

<br /><br />总结:
Magix 是一个用于训练大规模语言模型的轻量工具，能够有效地利用模型并行性，并具有灵活的数据和模型平行功能。通过 Magix，用户可以在 GitHub 上找到支持 model parallelism 的 huggingface transformers。Magix 的出现为训练大规模语言模型提供了更加高效和灵活的选择。 <div>
【Magix 是一个用于训练大规模语言模型的轻量工具，具有灵活的数据和模型平行功能】'Magix - Supercharge huggingface transformers with model parallelism.' GitHub: github.com/luyug/magix <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntz6t5nagj21e00pqjvg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 06:31:17 GMT</pubDate>
</item>
<item>
<title>【ArXiv Paper Reader：旨在简化和流利的arXiv论文阅读，使用 LaTeX 代码转换为 HTML 页面，然后提取文本和公式，将其转换为视频，并创建与 PDF 文档匹配的图，...</title>
<link>https://weibo.com/1402400261/O5q2nDkz5</link>
<guid>https://weibo.com/1402400261/O5q2nDkz5</guid>
<content:encoded><![CDATA[
<div> 简化、流利、arXiv论文、LaTeX代码、HTML页面、提取文本、公式、视频、PDF文档、图像<br />
<br />
提供了一个名为ArXiv Paper Reader的工具，旨在简化和流利地阅读arXiv论文。该工具首先将LaTeX代码转换为HTML页面，然后提取文本、公式，并将其转换为视频。接着创建与PDF文档匹配的图像，并将文本分段并转换为音频。通过这种方式，用户可以更方便地理解和阅读arXiv论文，提高阅读效率。总的来说，这个工具为阅读arXiv论文提供了更加便捷的方式，使得用户可以更加愉快地进行学术阅读。<br /><br />总结: <div>
【ArXiv Paper Reader：旨在简化和流利的arXiv论文阅读，使用 LaTeX 代码转换为 HTML 页面，然后提取文本和公式，将其转换为视频，并创建与 PDF 文档匹配的图，以及文本分段并将其转换为音频】'ArXiv Paper Reader - Code behind Arxiv Papers' GitHub: github.com/imelnyk/ArxivPapers <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntypo9wd3j221b0u0n1i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 06:14:47 GMT</pubDate>
</item>
<item>
<title>【Skyvern 利用 LLM 和计算机视觉，自动化浏览器基础工作流。它提供一个简洁的 API 端点，允许完全自动化手动工作流，取代难以维护或易于故障的自动化解决方案】...</title>
<link>https://weibo.com/1402400261/O5pYY8wLP</link>
<guid>https://weibo.com/1402400261/O5pYY8wLP</guid>
<content:encoded><![CDATA[
<div> LLMs, 计算机视觉, 自动化, 浏览器, API, 手动工作流, 维护, 故障, 解决方案, GitHub<br /><br />总结: Skyvern利用LLM和计算机视觉技术，自动化浏览器基础工作流。其提供了一个简洁的API端点，允许完全自动化手动工作流，取代难以维护或易于故障的自动化解决方案。该项目的GitHub链接为github.com/Skyvern-AI/skyvern。 <div>
【Skyvern 利用 LLM 和计算机视觉，自动化浏览器基础工作流。它提供一个简洁的 API 端点，允许完全自动化手动工作流，取代难以维护或易于故障的自动化解决方案】'Skyvern - Automate browser-based workflows with LLMs and Computer Vision' GitHub: github.com/Skyvern-AI/skyvern <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntygovm8aj213t0u0wgj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 06:06:22 GMT</pubDate>
</item>
<item>
<title>【Pretzel是一个开源，在线浏览器式数据探索和可视化的工具，提供快速便捷的数据分析和可视化功能。它无需后台设置，可在浏览器中实时运行，无需任何服务器连接...</title>
<link>https://weibo.com/1402400261/O5pPCFNVf</link>
<guid>https://weibo.com/1402400261/O5pPCFNVf</guid>
<content:encoded><![CDATA[
<div> Pretzel, 开源, 在线浏览器, 数据探索, 可视化, 数据分析, 数据变换, 实时更新, DuckDB-Wasm, PRQL

<br /><br />总结:
Pretzel是一个开源的在线浏览器式数据探索和可视化工具，无需后台设置，可实时在浏览器中运行，提供快速便捷的数据分析和可视化功能。用户可以通过视觉化的数据变换区块轻松操控数据，并实时更新所有与变换区块和图表相关的内容，使用了DuckDB-Wasm和PRQL技术。 <div>
【Pretzel是一个开源，在线浏览器式数据探索和可视化的工具，提供快速便捷的数据分析和可视化功能。它无需后台设置，可在浏览器中实时运行，无需任何服务器连接。Pretzel通过视觉化的数据变换区块轻松操控数据，并实时更新所有与变换区块和图表相关的区块和图表】'Pretzel - Open-source, browser-local data exploration using DuckDB-Wasm and PRQL' GitHub: github.com/pretzelai/pretzelai <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntxt0cgs0j21bz0u0qa8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:43:21 GMT</pubDate>
</item>
<item>
<title>【扩散蒸馏相关论文资源列表】’Awesome-Diffusion-Distillation - A list of papers, docs, codes about diffusion distillation.This repo collects various d...</title>
<link>https://weibo.com/1402400261/O5pF46IZu</link>
<guid>https://weibo.com/1402400261/O5pF46IZu</guid>
<content:encoded><![CDATA[
<div> GitHub, papers, docs, codes, diffusion distillation, distillation methods<br />
<br />
总结：<br />
这个GitHub仓库收集了关于扩散模型的各种蒸馏方法，欢迎贡献未被收录的相关作品（论文、代码库）。扩散蒸馏是一个重要的研究领域，通过这个仓库可以找到多种不同的蒸馏方法和资源。希望这个仓库可以帮助研究人员更好地了解和应用扩散蒸馏技术。 <div>
【扩散蒸馏相关论文资源列表】’Awesome-Diffusion-Distillation - A list of papers, docs, codes about diffusion distillation.This repo collects various distillation methods for the Diffusion model. Welcome to PR the works (papers, repositories) missed by the repo.' GitHub: github.com/cantbebetter2/Awesome-Diffusion-Distillation <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntwv7uq2gj20u80u0wj8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:17:19 GMT</pubDate>
</item>
<item>
<title>【Recommender AI Agent: 使用大语言模型提供交互式推荐功能的agent】’Recommender AI Agent: Integrating Large Language Models for Interactive Recommendat...</title>
<link>https://weibo.com/1402400261/O5pAps9gS</link>
<guid>https://weibo.com/1402400261/O5pAps9gS</guid>
<content:encoded><![CDATA[
<div> 关键词: Recommender AI Agent, 大语言模型, 交互式推荐, GitHub, Microsoft

总结:<br /><br />
这篇文章介绍了一个名为'Recommender AI Agent'的项目，该项目利用大语言模型来提供交互式推荐功能。通过GitHub上的链接github.com/microsoft/RecAI 可以找到该项目的代码和资源。这个项目的目标是整合大语言模型，通过与用户的交互，为他们提供更加个性化的推荐服务。这种推荐代理的技术可以被应用到各种领域，帮助用户更快地找到他们感兴趣的内容。Microsoft是这个项目的背后支持者，展示了他们在人工智能和数据科学领域的实力和创新能力。通过这种新型推荐技术，用户可以享受到更加智能化和高效的推荐体验，提升用户体验和满意度。 <div>
【Recommender AI Agent: 使用大语言模型提供交互式推荐功能的agent】’Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations' GitHub: github.com/microsoft/RecAI <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntwpyjejsj21b70glgp4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:05:52 GMT</pubDate>
</item>
<item>
<title>'Campus2025 - 2025届互联网校招信息汇总' GitHub: github.com/NAOSI-DLUT/Campus2025 #开源# #校招# [图片]</title>
<link>https://weibo.com/1402400261/O5pyCbZZ7</link>
<guid>https://weibo.com/1402400261/O5pyCbZZ7</guid>
<content:encoded><![CDATA[
<div> GitHub, Campus2025, 2025届, 互联网, 校招, 信息, 汇总

<br /><br />总结:
GitHub上有一个名为Campus2025的项目，汇总了2025届互联网校园招聘的信息。这个项目提供了一个集中查找各种互联网公司校招信息的平台，帮助学生更方便地了解招聘信息和机会。对于即将步入社会的2025届学生来说，这个项目提供了一个很好的资源，可以帮助他们更好地规划自己的职业发展方向。通过这个项目，学生可以及时了解各个互联网公司的招聘信息，选择最适合自己的发展方向和机会。整合了各种互联网公司的招聘信息，让学生可以更方便地比较和选择自己感兴趣的企业和岗位。建议2025届的学生多关注这个项目，及时了解就业信息，为自己的职业发展做好准备。 <div>
'Campus2025 - 2025届互联网校招信息汇总' GitHub: github.com/NAOSI-DLUT/Campus2025 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%A0%A1%E6%8B%9B%23&amp;isnewpage=1"><span class="surl-text">#校招#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntwle8h77j20un0u00wu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:01:27 GMT</pubDate>
</item>
<item>
<title>【大模型数据增强相关文献资源列表】’Papers and resources on data augmentation using large models - The official GitHub page for the survey paper "A Su...</title>
<link>https://weibo.com/1402400261/O5pxswqTp</link>
<guid>https://weibo.com/1402400261/O5pxswqTp</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据增强, 大模型, 调查论文, GitHub, 资源, 机器学习, 深度学习

总结:<br /><br />
这篇文章是关于在大模型时代中使用数据增强的调查论文。GitHub上有一份关于数据增强的官方调查论文页面，提供了大模型数据增强相关的论文和资源列表。该调查论文涵盖了数据增强在机器学习和深度学习中的应用，以及大模型时代如何利用数据增强来提升模型性能。通过研究论文和资源，我们可以更好地了解数据增强在大模型领域的应用和重要性，为我们在实践中更好地利用数据增强提供了指导和参考。 <div>
【大模型数据增强相关文献资源列表】’Papers and resources on data augmentation using large models - The official GitHub page for the survey paper "A Survey on Data Augmentation in Large Model Era"' GitHub: github.com/MLGroup-JLU/LLM-data-aug-survey <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntwi7n59vj210s0u0jxn.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntwidk0cgj21480u0jwj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:58:36 GMT</pubDate>
</item>
<item>
<title>【DRL-Based Trajectory Tracking (DRLTT) 是一个用于自动驾驶轨迹跟踪的开源项目，它结合深度强化学习(DRL)技术，并具有高效性和准确性的功能，可用于轨迹跟踪...</title>
<link>https://weibo.com/1402400261/O5pshzWGg</link>
<guid>https://weibo.com/1402400261/O5pshzWGg</guid>
<content:encoded><![CDATA[
<div> GitHub, DRL-Based Trajectory Tracking, 深度强化学习, 轨迹跟踪, 自动驾驶, 开源项目, 高效性, 准确性, 任务

<br /><br />总结:
DRL-Based Trajectory Tracking (DRLTT) 是一个开源项目，采用深度强化学习技术，旨在实现自动驾驶轨迹跟踪任务。该项目结合了高效性和准确性的特点，提供了一个有效的解决方案。通过 GitHub 平台展示和分享，用户可以了解和参与该项目，促进自动驾驶技术的发展。 <div>
【DRL-Based Trajectory Tracking (DRLTT) 是一个用于自动驾驶轨迹跟踪的开源项目，它结合深度强化学习(DRL)技术，并具有高效性和准确性的功能，可用于轨迹跟踪任务】'DRL-Based Trajectory Tracking (DRLTT) - DRL-based trajectory tracking.' GitHub: github.com/MARMOTatZJU/drl-based-trajectory-tracking <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntw56a5v2j215e0u079l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:45:51 GMT</pubDate>
</item>
<item>
<title>【Cpptrace：一个简洁、可移植和自建的 C++ stacktracker 库，支持 C++11 及更高版本的 Linux、macOS 和 Windows 运行环境，包括 MinGW 和 Cygwingwin。其目的是...</title>
<link>https://weibo.com/1402400261/O5prI8BI3</link>
<guid>https://weibo.com/1402400261/O5prI8BI3</guid>
<content:encoded><![CDATA[
<div> 简洁 可移植 自建 C++ stacktracker 库 C++11 Linux macOS Windows MinGW Cygwinwin<br />
<br />总结:<br />Cpptrace是一个简洁、可移植和自建的 C++ stacktracker 库，支持C++11及更高版本，在Linux、macOS和Windows运行环境下可使用，包括MinGW和Cygwingwin。它的目的是简化堆栈追踪，使其变得更容易。Cpptrace库的GitHub地址为github.com/jeremy-rifkin/cpptrace。 <div>
【Cpptrace：一个简洁、可移植和自建的 C++ stacktracker 库，支持 C++11 及更高版本的 Linux、macOS 和 Windows 运行环境，包括 MinGW 和 Cygwingwin。其目的是简化堆栈追踪，使其变得更容易】'Cpptrace - Simple, portable, and self-contained stacktrace library for C++11 and newer' GitHub: github.com/jeremy-rifkin/cpptrace <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23C%2B%2B%23"><span class="surl-text">#C++#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntw3ow5brj20xc0u0tce.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:44:26 GMT</pubDate>
</item>
<item>
<title>'Transformers 库快速入门教程' GitHub: github.com/jsksxs360/How-to-use-Transformers #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5pcFy2Gb</link>
<guid>https://weibo.com/1402400261/O5pcFy2Gb</guid>
<content:encoded><![CDATA[
<div> Transformers, 库, 快速, 入门, 教程, GitHub, 使用, 教程, 详细

<br /><br />总结: 该GitHub仓库提供了一个关于如何快速入门使用Transformers库的教程，详细介绍了如何利用这个功能强大的库来进行自然语言处理和其他机器学习任务。通过阅读这篇教程，你能够了解Transformers库的基本功能和使用方法，帮助你更快地上手并应用于实际项目中。如果你对自然语言处理或机器学习感兴趣，不妨花一些时间学习这篇教程，会受益匪浅。 <div>
'Transformers 库快速入门教程' GitHub: github.com/jsksxs360/How-to-use-Transformers <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntv14tvcoj21ii0u042p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:07:23 GMT</pubDate>
</item>
<item>
<title>【Flux 是一个 C++20 库，提供一系列用于序列处理的算法和适配器，类似于 C++20 ranges、Python itertools 和 Rust iterators】'Flux - A C++20 library for seq...</title>
<link>https://weibo.com/1402400261/O5p6WDJDd</link>
<guid>https://weibo.com/1402400261/O5p6WDJDd</guid>
<content:encoded><![CDATA[
<div> C++20, 库, Flux, 序列处理, 算法, 适配器, ranges, Python itertools, Rust iterators  
<br /><br />总结:  
Flux 是一个 C++20 库，提供一系列用于序列处理的算法和适配器，类似于 C++20 ranges、Python itertools 和 Rust iterators。这个库可以让开发者更加方便地处理序列数据，提供了丰富的功能和工具。通过 Flux，开发者可以更高效地进行序列处理，实现更加复杂和灵活的操作。它为 C++ 程序员提供了一种简洁而强大的方式来处理序列数据，帮助他们提高代码的可读性和性能。Flux 库的开发者在 GitHub 上持续维护和更新，为广大开发者提供了一个优秀的序列处理工具。 <div>
【Flux 是一个 C++20 库，提供一系列用于序列处理的算法和适配器，类似于 C++20 ranges、Python itertools 和 Rust iterators】'Flux - A C++20 library for sequence-orientated programming' GitHub: github.com/tcbrindle/flux <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntumcqwwaj21ji0puq7x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 03:53:17 GMT</pubDate>
</item>
<item>
<title>【StyleTTS 2: 可通过pip安装的Python包，用于实现人类水平的文本转语音和语音克隆】'StyleTTS 2: The Python Package - Pip installable package for StyleTTS ...</title>
<link>https://weibo.com/1402400261/O5oQCmWh7</link>
<guid>https://weibo.com/1402400261/O5oQCmWh7</guid>
<content:encoded><![CDATA[
<div> StyleTTS 2, Python包, pip安装, 文本转语音, 语音克隆, GitHub, sidharthrajaram, 人类水平, 实现, 

总结:<br /><br />
这篇文章介绍了StyleTTS 2，一个Python包，可以通过pip安装，用于实现人类水平的文本转语音和语音克隆。该包提供了一种简单而有效的方法来实现高质量的语音合成和克隆，让用户能够快速轻松地创建自然流畅的语音内容。GitHub上有相关资源和文档，使用户可以更方便地了解和使用这个工具。如果你想要实现人类水平的文本转语音和语音克隆，不妨尝试使用StyleTTS 2这一方便易用的工具。 <div>
【StyleTTS 2: 可通过pip安装的Python包，用于实现人类水平的文本转语音和语音克隆】'StyleTTS 2: The Python Package - Pip installable package for StyleTTS 2 human-level text-to-speech and voice cloning' GitHub: github.com/sidharthrajaram/StyleTTS2 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnttgd54x5j21ki0gu41j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 03:13:03 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模...</title>
<link>https://weibo.com/1402400261/O5oJlsK39</link>
<guid>https://weibo.com/1402400261/O5oJlsK39</guid>
<content:encoded><![CDATA[
<div> 度小满、大语言模型、杨青、全彩印刷、实践性、知识体系、训练经验、干货满满、系统性、神秘面纱

总结:<br /><br />本书《大语言模型：原理与工程实践(全彩)》由度小满的杨青负责编写，深入解读大语言模型的内在机理和应用实践。书籍的特色在于系统性的知识体系和对实践性的重视，配有代码并采用全彩印刷，内容充实且实用。作者作为大语言模型实践者，分享了他在十亿、百亿、千亿参数规模大语言模型训练方面的丰富经验，这些经验都被真诚而详尽地呈现在书中。通过本书，读者能够全面了解大语言模型的运作原理和实际应用，深入学习大模型的构建和训练方法，是一本值得一读的权威指南。 <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 02:55:08 GMT</pubDate>
</item>
<item>
<title>【对开源AI工具的观察总结】数据来源:- 通过GitHub搜索GPT、LLM和generative ai等关键词,结果分别为118K、590个、531个和38个。- 限定stars大于500的仓库,最终获...</title>
<link>https://weibo.com/1402400261/O5o4KnaXm</link>
<guid>https://weibo.com/1402400261/O5o4KnaXm</guid>
<content:encoded><![CDATA[
<div> GPT、LLM、generative ai、GitHub、技术栈、趋势、开发者、中国开源、短命项目、点子 <br />
<br />
总结：<br />
通过GitHub搜索了GPT、LLM和generative ai等关键词，共筛选出845个stars大于500的开源AI工具。AI技术栈分为基础设施层、模型开发层、应用开发层和应用层。2023年预计应用和应用开发层将迎来快速增长，特别是提示工程、人机界面和推理优化等领域。开发者中有20个账号贡献了23%的项目，80%为组织账号，个人账号如lucidrains也积极贡献了许多项目。中国开源生态活跃在GitHub上，有不少针对中文用户的工具和模型。许多项目虽然发展迅速但很快衰退，但对社区仍有一定价值。作者对批量推理优化、更快的解码器、模型融合和受约束采样等点子颇感兴趣，认为专注解决一个问题的项目也非常有价值。 <div>
【对开源AI工具的观察总结】<br />数据来源:<br />- 通过GitHub搜索GPT、LLM和generative ai等关键词,结果分别为118K、590个、531个和38个。<br />- 限定stars大于500的仓库,最终获得了845个软件仓库。<br />- 51个是教程和汇总列表,794个是软件项目。<br /><br />AI技术栈:<br />- 基础设施层:模型部署、计算管理、向量搜索数据库等。<br />- 模型开发层:框架、推理优化、数据集、评估等。<br />- 应用开发层:提示工程、人机界面、Agent、AIE框架等。 <br />- 应用层:编码、聊天机器人、信息聚合等。<br /><br />变化趋势:<br />- 2023年应用和应用开发层增长迅速。基础设施层变化不大。<br />- 提示工程、人机界面、推理优化最热门。<br /><br />开发者分布:<br />- 20个账号贡献了23%的项目,80%是组织账号。<br />- 个人账号如lucidrains等也贡献了很多项目,尤其是应用层。<br />- 超过2万开发者贡献了近100万次commit。<br /><br />中国开源生态:<br />- 中文社区也活跃在GitHub上,有针对中文及中英混合的模型。<br />- 也有面向中文用户的工具和模型应用。<br /><br />短命项目:<br />- 许多项目快速发展后也快速衰退,但对社区仍有价值。<br /><br />个人最喜欢的点子:<br />- 批量推理优化、更快的解码器、模型融合、受约束采样等。<br />- 专注解决一个问题的项目也很有价值。<br /><br />《What I learned from looking at 900 most popular open source AI tools》 <a href="https://huyenchip.com//2024/03/14/ai-oss.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntq1dgmbnj20xa0u0gqa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntq1h4v66j21jj0kagq0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1iybm0j21hb0u0gp7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntq1jt6qbj20y40t83zz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntq1lnbjkj21jj0kj79q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1p6tj6j21jj0tywh4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntq1rc7nej21760t6mzr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1s9iy7j21530u0tbb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1u96xqj21ex0u0gnq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 01:15:07 GMT</pubDate>
</item>
<item>
<title>【Deepfakes：从数字现实到虚假现实】1. 深度伪造(Deepfakes)利用先进的人工智能技术,生成逼真的虚假图像、视频和音频。 - 利用游戏引擎(如Unreal Engine 5)模拟...</title>
<link>https://weibo.com/1402400261/O5nUy4lA5</link>
<guid>https://weibo.com/1402400261/O5nUy4lA5</guid>
<content:encoded><![CDATA[
<div> 深度伪造 技术 人工智能 欺骗性质 安全隐患 伦理问题 检测防御 深思 认知 

总结:<br /><br />这篇文章介绍了深度伪造技术利用人工智能生成逼真虚假图像、视频和音频的现状，以及其潜在的伦理和安全隐患，引起了人们的深刻思考。技术能够精确模仿人物特征，但也可能被滥用用于制造虚假信息和诽谤。一些公司和研究人员正在研发新技术用于检测和防御深度伪造，但是人们对于是否应该限制或禁止这种技术的发展看法不一。文章唤起人们对于技术快速发展下如何保持理性和警惕的思考。 <div>
【Deepfakes：从数字现实到虚假现实】<br />1. 深度伪造(Deepfakes)利用先进的人工智能技术,生成逼真的虚假图像、视频和音频。<br />   - 利用游戏引擎(如Unreal Engine 5)模拟细致的光线和物理效果,创造出逼真的数字场景。<br />   - 使用生成对抗网络(GAN)等生成AI模型(如DeepMind的Sora),根据文本提示生成逼真的视频。<br />2. 深度伪造技术能够精确模仿人物的脸部特征、表情、声音和动作细节。<br />3. 虽然深度伪造在游戏、娱乐等领域具有创意应用潜力,但其欺骗性质也引发了严重的伦理和安全隐患。<br />   - 可能被滥用于制造虚假信息、诽谤等违法行为。<br />4. 一些公司和研究人员正在开发新技术,以检测和防御深度伪造。<br />5. 深度伪造技术的发展将继续模糊数字与现实世界的界限,引发人们对"真实"的重新思考。<br /><br />点评:<br />1. 文章揭示了深度伪造技术的发展现状和潜在风险,引发读者对技术伦理的深思。<br />2. 深度伪造不仅挑战了人们对"真实"的认知,也可能对社会造成严重的不实信息危害。<br />3. 一些读者质疑,是否应该限制或禁止这种技术的发展,以防被滥用。<br />4. 另一种观点认为,深度伪造只是一种工具,关键在于如何正确使用和管控。<br />5. 文章启发人们思考,在技术快速发展的今天,我们如何保持理性和警惕。<br /><br />《Deepfakes: From Digital Reality to Fake Reality | Datafloq》 <a href="https://datafloq.com/read/deepfakes-digital-reality-fake-reality/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntpbqv5atj213j0u0n3d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:49:59 GMT</pubDate>
</item>
<item>
<title>【大型语言模型(LLM)文本生成的理论速度极限】- LLM文本生成是一个按词(token)顺序进行的过程，当前词生成时依赖之前的所有词的状态，不存在并行的可能。 - LLM...</title>
<link>https://weibo.com/1402400261/O5nRLvdhX</link>
<guid>https://weibo.com/1402400261/O5nRLvdhX</guid>
<content:encoded><![CDATA[
<div> LLM 文本生成、速度极限、矩阵向量乘法、注意力计算、内存带宽限制、Mistral 7B模型、RTX 4090、理论速度极限分析、性能优化、推理性能

总结：<br /><br />本文从理论角度分析了LLM推理速度的极限，提出了计算最大FLOPS利用率和最小延迟时间的方法，为推理性能的衡量和优化提供了新思路。同时指出了影响实际推理速度的多个因素，启示我们在性能优化时需要全面考虑，不仅局限于计算本身。虽然理论极限难以达到，但仍是一个有意义的目标。文章专业性强，但对理解LLM推理性能优化具有重要指导意义。 <div>
【大型语言模型(LLM)文本生成的理论速度极限】<br />- LLM文本生成是一个按词(token)顺序进行的过程，当前词生成时依赖之前的所有词的状态，不存在并行的可能。   <br />- LLM主要包含两个运算：矩阵向量乘法和注意力计算，这两种运算都只需要对每个元素进行很少的浮点运算。   <br />- 现代CPU和GPU的算术运算速度远高于内存读取速度。因此LLM生成这类只需要对每个元素做少量运算的任务，其速度主要受内存带宽限制。   <br />- 以Mistral 7B模型为例，矩阵中的参数数量约为71亿，使用FP16时需要读取14.2GB数据。在RTX 4090(1008GB/s带宽)上理论最小生成时间是14.1ms/词。   <br />- 对比不同架构的实际速度与理论速度极限，可以评估软硬件实现的效率，并给进一步优化提供指导。   <br />- 矩阵向量乘法易受内存带宽限制，而注意力计算对内存大小也有严重影响。使用分组查询注意力(GQA)可以大幅减少注意力计算的内存需求。   <br />- 对于单用户单请求场景，理论速度极限是一个常数，可用于跨模型和设备评估预期性能，但多用户并发请求时，情况会改变。   <br />- 理论速度极限分析对于理解和优化LLM生成性能至关重要。<br /><br />点评：  <br />- 文章从理论角度分析了LLM推理速度的极限，这一视角有别于一般的性能优化讨论，具有独到之处。  <br />- 作者提出了计算理论最大FLOPS利用率和最小延迟时间的方法，为衡量和优化推理性能提供了新的思路。  <br />- 文章指出了影响实际推理速度的诸多因素，这启示我们在性能优化时需要全面考虑，而不仅仅局限于计算本身。  <br />- 尽管理论极限难以达到，但作者认为它仍然是一个有意义的目标，这一观点值得深思。  <br />- 文章虽然专业性强，但对于理解LLM推理性能优化具有重要指导意义。<br /><br />《zeux.io - LLM inference speed of light》 <a href="https://zeux.io/2024/03/15/llm-inference-sol/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntp4m8oolj20u00ubtek.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:43:08 GMT</pubDate>
</item>
<item>
<title>【整数标记化(tokenization)：语言模型数字处理的”bug"?】- GPT模型的整数标记化(tokenize)方式存在很大问题，这让模型学习数学知识和表示数学事实变得非常困难...</title>
<link>https://weibo.com/1402400261/O5nMx2bXx</link>
<guid>https://weibo.com/1402400261/O5nMx2bXx</guid>
<content:encoded><![CDATA[
<div> 整数标记化, 语言模型, GPT模型, 十进制系统, 数学知识, 数学运算, 数字处理, 算法, 问题

<br /><br />总结: 
作者对GPT模型的整数标记化方式存在的问题提出了质疑，表示现有方法可能影响模型对数学知识的学习和运用。理想的数字系统应该遵循十进制系统，对0-9的整数使用唯一的token，而更大的整数则用这些token的组合表示。然而，GPT在处理整数时为大量整数分配了独立的token，导致模型无法应用通用数学运算算法，只能依赖记忆特殊情况出现的结果。这种不一致的整数分块标记化方式影响了模型的推理能力，对其理解和应用数学运算与算法的提高具有重要意义。整数tokenize的改进是关键所在，有望让GPT模型在数学能力上取得进步。 <div>
【整数标记化(tokenization)：语言模型数字处理的”bug"?】<br />- GPT模型的整数标记化(tokenize)方式存在很大问题，这让模型学习数学知识和表示数学事实变得非常困难。   <br />- 理想的数字系统应该对0-9的整数使用唯一的token，而更大的整数则用这些token的组合表示，以体现十进制系统。   <br />- 但GPT的tokenize方式并未遵循十进制系统，而是为大量整数独立分配了唯一的token。这导致模型无法应用通用的数学运算算法，只能依赖大量模式匹配记忆。   <br />- 不仅小整数受影响，在较大的整数中也存在大量独立token的情况，这同样导致了无法应用通用算法的问题。   <br />- 即使在非独立token的整数中，分割整数的方式也不一致，导致模型同样无法应用统一的运算逻辑。   <br />- 这让模型进行数字运算时必须记忆大量特殊情况下的结果，而非应用通用算法，增加了学习和推理的难度。   <br />- 整数tokenize的这些问题说明，GPT模型距离真正理解和应用数学运算与算法还有很长的路要走。tokenize方式的改进是模型在数学能力上提高的关键。<br /><br />点评:<br />1. 作者对现有的整数标记化方法提出质疑,认为其存在不合理之处。<br />2. 揭示了语言模型在处理数字时的特殊机制可能影响模型对数字的理解和运算能力。<br />3. 举例说明了整数分块标记化的不一致性,这一发现对优化语言模型的数字处理方式具有启发意义。<br /><br />《Integer tokenization is insane》 <a href="https://www.beren.io/2023-02-04-Integer-tokenization-is-insane/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntor0oe8lj20hs0dcwet.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntor291rsj20hs0dcgn3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:30:14 GMT</pubDate>
</item>
<item>
<title>【开源路上，别让心理健康成了绊脚石】1. 开源维护者面临的心理健康挑战: - 工作与生活平衡 - 来自社区的期望和压力 - 个人对完美的追求2. 作者的应对方式: - 放...</title>
<link>https://weibo.com/1402400261/O5nGUCOBu</link>
<guid>https://weibo.com/1402400261/O5nGUCOBu</guid>
<content:encoded><![CDATA[
<div> 心理健康, 开源维护者, 压力, 应对方式, 社区, 建议, 展望, 资源, 可持续发展, 平衡

总结:<br /><br />本文探讨了开源维护者在面临心理健康挑战时的困境，包括工作与生活平衡、社区压力、追求完美等问题。作者提出了应对方式，如放慢节奏、写博客宣泄情绪、与社区沟通，以及对开源贡献者的建议，如设定合理预期、寻求帮助、关注自我等。同时，指出开源社区应营造友善氛围、关注心理健康、提供支持资源。关键在于不断学习调整，找到适合自己的方式，平衡投入和自我保护。 <div>
【开源路上，别让心理健康成了绊脚石】<br />1. 开源维护者面临的心理健康挑战:<br />   - 工作与生活平衡<br />   - 来自社区的期望和压力<br />   - 个人对完美的追求<br />2. 作者的应对方式:<br />   - 放慢节奏,享受过程而非执着于立竿见影的结果<br />   - 写博客梳理思路,宣泄负面情绪<br />   - 与社区保持开诚布公的沟通<br />3. 作者对开源贡献者的建议:<br />   - 设定合理预期,接纳"够好"的结果<br />   - 必要时寻求帮助,与他人分享感受<br />   - 关注自我,投入个人生活与兴趣爱好<br />4. 作者对开源社区的展望:<br />   - 营造友善、包容的氛围<br />   - 关注贡献者的心理健康<br />   - 提供更多帮助和支持资源<br />5. 开源之路没有完美的解决方案,关键是不断学习、调整,找到适合自己的方式。<br /><br />点评:<br />1. 开源工作获得回报的周期较长,需要贡献者保持耐心和动力。<br />2. 部分评论质疑开源是否必然导致心理压力,认为关键在于自我管理。<br />3. 有建议指出,参与者应主动控制参与度,必要时"说不"以保障个人生活。<br />4. 开源社区应提供更多支持资源,如心理健康指南、互助小组等。<br />5. 开源项目的可持续发展,需要在贡献者投入和自我保护间找到平衡。<br /><br />《Mental Health in Open Source》 <a href="https://antfu.me/posts/mental-health-oss"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntocrscepj20x00u0n1p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:16:24 GMT</pubDate>
</item>
<item>
<title>今日推介(第1347期)：语言模型算法带来的改进速率评估、用合成数据进行模型高效评估、检索增强思维在长程生成中实现上下文感知推理、面向向量嵌入和结构化数据的...</title>
<link>https://weibo.com/1402400261/O5nfJ9Pv8</link>
<guid>https://weibo.com/1402400261/O5nfJ9Pv8</guid>
<content:encoded><![CDATA[
<div> 语言模型算法、改进速率评估、合成数据、模型高效评估、检索增强思维、长程生成、上下文感知推理、面向向量嵌入、结构化数据、高性能、谓词不可知搜索方法、持续学习、灾难性遗忘

总结:<br /><br />本文分析了语言模型算法带来的改进速率评估以及使用合成数据进行模型高效评估的方法。进一步讨论了检索增强思维在长程生成中实现上下文感知推理的重要性。同时介绍了面向向量嵌入和结构化数据的高性能和谓词不可知搜索方法的应用。最后，探讨了持续学习与灾难性遗忘的问题，为相关领域的研究提供了启示。 <div>
今日推介(第1347期)：语言模型算法带来的改进速率评估、用合成数据进行模型高效评估、检索增强思维在长程生成中实现上下文感知推理、面向向量嵌入和结构化数据的高性能和谓词不可知搜索方法、持续学习与灾难性遗忘  公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687438947"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.17)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntmepeyz2j20k0094jsj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntmet15vnj20k00g50us.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntmevbeezj20k00eptaq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntmezj2v6j20k00bfjs2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntmf23pboj20k006v0ty.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 23:09:24 GMT</pubDate>
</item>
<item>
<title>[LG] Poly-View Contrastive Learning 网页链接 展示了一种名为多视对比学习(Poly-View Contrastive Learning)的新框架，挑战了传统对比学习中常见的观点，即需...</title>
<link>https://weibo.com/1402400261/O5nbmvDDn</link>
<guid>https://weibo.com/1402400261/O5nbmvDDn</guid>
<content:encoded><![CDATA[
<div> 对比学习、多视对比学习、视角数量、样本总量、计算资源、训练周期、批次数量、表现优势、图像表示学习、高效性
<br /><br />总结:
研究展示了一种新框架——多视对比学习，挑战了传统对比学习观点，证明增加单个样本的视角数量而非样本总量可以获得更好的表现。使用多视角对比模型，在限定的训练周期和批次设置下，可以超越传统对比学习模型的效果。这一研究改变了对大批量和长周期训练需求的传统看法，为图像表示学习提供了新方向，突显了高效性。 <div>
[LG] Poly-View Contrastive Learning  <br /><a href="https://arxiv.org/abs/2403.05490"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />展示了一种名为多视对比学习(Poly-View Contrastive Learning)的新框架，挑战了传统对比学习中常见的观点，即需要大量样本和多个训练周期来提高性能。研究表明，通过增加单个样本的视角数量而非样本总量，可以在有限的计算资源下获得更优的表现。具体来说，使用多视角对比模型，在128个训练周期、每批次256个样本的设置下，就能超越标准对比学习模型SimCLR在1024个周期、每批次4096个样本的训练效果。该研究改变了对大批量和长周期训练需求的传统看法，为高效的图像表示学习指明了新方向。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntm3w9ye2j213u1m2qoj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntm3wx3pxj21ui10awtc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:58:40 GMT</pubDate>
</item>
<item>
<title>[CV] Score-Guided Diffusion for 3D Human Recovery 网页链接 介绍了一种名为Score-Guided Human Mesh Recovery(ScoreHMR)的新方法，用于解决3D人体姿态和形状...</title>
<link>https://weibo.com/1402400261/O5n8ZBO7k</link>
<guid>https://weibo.com/1402400261/O5n8ZBO7k</guid>
<content:encoded><![CDATA[
<div> Score-Guided Human Mesh Recovery, 3D人体姿态和形状重建, 扩散模型, 得分引导, 图像观测, 单帧模型拟合, 多视角重建, 视频序列, 基准测试

<br /><br />总结:
本文介绍了一种新方法Score-Guided Human Mesh Recovery (ScoreHMR) 用于解决3D人体姿态和形状重建的逆问题。与传统方法不同，该方法利用扩散模型的潜空间并通过得分引导实现与图像观测的对齐。该方法在多项基准测试中展现出较高的准确性，有效提高了单帧模型拟合、多视角重建和视频序列中人体动作的精度，超越了所有优化基准模型。ScoreHMR不需要特定任务的扩散模型再训练，具有较高的实用性。 <div>
[CV] Score-Guided Diffusion for 3D Human Recovery  <br /><a href="https://arxiv.org/abs/2403.09623"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为Score-Guided Human Mesh Recovery(ScoreHMR)的新方法，用于解决3D人体姿态和形状重建的逆问题。与传统优化或回归方法不同，ScoreHMR利用扩散模型的潜空间并通过得分引导来实现与图像观测的对齐。这种方法不需要对无依赖任务的扩散模型进行特定任务的再训练，有效地提高了单帧模型拟合、多视角重建和视频序列中人体动作的准确性，并在多项基准测试中超越了所有优化基准模型。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntlxtzz9ij21a81ich9h.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntlxunm8nj21qa0y8dt3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:52:50 GMT</pubDate>
</item>
<item>
<title>[LG] Defending Against Unforeseen Failure Modes with Latent Adversarial Training 网页链接 深入探讨了AI系统部署后出现的意外行为，并提出一种新的防御手段...</title>
<link>https://weibo.com/1402400261/O5n6f85Bk</link>
<guid>https://weibo.com/1402400261/O5n6f85Bk</guid>
<content:encoded><![CDATA[
<div> 潜对抗训练, 意外行为, 防御手段, 潜表示层, 压缩, 抽象, 结构化, 图像分类, 文本分类, 文本生成

<br /><br />

总结: 本文深入探讨了AI系统部署后可能出现的意外行为，并提出了一种新的防御手段——潜对抗训练（LAT）。LAT通过在模型的潜表示层面干预，利用更加压缩、抽象和结构化的概念表示来防御未知的失败模式。实验证明，LAT在图像分类、文本分类和文本生成任务中，相比传统的对抗训练（AT），能提高模型对未知对抗样本类别的鲁棒性，同时移除特洛伊木马。这一发现显示LAT的潜力，为防御开发者无法明确识别的失败模式提供了可能的解决方案。 <div>
[LG] Defending Against Unforeseen Failure Modes with Latent Adversarial Training  <br /><a href="https://arxiv.org/abs/2403.05030"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />深入探讨了AI系统部署后出现的意外行为，并提出一种新的防御手段：潜对抗训练(LAT)。LAT区别于传统的对抗训练(AT)，它不通过生成触发模型失败的输入，而是在模型的潜表示层面进行干预，利用网络对信息进行处理时构建的更加压缩、抽象和结构化的概念表示。通过在图像分类、文本分类和文本生成任务中的实验表明，与AT相比，LAT通常能在不损害干净数据性能的同时，提高模型对未见过的对抗样本类别的鲁棒性，并能移除特洛伊木马。这一发现表明LAT可以成为一种有前景的工具，用于防御开发者无法显式识别的失败模式。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntlqrmnlzj212u1jctr6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntlqql6xrj21hi1cudyi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:46:03 GMT</pubDate>
</item>
<item>
<title>[LG] ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training 网页链接 提出PROTLLM，一个能同时处理蛋白质中心和蛋白质-语言任务的...</title>
<link>https://weibo.com/1402400261/O5n3Awz5o</link>
<guid>https://weibo.com/1402400261/O5n3Awz5o</guid>
<content:encoded><![CDATA[
<div> PROTLLM、蛋白质挂载机制、蛋白质词表、InterPT、跨模态大型语言模型、零样本学习、上下文学习、蛋白质中心任务、蛋白质-语言任务、预训练数据集

<br /><br />总结:
PROTLLM是一个跨模态大型语言模型，具有动态蛋白质挂载机制，可以处理复杂输入中的任意数量蛋白质。通过专门的蛋白质词表，模型能够同时预测自然语言和蛋白质。研究构建了大规模的蛋白质-文本数据集InterPT用于预训练，融合了结构化和非结构化数据源。PROTLLM在蛋白质中心任务上表现优于基线模型，并展现出零样本学习和上下文学习的能力。这项研究为蛋白质-语言任务提供了新的解决方案，并为蛋白质研究领域带来了创新的进展。 <div>
[LG] ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training  <br /><a href="https://arxiv.org/abs/2403.07920"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出PROTLLM，一个能同时处理蛋白质中心和蛋白质-语言任务的跨模态大型语言模型(LLM)。其特色是动态蛋白质挂载机制，使模型能够处理含有任意数量蛋白质的复杂输入。通过开发专门的蛋白质词表，模型能够从大量候选者中预测自然语言和蛋白质。构建了一个大规模交错的蛋白质-文本数据集InterPT用于预训练，融合了结构化和非结构化数据源。PROTLLM在蛋白质中心任务上优于专门的基线，并且在蛋白质-语言任务上展示了零样本和上下文学习能力。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntljyrwk6j213a1je7nq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntljzjjocj21fu11kakh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:39:31 GMT</pubDate>
</item>
<item>
<title>[CL] CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences 网页链接 介绍了CodeUltraFeedback和CODAL-Ben...</title>
<link>https://weibo.com/1402400261/O5n0v593n</link>
<guid>https://weibo.com/1402400261/O5n0v593n</guid>
<content:encoded><![CDATA[
<div> CodeUltraFeedback, CODAL-Bench, 数据集, 大型语言模型, 编程偏好, AI反馈, LLM-as-a-Judge方法, 偏好优化, 微调, RLAIF, 功能正确性, CodeLlama-7B-Instruct模型, SFT, DPO

总结:<br /><br />本文介绍了CodeUltraFeedback和CODAL-Bench，提供了一套用于微调和评估大型语言模型(LLM)以符合编程偏好的数据集和基准。CodeUltraFeedback包含复杂指令，通过AI反馈调整LLM偏好，反映了五种编程偏好。利用LLM-as-a-Judge方法对LLM的响应进行了标注，包括数值评分和文本反馈。研究表明经过微调的CodeLlama-7B-Instruct模型在功能正确性和偏好对齐方面表现优于基础模型和更大的34B LLM。这证明了CodeUltraFeedback在偏好调整中的实用性，以及SFT和DPO在提升LLM与人类编程偏好对齐方面的潜力。 <div>
[CL] CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences  <br /><a href="https://arxiv.org/abs/2403.09032"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了CodeUltraFeedback和CODAL-Bench，一套用于微调和评估大型语言模型(LLM)以符合编程偏好的数据集和基准。CodeUltraFeedback包含10000条复杂指令，用于通过AI反馈调整LLM偏好，反映了五种编程偏好。利用来自GPT-3.5的LLM-as-a-Judge方法，对LLM的响应进行了标注，包括数值评分和文本反馈。通过直接偏好优化(DPO)和AI反馈强化学习(RLAIF)的研究表明，经过微调的CodeLlama-7B-Instruct模型在功能正确性和偏好对齐方面均优于未微调的基础模型和更大的34B LLM。这证明了CodeUltraFeedback在偏好调整中的实用性，以及SFT和DPO在提升LLM与人类编程偏好对齐方面的潜力。<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntlc1minqj218a1ic4nd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntlc27482j21b01c2du8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntlc2bylej20y019cjyn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:31:54 GMT</pubDate>
</item>
<item>
<title>详尽分析了人工神经网络在持续学习过程中面临的灾难性遗忘挑战，探讨了六种主要的计算方法来提高持续学习能力，强调了在深度学习与认知科学之间建立联系的重要性...</title>
<link>https://weibo.com/1402400261/O5mVI6XCv</link>
<guid>https://weibo.com/1402400261/O5mVI6XCv</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工神经网络，持续学习，灾难性遗忘，深度学习，认知科学，计算方法，互相启发，发展，联系，挑战

总结:<br /><br />
本文详细分析了人工神经网络在持续学习过程中所面临的灾难性遗忘挑战，并通过探讨六种主要的计算方法来提高持续学习能力。作者强调了在深度学习与认知科学之间建立联系的重要性，旨在促进两个领域之间的互相启发和发展。文章指出，在人工智能领域持续学习是一个关键的问题，因为传统神经网络容易忘记之前学到的知识，导致新知识的学习会覆盖旧知识。为解决这一问题，提出了六种方法，包括反向传播、重放缓冲区、正交正则化、动态权重、增量学习和任务分解等。这些方法在一定程度上提高了人工神经网络的持续学习能力。同时，文章呼吁深度学习与认知科学之间建立更多的联系，通过相互启发和发展推动这两个领域的进步。这种综合性的研究方法可以为人工智能领域的持续学习问题带来新的突破。通过深入探讨人工神经网络如何应对灾难性遗忘挑战，可以不断提升其在持续学习任务中的表现，推动人工智能技术的发展。 <div>
详尽分析了人工神经网络在持续学习过程中面临的灾难性遗忘挑战，探讨了六种主要的计算方法来提高持续学习能力，强调了在深度学习与认知科学之间建立联系的重要性，旨在推动两领域的互相启发和发展。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Continual Learning and Catastrophic Forgetting》G M. v d Ven, N Soures, D Kudithipudi [KU Leuve &amp; University of Texas at San Antonio] (2024) <a href="https://arxiv.org/abs/2403.05175"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklqwed9j21eo0dwgs1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntklrqmumj21na0motf2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsa9x2j21n40kaaj9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsujzaj21n20nk7cy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntkznz89nj21120o7439.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:20:06 GMT</pubDate>
</item>
<item>
<title>[LG]《Continual Learning and Catastrophic Forgetting》G M. v d Ven, N Soures, D Kudithipudi [KU Leuve &amp; University of Texas at San Antonio] (2024) 网...</title>
<link>https://weibo.com/1402400261/O5mVF0Qpu</link>
<guid>https://weibo.com/1402400261/O5mVF0Qpu</guid>
<content:encoded><![CDATA[
<div> 学习，持续学习，灾难性遗忘，机器学习，人工智能，神经网络，模型，挑战，解决方案，实验<br />
<br />
总结:<br />
本文讨论了持续学习和灾难性遗忘的问题，提出了一种解决方案来解决这一挑战。研究人员指出，传统的机器学习算法在面对持续学习任务时会出现灾难性遗忘的情况，导致已学习过的知识被遗忘。为了克服这一问题，他们提出了一种基于神经网络的方法，通过对模型进行增量学习和保留重要信息的方式来解决灾难性遗忘。研究人员进行了一系列实验来验证他们的方法的有效性，结果表明他们的方法在持续学习任务中具有较好的性能表现。这项研究为解决持续学习和灾难性遗忘问题提供了新的思路和方法。 <div>
[LG]《Continual Learning and Catastrophic Forgetting》G M. v d Ven, N Soures, D Kudithipudi [KU Leuve &amp; University of Texas at San Antonio] (2024) <a href="https://arxiv.org/abs/2403.05175"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklqwed9j21eo0dwgs1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntklrqmumj21na0motf2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsa9x2j21n40kaaj9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsujzaj21n20nk7cy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntkznz89nj21120o7439.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:19:59 GMT</pubDate>
</item>
<item>
<title>ACORN是一种新的、性能优异且不限制谓词类型的混合搜索方法，通过改良HNSW索引和引入谓词子图遍历来同时高效处理向量和结构化数据，克服了传统方法在性能和搜索...</title>
<link>https://weibo.com/1402400261/O5mPdmC1P</link>
<guid>https://weibo.com/1402400261/O5mPdmC1P</guid>
<content:encoded><![CDATA[
<div> ACORN, HNSW索引, 混合搜索方法, 向量数据, 结构化数据, 高性能, 不限制谓词类型, 复杂多模态数据集, 高查询吞吐量, 低构建开销

<br /><br />总结:
研究介绍了一种新的混合搜索方法ACORN，它通过改良HNSW索引和引入谓词子图遍历来同时处理向量数据和结构化数据。ACORN能够高效处理复杂多模态数据集，克服了传统方法在性能和搜索谓词表达式上的限制。研究表明，ACORN实现了高查询吞吐量和低构建开销的优异性能，为搜索领域带来了新的可能性。 <div>
ACORN是一种新的、性能优异且不限制谓词类型的混合搜索方法，通过改良HNSW索引和引入谓词子图遍历来同时高效处理向量和结构化数据，克服了传统方法在性能和搜索谓词表达式上的限制，实现了在复杂多模态数据集上的高查询吞吐量和低构建开销。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [IR]《ACORN: Performant and Predicate-Agnostic Search Over Vector Embeddings and Structured Data》L Patel, P Kraft, C Guestrin, M Zaharia [Stanford University &amp; DBOS, Inc &amp; UC Berkeley] (2024) <a href="https://arxiv.org/abs/2403.04871"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkivhxhvj211e11eao2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkivwjjlj210y0l4wh3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkiwh65wj211a0tyjws.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntkiwpg9jj21160jetb3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkiy3hepj213s0e2gnl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkiy2ugdj20jg0d33zo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkiy3nidj213r0csgob.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkiy2z5dj213m08qgn0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkiy3nxyj20jg0f175q.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:04:06 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》(CVPR 2024) GitHub: github.c...</title>
<link>https://weibo.com/1402400261/O5jwVne0V</link>
<guid>https://weibo.com/1402400261/O5jwVne0V</guid>
<content:encoded><![CDATA[
<div> DNGaussian, 优化, 稀疏视图, 3D, 高斯辐射场, 全局局部深度规范化, GitHub, Pix2Gif, 运动引导扩散, GIF 生成, SSM, 视频扩散模型, 有效视频生成, 结构化状态空间, 语言模型, 可靠性, 过度训练, 下游任务

<br /><br />总结: 《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》提出了一种优化稀疏视图3D高斯辐射场的方法，通过全局局部深度规范化来改善渲染效果，代码可在GitHub上找到。《Pix2Gif: Motion-Guided Diffusion for GIF Generation》介绍了Pix2Gif，一种运动引导扩散技术，用于生成GIF图像。《SSM Meets Video Diffusion Models: Efficient Video Generation with Structured State Spaces》展示了SSM与视频扩散模型相结合，实现了有效的视频生成，采用了结构化状态空间。《Language models scale reliably with over-training and on downstream tasks》研究表明，语言模型在过度训练和下游任务中表现出可靠的扩展性，相关代码可在GitHub上获取。 <div>
几篇论文实现代码：<br />《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》(CVPR 2024) GitHub: github.com/Fictionarry/DNGaussian [fig1]<br />《Pix2Gif: Motion-Guided Diffusion for GIF Generation》(2024) GitHub: github.com/hiteshK03/Pix2Gif<br />《SSM Meets Video Diffusion Models: Efficient Video Generation with Structured State Spaces》(2024) GitHub: github.com/shim0114/SSM-Meets-Video-Diffusion-Models [fig2]<br />《Language models scale reliably with over-training and on downstream tasks》(2024) GitHub: github.com/mlfoundations/scaling<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnt3oac1q5j21iu0jiasp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnt3p0dq0hj22801904ns.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 13:40:48 GMT</pubDate>
</item>
<item>
<title>'Awesome-AISourceHub - AI科技领域高质量信息源列表’ GitHub: github.com/AmbroseX/Awesome-AISourceHub #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5jwP9UrG</link>
<guid>https://weibo.com/1402400261/O5jwP9UrG</guid>
<content:encoded><![CDATA[
<div> GitHub, AI, 科技, 高质量, 信息源, 列表, 开源项目, AmbroseX, Awesome-AISourceHub

总结:<br /><br />这是一个收集AI科技领域高质量信息源的开源项目，其中包括了各种资源列表和信息源，可以帮助人们更好地了解和学习关于人工智能的知识。由AmbroseX创建并维护，项目地址为github.com/AmbroseX/Awesome-AISourceHub。欢迎大家积极参与和贡献，共同打造一个强大的AI资源集合。 <div>
'Awesome-AISourceHub - AI科技领域高质量信息源列表’ GitHub: github.com/AmbroseX/Awesome-AISourceHub <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnt5z3jp2mj20y40u00y9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 13:40:33 GMT</pubDate>
</item>
<item>
<title>【EasyDetect：易于使用的多模态幻觉检测框架，用于多模态大型语言模型(MLLMs)如GPT-4V、Gemini、LlaVA的研究实验，通过统一的视角对多模态幻觉进行检测，包括模...</title>
<link>https://weibo.com/1402400261/O5j2octGD</link>
<guid>https://weibo.com/1402400261/O5j2octGD</guid>
<content:encoded><![CDATA[
<div> 多模态 幻觉检测框架 GPT-4V Gemini LlaVA 研究实验 统一视角 模态冲突 幻觉 事实冲突 幻觉

<br /><br />总结:
EasyDetect是一个易于使用的多模态幻觉检测框架，专为大型语言模型如GPT-4V、Gemini和LlaVA的研究实验而设计。该框架通过统一的视角对多模态幻觉进行检测，包括模态冲突幻觉和事实冲突幻觉。通过EasyDetect，研究人员可以更方便地进行多模态幻觉的实验和研究，从而深入探讨语言模型的表现和特性。 <div>
【EasyDetect：易于使用的多模态幻觉检测框架，用于多模态大型语言模型(MLLMs)如GPT-4V、Gemini、LlaVA的研究实验，通过统一的视角对多模态幻觉进行检测，包括模态冲突幻觉和事实冲突幻觉】’EasyDetect - An Easy-to-use Hallucination Detection Framework for LLMs.' GitHub: github.com/OpenKG-ORG/EasyDetect <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnt3t2xe1zj20i60fbdj0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnt3t5cqj1j20pp0gegqn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 12:25:34 GMT</pubDate>
</item>
<item>
<title>【ChatOllama：基于Nuxt 3和Ollama的聊天Web应用】'ChatOllama - a Nuxt 3 + Ollama web application. It's an example of Ollama Javascript library’ GitHub:...</title>
<link>https://weibo.com/1402400261/O5j0hzQkC</link>
<guid>https://weibo.com/1402400261/O5j0hzQkC</guid>
<content:encoded><![CDATA[
<div> ChatOllama、Nuxt 3、Ollama、web应用、GitHub、Javascript库、聊天应用、示例、开发、实现<br />
<br />总结:
ChatOllama是基于Nuxt 3和Ollama的聊天Web应用示例，使用Ollama Javascript库开发，代码托管在GitHub上，展示了如何开发和实现一个聊天应用。 <div>
【ChatOllama：基于Nuxt 3和Ollama的聊天Web应用】'ChatOllama - a Nuxt 3 + Ollama web application. It's an example of Ollama Javascript library’ GitHub: github.com/sugarforever/chat-ollama <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnt3ns8meej219c0jogny.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 12:20:23 GMT</pubDate>
</item>
<item>
<title>【Data is Better Together：由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。目前，该项目已经创...</title>
<link>https://weibo.com/1402400261/O5ihKbqgZ</link>
<guid>https://weibo.com/1402400261/O5ihKbqgZ</guid>
<content:encoded><![CDATA[
<div> Hugging Face, Argilla, 开源机器学习社区, 数据集, 合作, 提示, 排名, 10,000个, 质量

<br /><br />总结:
Data is Better Together是一个由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。该项目已经创建了一个由10,000个提示组成的数据集，并按照质量进行了排名。这个项目的目标是让开源社区共同努力，创造更好的数据集，为机器学习研究和实践提供更丰富的资源和支持。通过协作和合作，我们可以共同构建更具影响力和实用性的数据集，推动机器学习领域的发展和创新。 <div>
【Data is Better Together：由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。目前，该项目已经创建了一个由10,000个提示组成的数据集，按质量进行了排名】'Data is Better Together - Let's build better datasets, together!' GitHub: github.com/huggingface/data-is-better-together <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnt0hi5cbfj211y0lc78w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 10:30:39 GMT</pubDate>
</item>
<item>
<title>【OPEN TEACH: 多功能遥操作框架，使用Meta Quest3进行机器人操作，具有灵活性和多样性，包括VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，支持在各种...</title>
<link>https://weibo.com/1402400261/O5ih2p7R0</link>
<guid>https://weibo.com/1402400261/O5ih2p7R0</guid>
<content:encoded><![CDATA[
<div> 多功能遥操作框架, Meta Quest3, 机器人操作, 灵活性, 多样性, Unity脚本, 遥操作流程, 数据收集流程, 策略训练, GitHub  

<br /><br />总结:  
这篇文章介绍了一个名为"OPEN TEACH"的多功能遥操作框架，使用Meta Quest3进行机器人操作，并具有灵活性和多样性。该框架包括了VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，能够支持在各种机器人和仿真环境下进行遥操作和数据收集，并针对不同机器人和仿真进行策略训练。该框架的GitHub链接为github.com/aadhithya14/Open-Teach。 <div>
【OPEN TEACH: 多功能遥操作框架，使用Meta Quest3进行机器人操作，具有灵活性和多样性，包括VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，支持在各种机器人和仿真环境下进行遥操作和数据收集，并针对不同机器人和仿真进行策略训练】'OPEN TEACH: A Versatile Teleoperation System for Robotic Manipulation - A Versatile Teleoperation framework for Robotic Manipulation using Meta Quest3' GitHub: github.com/aadhithya14/Open-Teach <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnt0fre8fpj21ji0twwkh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 10:28:54 GMT</pubDate>
</item>
<item>
<title>今日推介(第1346期)：让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、用Moment Pooling简化机器学习...</title>
<link>https://weibo.com/1402400261/O5dqgdQEc</link>
<guid>https://weibo.com/1402400261/O5dqgdQEc</guid>
<content:encoded><![CDATA[
<div> 语言模型、结构化训练、灾难性遗忘、预期性恢复、马尔可夫决策过程、学习算法、Moment Pooling、机器学习潜空间、API保护、LLM的Logits

<br /><br />总结:
本文介绍了几个关键的技术和方法，包括让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、以及用Moment Pooling简化机器学习潜空间。另外，还提到了API保护LLM的Logits会泄漏模型专有信息的问题。这些方法和技术对于改进语言模型的能力，提高机器学习算法的效率和精确度都具有重要意义。通过不断探索和应用这些新技术，我们可以进一步推动人工智能领域的发展，为未来带来更多可能性。 <div>
今日推介(第1346期)：让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、用Moment Pooling简化机器学习潜空间、API保护LLM的Logits会泄漏模型专有信息 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687311397"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.16)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnsf0htg36j20k00b9gn7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnsf0k1lqgj20k006m751.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnsf0ml60tj20k007d0t5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnsf0p0i2ij20k00kq762.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnsf0repglj20k008pwfi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 22:07:54 GMT</pubDate>
</item>
<item>
<title>[RO] GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping 网页链接 提出一种名为GaussianGrasper的开放词表机器人抓取技术...</title>
<link>https://weibo.com/1402400261/O5dn86Ikc</link>
<guid>https://weibo.com/1402400261/O5dn86Ikc</guid>
<content:encoded><![CDATA[
<div> 高斯Splatting、机器人抓取技术、3D构建、视角输入、推理效率、特征蒸馏、对比学习、抓取姿态、语言指令、场景更新
<br /><br />总结:
提出了一种名为GaussianGrasper的开放词表机器人抓取技术，通过3D高斯Splatting构建场景，解决了传统隐式场景表达的问题。利用有限的RGB-D视角和高效特征蒸馏模块，结合对比学习来准确提取语言嵌入，使得预训练的抓取模型可以生成无碰撞的抓取姿态候选。通过法向引导的抓取模块选取最佳姿态。实验证明，该系统能准确响应语言指令，执行抓取任务，并实现快速场景更新。提供了新的解决方案用于语言引导操作任务，并公开了数据和代码资源。 <div>
[RO] GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping  <br /><a href="https://arxiv.org/abs/2403.09637"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出一种名为GaussianGrasper的开放词表机器人抓取技术，它通过3D高斯Splatting显式构建场景，解决了传统隐式场景表达(例如NeRF)需要大量视角输入和推理效率低下的问题。GaussianGrasper利用有限的RGB-D视角并通过一种高效特征蒸馏(EFD)模块，结合对比学习来准确提取语言嵌入。这使得其预训练的抓取模型能生成无碰撞的抓取姿态候选，并通过法向引导的抓取模块选取最佳姿态。实验表明，该系统能准确响应语言指令，执行抓取任务，并实现快速场景更新。此外，提供了用于语言引导操作任务的新解决方案，并公开了数据和代码资源。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsesr3i0dj219w1kc1kx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsesrglfpj21hq17uqlw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsesrlyxgj21h40uqqif.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 22:00:11 GMT</pubDate>
</item>
<item>
<title>[CV] Reconstruction and Simulation of Elastic Objects with Spring-Mass 3D Gaussians 网页链接 提出了Spring-Gaus框架，一个整合物理仿真和3D高斯模型的新方...</title>
<link>https://weibo.com/1402400261/O5difnNAc</link>
<guid>https://weibo.com/1402400261/O5difnNAc</guid>
<content:encoded><![CDATA[
<div> Spring-Gaus, 物理仿真, 3D高斯模型, 弹性物体, 多视角视频, 参数优化, 模拟粒子, 样本效率, 泛化能力, 形变预测

<br /><br />总结:
本文提出了Spring-Gaus框架，结合了物理仿真和3D高斯模型，用于重建和模拟弹性物体。通过3D弹簧-质点模型在个体点级别优化物理参数，解决了物理和外观学习的问题，提高了样本效率和泛化能力。Spring-Gaus在合成和真实数据集上证明了有效性，特别是在形变预测和不同环境参数下的模拟中表现出色。这一研究突破了物理参数优化和异质物体建模的限制，为预测视觉感知和沉浸式体验的应用提供了新的可能性。 <div>
[CV] Reconstruction and Simulation of Elastic Objects with Spring-Mass 3D Gaussians  <br /><a href="https://arxiv.org/abs/2403.09434"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出了Spring-Gaus框架，一个整合物理仿真和3D高斯模型的新方法，用于从多视角视频重建和模拟弹性物体。与传统的3D高斯方法相比，Spring-Gaus通过3D弹簧-质点模型在个体点级别优化物理参数，有效解缠物理和外观学习。这种方法提高了样本效率，增强了泛化能力，并减少了对仿真粒子分布的敏感性。在合成和真实世界数据集上的评估证明了Spring-Gaus在准确重建和模拟弹性物体方面的有效性，尤其是在进行未来形变预测和不同初始状态及环境参数下的模拟时。该研究突破了物理参数优化和异质物体建模的限制，为预测视觉感知和沉浸式体验的应用开辟了可能。<img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnseg8bri1j20z41e6wrp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnseg8nm5cj21fa0wstjg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnseg9gk2gj21fa1au18j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:48:10 GMT</pubDate>
</item>
<item>
<title>[LG] Majority-of-Three: The Simplest Optimal Learner? 网页链接 讨论了PAC学习中的一个开放问题：在实现环境下，寻找最简单的最优学习算法。分析了一个简单的...</title>
<link>https://weibo.com/1402400261/O5deGfwNR</link>
<guid>https://weibo.com/1402400261/O5deGfwNR</guid>
<content:encoded><![CDATA[
<div> 多数投票法, 最优学习算法, PAC学习, 期望误差, 高概率误差, Bagging算法, ERM分类器, 最优误差界, one-inclusion graph算法, 简化算法结构

<br /><br />总结:
本文讨论了在实现环境下寻找最简单的最优学习算法的问题，并提出了多数投票法可能是一个简单且最优的解决方案。该算法使用三个ERM分类器，在期望误差上达到了最优，并且在高概率误差上也接近最优。该发现挑战了之前认为ERM分类器无法独自实现最优误差界的观点。文章还提出了改进的Bagging算法，简化了之前复杂的算法结构。另外，研究指出了one-inclusion graph算法在高概率误差上的局限性，与之前的猜想相反。通过进一步分析，多数投票法可能在高概率误差上也是最优的。整体而言，本文为最简单有效的学习算法提供了新的思路，并拓展了对学习算法的理解。 <div>
[LG] Majority-of-Three: The Simplest Optimal Learner?  <br /><a href="https://arxiv.org/abs/2403.08831"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />讨论了PAC学习中的一个开放问题：在实现环境下，寻找最简单的最优学习算法。分析了一个简单的算法——多数投票法，其中只使用三个ERM分类器。文章的核心是这个算法在期望误差上达到了最优，并且近似于高概率误差上的最优。这一发现挑战了之前的认知，即ERM分类器无法独自实现最优误差界。本文还提出一种改进的Bagging算法，简化了之前复杂的算法结构，但分析过程仍然复杂。此外，一项新的研究揭示了one-inclusion graph算法在高概率误差上的局限性，这与之前Warmuth的猜想相反。本文认为，通过进一步分析，上述多数投票法可能在高概率误差上也是最优的。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnse738777j21841gmh1p.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnse73lpebj21co0zoqa5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:39:22 GMT</pubDate>
</item>
<item>
<title>[CV] MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training 网页链接 介绍了多模态大型语言模型(MLLM)的构建，重点在于体系结构组件和数据选择...</title>
<link>https://weibo.com/1402400261/O5dbMeVyI</link>
<guid>https://weibo.com/1402400261/O5dbMeVyI</guid>
<content:encoded><![CDATA[
<div> 模态语言模型 构建 组件 数据 体系结构 图像编码器 视觉语言连接器 预训练数据<br />
<br />
总结: 本文介绍了多模态大型语言模型(MLLM)的构建方法和分析，强调了体系结构组件和数据选择的重要性。研究发现，混合使用图像-文字、交错图像-文字和纯文字数据对实现少样本最先进结果(SOTA)至关重要。此外，图像编码器、图像分辨率和图像标记数量对结果有显著影响。作者构建了一个最高达30B参数的模型族MM1，通过大规模预训练实现了竞争性性能，并展现了吸引人的特性，能够实现少样本的连锁思维提示。 <div>
[CV] MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training  <br /><a href="https://arxiv.org/abs/2403.09611"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了多模态大型语言模型(MLLM)的构建，重点在于体系结构组件和数据选择的重要性。通过对图像编码器、视觉语言连接器和不同预训练数据选项的详尽剖析，揭示了几个关键设计经验。研究表明，混合使用图像-文字、交错图像-文字和纯文字数据对于实现多项基准测试中的少样本最先进结果(SOTA)至关重要。此外，图像编码器、图像分辨率和图像标记数量对结果有显著影响，而视觉-语言连接器设计的影响相对较小。作者通过扩大模型规模，构建了一个最高达30B参数的模型族MM1，包括密集型模型和专家混合型变体，这些模型在预训练度量上表现出色，并在一系列多模态基准测试中经过监督微调后获得了竞争性性能。MM1的大规模预训练赋予了它如上下文预测、多图像推理等吸引人的特性，使其能够实现少样本的连锁思维提示。<img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdzmld2pj21201iuapu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdzn0s90j21hk13aaq5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdznf268j21hk0tytm5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdznnj32j21hm0qiaiy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:32:13 GMT</pubDate>
</item>
<item>
<title>揭示了通过分析LLM API的输出，即便是在API保护下，仍能通过较少的成本就能获取大量关于大型语言模型(如OpenAI gpt-3.5-turbo)的私有参数和结构信息，强调了这种...</title>
<link>https://weibo.com/1402400261/O5d99bA9M</link>
<guid>https://weibo.com/1402400261/O5d99bA9M</guid>
<content:encoded><![CDATA[
<div> API保护、LLM、私有参数、结构信息、模型透明度、问责性、信息泄露、特性、分析、有效性<br />
<br />
提到了一种通过分析LLM API输出获取私有参数和结构信息的方法，即使在API保护下也能实现。强调了这种方法的有效性，指出可以将其作为一种特性来提高模型的透明度和问责性。文章的研究结果揭示了重要的信息泄露问题，也提示了提高模型透明度的重要性。这种方法对于模型的安全性和隐私保护具有重要影响，值得深入研究和思考。<br /><br />总结: 提出了一种通过分析LLM API输出泄露私有信息的方法，并强调了其有效性以及作为提高模型透明度和问责性的特性。 <div>
揭示了通过分析LLM API的输出，即便是在API保护下，仍能通过较少的成本就能获取大量关于大型语言模型(如OpenAI gpt-3.5-turbo)的私有参数和结构信息，强调了这种获取信息方法的有效性，指出如何将此作为一种特性来提高模型的透明度和问责性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) <a href="https://arxiv.org/abs/2403.09539"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdhz8pyhj21oc15s7p2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdhzlf91j21ks0w4wqg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdhzq3auj21ke0oigsg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdi02jdij21l80pe118.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdsgpg07j20ve0dy764.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdsgoh8fj20vg0dqq55.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdsgpg6xj20vd090aar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:25:44 GMT</pubDate>
</item>
<item>
<title>[CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) 网页链接...</title>
<link>https://weibo.com/1402400261/O5d8YfyGJ</link>
<guid>https://weibo.com/1402400261/O5d8YfyGJ</guid>
<content:encoded><![CDATA[
<div> API-Protected LLMs, Logits, Leakage, Proprietary Information, Privacy, Data Security, Machine Learning, Information Disclosure

总结:<br /><br />本文研究了API保护的语言模型（LLMs）的Logits可能泄漏专有信息的问题。研究人员发现，即使在API保护的情况下，LLMs的输出Logits也可能包含公司的机密信息。这种信息泄漏可能导致数据隐私和安全方面的问题。因此，需要采取相应的措施来确保机器学习模型不会泄露敏感信息，保障数据安全。 <div>
[CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) <a href="https://arxiv.org/abs/2403.09539"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdhz8pyhj21oc15s7p2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdhzlf91j21ks0w4wqg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdhzq3auj21ke0oigsg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdi02jdij21l80pe118.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdsgpg07j20ve0dy764.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdsgoh8fj20vg0dqq55.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdsgpg6xj20vd090aar.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:25:18 GMT</pubDate>
</item>
<item>
<title>提出一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来显著降低潜空间维数，同时保持或提升模型性能，并以更少的基函数构建相同的机器学习...</title>
<link>https://weibo.com/1402400261/O5d3xurjA</link>
<guid>https://weibo.com/1402400261/O5d3xurjA</guid>
<content:encoded><![CDATA[
<div> 关键词: Moment Pooling, 深度集网络, 多变量矩, 潜空间维数, 模型性能, 基函数, 机器学习观测值, 可视化, 解释.

总结:<br /><br />本文提出了一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来降低潜空间维数，以提升模型性能。这一方法能够在更少的基函数下构建相同的机器学习观测值，使得模型内部表示可以更简单地进行可视化和解释。 Moment Pooling 的应用可以显著简化潜在空间的维数，帮助提升模型的性能，并且使得模型更容易解释和理解。通过对多变量矩的运用，Moment Pooling 可以在保持甚至提升模型性能的同时，降低所需的基函数数量，从而简化模型构建和解释过程。这一方法有望为机器学习领域带来更高效和可解释的模型设计。 <div>
提出一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来显著降低潜空间维数，同时保持或提升模型性能，并以更少的基函数构建相同的机器学习观测值，使得模型内部表示的可视化和解释变得更加简单。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) <a href="https://arxiv.org/abs/2403.08854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdd9vs67j21is0gyk1g.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsddafjn1j21mo0w2472.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddapji1j21901amtg7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddav53cj20vi10c79w.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c6wmj20jp0o3q5d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6f420j2140147afj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6bkxyj20jp0litak.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsde6g62dj2140156dpr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6drm7j2140156jva.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:11:56 GMT</pubDate>
</item>
<item>
<title>[LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) 网页链接 ...</title>
<link>https://weibo.com/1402400261/O5d3oBouU</link>
<guid>https://weibo.com/1402400261/O5d3oBouU</guid>
<content:encoded><![CDATA[
<div> Streamlining, Latent Spaces, Machine Learning, Moment Pooling, MIT, Gambhir, Osathapan, Thaler, 2024

<br /><br />总结:
本文探讨了在机器学习中利用矩阵池化来简化潜在空间的方法。研究人员提出了一种称为Moment Pooling的新技术，通过将不同阶数的矩阵进行池化，从而提高了模型在学习高阶统计特性方面的能力。这种技术不仅能够提高模型的效率，还能够减少模型对大规模数据集的需求。研究还表明，Moment Pooling技术在训练时间和模型性能之间取得了良好的平衡，为机器学习领域的实践带来了新的启示。MIT的研究人员Gambhir、Osathapan和Thaler的工作为机器学习领域的发展提供了有益的思路和方法。 <div>
[LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) <a href="https://arxiv.org/abs/2403.08854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdd9vs67j21is0gyk1g.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsddafjn1j21mo0w2472.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddapji1j21901amtg7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddav53cj20vi10c79w.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c6wmj20jp0o3q5d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6f420j2140147afj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6bkxyj20jp0litak.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsde6g62dj2140156dpr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6drm7j2140156jva.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6ceorj20jp0l1dhh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6d31vj21400ki77c.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c36cj20jp0khgn1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6d5zdj20z20jpgny.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6dr66j20zc0jqtb4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:11:35 GMT</pubDate>
</item>
<item>
<title>创新性地提出了一个学习算法框架，用于在完全和部分知识情况下进行马尔可夫决策过程的验证，特别是在不需要MDP结构特性假设和时间界限的情况下，通过启发式方法...</title>
<link>https://weibo.com/1402400261/O5d2K9Lno</link>
<guid>https://weibo.com/1402400261/O5d2K9Lno</guid>
<content:encoded><![CDATA[
<div> 马尔可夫决策过程、学习算法、验证、完全知识、部分知识、MDP结构、时间界限、概率可达性、启发式方法、停止准则

<br /><br />总结:
该研究提出了一个学习算法框架，可用于验证马尔可夫决策过程，在完全和部分知识情况下，无需MDP结构特性假设和时间界限。通过启发式方法提供了概率可达性的精确和概率界，同时提出了适应性强的停止准则。这一创新性方法有望在解决复杂决策问题中发挥重要作用。 <div>
创新性地提出了一个学习算法框架，用于在完全和部分知识情况下进行马尔可夫决策过程的验证，特别是在不需要MDP结构特性假设和时间界限的情况下，通过启发式方法提供了概率可达性的精确和概率界，同时提出了适应性强的停止准则。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Learning Algorithms for Verification of Markov Decision Processes》T Brázdil, K Chatterjee, M Chmelik, V Forejt, J Křetínský, M Kwiatkowska, T Meggendorfer, D Parker, M Ujma [Google LLC &amp; IST Austria &amp; Lancaster University Leipzig] (2024) <a href="https://arxiv.org/abs/2403.09184"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdb2ek9bj210m0mb12q.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdb2s9l9j21ce0pwtbu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdb38x14j21n20lqq6c.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdb3sanvj21rg0ecwgs.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:09:58 GMT</pubDate>
</item>
<item>
<title>恭喜@sayfh_wu-wuy_su私人领域-_- 等3名用户获得【《SPSSAU科研数据分析方法与应用》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效...</title>
<link>https://weibo.com/1402400261/O56k4DmCh</link>
<guid>https://weibo.com/1402400261/O56k4DmCh</guid>
<content:encoded><![CDATA[
<div> SPSSAU, 数据分析, 科研, 应用, 抽奖, 微博, 研究方法, 问卷数据, 医学数据, 视频讲解

<br /><br />总结:
微博举办了一次抽奖活动，三名幸运用户将获得《SPSSAU科研数据分析方法与应用》。这本书系统介绍了科研数据分析方法，适合研究者快速学习和掌握。活动截止时间是2024年3月15日12:00，感兴趣的用户需要转发和评论才能参与。活动结果将通过微博官方唯一抽奖工具监督，公正有效。该书涵盖了数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等方面，并配有171集视频讲解，帮助研究者更好地理解科研数据分析方法。 <div>
恭喜<a href="https://weibo.com/n/sayfh_wu-wuy_su%E7%A7%81%E4%BA%BA%E9%A2%86%E5%9F%9F-_-">@sayfh_wu-wuy_su私人领域-_-</a> 等3名用户获得【《SPSSAU科研数据分析方法与应用》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20117566&amp;pageid=100140E51183068"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00，*可可粉*转发+评论即可参与。近万篇研究论文选用SPSSAU快速入门，本书从数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等五个方面系统地介绍科研数据的分析方法，涉及13项知识类应用（如影响关系、权重关系、数据预测、问卷研究）附赠171集配套视频讲解，适合研究者快速学习和掌握科研数据分析方法。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5009557898134749"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnj8n91y6bj20m80m8n19.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnj8n9h45kj20m80m8mzs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9rlbnj20m80m8tbk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9wj7pj20m80m80vr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 04:03:26 GMT</pubDate>
</item>
<item>
<title>【艺术成功之路：声誉与网络的量化分析】- 研究人员重建了50万名艺术家的展览历史，绘制出反映艺术在机构之间流动的共同展览网络。 - 在这个网络中的中心性捕捉...</title>
<link>https://weibo.com/1402400261/O54JlkeLD</link>
<guid>https://weibo.com/1402400261/O54JlkeLD</guid>
<content:encoded><![CDATA[
<div> 艺术家、声誉、网络、展览历史、职业轨迹、早期进入高声望机构、马尔可夫模型、原籍国、潜在政策、彩票系统

<br /><br />总结:研究人员通过重建艺术家展览历史，揭示了艺术界展览网络结构和声誉对艺术家职业成功的影响。进入声誉高的机构能提供终身影响，早期选择机构会影响职业轨迹。原籍国可影响艺术家初始声誉和职业发展，建议实施彩票系统以提高公平竞争。研究虽然量化了准入壁垒，但仍需关注艺术评估的主观性和非实物艺术形式。艺术家应在更广泛机构展出，挑战传统观点，同时要面对可能的阻力。不同原籍国在全球化艺术世界中仍对艺术家有影响，呼吁更多关注多维度的审视。 <div>
【艺术成功之路：声誉与网络的量化分析】<br />- 研究人员重建了50万名艺术家的展览历史，绘制出反映艺术在机构之间流动的共同展览网络。  <br />- 在这个网络中的中心性捕捉了机构的声望，允许分析单个艺术家在获取理想机构方面的职业轨迹。  <br />- 早期进入声望高、处于中心位置的机构，可以为艺术家提供终身进入高声望场所的机会，并降低退出率。  <br />- 从网络边缘开始职业生涯会导致高退出率，限制进入中心机构的机会。  <br />- 一个马尔可夫模型可以预测艺术家的职业轨迹，记录了艺术价值评估中强烈的路径依赖和历史依赖。  <br />- 艺术家最初声望(前五次展览)的分布因其原籍国而异，影响他们职业成功的机会。  <br />- 该研究量化了艺术界的分层和准入壁垒，提出了潜在的政策，如彩票系统，以营造公平的竞争环境。  <br /><br />思考：  <br />- 该研究提供了声誉和网络在主观领域(如艺术)中决定资源和回报获取的量化见解，在这些领域中很难客观衡量表现。  <br />- 早期进入声望高的机构会产生终身影响，这一发现挑战了精英制的概念，凸显了初始机会的重要性。  <br />- 该研究关注机构准入和经济价值，可能忽略了艺术丰富社会的其他维度，如文化和情感价值。  <br />- 艺术家原籍国影响其初始声望和职业轨迹，这一观察结果引发了对艺术界系统性偏见和不平等的质疑。  <br />- 建议在艺术界实施彩票系统或盲选程序以提高代表性不足艺术家的包容性，可能面临既得利益机构和艺术界的阻力。  <br />- 尽管该研究量化了准入壁垒，但并未直接解决艺术评估的主观性质以及评估过程中固有的潜在偏见。  <br />- 该研究依赖展览和拍卖数据，可能低估了非实物艺术形式，如行为艺术，因为这些艺术形式无法通过这些渠道捕捉。   <br />- 研究发现，在职业生涯早期在更广泛的机构展出可以提高突破的机会，这挑战了专注于特定领域或风格的传统观点。  <br />- 该研究建议在艺术界实施彩票系统或盲选程序，这些做法更常见于就业或音乐试演等领域。  <br />- 观察到艺术家的原籍国影响其初始声望和职业轨迹，这一点有悖常理，因为在全球化的艺术世界中，人们可能认为天赋与地理因素无关。<br />《Quantifying reputation and success in art | Science》 <a href="https://www.science.org/doi/10.1126/science.aau7224"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnrcnblrptj20u00x113j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 00:00:12 GMT</pubDate>
</item>
<item>
<title>【Cappy：用小型评分器提升大型语言模型性能】 - Google研究人员提出了一种名为Cappy的新方法，可以通过一个小型评分器(scorer)来提升和增强大型多任务语言模型...</title>
<link>https://weibo.com/1402400261/O54Dc9dTt</link>
<guid>https://weibo.com/1402400261/O54Dc9dTt</guid>
<content:encoded><![CDATA[
<div> Cappy, 小型评分器, 大型语言模型, 性能提升, 多任务, 输出质量, 灵活性, 高效性, 实际应用, 可扩展性

<br /><br />总结: 
Google研究人员提出了一种名为Cappy的新方法，通过引入一个小型评分器来提升和增强大型多任务语言模型的性能。Cappy利用评分器重新排序生成的候选输出，提高输出质量。评分器是一个轻量级神经网络模型，专门用于评估候选输出质量，并与大型语言模型结合。Cappy在多个基准测试中展现出优异性能，提高大型模型表现。该方法灵活性强，可与各种大型语言模型结合，适用于不同任务。尽管在基准测试中表现出色，实际应用场景中的效果和可扩展性还需进一步验证。Cappy的高效性和轻量设计或将受益于未来硬件发展，如专用AI加速器。然而，引入新的偏差和不确定性也需进一步研究和优化。Cappy为提高大型语言模型性能提供了新的范式。 <div>
【Cappy：用小型评分器提升大型语言模型性能】  <br />- Google研究人员提出了一种名为Cappy的新方法，可以通过一个小型评分器(scorer)来提升和增强大型多任务语言模型的性能。  <br />- Cappy利用一个小型评分器来重新排序大型语言模型生成的候选输出，从而提高输出质量。  <br />- 评分器是一个轻量级的神经网络模型，专门用于评估候选输出的质量，而不负责生成输出。  <br />- 在多个基准测试中，Cappy展现出优于大型语言模型的性能，同时也能够提升这些大型模型的表现。  <br />- Cappy的优势在于其高效性和灵活性，可以与各种大型语言模型相结合，并在不同任务上发挥作用。  <br />- 研究人员认为，Cappy为提高大型语言模型的性能和效率提供了一种新的范式。  <br /><br />思考：  <br />- Cappy的提出解决了大型语言模型在某些任务上表现不佳的问题，通过引入一个小型评分器来提升整体性能，这种思路值得关注。  <br />- 将生成和评估分离的方法使Cappy具有灵活性，可以与不同的大型模型相结合，提高了其适用范围。  <br />- 尽管Cappy在基准测试中表现出色，但其在实际应用场景中的效果和可扩展性仍有待进一步验证。  <br />- Cappy的高效性和轻量设计可能会受益于未来硬件的发展，如专用AI加速器等，从而进一步提升其性能。  <br />- 虽然Cappy旨在提高大型语言模型的性能，但其本身也可能引入新的偏差和不确定性，需要进一步研究和优化。<br />《Cappy: Outperforming and boosting large multi-task language models with a small scorer – Google Research Blog》 <a href="https://blog.research.google/2024/03/cappy-outperforming-and-boosting-large.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnrc7chdqkj21780go75q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc7csa3qj21jj0r3q63.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnrc7dkpzrj21jj0c6jv0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc7ffs7jj21jj0sw42p.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnrc7fyfiuj21hb0u0goi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:45:03 GMT</pubDate>
</item>
<item>
<title>【聊天机器人变身生产力助手：Command-R用Tool Use功能重塑业务工作流】- Cohere推出了Command-R模型的Tool Use功能，使语言模型能够与用户定义的工具交互，实现...</title>
<link>https://weibo.com/1402400261/O54B6h2pa</link>
<guid>https://weibo.com/1402400261/O54B6h2pa</guid>
<content:encoded><![CDATA[
<div> Command-R, Tool Use, 应用示例, 生产力助手, 跨平台, 自动化工作流程, 部署灵活性, 实施过程, AI应用, 语言模型

<br /><br />总结: 
Command-R推出了Tool Use功能，使语言模型能够与外部工具交互，执行复杂任务，提升生产力。该功能连接不同应用程序和系统，实现跨平台的自动化工作流程。结合Tool Use，Command-R从聊天机器人发展为强大的生产力助手和研究工具，可能改变AI交互方式。平衡了性能、效率和部署灵活性，适用于构建AI应用，突破了单一云环境的限制。企业实施Tool Use的简化四步过程降低了门槛，加速了应用，但需评估具体需求和系统兼容性。 <div>
【聊天机器人变身生产力助手：Command-R用Tool Use功能重塑业务工作流】<br />- Cohere推出了Command-R模型的Tool Use功能，使语言模型能够与用户定义的工具交互，实现高度复杂任务的自动化。  <br />- Command-R在Tool Use模式下可以根据用户交互和对话历史创建API负载(包含特定参数的JSON)，用于指示其他应用程序或工具。  <br />- Tool Use的应用示例包括自动分类和路由支持凭证、更新客户关系管理软件(CRM)中的状态，以及从向量数据库中检索相关片段。  <br />- 应用的输出会反馈给Command-R，用于生成最终响应。响应中包含引用，便于用户从源数据或工具结果中追溯声明。  <br />- Tool Use使Command-R的应用从简单的聊天机器人发展为强大的代理和研究工具，提高了生产力。  <br />- Command-R在高效率、强大性能和跨主要云提供商的灵活部署之间取得了平衡，是构建依赖Tool Use的AI应用的有竞争力的解决方案。  <br />- 在企业中实施Tool Use对开发人员来说是一个简单的四步过程。  <br /><br />思考：  <br />- Tool Use功能突破了语言模型仅限于自然语言处理的边界，使其能够与外部工具交互，执行复杂的任务和工作流程，开辟了语言模型应用的新领域。  <br />- Command-R与Tool Use的结合，使聊天机器人从简单的对话工具转变为强大的生产力助手和研究辅助工具，这可能改变我们与AI交互和协作的方式。  <br />- Tool Use通过自然语言交互连接不同的应用程序和系统，实现了跨平台的自动化工作流程，这种方法简化了复杂任务的自动化过程，提高了效率。  <br />- Command-R在性能、效率和部署灵活性方面的平衡，使其成为构建基于Tool Use的AI应用的理想选择，这表明语言模型的应用不再局限于单一的云环境。  <br />- 简化的四步实施过程降低了企业采用Tool Use的门槛，有望加速其在实际业务场景中的应用，但企业仍需评估其具体需求和现有系统的兼容性。<br />《Introducing Tool Use With Command-R: Seamlessly Automate Business Workflows》 <a href="https://txt.cohere.com/tool-use-with-command-r/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnrc23fa5bj20v40l83zo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc23o7u5j20qo0f00ue.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:39:53 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;携手@博文视点Broadview 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00...</title>
<link>https://weibo.com/1402400261/O54zSFqzU</link>
<guid>https://weibo.com/1402400261/O54zSFqzU</guid>
<content:encoded><![CDATA[
<div> SPSSAU、数据分析、研究方法、应用、科研、快速入门、知识类、视频讲解、研究者、学习

总结:<br /><br />今天开奖活动欢迎大家参与，“可可粉”转发+评论即可参与赢取《SPSSAU科研数据分析方法与应用》这本书。该书系统介绍了科研数据分析方法，包括数据分析入门、常用研究方法应用、数据综合评价与预测、问卷数据分析、医学数据分析等五个方面，涵盖了13个知识类应用，同时还附赠了171集配套视频讲解。这本书适合研究者快速学习和掌握科研数据分析方法，近万篇研究论文选择SPSSAU作为快速入门工具。截止日期为2024年3月15日。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00，*可可粉*转发+评论即可参与。近万篇研究论文选用SPSSAU快速入门，本书从数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等五个方面系统地介绍科研数据的分析方法，涉及13项知识类应用（如影响关系、权重关系、数据预测、问卷研究）附赠171集配套视频讲解，适合研究者快速学习和掌握科研数据分析方法。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5009557898134749"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnj8n91y6bj20m80m8n19.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnj8n9h45kj20m80m8mzs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9rlbnj20m80m8tbk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9wj7pj20m80m80vr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:36:53 GMT</pubDate>
</item>
<item>
<title>今日推介(第1345期)：基于在线偏好优化的大型语言模型与人类偏好对齐、自注意力的下一token预测机制 、持续预训练大型语言模型的简单可扩展策略、现代大规模数据...</title>
<link>https://weibo.com/1402400261/O548I0b8m</link>
<guid>https://weibo.com/1402400261/O548I0b8m</guid>
<content:encoded><![CDATA[
<div> 在线偏好优化、大型语言模型、人类偏好对齐、自注意力、下一token预测机制、持续预训练、简单可扩展策略、现代大规模数据集、偏差问题、过训练语言模型

总结:<br />
本篇文章介绍了基于在线偏好优化的大型语言模型与人类偏好对齐的方法，通过自注意力的下一token预测机制实现了优化。同时提出了一种简单可扩展的持续预训练大型语言模型的策略，探讨了现代大规模数据集是否还存在偏差问题，并研究了过训练语言模型在下游任务中的可靠性扩展。这些研究对于优化大型语言模型的训练方法和应用具有重要意义。 <div>
今日推介(第1345期)：基于在线偏好优化的大型语言模型与人类偏好对齐、自注意力的下一token预测机制 、持续预训练大型语言模型的简单可扩展策略、现代大规模数据集是否还存在偏差问题、过训练语言模型在下游任务中的可靠扩展 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687109258"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.15)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra0zsf8qj20k00aawf0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra126v1dj20k008gjsd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnra15w1cdj20k00c3mzg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra1b1fw5j20k00hsad3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra1dmuy3j20k00e1q56.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:29:56 GMT</pubDate>
</item>
<item>
<title>[CV] DAM: Dynamic Adapter Merging for Continual Video QA Learning 网页链接 介绍了一种名为DAM的视频问答(VidQA)持续学习方法，以解决灾难性遗忘问题、适应...</title>
<link>https://weibo.com/1402400261/O544i5YCV</link>
<guid>https://weibo.com/1402400261/O544i5YCV</guid>
<content:encoded><![CDATA[
<div> 动态适配器合并, 持续学习, VidQA, 适配器训练, 路由器函数, 跨域知识共享, 性能优于当前方法, 图像分类, 图像问答

总结:<br /><br />
这篇文章介绍了一种名为DAM的视频问答持续学习方法，旨在解决灾难性遗忘、适应新数据集、处理未知数据集输入以及促进跨域知识共享等挑战。DAM通过动态适配器合并，在训练过程中训练特定数据集的适配器并冻结预训练的视频语言骨干网络。在推理过程中，利用非参数路由器函数计算适配器相关性概率，动态合并适配器权重定制新的适配器实例进行VidQA预测，从而降低路由器预测不准确的影响并提升跨域知识共享。DAM在多个VidQA数据集上的表现优于当前持续学习方法，并在图像分类和图像问答任务上也具有明显优势。 <div>
[CV] DAM: Dynamic Adapter Merging for Continual Video QA Learning  <br /><a href="https://arxiv.org/abs/2403.08755"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为DAM的视频问答(VidQA)持续学习方法，以解决灾难性遗忘问题、适应持续到来的数据集、处理未知数据集的输入以及跨相似数据集域共享知识等挑战。DAM通过动态适配器合并，训练特定数据集的适配器并冻结预训练的视频语言骨干网络。推理时，DAM使用非参数路由器函数计算每个适配器的相关性概率，随后动态合并适配器权重，以定制新的适配器实例进行VidQA预测，从而降低路由器预测不准确的影响并促进跨域知识共享。DAM在多个VidQA数据集上的性能超过了当前最先进的持续学习方法，并且在图像分类和图像问答任务上也展现出显著优势。<img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9q1w748j212s1lm4i4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9q2da9lj21pc0zitl9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9q2wsp9j21pa1b6nc5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:19:03 GMT</pubDate>
</item>
<item>
<title>[CV] GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting 网页链接 介绍了一种名为GaussianImage的新的图像表示和压缩方...</title>
<link>https://weibo.com/1402400261/O541SxwIU</link>
<guid>https://weibo.com/1402400261/O541SxwIU</guid>
<content:encoded><![CDATA[
<div> GaussianImage, 2D高斯Splatting, GPU资源, 隐式神经表示, INR, 渲染算法, GPU内存占用, 拟合时间, 渲染速度, 向量量化技术

总结:<br /><br />该文章介绍了一种名为GaussianImage的新的图像表示和压缩方法，基于2D高斯Splatting技术。与依赖GPU资源且训练时间长的隐式神经表示(INR)不同，GaussianImage通过每个2D高斯的8个参数来表示图像，使用累积求和的新渲染算法。这一方法显著减少了GPU内存占用和拟合时间，同时提供了与INR相当的表示性能和更快的渲染速度。该方法配合现有向量量化技术的编解码器在实验中表现出与基于压缩的INR（如COIN和COIN++）相当的速率失真性能，同时实现了约1000 FPS的解码速度。初步概念验证显示，在使用部分比特回传编码时，该编解码器的性能超过了COIN和COIN++。 <div>
[CV] GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting  <br /><a href="https://arxiv.org/abs/2403.08551"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为GaussianImage的新的图像表示和压缩方法，基于2D高斯Splatting技术。不同于依赖GPU资源且训练时间长的隐式神经表示(INR)，GaussianImage通过每个2D高斯的8个参数来表示图像，用累积求和的新渲染算法。这一方法显著减少了GPU内存占用(至少减少3倍)和拟合时间(加快5倍)，同时提供了与INR相当的表示性能和更快的渲染速度(1500-2000 FPS)。此外，集成了现有向量量化技术的图像编解码器在实验中展现出了与基于压缩的INR(如COIN和COIN++)相当的速率失真性能，并实现了约1000 FPS的解码速度。初步概念验证还表明，使用部分比特回传编码时，该编解码器的性能超过了COIN和COIN++。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9jwd3olj213i1kw18a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9jwqeu2j21hq0t0qay.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr9jwv8uyj21hc0gudmi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr9jx0572j21ha0mi7a8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:13:07 GMT</pubDate>
</item>
<item>
<title>[CL] Gemma: Open Models Based on Gemini Research and Technology 网页链接 介绍了Google DeepMind团队开发的Gemma模型，这是一组基于Gemini研究和技术构建的...</title>
<link>https://weibo.com/1402400261/O53Z1zK3Y</link>
<guid>https://weibo.com/1402400261/O53Z1zK3Y</guid>
<content:encoded><![CDATA[
<div> Google DeepMind, Gemma, Gemini, 轻量, 开放, 性能, 安全性, Transformer, TPUv5e, 负责任
<br />
<br />
总结: 
Google DeepMind团队开发了基于Gemini研究和技术的Gemma模型，是一组轻量、开放的最新模型。Gemma在语言理解、推理和安全性方面表现出强大性能，在18项文本任务中有11项超越同等规模的开放模型。该模型使用了基于Transformer的架构，优化了多查询注意力、RoPE嵌入、GeGLU激活函数和RMSNorm等技术，并使用TPUv5e硬件和分布式系统技术进行训练。发布了规模为20亿和70亿参数的两种模型，提供了预训练和微调检查点。强调了负责任发布大型语言模型对提升安全性、促进技术公平获取和驱动创新的重要性。对模型的安全性和负责任也进行了全面评估。 <div>
[CL] Gemma: Open Models Based on Gemini Research and Technology  <br /><a href="https://arxiv.org/abs/2403.08295"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了Google DeepMind团队开发的Gemma模型，这是一组基于Gemini研究和技术构建的轻量、开放的最新模型。Gemma在语言理解、推理和安全性方面在学术基准测试中展现出强大的性能。发布了两种规模的模型(20亿和70亿参数)，提供了预训练和微调的检查点。Gemma在18项文本任务中的11项上超越了同等规模的开放模型，并对模型的安全性和负责任进行了全面评估。Gemma利用了基于Transformer的架构，优化了多查询注意力、RoPE嵌入、GeGLU激活函数和RMSNorm等技术。训练使用了TPUv5e硬件和先进的分布式系统技术。强调了负责任发布大型语言模型(LLM)对于提升前沿模型安全性、促进技术公平获取、严格评估现有技术和驱动创新的重要性。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9ckrwzaj215e1ia7qg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9cl1imxj21ee0suwjs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9clc1n5j20p40n6adb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9clj4cfj20pc0ksgoa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:06:05 GMT</pubDate>
</item>
<item>
<title>创新地研究了在过训练情况下的语言模型扩展律，并建立了模型困惑度与其在下游任务表现之间的关联，提供了在减少计算成本的同时有效预测模型表现的方法，挑战了只...</title>
<link>https://weibo.com/1402400261/O53WGwMw8</link>
<guid>https://weibo.com/1402400261/O53WGwMw8</guid>
<content:encoded><![CDATA[
<div> 扩展律、语言模型、过训练、模型困惑度、下游任务、关联、计算成本、预测、模型表现、传统观点

<br /><br />总结：
该研究创新地研究了语言模型在过训练情况下的扩展律，并建立了模型困惑度与在下游任务表现之间的关联。提供了一种方法，在减少计算成本的同时有效预测模型表现，挑战了传统观点认为只有在计算最优训练阶段才能应用扩展律的观点。Researchers在此研究中展示了语言模型在过训练时表现稳定，并且其性能与下游任务的表现存在关联。他们的研究结果具有实践意义，可以帮助在研究领域中更有效地运用语言模型。 <div>
创新地研究了在过训练情况下的语言模型扩展律，并建立了模型困惑度与其在下游任务表现之间的关联，提供了在减少计算成本的同时有效预测模型表现的方法，挑战了只有在计算最优训练阶段才能应用扩展律的传统观点。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University &amp; UT Austin &amp; Apple] (2024) <a href="https://arxiv.org/abs/2403.08540"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96ao77pj21ga0qanai.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96b57p7j21my15caoy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96bitojj21n61167jj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96c1k8zj21mi0xo49l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyggij210z0ken19.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz8taj21120ir78f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gyotij21120lln0l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gz5nqj21170oktd1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz9y5j21110fkacs.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:00:19 GMT</pubDate>
</item>
<item>
<title>[CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University...</title>
<link>https://weibo.com/1402400261/O53WE06Ly</link>
<guid>https://weibo.com/1402400261/O53WE06Ly</guid>
<content:encoded><![CDATA[
<div> Language models, scale, over-training, downstream tasks, reliability, Columbia University, UT Austin, Apple

<br /><br />总结:
这篇文章研究了语言模型在超过训练规模以及在下游任务中的表现，发现语言模型在这些情况下能够可靠地扩展，通过在哥伦比亚大学、德克萨斯大学奥斯汀分校和苹果公司的合作进行了实验。他们的研究结果为语言模型的发展提供了有益的参考，为今后的研究和应用提供了新的思路。 <div>
[CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University &amp; UT Austin &amp; Apple] (2024) <a href="https://arxiv.org/abs/2403.08540"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96ao77pj21ga0qanai.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96b57p7j21my15caoy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96bitojj21n61167jj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96c1k8zj21mi0xo49l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyggij210z0ken19.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz8taj21120ir78f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gyotij21120lln0l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gz5nqj21170oktd1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz9y5j21110fkacs.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gypmlj210y0hg42h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96h0bszj210z0umjxf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gzuksj21120pbafd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gzkggj21110j1whm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gypocj21110j1who.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyc00j21120domzf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96h0emmj21131blqc1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:00:13 GMT</pubDate>
</item>
</channel>
</rss>