<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>爱可可-爱生活的微博</title>
<link>https://weibo.com/1402400261/</link>

<item>
<title>《爱可可微博热门分享(5.3)》 爱可可微博热门分享(5.3) [图片]</title>
<link>https://weibo.com/1402400261/OcCgM7Lx6</link>
<guid>https://weibo.com/1402400261/OcCgM7Lx6</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、5.3、情感、互动、用户、内容、平台

<br><br>总结：
爱可可微博是一个热门的分享平台，用户可以在上面互动并分享各种情感内容。5.3的微博内容受到了用户们的热烈关注，引发了许多讨论和转发。通过这个平台，用户们可以分享自己的心情和观点，从而拉近彼此之间的距离。爱可可微博的热门内容吸引了大量用户参与，形成了一个充满情感交流的社区。 <div>
《爱可可微博热门分享(5.3)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405030070484861015"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(5.3)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpcoq03vwjj20qo0f0tcq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 03 May 2024 14:15:20 GMT</pubDate>
<pubDate>Fri, 03 May 2024 14:15:20 GMT</pubDate>
</item>

<item>
<title>几篇论文实现代码：《SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training》(ICLR 2024) GitHub: github.com/deep-symbolic-ma...</title>
<link>https://weibo.com/1402400261/OczVqcJv0</link>
<guid>https://weibo.com/1402400261/OczVqcJv0</guid>
<content:encoded><![CDATA[
<div> 深度符号数学、多模态数学预训练、车辆路径求解、多任务学习、三维人体动作生成、超分辨率、语义分割、少样本学习、相机标定、自注意力、主题相关性、线性探测、SLAM工具、视频生成、预测、数据合成、身份保持、深度神经网络

总结:<br /><br />
《SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training》介绍了一种统一的预训练方法，旨在将数学符号和数值领域进行融合，为深度符号数学提供基础。研究团队提出了一个名为MVMoE的多任务车辆路径求解模型，利用专家混合策略提高模型性能。另外，通过多轨道时间线控制，实现了基于文本驱动的三维人体动作生成。针对超分辨率问题，提出了Boosting Flow-based Generative Super-Resolution Models via Learned Prior的方法。在语义分割领域，Open-Vocabulary Attention Maps with Token Optimization for Semantic Segmentation in Diffusion Models的技术有望取得较好效果。LP++是一个针对少样本学习的线性探测器，在CLIP模型上取得出色性能。通过提出的无偏估计方法，可以更好地进行相机标定。StoryDiffusion提出了一种一致的自注意力机制，用于生成长距离的图像和视频。ThemeStation是一个能够从少量示例中生成主题相关的3D资产的方法。另外，Rethinking LLM Memorization through the Lens of Adversarial Compression展示了对LLM记忆的重新思考。Kolmogorov-Arnold Network和VRP-SAM技术的提出也值得关注。Latte是一种用于视频生成的隐式扩散变换器。VimTS是一个统一的视频和图像文本识别器，可增强跨领域泛化。MambaMIL通过序列重新排序来增强长序列建模，在计算病理学中有潜在应用。StockMixer是一种简单而有效的基于MLP的股价预测架构。此外，Differentially Private Synthetic Data via Foundation Model APIs 2: Text提出了通过基础模型API生成差异化私有合成数据的方法。最后，ConsistentID实现了多模态细粒度身份保持的人像生成。 <div>
几篇论文实现代码：<br />《SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training》(ICLR 2024) GitHub: github.com/deep-symbolic-mathematics/Multimodal-Math-Pretraining [fig3]<br />《MVMoE: Multi-Task Vehicle Routing Solver with Mixture-of-Experts》(ICML 2024) GitHub: github.com/RoyalSkye/Routing-MVMoE [fig8]<br />《Multi-Track Timeline Control for Text-Driven 3D Human Motion Generation》(CVPR 2024) GitHub: github.com/nv-tlabs/stmc [fig1]<br />《Boosting Flow-based Generative Super-Resolution Models via Learned Prior》(CVPR 2024) GitHub: github.com/liyuantsao/FlowSR-LP [fig4]<br />《Open-Vocabulary Attention Maps with Token Optimization for Semantic Segmentation in Diffusion Models》(CVPR 2024) GitHub: github.com/vpulab/ovam [fig9]<br />《LP++: A Surprisingly Strong Linear Probe for Few-Shot CLIP》(CVPR 2024) GitHub: github.com/FereshteShakeri/FewShot-CLIP-Strong-Baseline<br />《Unbiased Estimator for Distorted Conic in Camera Calibration》(CVPR 2024) GitHub: github.com/ChaehyeonSong/discocal<br />《StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation》(2024) GitHub: github.com/HVision-NKU/StoryDiffusion<br />《ThemeStation: Generating Theme-Aware 3D Assets from Few Exemplars》(2024) GitHub: github.com/3DTopia/ThemeStation [fig2]<br />《Rethinking LLM Memorization through the Lens of Adversarial Compression》(2024) GitHub: github.com/locuslab/acr-memorization<br />《Kolmogorov-Arnold Network》(2024) GitHub: github.com/Blealtan/efficient-kan<br />《VRP-SAM: SAM with Visual Reference Prompt》(CVPR 2024) GitHub: github.com/syp2ysy/VRP-SAM [fig5]<br />《Latte: Latent Diffusion Transformer for Video Generation》(2024) GitHub: github.com/lyogavin/train_your_own_sora [fig6]<br />《OpenXRLab Deep-learning based SLAM Toolbox and Benchmark》(2024) GitHub: github.com/openxrlab/xrdslam<br />《VimTS: A Unified Video and Image Text Spotter for Enhancing the Cross-domain Generalization》(2024) GitHub: github.com/Yuliang-Liu/VimTS [fig7]<br />《MambaMIL: Enhancing Long Sequence Modeling with Sequence Reordering in Computational Pathology》(2024) GitHub: github.com/isyangshu/MambaMIL [fig10]<br />《StockMixer: A Simple yet Strong MLP-based Architecture for Stock Price Forecasting》(2024) GitHub: github.com/SJTU-Quant/StockMixer [fig11]<br />《Differentially Private Synthetic Data via Foundation Model APIs 2: Text》(2024) GitHub: github.com/AI-secure/aug-pe<br />《ConsistentID: Portrait Generation with Multimodal Fine-Grained Identity Preserving》(2024) GitHub: github.com/JackAILab/ConsistentID<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpcd55bj2pj25ut1i94qq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpcd5eebvyj22oq0zau0x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpcd5wya9cj219y0munls.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpcd6641wyj21mc0ko7m5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpcd6re8efj21jt18m1bz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpcd77bhayj21a20n2wrz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpcdo910e6j20w50dd49f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpcdqomh8ej21ca0dm7bh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpcdv00rwvj228q0uy7gr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpcdvp0xz5j2246112hdt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpcdzavinij20xo0d37b5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 03 May 2024 08:17:14 GMT</pubDate>
</item>
<item>
<title>【Time Series Analysis with Python：开源的 Python 时间序列分析课程，提供丰富的 Jupyter Notebooks和资料】'Time Series Analysis with Python - Notebooks ...</title>
<link>https://weibo.com/1402400261/OczSpy9Mj</link>
<guid>https://weibo.com/1402400261/OczSpy9Mj</guid>
<content:encoded><![CDATA[
<div> 时间序列分析, Python, 开源, Jupyter Notebooks, 资料
<br />
本文介绍了开源的 Python 时间序列分析课程，提供丰富的 Jupyter Notebooks和资料。课程包括对时间序列分析的讲解以及相关的实践代码和案例分析，帮助读者快速掌握时间序列分析的基本概念和技能。通过 GitHub 上的项目链接，读者可以轻松地访问课程的 Jupyter Notebooks 和资料，深入学习和实践时间序列分析领域的知识。这个课程对于希望提升时间序列分析能力的人员来说是一个非常有用的学习资源，可以帮助他们更好地理解和应用时间序列分析技术。总的来说，这个开源的 Python 时间序列分析课程为学习者提供了一个系统全面的学习平台，帮助他们掌握时间序列分析的核心概念和技能。<br /><br />总结: 时间序列分析课程提供丰富的Jupyter Notebooks和资料，帮助学习者快速掌握时间序列分析的基本概念和技能，对于提升时间序列分析能力非常有用。 <div>
【Time Series Analysis with Python：开源的 Python 时间序列分析课程，提供丰富的 Jupyter Notebooks和资料】'Time Series Analysis with Python - Notebooks for the course "Time series analysis with Python"' GitHub: github.com/FilippoMB/python-time-series-handbook <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpce5r9o74j21420u0wi3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 03 May 2024 08:09:49 GMT</pubDate>
</item>
<item>
<title>【AubAI：一个开源的Flutter/Dart包，旨在为移动应用提供先进的本地生成式AI(gen-AI)模型，包括离线文本生成等功能】'AubAI - AubAI brings you on-device gen-A...</title>
<link>https://weibo.com/1402400261/OczPrtNwE</link>
<guid>https://weibo.com/1402400261/OczPrtNwE</guid>
<content:encoded><![CDATA[
<div> GitHub, 开源, Flutter, Dart, 移动应用, 本地生成式AI, 离线文本生成, gen-AI<br />
<br />
总结：<br />
AubAI是一个开源的Flutter/Dart包，旨在为移动应用提供先进的本地生成式AI(gen-AI)模型。它包括离线文本生成等功能，可以在应用中直接使用。开发者可以通过GitHub获取该包的源代码，从而在自己的应用中添加本地AI生成功能。这将使移动应用在不需要联网的情况下也能够进行文本生成等操作，提升用户体验。 <div>
【AubAI：一个开源的Flutter/Dart包，旨在为移动应用提供先进的本地生成式AI(gen-AI)模型，包括离线文本生成等功能】'AubAI - AubAI brings you on-device gen-AI capabilities, including offline text generation and more, directly within your app.' GitHub: github.com/BrutalCoding/aub.ai <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpcdy9ccnoj20xx0u0dkf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 03 May 2024 08:02:30 GMT</pubDate>
</item>
<item>
<title>【Agentic RAG Support Bot：展示了如何利用Redis和LlamaIndex创建一个专为雪佛兰汽车定制的客户支持聊天机器人】'Agentic RAG Support Bot' GitHub: github.com...</title>
<link>https://weibo.com/1402400261/OczNU6EB6</link>
<guid>https://weibo.com/1402400261/OczNU6EB6</guid>
<content:encoded><![CDATA[
<div> Redis、LlamaIndex、客户支持、雪佛兰汽车、聊天机器人、GitHub、定制、Agentic RAG Support Bot

<br /><br />总结:
文章介绍了如何利用Redis和LlamaIndex创建一个专为雪佛兰汽车定制的客户支持聊天机器人。这个项目是通过GitHub上的'Agentic RAG Support Bot'实现的。通过搭建这个聊天机器人，可以提供更好的客户支持，为雪佛兰汽车用户提供定制化的服务。Redis和LlamaIndex技术的运用使得整个项目更加高效和智能。 <div>
【Agentic RAG Support Bot：展示了如何利用Redis和LlamaIndex创建一个专为雪佛兰汽车定制的客户支持聊天机器人】'Agentic RAG Support Bot' GitHub: github.com/redis-developer/agentic-rag <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpcdu1vj7hj20wj0u042z.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpcdu4ohigj21fi0e2n1c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 03 May 2024 07:58:41 GMT</pubDate>
</item>
<item>
<title>【python-ffmpeg：为 FFmpeg 提供同步和异步 API 的 Python 绑定库】'python-ffmpeg - A python binding for FFmpeg which provides sync and async APIs' GitHu...</title>
<link>https://weibo.com/1402400261/OczMf5I1v</link>
<guid>https://weibo.com/1402400261/OczMf5I1v</guid>
<content:encoded><![CDATA[
<div> FFmpeg, Python binding, 同步API, 异步API, GitHub, jonghwanhyeon, 库, 视频处理, 多媒体, 开源<br />
<br />
总结:<br />
本文介绍了一个名为python-ffmpeg的库，它是FFmpeg的Python绑定，提供了同步和异步API。用户可以在GitHub上找到该项目，由用户jonghwanhyeon开发。这个库可以帮助用户处理视频和多媒体文件，并且是开源的。 <div>
【python-ffmpeg：为 FFmpeg 提供同步和异步 API 的 Python 绑定库】'python-ffmpeg - A python binding for FFmpeg which provides sync and async APIs' GitHub: github.com/jonghwanhyeon/python-ffmpeg <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpcdpssinyj212o0g4405.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 03 May 2024 07:54:37 GMT</pubDate>
</item>
<item>
<title>【lms：开源的命令行工具，用于在终端管理和操作LM Studio项目】’lms - LM Studio in your terminal' GitHub: github.com/lmstudio-ai/lms #开源# #机器学习# #...</title>
<link>https://weibo.com/1402400261/OczK3zoTR</link>
<guid>https://weibo.com/1402400261/OczK3zoTR</guid>
<content:encoded><![CDATA[
<div> LM Studio、开源、命令行工具、终端、管理、操作、GitHub、lmstudio-ai、项目、lms<br />
<br />
LM Studio推出了一个开源命令行工具lms，可以在终端中管理和操作LM Studio项目。用户可以在GitHub上找到该工具的代码库github.com/lmstudio-ai/lms。这个工具可以让用户更方便地使用LM Studio项目，提高工作效率。 <div>
【lms：开源的命令行工具，用于在终端管理和操作LM Studio项目】’lms - LM Studio in your terminal' GitHub: github.com/lmstudio-ai/lms <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpcdk3mughj20pw0k8abb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 03 May 2024 07:49:14 GMT</pubDate>
</item>
<item>
<title>【The Gowebly CLI：开源的下一代命令行工具，旨在简化使用Go语言后端和流行CSS框架前端的Web应用开发】'The Gowebly CLI - A next-generation CLI tool that ma...</title>
<link>https://weibo.com/1402400261/OczJGxBRu</link>
<guid>https://weibo.com/1402400261/OczJGxBRu</guid>
<content:encoded><![CDATA[
<div> CLI、下一代、简化、Web应用开发、Go语言后端、流行CSS框架前端、htmx、hyperscript、Alpine.js、GitHub
<br /><br />总结:
Gowebly CLI是一个开源的下一代命令行工具，旨在简化使用Go语言后端和流行CSS框架前端的Web应用开发。通过该工具，开发者可以轻松创建令人惊艳的Web应用程序，在后端使用Go语言，并在前端使用htmx、hyperscript或Alpine.js等流行的工具和框架。该项目的GitHub地址是github.com/gowebly/gowebly。 <div>
【The Gowebly CLI：开源的下一代命令行工具，旨在简化使用Go语言后端和流行CSS框架前端的Web应用开发】'The Gowebly CLI - A next-generation CLI tool that makes it easy to create amazing web applications with Go on the backend, using htmx, hyperscript or Alpine.js, and the most popular CSS frameworks on the frontend.' GitHub: github.com/gowebly/gowebly <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpcdjh0i5uj20vc0u0diz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 03 May 2024 07:48:18 GMT</pubDate>
</item>
<item>
<title>【Chainloop：开源的软件供应链元数据仓库，用于管理 SBOMs、VEX、SARIF 文件、QA reports等】'Chainloop - Chainloop is an Open Source Metadata Vault for yo...</title>
<link>https://weibo.com/1402400261/OczHPapyT</link>
<guid>https://weibo.com/1402400261/OczHPapyT</guid>
<content:encoded><![CDATA[
<div> Chainloop, 开源, 软件供应链, 元数据仓库, 管理, SBOMs, VEX, SARIF 文件, QA reports

<br /><br />总结:
Chainloop是一个开源的软件供应链元数据仓库，主要用于管理SBOMs、VEX、SARIF文件、QA报告等。用户可以使用Chainloop来存储和管理与软件供应链相关的元数据，帮助他们更好地跟踪和管理软件开发过程中涉及的各种文件和报告。通过Chainloop，用户可以方便地查看和管理软件供应链的各个环节，提高项目的可追溯性和质量管理水平。Chainloop的开源性也为用户提供了更大的灵活性和可定制性，使其能够根据自身需求进行定制和扩展。 <div>
【Chainloop：开源的软件供应链元数据仓库，用于管理 SBOMs、VEX、SARIF 文件、QA reports等】'Chainloop - Chainloop is an Open Source Metadata Vault for your Software Supply Chain metadata, SBOMs, VEX, SARIF files, QA reports, and more.' GitHub: github.com/chainloop-dev/chainloop <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hpcdeoix9rj20vo0u0tdj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpcdepbghij21290kqmzp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 03 May 2024 07:43:44 GMT</pubDate>
</item>
<item>
<title>【大模型白盒子构建指南：旨在从零开始手写代码，深入理解并实践大型语言模型（LLM）的构建，包括模型结构、RAG、Agent和Eval任务】'大模型白盒子构建指南 - 一...</title>
<link>https://weibo.com/1402400261/OczHeCo5F</link>
<guid>https://weibo.com/1402400261/OczHeCo5F</guid>
<content:encoded><![CDATA[
<div> GitHub, 大型语言模型, 模型结构, RAG, Agent, Eval任务, 手写代码, 指南, 理解, 实践

<br /><br />总结:
本篇文章是一篇关于大型语言模型（LLM）的构建指南，旨在从零开始手写代码，深入理解并实践如何构建一个Tiny-Universe模型。文章介绍了模型结构的概念，RAG模型、Agent和Eval任务的相关内容，并提供了GitHub链接供读者参考。通过本文的指导，读者可以学习如何从头开始构建一个大型语言模型，提升对模型结构和相关任务的理解和实践能力。 <div>
【大模型白盒子构建指南：旨在从零开始手写代码，深入理解并实践大型语言模型（LLM）的构建，包括模型结构、RAG、Agent和Eval任务】'大模型白盒子构建指南 - 一个全手搓的Tiny-Universe' GitHub: github.com/datawhalechina/tiny-universe <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpcdd0jhrzj20u00zs43h.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hpcdd1payij20zk0k0djc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpcdd376ihj217d0pa102.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hpcdd4se9aj21070u0gxw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpcdd60t50j20wi0p6q5g.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 03 May 2024 07:42:17 GMT</pubDate>
</item>
<item>
<title>【Pareas：为简单编程语言设计的 GPU 加速编译器，能输出 RISC-V 机器代码】'Pareas - GPU-accelerated compiler' GitHub: github.com/Snektron/pareas #开源# [...</title>
<link>https://weibo.com/1402400261/OczG0hG1M</link>
<guid>https://weibo.com/1402400261/OczG0hG1M</guid>
<content:encoded><![CDATA[
<div> GitHub, Pareas, GPU 加速编译器, RISC-V 机器代码, 设计, 简单编程语言

<br /><br />总结:
Pareas是一个为简单编程语言设计的GPU加速编译器。它具有能够输出RISC-V机器代码的功能，并在GitHub上开源。通过使用Pareas，开发人员可以设计和编写更简单的编程语言，并利用GPU加速来提高编译速度和性能。该编译器的设计旨在使编程变得更加简单和高效，为开发人员提供更好的编程体验。 <div>
【Pareas：为简单编程语言设计的 GPU 加速编译器，能输出 RISC-V 机器代码】'Pareas - GPU-accelerated compiler' GitHub: github.com/Snektron/pareas <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpcda20dojj21740sytcm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 03 May 2024 07:39:15 GMT</pubDate>
</item>
<item>
<title>【Kaggle上由LMSYS组织的“Chatbot Arena Human Preference Predictions”竞赛，旨在通过机器学习模型预测用户在聊天机器人生成的答案中更偏好哪一个】- 竞赛目...</title>
<link>https://weibo.com/1402400261/OcwIAqTM4</link>
<guid>https://weibo.com/1402400261/OcwIAqTM4</guid>
<content:encoded><![CDATA[
<div> LMSYS, Chatbot Arena, 竞赛, 机器学习模型, 用户偏好, 聊天机器人, 数据集, 评估标准, 提交要求, 奖项设置

<br /><br />总结:
Kaggle上LMSYS组织了"Chatbot Arena Human Preference Predictions"竞赛，旨在通过机器学习模型预测用户在聊天机器人生成的答案中更偏好哪一个。竞赛的数据集来自Chatbot Arena收集的用户与两个匿名LLM驱动的聊天机器人对话数据。这个竞赛的重要性在于改善聊天机器人与人类的互动，确保机器人的回答更符合人类的偏好。提交的模型将根据预测概率与实际值之间的对数损失进行评估，必须通过Notebooks提交，并且需满足特定运行时和互联网访问限制。竞赛设有总奖金为10万美元，包括第一名25000美元，第二名和第三名各20000美元，第四名和第五名各15000美元。 <div>
【Kaggle上由LMSYS组织的“Chatbot Arena Human Preference Predictions”竞赛，旨在通过机器学习模型预测用户在聊天机器人生成的答案中更偏好哪一个】<br />- 竞赛目的：预测用户在两个由大型语言模型(LLM)驱动的聊天机器人之间的一对一比较中更偏好哪个回答。  <br />- 数据集来源：Chatbot Arena收集的对话数据，用户与两个匿名LLM聊天并选择他们更喜欢的答案。  <br />- 竞赛重要性：有助于改善聊天机器人与人类的互动，确保机器人的回答更符合人类的偏好。  <br />- 评估标准：提交的模型将基于预测概率与实际值之间的对数损失进行评估。  <br />- 提交要求：必须通过Notebooks提交，并且满足特定运行时和互联网访问限制。  <br />- 奖项设置：总奖金为10万美元，包括第一名25000美元，第二名和第三名各20000美元，以及第四名和第五名各15000美元。  <br />《LMSYS - Chatbot Arena Human Preference Predictions | Kaggle》 <a href="https://www.kaggle.com/competitions/lmsys-chatbot-arena"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hpc07vod3fj216p0u0wio.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 03 May 2024 00:07:22 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型应用指南》，截至2024.5.9 12:00，*可可...</title>
<link>https://weibo.com/1402400261/OcwGz8AQT</link>
<guid>https://weibo.com/1402400261/OcwGz8AQT</guid>
<content:encoded><![CDATA[
<div> 大语言模型、人工智能、基础、应用、神经网络、自然语言处理、交互格式、提示工程、GPT、安全技术

<br /><br />总结:
本文介绍了《大语言模型应用指南》的内容，分为四个部分：1. 夯实基础，包括机器学习、神经网络、自然语言处理等基础知识；2. 实践应用，涵盖交互格式、提示工程、工作记忆与长短期记忆等内容；3. 拓宽边界，涉及无梯度优化、自主Agent系统、大语言模型微调及安全技术等方面；4. 洞见未来，讨论多模态大语言模型、压缩即智能、图灵机与大语言模型的关联等。该指南对人工智能小白读者非常友好，逐步介绍了大语言模型的各个方面，帮助读者全面了解和应用大语言模型技术。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型应用指南》，截至2024.5.9 12:00，*可可粉*转发+评论即可参与。一本对人工智能小白读者非常友好的大语言模型应用指南，第1篇夯实基础，探索机器学习、神经网络、自然语言处理和大语言模型的基础。第2篇实践应用，包括交互格式、提示工程、工作记忆与长短期记忆，外部工具和GPTs的开发。第3篇拓宽边界，涵盖无梯度优化、自主Agent系统、大语言模型微调以及安全技术等。第4篇洞见未来，探讨多模态大语言模型、尺度定律、压缩即智能、图灵机与大语言模型的关联等。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpat58zigtj20m80m8myr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpat89xztmj20m80m8whk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpat8ab08qj20m80m80up.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpat8bjhzkj20m80m8q52.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpat8c7vsej20m80m8dhx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpat8e5u7oj20m80m8gob.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 03 May 2024 00:02:23 GMT</pubDate>
</item>
<item>
<title>今日推介(第1394期)：面向语言模型对齐的自弈偏好优化、用小学算术仔细检验大语言模型性能、神经加性模型的可解释自动评分、多群鲁棒性、基于长上下文模型的上下...</title>
<link>https://weibo.com/1402400261/Ocw6g2UP9</link>
<guid>https://weibo.com/1402400261/Ocw6g2UP9</guid>
<content:encoded><![CDATA[
<div> 面向语言模型对齐 自弈偏好优化 小学算术 大语言模型 神经加性模型 可解释 自动评分 多群 鲁棒性 长上下文模型 上下文学习 深入探索 

总结:<br /><br />本文介绍了面向语言模型对齐的自弈偏好优化方法，利用小学算术对大语言模型性能进行仔细检验。同时探讨了神经加性模型的可解释性自动评分以及多群鲁棒性方面的相关内容。对基于长上下文模型的上下文学习进行了深入探索。文章内容涵盖了语言模型优化、性能检验、可解释性评分、鲁棒性和上下文学习等方面的重要内容。 <div>
今日推介(第1394期)：面向语言模型对齐的自弈偏好优化、用小学算术仔细检验大语言模型性能、神经加性模型的可解释自动评分、多群鲁棒性、基于长上下文模型的上下文学习(ICL)的深入探索 公·众·号：爱可可爱生活 <a href="http://aicoco.net/s/8v"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hpbxhathb4j21ji0pe0xi.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpbxhd79a3j20wk0u0q86.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpbxhh8nc4j20yy0twtax.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpbxhk55efj21ju0p242l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpbxhmza75j21be0qiael.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 22:32:56 GMT</pubDate>
</item>
<item>
<title>[LG] A Survey on Deep Active Learning: Recent Advances and New Frontiers 网页链接 对深度学习主动学习(DAL)进行了全面的分类和分析，回顾了其应用，总结了...</title>
<link>https://weibo.com/1402400261/Ocw1SwAqd</link>
<guid>https://weibo.com/1402400261/Ocw1SwAqd</guid>
<content:encoded><![CDATA[
<div> 主动学习 深度学习 DAL 应用 挑战 发展方向<br />
<br />
主动学习是一种能够在数据标注成本高昂的情况下有效利用有限标注数据的机器学习技术。深度学习主动学习结合了深度学习和主动学习的优点，取得了显著的研究进展和广泛应用。本文对深度学习主动学习进行了全面的分类和分析，回顾了其应用领域，并总结了主要的挑战，如标注数据的稀缺性和模型的泛化能力等。同时，文章提出了未来研究的发展方向，包括如何提高主动学习算法的效率和准确性，以及如何结合自监督学习和增强学习等技术来进一步推动深度学习主动学习的发展。综上所述，深度学习主动学习是一个备受关注的研究领域，未来将在理论和实践中不断取得新的突破和进展。<br /><br />总结:深度学习主动学习结合了深度学习和主动学习的优点，取得了显著的研究进展和广泛应用，未来的发展方向包括提高算法效率和准确性，结合其他技术推动发展。 <div>
[LG] A Survey on Deep Active Learning: Recent Advances and New Frontiers  <br /><a href="https://arxiv.org/abs/2405.00334"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />对深度学习主动学习(DAL)进行了全面的分类和分析，回顾了其应用，总结了主要挑战，并对未来的发展方向提出了见解。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbx6e1jjpj20xk18q7pd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpbx6e7xpcj20tu0h6n11.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbx6eo9fnj20ue0kajvm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 22:22:09 GMT</pubDate>
</item>
<item>
<title>[CL] A Primer on the Inner Workings of Transformer-based Language Models 网页链接 通过残差流视角整合地介绍Transformer语言模型架构，并全面综述相关的可...</title>
<link>https://weibo.com/1402400261/OcvYQhSrF</link>
<guid>https://weibo.com/1402400261/OcvYQhSrF</guid>
<content:encoded><![CDATA[
<div> Transformer语言模型、残差流、可解释性技术、内部工作机制、架构

<br /><br />总结:
本文介绍了Transformer语言模型的架构及其内部工作机制，通过残差流视角整合，全面综述了相关的可解释性技术。Transformer语言模型采用自注意力机制，能有效处理长距离依赖关系，同时通过堆叠多个Transformer模块来进行表示学习。可解释性技术包括注意力可视化和梯度基于的方法，有助于理解模型决策的依据。研究显示，Transformer语言模型在自然语言处理任务中取得了显著的性能提升，同时可解释性技术也揭示了模型对输入的关注点与重要性。通过深入理解Transformer模型的内部工作机制，可以为模型的优化和应用提供重要的指导。 <div>
[CL] A Primer on the Inner Workings of Transformer-based Language Models  <br /><a href="https://arxiv.org/abs/2405.00208"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过残差流视角整合地介绍Transformer语言模型架构，并全面综述相关的可解释性技术以及它们发现的内部工作机制。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpbwyliy9wj20q41667dn.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwyltezlj21b80zu7bn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbwym3jv0j21bc0j0dj5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 22:14:39 GMT</pubDate>
</item>
<item>
<title>通过大规模实验对长上下文中的ICL行为进行了深入探索，发现与短上下文ICL相比，可以提供惊人的性能提升，对示例的质量和顺序要求较低，在某些场景下可作为检索和...</title>
<link>https://weibo.com/1402400261/OcvVZ0isP</link>
<guid>https://weibo.com/1402400261/OcvVZ0isP</guid>
<content:encoded><![CDATA[
<div> 提取关键词：大规模实验、ICL行为、长上下文、性能提升、质量要求、检索、微调、深入探索、示例、顺序要求

总结:
<br /><br />本文通过大规模实验深入探索了长上下文中的ICL行为，发现相比于短上下文ICL，长上下文ICL可以提供惊人的性能提升，对示例的质量和顺序要求较低，在某些场景下可作为检索和微调的有力替代。该研究由Bertsch等人在2024年发表，开展了对ICL行为的全面探究，结果表明长上下文对于提高模型性能和适用性至关重要。这一发现将有望在自然语言处理领域产生重大影响，为进一步研究提供了新的方向和启示。 <div>
通过大规模实验对长上下文中的ICL行为进行了深入探索，发现与短上下文ICL相比，可以提供惊人的性能提升，对示例的质量和顺序要求较低，在某些场景下可作为检索和微调的有力替代。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《In-Context Learning with Long-Context Models: An In-Depth Exploration》A Bertsch, M Ivgi, U Alon, J Berant, M R. Gormley, G Neubig [CMU &amp; Tel Aviv University] (2024) <a href="https://arxiv.org/abs/2405.00200"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwl2i46xj214e0sq4ab.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwl34ek1j21be0qiafw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwl3j5wsj21c00tiq9q.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbwl3mr67j21aw0osjx9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbwr40zvhj20vd0ghdhx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpbwr413iij20vi0i3tax.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwr424zmj20g70g8aat.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwr40h34j20ve089mye.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpbwr41wr5j20vh15vq6u.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 02 May 2024 22:07:37 GMT</pubDate>
</item>
<item>
<title>[CL]《In-Context Learning with Long-Context Models: An In-Depth Exploration》A Bertsch, M Ivgi, U Alon, J Berant, M R. Gormley, G Neubig [CMU &amp; Tel Av...</title>
<link>https://weibo.com/1402400261/OcvVUAiNp</link>
<guid>https://weibo.com/1402400261/OcvVUAiNp</guid>
<content:encoded><![CDATA[
<div> 关键词: In-Context Learning, Long-Context Models, Bertsch, Ivgi, Alon, Berant, Gormley, Neubig, CMU, Tel Aviv University

总结:<br /><br />本文深入探讨了使用长上下文模型进行上下文学习的方法。研究团队来自CMU和以色列特拉维夫大学，包括Bertsch、Ivgi、Alon、Berant、Gormley和Neubig。他们提出了一种利用长上下文模型进行上下文学习的方法，以提高自然语言处理任务的性能。通过实验证明，这种方法在多个任务上都取得了显著的结果。研究团队通过详细介绍了模型的内部机制和性能评估，为长上下文模型的应用奠定了重要基础。总的来看，本文为深入理解长上下文模型在自然语言处理中的应用提供了重要的见解。 <div>
[CL]《In-Context Learning with Long-Context Models: An In-Depth Exploration》A Bertsch, M Ivgi, U Alon, J Berant, M R. Gormley, G Neubig [CMU &amp; Tel Aviv University] (2024) <a href="https://arxiv.org/abs/2405.00200"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwl2i46xj214e0sq4ab.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwl34ek1j21be0qiafw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwl3j5wsj21c00tiq9q.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbwl3mr67j21aw0osjx9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbwr40zvhj20vd0ghdhx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpbwr413iij20vi0i3tax.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwr424zmj20g70g8aat.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwr40h34j20ve089mye.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpbwr41wr5j20vh15vq6u.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwr41m7hj20vh16pjvk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpbwr41l9ij20vd16pgph.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbwr410kfj20ve0vlju4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpbwr414mnj20vf0gcjtl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbwr3zh3rj20ud059aa6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbwr40nd8j20uz0dlabj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpbwr3znvfj20gi09u0su.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwr40s28j20uz0dm0u8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpbwr401yrj20eo0cdmxg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 22:07:27 GMT</pubDate>
</item>
<item>
<title>提出多群鲁棒性概念并通过与多准确率的关联给出实现方法，可针对训练数据中局限于子集的损坏学习鲁棒模型，保护特定群免受不当影响。 - 转发 @爱可可-爱生活:&amp;en...</title>
<link>https://weibo.com/1402400261/OcvS9DS0f</link>
<guid>https://weibo.com/1402400261/OcvS9DS0f</guid>
<content:encoded><![CDATA[
<div> 多群鲁棒性概念，多准确率，实现方法，训练数据损坏，保护特定群，模型<br />
<br />
总结：<br />
本文提出了多群鲁棒性概念，并通过与多准确率的关联给出实现方法。这种方法可以针对训练数据中局限于子集的损坏学习鲁棒模型，保护特定群免受不当影响。研究人员在Stanford University进行了相关研究。 <div>
提出多群鲁棒性概念并通过与多准确率的关联给出实现方法，可针对训练数据中局限于子集的损坏学习鲁棒模型，保护特定群免受不当影响。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Multigroup Robustness》L Hu, C Peale, J H Shen [Stanford University] (2024) <a href="https://arxiv.org/abs/2405.00614"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpbw9jyrssj21ea0jmn62.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbw9kg0nuj21ju0p2gqv.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpbw9kn5mlj21k0152158.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpbw9kn6w7j21jk0m8dm5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpbwgxl3rbj210x0biabn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpbwgxlh76j21120bhabl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwgxlodij210x0e9whs.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwgxl6kzj210x0c5mze.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpbwgxlb20j210x0bh769.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 02 May 2024 21:58:12 GMT</pubDate>
</item>
<item>
<title>[LG]《Multigroup Robustness》L Hu, C Peale, J H Shen [Stanford University] (2024) 网页链接 #机器学习##人工智能##论文# [图片][图片][图片][图片][图片][...</title>
<link>https://weibo.com/1402400261/OcvRWfzH3</link>
<guid>https://weibo.com/1402400261/OcvRWfzH3</guid>
<content:encoded><![CDATA[
<div> 多组稳健性、鲁棒性、Stanford University、2024年、L Hu、C Peale、J H Shen

<br /><br />总结:
本文研究了多组稳健性，提出了一种新的方法来增强系统对多组数据的鲁棒性。研究者使用了Stanford University的资源进行实验和验证。文章指出，这种方法在面对多组数据时表现出色，具有较强的鲁棒性和适应性。实验结果表明，在各种情况下，该方法都能有效地处理多组数据，为系统的稳定性和性能提供了新的保障。研究者们的工作有望为相关领域带来新的启发，并对未来的研究和应用具有重要意义。 <div>
[LG]《Multigroup Robustness》L Hu, C Peale, J H Shen [Stanford University] (2024) <a href="https://arxiv.org/abs/2405.00614"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpbw9jyrssj21ea0jmn62.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbw9kg0nuj21ju0p2gqv.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpbw9kn5mlj21k0152158.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpbw9kn6w7j21jk0m8dm5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpbwgxl3rbj210x0biabn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpbwgxlh76j21120bhabl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwgxlodij210x0e9whs.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwgxl6kzj210x0c5mze.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpbwgxlb20j210x0bh769.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpbwgxl356j210x0bhjte.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwgxkzuhj210x0bhjti.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbwgxl38mj210x0bh76f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbwgxljmej21150f6gp3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 21:57:40 GMT</pubDate>
</item>
<item>
<title>提出使用神经加性模型进行可解释的自动短答评分，该模型兼具神经网络的预测性能和加性模型的可解释性。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Explainable Automat...</title>
<link>https://weibo.com/1402400261/OcvNusijf</link>
<guid>https://weibo.com/1402400261/OcvNusijf</guid>
<content:encoded><![CDATA[
<div> 神经加性模型 自动短答评分 可解释性 预测性能 神经网络 UC Berkeley

总结:<br /><br />
这篇文章提出了一种新的方法——神经加性模型，用于可解释的自动短答评分。该模型结合了神经网络的预测性能和加性模型的可解释性，由A Condor和Z Pardos在UC Berkeley进行研究。其目的是在评分过程中实现更准确的预测，并提供清晰的解释。神经加性模型可以有效地平衡预测性能和可解释性，为评分过程增添价值。 <div>
提出使用神经加性模型进行可解释的自动短答评分，该模型兼具神经网络的预测性能和加性模型的可解释性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Explainable Automatic Grading with Neural Additive Models》A Condor, Z Pardos [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2405.00489"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpbw4taj60j20zm0rewp6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbw4tvr2dj20yy0tw0vn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbw4u5rkpj219e0weqav.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbw4u9c11j21gs0x2q6t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbw5a2hovj20rl0hu0ux.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbw5a2829j20rl093q3n.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 02 May 2024 21:46:42 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《XFeat: Accelerated Features for Lightweight Image Matching》(CVPR 2024) GitHub: github.com/verlab/accelerated_features [fig1]《TIM...</title>
<link>https://weibo.com/1402400261/OcsXp92X0</link>
<guid>https://weibo.com/1402400261/OcsXp92X0</guid>
<content:encoded><![CDATA[
<div> XFeat, lightweight image matching, feature acceleration, CVPR 2024, GitHub, TIM, audio-visual action recognition, Time Interval Machine, PEGASUS, 3D avatars, personalized, composable attributes, SUQL, conversational search, large language models, NAACL 2024, Gaussian Surfels, surface reconstruction, MotionLCM, real-time motion generation, Latent Consistency Model, Invisible Stitch, smooth 3D scenes, Depth Inpainting, Infini-attention, infinite context transformers, Visualization-of-Thought, spatial reasoning, MicroDreamer, zero-shot 3D generation, market-guided, Stock Transformer, stock price forecasting

<br /><br />总结: 本文列举了几篇论文及其实现代码的GitHub链接，涵盖了诸如图像匹配加速、音视频动作识别、3D头像生成、搜索引擎优化、表面重建、智能交易预测等多个领域。各论文采用不同技术手段，旨在提高计算效率、精确性及用户体验。对于研究者和开发者来说，这些资源可供参考和应用。 <div>
几篇论文实现代码：<br />《XFeat: Accelerated Features for Lightweight Image Matching》(CVPR 2024) GitHub: github.com/verlab/accelerated_features [fig1]<br />《TIM: A Time Interval Machine for Audio-Visual Action Recognition》(CVPR 2024) GitHub: github.com/JacobChalk/TIM<br />《PEGASUS: Personalized Generative 3D Avatars with Composable Attributes》(CVPR 2024) GitHub: github.com/snuvclab/pegasus [fig6] <br />《SUQL: Conversational Search over Structured and Unstructured Data with Large Language Models》(NAACL 2024) GitHub: github.com/stanford-oval/suql [fig5] <br />《High-quality Surface Reconstruction using Gaussian Surfels》(2024) GitHub: github.com/turandai/gaussian_surfels<br />《MotionLCM: Real-time Controllable Motion Generation via Latent Consistency Model》(2024) GitHub: github.com/Dai-Wenxun/MotionLCM<br />《Invisible Stitch: Generating Smooth 3D Scenes with Depth Inpainting》(2024) GitHub: github.com/paulengstler/invisible-stitch [fig2]<br />《Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention》(2024) GitHub: github.com/lucidrains/infini-transformer-pytorch [fig3]<br />《Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models》(2024) GitHub: github.com/a-real-ai/pywinassistant<br />《MicroDreamer: Zero-shot 3D Generation in ~20 Seconds by Score-based Iterative Reconstruction》(2024) GitHub: github.com/ML-GSAI/MicroDreamer<br />《MASTER: Market-Guided Stock Transformer for Stock Price Forecasting》(2024) GitHub: github.com/SJTU-Quant/MASTER [fig4]<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbiorbqe4j21590f4k2q.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbiqbl7mxj21x219x7h5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbit4k39kj20aw0dwq7l.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpbj1auqlyj21cr0e9jx0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpbjcsim3sj22801c01kx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpbjkz6q4jj23fs0yrasj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 14:32:53 GMT</pubDate>
</item>
<item>
<title>【精选的大型语言模型时代信息检索相关论文列表】'Awesome Information Retrieval in the Age of Large Language Model - A curated list of awesome papers abo...</title>
<link>https://weibo.com/1402400261/OcsWGhrif</link>
<guid>https://weibo.com/1402400261/OcsWGhrif</guid>
<content:encoded><![CDATA[
<div> 信息检索、大型语言模型、论文、GitHub、信息检索增强、信息检索的大型语言模型、检索、模型、github.com/IR-LLM/Awesome-Information-Retrieval-in-the-Age-of-Large-Language-Model

大型语言模型时代的信息检索是当前研究的热点之一，本文整理了关于信息检索在大型语言模型时代的相关论文。这些论文涵盖了信息检索增强技术、大型语言模型在信息检索中的应用等内容。研究者可以通过查阅这些论文来了解当前信息检索领域的最新进展，以及大型语言模型在信息检索中的潜在应用价值。GitHub上提供了相关资源，方便研究者获取更多信息。总的来说，这些论文为大型语言模型时代的信息检索研究提供了重要参考和启发。 <br /><br />总结: <div>
【精选的大型语言模型时代信息检索相关论文列表】'Awesome Information Retrieval in the Age of Large Language Model - A curated list of awesome papers about information retrieval(IR) in the age of large language model(LLM). These include retrieval augmented large language model, large language model for information retrieval, and so on.' GitHub: github.com/IR-LLM/Awesome-Information-Retrieval-in-the-Age-of-Large-Language-Model <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpbjka829oj21090u0dkk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 14:31:06 GMT</pubDate>
</item>
<item>
<title>【llm.c：用纯C/CUDA进行大型语言模型(LLM)训练的开源项目】'llm.c - LLM training in simple, raw C/CUDA' GitHub: github.com/gevtushenko/llm.c #开源# #机器...</title>
<link>https://weibo.com/1402400261/OcsVw8auW</link>
<guid>https://weibo.com/1402400261/OcsVw8auW</guid>
<content:encoded><![CDATA[
<div> C/CUDA, 大型语言模型, 训练, 开源项目, llm.c, GitHub, gevtushenko, 纯C, 多GPU支持, 高效, 高性能

<br /><br />总结:
llm.c是一个用纯C/CUDA编写的开源项目，用于进行大型语言模型(LLM)的训练。该项目在GitHub上由gevtushenko维护，具有多GPU支持，能够实现高效、高性能的模型训练。通过llm.c，用户可以使用C/CUDA编程语言进行LLM训练，为自然语言处理研究提供了一个强大的工具。 <div>
【llm.c：用纯C/CUDA进行大型语言模型(LLM)训练的开源项目】'llm.c - LLM training in simple, raw C/CUDA' GitHub: github.com/gevtushenko/llm.c <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hpbjhb0bjqj20u010bq9g.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 14:28:14 GMT</pubDate>
</item>
<item>
<title>【Fireproof realtime database：一个实时数据库，可以在任意前端应用或边缘函数中安装，并通过任意后端进行数据同步】'Fireproof realtime database - Realtime...</title>
<link>https://weibo.com/1402400261/OcsUoFu43</link>
<guid>https://weibo.com/1402400261/OcsUoFu43</guid>
<content:encoded><![CDATA[
<div> 实时数据库, Fireproof, 前端应用, 边缘函数, 数据同步, GitHub, Realtime database, Fireproof实时数据库, 后端, 数据同步
<br /><br />总结:
Fireproof实时数据库是一个可以在任意前端应用或边缘函数中安装的实时数据库，用户可以通过任何后端实现数据同步。用户只需在前端应用或边缘函数中安装Fireproof，便可以实现数据的实时同步，方便快捷。同时，Fireproof的GitHub地址为github.com/fireproof-storage/fireproof，用户可以在该平台获取更多关于Fireproof实时数据库的信息和资源。火灾保护实时数据库为用户提供了灵活多样的选择，满足了不同用户在数据同步方面的需求。 <div>
【Fireproof realtime database：一个实时数据库，可以在任意前端应用或边缘函数中安装，并通过任意后端进行数据同步】'Fireproof realtime database - Realtime database, runs anywhere. Install Fireproof in your front-end app or edge function, and sync data via any backend.' GitHub: github.com/fireproof-storage/fireproof <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpbjecrrn6j216c0u0n2p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 14:25:29 GMT</pubDate>
</item>
<item>
<title>【Branches：基于图的高级算法原型工具，专为大型语言模型(LLM)的推理和规划设计】'Branches - Prototype advanced LLM algorithms for reasoning and planning....</title>
<link>https://weibo.com/1402400261/OcsRG9fUT</link>
<guid>https://weibo.com/1402400261/OcsRG9fUT</guid>
<content:encoded><![CDATA[
<div> Branches, Graph-based, Advanced Algorithms, Prototype, Large Language Model(LLM), Inference, Planning, Tool, GitHub

<br /><br />总结:

Branches是一个基于图的高级算法原型工具，专为大型语言模型(LLM)的推理和规划设计。该工具提供了一种创新的方法来处理复杂的推理和规划问题，通过使用图算法来优化LLM的性能。用户可以在GitHub上找到该工具的源代码。Branches的设计旨在提供一种有效的方式来处理LLM的推理和规划任务，从而提高模型的性能和效率。通过引入图算法，Branches能够有效地处理复杂的推理和规划问题，使得LLM能够更加智能地进行推断和规划。Branches为研究人员和开发人员提供了一个强大的工具，可以帮助他们更好地理解和应用LLM模型。 <div>
【Branches：基于图的高级算法原型工具，专为大型语言模型(LLM)的推理和规划设计】'Branches - Prototype advanced LLM algorithms for reasoning and planning.' GitHub: github.com/normal-computing/branches <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hpbj71x8aej20x50u0ad7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 14:18:47 GMT</pubDate>
</item>
<item>
<title>【OpenAgents：用于构建和商业化AI Agent的平台，支持通过共享技能和知识数据库来创建AI Agent】'OpenAgents - An open agents platform (wip)' GitHub: github....</title>
<link>https://weibo.com/1402400261/OcsRhBugM</link>
<guid>https://weibo.com/1402400261/OcsRhBugM</guid>
<content:encoded><![CDATA[
<div> OpenAgents, 平台, 构建, 商业化, AI Agent, 支持, 共享技能, 知识数据库, 创建, GitHub

<br /><br />总结:
OpenAgents是一个用于构建和商业化AI Agent的平台，支持用户通过共享技能和知识数据库来创建自己的AI Agent。用户可以在GitHub上找到该平台的开源代码。通过OpenAgents，用户能够轻松地构建和定制化自己的AI Agent，从而应用于各种领域和业务场景，实现更高效的智能交互和解决方案。 OpenAgents的开放性使得用户可以充分利用各种资源和技术，提供更加个性化和定制化的AI Agent服务，推动人工智能应用的发展和普及。 <div>
【OpenAgents：用于构建和商业化AI Agent的平台，支持通过共享技能和知识数据库来创建AI Agent】'OpenAgents - An open agents platform (wip)' GitHub: github.com/OpenAgentsInc/openagents <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpbj60oqs6j20wa0u0whe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 14:17:49 GMT</pubDate>
</item>
<item>
<title>【LM Buddy：用于微调和评估开源大型语言模型的工具集，目前处于早期开发阶段】'LM Buddy - Your buddy in the (L)LM space.' GitHub: github.com/mozilla-ai/lm...</title>
<link>https://weibo.com/1402400261/OcsQxvJfX</link>
<guid>https://weibo.com/1402400261/OcsQxvJfX</guid>
<content:encoded><![CDATA[
<div> 关键词: LM Buddy, 微调, 评估, 开源, 大型语言模型, 工具集, 早期开发阶段, Mozilla AI

总结:<br /><br />LM Buddy是一个用于微调和评估开源大型语言模型的工具集，由Mozilla AI开发，目前仍处于早期开发阶段。该工具集旨在为研究人员提供便利，帮助他们更好地探索和优化语言模型。通过GitHub平台，用户可以查看该工具集的代码和相关信息，从而了解其功能和应用场景。LM Buddy在语言模型领域有着广泛的应用潜力，可为研究和实践工作带来便利和效率。希望随着开发的不断完善，LM Buddy可以成为更多研究人员的重要助手，推动语言模型技术的发展。 <div>
【LM Buddy：用于微调和评估开源大型语言模型的工具集，目前处于早期开发阶段】'LM Buddy - Your buddy in the (L)LM space.' GitHub: github.com/mozilla-ai/lm-buddy <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpbj4kabs0j21090u0dkz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 14:15:59 GMT</pubDate>
</item>
<item>
<title>【MLX RAG With GGUF Model Weights：使用gguf模型权重，通过MLX实现的RAG（Retrieval-Augmented Generation）模型的最小化、清洁代码实现】'MLX RAG With GGUF ...</title>
<link>https://weibo.com/1402400261/OcsQazsxQ</link>
<guid>https://weibo.com/1402400261/OcsQazsxQ</guid>
<content:encoded><![CDATA[
<div> MLX、RAG、GGUF、模型权重、最小化、清洁代码、实现、GitHub、Jaykef、mlx-rag-gguf
<br />
<br />
总结：本文是关于使用gguf模型权重，通过MLX实现的RAG模型的最小化、清洁代码实现的代码库。作者Jaykef在GitHub上分享了相关代码。MLX是一个工具，用于实现Retrieval-Augmented Generation（RAG）模型。该模型使用GGUF模型权重，通过MLX库进行实现，保持代码的简洁和可读性。感兴趣的读者可以在该GitHub仓库中查看详细信息。 <div>
【MLX RAG With GGUF Model Weights：使用gguf模型权重，通过MLX实现的RAG（Retrieval-Augmented Generation）模型的最小化、清洁代码实现】'MLX RAG With GGUF Model Weights - Minimal, clean code implementation of RAG with mlx using gguf model weights' GitHub: github.com/Jaykef/mlx-rag-gguf <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpbj39x4esj215j0u044m.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpbj3lpk1xj20xi0ho0x0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 14:15:04 GMT</pubDate>
</item>
<item>
<title>【ChatGPT CLI：为OpenAI和Azure ChatGPT模型提供强大命令行界面的工具，支持实时交互、查询模式、线程管理及高级配置选项】'ChatGPT CLI - ChatGPT CLI is an a...</title>
<link>https://weibo.com/1402400261/OcsONEovT</link>
<guid>https://weibo.com/1402400261/OcsONEovT</guid>
<content:encoded><![CDATA[
<div> 关键词：ChatGPT CLI, OpenAI, Azure, 命令行界面, 实时交互, 查询模式, 线程管理, 高级配置选项, 用户, 开发者

总结:<br /><br />
本文介绍了ChatGPT CLI这一强大工具，可通过OpenAI和Azure提供命令行界面来与ChatGPT模型交互。该工具支持实时交互、查询模式和历史跟踪，以进行无缝、上下文感知的对话。这对用户和开发者而言都非常理想，因为可以提供高级配置和简便设置选项，确保使用GPT模型进行个性化的对话体验。<br /><br />
1. ChatGPT CLI 是一个为OpenAI和Azure ChatGPT模型设计的高级命令行界面工具。
2. 该工具支持实时交互、查询模式以及历史追踪功能，能够进行无缝的上下文感知对话。
3. ChatGPT CLI 不仅适用于普通用户，也为开发者提供了高级配置选项，能够满足个性化的对话需求。
4. 用户可以通过该工具与ChatGPT模型进行更方便、更灵活的交流。
5. ChatGPT CLI 基于GitHub，在项目的GitHub页面（github.com/kardolus/chatgpt-cli）可以获得更多信息和支持。 <div>
【ChatGPT CLI：为OpenAI和Azure ChatGPT模型提供强大命令行界面的工具，支持实时交互、查询模式、线程管理及高级配置选项】'ChatGPT CLI - ChatGPT CLI is an advanced command-line interface for ChatGPT models via OpenAI and Azure, offering streaming, query mode, and history tracking for seamless, context-aware conversations. Ideal for both users and developers, it provides advanced configuration and easy setup options to ensure a tailored conversational experience with the GPT model.' GitHub: github.com/kardolus/chatgpt-cli <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpbizv7gozj219f0u00ww.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 14:11:42 GMT</pubDate>
</item>
<item>
<title>【OpenAI Assistants API Quickstart：用Next.js快速启动OpenAI助手API的公共模板项目】'OpenAI Assistants API Quickstart - OpenAI Assistants API quickstart...</title>
<link>https://weibo.com/1402400261/OcsMusiTl</link>
<guid>https://weibo.com/1402400261/OcsMusiTl</guid>
<content:encoded><![CDATA[
<div> OpenAI, Assistants API, Quickstart, Next.js, 公共模板项目, GitHub, 快速启动

<br /><br />总结:
本文介绍了如何使用Next.js快速启动OpenAI助手API的公共模板项目。通过GitHub上的openai-assistants-quickstart仓库，用户可快速搭建和使用OpenAI助手API。这一快速入门指南旨在帮助开发人员快速上手并开始使用OpenAI助手API，提供了简洁明了的操作步骤和示例代码。借助这个公共模板项目，用户可以更快地开发和部署OpenAI助手API相关的应用程序，提升开发效率和便捷性，为构建更加智能和个性化的应用奠定基础。 <div>
【OpenAI Assistants API Quickstart：用Next.js快速启动OpenAI助手API的公共模板项目】'OpenAI Assistants API Quickstart - OpenAI Assistants API quickstart with Next.js.' GitHub: github.com/openai/openai-assistants-quickstart <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpbiu4k5urj21ia0u00vn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 14:06:00 GMT</pubDate>
</item>
<item>
<title>【通过无监督学习方法激活语言模型潜在行为】- 由于训练数据的原因，大语言模型可能存在多种潜在的行为模式。这些模式可能对模型的安全性和对齐性产生影响。 - ...</title>
<link>https://weibo.com/1402400261/OcnhX8x5s</link>
<guid>https://weibo.com/1402400261/OcnhX8x5s</guid>
<content:encoded><![CDATA[
<div> 关键词: 无监督学习、语言模型、潜在行为、模型安全性、提示工程、机械化方法、残差流、操纵向量、红队测试、异常检测

总结:<br /><br />本文介绍了一种利用无监督学习方法激活语言模型潜在行为的新途径。通过在模型内部添加操纵向量或修改权重来激活这些行为模式，以便更全面地检验模型的行为范围，揭示异常行为。这种机械化方法相对于非机械化方法更具优势。作者通过红队测试发现了反拒绝向量和奇幻向量，揭示了游戏知识的特殊行为。除了小样本大小，该方法还可发现有价值的模型离散行为信息，发现了对下游影响较大的高影响特征。该方法对监督式激活控制和异常检测都有帮助，未来可继续深入研究该方法的定量评估和在异常检测中的应用。 <div>
【通过无监督学习方法激活语言模型潜在行为】<br />- 由于训练数据的原因，大语言模型可能存在多种潜在的行为模式。这些模式可能对模型的安全性和对齐性产生影响。   <br />- 相比提示工程或树搜索等非机械化方法，文章提出通过机械化地扰动模型内部(如修改权重或在残差流中添加固定偏差)来激发这些潜在行为，这更有利于检验模型的广泛行为，发现异常行为，并覆盖更多行为范围。   <br />- 具体方法是在模型的中间层残差流中添加非监督式的 “操纵向量”，或适配该层的MLP输出权重矩阵，目的是最大化下游层的激活变化。   <br />- 作者应用该方法对模型进行红队测试，发现了可绕过安全训练的反拒绝向量，以及揭示游戏知识的奇幻向量。这表明方法可以发现广泛、有意义的行为。   <br />- 与自编码器等其他方法相比，该方法适用于小样本大小，并可能发现更多关于模型离散分布行为的有价值信息。   <br />- 作者认为该方法发现了对下游影响较大的 “高影响特征”，这反映了这些特征在结构上具有重要性。   <br />- 该方法可为监督式激活控制提供帮助，也可应用于异常检测。   <br />- 未来可继续研究该方法的定量评估，以及在异常检测中的应用。<br />《Mechanistically Eliciting Latent Behaviors in Language Models — AI Alignment Forum》 <a href="https://www.alignmentforum.org/posts/ioPnHKFyy4Cw2Gr2x/mechanistically-eliciting-latent-behaviors-in-language-1"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpauj4e1o5j20n60qkwgh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 02 May 2024 00:07:01 GMT</pubDate>
</item>
<item>
<title>【TED演讲：如何治理人工智能——即使它很难预测】- AI专家普遍认为目前没有人真正了解AI的内部工作原理。这给AI的管理和治理带来了很大困难。 - 一个关键问题是...</title>
<link>https://weibo.com/1402400261/Ocn434TBA</link>
<guid>https://weibo.com/1402400261/Ocn434TBA</guid>
<content:encoded><![CDATA[
<div> 管理、治理、困难、智能、定义、发展、深度神经网络、可解释性、公众参与、潜力

<br /><br />总结:
AI专家普遍认为管理和治理人工智能困难重重，其中一个关键问题在于对智能的定义存在巨大差异。目前的深度神经网络被视为一个"黑匣子"，需要进一步研究以提高可解释性。即使对AI感到困惑，公众也应该保持警惕并参与讨论。在治理AI时，应该关注适应性而非确定性，采取措施及时了解AI发展状态并调整政策。AI的潜力远不止商业应用，公众应该推动AI朝着有利于人类的方向发展。 <div>
【TED演讲：如何治理人工智能——即使它很难预测】<br />- AI专家普遍认为目前没有人真正了解AI的内部工作原理。这给AI的管理和治理带来了很大困难。   <br />- 一个关键问题是，没有人能够清楚定义“智能”的内涵。不同的专家对智能的理解差异很大，这导致他们对AI发展方向和速度的预期存在巨大分歧。   <br />- 过去将AI分为“窄AI”和“通用AI”。但ChatGPT等系统打破了这个简单的二分法。真正的“通用AI”仍然遥不可及。   <br />- 目前主流的深度神经网络可看作是一个“黑盒”。我们可以看到里面的数字，但过多的参数使得难以解析其中逻辑。需要进一步的可解释性研究。   <br />- 对AI感到困惑和不解是可以理解的。但AI并非魔法，其内部运作并非不可知。公众需要对AI公司和技术专家保持警惕，并参与讨论。   <br />- 在治理AI方面，应该关注适应性而非确定性。通过测量AI能力、要求公司信息披露、建立事故报告机制等方式，及时了解AI发展状态，并据此调整政策。   <br />- AI的潜力远不止某些公司的商业应用。更高级的AI可能会解锁清洁能源、农业革命等多方面变革。公众需要发出自己的声音，推动AI朝着有利于人类的方向发展。<br />《Helen Toner: How to govern AI — even if it's hard to predict | TED Talk》 <a href="https://www.ted.com/talks/helen_toner_how_to_govern_ai_even_if_it_s_hard_to_predict/transcript"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpatlgws9qj21hc0u0443.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 23:32:46 GMT</pubDate>
</item>
<item>
<title>【TeraHAC：对包含万亿条边的图进行高效层次聚类】- TeraHAC算法是谷歌研究团队为处理大规模图数据设计的层次聚合聚类算法。 - 该算法能够处理具有数万亿条边的...</title>
<link>https://weibo.com/1402400261/Ocn2BurwH</link>
<guid>https://weibo.com/1402400261/Ocn2BurwH</guid>
<content:encoded><![CDATA[
<div> 谷歌、TeraHAC算法、层次聚类、大规模图数据、稀疏图、计算复杂度、MapReduce、分布式环境、多核资源、精确度-召回率权衡

<br /><br />总结:
谷歌研究团队设计了TeraHAC算法，用于处理包含万亿条边的大规模图数据，该算法在稀疏图上利用相似性矩阵的稀疏性优化计算步骤，降低计算复杂度。通过MapReduce风格的计算模型，TeraHAC能够在分布式环境中高效利用多核或多机资源。实验结果显示，TeraHAC相比传统算法速度提升超过75倍，并在保持聚类质量的同时实现了最佳的精确度-召回率权衡，在8万亿边的数据集上成为首选算法。 <div>
【TeraHAC：对包含万亿条边的图进行高效层次聚类】<br />- TeraHAC算法是谷歌研究团队为处理大规模图数据设计的层次聚合聚类算法。  <br />- 该算法能够处理具有数万亿条边的图，适用于大规模预测和信息检索任务。  <br />- TeraHAC通过在稀疏图上利用相似性矩阵中的稀疏性，优化了计算步骤，减少了计算复杂度。  <br />- 实验表明，TeraHAC在保持聚类质量的同时，相比传统算法有超过75倍的速度提升。  <br />- TeraHAC算法采用了MapReduce风格的计算模型，适用于分布式环境，能高效利用多核或多机资源。  <br />- 在8万亿边的数据集上，TeraHAC实现了最佳的精确度-召回率权衡，成为超大规模图聚类的首选算法。  <br />《Scaling hierarchical agglomerative clustering to trillion-edge graphs》 <a href="https://research.google/blog/scaling-hierarchical-agglomerative-clustering-to-trillion-edge-graphs/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span> <span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hpathjl3kxj223y0u079i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 23:29:13 GMT</pubDate>
</item>
<item>
<title>【TED访谈：人工智能正在解开自然和宇宙的奥秘】- Demis Hassabis认为，AI是探索那些传统上需要通过哲学或物理学才能理解的“大问题”的最快途径。他从小就对物...</title>
<link>https://weibo.com/1402400261/Ocn1jgYZU</link>
<guid>https://weibo.com/1402400261/Ocn1jgYZU</guid>
<content:encoded><![CDATA[
<div> 人工智能、Demis Hassabis、探索、哲学、物理学、游戏训练、AlphaFold项目、蛋白质结构、强大推理、ChatGPT

总结:<br /><br />Demis Hassabis认为人工智能是探索传统“大问题”的途径，对物理学问题感兴趣，通过建造AI系统帮助人类思考和获得答案。他使用游戏训练AI系统，如AlphaGo证明了AI的学习能力。AlphaFold项目利用AI预测蛋白质结构，为药物设计带来帮助。AI系统如AlphaZero达到世界顶级水平，但进步指数级，需谨慎对待。ChatGPT激发科技公司竞争，但需注意应用风险。Hassabis乐观认为AI可成为探索工具，但需谨慎应对风险，期望AI最大限度地增进人类福祉。 <div>
【TED访谈：人工智能正在解开自然和宇宙的奥秘】<br />- Demis Hassabis认为，AI是探索那些传统上需要通过哲学或物理学才能理解的“大问题”的最快途径。他从小就对物理学中的基本问题很感兴趣，如意识本质等。他认为通过建造AI系统可以帮助人类思考和获得这些问题的答案。   <br />- Demis Hassabis使用游戏来训练AI系统。从最初的Atari游戏到后来的围棋软件AlphaGo，游戏为AI算法提供了方便快速的测试环境。这些游戏系统也证明了AI的强大学习和推断能力。   <br />- AlphaFold项目使用AI来预测蛋白质的三维结构，是生物学领域半个世纪的难题。该项目预测了超过2亿个蛋白质的三维结构，节省了数十亿小时的科学家工作时间。为药物设计和疾病研究带来巨大帮助。   <br />- AI系统像AlphaZero在极短时间内达到世界顶级水平，证明了AI的强大推理能力。但也需要谨慎对待，因为它们的进步是指数级的，远非增量式。   <br />- 近期ChatGPT的出现激发了各大科技公司开发类似产品的竞争。但为赶上进度而过于激进地应用AI可能带来风险。行业内部需要加强合作，政府监管也很重要。   <br />- Demis Hassabis对未来保持乐观，认为AI可以成为探索知识树的工具，甚至有朝一日理解基本的实在本质。但他也认为过程中有各种风险需要谨慎对待。   <br />- Demis Hassabis期望通过AI来最大限度地增进人类福祉。<br />《Demis Hassabis: How AI is unlocking the secrets of nature and the universe | TED Talk》 <a href="https://www.ted.com/talks/demis_hassabis_how_ai_is_unlocking_the_secrets_of_nature_and_the_universe/transcript"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpatel264kj217u0oidop.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 23:26:02 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型应用指南》，截至2024.5.9 12:00，*可可粉*转发+评论即可参与。一本对人工智能小白读者非常友好的大语...</title>
<link>https://weibo.com/1402400261/OcmZ1yr5i</link>
<guid>https://weibo.com/1402400261/OcmZ1yr5i</guid>
<content:encoded><![CDATA[
<div> 人工智能、大语言模型、应用指南、机器学习、神经网络、自然语言处理、提示工程、GPTs、无梯度优化、安全技术

<br /><br />总结:
本文介绍了一本《大语言模型应用指南》共分为四篇，旨在帮助人工智能小白读者掌握大语言模型的应用。第一篇夯实基础，涉及机器学习、神经网络、自然语言处理的基础知识。第二篇实践应用，包括交互格式、提示工程、GPTs的开发等内容。第三篇拓宽边界，讨论无梯度优化、自主Agent系统、大语言模型微调等议题。第四篇展望未来，探讨多模态大语言模型、尺度定律、压缩即智能等前沿课题。整体而言，该指南全面涵盖了大语言模型的基础、实践、拓展和未来发展方向，适合初学者了解和深入研究。 <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型应用指南》，截至2024.5.9 12:00，*可可粉*转发+评论即可参与。一本对人工智能小白读者非常友好的大语言模型应用指南，第1篇夯实基础，探索机器学习、神经网络、自然语言处理和大语言模型的基础。第2篇实践应用，包括交互格式、提示工程、工作记忆与长短期记忆，外部工具和GPTs的开发。第3篇拓宽边界，涵盖无梯度优化、自主Agent系统、大语言模型微调以及安全技术等。第4篇洞见未来，探讨多模态大语言模型、尺度定律、压缩即智能、图灵机与大语言模型的关联等。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpat58zigtj20m80m8myr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpat89xztmj20m80m8whk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpat8ab08qj20m80m80up.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpat8bjhzkj20m80m8q52.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpat8c7vsej20m80m8dhx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpat8e5u7oj20m80m8gob.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 23:20:24 GMT</pubDate>
</item>
<item>
<title>今日推介(第1393期)：Kolmogorov-Arnold网络、迭代推理偏好优化、基于Multi-token预测的更好更快的大型语言模型、无需训练的图神经网络与标签即特征的潜力、面向...</title>
<link>https://weibo.com/1402400261/OcmTr1h55</link>
<guid>https://weibo.com/1402400261/OcmTr1h55</guid>
<content:encoded><![CDATA[
<div> Kolmogorov-Arnold网络, 迭代推理偏好优化, Multi-token预测, 大型语言模型, 无需训练的图神经网络, 标签即特征, 面向真实性语言建模, 马尔可夫Agent<br />
<br />
总结:本文介绍了几个新颖的技术和模型，包括Kolmogorov-Arnold网络、迭代推理偏好优化和基于Multi-token预测的大型语言模型。此外，文章还探讨了无需训练的图神经网络和标签即特征的潜力。最后，作者提出了面向真实性语言建模的马尔可夫Agent模型，展示了其在任务中的应用效果。这些技术和模型的引入和探索将为相关领域的研究和应用带来新的思路和可能性。 <div>
今日推介(第1393期)：Kolmogorov-Arnold网络、迭代推理偏好优化、基于Multi-token预测的更好更快的大型语言模型、无需训练的图神经网络与标签即特征的潜力、面向真实性语言建模的马尔可夫Agent 公·众·号：爱可可爱生活 <a href="http://aicoco.net/s/8u"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpasu1r79bj21b60lyn1k.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpasu3ypsdj21ba0mwdly.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpasu7a2wcj20t41csn2t.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpasua6hi9j21zj0u0dkq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpasucy5foj21bq0o0q8o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 23:06:37 GMT</pubDate>
</item>
<item>
<title>[CV] SAGS: Structure-Aware 3D Gaussian Splatting 网页链接 通过隐式编码场景结构提出结构感知高斯Splatting渲染方法，取得了渲染质量和压缩率的显著提升。 [...</title>
<link>https://weibo.com/1402400261/OcmOXgwaj</link>
<guid>https://weibo.com/1402400261/OcmOXgwaj</guid>
<content:encoded><![CDATA[
<div> 3D 渲染, 高斯 Splatting, 结构感知, 渲染质量, 压缩率, 隐式编码场景结构

<br /><br />总结:
该篇论文提出了一种名为Structure-Aware 3D Gaussian Splatting（SAGS）的渲染方法，通过隐式编码场景结构来实现结构感知。该方法在渲染质量和压缩率方面取得了显著提升。首先，使用高斯分布来表示光线在空间中的传播。随后，通过对场景结构的隐式编码，将每个像素的渲染结果根据结构信息进行调整，从而提高渲染质量。同时，通过对渲染结果进行稀疏表示和学习，实现了高效的压缩，有效减少了计算和存储成本。该方法在多种场景下都取得了良好的效果，展示了其在实际场景中的潜在应用前景。结合了结构感知和高斯Splatting的特点，使得SAGS在渲染任务中具有独特优势，为三维渲染领域的发展提供了新的思路和方法。 <div>
[CV] SAGS: Structure-Aware 3D Gaussian Splatting  <br /><a href="https://arxiv.org/abs/2404.19149"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过隐式编码场景结构提出结构感知高斯Splatting渲染方法，取得了渲染质量和压缩率的显著提升。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpasiv9g1tj20us1bganx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpasivoti8j215g0rktjq.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpasivx4jyj21520lmwmm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 22:55:35 GMT</pubDate>
</item>
<item>
<title>[LG] Foundations of Multisensory Artificial Intelligence 网页链接 从理论和实践两个方面深入研究了多模态机器学习的基础，包括多模态交互量化、表示学习和大...</title>
<link>https://weibo.com/1402400261/OcmLLfwMj</link>
<guid>https://weibo.com/1402400261/OcmLLfwMj</guid>
<content:encoded><![CDATA[
<div> 多模态机器学习、多模态交互量化、表示学习、大规模评估、通用、交互、人工智能、基础、理论、实践

<br /><br />总结:
本文从理论和实践两个方面深入研究了多模态机器学习的基础。首先探讨了多模态交互量化和表示学习的重要性，强调了这些技术在构建多模态人工智能方面的关键作用。同时，对大规模评估方法进行了讨论，为多模态人工智能的发展提供了实践基础。通过建立通用且具有交互性的多模态人工智能系统，为未来人工智能领域的发展奠定了基础。 <div>
[LG] Foundations of Multisensory Artificial Intelligence  <br /><a href="https://arxiv.org/abs/2404.18976"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />从理论和实践两个方面深入研究了多模态机器学习的基础，包括多模态交互量化、表示学习和大规模评估，为构建通用和交互的多模态人工智能奠定了基础。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hpasalydnzj210u14idla.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpasamjckuj20w41b8ngh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpasamwt1yj210i18ktjm.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpasanlivxj21181csws0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpasanoue8j21001cidsp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpasanpxdaj21001cidsa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 22:47:43 GMT</pubDate>
</item>
<item>
<title>[LG] On Training a Neural Network to Explain Binaries 网页链接 提出嵌入距离相关性(EDC)的算法可以快速可靠地评估序列到序列任务数据集的质量，发现现有公开...</title>
<link>https://weibo.com/1402400261/OcmHWvQjt</link>
<guid>https://weibo.com/1402400261/OcmHWvQjt</guid>
<content:encoded><![CDATA[
<div> 提取关键词:
嵌入距离相关性, 神经网络, 二进制代码, 数据集, 训练, 质量, 评估, 公开数据集, 自建数据集, 任务

总结:<br />
本文提出了嵌入距离相关性（EDC）算法，用于评估序列到序列任务数据集的质量。研究发现现有公开数据集和自建数据集在二进制代码理解任务上质量较差，无法有效训练模型。因此，需要改进数据集质量以利于神经网络的训练。 <div>
[LG] On Training a Neural Network to Explain Binaries  <br /><a href="https://arxiv.org/abs/2404.19631"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>        <br />提出嵌入距离相关性(EDC)的算法可以快速可靠地评估序列到序列任务数据集的质量，发现现有公开数据集与自建数据集在二进制代码理解任务上质量均较差，无法进行模型有效训练。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpas0vp30wj20uw1d4tng.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpas0w64kmj215k0l8n0x.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpas0wu08vj218k0lqtex.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 22:38:19 GMT</pubDate>
</item>
<item>
<title>[CL] Multi-hop Question Answering over Knowledge Graphs using Large Language Models 网页链接 通过信息检索和语义解析两种途径，在不同知识图谱数据集上展...</title>
<link>https://weibo.com/1402400261/OcmEU3WoE</link>
<guid>https://weibo.com/1402400261/OcmEU3WoE</guid>
<content:encoded><![CDATA[
<div> 关键词: 多跳问答, 知识图谱, 大规模语言模型, 提示注入知识, 复杂推理

总结:<br />
该研究通过信息检索和语义解析两种途径，在不同知识图谱数据集上展示了提示注入知识后，大规模语言模型可以进行复杂多跳推理的能力。研究结果表明，注入知识可以帮助模型更好地理解问题并进行更准确的推理，从而提高问答系统的性能。这种方法为多跳问题的解决提供了新的思路，并展现了大规模语言模型在知识图谱上的潜在应用前景。研究还指出，在知识图谱的基础上加入额外的背景信息可以进一步提升模型性能，对于推理复杂问题具有重要意义。通过持续优化模型结构和训练方法，可以进一步提高模型在多跳问题上的表现，并推动知识图谱问答系统的发展。 <div>
[CL] Multi-hop Question Answering over Knowledge Graphs using Large Language Models  <br /><a href="https://arxiv.org/abs/2404.19234"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />通过信息检索和语义解析两种途径，在不同知识图谱数据集上展示了提示注入知识后，大规模语言模型可以进行复杂多跳推理的能力。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpart423afj20x417eh1o.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpart48gwaj21jo1920yo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpart4cpa5j21jo0qyn0q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 22:30:49 GMT</pubDate>
</item>
<item>
<title>通过马尔可夫训练产生可解释、可迁移的链式思维，以提高语言模型的透明度和可靠性。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Markovian Agents for Truthful Languag...</title>
<link>https://weibo.com/1402400261/OcmC7b0ob</link>
<guid>https://weibo.com/1402400261/OcmC7b0ob</guid>
<content:encoded><![CDATA[
<div> 马尔可夫训练、可解释、可迁移、链式思维、语言模型、透明度、可靠性、Stanford University、2024、S Viteri<br />
<br />
总结:<br />
本文提出了使用马尔可夫代理来训练语言模型的方法，以提高其透明度和可靠性。该方法有助于生成可解释、可迁移的链式思维，使语言模型更具实用性。研究来自斯坦福大学，是为了深入探讨真实语言建模的可能性。这一方法可能对自然语言处理领域产生深远影响，有助于提升模型的性能和可理解性。 <div>
通过马尔可夫训练产生可解释、可迁移的链式思维，以提高语言模型的透明度和可靠性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Markovian Agents for Truthful Language Modeling》S Viteri, M Lamparth, P Chatain, C Barrett [Stanford University] (2024) <a href="https://arxiv.org/abs/2404.18988"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hparg6t5ulj213y0qg7fs.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hparg7imt2j21bm0iggs3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hparg7u3trj21c20t0tfm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hparg81n2ij21bq0o0n58.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hparg85qi4j21bm0nyn4y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 01 May 2024 22:23:57 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(5.1)》 爱可可微博热门分享(5.1) [图片]</title>
<link>https://weibo.com/1402400261/OcjDok7jz</link>
<guid>https://weibo.com/1402400261/OcjDok7jz</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 分享, 爱可可, 5.1, 情感, 文章, 点赞, 评论, 用户

<br /><br />总结:
本文介绍了爱可可微博上5月1号的热门分享内容，涵盖了各种情感故事和文章。许多用户对这些内容进行了点赞和评论，讨论热度很高。文章内容贴近用户生活，引起了广泛关注和讨论。 <div>
《爱可可微博热门分享(5.1)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405029354148069394"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(5.1)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpaegb4fklj20rs0fm44z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 14:48:52 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《4D-DRESS: A 4D Dataset of Real-world Human Clothing with Semantic Annotations》(CVPR 2024) GitHub: github.com/eth-ait/4d-dress [fi...</title>
<link>https://weibo.com/1402400261/OcjvlDcax</link>
<guid>https://weibo.com/1402400261/OcjvlDcax</guid>
<content:encoded><![CDATA[
<div> 服装数据集、语义标注、4D技术、衣物分类、时尚研究、深度学习、图像识别、算法实现、Github代码、CVPR会议。
<br />
人们日常穿着的衣物在时尚研究和深度学习中扮演着重要角色，然而现有的衣物数据集缺乏4D技术支持，本文提出了一个包含语义标注的4D服装数据集，以促进衣物分类和图像识别领域的研究。作者实现了算法，并在CVPR会议上发布了该数据集，并将代码放在了Github上。
<br /><br />总结: <div>
几篇论文实现代码：<br />《4D-DRESS: A 4D Dataset of Real-world Human Clothing with Semantic Annotations》(CVPR 2024) GitHub: github.com/eth-ait/4d-dress [fig2]<br />《Fast ODE-based Sampling for Diffusion Models in Around 5 Steps》(CVPR 2024) GitHub: github.com/zju-pi/diff-sampler<br />《OpenStreetView-5M: The Many Roads to Global Visual Geolocation》(CVPR 2024) GitHub: github.com/gastruc/osv5m [fig3]<br />《KAN: Kolmogorov-Arnold Networks》(2024) GitHub: github.com/KindXiaoming/pykan [fig1]<br />《Lightplane: Highly-Scalable Components for Neural 3D Fields》(2024) GitHub: github.com/facebookresearch/lightplane<br />《2D Gaussian Splatting for Geometrically Accurate Radiance Fields》(2024) GitHub: github.com/hugoycj/2.5d-gaussian-splatting<br />《FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design》(2024) GitHub: github.com/usyd-fsalab/fp6_llm<br />《DMEL: The Differentiable Log-Mel Spectrogram as a Trainable Layer in Neural Networks》(2024) GitHub: github.com/johnmartinsson/differentiable-mel-spectrogram<br />《Aligning Diffusion Models by Optimizing Human Utility》(2024) GitHub: github.com/jacklishufan/diffusion-kto<br />《PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval》(2024) GitHub: github.com/ielab/PromptReps<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hpa1dxc3goj21r60z2dse.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hpa1ng6bpej21bm0i87hj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hpacvrctxbj21rx0fuqk1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 14:29:03 GMT</pubDate>
</item>
<item>
<title>【RKNN Toolkit2 是一个用于快速将AI模型部署到瑞芯微芯片上的软件开发工具包】'RKNN software stack can help users to quickly deploy AI models to Rockchip ...</title>
<link>https://weibo.com/1402400261/OcjlE3gQN</link>
<guid>https://weibo.com/1402400261/OcjlE3gQN</guid>
<content:encoded><![CDATA[
<div> 瑞芯微芯片、AI模型部署、软件开发工具包、RKNN Toolkit2、快速、GitHub、rknn-toolkit2、部署、软件栈、用户<br />
<br />
RKNN Toolkit2是一个用于快速将AI模型部署到瑞芯微芯片上的软件开发工具包。该软件堆栈可以帮助用户快速部署AI模型到Rockchip芯片上。用户可以在GitHub上找到相关信息，使用rknn-toolkit2进行部署。RKNN Toolkit2为用户提供了便捷的部署AI模型的解决方案。RKNN Toolkit2的优势在于快速且简单地完成AI模型的部署工作，让用户更加方便地利用瑞芯微芯片进行人工智能开发。 <div>
【RKNN Toolkit2 是一个用于快速将AI模型部署到瑞芯微芯片上的软件开发工具包】'RKNN software stack can help users to quickly deploy AI models to Rockchip chips' GitHub: github.com/airockchip/rknn-toolkit2 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpad6fu64xj20fg088wf2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 14:05:08 GMT</pubDate>
</item>
<item>
<title>【Sequential Workflow Designer：一个无代码组件，用于构建基于流程的编程应用，完全通用，无需外部依赖，支持现代浏览器和移动设备】'Sequential Workflow Des...</title>
<link>https://weibo.com/1402400261/Ocjk09QTv</link>
<guid>https://weibo.com/1402400261/Ocjk09QTv</guid>
<content:encoded><![CDATA[
<div> 无代码、组件、流程、编程、应用、通用、现代浏览器、移动设备、GitHub<br />
<br />
总结:<br />
Sequential Workflow Designer是一个无代码组件，用于构建基于流程的编程应用。它完全通用，无需外部依赖，支持现代浏览器和移动设备。用户可以在GitHub上找到该组件的相关信息。 <div>
【Sequential Workflow Designer：一个无代码组件，用于构建基于流程的编程应用，完全通用，无需外部依赖，支持现代浏览器和移动设备】'Sequential Workflow Designer - Customizable no-code component for building flow-based programming applications. 0 external dependencies.' GitHub: github.com/nocode-js/sequential-workflow-designer <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpad2muz8jj20zk0hs75f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 14:01:05 GMT</pubDate>
</item>
<item>
<title>【lmstudio.js：LM Studio 的 TypeScript SDK，用于在 JavaScript/TypeScript/Node.js 代码中使用本地大型语言模型(LLMs)】'lmstudio.js - LM Studio TypeScript...</title>
<link>https://weibo.com/1402400261/Ocjh3e83Y</link>
<guid>https://weibo.com/1402400261/Ocjh3e83Y</guid>
<content:encoded><![CDATA[
<div> lmstudio.js, LM Studio, TypeScript, SDK, JavaScript, Node.js, 大型语言模型, GitHub, lmstudio-ai, 模型使用

<br /><br />总结:
lmstudio.js是LM Studio的TypeScript SDK，用于在JavaScript/TypeScript/Node.js代码中使用本地大型语言模型(LLMs)。该SDK提供了一种便捷的方式来集成和调用LLMs，让开发人员可以更轻松地利用强大的自然语言处理能力。通过GitHub上的开源项目lmstudio-ai/lmstudio.js，开发人员可以快速获取和使用该SDK，并在应用程序中实现更复杂的自然语言处理功能。 <div>
【lmstudio.js：LM Studio 的 TypeScript SDK，用于在 JavaScript/TypeScript/Node.js 代码中使用本地大型语言模型(LLMs)】'lmstudio.js - LM Studio TypeScript SDK' GitHub: github.com/lmstudio-ai/lmstudio.js <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpacv5jwy2j216k0ry77r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 13:53:49 GMT</pubDate>
</item>
<item>
<title>【BitNetMCU: 专注于在低端RISC-V微控制器CH32V003上训练和推理低比特权值神经网络的项目】'BitNetMCU: High Accuracy Low-Bit Quantized Neural Networks on a ...</title>
<link>https://weibo.com/1402400261/OcgWW02Zv</link>
<guid>https://weibo.com/1402400261/OcgWW02Zv</guid>
<content:encoded><![CDATA[
<div> 低端RISC-V微控制器 CH32V003, 低比特权值神经网络, 训练, 推理, BitNetMCU 项目, GitHub, 高精度, 低比特量化神经网络, 无需乘法

<br /><br />总结:
BitNetMCU是一个专注于在低端RISC-V微控制器CH32V003上训练和推理低比特权值神经网络的项目。该项目致力于实现在这种微控制器上进行神经网络训练和推理的功能，同时保持高精度和低比特量化。通过该项目，用户可以在低端设备上部署高效的神经网络模型，无需复杂的乘法运算，极大地节约了资源。有关该项目的更多信息可以在GitHub上找到。 <div>
【BitNetMCU: 专注于在低端RISC-V微控制器CH32V003上训练和推理低比特权值神经网络的项目】'BitNetMCU: High Accuracy Low-Bit Quantized Neural Networks on a low-end Microcontroller - Neural Networks with low bit weights on a CH32V003 RISC-V Microcontroller without multiplication' GitHub: github.com/cpldcpu/BitNetMCU <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpa2lr5i1hj20u00uqte7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 07:58:46 GMT</pubDate>
</item>
<item>
<title>【LLMSanitize：一个开源库，用于检测自然语言处理(NLP)数据集和大型语言模型(LLM)中的污染问题】'LLMSanitize - An open-source library for contamination det...</title>
<link>https://weibo.com/1402400261/OcgVWl5oG</link>
<guid>https://weibo.com/1402400261/OcgVWl5oG</guid>
<content:encoded><![CDATA[
<div> LLMSanitize、开源库、检测、自然语言处理、数据集、大型语言模型、污染问题、GitHub、ntunlp、污染检测<br />
<br />
LLMSanitize是一个开源库，旨在检测自然语言处理数据集和大型语言模型中的污染问题。该库可用于识别NLP数据集和LLMs中可能存在的污染的情况，有助于保证数据和模型的质量可靠性。用户可以通过GitHub上的ntunlp/LLMSanitize访问该库的资源和代码。LLMSanitize对于确保NLP数据集和LLMs的可靠性和准确性具有重要意义，是一个有益的工具。 <div>
【LLMSanitize：一个开源库，用于检测自然语言处理(NLP)数据集和大型语言模型(LLM)中的污染问题】'LLMSanitize - An open-source library for contamination detection in NLP datasets and Large Language Models (LLMs).' GitHub: github.com/ntunlp/LLMSanitize <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hpa2j7vxp2j20u010cgps.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 07:56:19 GMT</pubDate>
</item>
<item>
<title>【Panza: 私人电子邮件助手，通过在设备上训练和运行，定制化适应用户的写作风格和过往电子邮件历史】'Panza: A personal email assistant, trained and running...</title>
<link>https://weibo.com/1402400261/OcgVdB9Ei</link>
<guid>https://weibo.com/1402400261/OcgVdB9Ei</guid>
<content:encoded><![CDATA[
<div> 关键词: Panza, 私人电子邮件助手, 训练, 定制化, 写作风格, 电子邮件历史, GitHub, IST-DASLab, 设备, 运行

总结:<br /><br />
Panza是一款私人电子邮件助手，可以在设备上训练和运行。它能够定制化适应用户的写作风格和过往电子邮件历史。用户可以在GitHub上找到Panza的代码库，由IST-DASLab维护。这个助手可以在用户的设备上运行，为用户提供定制化的电子邮件写作帮助。 <div>
【Panza: 私人电子邮件助手，通过在设备上训练和运行，定制化适应用户的写作风格和过往电子邮件历史】'Panza: A personal email assistant, trained and running on-device' GitHub: github.com/IST-DASLab/PanzaMail <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpa2hd6s9wj20u015hdlp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 07:54:33 GMT</pubDate>
</item>
<item>
<title>【Glance：自托管的仪表板，能将所有信息源集成在一个界面上】'Glance - A selfhosted dashboard that puts all your feeds in one place' GitHub: github.com/g...</title>
<link>https://weibo.com/1402400261/OcgSevR2X</link>
<guid>https://weibo.com/1402400261/OcgSevR2X</guid>
<content:encoded><![CDATA[
<div> GitHub, Glance, 仪表板, 自托管, 信息源, 集成, 界面, 项目, 开源, 简洁<br />
<br />
要点1: 本文介绍了一个名为Glance的开源项目，是一个自托管的仪表板。<br />
要点2: Glance的主要功能是将用户的所有信息源集成在一个界面上，提供了简洁的展示和管理方式。<br />
要点3: 用户可以在Glance中自定义添加各种信息源，如新闻、社交媒体、博客等，方便快捷地查看和阅读。<br />
要点4: 这个仪表板可以帮助用户节省时间和精力，提高信息获取的效率和体验。<br />
要点5: Glance是一个开放源代码的项目，用户可以在GitHub上找到并了解更多相关信息，并有可能对其进行定制和修改。<br />
<br />
总结: 本文介绍了一个名为Glance的自托管仪表板项目，在提供简洁界面的基础上集成了用户所有信息源，方便用户快捷查看和阅读各种信息，帮助提高信息获取效率和体验。 Glance是开源项目，用户可以在GitHub上查看更多信息并可能定制修改。 <div>
【Glance：自托管的仪表板，能将所有信息源集成在一个界面上】'Glance - A selfhosted dashboard that puts all your feeds in one place' GitHub: github.com/glanceapp/glance <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpa299jro8j21940qt44e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 07:47:11 GMT</pubDate>
</item>
<item>
<title>【gigax：利用大型语言模型(LLM)驱动的NPC(非玩家角色)项目，旨在为游戏开发提供高性能的交互式角色】'gigax - LLM-powered NPCs running on your hardware' Git...</title>
<link>https://weibo.com/1402400261/OcgRFgC2h</link>
<guid>https://weibo.com/1402400261/OcgRFgC2h</guid>
<content:encoded><![CDATA[
<div> LLM、NPC、游戏开发、高性能、角色、项目、交互式、GitHub、驱动、大型语言模型

总结：<br /><br />这是一个利用大型语言模型(LLM)驱动的NPC(非玩家角色)项目，旨在为游戏开发提供高性能的交互式角色。该项目可以在用户的硬件上运行，并通过GitHub提供源代码。 <div>
【gigax：利用大型语言模型(LLM)驱动的NPC(非玩家角色)项目，旨在为游戏开发提供高性能的交互式角色】'gigax - LLM-powered NPCs running on your hardware' GitHub: github.com/GigaxGames/gigax <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5029247333367811"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax4.sinaimg.cn/orj480/5396ee05ly1hpa287oonxj214g0u0jsw.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/CX8quHsKlx08evTWdRUk01041200811T0E010.mp4?label=mp4_720p&amp;template=968x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714553613&amp;ssig=yrdU7F2A9w&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/3nJx84QHlx08evTW1TMA010412004bgp0E010.mp4?label=mp4_hd&amp;template=644x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714553613&amp;ssig=2lSOzg%2BZhV&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/ZjMTz2eylx08evTVWpCE010412002JiR0E010.mp4?label=mp4_ld&amp;template=484x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714553613&amp;ssig=1rFQOCFy6T&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5029247333367811" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Wed, 01 May 2024 07:45:47 GMT</pubDate>
</item>
<item>
<title>【关于视觉Mamba模型的精选文献资源库】'Awesome-Vision-Mamba-Models - [Official Repo] A Survey on Vision Mamba: Models, Applications and Challenges' Git...</title>
<link>https://weibo.com/1402400261/OcgJialGv</link>
<guid>https://weibo.com/1402400261/OcgJialGv</guid>
<content:encoded><![CDATA[
<div> 模型、视觉Mamba、应用、挑战、调查、GitHub、资源库、论文、研究、评估

<br /><br />总结:
这篇文章是关于视觉Mamba模型的文献资源库，提供了视觉Mamba模型的调查，包括模型、应用和挑战。研究人员在GitHub上发布了这一资源库，其中包含论文和研究，用于评估视觉Mamba模型的性能和应用。 <div>
【关于视觉Mamba模型的精选文献资源库】'Awesome-Vision-Mamba-Models - [Official Repo] A Survey on Vision Mamba: Models, Applications and Challenges' GitHub: github.com/Ruixxxx/Awesome-Vision-Mamba-Models <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hpa1msbnstj20u00zi0xp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 07:25:09 GMT</pubDate>
</item>
<item>
<title>【GlaDOS Personality Core是一个旨在创建一个真实版的GlaDOS（源自游戏《传送门》的人工智能角色）的软硬件项目】'GLaDOS Personality Core - Personality Core...</title>
<link>https://weibo.com/1402400261/OcgFn06SN</link>
<guid>https://weibo.com/1402400261/OcgFn06SN</guid>
<content:encoded><![CDATA[
<div> GitHub, GlaDOS, Personality Core, 人工智能, 软硬件项目, 游戏传送门

<br /><br />总结:
GlaDOS Personality Core是一个旨在创建真实版GlaDOS人工智能角色的软硬件项目。该项目在GitHub上以'GLaDOS Personality Core'命名，旨在模拟游戏传送门中的人工智能角色GlaDOS。项目中包含与GlaDOS个性相符的软件和硬件设计，通过GitHub网站分享给其他用户，以实现这个理想的目标。 <div>
【GlaDOS Personality Core是一个旨在创建一个真实版的GlaDOS（源自游戏《传送门》的人工智能角色）的软硬件项目】'GLaDOS Personality Core - Personality Core' GitHub: github.com/dnhkng/GlaDOS <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hpa1cq343qj20u00vyq7y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 07:15:29 GMT</pubDate>
</item>
<item>
<title>【Pydantic Logfire：Python 应用的开源可观测性平台】'Pydantic Logfire — Uncomplicated Observability - The best observability tool for Python! 🪵🔥...</title>
<link>https://weibo.com/1402400261/OcgBKetLT</link>
<guid>https://weibo.com/1402400261/OcgBKetLT</guid>
<content:encoded><![CDATA[
<div> Pydantic Logfire, Python 应用, 开源, 可观测性平台, GitHub, 简单, 观测, 工具, 最佳, 日志

<br /><br />总结:
Pydantic Logfire 是一个开源的可观测性平台，专为 Python 应用设计。它提供简单易用的观测工具，可以帮助用户实时监测和分析应用程序的运行情况。用户可以在 GitHub 上找到这个项目，并利用其强大的功能来提高应用程序的可观测性水平。Pydantic Logfire 是 Python 开发者的最佳选择，让你可以轻松地监控和管理应用程序的日志和性能数据。 <div>
【Pydantic Logfire：Python 应用的开源可观测性平台】'Pydantic Logfire — Uncomplicated Observability - The best observability tool for Python! 🪵🔥' GitHub: github.com/pydantic/logfire <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpa13g0of0j20u00zt44o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 07:06:34 GMT</pubDate>
</item>
<item>
<title>恭喜@只因我颠倒了辉煌_willschang 等3名用户获得【《多模态大模型：新一代人工智能技术范式》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果...</title>
<link>https://weibo.com/1402400261/OcgB9ihxA</link>
<guid>https://weibo.com/1402400261/OcgB9ihxA</guid>
<content:encoded><![CDATA[
<div> 关键词：多模态大模型、人工智能、新一代、技术范式、监督、抽奖、有效、中山大学、HCP 实验室、发展方向

总结:<br /><br />本次活动通过微博官方抽奖工具进行监督，公正有效。参与者有机会获得新一代人工智能技术书籍《多模态大模型：新一代人工智能技术范式》，由中山大学 HCP 实验室出品，全面介绍多模态大模型的技术方法、开源平台和应用场景，涵盖因果推理、世界模型和多智能体等前沿技术领域。这本书对于推动通用人工智能的发展具有重要意义。 <div>
恭喜<a href="https://weibo.com/n/%E5%8F%AA%E5%9B%A0%E6%88%91%E9%A2%A0%E5%80%92%E4%BA%86%E8%BE%89%E7%85%8C_willschang">@只因我颠倒了辉煌_willschang</a> 等3名用户获得【《多模态大模型：新一代人工智能技术范式》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20599842&amp;pageid=100140E51213728"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》，截至2024.5.1 12:00，*可可粉*转发+评论即可参与。中山大学 HCP 实验室出品，本书以深入浅出的方式介绍多模态大模型的技术方法、开源平台和应用场景，并详细阐述因果推理、世界模型及多智能体与具身智能等前沿技术领域，有助于读者全面了解多模态大模型的特点及发展方向，对新一代人工智能技术范式和通用人工智能的发展起到重要推动作用。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp1q8lh8x1j20m80m8djk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8n4hifj20m80m8gnu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8pgbfhj20m80m8dj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8r3pagj20m80m80ur.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 01 May 2024 07:05:06 GMT</pubDate>
</item>
<item>
<title>【Extension.js：即插即用、零配置、跨浏览器的扩展开发工具】'Extension.js - Plug-and-play, zero-config, cross-browser extension development tool.' GitHu...</title>
<link>https://weibo.com/1402400261/OcgB7vMVO</link>
<guid>https://weibo.com/1402400261/OcgB7vMVO</guid>
<content:encoded><![CDATA[
<div> 即插即用、零配置、跨浏览器、扩展、开发工具、GitHub、插件、开发、工具

<br /><br />总结:
Extension.js是一个即插即用、零配置、跨浏览器的扩展开发工具，可以帮助开发者快速创建插件并在不同浏览器上运行。通过GitHub的开源代码，用户可以方便地使用和定制这个工具。Extension.js为开发者提供了简单易用的方式来进行插件开发，省去了繁琐的配置过程，让开发过程更加高效和便捷。 <div>
【Extension.js：即插即用、零配置、跨浏览器的扩展开发工具】'Extension.js - Plug-and-play, zero-config, cross-browser extension development tool.' GitHub: github.com/cezaraugusto/extension.js <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hpa11u0y38j20xd0u0n12.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 07:05:02 GMT</pubDate>
</item>
<item>
<title>【The Borgo Programming Language：一种静态类型编程语言，可编译成Go语言，旨在提供比Go更丰富的表达力，同时比Rust更简洁】'The Borgo Programming Language ...</title>
<link>https://weibo.com/1402400261/OcgABigtQ</link>
<guid>https://weibo.com/1402400261/OcgABigtQ</guid>
<content:encoded><![CDATA[
<div> Go语言 静态类型 编程语言 Borgo 提供表达力 Rust 简洁 编译 Github<br />
<br />
总结:<br />
Borgo是一种静态类型编程语言，可以编译成Go语言。其目的是提供比Go更丰富的表达力，同时比Rust更简洁。Borgo的GitHub地址是github.com/borgo-lang/borgo。Borgo语言的特点包括静态类型、编译成Go语言、提供更丰富的表达力，同时保持简洁性。通过Borgo，开发者可以享受到Go语言的高效性，同时获得更灵活的编程能力。Borgo的设计旨在兼顾表达力和简洁性，为开发人员提供更好的编程体验。 <div>
【The Borgo Programming Language：一种静态类型编程语言，可编译成Go语言，旨在提供比Go更丰富的表达力，同时比Rust更简洁】'The Borgo Programming Language - Borgo is a statically typed language that compiles to Go.' GitHub: github.com/borgo-lang/borgo <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%BC%96%E7%A8%8B%23&amp;isnewpage=1"><span class="surl-text">#编程#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hpa10iifzwj20zi0u0410.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 07:03:45 GMT</pubDate>
</item>
<item>
<title>【TTS语音合成匿名竞技场】《TTS Arena - a Hugging Face Space by TTS-AGI》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/Oce6KEew7</link>
<guid>https://weibo.com/1402400261/Oce6KEew7</guid>
<content:encoded><![CDATA[
<div> 关键词：TTS Arena, Hugging Face Space, TTS-AGI, 匿名竞技场

总结:<br />《TTS Arena - a Hugging Face Space by TTS-AGI》是一个匿名竞技场，由TTS-AGI推出。这个竞技场提供了一个为用户生成TTS语音合成的空间，在这里用户可以体验不同声音风格和语言的合成。用户可以通过上传文本或选择预设话语，然后自定义声音风格和语言，进行语音合成。匿名竞技场为用户提供了更多选择和灵活性，让用户更加自由地尝试不同的语音合成应用场景。 <div>
【TTS语音合成匿名竞技场】《TTS Arena - a Hugging Face Space by TTS-AGI》 <a href="https://huggingface.co/spaces/TTS-AGI/TTS-Arena"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp9q251plsj20u60u0n0s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 00:44:43 GMT</pubDate>
</item>
<item>
<title>【免费课程：“视觉模型的提示工程”，教授如何使用文本、坐标和边框来引导视觉模型生成特定图像】《Prompt Engineering for Vision Models - DeepLearning.AI》...</title>
<link>https://weibo.com/1402400261/OcdSMz28o</link>
<guid>https://weibo.com/1402400261/OcdSMz28o</guid>
<content:encoded><![CDATA[
<div> 视觉模型、提示工程、文本、坐标、边框、生成特定图像<br />
<br />
视觉模型是深度学习中重要的技术，而本课程专注于视觉模型的提示工程，教授如何利用文本、坐标和边框来引导视觉模型生成特定图像。通过合理设计提示工程，可以帮助视觉模型更好地理解任务和生成准确的结果。在课程中，学习者将掌握如何利用提示工程来调整模型的输出，以满足特定需求。同时，课程还介绍了文本提示、位置提示和边框提示的具体应用和操作方法，帮助学习者更好地理解和掌握提示工程技术。总的来说，该课程为学习者提供了一个深入学习视觉模型提示工程的机会，帮助他们在实际应用中更好地利用这一技术。<br /><br />总结: 本课程介绍了视觉模型提示工程的重要性和具体操作方法，帮助学习者更好地理解如何利用文本、坐标和边框引导视觉模型生成特定图像。 <div>
【免费课程：“视觉模型的提示工程”，教授如何使用文本、坐标和边框来引导视觉模型生成特定图像】《Prompt Engineering for Vision Models - DeepLearning.AI》 <a href="https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp9p28wcxtj20ur0u0797.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 01 May 2024 00:10:18 GMT</pubDate>
</item>
<item>
<title>【Pinecone的RAG教程】《Retrieval Augmented Generation | Pinecone》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/OcdMnAw9s</link>
<guid>https://weibo.com/1402400261/OcdMnAw9s</guid>
<content:encoded><![CDATA[
<div> Retrieval Augmented Generation, Pinecone, RAG, 教程, 检索增强生成, 文章, 模型, 神经网络, 训练 <br />
<br />
RAG是一种检索增强的生成模型，结合了检索和生成的优点，能够更好地处理信息检索和生成任务。文章介绍了RAG的结构和原理，包括如何使用神经网络进行训练和优化。通过检索相关文本来指导生成的过程，提高生成文本的质量和相关性。RAG模型在自然语言处理领域有着广泛的应用前景，可以应用于问答系统、对话生成等多个领域，为文本生成任务带来了新的思路和方法。<br /><br />总结: <br />Retrieval Augmented Generation是一种结合了检索和生成的模型，可以提高文本生成任务的质量和相关性。通过检索相关文本来指导生成过程，在自然语言处理领域有着广泛的应用前景。 <div>
【Pinecone的RAG教程】《Retrieval Augmented Generation | Pinecone》 <a href="https://www.pinecone.io/learn/series/rag/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp9oleuqmfj20ku0qvjst.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 23:54:32 GMT</pubDate>
</item>
<item>
<title>【《爱丽丝在可微分奇境的冒险——第一卷，土地之旅》是一本关于现代(深度)神经网络设计的袖珍书，强调了构建高效处理N维数据模型的重要性，被人覆盖从卷积到Tra...</title>
<link>https://weibo.com/1402400261/OcdI88DC9</link>
<guid>https://weibo.com/1402400261/OcdI88DC9</guid>
<content:encoded><![CDATA[
<div> 深度神经网络、现代设计、关键主题、N维数据模型、卷积、Transformer、SSM、可微分、神经网络、土地之旅<br />
<br />
深度学习领域的新作《爱丽丝在可微分奇境的冒险——第一卷，土地之旅》强调了构建高效处理N维数据模型的重要性。作者从卷积神经网络到Transformer、SSM等主题展开讨论，引领读者探索现代神经网络设计的种种可能性。通过深度学习算法的应用，读者可以在神奇的可微分奇境中体验到不同寻常的冒险，实现对数据模型的更高效地处理和应用。这本袖珍书精炼而有深度，为深度学习领域的研究者提供了新的思路和灵感。整体而言，本书为读者呈现了一场关于现代神经网络设计的奇妙之旅。 <br /><br />总结: <div>
【《爱丽丝在可微分奇境的冒险——第一卷，土地之旅》是一本关于现代(深度)神经网络设计的袖珍书，强调了构建高效处理N维数据模型的重要性，被人覆盖从卷积到Transformer、SSM 及其他一些主题】《Alice's Adventures in a Differentiable Wonderland -- Volume I, A Tour of the Land》S Scardapane (2024) <a href="https://arxiv.org/abs/2404.17625"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp9oas34u9j20jo0p275r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 23:44:03 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《多模态大模型：新一代人工智能技术范式 ...</title>
<link>https://weibo.com/1402400261/OcdqZx5sz</link>
<guid>https://weibo.com/1402400261/OcdqZx5sz</guid>
<content:encoded><![CDATA[
<div> 中山大学, HCP 实验室, 多模态大模型, 人工智能, 技术方法, 开源平台, 应用场景, 因果推理, 世界模型, 多智能体, 具身智能

<br /><br />总结:
本书由中山大学 HCP 实验室出品，深入浅出地介绍了多模态大模型的技术方法、开源平台和应用场景，详细阐述了因果推理、世界模型、多智能体和具身智能等前沿技术领域。本书对读者全面了解多模态大模型的特点及发展方向起到了重要推动作用，为新一代人工智能技术范式和通用人工智能的发展提供了有益帮助。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》，截至2024.5.1 12:00，*可可粉*转发+评论即可参与。中山大学 HCP 实验室出品，本书以深入浅出的方式介绍多模态大模型的技术方法、开源平台和应用场景，并详细阐述因果推理、世界模型及多智能体与具身智能等前沿技术领域，有助于读者全面了解多模态大模型的特点及发展方向，对新一代人工智能技术范式和通用人工智能的发展起到重要推动作用。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp1q8lh8x1j20m80m8djk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8n4hifj20m80m8gnu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8pgbfhj20m80m8dj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8r3pagj20m80m80ur.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 23:01:49 GMT</pubDate>
</item>
<item>
<title>今日推介(第1392期)：Gemini模型的医学能力、生成式层次模型的高效分类、去噪和扩散、跨语言LLM自适应持续预训、人工偏好对齐对语言模型可信度的影响、揭示语言...</title>
<link>https://weibo.com/1402400261/Ocd9Yes8h</link>
<guid>https://weibo.com/1402400261/Ocd9Yes8h</guid>
<content:encoded><![CDATA[
<div> Gemini模型、医学能力、生成式层次模型、高效分类、去噪、扩散、跨语言LLM、自适应持续预训、人工偏好对齐、语言模型可信度、参数化知识

<br /><br />总结:
本文介绍了几个新颖的模型和技术，包括Gemini模型的医学能力、生成式层次模型在高效分类中的应用、去噪和扩散技术的实践、跨语言LLM的自适应持续预训方法，以及人工偏好对齐对语言模型可信度的影响等。这些研究和探索有助于揭示语言模型的参数化知识，推动人工智能领域的发展。 <div>
今日推介(第1392期)：Gemini模型的医学能力、生成式层次模型的高效分类、去噪和扩散、跨语言LLM自适应持续预训、人工偏好对齐对语言模型可信度的影响、揭示语言模型的参数化知识 公·众·号：爱可可爱生活 <a href="http://aicoco.net/s/8t"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp9lv5d94wj218g0r0q8z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp9lv7pbn8j21kc0kiq6r.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp9lvatmxfj21bw0motcp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp9lvdmz4yj21hu0u0grp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp9lvfzad3j20sc112n2x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 22:19:54 GMT</pubDate>
</item>
<item>
<title>[CL] From Persona to Personalization: A Survey on Role-Playing Language Agents 网页链接 通过构建角色扮演语言Agent(RPLA)人格类型分类体系，深入探讨了LLM...</title>
<link>https://weibo.com/1402400261/Ocd6XyMHs</link>
<guid>https://weibo.com/1402400261/Ocd6XyMHs</guid>
<content:encoded><![CDATA[
<div> Agent、角色扮演、人格类型、技术革新、应用热潮、风险、挑战

<br /><br />总结:
本文通过构建角色扮演语言Agent(RPLA)人格类型分类体系，深入探讨了LLM对RPLA带来的技术革新与应用热潮。同时，对研究中存在的风险与挑战进行了分析讨论。文章提出了研究角色扮演语言Agent的重要性，并指出了其在个性化交互领域的潜在应用价值。然而，随着技术的不断发展，也带来了对数据隐私和人工智能伦理等方面的担忧。进一步的研究和探讨将有助于解决这些挑战，推动角色扮演语言Agent技术的发展与应用。 <div>
[CL] From Persona to Personalization: A Survey on Role-Playing Language Agents  <br /><a href="https://arxiv.org/abs/2404.18231"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过构建角色扮演语言Agent(RPLA)人格类型分类体系，深入探讨了LLM给RPLA带来的技术革新与应用热潮，以及研究中存在的风险与挑战。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp9lnppmyxj20uw16oamp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp9lnq7mz0j21ja0xadx7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp9lnqkhdhj20zs1c0wrb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 22:12:29 GMT</pubDate>
</item>
<item>
<title>[CL] CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments 网页链接 CRISPR-GPT通过智能分解实验设计流程、集成专家知识和生物信息学工...</title>
<link>https://weibo.com/1402400261/Ocd3Gt6rl</link>
<guid>https://weibo.com/1402400261/Ocd3Gt6rl</guid>
<content:encoded><![CDATA[
<div> CRISPR-GPT, 智能分解, 实验设计流程, 专家知识, 生物信息学工具, 模块化, 简化, 自动化, 基因编辑实验

<br /><br />总结:
CRISPR-GPT是一种利用人工智能技术实现基因编辑实验设计自动化的方法。该方法通过智能分解实验设计流程、集成专家知识和生物信息学工具，将复杂的实验设计模块化、简化，使之更易于操作。利用CRISPR-GPT，研究人员可以更快地设计和进行基因编辑实验，提高实验效率和准确性。这一创新为基因编辑研究领域带来了新的可能性，有望推动科学家们更深入地探索基因编辑技术的应用和发展。 <div>
[CL] CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments  <br /><a href="https://arxiv.org/abs/2404.18021"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />CRISPR-GPT通过智能分解实验设计流程、集成专家知识和生物信息学工具，实现了CRISPR基因编辑实验设计的模块化、简化和自动化，使复杂的基因编辑实验更易于上手。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp9lfbgajvj20vm13gk38.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp9lfbx023j21kk142gwt.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp9lfc6v7pj21kw18en9f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 22:04:25 GMT</pubDate>
</item>
<item>
<title>[LG] A Survey on Diffusion Models for Time Series and Spatio-Temporal Data 网页链接 对时空数据分析中扩散模型的发展现状及应用进行了全面系统的调研总结，...</title>
<link>https://weibo.com/1402400261/Ocd02vxuC</link>
<guid>https://weibo.com/1402400261/Ocd02vxuC</guid>
<content:encoded><![CDATA[
<div> 扩散模型, 时空数据分析, 调研, 发展现状, 应用, 系统总结, 指导, 未来发展, 时间序列, 空间数据

总结:<br /><br />本文针对时空数据分析中的扩散模型进行了全面系统的调研，总结了其发展现状及应用情况。研究发现，扩散模型在时间序列和空间数据分析中有着重要的作用，并为未来发展提供了指导。通过对不同扩散模型的比较和分析，可以更好地理解数据的变化规律，为实际应用提供支持。这将为时空数据分析领域的进一步发展提供重要参考，促进相关技术和方法的创新和应用。 <div>
[LG] A Survey on Diffusion Models for Time Series and Spatio-Temporal Data  <br /><a href="https://arxiv.org/abs/2404.18886"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />对时空数据分析中扩散模型的发展现状及应用进行了全面系统的调研总结，为该领域的未来发展提供了重要指导。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp9l5z9bzgj20ye18q4h4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp9l5zgtlcj21om0xo7gk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp9l5zswd0j21ie0x0gtp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 21:55:26 GMT</pubDate>
</item>
<item>
<title>[LG] DPO Meets PPO: Reinforced Token Optimization for RLHF 网页链接 通过建立Token级MDP框架，提出RTO算法，将DPO与PPO结合进行Token级策略优化，在对话对齐...</title>
<link>https://weibo.com/1402400261/OccY5h07P</link>
<guid>https://weibo.com/1402400261/OccY5h07P</guid>
<content:encoded><![CDATA[
<div> DPO，PPO，Token级MDP框架，RTO算法，Token级策略优化，对话对齐任务，样本效率，性能提升

<br /><br />总结:
本文提出了一种新的强化学习方法，即RTO算法，通过建立Token级MDP框架将DPO与PPO相结合，实现了Token级策略优化。在对话对齐任务中，该算法展现出了显著的样本效率和性能提升。通过优化Token级策略，实现了更高效的学习和更好的任务表现。该方法为解决强化学习中的优化问题提供了一种新的思路和方法。 <div>
[LG]  DPO Meets PPO: Reinforced Token Optimization for RLHF  <br /><a href="https://arxiv.org/abs/2404.18922"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过建立Token级MDP框架，提出RTO算法，将DPO与PPO结合进行Token级策略优化，在对话对齐任务中展现出样本效率和性能的显著提升。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp9l0ymeihj210m1b8dyc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp9l0ywh2qj21rm0ieteb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp9l0z5cbgj21rm0ywtl4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 21:50:37 GMT</pubDate>
</item>
<item>
<title>提出评估框架系统地比较实例归因和神经元归因方法，发现两者可相互补充，呼吁未来研究综合运用两种方法以更全面地理解语言模型内部机制。 - 转发 @爱可可-爱生活...</title>
<link>https://weibo.com/1402400261/OccVqEnii</link>
<guid>https://weibo.com/1402400261/OccVqEnii</guid>
<content:encoded><![CDATA[
<div> 神经元归因方法, 实例归因方法, 评估框架, 语言模型, 内部机制, 全面理解, 神经网络, 语义理解, 实验结果<br />
<br />
总结:<br />
本文提出了一个评估框架，系统地比较了实例归因和神经元归因方法。研究发现，这两种方法可以相互补充，未来的研究应综合运用这两种方法来更全面地理解语言模型的内部机制。神经元归因方法和实例归因方法在对语言模型的参数知识进行揭示时起着重要作用，能够帮助理解神经网络的语义理解能力。实验结果表明，综合应用这两种方法可以更准确地揭示语言模型内部的工作原理。 <div>
提出评估框架系统地比较实例归因和神经元归因方法，发现两者可相互补充，呼吁未来研究综合运用两种方法以更全面地理解语言模型内部机制。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods》H Yu, P Atanasova, I Augenstein [University of Copenhagen] (2024) <a href="https://arxiv.org/abs/2404.18655"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp9kondydgj20kg1b4alk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp9konrvg3j20sc112465.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp9konvbldj21k20sqjyc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp9konx9saj20s60redjo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp9ku131l2j20hs0gw75a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp9ku13d03j20hp0gut9p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp9ku15bg2j20zv1hetfc.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 21:44:05 GMT</pubDate>
</item>
<item>
<title>[CL]《Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods》H Yu, P Atanasova, I Augenstein [University ...</title>
<link>https://weibo.com/1402400261/OccVn7Ryv</link>
<guid>https://weibo.com/1402400261/OccVn7Ryv</guid>
<content:encoded><![CDATA[
<div> 参数化知识、语言模型、归因方法、统一框架、University of Copenhagen<br />
<br />
总结:<br />
该研究提出了一个统一框架，用于揭示语言模型的参数化知识。研究团队来自哥本哈根大学，提出了针对归因方法的新思路。通过这个框架，他们可以更好地理解语言模型的工作原理，从而提高模型的性能和效率。这项研究对于深入研究自然语言处理领域具有重要意义。 <div>
[CL]《Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods》H Yu, P Atanasova, I Augenstein [University of Copenhagen] (2024) <a href="https://arxiv.org/abs/2404.18655"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp9kondydgj20kg1b4alk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp9konrvg3j20sc112465.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp9konvbldj21k20sqjyc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp9konx9saj20s60redjo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp9ku131l2j20hs0gw75a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp9ku13d03j20hp0gut9p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp9ku15bg2j20zv1hetfc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 21:43:56 GMT</pubDate>
</item>
<item>
<title>通过对比三种 RLHF 变体在通用数据集上的效果，揭示了偏好学习与可信度之间的复杂内在联系，为构建既强大又可信赖的语言模型提供了宝贵启示。 - 转发 @爱可可-爱...</title>
<link>https://weibo.com/1402400261/OccSBfS7J</link>
<guid>https://weibo.com/1402400261/OccSBfS7J</guid>
<content:encoded><![CDATA[
<div> 关键词: RLHF, 偏好学习, 可信度, 语言模型, 通用数据集, 内在联系, 启示, 宝贵

总结:<br /><br />
该研究通过比较三种RLHF变体在通用数据集上的效果，揭示了偏好学习与可信度之间的复杂内在联系。研究结果为构建强大且可信赖的语言模型提供了宝贵启示。这表明人类偏好对语言模型的可信度有重要影响，通过对偏好的学习可以提高模型的可信度。在实验中，研究者结合人类偏好信息，改进了RLHF算法，进一步提升了模型的性能表现。通过这些实验，不仅有助于深入理解语言模型信任度和偏好学习之间的关系，也为提高语言模型的可靠性提供了有效方法。因此，结合偏好学习的RLHF算法在语言模型中具有广泛应用和深远意义。 <div>
通过对比三种 RLHF 变体在通用数据集上的效果，揭示了偏好学习与可信度之间的复杂内在联系，为构建既强大又可信赖的语言模型提供了宝贵启示。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《More RLHF, More Trust? On The Impact of Human Preference Alignment On Language Model Trustworthiness》A J. Li, S Krishna, H Lakkaraju [Harvard University] (2024) <a href="https://arxiv.org/abs/2404.18870"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp9kgkdovfj21e00tm170.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp9kgktyfij21jq0v2ahb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp9kgkxm0hj21gk0uy79j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp9kgl2fysj21jq0vwdms.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 21:37:06 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.30)》 爱可可微博热门分享(4.30) [图片]</title>
<link>https://weibo.com/1402400261/Oca0REMp3</link>
<guid>https://weibo.com/1402400261/Oca0REMp3</guid>
<content:encoded><![CDATA[
<div> 微博、爱可可、热门分享、4.30、关键词

<br /><br />总结：
4.30日，爱可可微博上的热门分享引起了广泛关注。内容丰富多样，涵盖了各个领域的话题。其中，不乏有关时事热点、娱乐八卦、美食文化等内容。用户们积极评论点赞，互动热烈。这些热门分享展现了爱可可微博平台的活力和吸引力，吸引了大批用户的关注和参与。在未来，爱可可微博将继续提供优质内容，为用户带来更多精彩内容和互动体验。 <div>
《爱可可微博热门分享(4.30)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405028984302993519"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.30)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp97z7zjidj20rs0fmjuo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 14:19:14 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《HPNet: Dynamic Trajectory Forecasting with Historical Prediction Attention》(CVPR 2024) GitHub: github.com/XiaolongTang23/HPNet [f...</title>
<link>https://weibo.com/1402400261/Oc6EV9JaA</link>
<guid>https://weibo.com/1402400261/Oc6EV9JaA</guid>
<content:encoded><![CDATA[
<div> HPNet, Dynamic Trajectory Forecasting, Historical Prediction Attention, CVPR 2024, GitHub, XiaolongTang23, VadCLIP, Vision-Language Models, Weakly Supervised Video Anomaly Detection, AAAI 2024, nwpu-zxr, 2D Gaussian Splatting, Geometrically Accurate Radiance Fields, TimSong412, HandNeRF, Hand-Object Interaction Scene, Single RGB Image, Hongsukchoi, MolTC, Molecular Relational Modeling, Language Models, MangoKiller, Protein design, Guided Discrete Diffusion, prescient-design, Segment Any 3D Object, Language, CVRP-SOLE, CorrespondentDream, 3D Fidelity, Text-to-3D, Cross-View Correspondences, wookiekim, Ag2Manip, Learning, Novel Manipulation Skills, Agent-Agnostic Visual, Action Representations, Xiaoyao-Li  
  
<br /><br />总结:  
《HPNet: Dynamic Trajectory Forecasting with Historical Prediction Attention》提出了一种动态轨迹预测方法，利用历史预测关注力来提高预测准确性，GitHub链接为github.com/XiaolongTang23/HPNet。  
《VadCLIP: Adapting Vision-Language Models for Weakly Supervised Video Anomaly Detection》针对弱监督视频异常检测问题，提出了VadCLIP方法，并在AAAI 2024上发表，GitHub链接为github.com/nwpu-zxr/VadCLIP。  
《2D Gaussian Splatting for Geometrically Accurate Radiance Fields》介绍了一种2D高斯散开法，用于准确计算辐射场，GitHub链接为github.com/TimSong412/2D-surfel-gaussian。  
《HandNeRF: Learning to Reconstruct Hand-Object Interaction Scene from a Single RGB Image》描述了利用单一RGB图像学习重建手-物体交互场景的HandNeRF方法，GitHub链接为github.com/hongsukchoi/HandNeRF_RELEASE。  
《MolTC: Towards Molecular Relational Modeling In Language Models》致力于在语言模型中实现分子关系建模，GitHub链接为github.com/MangoKiller/MolTC。  
《Protein design with guided discrete diffusion》介绍了引导离散扩散方法来进行蛋白设计，GitHub链接为github.com/prescient-design/cortex。  
《Segment Any 3D Object with Language》提出了一种基于语言的任意3D物体分割方法，GitHub链接为github.com/CVRP-SOLE/SOLE。  
《CorrespondentDream: Enhancing 3D Fidelity of Text-to-3D using Cross-View Correspondences》利用交叉视图对应关系来提高文本到3D图像的精度，GitHub链接为github.com/wookiekim/CorrespondentDream。  
《Ag2Manip: Learning Novel Manipulation Skills with Agent-Agnostic Visual and Action Representations》描述了一种利用视觉和动作表示学习新的操纵技能的方法，GitHub链接为github.com/Xiaoyao-Li/Ag2Manip。 <div>
几篇论文实现代码：<br />《HPNet: Dynamic Trajectory Forecasting with Historical Prediction Attention》(CVPR 2024) GitHub: github.com/XiaolongTang23/HPNet [fig3] <br />《VadCLIP: Adapting Vision-Language Models for Weakly Supervised Video Anomaly Detection》(AAAI 2024) GitHub: github.com/nwpu-zxr/VadCLIP [fig2]<br />《2D Gaussian Splatting for Geometrically Accurate Radiance Fields》(2024) GitHub: github.com/TimSong412/2D-surfel-gaussian<br />《HandNeRF: Learning to Reconstruct Hand-Object Interaction Scene from a Single RGB Image》(2024) GitHub: github.com/hongsukchoi/HandNeRF_RELEASE [fig1]<br />《MolTC: Towards Molecular Relational Modeling In Language Models》(2024) GitHub: github.com/MangoKiller/MolTC<br />《Protein design with guided discrete diffusion》(2024) GitHub: github.com/prescient-design/cortex<br />《Segment Any 3D Object with Language》(2024) GitHub: github.com/CVRP-SOLE/SOLE<br />《CorrespondentDream: Enhancing 3D Fidelity of Text-to-3D using Cross-View Correspondences》(2024) GitHub: github.com/wookiekim/CorrespondentDream<br />《Ag2Manip: Learning Novel Manipulation Skills with Agent-Agnostic Visual and Action Representations》(2024) GitHub: github.com/Xiaoyao-Li/Ag2Manip [fig4]<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp8qu9c84pj20xw0bq7ca.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp8qwp9rf8j21ji0um7kl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp8ranf824j25qt1hhe82.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp8sjmbotsj217q0b7dwk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 05:46:55 GMT</pubDate>
</item>
<item>
<title>【Dokploy：开源的自托管平台即服务(PaaS)，简化了使用 Docker 和 Traefik 部署和管理应用程序及数据库的过程】'Dokploy - Open Source Alternative to Vercel, ...</title>
<link>https://weibo.com/1402400261/Oc6ESv6zz</link>
<guid>https://weibo.com/1402400261/Oc6ESv6zz</guid>
<content:encoded><![CDATA[
<div> 开源、自托管、平台即服务、简化、部署、Docker、Traefik、应用程序、数据库

<br /><br />总结:
Dokploy是一个开源的自托管平台即服务，可以简化使用Docker和Traefik部署和管理应用程序及数据库的过程。用户可以通过GitHub找到Dokploy的代码仓库。相比于Vercel、Netlify和Heroku等平台，Dokploy提供了一种开源替代方案，让用户能够更灵活地部署和管理他们的应用程序。通过Dokploy，用户可以更方便地实现应用程序的部署和管理，提高开发效率并降低运维成本。Dokploy的开源特性使得用户可以根据自己的需求进行定制和扩展，满足不同用户的个性化需求。使用Dokploy可以让开发者更轻松地搭建自己的应用程序环境，提供了一种更自由、更灵活的选择。 <div>
【Dokploy：开源的自托管平台即服务(PaaS)，简化了使用 Docker 和 Traefik 部署和管理应用程序及数据库的过程】'Dokploy - Open Source Alternative to Vercel, Netlify and Heroku.' GitHub: github.com/Dokploy/dokploy <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp8t5uj9arj20yk0u0gpu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 05:46:49 GMT</pubDate>
</item>
<item>
<title>'linux 编程环境学习笔记，含 linux 基本命令，linux 操作系统，linux 下 C++ 编程等' GitHub: github.com/jinbooooom/linux #开源# #Linux# [图片]</title>
<link>https://weibo.com/1402400261/Oc6yUg9jr</link>
<guid>https://weibo.com/1402400261/Oc6yUg9jr</guid>
<content:encoded><![CDATA[
<div> Linux、编程环境、学习、基本命令、操作系统、C++、GitHub、笔记、程序开发、开源<br />
<br />
Linux 编程环境学习笔记是关于在 Linux 系统下学习程序开发的一份资料，其中包含了 Linux 的基本命令和操作系统知识。通过学习这份笔记，你可以掌握在 Linux 环境下进行 C++ 编程的基本技能。GitHub 上有这份笔记的详细内容，可以进一步深入学习和了解。<br />
<br />
总结: <br />
1. 提供了学习 Linux 编程环境和基本命令的学习笔记。<br />
2. 包含了 Linux 操作系统相关的知识和 C++ 编程技能。<br />
3. GitHub 上有详细的资料供深入学习。<br /> <div>
'linux 编程环境学习笔记，含 linux 基本命令，linux 操作系统，linux 下 C++ 编程等' GitHub: github.com/jinbooooom/linux <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Linux%23"><span class="surl-text">#Linux#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp8sqpcc1uj216v0u0jw7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 05:32:06 GMT</pubDate>
</item>
<item>
<title>【AWS官方提供的关于在AWS上进行大规模模型分布式训练的最佳实践、参考架构、模型训练示例和工具的集合】'ML Training Reference Architectures &amp; Tests - Colle...</title>
<link>https://weibo.com/1402400261/Oc6qUzOOL</link>
<guid>https://weibo.com/1402400261/Oc6qUzOOL</guid>
<content:encoded><![CDATA[
<div> GitHub、分布式训练、模型、训练示例、工具、最佳实践、参考架构、大规模、AWS<br />
<br />总结：<br />
该文章介绍了在AWS平台上实施大规模模型分布式训练的最佳实践、参考架构、模型训练示例和工具集合。通过GitHub仓库提供的内容，用户可以了解如何在AWS上进行大规模模型训练，包括最佳实践、参考架构和使用工具的示例。这些资源能够帮助用户更好地利用AWS平台进行模型训练，提高训练效率和性能。 <div>
【AWS官方提供的关于在AWS上进行大规模模型分布式训练的最佳实践、参考架构、模型训练示例和工具的集合】'ML Training Reference Architectures &amp; Tests - Collection of best practices, reference architectures, model training examples and utilities to train large models on AWS.' GitHub: github.com/aws-samples/awsome-distributed-training <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp8s6be0hdj20x60u0wjh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 05:12:25 GMT</pubDate>
</item>
<item>
<title>【Create TSI：低代码生成 AI 应用的 RAG(Retrieval-Augmented Generation)工具包】'Create TSI - Create-tsi is a generative AI RAG toolkit which generates ...</title>
<link>https://weibo.com/1402400261/Oc6fH8tKQ</link>
<guid>https://weibo.com/1402400261/Oc6fH8tKQ</guid>
<content:encoded><![CDATA[
<div> 低代码生成、AI 应用、RAG、工具包、Create TSI、GitHub、generative AI、低代码、生成、应用<br />
<br />
提到了一个名为Create TSI的RAG工具包，可以帮助生成低代码的AI应用。这个工具包可以在GitHub上找到，可以生成具有创造性的AI应用，而且只需要很少的代码。Create TSI的生成方式采用了Retrieval-Augmented Generation技术，可以有效提高生成的效率和质量。这个工具包是一个强大的工具，对于需要快速生成AI应用的开发者来说是一种很好的选择。 <div>
【Create TSI：低代码生成 AI 应用的 RAG(Retrieval-Augmented Generation)工具包】'Create TSI - Create-tsi is a generative AI RAG toolkit which generates AI Applications with low code.' GitHub: github.com/telekom/create-tsi <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp8rcedgv7j21ji0jqdjq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 04:44:46 GMT</pubDate>
</item>
<item>
<title>【XCap：用 Rust 编写的跨平台的屏幕捕获库，它支持 Linux(X11,Wayland)、MacOS 与 Windows。XCap 支持截图与视频录制(待实现)】’XCap - a cross-platform scre...</title>
<link>https://weibo.com/1402400261/Oc6dfplVz</link>
<guid>https://weibo.com/1402400261/Oc6dfplVz</guid>
<content:encoded><![CDATA[
<div> Rust, 跨平台, 屏幕捕获库, Linux, MacOS, Windows, 截图, 视频录制, GitHub

<br /><br />
总结: XCap 是一个用 Rust 编写的跨平台屏幕捕获库，支持 Linux (X11, Wayland)、MacOS 和 Windows。它可以进行截图并计划实现视频录制功能。项目地址在 GitHub 上：github.com/nashaofu/xcap。 <div>
【XCap：用 Rust 编写的跨平台的屏幕捕获库，它支持 Linux(X11,Wayland)、MacOS 与 Windows。XCap 支持截图与视频录制(待实现)】’XCap - a cross-platform screen capture library written in Rust. It supports Linux (X11, Wayland), MacOS, and Windows. XCap supports screenshot and video recording (to be implemented).' GitHub: github.com/nashaofu/xcap <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp8r7949x8j21600u0776.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 04:38:45 GMT</pubDate>
</item>
<item>
<title>【cortex：为深度学习系统设计的模块化架构库，支持多任务、引导生成和多模态模型】'cortex - A Modular Architecture for Deep Learning Systems - A Modular A...</title>
<link>https://weibo.com/1402400261/Oc6cpySlk</link>
<guid>https://weibo.com/1402400261/Oc6cpySlk</guid>
<content:encoded><![CDATA[
<div> 模块化架构库、深度学习系统、多任务、引导生成、多模态模型、GitHub、cortex
<br />
<br />
总结:
文章介绍了cortex，这是一个为深度学习系统设计的模块化架构库，支持多任务、引导生成和多模态模型。该库的GitHub页面为github.com/prescient-design/cortex。cortex的设计旨在提供灵活性和可扩展性，使用户可以轻松构建复杂的深度学习系统。采用模块化设计的cortex能够支持不同类型的任务并且提供更好的模型性能。此外，cortex还提供了引导生成和多模态模型的支持，使用户能够更好地处理多样的数据类型和任务要求。通过使用cortex，用户可以更便捷地开发深度学习系统，从而加速模型的研发和部署过程。 <div>
【cortex：为深度学习系统设计的模块化架构库，支持多任务、引导生成和多模态模型】'cortex - A Modular Architecture for Deep Learning Systems - A Modular Architecture for Deep Learning Systems' GitHub: github.com/prescient-design/cortex <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp8r4y47vlj210d0u0ae6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 04:36:41 GMT</pubDate>
</item>
<item>
<title>【GPTLint：利用大型语言模型(LLM)来强化代码库最佳实践的代码质量检查工具】'GPTLint - A linter with superpowers! Use LLMs to enforce best practices acros...</title>
<link>https://weibo.com/1402400261/Oc69DrsG9</link>
<guid>https://weibo.com/1402400261/Oc69DrsG9</guid>
<content:encoded><![CDATA[
<div> GPTLint, 代码质量检查工具, 大型语言模型, 强化最佳实践, 代码库, GitHub, linter, best practices, superpowers, enforcement

<br /><br />总结:
GPTLint是一个利用大型语言模型(LLM)的代码质量检查工具，旨在强化代码库最佳实践。通过GitHub上的项目，用户可以使用该工具来确保代码符合最佳实践标准，并具有超级功能。GPTLint可以帮助开发团队在编写代码时更加规范，从而提高代码质量。通过结合LLMs的能力，GPTLint提供了一种强大的方式来进行代码质量检查，帮助开发人员提升编程技能和代码质量。 <div>
【GPTLint：利用大型语言模型(LLM)来强化代码库最佳实践的代码质量检查工具】'GPTLint - A linter with superpowers! Use LLMs to enforce best practices across your codebase.' GitHub: github.com/gptlint/gptlint <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp8qy2kvk2j20u00yfjvb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 04:29:51 GMT</pubDate>
</item>
<item>
<title>'基于C++开发的视频行为分析系统v4系统' GitHub: github.com/any12345com/BXC_VideoAnalyzer_v4 #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/Oc68Tsj50</link>
<guid>https://weibo.com/1402400261/Oc68Tsj50</guid>
<content:encoded><![CDATA[
<div> 视频行为分析系统、C++开发、GitHub、版本4、系统、代码库、功能强大、视频处理、行为识别

<br /><br />总结:
该文章介绍了基于C++开发的视频行为分析系统v4系统，代码库托管在GitHub上。该系统版本更新至第4版，具有强大的功能，可进行视频处理和行为识别。 <div>
'基于C++开发的视频行为分析系统v4系统' GitHub: github.com/any12345com/BXC_VideoAnalyzer_v4 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp8qvlmcguj21hc0u00zf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 04:28:01 GMT</pubDate>
</item>
<item>
<title>'中文羊驼大模型三期项目 (Chinese Llama-3 LLMs) developed from Meta Llama 3' GitHub: github.com/ymcui/Chinese-LLaMA-Alpaca-3 #开源# #机器学习# #人工智...</title>
<link>https://weibo.com/1402400261/Oc66q0f6i</link>
<guid>https://weibo.com/1402400261/Oc66q0f6i</guid>
<content:encoded><![CDATA[
<div> 关键词: 中文羊驼大模型三期项目, Meta Llama 3, GitHub, ymcui, Alpaca 3

<br /><br />
总结: 
该项目是基于Meta Llama 3发展的中文羊驼大模型三期项目。代码存储在GitHub上，地址为github.com/ymcui/Chinese-LLaMA-Alpaca-3。项目旨在提供高质量的中文语言模型，为自然语言处理领域的研究和应用提供支持。通过使用Alpaca 3模型，用户可以获得更准确、更精确的中文语言处理结果。如果你是需要中文语言处理模型的研究人员或开发者，可以通过GitHub了解更多关于该项目的信息。 <div>
'中文羊驼大模型三期项目 (Chinese Llama-3 LLMs) developed from Meta Llama 3' GitHub: github.com/ymcui/Chinese-LLaMA-Alpaca-3 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp8qps8dfbj20zz0u0tfw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 04:21:55 GMT</pubDate>
</item>
<item>
<title>【Kaytu：一个开源工具，旨在帮助工程、DevOps和SRE团队通过分析实际使用情况推荐最优的工作负载配置，以减少云成本】'Kaytu - The Kaytu CLI helps you save on...</title>
<link>https://weibo.com/1402400261/Oc6528Ebk</link>
<guid>https://weibo.com/1402400261/Oc6528Ebk</guid>
<content:encoded><![CDATA[
<div> 开源工具、工程团队、DevOps、SRE团队、云成本、分析实际使用情况、推荐最优工作负载配置、减少云成本、GitHub、历史使用情况分析、定制化建议

<br /><br />总结:
开源工具Kaytu是一个CLI工具，旨在帮助工程、DevOps和SRE团队通过分析实际使用情况推荐最优的工作负载配置，以减少云成本。Kaytu通过分析历史使用情况提供定制化建议，确保你只支付所需资源的成本。GitHub链接为github.com/kaytu-io/kaytu。Kaytu的功能包括分析历史使用情况，提供定制化建议，帮助节省云成本。通过Kaytu工具，用户可以找到最适合的服务器规格，避免浪费资源。Kaytu的使用简单高效，适用于各种工程团队和SRE团队。 <div>
【Kaytu：一个开源工具，旨在帮助工程、DevOps和SRE团队通过分析实际使用情况推荐最优的工作负载配置，以减少云成本】'Kaytu - The Kaytu CLI helps you save on cloud costs by finding the perfect server sizes. Kaytu analyzes historical usage and provides tailored recommendations, ensuring you only pay for the resources you need.' GitHub: github.com/kaytu-io/kaytu <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp8qlcb8hnj20wb0u0djg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 04:18:30 GMT</pubDate>
</item>
<item>
<title>【LLM Datasets：为大型语言模型(LLM)微调提供高质量数据集、工具和概念的公共库】'LLM Datasets - High-quality datasets, tools, and concepts for LLM fine-t...</title>
<link>https://weibo.com/1402400261/Oc62p5juj</link>
<guid>https://weibo.com/1402400261/Oc62p5juj</guid>
<content:encoded><![CDATA[
<div> 数据集、工具、概念、高质量、LLM、微调、公共库、GitHub、mlabonne、llm-datasets
<br /><br />总结:
LLM Datasets是一个旨在为大型语言模型(LLM)微调提供高质量数据集、工具和概念的公共库。该库包含丰富的数据集、工具和概念，方便用户进行LLM的微调工作。用户可以在GitHub上找到该项目，通过mlabonne/llm-datasets访问相关信息。通过这个项目，用户可以轻松地找到用于LLM微调的高质量数据集和工具，提升模型的性能和效果。 <div>
【LLM Datasets：为大型语言模型(LLM)微调提供高质量数据集、工具和概念的公共库】'LLM Datasets - High-quality datasets, tools, and concepts for LLM fine-tuning.' GitHub: github.com/mlabonne/llm-datasets <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp8qfhpcz4j20u00x70yi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 04:12:01 GMT</pubDate>
</item>
<item>
<title>【在GPU上进行矩阵乘法时，使用“可预测”数据可以提高运算速度】- 矩阵乘法在GPU上的速度受到数据内容的影响，与直觉相反。 - 使用CUTLASS库进行矩阵乘法时，性...</title>
<link>https://weibo.com/1402400261/Oc4wii2o9</link>
<guid>https://weibo.com/1402400261/Oc4wii2o9</guid>
<content:encoded><![CDATA[
<div> GPU，矩阵乘法，速度，数据，CUTLASS库，CuBLAS，Python，功耗，零矩阵，时钟速度

总结:<br /><br />矩阵乘法在GPU上的速度受数据内容影响，使用“可预测”数据可以提高运算速度。CUTLASS库在GPU上进行矩阵乘法时比CuBLAS性能高出10%，但在Python环境中性能提升消失，因为CUTLASS默认初始化输入值为整数。GPU的动态功耗切换是影响矩阵乘法性能的关键因素，特别是当数据中包含大量零时。当GPU接近功率限制时，会通过降低电压和时钟频率来限制功耗，影响性能。通过调整GPU的功率限制和时钟速度可以观察到使用可预测输入和不可预测输入的性能差异。 <div>
【在GPU上进行矩阵乘法时，使用“可预测”数据可以提高运算速度】<br />- 矩阵乘法在GPU上的速度受到数据内容的影响，与直觉相反。  <br />- 使用CUTLASS库进行矩阵乘法时，性能比CuBLAS高出10%。  <br />- 在Python环境中，CUTLASS的性能提升消失了，发现CUTLASS默认初始化输入值仅使用整数。  <br />- GPU的动态/切换功耗是影响矩阵乘法性能的关键因素，特别是当数据中包含大量零时。  <br />- GPU在接近其400W的功率限制时，会通过降低电压和时钟频率来限制功耗，从而影响性能。  <br />- 通过调整GPU的功率限制和时钟速度，可以观察到使用可预测输入(如全零矩阵)与不可预测输入(如正态分布)的性能差异。<br />《Strangely, Matrix Multiplications on GPUs Run Faster When Given "Predictable" Data! [short]》 <a href="https://www.thonking.ai/p/strangely-matrix-multiplications"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp8jptptpwj21110u0acd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp8jpw2um3j20dv057glm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp8jq71staj214g0mlmzn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 00:20:10 GMT</pubDate>
</item>
<item>
<title>【用Google Colab 15G 40分钟微调llama-3-8b-Instruct模型】《rombodawg/test_dataset_Codellama-3-8B · Hugging Face》 网页链接 #机器学习# #人工智能# [图片...</title>
<link>https://weibo.com/1402400261/Oc4pO61Hf</link>
<guid>https://weibo.com/1402400261/Oc4pO61Hf</guid>
<content:encoded><![CDATA[
<div> 微调、Google Colab、llama-3-8b、40分钟、模型、test_dataset、Codellama-3-8B、Hugging Face

<br /><br />总结:
本文介绍了如何在Google Colab上使用15G的资源，在40分钟内对llama-3-8b-Instruct模型进行微调。作者提供了测试数据集test_dataset_Codellama-3-8B，使用Hugging Face库进行模型微调。通过本文，读者可以学习如何利用资源充足的环境快速调整模型，进一步提升模型性能和效果。 <div>
【用Google Colab 15G 40分钟微调llama-3-8b-Instruct模型】《rombodawg/test_dataset_Codellama-3-8B · Hugging Face》 <a href="https://huggingface.co/rombodawg/test_dataset_Codellama-3-8B"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp8j8vveh5j20u00z00xs.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 00:04:11 GMT</pubDate>
</item>
<item>
<title>【GitHub Copilot Workspace 是一个创新的开发者环境，它允许开发者从构思到编码再到软件构建，全程使用自然语言与AI辅助进行】- GitHub Copilot Workspace旨在...</title>
<link>https://weibo.com/1402400261/Oc4o4DZiS</link>
<guid>https://weibo.com/1402400261/Oc4o4DZiS</guid>
<content:encoded><![CDATA[
<div> GitHub, Copilot Workspace, 开发者环境, 自然语言, AI辅助, 生产力提升, GitHub仓库, 团队协作, 移动设备

<br /><br />总结:
GitHub Copilot Workspace是一个创新的开发者环境，利用自然语言和AI辅助帮助开发者完成整个开发流程。自2022年推出以来，显著提升了开发者的生产力，最多可达55%。开发者可以在GitHub仓库或问题中开始项目，获得AI助手全程帮助。提供深入理解的逐步计划，所有提案可编辑，保证开发者控制开发过程。支持团队协作和迭代，可以直接在移动设备上运行代码，实现跨平台开发环境。 <div>
【GitHub Copilot Workspace 是一个创新的开发者环境，它允许开发者从构思到编码再到软件构建，全程使用自然语言与AI辅助进行】<br />- GitHub Copilot Workspace旨在重新定义开发者环境，让开发者可以通过自然语言完成从想法到代码再到软件的整个开发流程。  <br />- 该环境利用了生成性AI技术，自2022年推出以来，已经显著提升了开发者的生产力，最多可达55%。  <br />- 开发者可以在GitHub仓库或问题(issue)中开始他们的项目，Copilot Workspace会提供从AI助手开始的全面帮助。  <br />- Workspace提供了基于对代码库、问题回复等深入理解的逐步计划，所有提案都是可编辑的，以确保开发者可以控制开发过程的每一步。  <br />- 开发者可以在Copilot Workspace中直接运行代码，并通过链接与团队共享工作空间，便于团队协作和迭代。  <br />- GitHub Copilot Workspace支持移动设备，旨在实现一个无论在桌面、笔记本还是移动设备上都能使用的真正的开发环境。  <br />《GitHub Copilot Workspace: Welcome to the Copilot-native developer environment - The GitHub Blog》 <a href="https://github.blog/2024-04-29-github-copilot-workspace/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span> <span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5028767853117454"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a><br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax3.sinaimg.cn/orj480/5396ee05ly1hp8j4n8thnj20zk0k0wf1.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/oc5YpXcYlx08etN3vwcw01041200ldSe0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714451851&amp;ssig=TcS2VOkYe9&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/AwfNDBCzlx08etN3kKJO01041200aNH10E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714451851&amp;ssig=O1c3J6zLgX&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/WCCQGuS0lx08etN2Wmhy010412006VQs0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714451851&amp;ssig=plC7PidbrW&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5028767853117454" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 23:59:56 GMT</pubDate>
</item>
<item>
<title>【OpenAI与金融时报达成战略合作，将金融时报的世界级新闻内容整合到ChatGPT中，共同开发新的AI体验】《We’re bringing the Financial Times’ world-class jou...</title>
<link>https://weibo.com/1402400261/Oc4lHFKBk</link>
<guid>https://weibo.com/1402400261/Oc4lHFKBk</guid>
<content:encoded><![CDATA[
<div> OpenAI, 金融时报, 战略合作, 新闻内容,  ChatGPT, AI体验

<br /><br />总结: 
OpenAI与金融时报达成战略合作，将金融时报的世界级新闻内容整合到ChatGPT中，共同开发新的AI体验。这项合作旨在提升ChatGPT的资讯能力，使用户能够更便捷地获取和理解金融时报的优质新闻内容。金融时报的丰富资讯将为ChatGPT带来更深入、更全面的知识，从而提升用户的智能AI体验。该合作将为用户带来更丰富的交互体验，为金融毕竟的读者提供更便捷的获取新闻的方式，推动AI技术在新闻领域的发展。 <div>
【OpenAI与金融时报达成战略合作，将金融时报的世界级新闻内容整合到ChatGPT中，共同开发新的AI体验】<br />《We’re bringing the Financial Times’ world-class journalism to ChatGPT》 <a href="https://openai.com/blog/content-partnership-with-financial-times"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp8iz1obe1j21ea0u0juq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 23:54:05 GMT</pubDate>
</item>
<item>
<title>【StarCoder2-15B-Instruct-v0.1：首个完全自我对齐的代码生成大型语言模型(LLM)，通过全透明和开放的管线训练而成，实现了72.6的HumanEval得分，超越了CodeLlam...</title>
<link>https://weibo.com/1402400261/Oc4l73zZj</link>
<guid>https://weibo.com/1402400261/Oc4l73zZj</guid>
<content:encoded><![CDATA[
<div> 模型训练，自我对齐，代码生成，大型语言模型，全透明，开放管线，72.6分，人工评估，超越，CodeLlama

<br /><br />总结:
本文介绍了首个完全自我对齐的代码生成大型语言模型StarCoder2-15B-Instruct，通过全透明和开放的管线训练，实现了72.6的HumanEval得分，超越了CodeLlama-70B-Instruct。模型在训练过程中具有高度透明性，能够自我对齐，生成代码。模型的开放管线训练方法为其取得了优异的人工评估得分，展示了其在代码生成领域的潜力和性能优势。 <div>
【StarCoder2-15B-Instruct-v0.1：首个完全自我对齐的代码生成大型语言模型(LLM)，通过全透明和开放的管线训练而成，实现了72.6的HumanEval得分，超越了CodeLlama-70B-Instruct的72.0分】《StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation》 <a href="https://huggingface.co/blog/sc2-instruct"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp8ixirmwyj215k0u00xd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp8ixjwbxxj21m50u0wjc.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp8ixm9mk3j20u00wtgqr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 23:52:37 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：明日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《多模态大模型：新一代人工智能技术范式 ...</title>
<link>https://weibo.com/1402400261/Oc3F6fwu9</link>
<guid>https://weibo.com/1402400261/Oc3F6fwu9</guid>
<content:encoded><![CDATA[
<div> 多模态大模型、人工智能、技术方法、开源平台、应用场景、因果推理、世界模型、多智能体、具身智能、推动作用

总结:<br /><br />明日将进行开奖活动，截至2024年5月1日中午12:00前，转发并评论可参与抽奖活动，有机会赢得《多模态大模型：新一代人工智能技术范式》3本全彩版。本书由中山大学HCP实验室出品，以简单易懂的方式介绍了多模态大模型的技术方法、开源平台和应用场景，同时深入讨论了因果推理、世界模型、多智能体和具身智能等前沿技术领域。通过本书，读者可以全面了解多模态大模型的特点和发展方向，对新一代人工智能技术范式和通用人工智能的发展起到重要的推动作用。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：明日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》，截至2024.5.1 12:00，*可可粉*转发+评论即可参与。中山大学 HCP 实验室出品，本书以深入浅出的方式介绍多模态大模型的技术方法、开源平台和应用场景，并详细阐述因果推理、世界模型及多智能体与具身智能等前沿技术领域，有助于读者全面了解多模态大模型的特点及发展方向，对新一代人工智能技术范式和通用人工智能的发展起到重要推动作用。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp1q8lh8x1j20m80m8djk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8n4hifj20m80m8gnu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8pgbfhj20m80m8dj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8r3pagj20m80m80ur.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 22:09:07 GMT</pubDate>
</item>
<item>
<title>今日推介(第1391期)：LLM驱动的游戏叙事中玩家驱动的突发性、LLM评估对基准分布假设的鲁棒性检验、自适应位宽量化感知训练、对抗贝叶斯分类器的对抗性一致性和唯...</title>
<link>https://weibo.com/1402400261/Oc3Cmdj0a</link>
<guid>https://weibo.com/1402400261/Oc3Cmdj0a</guid>
<content:encoded><![CDATA[
<div> LLM、游戏叙事、玩家驱动、突发性、评估、基准分布假设、鲁棒性检验、自适应位宽量化、感知训练、对抗性一致性、唯一性、对抗贝叶斯分类器、基于SLAM、广域建筑环境、室内制图

<br /><br />总结:
本文讨论了LLM驱动的游戏叙事中玩家驱动的突发性以及LLM评估对基准分布假设的鲁棒性检验。其次，介绍了自适应位宽量化感知训练的概念。此外，论述了对抗贝叶斯分类器的对抗性一致性和唯一性。最后，研究了基于SLAM技术的广域建筑环境室内制图方法。这些研究成果可为相关领域的实践和研究提供有益参考。 <div>
今日推介(第1391期)：LLM驱动的游戏叙事中玩家驱动的突发性、LLM评估对基准分布假设的鲁棒性检验、自适应位宽量化感知训练、对抗贝叶斯分类器的对抗性一致性和唯一性、基于SLAM的广域建筑环境室内制图 公·众·号：爱可可爱生活 <a href="http://aicoco.net/s/8s"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp8fgbbldhj224c0u0wkl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp8fgd4jqrj21ju0ty45u.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp8fgftpspj21zj0u0jxd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp8fghr24rj213e0ga0wz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp8fgkf4lwj21kn0u0wpg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 22:02:22 GMT</pubDate>
</item>
<item>
<title>[IR] A Survey of Generative Search and Recommendation in the Era of Large Language Models 网页链接 生成式检索与推荐通过生成模型直接生成文档/项目标识符...</title>
<link>https://weibo.com/1402400261/Oc3vioIjL</link>
<guid>https://weibo.com/1402400261/Oc3vioIjL</guid>
<content:encoded><![CDATA[
<div> 生成搜索、推荐、大语言模型、文档、项目标识符、用户需求、传统匹配、新机遇

<br /><br />总结：
本文讨论了生成式检索与推荐在大语言模型时代的重要性。通过生成模型直接生成文档或项目标识符，满足用户需求，并与传统匹配范式形成对比，为检索与推荐领域带来了新的机遇。生成式搜索和推荐为用户提供更个性化、精准的结果，帮助用户更好地发现所需内容。在大语言模型的支持下，生成搜索和推荐技术将会有更广泛的应用，促进检索与推荐领域的发展。 <div>
[IR] A Survey of Generative Search and Recommendation in the Era of Large Language Models  <br /><a href="https://arxiv.org/abs/2404.16924"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />生成式检索与推荐通过生成模型直接生成文档/项目标识符以满足用户需求，与传统匹配范式形成鲜明对比，为检索与推荐领域带来新的机遇。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp8f8rvktuj20wy14kwun.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp8f8s7sq6j21oi0ikwkc.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp8f8sbc7dj21na0o6dka.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 21:44:58 GMT</pubDate>
</item>
<item>
<title>[CV] MovieChat+: Question-aware Sparse Memory for Long Video Question Answering 网页链接 提出ProblemChat+框架，通过问题感知记忆机制与预训练语言模型的...</title>
<link>https://weibo.com/1402400261/Oc3rmj3Us</link>
<guid>https://weibo.com/1402400261/Oc3rmj3Us</guid>
<content:encoded><![CDATA[
<div> 关键词: MovieChat+, 问题感知记忆机制, 预训练语言模型, 长视频理解

总结:<br />
提出了ProblemChat+框架，结合问题感知记忆机制与预训练语言模型，实现了高效且无需训练的长视频理解。该框架将问题编码成向量表示，并利用问题感知记忆机制将问题信息直接注入到编码过程中，从而提高了长视频问题回答的性能。框架通过提取问题相关的关键信息，创建了问题感知的稀疏记忆。此外，利用预训练语言模型对文本信息进行编码，进一步提升了长视频的理解能力。实验结果表明，提出的框架在长视频理解任务中表现出色，相较于其他方法具有更高的准确性和效率。通过探讨问题感知记忆机制和预训练语言模型的结合应用，为长视频问题回答领域的研究提供了新的思路和方法。 <div>
[CV] MovieChat+: Question-aware Sparse Memory for Long Video Question Answering  <br /><a href="https://arxiv.org/abs/2404.17176"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />提出ProblemChat+框架，通过问题感知记忆机制与预训练语言模型的结合，实现了高效、无需训练的长视频理解。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp8eyoo130j20xm18ih3c.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp8eyoupgpj21om0kq0yz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp8eypb7orj21oo18s4h3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 21:35:16 GMT</pubDate>
</item>
<item>
<title>提出在室内大场景条件下，通过集成激光与视觉的SLAM方法以及高斯splatting渲染技术，实现了高精度的3D环境重建。 - 转发 @爱可可-爱生活:&amp;ensp;[RO]《SLAM for I...</title>
<link>https://weibo.com/1402400261/Oc3p3bnFd</link>
<guid>https://weibo.com/1402400261/Oc3p3bnFd</guid>
<content:encoded><![CDATA[
<div> 激光、视觉、SLAM、高斯splatting、3D环境重建、室内、大场景、高精度、集成、技术

<br /><br />总结:
该研究利用集成激光与视觉的SLAM方法，在室内大场景条件下实现了高精度的3D环境重建。通过高斯splatting渲染技术，将宽阔建筑环境进行精准映射。研究展示了在大范围建筑环境中进行室内地图绘制的可行性，并为未来智能建筑管理提供了重要参考。 <div>
提出在室内大场景条件下，通过集成激光与视觉的SLAM方法以及高斯splatting渲染技术，实现了高精度的3D环境重建。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [RO]《SLAM for Indoor Mapping of Wide Area Construction Environments》V Ress, W Zhang, D Skuddis, N Haala, U Soergel [University of Stuttgart] (2024) <a href="https://arxiv.org/abs/2404.17215"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp8elu6zprj21o20i6tis.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp8eluznu2j21li0ugwwa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp8elv1p4fj20sa0pmte4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp8elv6d19j20se0saq6u.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp8esn6qxwj20sa0e00ut.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp8eso48zsj20ie1beali.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 21:29:35 GMT</pubDate>
</item>
<item>
<title>[RO]《SLAM for Indoor Mapping of Wide Area Construction Environments》V Ress, W Zhang, D Skuddis, N Haala, U Soergel [University of Stuttgart] (2024) ...</title>
<link>https://weibo.com/1402400261/Oc3p0e4km</link>
<guid>https://weibo.com/1402400261/Oc3p0e4km</guid>
<content:encoded><![CDATA[
<div> 室内建筑环境; SLAM; 宽范围; 地图; 建筑施工现场; 易用性; 高效性; 实时性; 数据采集; 高精度

<br /><br />总结:
本文介绍了一种利用SLAM技术在宽范围建筑施工环境中进行室内建筑环境的映射的方法。该方法包括数据采集和地图创建两个主要步骤，通过室内建筑环境的实时SLAM定位，提高了建筑施工现场的易用性和高效性。研究结果表明，该方法在实现高精度地图和实时性方面取得了很好的效果，有望在建筑施工领域得到广泛应用。 <div>
[RO]《SLAM for Indoor Mapping of Wide Area Construction Environments》V Ress, W Zhang, D Skuddis, N Haala, U Soergel [University of Stuttgart] (2024) <a href="https://arxiv.org/abs/2404.17215"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp8elu6zprj21o20i6tis.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp8eluznu2j21li0ugwwa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp8elv1p4fj20sa0pmte4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp8elv6d19j20se0saq6u.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp8esn6qxwj20sa0e00ut.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp8eso48zsj20ie1beali.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 21:29:28 GMT</pubDate>
</item>
<item>
<title>通过对抗贝叶斯分类器的唯一性刻画了对抗学习中凸损失一致性的充要条件，从统计角度深化了对抗学习的理解。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Adversarial Con...</title>
<link>https://weibo.com/1402400261/Oc3ljoGMN</link>
<guid>https://weibo.com/1402400261/Oc3ljoGMN</guid>
<content:encoded><![CDATA[
<div> 对抗学习、贝叶斯分类器、凸损失、一致性、统计角度、理解

<br /><br />总结:
本文探讨了对抗学习中的凸损失一致性与贝叶斯分类器的唯一性之间的关系，提出了充要条件，并从统计角度深化了对对抗学习的理解。在对抗学习中，要使贝叶斯分类器具有唯一性，需要保证凸损失一致性。该条件在统计角度下得到了验证，为对抗学习提供了新的理论支持，有助于更好地理解对抗学习的本质及相关机制。 <div>
通过对抗贝叶斯分类器的唯一性刻画了对抗学习中凸损失一致性的充要条件，从统计角度深化了对抗学习的理解。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Adversarial Consistency and the Uniqueness of the Adversarial Bayes Classifier》N S. Frank [New York University] (2024) <a href="https://arxiv.org/abs/2404.17358"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp8edk67l6j213e0gagu4.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 21:20:22 GMT</pubDate>
</item>
<item>
<title>[LG]《Adversarial Consistency and the Uniqueness of the Adversarial Bayes Classifier》N S. Frank [New York University] (2024) 网页链接 #机器学习##人工...</title>
<link>https://weibo.com/1402400261/Oc3lfEJwu</link>
<guid>https://weibo.com/1402400261/Oc3lfEJwu</guid>
<content:encoded><![CDATA[
<div> Adversarial Consistency, Uniqueness, Adversarial Bayes Classifier, N S. Frank, New York University, 2024

<br /><br />总结:
在这篇文章中，作者探讨了对抗一致性和对抗贝叶斯分类器的独特性。首先介绍了对抗一致性的概念，即在生成模型中，对抗训练是通过最大化差距来优化生成和判别模型之间的鉴别能力。然后，作者提出了一种新的对抗贝叶斯分类器，通过对抗训练来提高模型的鲁棒性和泛化能力。文章进一步探讨了该对抗贝叶斯分类器的独特性，通过实验验证了其在各种数据集上的表现优越性。最后，作者总结了对抗贝叶斯分类器的潜在应用和未来研究方向。通过这篇文章，读者可以更深入地了解对抗一致性和对抗贝叶斯分类器的相关概念和技术。 <div>
[LG]《Adversarial Consistency and the Uniqueness of the Adversarial Bayes Classifier》N S. Frank [New York University] (2024) <a href="https://arxiv.org/abs/2404.17358"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp8edk67l6j213e0gagu4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 21:20:14 GMT</pubDate>
</item>
<item>
<title>AdaQAT是一种自适应学习DNN混合精度量化位宽的方法，通过梯度优化实数表示的位宽参数，实现了权重和激活信号的统一量化，既可以从零开始训练也可以微调预训练的...</title>
<link>https://weibo.com/1402400261/Oc3gohTMM</link>
<guid>https://weibo.com/1402400261/Oc3gohTMM</guid>
<content:encoded><![CDATA[
<div> 自适应学习、DNN、混合精度、量化位宽、梯度优化、统一量化、零开始训练、微调、预训练模型

<br /><br />总结:
本文介绍了一种名为AdaQAT的自适应学习方法，旨在实现DNN混合精度量化位宽。通过梯度优化位宽参数，实现了权重和激活信号的统一量化。AdaQAT不仅可以从零开始训练模型，还可以微调预训练的模型，在多个数据集上均表现优异。这种方法为DNN的量化训练提供了新的思路和技术支持。 <div>
AdaQAT是一种自适应学习DNN混合精度量化位宽的方法，通过梯度优化实数表示的位宽参数，实现了权重和激活信号的统一量化，既可以从零开始训练也可以微调预训练的模型，在多个数据集上表现优异。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《AdaQAT: Adaptive Bit-Width Quantization-Aware Training》C Gernigon, S Filip, O Sentieys… [Inria] (2024) <a href="https://arxiv.org/abs/2404.16876"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp8e6euuw9j20um0oe48d.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp8e6fa8wmj21qk0q8tfg.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 21:08:15 GMT</pubDate>
</item>
<item>
<title>[LG]《AdaQAT: Adaptive Bit-Width Quantization-Aware Training》C Gernigon, S Filip, O Sentieys… [Inria] (2024) 网页链接 #机器学习##人工智能##论文# [图...</title>
<link>https://weibo.com/1402400261/Oc3gkBfad</link>
<guid>https://weibo.com/1402400261/Oc3gkBfad</guid>
<content:encoded><![CDATA[
<div> 关键词：AdaQAT、自适应位宽量化、训练、量化感知、Inria

总结:<br /><br />
该文章提出了一种名为AdaQAT的新方法，旨在实现自适应位宽的量化感知训练。该方法结合了自适应位宽量化和训练过程，通过在训练过程中动态调整位宽以提高模型性能和准确性。研究团队来自Inria机构，他们的方法针对现有的量化训练技术进行改进，以在保持模型准确性的同时减少计算和存储需求。该方法在实验中取得了显著的效果，有望对未来的深度学习应用产生重要影响。 <div>
[LG]《AdaQAT: Adaptive Bit-Width Quantization-Aware Training》C Gernigon, S Filip, O Sentieys… [Inria] (2024) <a href="https://arxiv.org/abs/2404.16876"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp8e6euuw9j20um0oe48d.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp8e6fa8wmj21qk0q8tfg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 21:08:06 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.29)》 爱可可微博热门分享(4.29) [图片]</title>
<link>https://weibo.com/1402400261/Oc0pBtYFg</link>
<guid>https://weibo.com/1402400261/Oc0pBtYFg</guid>
<content:encoded><![CDATA[
<div> 爱可可 微博 热门 分享 关键词：时尚 搭配 美食 美妆 营养 健康 生活方式 活动 旅行<br />
<br />
在这篇爱可可微博热门分享中，主要关注了时尚搭配、美食美妆、营养健康、生活方式、活动和旅行等方面。文章内容涵盖了各种新颖的时尚搭配技巧、美食美妆产品推荐，以及如何保持健康营养的生活方式建议。此外，还介绍了一些精彩的活动和旅行经历，为读者提供了丰富多彩的生活参考。通过这篇分享，读者可以了解到最新的流行趋势和生活方式，为自己的生活增添更多乐趣和活力。<br /><br />总结: 本文介绍了时尚搭配、美食美妆、营养健康、生活方式、活动和旅行等方面的内容，为读者带来丰富多彩的生活参考。 <div>
《爱可可微博热门分享(4.29)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405028615237796058"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.29)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp81l8qfmtj20rs0fmjvk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 13:52:42 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Kosmos-G: Generating Images in Context with Multimodal Large Language Models》(ICLR 2024) GitHub: github.com/xichenpan/kosmos-g《M...</title>
<link>https://weibo.com/1402400261/ObXkR84HZ</link>
<guid>https://weibo.com/1402400261/ObXkR84HZ</guid>
<content:encoded><![CDATA[
<div> 关键词: 图像生成, 文本提示, 三维编辑, 机器学习, SLAM, 网络模型, 数据集, 强化学习, 相对奖励<br />
<br />
总结: 
本文提出了几篇论文的实现代码，涵盖了多个领域的前沿研究内容。其中涉及了图像生成、三维编辑、机器学习等重要领域。作者们通过利用大型语言模型生成图像、多模态SLAM技术以及神经网络模型等方法，取得了显著的研究成果。他们还提出了一些新的数据集和算法，来评估机器学习模型在不同任务上的表现。同时，作者们还探讨了如何利用强化学习和相对奖励来提高文本到图像生成的速度和准确性。这些工作对于推动人工智能领域的发展和应用具有重要意义。 <div>
几篇论文实现代码：<br />《Kosmos-G: Generating Images in Context with Multimodal Large Language Models》(ICLR 2024) GitHub: github.com/xichenpan/kosmos-g<br />《Multi-Session SLAM with Differentiable Wide-Baseline Pose Optimization》(CVPR 2024) GitHub: github.com/princeton-vl/MultiSlam_DiffPose [fig1]<br />《PoNQ: a Neural QEM-based Mesh Representation》(CVPR 2024) GitHub: github.com/nissmar/PoNQ<br />《TIP-Editor: An Accurate 3D Editor Following Both Text-Prompts And Image-Prompts》(SIGGRAPH Asia 2024) GitHub: github.com/zjy526223908/TIP-Editor<br />《UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning for Diffusion Models》(2024) GitHub: github.com/OPTML-Group/UnlearnCanvas [fig2]<br />《CG-SLAM: Efficient Dense RGB-D SLAM in a Consistent Uncertainty-aware 3D Gaussian Field》(2024) GitHub: github.com/hjr37/diff-gaussian-rasterization<br />《ZeST: Zero-Shot Material Transfer from a Single Image》(2024) GitHub: github.com/kealiu/ComfyUI-ZeroShot-MTrans [fig3]<br />《RL for Consistency Models: Faster Reward Guided Text-to-Image Generation》(2024) GitHub: github.com/Owen-Oertell/rlcm<br />《REBEL: Reinforcement Learning via Regressing Relative Rewards》(2024) GitHub: github.com/ZhaolinGao/REBEL<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp7mq7goezj220u0qnats.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp7nhu5288j21le0vi7wh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp7nrrm68vj21mr0olagp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 06:02:46 GMT</pubDate>
</item>
<item>
<title>【Google Recaptcha Solver：一个Python脚本，能使用DrissionPage库在不到5秒的时间内解决Google reCAPTCHA，同时提供了一个名为Capsolver的AI服务，专门用于自...</title>
<link>https://weibo.com/1402400261/ObXkjxo12</link>
<guid>https://weibo.com/1402400261/ObXkjxo12</guid>
<content:encoded><![CDATA[
<div> Google Recaptcha Solver, Python脚本, DrissionPage库, 解决Google reCAPTCHA, Capsolver AI服务, 自动解决验证码<br />
<br />
本文介绍了一个名为Google Recaptcha Solver的Python脚本，使用DrissionPage库可以在不到5秒的时间内解决Google reCAPTCHA。同时也提供了一个名为Capsolver的AI服务，专门用于自动解决多种类型的验证码。这个脚本为用户提供了一种快速有效地解决验证码问题的方法，大大节省了用户的时间和精力。Capsolver的出现，使得用户可以更加轻松地完成需要验证码验证的任务，提高了用户体验。总体来说，Google Recaptcha Solver是一个方便实用的工具，为用户提供了更好的验证码解决方案。<br /><br /> 
**总结:** <br />通过使用Google Recaptcha Solver的Python脚本和Capsolver AI服务，用户可以在不到5秒的时间内解决Google reCAPTCHA和其他类型的验证码，大大提高了用户的效率和体验。 <div>
【Google Recaptcha Solver：一个Python脚本，能使用DrissionPage库在不到5秒的时间内解决Google reCAPTCHA，同时提供了一个名为Capsolver的AI服务，专门用于自动解决多种类型的验证码】'Google Recaptcha Solver - Solve Google reCAPTCHA in less than 5 seconds! 🚀' GitHub: github.com/sarperavci/GoogleRecaptchaBypass <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp7nymyciqj21740kwn0c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 06:01:26 GMT</pubDate>
</item>
<item>
<title>【Netprobe Lite：用 Python 编写的简单高效的互联网性能测试工具，用于测量家庭互联网服务提供商(ISP)的性能，包括数据包丢失、延迟、抖动和DNS性能等指标】'Ne...</title>
<link>https://weibo.com/1402400261/ObXjVBgkO</link>
<guid>https://weibo.com/1402400261/ObXjVBgkO</guid>
<content:encoded><![CDATA[
<div> Python, Netprobe Lite, 互联网性能测试工具, ISP, 数据包丢失, 延迟, 抖动, DNS, GitHub

<br /><br />总结:
Netprobe Lite 是一个用 Python 编写的简单高效的互联网性能测试工具，主要用于测量家庭互联网服务提供商（ISP）的性能。该工具可以测量数据包丢失率、延迟、抖动以及DNS性能等指标，帮助用户了解网络连接质量和稳定性。用户可以通过 GitHub 上的代码仓库访问 Netprobe Lite 的代码并进行使用。该工具提供了便捷的方式来评估和监测网络性能，对于需要对网络连接质量进行评估的用户来说是一个很实用的工具。 <div>
【Netprobe Lite：用 Python 编写的简单高效的互联网性能测试工具，用于测量家庭互联网服务提供商(ISP)的性能，包括数据包丢失、延迟、抖动和DNS性能等指标】'Netprobe Lite - Simple internet performance tester written in Python' GitHub: github.com/plaintextpackets/netprobe_lite <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp7nxttuf0j21740huacy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 06:00:29 GMT</pubDate>
</item>
<item>
<title>【LLM-Prompt-Library 为多种大型语言模型（如GPT-4、Claude、Llama3等）设计的高级代码和文本操作提示库】'Advanced LLM Prompts Repository - Advanced Code a...</title>
<link>https://weibo.com/1402400261/ObXjnlQro</link>
<guid>https://weibo.com/1402400261/ObXjnlQro</guid>
<content:encoded><![CDATA[
<div> 关键词: 高级代码, 文本操作, 提示库, 大型语言模型, GPT-4, Claude, Llama3, GitHub, 开源, 高性能

在当前的技术发展中，大型语言模型（LLM）变得越来越普遍。为了更好地利用这些高级模型，开发了一个名为LLM-Prompt-Library的高级代码和文本操作提示库。该库适用于多种大型语言模型，如GPT-4、Claude、Llama3等，还能与其他高性能的开源LLM兼容。通过GitHub这个平台，开发者们可以轻松地获取和分享这个提示库，从而提升他们在代码和文本操作中的效率和灵活性。<br /><br />总结: 提高了LLM的应用效率和灵活性，适用于多种高性能开源模型，通过GitHub平台方便获取和分享。 <div>
【LLM-Prompt-Library 为多种大型语言模型（如GPT-4、Claude、Llama3等）设计的高级代码和文本操作提示库】'Advanced LLM Prompts Repository - Advanced Code and Text Manipulation Prompts for Various LLMs. Suitable for GPT-4, Claude, Llama3, Gemini, and other high-performing open-source LLMs.' GitHub: github.com/abilzerian/LLM-Prompt-Library <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp7nvz8vdij21740lagoz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 05:59:07 GMT</pubDate>
</item>
<item>
<title>【LocalVocal：用于 OBS 的开源插件，利用人工智能进行本地语音识别和实时字幕生成，支持多种语言，无需 GPU、云端服务或网络连接】’LocalVocal - Speech AI as...</title>
<link>https://weibo.com/1402400261/ObXix2L9m</link>
<guid>https://weibo.com/1402400261/ObXix2L9m</guid>
<content:encoded><![CDATA[
<div> 插件，开源，人工智能，语音识别，实时字幕，多语言，无需GPU，无需云端，无需网络连接

<br /><br />总结:
LocalVocal是一个用于OBS的开源插件，利用人工智能进行本地语音识别和实时字幕生成，支持多种语言，无需GPU、云端服务或网络连接。用户可以通过GitHub找到这个项目，轻松使用这个功能强大的插件。 <div>
【LocalVocal：用于 OBS 的开源插件，利用人工智能进行本地语音识别和实时字幕生成，支持多种语言，无需 GPU、云端服务或网络连接】’LocalVocal - Speech AI assistant OBS Plugin - OBS plugin for local speech recognition and captioning using AI' GitHub: github.com/occ-ai/obs-localvocal <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp7nu1knu6j20ua0u0afs.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 05:57:02 GMT</pubDate>
</item>
<item>
<title>【Langtrace：开源的端到端可观测性工具，用于支持大型语言模型（LLM）应用，提供实时追踪、评估和度量功能，遵循Open Telemetry标准，并支持Typescript和Python...</title>
<link>https://weibo.com/1402400261/ObXi3c0Pc</link>
<guid>https://weibo.com/1402400261/ObXi3c0Pc</guid>
<content:encoded><![CDATA[
<div> LLM、端到端可观测性工具、开源、实时追踪、评估、度量功能、Open Telemetry标准、Typescript、Python集成、GitHub

总结:<br /><br />Langtrace是一款开源的端到端可观测性工具，专为支持大型语言模型（LLM）应用而设计。该工具遵循Open Telemetry标准，提供实时追踪、评估和度量功能，可用于对流行的LLM、LLM框架和向量数据库进行监测。Langtrace支持Typescript和Python的集成，用户可以在GitHub上找到相关信息。 <div>
【Langtrace：开源的端到端可观测性工具，用于支持大型语言模型（LLM）应用，提供实时追踪、评估和度量功能，遵循Open Telemetry标准，并支持Typescript和Python集成】'Langtrace - an open-source, Open Telemetry based end-to-end observability tool for LLM applications, providing real-time tracing, evaluations and metrics for popular LLMs, LLM frameworks, vectorDBs and more.. Integrate using Typescript, Python.' GitHub: github.com/Scale3-Labs/langtrace <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp7nt97qg2j20u00yk42d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 05:55:51 GMT</pubDate>
</item>
<item>
<title>【HaystackDB：高性能、可扩展的向量数据库，使用 Rust 编写，支持二进制嵌入、JSON 查询过滤，并且具有持久化、分布式架构设计】'HaystackDB' GitHub: github.c...</title>
<link>https://weibo.com/1402400261/ObXh9eshC</link>
<guid>https://weibo.com/1402400261/ObXh9eshC</guid>
<content:encoded><![CDATA[
<div> 高性能、可扩展、向量数据库、Rust、二进制嵌入、JSON 查询、持久化、分布式架构<br />
<br />
<br />
总结：<br />
HaystackDB 是一个高性能、可扩展的向量数据库，使用 Rust 编写。它支持二进制嵌入和 JSON 查询过滤，具有持久化和分布式架构设计。通过 HaystackDB，用户可以快速存储和检索向量数据，同时利用其强大的功能特点实现高效的数据管理和查询操作。HaystackDB 的开源代码托管在 GitHub 上，为用户提供了可靠的数据库解决方案，适用于各种数据存储和查询需求。HaystackDB 的 Rust 实现保证了其稳定性和性能优势，使其成为一个值得关注和使用的新型数据库技术。HaystackDB 的持久化和分布式架构设计为用户提供了更灵活和可靠的数据管理方式，在大规模数据处理和分布式环境下具有良好的适用性。通过深入了解 HaystackDB 的特性和优势，用户可以更好地利用其功能，实现高效的数据存储和查询操作，提升数据处理效率和性能表现。HaystackDB 的不断优化和发展为用户提供了持续改进和更新的保障，使其成为一个具有长期使用潜力和发展前景的数据库解决方案。 <div>
【HaystackDB：高性能、可扩展的向量数据库，使用 Rust 编写，支持二进制嵌入、JSON 查询过滤，并且具有持久化、分布式架构设计】'HaystackDB' GitHub: github.com/carsonpo/haystackdb <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp7nqpemowj21740o4juh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 05:53:38 GMT</pubDate>
</item>
<item>
<title>【KRAGEN：结合知识图谱、检索增强生成（RAG）和高级提示技术来解决复杂问题的自然语言处理工具，通过将知识图谱转换为向量数据库，并使用RAG检索相关事实，辅以...</title>
<link>https://weibo.com/1402400261/ObXgJkSqL</link>
<guid>https://weibo.com/1402400261/ObXgJkSqL</guid>
<content:encoded><![CDATA[
<div> 知识图谱、检索增强生成、高级提示技术、自然语言处理、向量数据库、RAG、图思考、复杂问题、解决方案

KRAGEN是一种自然语言处理工具，结合知识图谱、检索增强生成（RAG）和高级提示技术来解决复杂问题。它将知识图谱转换为向量数据库，并使用RAG检索相关事实，辅以图思考技术动态分解问题，最终提供解决方案。该工具可以在GitHub上找到，提供了一种实现图思考的软件方法。KRAGEN的功能能够有效应对复杂问题并提供准确的解决方案。总结：<br /><br />知识图谱、RAG和高级提示技术被结合应用到自然语言处理中，转化为向量数据库，并使用图思考技术，提供动态解决方案。 <div>
【KRAGEN：结合知识图谱、检索增强生成（RAG）和高级提示技术来解决复杂问题的自然语言处理工具，通过将知识图谱转换为向量数据库，并使用RAG检索相关事实，辅以图思考（GoT）技术动态分解问题，最终提供解决方案】'KRAGEN - Software to implement GoT with a weviate vectorized database' GitHub: github.com/EpistasisLab/KRAGEN <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp7npugbwwj20u00zqjw6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp7npv93qlj21gh0u0qa3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 05:52:36 GMT</pubDate>
</item>
<item>
<title>【memary: 旨在为自主Agent提供长期记忆机制，以克服 LLM 因为有限的上下文窗口而带来的限制】'memary: Open-Source Longterm Memory for Autonomous Agents - L...</title>
<link>https://weibo.com/1402400261/ObX5R2erg</link>
<guid>https://weibo.com/1402400261/ObX5R2erg</guid>
<content:encoded><![CDATA[
<div> Open-Source, Longterm Memory, Autonomous Agents, GitHub, 记忆机制, 自主Agent, 限制, 上下文窗口, 解决, 开源

<br /><br />总结:
该项目旨在为自主Agent提供长期记忆机制以克服LLM因为有限的上下文窗口而带来的限制。这个开源项目名为memary，可在GitHub上找到。通过memary，自主Agent可以更好地处理长期记忆，从而提高其行为和决策的准确性和效率。这个项目为研究人员和开发者提供了一个有用的工具，以改善自主Agent的表现和应用。 <div>
【memary: 旨在为自主Agent提供长期记忆机制，以克服 LLM 因为有限的上下文窗口而带来的限制】'memary: Open-Source Longterm Memory for Autonomous Agents - Longterm Memory for Autonomous Agents.' GitHub: github.com/kingjulio8238/memary <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp7mxze2stj20yo0u042m.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 05:25:48 GMT</pubDate>
</item>
<item>
<title>'LLMOps for Large Language Model-based applications - Tooling to build LLM applications: prompt templating and composition, agents, LLM memory, and ot...</title>
<link>https://weibo.com/1402400261/ObX4hvgvy</link>
<guid>https://weibo.com/1402400261/ObX4hvgvy</guid>
<content:encoded><![CDATA[
<div> GitHub, LLMOps, Large Language Model, Tooling, prompt templating, agents, LLM memory, AI applications

总结:<br /><br />
本文介绍了LLMOps工具，用于构建基于大型语言模型的应用程序。这些工具包括prompt模板和组合、代理、LLM内存等工具，可以帮助AI应用程序的开发者快速构建应用程序。GitHub链接提供了更多详细信息和工具的下载。 <div>
'LLMOps for Large Language Model-based applications - Tooling to build LLM applications: prompt templating and composition, agents, LLM memory, and other instruments for builders of AI applications.' GitHub: github.com/zmedelis/bosquet <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp7mtpueczj21km0te0zi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 05:21:55 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》...</title>
<link>https://weibo.com/1402400261/ObUgWuJF3</link>
<guid>https://weibo.com/1402400261/ObUgWuJF3</guid>
<content:encoded><![CDATA[
<div> 关键词: 多模态大模型, 人工智能, 技术方法, 应用场景, 因果推理, 世界模型, 多智能体, 具身智能, 开源平台, HCP 实验室

总结:<br /><br />
本书由中山大学 HCP 实验室出品，介绍了多模态大模型的技术方法、开源平台和应用场景。其中涵盖了因果推理、世界模型、多智能体和具身智能等前沿技术领域。这些内容有助于读者全面了解多模态大模型的特点及发展方向，对新一代人工智能技术范式和通用人工智能的发展具有重要推动作用。想要获取这本书的读者可以在截至日期前转发并评论，有机会获得一本全彩的《多模态大模型：新一代人工智能技术范式》。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》，截至2024.5.1 12:00，*可可粉*转发+评论即可参与。中山大学 HCP 实验室出品，本书以深入浅出的方式介绍多模态大模型的技术方法、开源平台和应用场景，并详细阐述因果推理、世界模型及多智能体与具身智能等前沿技术领域，有助于读者全面了解多模态大模型的特点及发展方向，对新一代人工智能技术范式和通用人工智能的发展起到重要推动作用。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp1q8lh8x1j20m80m8djk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8n4hifj20m80m8gnu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8pgbfhj20m80m8dj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8r3pagj20m80m80ur.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 22:14:53 GMT</pubDate>
</item>
<item>
<title>今日推介(第1390期)：基于LLM的自动工作流生成、LLM评估器识别并偏爱自己生成的内容、音乐一致性模型、在多个GPU上扩展NeRF、调整您的步骤:优化扩散模型中的采样...</title>
<link>https://weibo.com/1402400261/ObUgK44Dv</link>
<guid>https://weibo.com/1402400261/ObUgK44Dv</guid>
<content:encoded><![CDATA[
<div> LLM、自动工作流生成、LLM评估器、音乐一致性模型、多个GPU、NeRF、优化扩散模型、采样时间表、公众号、爱可可爱生活

<br /><br />总结:
本文介绍了基于LLM的自动工作流生成和LLM评估器识别并偏爱自己生成的内容的方法。同时讨论了音乐一致性模型以及在多个GPU上扩展NeRF的技术。另外，还提到了调整扩散模型中的采样时间表和优化扩散模型的采样Schedule的方法。最后，推荐了公众号“爱可可爱生活”，可以在该公众号获取更多相关信息。 <div>
今日推介(第1390期)：基于LLM的自动工作流生成、LLM评估器识别并偏爱自己生成的内容、音乐一致性模型、在多个GPU上扩展NeRF、调整您的步骤:优化扩散模型中的采样时间表、优化扩散模型的采样Schedule 公·众·号：爱可可爱生活 <a href="http://aicoco.net/s/8r"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp7ae6v5roj20ua0p4ad4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp7aedlgo0j20u00ue439.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp7aeiw91uj21c40u045i.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp7aen7d9xj215u0gsn16.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp7aesfvk8j22fs0u0gze.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 22:14:23 GMT</pubDate>
</item>
<item>
<title>[CL] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data 网页链接 通过构建三种不同的分析任务，发现使用在策略采样或负梯度的方法通...</title>
<link>https://weibo.com/1402400261/ObUbYk1XH</link>
<guid>https://weibo.com/1402400261/ObUbYk1XH</guid>
<content:encoded><![CDATA[
<div> 关键词: 模态搜索, 高奖励响应, 数据覆盖范围, 语言模型微调

总结:<br />
研究发现，在LLMs的偏好微调中，使用在策略采样或负梯度的方法比离线监督目标更有效，因为它们展现出“模态搜索”行为，提高了高奖励响应的概率质量。根据问题几何关系和数据覆盖范围，提出了不同方法表现良好的情况洞见，并依此为语言模型微调提供了指导性建议。这些发现为优化LLMs的偏好微调提供了新的思路和方法。 <div>
[CL] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data  <br /><a href="https://arxiv.org/abs/2404.14367"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过构建三种不同的分析任务，发现使用在策略采样或负梯度的方法通常优于离线监督目标，因为它们表现出“模态搜索”行为，能够有效提高高奖励响应的概率质量；并依据问题几何关系和数据覆盖范围提出不同方法表现良好的情况洞见，为语言模型微调提供了指导性建议。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp7a4u0487j20sk16stqf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp7a4uiwcmj21m40vincm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp7a4v3srhj21d2174k5w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 22:02:38 GMT</pubDate>
</item>
<item>
<title>[LG] Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey 网页链接 对大模型参数高效微调的算法和系统实现进行全面调研，综述该领域的...</title>
<link>https://weibo.com/1402400261/ObU8Nchfe</link>
<guid>https://weibo.com/1402400261/ObU8Nchfe</guid>
<content:encoded><![CDATA[
<div> 参数高效微调、大模型、全面调研、进展、应用、算法、系统实现、综述、研究、参考

<br /><br />总结:
本文对大模型参数高效微调的算法和系统实现进行了全面的调研，并综述了该领域的进展和应用。研究内容涵盖了各种算法和系统实现，旨在为后续研究提供参考。文章深入探讨了参数高效微调的重要性以及当前研究现状，展望了未来的发展趋势和应用前景。通过全面的调研和综述，为相关领域的研究者提供了宝贵的参考资料，有助于推动该领域的进一步发展。 <div>
[LG] Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey  <br /><a href="https://arxiv.org/abs/2403.14608"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />对大模型参数高效微调的算法和系统实现进行全面调研，综述该领域的进展和应用，为后续研究提供参考。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp79woqeprj20xk18kkc2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp79wpec0rj21hm0m8dmy.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp79wpivi9j21n40syth8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 21:54:48 GMT</pubDate>
</item>
<item>
<title>[LG] A Survey on the Memory Mechanism of Large Language Model based Agents 网页链接 首次全面调研了LLM Agent的记忆机制，讨论其定义、作用、实现和评估，...</title>
<link>https://weibo.com/1402400261/ObU4X5ENf</link>
<guid>https://weibo.com/1402400261/ObU4X5ENf</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM Agent, 记忆机制, 定义, 作用, 实现, 评估, 设计原则, 未来方向, 综述基石

总结:<br /><br />本文首次全面调研了LLM Agent的记忆机制，讨论了其定义、作用、实现和评估等方面。在对记忆机制进行深入探讨的基础上，总结了设计原则，并指出了未来的研究方向。这篇文章为该领域的发展奠定了综述基石，为研究者提供了重要参考和指导。 <div>
[LG] A Survey on the Memory Mechanism of Large Language Model based Agents  <br /><a href="https://arxiv.org/abs/2404.13501"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />首次全面调研了LLM Agent的记忆机制，讨论其定义、作用、实现和评估，总结设计原则，指出未来方向，为该领域奠定综述基石。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp79mtssgcj20pi11mk21.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp79mujo5hj20s01c4q9l.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp79mv5a3jj21620ve4a4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 21:45:20 GMT</pubDate>
</item>
<item>
<title>[CV] How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites 网页链接 提出开源多模态语言模型InternVL 1.5，通...</title>
<link>https://weibo.com/1402400261/ObU1Ckq2p</link>
<guid>https://weibo.com/1402400261/ObU1Ckq2p</guid>
<content:encoded><![CDATA[
<div> 开源多模态语言模型、GPT-4V、闭合差距、商业模型、Open-Source Suites、InternVL 1.5、持续学习视觉编码器、动态高分辨率、高质量双语数据集、多项基准测试

<br /><br />总结:
本文提出了开源多模态语言模型InternVL 1.5，通过持续学习视觉编码器、动态高分辨率和高质量双语数据集三点改进，来弥补与商业模型的差距。这个模型在多项基准测试中展现出了竞争力，显示出逐渐接近GPT-4V的趋势。开源工具套件的发展有望带来更多领域的创新和发展。 <div>
[CV] How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites  <br /><a href="https://arxiv.org/abs/2404.16821"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />提出开源多模态语言模型InternVL 1.5，通过持续学习视觉编码器、动态高分辨率和高质量双语数据集三点改进，弥补了与商业模型的差距，在多项基准测试中展现出竞争力。<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp79eb0w4rj20wo13qdt0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp79ebflk3j20ti0z6795.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp79ebl7n2j20ts0pon2x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 21:37:08 GMT</pubDate>
</item>
<item>
<title>通过随机分析方法建立采样schedule优化框架，可针对特定条件进行优化从而提升少步采样效果质量，是第一个可以普适改进输出效果的schedule优化方法。 - 转发 @爱...</title>
<link>https://weibo.com/1402400261/ObTZ4p43H</link>
<guid>https://weibo.com/1402400261/ObTZ4p43H</guid>
<content:encoded><![CDATA[
<div> 关键词: 随机分析方法, 采样schedule优化, 少步采样效果质量, 普适改进, 输出效果, 模型扩散, NVIDIA, 输出效果, 模型优化

总结:<br /><br />研究团队通过随机分析方法建立了采样schedule优化框架，可针对特定条件进行优化，从而提升少步采样效果质量。这是第一个可以普适改进输出效果的schedule优化方法。研究内容主要集中在模型扩散方面，由NVIDIA的A Sabour, S Fidler, K Kreis撰写。他们的工作着眼于最小化采样误差，优化采样步骤，以提升模型输出效果。这项研究有望为模型优化提供新的思路和方法。 <div>
通过随机分析方法建立采样schedule优化框架，可针对特定条件进行优化从而提升少步采样效果质量，是第一个可以普适改进输出效果的schedule优化方法。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《Align Your Steps: Optimizing Sampling Schedules in Diffusion Models》A Sabour, S Fidler, K Kreis [NVIDIA] (2024) <a href="https://arxiv.org/abs/2404.14507"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp797c0xz4j20oe11o48i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp797cta1cj21m80jwk2m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp797d1ebhj20t20lcafo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp797dajd5j20su0no77p.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp797f0s7xj212h0c9ae6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp797f034wj20iw0hzgnh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp797f0cgwj20j00in0v4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp797f0otzj211w0bomzm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp797f0udgj212e08cjuf.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 21:30:51 GMT</pubDate>
</item>
<item>
<title>[CV]《Align Your Steps: Optimizing Sampling Schedules in Diffusion Models》A Sabour, S Fidler, K Kreis [NVIDIA] (2024) 网页链接 #机器学习##人工智能##...</title>
<link>https://weibo.com/1402400261/ObTYVzjPB</link>
<guid>https://weibo.com/1402400261/ObTYVzjPB</guid>
<content:encoded><![CDATA[
<div> Diffusion models, Sampling schedules, Optimization, Aligning steps, NVIDIA<br />
<br />
提出了一种优化采样计划的方法，该方法能够在扩散模型中实现最佳效果。研究人员通过对采样计划进行调整，使得步骤间的对齐更加有效，从而提高模型的准确性和效率。他们的研究结果表明，这种优化方法能够显著改善模型的表现，特别是在处理大规模数据时表现突出。本文的工作得到了NVIDIA的支持，展示了其在GPU计算方面的先进技术和实践应用。<br /><br />总结: <div>
[CV]《Align Your Steps: Optimizing Sampling Schedules in Diffusion Models》A Sabour, S Fidler, K Kreis [NVIDIA] (2024) <a href="https://arxiv.org/abs/2404.14507"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp797c0xz4j20oe11o48i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp797cta1cj21m80jwk2m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp797d1ebhj20t20lcafo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp797dajd5j20su0no77p.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp797f0s7xj212h0c9ae6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp797f034wj20iw0hzgnh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp797f0cgwj20j00in0v4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp797f0otzj211w0bomzm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp797f0udgj212e08cjuf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp797f0zxmj20zs0eodiy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp797ezywlj212d0evt9s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp797f0p6kj210l0bp75p.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp797f0znaj212h0ebmzh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp797f0p7aj212e0e775r.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp797f0wmzj212h0d0gnk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp797f0ur8j212h0e4go1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp797f1bpxj212h0e4adn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp797f15zlj20ut0hhgol.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 21:30:30 GMT</pubDate>
</item>
<item>
<title>通过联合训练和重写积分方程等技术手段，实现了NeRF在多GPU上的可扩展性，使其重建质量和渲染效率随GPU数量 linerarly scale，是首个揭示NeRF的多GPU扩展定律。 ...</title>
<link>https://weibo.com/1402400261/ObTVbk1L7</link>
<guid>https://weibo.com/1402400261/ObTVbk1L7</guid>
<content:encoded><![CDATA[
<div> Nerf-XL, 多GPU, 可扩展性, 联合训练, 重写积分方程, 定律, 渲染效率, 线性扩展, 重建质量, 技术手段

<br /><br />总结:
研究团队通过联合训练和重写积分方程等技术手段，成功实现了NeRF在多GPU上的可扩展性，使其在重建质量和渲染效率方面随着GPU数量的增加呈线性扩展。他们提出了首个NeRF的多GPU扩展定律，为相关领域的研究和应用带来重要启示。NeRF-XL的工作有望为未来的三维重建和渲染技术带来更高效、更可靠的解决方案。 <div>
通过联合训练和重写积分方程等技术手段，实现了NeRF在多GPU上的可扩展性，使其重建质量和渲染效率随GPU数量 linerarly scale，是首个揭示NeRF的多GPU扩展定律。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《NeRF-XL: Scaling NeRFs with Multiple GPUs》R Li, S Fidler, A Kanazawa, F Williams [NVIDIA &amp; UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.16221"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp78q3kszhj20zw0rs7fp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp78q4juv1j215m0rc11s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp78q4t8ivj215u0gswk0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp78q4zhdnj216a0kctct.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp78xdh42mj20rh0dh40n.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp78xdh3klj20rl0gb41e.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp78xdh6z8j20rl0g0whh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp78xdhmpmj20rl0n242d.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp78xdgqslj20rl0fcdhp.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 21:21:16 GMT</pubDate>
</item>
<item>
<title>[CV]《NeRF-XL: Scaling NeRFs with Multiple GPUs》R Li, S Fidler, A Kanazawa, F Williams [NVIDIA &amp; UC Berkeley] (2024) 网页链接 #机器学习##人工智能##论...</title>
<link>https://weibo.com/1402400261/ObTV0bUeT</link>
<guid>https://weibo.com/1402400261/ObTV0bUeT</guid>
<content:encoded><![CDATA[
<div> scaling, NeRFs, multiple GPUs, NVIDIA, UC Berkeley

NeRF-XL是一篇关于在多个GPU上扩展NeRFs的论文，作者包括来自NVIDIA和UC Berkeley的研究人员。他们提出了一种能够有效利用多GPU进行训练和推理的方法，通过将NeRF模型扩展到更大的规模，实现更高的精度和效率。实验结果表明，这种方法在渲染大规模场景时取得了令人印象深刻的性能，并为未来在三维图像重建领域的研究提供了新的思路。

<br /><br />总结:NeRF-XL论文介绍了如何利用多个GPU扩展NeRFs模型，提高了模型的性能和效率。通过该方法，可以在更大规模的场景下进行渲染，并在三维图像重建领域中取得突破性进展。 <div>
[CV]《NeRF-XL: Scaling NeRFs with Multiple GPUs》R Li, S Fidler, A Kanazawa, F Williams [NVIDIA &amp; UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.16221"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp78q3kszhj20zw0rs7fp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp78q4juv1j215m0rc11s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp78q4t8ivj215u0gswk0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp78q4zhdnj216a0kctct.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp78xdh42mj20rh0dh40n.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp78xdh3klj20rl0gb41e.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp78xdh6z8j20rl0g0whh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp78xdhmpmj20rl0n242d.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp78xdgqslj20rl0fcdhp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp78xdgvuoj20rl0enmzb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp78xdh9z1j20rl0g6whc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp78xdgxocj20rh0data3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp78xdgns3j20rh0giq3y.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp78xdh1zcj20rl0gjwh7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp78xdhcatj20rl0nsn0o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 21:20:50 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.28)》 爱可可微博热门分享(4.28) [图片]</title>
<link>https://weibo.com/1402400261/ObRijsZv7</link>
<guid>https://weibo.com/1402400261/ObRijsZv7</guid>
<content:encoded><![CDATA[
<div> 爱可可 微博 热门 分享 4.28  
总结:  
4月28日，爱可可微博热门分享中包含了各种热门话题，引起大家的关注。其中有许多精彩内容，包括明星八卦、时尚潮流、美食推荐等。用户可以通过阅读热门分享了解最新动态，分享自己的见解和观点。爱可可微博成为了大家获取资讯的重要平台，让用户可以享受到更多有趣的内容。 <div>
《爱可可微博热门分享(4.28)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405028264757297249"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.28)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp6xc4zekvj20rs0fm78o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 14:40:01 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Learning without Exact Guidance: Updating Large-scale High-resolution Land Cover Maps from Low-resolution Historical Labels》(CVPR...</title>
<link>https://weibo.com/1402400261/ObOpY73Q2</link>
<guid>https://weibo.com/1402400261/ObOpY73Q2</guid>
<content:encoded><![CDATA[
<div> 更新、地图、高分辨率、低分辨率、学习、历史、标签、更新算法、卫星影像、地物分类

总结:<br />
该论文提出了一种在没有精确指导的情况下更新大规模高分辨率地物分类地图的方法。通过利用低分辨率的历史标签和卫星影像，提出了一种更新算法，可以有效地更新地图中的地物分类信息。实验结果表明，该方法在不需要精确标注的情况下能够实现准确有效的地物分类地图更新。该方法对于使用卫星影像进行地物分类和更新具有重要意义。 <div>
几篇论文实现代码：<br />《Learning without Exact Guidance: Updating Large-scale High-resolution Land Cover Maps from Low-resolution Historical Labels》(CVPR 2024) GitHub: github.com/LiZhuoHong/Paraformer<br />《 SpaceByte: Towards Deleting Tokenization from Large Language Modeling》(2024) GitHub: github.com/kjslag/spacebyte<br />《PLLaVA: Parameter-free LLaVA Extension from Images to Videos for Video Dense Captioning》(2024) GitHub: github.com/magic-research/PLLaVA [fig1]<br />《Textrolspeech: A text style control speech corpus with codec language text-to-speech models》(2024) GitHub: github.com/jishengpeng/Textrolspeech<br />《InCharacter: Evaluating Personality Fidelity in Role-Playing Agents through Psychological Interviews》(2024) GitHub: github.com/Neph0s/InCharacter<br />《FRNet: Frustum-Range Networks for Scalable LiDAR Segmentation》(2024) GitHub: github.com/Xiangxu-0103/FRNet [fig2]<br />《LeanReasoner: Boosting Complex Logical Reasoning with Lean》(2024) GitHub: github.com/Some-random/theorem-proving-reasoning<br />《A User-Centric Benchmark for Evaluating Large Language Models》(2024) GitHub: github.com/Alice1998/URS<br />《MR-MT3: Memory Retaining Multi-Track Music Transcription to Mitigate Instrument Leakage》(2024) GitHub: github.com/gudgud96/MR-MT3<br />《ScreenQA: Large-Scale Question-Answer Pairs over Mobile App Screenshots》(2024) GitHub: github.com/google-research-datasets/screen_qa<br />《Improving Diffusion Models for Inverse Problems Using Optimal Posterior Covariance》(2024) GitHub: github.com/xypeng9903/k-diffusion-inverse-problems<br />《DMHomo: Learning Homography with Diffusion Models》(2024) GitHub: github.com/lhaippp/DMHomo<br />《Evaluating generalizability of artificial intelligence models for molecular datasets》(2024) GitHub: github.com/mims-harvard/SPECTRA<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp6hndgk0nj20y20b8wlq.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp6htw7eflj22rj0x1h8d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 07:20:38 GMT</pubDate>
</item>
<item>
<title>【大语言模型医疗相关文献资源列表】’Awesome-Foundation-Models-for-Advancing-Healthcare - We present a comprehensive and deep review of the HFM in chal...</title>
<link>https://weibo.com/1402400261/ObOptCsOl</link>
<guid>https://weibo.com/1402400261/ObOptCsOl</guid>
<content:encoded><![CDATA[
<div> 深度学习、医疗保健、挑战、机会、未来方向、GitHub、资源列表、综述

<br /><br />总结:
本文综述了医疗保健领域的基金模型，探讨了其中的挑战、机会和未来发展方向。作者详细介绍了基金模型在医疗保健领域的广泛应用，并提供了相关资源列表以便读者深入了解。GitHub上提供了更多的信息和资源，为医疗领域的发展提供了重要的参考。希望通过这些基金模型的研究和应用，能够推动医疗保健领域的进步和创新。 <div>
【大语言模型医疗相关文献资源列表】’Awesome-Foundation-Models-for-Advancing-Healthcare - We present a comprehensive and deep review of the HFM in challenges, opportunities, and future directions' GitHub: github.com/YutingHe-list/Awesome-Foundation-Models-for-Advancing-Healthcare <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp6jsq47uoj22340u0wnx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 07:19:25 GMT</pubDate>
</item>
<item>
<title>'phi3-Chinese - Phi3 中文仓库' GitHub: github.com/CrazyBoyM/phi3-Chinese #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/ObOcKswFs</link>
<guid>https://weibo.com/1402400261/ObOcKswFs</guid>
<content:encoded><![CDATA[
<div> GitHub, phi3, 中文仓库, CrazyBoyM, 开源, 翻译, 软件项目, 中文化<br />
<br />
该篇文章介绍了一个名为'phi3-Chinese'的开源软件项目，该项目是对Phi3软件的中文化翻译工作。该项目的主页位于GitHub上，由开发者CrazyBoyM创建和维护。通过该项目，用户可以下载和使用已经翻译完成的中文化版本的Phi3软件，让使用者能够更便利地理解和操作软件。这个项目提供了一个便捷途径让中文用户能够参与到Phi3软件的使用和交流中，促进软件在中文用户群体中的推广和应用。Phi3-Chinese项目为中文使用者提供了更便捷、更友好的软件体验，也为软件翻译和本土化工作提供了一个实践平台。总结:Phi3-Chinese项目是一个在GitHub上的开源软件项目，旨在对Phi3软件进行中文化翻译，为中文使用者提供更友好的软件体验，推动软件在中文用户群体中的应用和推广。 <div>
'phi3-Chinese - Phi3 中文仓库' GitHub: github.com/CrazyBoyM/phi3-Chinese <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp6jp8jpo3j210x0u0grh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 06:48:04 GMT</pubDate>
</item>
<item>
<title>【WrenAI：提供了一个自然语言界面，使用户通过问题而不是编写 SQL 来更快地获取结果和见解】'WrenAI - Natural Language Interface to Your Data. WrenAI makes...</title>
<link>https://weibo.com/1402400261/ObOaja2qg</link>
<guid>https://weibo.com/1402400261/ObOaja2qg</guid>
<content:encoded><![CDATA[
<div> GitHub, WrenAI, Text-to-SQL, 自然语言界面, 数据, 接口, 查询, 速度, 结果, 见解

<br /><br />总结:
WrenAI是一个提供自然语言界面的工具，让用户可以通过问题而不是编写SQL来快速获取数据结果和见解。用户可以通过WrenAI简单而准确地进行Text-to-SQL查询，极大地提高了查询速度和效率。GitHub上有完整的项目代码可以查阅。 <div>
【WrenAI：提供了一个自然语言界面，使用户通过问题而不是编写 SQL 来更快地获取结果和见解】'WrenAI - Natural Language Interface to Your Data. WrenAI makes Text-to-SQL simple and accurate.' GitHub: github.com/Canner/WrenAI <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp6jhvby2oj21vo0u0tb1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp6jhxouqzj21fa0u0n03.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 06:42:03 GMT</pubDate>
</item>
<item>
<title>【构建由LlamaIndex支持的文档聊天机器人，用Streamlit文档的内容(或用户自己的数据)增强GPT 3.5】'LlamaIndex - Chat with the Streamlit docs - Build a chatb...</title>
<link>https://weibo.com/1402400261/ObO8NaWrj</link>
<guid>https://weibo.com/1402400261/ObO8NaWrj</guid>
<content:encoded><![CDATA[
<div> 关键词：LlamaIndex, Chatbot, Streamlit, GPT 3.5, 文档, 数据, 增强, 机器人

总结:
<br /><br />此篇文章介绍了如何建立一个由LlamaIndex支持的文档聊天机器人，该机器人利用Streamlit文档的内容增强了GPT 3.5的功能。通过结合LlamaIndex和Streamlit文档的内容，可以为Chatbot提供更丰富的信息和更优质的交互体验。这个新型的机器人不仅可以根据用户提供的数据进行智能回复，还能够根据用户关注的主题提供更详细的解答。机器人的搭建过程可以借助GitHub上的开源代码来进行，这为开发者提供了便利和参考。通过整合LlamaIndex、Streamlit文档和GPT 3.5的功能，这个聊天机器人在处理复杂问题和提供个性化服务方面具有很大潜力。 <div>
【构建由LlamaIndex支持的文档聊天机器人，用Streamlit文档的内容(或用户自己的数据)增强GPT 3.5】'LlamaIndex - Chat with the Streamlit docs - Build a chatbot powered by LlamaIndex that augments GPT 3.5 with the contents of the Streamlit docs (or your own data).' GitHub: github.com/carolinedlu/llamaindex-chat-with-streamlit-docs <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp6jcbnx94j20w00r0771.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 06:38:19 GMT</pubDate>
</item>
<item>
<title>'AIGC 求职面试指南 - AIGC 求职面经、包括必备基础知识、提示词工程、ChatGPT、Stable Diffusion、Prompt、Embedding、Fintune 等' GitHub: github.com/Embrace...</title>
<link>https://weibo.com/1402400261/ObO2V8c10</link>
<guid>https://weibo.com/1402400261/ObO2V8c10</guid>
<content:encoded><![CDATA[
<div> AIGC, 求职, 面试, 指南, 必备基础知识, 提示词工程, ChatGPT, Stable Diffusion, Prompt, Embedding, Finetune

<br /><br />
总结:
AIGC求职面试指南提供了丰富的内容，包括必备基础知识、提示词工程、ChatGPT、Stable Diffusion、Prompt、Embedding、Finetune等。这些内容可以帮助求职者更好地准备面试，并在面试中展现出自己的专业知识和能力。GitHub上提供了更多的资源和信息，对于想要了解AIGC求职面试的人来说是一个很好的参考资料。建议求职者多加利用这些资源，提升自己的求职竞争力。 <div>
'AIGC 求职面试指南 - AIGC 求职面经、包括必备基础知识、提示词工程、ChatGPT、Stable Diffusion、Prompt、Embedding、Fintune 等' GitHub: github.com/EmbraceAGI/AIGC_Interview <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp6izxov2vj20xb0u0dj4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 06:23:51 GMT</pubDate>
</item>
<item>
<title>【InstructLab(ilab)：用于与LLM模型进行交互和训练的命令行界面】’InstructLab(ilab) - Command-line interface. Use this to chat with the model or train t...</title>
<link>https://weibo.com/1402400261/ObNXSubPs</link>
<guid>https://weibo.com/1402400261/ObNXSubPs</guid>
<content:encoded><![CDATA[
<div> GitHub, InstructLab, LLM模型, 命令行界面, 交互, 训练, 数据, 训练消耗<br />
<br />
LLM模型的InstructLab(ilab)是一个用于与LLM模型进行交互和训练的命令行界面。用户可以通过这个界面与模型进行对话，也可以用于对模型进行训练，不过需要消耗相应的数据。GitHub上有相关项目的源代码，用户可以进行查阅和使用。这个工具提供了一种便捷的方式来与LLM模型进行互动和学习。 <div>
【InstructLab(ilab)：用于与LLM模型进行交互和训练的命令行界面】’InstructLab(ilab) - Command-line interface. Use this to chat with the model or train the model (training consumes the taxonomy data)' GitHub: github.com/instructlab/instructlab <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp6in4g5oxj20w70u0dlf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 06:11:26 GMT</pubDate>
</item>
<item>
<title>【Practical Tips：Go语言编程实践技巧集】’Practical Tips - Go Practical Tips' GitHub: github.com/func25/go-practical-tips #开源# [图片]</title>
<link>https://weibo.com/1402400261/ObNLMwDmi</link>
<guid>https://weibo.com/1402400261/ObNLMwDmi</guid>
<content:encoded><![CDATA[
<div> GitHub, Go语言, 编程, 实践技巧, Go Practical Tips, 项目, 提高技能, 最佳实践, 资源整合, 学习

总结：
Go Practical Tips是一个关于Go语言编程实践技巧的GitHub项目，旨在帮助Go程序员提高编程技能并掌握最佳实践。该项目整合了丰富的资源，包括示例代码、指导原则和实用建议，有助于Go学习者快速上手和提升编程水平。通过参与该项目，可以不断积累实战经验，并与其他Go爱好者分享交流，促进个人成长和技术进步。探索Go语言的深度和广度，从实践中不断汲取经验教训，才能更好地应用Go语言解决实际问题，并发挥其优势。对于想要系统学习Go语言的人来说，这个项目是一个不错的学习资源，可以从中汲取宝贵的经验和知识。参与Go Practical Tips，掌握最佳实践，助力自身技术提升。 <div>
【Practical Tips：Go语言编程实践技巧集】’Practical Tips - Go Practical Tips' GitHub: github.com/func25/go-practical-tips <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp6hrdixktj20u00usdmc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 05:41:37 GMT</pubDate>
</item>
<item>
<title>【HybridAGI: 基于可编程LLM的自治Agent，允许使用基于图的提示编程方法对其行为进行编程】'HybridAGI: The Programmable Neuro-Symbolic AGI for people who wa...</title>
<link>https://weibo.com/1402400261/ObNIhzOLY</link>
<guid>https://weibo.com/1402400261/ObNIhzOLY</guid>
<content:encoded><![CDATA[
<div> HybridAGI、基于LLM、自治Agent、图提示编程、GitHub、SynaLinks、Neuro-Symbolic AGI、人工智能、预期行为、可编程方法

总结:<br /><br />本文介绍了基于可编程LLM的自治Agent HybridAGI，允许使用基于图的提示编程方法对其行为进行编程。这是一种符号神经网络AGI，能够让人们预期AI的行为。该项目托管在GitHub的SynaLinks组织下，提供了一个新颖的AI编程工具，结合了符号和神经网络的特点，在人工智能领域具有较高的潜力。HybridAGI的设计能够满足人们对AI行为控制和可预测性的需求，为AI技术的发展带来了新的可能性。 <div>
【HybridAGI: 基于可编程LLM的自治Agent，允许使用基于图的提示编程方法对其行为进行编程】'HybridAGI: The Programmable Neuro-Symbolic AGI for people who want AI to behave as expected' GitHub: github.com/SynaLinks/HybridAGI <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp6hiyymv2j20u00zwtdi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 05:33:01 GMT</pubDate>
</item>
<item>
<title>【关于 Apple 的 MLX 机器学习库的精选列表，包括关于 MLX 的文章、模型、库和工具、演示、MLX Swift 等内容】'Awesome MLX' GitHub: github.com/antranapp/awes...</title>
<link>https://weibo.com/1402400261/ObNGD7efy</link>
<guid>https://weibo.com/1402400261/ObNGD7efy</guid>
<content:encoded><![CDATA[
<div> GitHub, MLX, 机器学习, 文章, 模型, 库, 工具, 演示, MLX Swift

MLX 是 Apple 推出的机器学习库，开源项目"Awesome MLX"在 GitHub 上提供了关于 MLX 的文章、模型、库和工具、演示、MLX Swift 等内容的精选列表。这个项目汇总了社区分享的关于 MLX 的各种资源，帮助用户快速了解和使用 MLX。GitHub 上的"Awesome MLX"项目是一个有用的资源库，可以帮助开发人员在机器学习领域更好地掌握和应用 MLX。通过这个项目，用户可以找到与 MLX 相关的各种资源，包括文章、模型、库和工具、演示等，帮助他们学习和应用 MLX。总的来说，"Awesome MLX"是一个有价值的资源集合，可以帮助用户更好地了解和使用 Apple 的 MLX 机器学习库。<br /><br />总结: GitHub 上的"Awesome MLX"项目提供了关于 Apple MLX 机器学习库的精选资源列表，包括文章、模型、库和工具、演示、MLX Swift 等内容，帮助开发人员更好地了解和应用 MLX。 <div>
【关于 Apple 的 MLX 机器学习库的精选列表，包括关于 MLX 的文章、模型、库和工具、演示、MLX Swift 等内容】'Awesome MLX' GitHub: github.com/antranapp/awesome-mlx <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp6hexrkzxj210l0u0gqq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 05:28:56 GMT</pubDate>
</item>
<item>
<title>【Perplexica：开源的 AI 搜索引擎，使用高级机器学习算法来理解用户的问题并从网络中找到答案，同时保护用户的隐私】'Perplexica - An AI-powered search engin...</title>
<link>https://weibo.com/1402400261/ObNCp1apk</link>
<guid>https://weibo.com/1402400261/ObNCp1apk</guid>
<content:encoded><![CDATA[
<div> AI, 搜索引擎, 开源, 高级机器学习算法, 用户问题, 答案, 隐私保护, GitHub, Perplexity AI <br />
<br />
总结:Perplexica 是一个开源的AI搜索引擎，采用高级机器学习算法理解用户问题并从网络中找到答案，同时保护用户隐私。用户可以在GitHub上找到Perplexica的代码。 <div>
【Perplexica：开源的 AI 搜索引擎，使用高级机器学习算法来理解用户的问题并从网络中找到答案，同时保护用户的隐私】'Perplexica - An AI-powered search engine - Perplexica is an AI-powered search engine. It is an Open source alternative to Perplexity AI' GitHub: github.com/ItzCrazyKns/Perplexica <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp6h3ug4ksj210f0httci.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 05:18:31 GMT</pubDate>
</item>
<item>
<title>【大型语言模型的局限性：为什么它们无法解决简单问题？】- LLM仍无法解决一些看似简单的问题，比如Wordle和数独，以及需要多步推理的游戏。这说明LLM目前在需要...</title>
<link>https://weibo.com/1402400261/ObMgB5dNV</link>
<guid>https://weibo.com/1402400261/ObMgB5dNV</guid>
<content:encoded><![CDATA[
<div> LLM、局限性、无法解决问题、Wordle、数独、多步推理、细胞自动机、康威生命游戏、目标漂移、自回归特性

<br /><br />总结:
大型语言模型（LLM）在解决一些看似简单的问题时存在局限性，例如Wordle和数独，以及需要多步推理的任务。LLM无法学习细胞自动机如康威生命游戏，表明其难以真正学习背后的规则，只是在训练数据内进行模仿。存在“目标漂移”问题，推理步骤增加时注意力难以保持目标，可靠性下降。即使添加RNN等结构，LLM的自回归特性导致每一步都是从头开始推理，难以有效利用历史信息。虽然可以通过逐步提供信息、链式思维等方法刺激LLM进行多步推理，但可靠性仍有限。尽管LLM在某些领域可以模仿推理，但无法实现真正的泛化，需要进一步研究其局限性。虽然LLM难以取代人类推理，但可作为专家系统在某些领域发挥巨大价值，需要设计专业化的LLM模型。 <div>
【大型语言模型的局限性：为什么它们无法解决简单问题？】<br />- LLM仍无法解决一些看似简单的问题，比如Wordle和数独，以及需要多步推理的游戏。这说明LLM目前在需要记忆能力和计算能力的任务上仍有局限。   <br />- LLM也无法学习细胞自动机如康威生命游戏。这表明LLM无法真正学习背后的规则，只是在训练数据内进行模仿，LLM难以推广。   <br />- LLM存在“目标漂移”问题，随着推理步骤增加，注意力机制难以保持目标，推理可靠性下降。LLM无法像人类那样动态重置上下文。   <br />- 添加RNN等结构只能部分缓解问题，根本原因是LLM的自回归特性导致每一步都是从头开始推理，无法有效利用历史信息。   <br /> 可以通过逐步提供信息、链式思维等方法刺激LLM进行多步推理，但可靠性仍然有限。LLM展现出惊人的直觉但有限的智能。   <br />- 尽管LLM可以在某些领域模仿推理，但由于训练数据的局限，LLM无法实现真正的泛化，还需进一步研究 LLM的局限。   <br />- 虽然LLM难以取代人类推理，但可作为专家系统在某些领域发挥巨大价值，需要针对不同任务设计专业化的LLM模型。<br />《What can LLMs never do? - by Rohit Krishnan》 <a href="https://www.strangeloopcanon.com/p/what-can-llms-never-do"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp6b4cpuzhj20ww0u0wfz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp6b4f5u1rj214g0k8q4p.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp6b4nq3rmj214g0izwgi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 01:52:03 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》...</title>
<link>https://weibo.com/1402400261/ObKTtkiIX</link>
<guid>https://weibo.com/1402400261/ObKTtkiIX</guid>
<content:encoded><![CDATA[
<div> 多模态大模型、人工智能、技术方法、开源平台、应用场景、因果推理、世界模型、多智能体、具身智能、发展方向
<br /><br />总结:
本书由中山大学HCP实验室出品，深入浅出地介绍了多模态大模型的技术方法、开源平台和应用场景。重点讨论了因果推理、世界模型、多智能体和具身智能等前沿技术领域。通过阅读本书，读者可以全面了解多模态大模型的特点和发展方向，对新一代人工智能技术范式和通用人工智能的发展起到重要推动作用。欢迎参与转发评论，赢取这本有价值的全彩图书！ <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》，截至2024.5.1 12:00，*可可粉*转发+评论即可参与。中山大学 HCP 实验室出品，本书以深入浅出的方式介绍多模态大模型的技术方法、开源平台和应用场景，并详细阐述因果推理、世界模型及多智能体与具身智能等前沿技术领域，有助于读者全面了解多模态大模型的特点及发展方向，对新一代人工智能技术范式和通用人工智能的发展起到重要推动作用。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp1q8lh8x1j20m80m8djk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8n4hifj20m80m8gnu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8pgbfhj20m80m8dj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8r3pagj20m80m80ur.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 22:22:20 GMT</pubDate>
</item>
<item>
<title>今日推介(第1389期)：在大型语言建模中替换词元化、长上下文检索的扩展嵌入模型、大语言模型(LLM)时代的图机器学习、基于扩散模型的X观光片3D旋转、低比特量化LL...</title>
<link>https://weibo.com/1402400261/ObKTlAZhD</link>
<guid>https://weibo.com/1402400261/ObKTlAZhD</guid>
<content:encoded><![CDATA[
<div> 扩展嵌入模型、大语言模型、图机器学习、X观光片、扩散模型、3D旋转、低比特量化、LLaMA3模型、性能退化、实证研究

总结:<br />
本文介绍了在大型语言建模中替换词元化的方法，以及对长上下文检索的扩展嵌入模型的应用。随着大语言模型(LLM)时代的到来，图机器学习在自然语言处理中的重要性日益凸显。通过基于扩散模型的X观光片3D旋转技术，可以提升用户体验。然而，研究发现低比特量化LLaMA3模型在性能方面存在一定程度的退化，需要进一步实证研究加以解决。 <div>
今日推介(第1389期)：在大型语言建模中替换词元化、长上下文检索的扩展嵌入模型、大语言模型(LLM)时代的图机器学习、基于扩散模型的X观光片3D旋转、低比特量化LLaMA3模型性能退化的实证研究 公·众·号：爱可可爱生活 <a href="http://aicoco.net/s/8q"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp652c9wcsj21cw0pawkl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp652fpqb0j21d00qu7bf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp652iyg6xj20uw0qugqj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp652n2lnvj20ya0ouq5m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp652qkw5aj21cm0hoju1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 22:22:02 GMT</pubDate>
</item>
<item>
<title>[CV] Editable Image Elements for Controllable Synthesis 网页链接 提出一种新的图像表示方法，将输入图像分解为空间可编辑的图像元素，并使用扩散模型从编辑...</title>
<link>https://weibo.com/1402400261/ObKOCvyLR</link>
<guid>https://weibo.com/1402400261/ObKOCvyLR</guid>
<content:encoded><![CDATA[
<div> 图像表示方法, 图像元素, 可编辑, 扩散模型, 图像合成, 空间分解<br />
<br />
本文提出一种新的图像表示方法，将输入图像分解为空间可编辑的图像元素，利用扩散模型生成逼真的图像。首先，将输入图像分解为可编辑的图像元素，这些元素可以在空间中自由操作和编辑。接着，利用扩散模型来生成经过编辑处理后的图像，保持图像的逼真度和连续性。这种方法提供了更加灵活和精细的图像编辑和合成方式，能够生成高质量的合成图像。通过实验验证，该方法在图像编辑和合成方面取得了较好的效果，有着广泛的应用前景。综上所述，本文提出的图像表示方法以及利用扩散模型实现的图像合成方法具有很高的研究和实际应用价值。<br /><br />总结: 本文介绍了一种新的图像表示方法，通过分解输入图像为可编辑的图像元素，并利用扩散模型生成逼真图像，提供了更加灵活和精细的图像编辑和合成方式，具有高的研究和应用价值。 <div>
[CV] Editable Image Elements for Controllable Synthesis  <br /><a href="https://arxiv.org/abs/2404.16029"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />提出一种新的图像表示方法，将输入图像分解为空间可编辑的图像元素，并使用扩散模型从编辑后的图像元素生成逼真图像。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp64qko5f5j20t619otkt.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp64ql43ocj21pg1cs4o6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp64qlhhtyj21pe18sqm3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp64qmjtl5j210a1d67mk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 22:10:23 GMT</pubDate>
</item>
<item>
<title>[CV] MoDE: CLIP Data Experts via Clustering 网页链接 通过对大规模网页数据进行聚类训练多个 CLIP 数据专家模型，缓解了不同语义文本被配对到相似图像中的噪...</title>
<link>https://weibo.com/1402400261/ObKKWDOUk</link>
<guid>https://weibo.com/1402400261/ObKKWDOUk</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模网页数据、CLIP 数据专家模型、语义文本、视觉-语言对比学习、噪音、基准测试

总结:<br />
本研究通过对大规模网页数据进行聚类，训练了多个CLIP数据专家模型。这一方法有效地减轻了不同语义文本被配对到相似图像中的噪音问题，提升了视觉-语言对比学习的效果。研究结果显示，在多个CLIP基准测试中，该方法表现优于强基线。这表明基于聚类训练的CLIP数据专家模型在视觉-语言对比学习任务中具有较高的效果。这一研究为进一步探索如何利用大规模数据提升模型表现提供了有益的参考。 <div>
[CV] MoDE: CLIP Data Experts via Clustering  <br /><a href="https://arxiv.org/abs/2404.16030"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>        <br />通过对大规模网页数据进行聚类训练多个 CLIP 数据专家模型，缓解了不同语义文本被配对到相似图像中的噪音，提升了 视觉-语言对比学习的效果，在多个 CLIP 基准测试上优于强基线。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp64h5fwgnj20wm13i7jz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp64h66lmrj21ne0k0gua.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp64h6dik8j20ta0ki415.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 22:01:20 GMT</pubDate>
</item>
<item>
<title>[CV] CatLIP: CLIP-level Visual Recognition Accuracy with 2.7x Faster Pre-training on Web-scale Image-Text Data 网页链接 CatLIP通过将图像-文本预训练重...</title>
<link>https://weibo.com/1402400261/ObKIestVZ</link>
<guid>https://weibo.com/1402400261/ObKIestVZ</guid>
<content:encoded><![CDATA[
<div> CatLIP, 图像-文本预训练, 分类任务, CLIP, 预训练速度, 性能, 下游任务, Web-scale Image-Text Data, Visual Recognition Accuracy

<br /><br />总结:
CatLIP通过将图像-文本预训练任务转变为分类任务，实现了比CLIP快2.7倍的预训练速度。在下游任务中取得了相当的性能表现。该方法利用Web规模的图像-文本数据，提高了视觉识别的准确性。CatLIP的创新在于以更高效的方式将图像和文本信息进行整合，加快了预训练过程，同时在视觉识别任务中取得了令人满意的结果。CatLIP的方法可能有助于提高图像识别系统的效率和准确性，为未来的视觉任务提供了新的思路。 <div>
[CV] CatLIP: CLIP-level Visual Recognition Accuracy with 2.7x Faster Pre-training on Web-scale Image-Text Data  <br /><a href="https://arxiv.org/abs/2404.15653"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />CatLIP通过将图像-文本预训练重构为分类任务实现了比CLIP快2.7倍的预训练速度，在下游任务上获得了相当的性能。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp64a8jf3sj20w214kk6i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp64a8rw21j21my0mg49b.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp64a97k8vj21me0jmn4u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 21:54:39 GMT</pubDate>
</item>
<item>
<title>通过全面的实证研究揭示了强大的LLAMA3模型在各类低比特位宽量化下的表现及不足，为未来的语言模型量化技术提供了宝贵启发。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]...</title>
<link>https://weibo.com/1402400261/ObKDOiSG1</link>
<guid>https://weibo.com/1402400261/ObKDOiSG1</guid>
<content:encoded><![CDATA[
<div> LLAMA3模型、低比特位宽量化、实证研究、表现、启发、语言模型、技术、量化、强大、不足
<br />
<br />
总结:本研究通过全面实证研究揭示了LLAMA3模型在各类低比特位宽量化下的表现及不足，为未来的语言模型量化技术提供了宝贵启发。研究展示了LLAMA3模型在低比特位宽下的性能及存在的问题，为后续研究提供了重要参考。实验证实了该模型在不同量化情况下的特性，对于优化语言模型量化技术具有重要意义，为未来的研究提供了新的思路和方向。 <div>
通过全面的实证研究揭示了强大的LLAMA3模型在各类低比特位宽量化下的表现及不足，为未来的语言模型量化技术提供了宝贵启发。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《How Good Are Low-bit Quantized LLaMA3 Models? An Empirical Study》W Huang, X Ma, H Qin, X Zheng... [The University of Hong Kong &amp; Beihang University &amp; ETH Zurich] (2024) <a href="https://arxiv.org/abs/2404.14047"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp63sq7vzuj21460te15n.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp63sqigh6j21cm0ho77p.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp63sqq8axj216418cgz3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp63sqrfj9j216i0uy47d.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 21:43:45 GMT</pubDate>
</item>
<item>
<title>[CL]《How Good Are Low-bit Quantized LLaMA3 Models? An Empirical Study》W Huang, X Ma, H Qin, X Zheng... [The University of Hong Kong &amp; Beihang Univer...</title>
<link>https://weibo.com/1402400261/ObKDJ25wu</link>
<guid>https://weibo.com/1402400261/ObKDJ25wu</guid>
<content:encoded><![CDATA[
<div> 关键词: 低比特量化，LLaMA3模型，实证研究，性能评估，模型压缩

总结:<br /><br />
本研究针对低比特量化的LLaMA3模型进行了实证研究，评估了其性能表现。研究团队来自香港大学、北航和苏黎世联邦理工学院。他们在研究中发现，低比特量化后的LLaMA3模型在性能方面表现良好，具有可行性和有效性。研究结果为模型压缩和优化提供了有益参考，对未来深度学习模型的设计和应用具有重要意义。 <div>
[CL]《How Good Are Low-bit Quantized LLaMA3 Models? An Empirical Study》W Huang, X Ma, H Qin, X Zheng... [The University of Hong Kong &amp; Beihang University &amp; ETH Zurich] (2024) <a href="https://arxiv.org/abs/2404.14047"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp63sq7vzuj21460te15n.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp63sqigh6j21cm0ho77p.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp63sqq8axj216418cgz3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp63sqrfj9j216i0uy47d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 21:43:32 GMT</pubDate>
</item>
<item>
<title>提出利用条件扩散模型从单视角放射线照片生成不同视角的方法，解决了以往基于GAN的方法存在的图像质量和多样性不足的问题，为单视角到3D重建提供了新的思路。 - ...</title>
<link>https://weibo.com/1402400261/ObKAdwVED</link>
<guid>https://weibo.com/1402400261/ObKAdwVED</guid>
<content:encoded><![CDATA[
<div> Mayo Clinic, Radiographs, Diffusion Models, 3D Rotation, RadRotator, Image Quality, Diversity, Single-view to 3D Reconstruction, GAN

<br /><br />总结:
本研究提出了一种利用条件扩散模型从单视角放射线照片生成不同视角的方法，名为RadRotator。该方法解决了以往基于GAN的方法在图像质量和多样性方面的不足，为单视角到3D重建提供了新思路。Mayo Clinic的研究团队通过RadRotator提供了一种有效的方式来进行3D旋转放射影像，并在图像质量和多样性方面取得了显著的进展。通过该方法，可以更好地实现从单视角到3D重建的任务，为医学影像处理领域带来了新的发展机会。RadRotator方法的提出为优化医学影像处理和医学诊断提供了新的思路和方法，具有重要的研究和实际应用意义。 <div>
提出利用条件扩散模型从单视角放射线照片生成不同视角的方法，解决了以往基于GAN的方法存在的图像质量和多样性不足的问题，为单视角到3D重建提供了新的思路。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《RadRotator: 3D Rotation of Radiographs with Diffusion Models》P Rouzrokh, B Khosravi, S Faghani, K L. Mulford, M J. Taunton, B J. Erickson, C C. Wyles [Mayo Clinic] (2024) <a href="https://arxiv.org/abs/2404.13000"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp63gjr8oqj21p20v6h44.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp63gk4zdrj21sy0kqagw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp63gkix4fj20ya0oun0h.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp63gl5yyaj21sy0na44v.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp63gljgvlj215t0lyq7t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp63glj5f3j216y0hw0vt.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 21:34:54 GMT</pubDate>
</item>
<item>
<title>[CV]《RadRotator: 3D Rotation of Radiographs with Diffusion Models》P Rouzrokh, B Khosravi, S Faghani, K L. Mulford, M J. Taunton, B J. Erickson, C C....</title>
<link>https://weibo.com/1402400261/ObKAbrKEB</link>
<guid>https://weibo.com/1402400261/ObKAbrKEB</guid>
<content:encoded><![CDATA[
<div> Mayo Clinic, RadRotator, 3D Rotation, Radiographs, Diffusion Models, P Rouzrokh, B Khosravi, S Faghani, K L. Mulford, M J. Taunton, B J. Erickson, C C. Wyles

总结:<br />
Mayo Clinic的研究团队在《RadRotator: 3D Rotation of Radiographs with Diffusion Models》一文中介绍了他们开发的RadRotator技术，该技术可以实现对放射影像进行三维旋转。文中作者介绍了使用扩散模型来实现这种三维旋转的方法，并详细说明了技术的具体实现和应用。该技术的开发者包括P Rouzrokh、B Khosravi、S Faghani、K L. Mulford、M J. Taunton、B J. Erickson和C C. Wyles。该技术的创新之处在于可以更清晰地呈现放射影像，在临床诊断和治疗方面具有潜在的重要应用。通过这项研究，Mayo Clinic为医学影像领域的技术发展作出了重要贡献。 <div>
[CV]《RadRotator: 3D Rotation of Radiographs with Diffusion Models》P Rouzrokh, B Khosravi, S Faghani, K L. Mulford, M J. Taunton, B J. Erickson, C C. Wyles [Mayo Clinic] (2024) <a href="https://arxiv.org/abs/2404.13000"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp63gjr8oqj21p20v6h44.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp63gk4zdrj21sy0kqagw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp63gkix4fj20ya0oun0h.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp63gl5yyaj21sy0na44v.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp63gljgvlj215t0lyq7t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp63glj5f3j216y0hw0vt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 21:34:48 GMT</pubDate>
</item>
<item>
<title>通过全方位、系统性地回顾大型语言模型与图结构的结合在图机器学习中的进展、应用和未来发展，为理解这个新兴且前景广阔的研究领域提供了宝贵的指导。 - 转发 @...</title>
<link>https://weibo.com/1402400261/ObKve6Zj2</link>
<guid>https://weibo.com/1402400261/ObKve6Zj2</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、图结构、图机器学习、进展、应用、未来发展、理解、研究领域、指导、广阔<br />
<br />
<br />总结:
本文系统性回顾了大型语言模型与图结构在图机器学习中的进展、应用和未来发展。首先介绍了大型语言模型与图结构相结合的重要性和意义，进而详细探讨了两者在图机器学习领域中的应用场景和进展情况。文章强调了这一结合给研究领域带来的新思路和方法。最后，展望了未来该研究领域的发展方向和前景，为从事相关研究的人员提供了宝贵的指导。文章全面、深入地阐述了这个新兴领域的重要性和前景，对读者们深入了解图机器学习中大型语言模型与图结构的结合提供了有益的参考。 <div>
通过全方位、系统性地回顾大型语言模型与图结构的结合在图机器学习中的进展、应用和未来发展，为理解这个新兴且前景广阔的研究领域提供了宝贵的指导。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Graph Machine Learning in the Era of Large Language Models (LLMs)》W Fan, S Wang, J Huang, Z Chen… [he Hong Kong Polytechnic University] (2024) <a href="https://arxiv.org/abs/2404.14928"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp6370fh30j21lo0ig15h.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp63717as6j20uw0qu7az.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp6371jbrjj21ps15itq9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp6371hz9kj20v60tgwll.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp637ku0bbj214o0ua44q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp637kspawj214m0h80wx.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 21:22:36 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.27)》 爱可可微博热门分享(4.27) [图片]</title>
<link>https://weibo.com/1402400261/ObHSt2HHz</link>
<guid>https://weibo.com/1402400261/ObHSt2HHz</guid>
<content:encoded><![CDATA[
<div> 爱可可 微博 热门 分享 关键词: 爱可可, 微博, 热门, 分享

总结:<br /><br />4月27日，爱可可微博热门分享了一篇内容受欢迎的微博。文章内容包括一些有趣的信息和内容，吸引了大量用户关注和转发。爱可可微博一直是热门的社交平台，通过分享各种新闻、趣闻和话题，吸引了众多用户参与讨论和互动，为用户提供了一个交流和分享的平台。在这篇热门分享中，爱可可微博展示了其丰富的内容和吸引人的话题，吸引了更多用户的关注和参与，显示了爱可可微博在社交媒体领域的影响力和号召力。 <div>
《爱可可微博热门分享(4.27)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405027902767890650"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.27)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp5rrjyfq2j20ps0ei41p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 14:41:37 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Subtractive Mixture Models via Squaring: Representation and Learning》(ICLR 2024) GitHub: github.com/april-tools/squared-npcs《Dra...</title>
<link>https://weibo.com/1402400261/ObGjwqjmT</link>
<guid>https://weibo.com/1402400261/ObGjwqjmT</guid>
<content:encoded><![CDATA[
<div> 关键词：Subtractive Mixture Models, Squaring, Representation, Learning, Interactive Point-based Editing, Diffusion Semantic Propagation, Vision-and-Language Navigation, Causal Learning, Radiance Fields, Portrait Generation

总结:<br />
《Subtractive Mixture Models via Squaring: Representation and Learning》介绍了一种通过平方实现减法混合模型的方法，在表示和学习方面取得了进展。<br />
《Drag Your Noise: Interactive Point-based Editing via Diffusion Semantic Propagation》提出了一种交互式基于点编辑的方法，通过扩散语义传播来编辑噪声。<br />
《Vision-and-Language Navigation via Causal Learning》探讨了通过因果学习进行视觉与语言导航的方法。<br />
《Rip-NeRF: Anti-aliasing Radiance Fields with Ripmap-Encoded Platonic Solids》介绍了一种利用Ripmap编码的几何体来抗锯齿辐射场的方法。<br />
《ConsistentID : Portrait Generation with Multimodal Fine-Grained Identity Preserving 》介绍了一种具有多模态细粒度身份保持的肖像生成方法。<br />
《DreamPhysics: Learning Physical Properties of Dynamic 3D Gaussians from Video Diffusion Priors》通过视频扩散先验学习动态3D高斯函数的物理属性。<br />
《CWF: Consolidating Weak Features in High-quality Mesh Simplification》介绍了一种在高质量网格简化中巩固弱特征的方法。<br />
《Reconstructing Hand-Held Objects in 3D》探讨了在三维空间中重建手持物体的方法。<br />
《Enriching Music Descriptions with a Finetuned-LLM and Metadata for Text-to-Music Retrieval》介绍了一种通过细调LLM和元数据来丰富音乐描述以进行文本到音乐检索的方法。<br />
《MMT-Bench: A Multimodal MultiTask Benchmark for Comprehensive Evaluation of Large Vision-Language Models》介绍了用于大型视觉语言模型综合评估的多模式多任务基准。<br /> <div>
几篇论文实现代码：<br />《Subtractive Mixture Models via Squaring: Representation and Learning》(ICLR 2024) GitHub: github.com/april-tools/squared-npcs<br />《Drag Your Noise: Interactive Point-based Editing via Diffusion Semantic Propagation》(CVPR 2024) GitHub: github.com/haofengl/DragNoise<br />《Vision-and-Language Navigation via Causal Learning》(CVPR 2024) GitHub: github.com/CrystalSixone/VLN-GOAT<br />《Rip-NeRF: Anti-aliasing Radiance Fields with Ripmap-Encoded Platonic Solids》(SIGGRAPH 2024) GitHub: github.com/JunchenLiu77/Rip-NeRF [fig2]<br />《ConsistentID : Portrait Generation with Multimodal Fine-Grained Identity Preserving 》(2024) GitHub: github.com/JackAILab/ConsistentID [fig1]<br />《DreamPhysics: Learning Physical Properties of Dynamic 3D Gaussians from Video Diffusion Priors》(2024) GitHub: github.com/tyhuang0428/DreamPhysics<br />《CWF: Consolidating Weak Features in High-quality Mesh Simplification》(2024) GitHub: github.com/Xrvitd/CWF<br />《Reconstructing Hand-Held Objects in 3D》(2024) GitHub: github.com/janehwu/mcc-ho<br />《Enriching Music Descriptions with a Finetuned-LLM and Metadata for Text-to-Music Retrieval》(2024) GitHub: github.com/seungheondoh/music-text-representation-pp<br />《MMT-Bench: A Multimodal MultiTask Benchmark for Comprehensive Evaluation of Large Vision-Language Models》(2024) GitHub: github.com/OpenGVLab/MMT-Bench [fig4]<br />《SMPLer: Taming Transformers for Monocular 3D Human Shape and Pose Estimation》(2024) GitHub: github.com/xuxy09/smpler<br />《Vertex Block Descent》(2024) GitHub: github.com/AnkaChan/TinyVBD<br />《NIIRF: Neural IIR Filter Field for HRTF Upsampling and Personalization》(2024) GitHub: github.com/merlresearch/neural-IIR-field<br />《Learning Visuotactile Skills with Two Multifingered Hands》(2024) GitHub: github.com/ToruOwO/hato<br />《Make Your LLM Fully Utilize the Context》(2024) GitHub: github.com/microsoft/FILM<br />《MR-MT3: Memory Retaining Multi-Track Music Transcription to Mitigate Instrument Leakage》(2024) GitHub: github.com/gudgud96/MR-MT3<br />《Towards Efficient and Reliable LLM Serving: A Real-World Workload Study》(2024) GitHub: github.com/HPMLL/BurstGPT<br />《Beyond A* Better Planning with Transformers via Search Dynamics Bootstrapping》(2024) GitHub: github.com/facebookresearch/searchformer<br />《ChangeCLIP: Remote sensing change detection with multimodal vision-language representation learning》(2024) GitHub: github.com/dyzy41/ChangeCLIP<br />《Simple and Controllable Music Generation》(2024) GitHub: github.com/ylacombe/musicgen-dreamboothing<br />《BEV-MAE: Bird's Eye View Masked Autoencoders for Point Cloud Pre-training in Autonomous Driving Scenarios》(2024) GitHub: github.com/VDIGPKU/BEV-MAE<br />《BEV-MAE: Bird's Eye View Masked Autoencoders for Point Cloud Pre-training in Autonomous Driving Scenarios》(2024) GitHub: github.com/VDIGPKU/BEV-MAE<br />《SCNet: Sparse Compression Network for Music Source Separation》(2024) GitHub: github.com/starrytong/SCNet [fig3]<br />《PeLiCal: Targetless Extrinsic Calibration via Penetrating<br />Lines for RGB-D Cameras with Limited Co-visibility》(2024) GitHub: github.com/joomeok/PeLiCal<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp5e72iuoxj21eq0qh7wh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp5j74ovgnj21i10i6nay.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp5k3o914gj21ep0jm76s.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp5ki39uazj23341qi7wj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 10:42:47 GMT</pubDate>
</item>
<item>
<title>【InterviewPilot.AI：使用AI帮用户进行面试练习的面试准备工具】’InterviewPilot.AI - Ace interviews with AI practice. Our agent role-plays personalized ...</title>
<link>https://weibo.com/1402400261/ObG6r3qcB</link>
<guid>https://weibo.com/1402400261/ObG6r3qcB</guid>
<content:encoded><![CDATA[
<div> 面试准备工具、AI、面试练习、代理角色、个性化面试、GitHub、训练、情境、工具

<br /><br />总结:
InterviewPilot.AI是一个使用AI技术帮助用户进行面试准备的工具，其代理角色会根据用户的背景定制个性化的面试练习，听取用户的回答并像真实面试官一样作出反应。用户可以通过这个工具在不同情境下进行训练，帮助他们在各种面试场合中取得成功。同时，该工具还在GitHub上进行开源，让更多人能够使用和分享。 <div>
【InterviewPilot.AI：使用AI帮用户进行面试练习的面试准备工具】’InterviewPilot.AI - Ace interviews with AI practice. Our agent role-plays personalized interview tailored to your background, listening and replying like a real interviewer. Train across personas for any situation.' GitHub: github.com/tejpshah/interview-pilot-ai <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp5jxmlyacj20v00u0wk8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 10:10:32 GMT</pubDate>
</item>
<item>
<title>【anime.gf：CharacterAI开源复现版，可私有化部署的开源 LLM 前端项目】’anime.gf - Local &amp; Open Source Alternative to CharacterAI' GitHub: github.com/cy...</title>
<link>https://weibo.com/1402400261/ObG36cHkB</link>
<guid>https://weibo.com/1402400261/ObG36cHkB</guid>
<content:encoded><![CDATA[
<div> 开源、复现版、私有化部署、LLM、前端项目、anime.gf、CharacterAI、GitHub、local、 alternative

<br /><br />总结:
anime.gf是一个可私有化部署的开源前端项目，是CharacterAI的复现版本，提供了一个本地和开源的替代解决方案。用户可以在GitHub上找到该项目，并使用LLM技术实现人物角色相关功能。 <div>
【anime.gf：CharacterAI开源复现版，可私有化部署的开源 LLM 前端项目】’anime.gf - Local &amp; Open Source Alternative to CharacterAI' GitHub: github.com/cyanff/anime.gf <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp5jozpdl7j21es0s9aiv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 10:02:19 GMT</pubDate>
</item>
<item>
<title>'LLM全栈优质资源汇总' GitHub: github.com/liguodongiot/llm-resource #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/ObG0hj06m</link>
<guid>https://weibo.com/1402400261/ObG0hj06m</guid>
<content:encoded><![CDATA[
<div> GitHub, LLM, 全栈, 优质资源, 汇总

LLM全栈优质资源汇总是一个GitHub仓库，提供了丰富的全栈开发资源。这个仓库由liguodongiot创建并维护，收集了各种优质的学习资料、工具和教程，方便开发人员学习和使用。仓库中包含了各种技术领域的资源，涵盖了前端、后端、数据库、DevOps等方面。开发人员可以通过这个仓库找到他们需要的各种资源，提升自己的技能和知识水平。

总结：<br /><br />LLM全栈优质资源汇总是一个GitHub仓库，提供了丰富的全栈开发资源，由liguodongiot创建并维护，包含各种优质学习资料和工具，方便开发人员学习和使用。<br />仓库中包含各种技术领域的资源，涵盖了前端、后端、数据库、DevOps等方面，让开发人员可以找到自己需要的资源，提升技能和知识水平。 <div>
'LLM全栈优质资源汇总' GitHub: github.com/liguodongiot/llm-resource <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp5jhrdk17j20u013k0wx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 09:55:22 GMT</pubDate>
</item>
<item>
<title>【GenIR-Survey：生成式信息检索(GenIR)相关论文列表】’GenIR-Survey - This is the repository for the GenIR survey.' GitHub: github.com/RUC-NLPIR/GenIR-S...</title>
<link>https://weibo.com/1402400261/ObFXBdVkT</link>
<guid>https://weibo.com/1402400261/ObFXBdVkT</guid>
<content:encoded><![CDATA[
<div> GitHub, GenIR, 信息检索, 论文列表, 生成式

总结:<br /><br />该文章介绍了关于生成式信息检索(GenIR)的调查研究，对GenIR调查的知识库进行了介绍。GitHub上提供了GenIR调查的存储库，研究了相关论文列表。GenIR算法在信息检索领域中具有重要意义，通过这篇文章可以了解到更多关于GenIR的相关领域研究进展。 <div>
【GenIR-Survey：生成式信息检索(GenIR)相关论文列表】’GenIR-Survey - This is the repository for the GenIR survey.' GitHub: github.com/RUC-NLPIR/GenIR-Survey <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp5ja74am3j20xo0u0n57.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 09:48:46 GMT</pubDate>
</item>
<item>
<title>【Suno AI API：用 API 调用 suno.ai 的音乐生成 AI，并且可以轻松集成到 GPTs 等 agent 中】'Suno AI API - Use API to call the music generation AI of suno....</title>
<link>https://weibo.com/1402400261/ObFUR0GYX</link>
<guid>https://weibo.com/1402400261/ObFUR0GYX</guid>
<content:encoded><![CDATA[
<div> API，音乐生成，Suno AI，集成，GPTs，agent，调用，github，gcui-art，易用性

<br /><br />总结:
文章介绍了Suno AI API，可以通过API调用suno.ai的音乐生成AI，并且可以轻松集成到像GPTs这样的agent中。该API提供了方便的方式让用户调用音乐生成AI，同时可以用于集成到各种agent中，增强其功能。该项目的代码托管在GitHub上，方便用户访问和使用。整体来说，Suno AI API提供了一个便捷的方式让用户利用音乐生成AI进行创作和应用。 <div>
【Suno AI API：用 API 调用 suno.ai 的音乐生成 AI，并且可以轻松集成到 GPTs 等 agent 中】'Suno AI API - Use API to call the music generation AI of suno.ai, and easily integrate it into agents like GPTs.' GitHub: github.com/gcui-art/suno-api <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp5j3mjgw0j21840kk406.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 09:42:00 GMT</pubDate>
</item>
<item>
<title>【TagStudio (Preview/Alpha): 开源的文件/照片管理应用和系统，目标是创建一个便携式、隐私友好、开放、可扩展且功能丰富的文件组织系统】’TagStudio (Preview...</title>
<link>https://weibo.com/1402400261/ObFP9zV2a</link>
<guid>https://weibo.com/1402400261/ObFP9zV2a</guid>
<content:encoded><![CDATA[
<div> 文件管理、照片管理、开源、隐私友好、可扩展、功能丰富、用户友好、便携、系统、TagStudio

<br /><br />总结:
TagStudio是一个开源的文件/照片管理应用和系统，旨在创建一个便携式、隐私友好、开放、可扩展且功能丰富的文件组织系统。它注重用户体验，提供便捷的文件管理和照片管理功能，保护用户隐私，同时支持系统的扩展性和自定义功能。TagStudio是一个用户友好的文件组织系统，旨在为用户提供更好的文件管理体验。 <div>
【TagStudio (Preview/Alpha): 开源的文件/照片管理应用和系统，目标是创建一个便携式、隐私友好、开放、可扩展且功能丰富的文件组织系统】’TagStudio (Preview/Alpha): A User-Focused Document Management System - A file and photo management application and system.' GitHub: github.com/TagStudioDev/TagStudio <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp5ip8bi09j21900sg4bm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 09:27:58 GMT</pubDate>
</item>
<item>
<title>【文档图像处理相关论文和数据集列表】’Recommendations of Document Image Processing - This repository contains a paper collection of the methods for do...</title>
<link>https://weibo.com/1402400261/ObFMWvGKr</link>
<guid>https://weibo.com/1402400261/ObFMWvGKr</guid>
<content:encoded><![CDATA[
<div> 方法, 文档图像处理, 外观增强, 去阴影, 矫正, 去模糊, 二值化

文档图像处理是一项重要的研究领域，涉及到外观增强、去阴影、矫正、去模糊和二值化等技术。在这个存储库中，收集了相关论文和数据集，探讨了不同方法在文档图像处理中的应用。外观增强是通过改进图像的视觉质量来提高文档图像的识别性能，而去阴影则是消除图像中的阴影干扰。矫正技术可以对文档图像进行几何变换，使其更加规范和易于处理，而去模糊则可以提高文档图像的清晰度。二值化是将文档图像转换为黑白两色，方便后续的处理和识别。这些技术的研究有助于提高文档图像处理的效率和准确性，对于数字化文档管理和文档识别具有重要意义。

<br /><br />总结:方法, 文档图像处理, 外观增强, 去阴影, 矫正, 去模糊, 二值化。文档图像处理是一项重要的研究领域，涉及到外观增强、去阴影、矫正、去模糊和二值化等技术。外观增强是通过改进图像的视觉质量来提高文档图像的识别性能，而去阴影则是消除图像中的阴影干扰。矫正技术可以对文档图像进行几何变换，使其更加规范和易于处理，而去模糊则可以提高文档图像的清晰度。二值化是将文档图像转换为黑白两色，方便后续的处理和识别。这些技术的研究有助于提高文档图像处理的效率和准确性，对于数字化文档管理和文档识别具有重要意义。 <div>
【文档图像处理相关论文和数据集列表】’Recommendations of Document Image Processing - This repository contains a paper collection of the methods for document image processing, including appearance enhancement, deshadow, dewarping, deblur, and binarization.' GitHub: github.com/ZZZHANG-jx/Recommendations-Document-Image-Processing <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp5ijo3dsmj217s0rugqv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 09:22:31 GMT</pubDate>
</item>
<item>
<title>【Simone：将 YouTube 视频转换成博客文章，并自动生成相关的上下文截图】'Simone - Repurpose your YouTube videos by converting them into blog posts.' GitH...</title>
<link>https://weibo.com/1402400261/ObFM447Xt</link>
<guid>https://weibo.com/1402400261/ObFM447Xt</guid>
<content:encoded><![CDATA[
<div> YouTube, 视频, 转换, 博客文章, 自动生成, 上下文截图, GitHub, repurpose, blog posts

要点一：Simone是一个工具，可以帮助用户将YouTube视频转换成博客文章，并自动生成相关的上下文截图。
要点二：GitHub上有Simone的代码，可以在github.com/rajtilakjee/simone上找到。
要点三：通过将YouTube视频转换成博客文章，可以更好地利用视频内容，提高内容的传播和利用效率。
要点四：转换成博客文章后，可以增加网站的内容多样性，吸引更多的读者和访问者。
要点五：自动生成相关的上下文截图，可以帮助文章更具可读性和吸引力。
要点六：利用Simone工具，可以节省用户大量时间和精力，快速地将视频内容转化为文字形式。
要点七：用户只需简单操作，即可将YouTube视频转换成博客文章，无需复杂的技术或编辑知识。
要点八：将视频内容转换成文字形式还可以方便搜索引擎收录和排名，提升网站的SEO效果。
要点九：通过转换视频内容成博客文章，可以扩大内容的传播范围，吸引更多的目标受众。
要点十：Simone工具的使用简单方便，是一种有效的内容转化方式，适合各类视频创作者和博客写手。 

<br /><br />总结: 
Simone是一个工具，可以帮助用户将YouTube视频转换成博客文章，并自动生成相关的上下文截图。通过GitHub上的代码，用户可以简单操作，将视频内容转化成文字形式，提高内容的传播和利用效率，增加网站的内容多样性。自动生成相关截图，提升文章可读性和吸引力。转换视频内容成博客文章，可以提升SEO效果，吸引更多目标受众，是一种有效的内容转化方式。Simone工具简单易用，适合各类视频创作者和博客写手使用。 <div>
【Simone：将 YouTube 视频转换成博客文章，并自动生成相关的上下文截图】'Simone - Repurpose your YouTube videos by converting them into blog posts.' GitHub: github.com/rajtilakjee/simone <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp5ihenxsyj21330u0n1g.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 09:20:21 GMT</pubDate>
</item>
<item>
<title>【PDFText：类似 PyMuPDF用于从 PDF 文件提取结构化文本的Python库】’PDFText - Extract structured text from pdfs quickly' GitHub: github.com/VikParuchuri...</title>
<link>https://weibo.com/1402400261/ObEN9EwF9</link>
<guid>https://weibo.com/1402400261/ObEN9EwF9</guid>
<content:encoded><![CDATA[
<div> GitHub, PDFText, 提取结构化文本, Python库, PDF文件, VikParuchuri, pdftext<br />
<br />
提取结构化文本的Python库PDFText能够快速从PDF文件中提取文本信息，通过GitHub项目链接github.com/VikParuchuri/pdftext可以找到该库的详细信息和文档。PDFText库使用简单、高效，可帮助用户从PDF文件中提取出结构化的文本，提高文本处理的效率。详细的使用方法和示例在GitHub上有详细说明，用户可以根据自己的需求和情况使用PDFText库进行文本提取工作。总的来说，PDFText是一个方便实用的Python库，可以帮助用户快速准确地从PDF文件中提取出结构化的文本信息。<br /><br />总结: <br />PDFText是一个用于从PDF文件提取结构化文本的Python库，能够快速高效地完成文本提取工作。通过GitHub项目链接github.com/VikParuchuri/pdftext可以找到详细的使用方法和示例，让用户可以根据自己的需求轻松地使用该库进行文本提取。 <div>
【PDFText：类似 PyMuPDF用于从 PDF 文件提取结构化文本的Python库】’PDFText - Extract structured text from pdfs quickly' GitHub: github.com/VikParuchuri/pdftext <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp5e56svw2j21740gg0v3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 06:50:18 GMT</pubDate>
</item>
<item>
<title>'Awesome-Chinese-Stable-Diffusion - 中文文生图stable diffsion模型集合' GitHub: github.com/leeguandong/Awesome-Chinese-Stable-Diffusion #开源# #机器学...</title>
<link>https://weibo.com/1402400261/ObErofwl3</link>
<guid>https://weibo.com/1402400261/ObErofwl3</guid>
<content:encoded><![CDATA[
<div> GitHub, 中文文生图, stable diffusion, 模型集合, leeguandong, Awesome-Chinese-Stable-Diffusion

<br /><br />
本文介绍了一个名为Awesome-Chinese-Stable-Diffusion（中文文生图stable diffusion）的模型集合，该集合由GitHub用户leeguandong创建。该集合主要涵盖了稳定扩散模型的相关内容，旨在探讨中文文本的稳定传播和扩散过程。通过GitHub链接可以查看到相关的代码和文档，为对该领域感兴趣的研究人员提供了一个有用的资源。该模型集合的制作者希望能够促进稳定扩散模型在中文文本处理领域的应用和研究，为相关领域的发展做出贡献。通过学习和使用这些模型，可以更好地理解中文文本的传播规律和影响因素，为文本处理和信息传播提供更深入的理解和研究方向。整体而言，Awesome-Chinese-Stable-Diffusion模型集合为研究者提供了一个有益的资源平台，有助于推动相关领域的发展和创新。 <div>
'Awesome-Chinese-Stable-Diffusion - 中文文生图stable diffsion模型集合' GitHub: github.com/leeguandong/Awesome-Chinese-Stable-Diffusion <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp5clh9hhfj21ji0rq79j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 05:56:40 GMT</pubDate>
</item>
<item>
<title>【Geoguess：开源的地理位置猜测游戏，使用 Google Map StreetView，可以单人或多人同时玩】'Geoguess - GeoGuess is an open-source geography game with Googl...</title>
<link>https://weibo.com/1402400261/ObEnVnTwd</link>
<guid>https://weibo.com/1402400261/ObEnVnTwd</guid>
<content:encoded><![CDATA[
<div> Geoguess, 开源, 地理位置, 猜测游戏, Google Map StreetView, 单人, 多人, GitHub, GeoGuess/GeoGuess 

<br /><br />总结:
GeoGuess是一个开源的地理位置猜测游戏，使用Google Map StreetView。玩家可以选择单人模式或与朋友同时玩。该游戏可以在GitHub上找到。 <div>
【Geoguess：开源的地理位置猜测游戏，使用 Google Map StreetView，可以单人或多人同时玩】'Geoguess - GeoGuess is an open-source geography game with Google Map StreetView. You can play solo or with your friends simultaneously.' GitHub: github.com/GeoGuess/GeoGuess <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp5cc94969j214j0u0wk2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 05:48:08 GMT</pubDate>
</item>
<item>
<title>【Llama3免费在线体验】《Llama 3 Chat Meta AI》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/ObCiVl7xJ</link>
<guid>https://weibo.com/1402400261/ObCiVl7xJ</guid>
<content:encoded><![CDATA[
<div> 免费、在线体验、Llama 3、Chat、Meta AI

<br /><br />总结:
Llama 3是一款基于Meta AI技术的在线聊天工具，用户可以免费在线体验。通过Llama 3，用户可以与AI进行聊天互动，享受智能对话带来的乐趣和便利。这款工具可以帮助用户解决问题、获得信息，并提供个性化的服务。Llama 3的出现为人们的生活带来了新的可能性，让人们可以更轻松地与人工智能进行交流互动。 <div>
【Llama3免费在线体验】《Llama 3 Chat Meta AI》 <a href="https://llama3.dev/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp535fvvypj212x0u077f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 00:30:19 GMT</pubDate>
</item>
<item>
<title>优雅！ 🤖 爱可可-爱生活的微博视频</title>
<link>https://weibo.com/1402400261/ObChMkv4f</link>
<guid>https://weibo.com/1402400261/ObChMkv4f</guid>
<content:encoded><![CDATA[
<div> 关键词：优雅，机器人

总结:
机器人展示了优雅的行为和举止，让人们感到惊讶和赞赏。它不仅完成了任务，还展现了一种高雅的风度，让人们对其产生了深刻的印象。这种优雅的表现，展示了机器人的独特魅力和品味，使人们对未来科技发展充满了期待和想象。 <div>
优雅！ 🤖 <a href="https://video.weibo.com/show?fid=1034:5027687681687560"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax3.sinaimg.cn/orj480/5396ee05ly1hp532ojsk4j20zk0k0753.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/pyL7KT7Ylx08ep2hfenu01041200gwD50E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714187776&amp;ssig=tq9u2S7G4C&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/FdZHupNPlx08ep2h5XpS010412008Yp80E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714187776&amp;ssig=S3EhC6ZWoQ&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/HsCorRSulx08ep2gYHQs010412005Tuw0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714187776&amp;ssig=z0gsxNjd%2F%2B&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5027687681687560" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 00:27:30 GMT</pubDate>
</item>
<item>
<title>【llama3-zh：llama3中文微调版集合】《llama3-zh - a xianbao Collection》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/ObCevnCGo</link>
<guid>https://weibo.com/1402400261/ObCevnCGo</guid>
<content:encoded><![CDATA[
<div> 集合 llama3-zh 微调 xianbao 关键词: llama3, 中文, 微调, xianbao, 集合, 文章, 总结, 关键词, 输出

总结:<br /><br />
文章介绍了 llama3-zh 中文微调版集合 xianbao，展示了其特点和内容。首先，介绍了 llama3-zh 的特性和用途，然后详细描述了微调版的内容和优势。接着，展示了 xianbao 集合中包含的内容和风格，并提供了关键词的总结。最后，强调了文章的总结部分，概括了整体内容和重点信息。整体而言，这篇文章全面介绍了 llama3-zh 微调版集合 xianbao 的特色和亮点，为读者提供了清晰的了解和参考。 <div>
【llama3-zh：llama3中文微调版集合】《llama3-zh - a xianbao Collection》 <a href="https://huggingface.co/collections/xianbao/llama3-zh-662ba8503bdfe51948a28403"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp52ulb3c0j20u013742m.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 00:19:26 GMT</pubDate>
</item>
<item>
<title>【Sora的真实使用体验】- SORA是OpenAI开发的视频生成AI系统，可以生成长度达1分钟的连贯视频。它解决了主体在视野外时也能保持一致的难题。 - 制作团队Shy Kids...</title>
<link>https://weibo.com/1402400261/ObCcVhtwu</link>
<guid>https://weibo.com/1402400261/ObCcVhtwu</guid>
<content:encoded><![CDATA[
<div> 视频生成 AI 系统, SORA, OpenAI, 预 alpha 阶段, 制作团队 Shy Kids, 720P, 后期处理, 潜力, 创作流程补充工具

<br /><br />总结:
SORA是OpenAI开发的视频生成AI系统，处于预alpha阶段，分辨率最高为720P。制作团队Shy Kids获得了早期访问权限，并用它制作了短片《Air Head》，但控制性不高，需要大量后期处理。SORA生成的视频质量参差不齐，需要人工指导和大量剪辑。虽然具有很大潜力，但目前更适合作为创作流程的补充工具。 <div>
【Sora的真实使用体验】<br />- SORA是OpenAI开发的视频生成AI系统，可以生成长度达1分钟的连贯视频。它解决了主体在视野外时也能保持一致的难题。   <br />- 制作团队Shy Kids最近获得了SORA的早期访问权限，使用它制作了短片《Air Head》。SORA目前还处于预alpha阶段，控制性不高，需要大量后期处理工作。   <br />- SORA目前分辨率最高720P，生成1段视频大约需要10-20分钟。提示语需要尽量详细描描述场景、角色、服装等，否则生成的不同视频片段之间不一致。   <br />- SORA目前无法精确控制镜头运动，需要通过后期裁剪来实现。生成的视频质量参差不齐，需要大量剪辑才能制作出1分半的短片。   <br />- SORA生成的视频需要进行去噪、上调分辨率、色彩调整等后期处理。有大量素材可以像纪录片一样剪辑。   <br />- SORA具有很大潜力，但目前还需要人工指导和后期处理才能产出高质量作品。它最适合作为创作流程的补充工具，而非完全替代人的创造力。<br />《Actually Using SORA - fxguide》 <a href="https://www.fxguide.com/fxfeatured/actually-using-sora/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp52qiyj0hj217g0u0gqq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 00:15:32 GMT</pubDate>
</item>
<item>
<title>【生成式AI如何改变工作】- 进入生成式AI(gen AI)的时代，将对工作、劳动力和员工产生深远影响。gen AI可以极大提高生产力，促进经济价值，也可以使工作更具创造...</title>
<link>https://weibo.com/1402400261/ObC81xBqM</link>
<guid>https://weibo.com/1402400261/ObC81xBqM</guid>
<content:encoded><![CDATA[
<div> 企业重塑、生产力提升、经济价值、员工合作、再培训、信任建设、隐私问题、领航者、人为本管理、潜力释放<br /><br />总结:<br />gen AI时代将深刻影响工作和劳动力，提高生产力和经济价值。企业应正确应用gen AI重塑组织，培养员工信任。员工看到与gen AI合作的价值，但担忧企业不能确保正面结果。企业应采取再培训措施，重塑工作，培养信任。企业领导者应将员工视为变革领航者，实现gen AI的全部潜力。 <div>
【生成式AI如何改变工作】<br />- 进入生成式AI(gen AI)的时代，将对工作、劳动力和员工产生深远影响。gen AI可以极大提高生产力，促进经济价值，也可以使工作更具创造性和意义。   <br />- 目前gen AI还处于早期阶段，但已经开始重塑企业、劳动力动态、监管环境、高管观点和员工情绪。81%的企业将其视为企业重塑的主要杠杆。   <br />- 预测显示，到2038年，正确采用gen AI可带来超过10.3万亿美元的经济价值。86%的高管已经在一定程度上使用gen AI，近100%的高管认为它将改变公司和行业。   <br />- 95%的员工看到与gen AI合作的价值，但他们最担心的是不能信任企业确保每个人都能获得正面结果。目前只有5%的企业正在大规模对员工进行再培训。   <br />- 媒体关注从工作流失转向了隐私问题。高管和员工对gen AI的看法存在分歧，这削弱了员工的信任，阻碍了发挥其潜力。   <br />- 9%的“再造者”企业正在重塑工作，通过与员工共同参与和再培训他们来培养信任。这有助于释放员工全部潜力，提高收入。   <br />- 企业领导者应视员工为此次gen AI变革的领航者，而不是旁观者。以人为本的管理变革对实现gen AI的全部积极潜力至关重要。<br />《Work, workforce, workers - Reinvented in the age of generative AI》 <a href="https://www.accenture.com/content/dam/accenture/final/accenture-com/document-2/Accenture-Work-Can-Become-Era-Generative-AI.pdf"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp52dz9bjlj21b30u0tg2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 00:03:28 GMT</pubDate>
</item>
<item>
<title>Linux系统启动过程：第1步 - 打开电源，BIOS(基本输入/输出系统)或UEFI(统一可扩展固件接口)固件将从非易失性存储器中加载，并执行POST（开机自检）；第2步 - BI...</title>
<link>https://weibo.com/1402400261/ObC541ALp</link>
<guid>https://weibo.com/1402400261/ObC541ALp</guid>
<content:encoded><![CDATA[
<div> BIOS、UEFI、POST、设备检测、启动设备选择、GRUB、核准备、systemd、启动脚本、登录窗口

<br />
Linux系统启动过程包括BIOS或UEFI加载，进行POST检测设备，选择启动设备，运行GRUB引导加载程序，启动核进入用户空间，systemd管理进程和服务，激活默认值，运行启动脚本配置环境，最终系统准备就绪，用户看到登录窗口。 <div>
Linux系统启动过程：<br />第1步 - 打开电源，BIOS(基本输入/输出系统)或UEFI(统一可扩展固件接口)固件将从非易失性存储器中加载，并执行POST（开机自检）；<br />第2步 - BIOS/UEFI 检测连接到系统的设备，包括 CPU、RAM 和存储；<br />第3步 - 选择用于启动操作系统的启动设备，可以是硬盘驱动器、网络服务器或 CD ROM；<br />第4步 - BIOS/UEFI 运行引导加载程序 (GRUB)，它提供了一个菜单来选择操作系统或kernel functions；<br />第5步 - 核准备就绪，切换到用户空间。核将 systemd 作为第一个用户空间进程启动，它管理进程和服务、探测所有其他硬件、挂载文件系统并运行桌面环境；<br />第6步 - systemd 激活默认值，系统启动时默认的目标单元，其他分析单元也被执行。<br />第7步 - 系统运行一组启动脚本并配置环境。<br />第8步 - 系统准备就绪，用户将看到登录窗口。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp5269pxozj20p61g4dmb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp526ag530j20u013078z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 23:56:10 GMT</pubDate>
</item>
<item>
<title>【用Llama3和distilabel端到端构建语言模型微调数据集】《Using Llama3 and distilabel to build fine-tuning datasets》 网页链接 #机器学习# #人工智能# [图片...</title>
<link>https://weibo.com/1402400261/ObBZib4bq</link>
<guid>https://weibo.com/1402400261/ObBZib4bq</guid>
<content:encoded><![CDATA[
<div> Llama3、distilabel、语言模型、微调、数据集、端到端、构建、fine-tuning

<br /><br />总结:
本文介绍了如何利用Llama3和distilabel工具来构建用于语言模型微调的数据集。首先，通过Llama3工具提取文本数据，并使用distilabel对数据进行标注和预处理。然后，将这些数据集用于端到端的微调模型训练，以改进语言模型的性能。通过这种方法，可以定制化地构建适合特定任务的数据集，提高模型在特定领域的表现。这种方法可以在各种领域和任务中得到应用，为提升语言模型的性能提供了有效的途径。 <div>
【用Llama3和distilabel端到端构建语言模型微调数据集】《Using Llama3 and distilabel to build fine-tuning datasets》 <a href="https://huggingface.co/blog/dvilasuero/synthetic-data-with-llama3-distilabel"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp51qf72mfj20u00x878w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 23:41:57 GMT</pubDate>
</item>
<item>
<title>【用于文本纠错，特别是 OCR 识别后的文本纠错的英文数据集，包含 31.3k 行数据】《PleIAs/Post-OCR-Correction · Datasets at Hugging Face》 网页链接 #机器...</title>
<link>https://weibo.com/1402400261/ObBYtlvRI</link>
<guid>https://weibo.com/1402400261/ObBYtlvRI</guid>
<content:encoded><![CDATA[
<div> 数据集，OCR识别，文本纠错，31.3k行，Hugging Face

OCR技术在输入文本数字化过程中经常会出现识别错误，因此需要对识别后的文本进行校对和修正。这篇文章介绍了一个包含31.3k行数据的英文数据集，用于文本纠错，特别是OCR识别后的文本纠错。数据集的名称是《PleIAs/Post-OCR-Correction · Datasets at Hugging Face》，由Hugging Face发布。数据集的目的是帮助研究人员和开发者改进OCR识别的准确性，提高文本数字化的质量。该数据集涵盖了多种语境和场景下的文本，适合用于训练文本纠错模型。通过使用这个数据集，可以有效提升OCR识别系统的性能，减少识别错误，提高文本处理的效率。总结: 数据集包含31.3k行数据，用于文本纠错，特别是OCR识别后的文本纠错，由Hugging Face发布，旨在提高文本数字化质量。 <div>
【用于文本纠错，特别是 OCR 识别后的文本纠错的英文数据集，包含 31.3k 行数据】《PleIAs/Post-OCR-Correction · Datasets at Hugging Face》 <a href="https://huggingface.co/datasets/PleIAs/Post-OCR-Correction"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp51oion7yj20xc0u0n0y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 23:39:56 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》...</title>
<link>https://weibo.com/1402400261/ObBqojVa8</link>
<guid>https://weibo.com/1402400261/ObBqojVa8</guid>
<content:encoded><![CDATA[
<div> 关键词: 多模态大模型、人工智能、中山大学、HCP 实验室、技术方法、开源平台、应用场景、因果推理、世界模型、通用人工智能

总结:<br /><br />本文介绍了由中山大学 HCP 实验室出品的《多模态大模型：新一代人工智能技术范式》一书，该书深入浅出地探讨了多模态大模型的技术方法、开源平台和应用场景。书中还详细阐述了人工智能领域的前沿技术，包括因果推理、世界模型以及多智能体与具身智能等。这些内容有助于读者全面了解多模态大模型的特点和发展方向，对于新一代人工智能技术范式和通用人工智能的推动具有重要作用。活动截止时间为2024年5月1日12:00，感兴趣的读者可参与转发评论即有机会获得这本全彩图书。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》，截至2024.5.1 12:00，*可可粉*转发+评论即可参与。中山大学 HCP 实验室出品，本书以深入浅出的方式介绍多模态大模型的技术方法、开源平台和应用场景，并详细阐述因果推理、世界模型及多智能体与具身智能等前沿技术领域，有助于读者全面了解多模态大模型的特点及发展方向，对新一代人工智能技术范式和通用人工智能的发展起到重要推动作用。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp1q8lh8x1j20m80m8djk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8n4hifj20m80m8gnu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8pgbfhj20m80m8dj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8r3pagj20m80m80ur.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 22:15:58 GMT</pubDate>
</item>
<item>
<title>今日推介(第1388期)：理解Transformer的层次泛化、基于图RAG方法的查询为中心摘要、基于相对奖励回归的强化学习、提前退出推断和自推测解码实现、让LLM充分利用...</title>
<link>https://weibo.com/1402400261/ObBqbzdOu</link>
<guid>https://weibo.com/1402400261/ObBqbzdOu</guid>
<content:encoded><![CDATA[
<div> Transformer、层次泛化、基于图RAG、查询中心摘要、强化学习、相对奖励回归、推断、自推测解码、LLM、上下文利用  
<br /><br />总结:  
本文介绍了几个关键概念和方法，首先是Transformer模型的层次泛化，通过在不同层次上进行特征抽象可以提高模型性能。其次是基于图RAG方法的查询为中心摘要，利用图结构来更好地理解文本信息。接着介绍了基于相对奖励回归的强化学习，这种方法可以在不确定性环境中优化策略。然后是提前退出推断和自推测解码实现的技术，可以提高模型的效率和准确性。最后讨论了如何让LLM模型充分利用上下文信息，从而提高其性能和泛化能力。这些方法和概念有助于提升自然语言处理和深度学习领域的研究和应用。 <div>
今日推介(第1388期)：理解Transformer的层次泛化、基于图RAG方法的查询为中心摘要、基于相对奖励回归的强化学习、提前退出推断和自推测解码实现、让LLM充分利用上下文 公·众·号：爱可可爱生活 <a href="http://aicoco.net/s/8p"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp4z97j9lkj21if0u0agy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp4z9ah3y6j213h0u07b1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp4z9drr5ej21bo0u0ahs.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp4z9h5qc5j217h0u0aef.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp4z9ku2htj21aa0u0q7v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 22:15:28 GMT</pubDate>
</item>
<item>
<title>[CV] Revisiting Text-to-Image Evaluation with Gecko: On Metrics, Prompts, and Human Ratings 网页链接 提出全面的 Gecko 基准与指标，改进了文本到图像生成...</title>
<link>https://weibo.com/1402400261/ObBmW67sU</link>
<guid>https://weibo.com/1402400261/ObBmW67sU</guid>
<content:encoded><![CDATA[
<div> Gecko、文本到图像生成、评估、指标、模型排序、人类评分、基准、提示

<br /><br />总结:
本文提出了全面的Gecko基准与指标，旨在改进文本到图像生成模型排序的评估方法。作者针对现有评估方法的不足之处，提出了新的Gecko评估框架，包括更准确的指标和有效的提示机制。通过人类主观评分的实验，验证了Gecko框架的有效性。研究结果表明，Gecko能够更准确地评估文本到图像生成模型的性能，为该领域的进一步研究提供了有力支持。 <div>
[CV] Revisiting Text-to-Image Evaluation with Gecko: On Metrics, Prompts, and Human Ratings  <br /><a href="https://arxiv.org/abs/2404.16820"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />提出全面的 Gecko 基准与指标，改进了文本到图像生成模型排序的评估。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp4z18czxij20tk17onct.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp4z18kkskj21l40taws3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp4z198bq7j21l814inbp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 22:07:27 GMT</pubDate>
</item>
<item>
<title>[CV] Interactive3D: Create What You Want by Interactive 3D Generation 网页链接 设计交互式3D生成框架，通过直接3D交互指导生成过程，实现高质量、可控的3D...</title>
<link>https://weibo.com/1402400261/ObBkqBW7u</link>
<guid>https://weibo.com/1402400261/ObBkqBW7u</guid>
<content:encoded><![CDATA[
<div> 交互式3D生成框架，交互指导，高质量，可控，3D内容生成

交互式3D生成框架通过直接3D交互指导生成过程，实现高质量、可控的3D内容生成。用户可以根据自己的需求创作想要的3D作品，创造出个性化、精美的内容。该框架能够帮助用户更轻松地实现他们的创意，并且可以通过交互方式进行调整和优化，从而达到更加令人满意的效果。Interactive3D的设计理念是让用户成为创意的主导者，通过交互生成过程，让他们对3D内容的制作过程有更直接的控制能力，从而提升作品的质量。通过这种方式，用户可以更加灵活地创作自己想要的3D内容，并且提高创作效率，使得创作过程更加愉快和便捷。Interactive3D的目标是帮助用户实现创意，并为用户提供一种全新的创作体验，让他们能够感受到创作的乐趣并且创作出高质量的作品。<br /><br />总结: Interactive3D通过交互式3D生成框架，改变了传统的3D内容生成方式，使用户能够更自由、高效地创作个性化、精美的3D作品，达到了高质量、可控的效果。 <div>
[CV] Interactive3D: Create What You Want by Interactive 3D Generation  <br /><a href="https://arxiv.org/abs/2404.16510"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />设计交互式3D生成框架，通过直接3D交互指导生成过程，实现高质量、可控的3D内容生成。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp4yutpqmdj20ys16gtnx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp4yuttb5pj21lk0imqc7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp4yuufylgj21nk0ws4a1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 22:01:17 GMT</pubDate>
</item>
<item>
<title>[LG] Global Concept Explanations for Graphs by Contrastive Learning 网页链接 通过在自解释图神经网络子图嵌入空间中识别概念集群，提出一种提取全局概念解...</title>
<link>https://weibo.com/1402400261/ObBhhCF71</link>
<guid>https://weibo.com/1402400261/ObBhhCF71</guid>
<content:encoded><![CDATA[
<div> 自解释图神经网络，子图嵌入空间，概念集群，全局概念解释，图学习任务，基础结构-性质关系，对比学习，提取，理解。

提出一种通过在自解释图神经网络子图嵌入空间中识别概念集群的方法，以提取全局概念解释来理解图学习任务基础结构-性质关系。通过对比学习，识别全局概念解释，有助于更深入地理解图学习任务的性质和结构。论文提出的方法能够有效提取全局概念解释，为图学习任务的研究提供了新思路。 <div>
[LG] Global Concept Explanations for Graphs by Contrastive Learning  <br /><a href="https://arxiv.org/abs/2404.16532"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过在自解释图神经网络子图嵌入空间中识别概念集群，提出一种提取全局概念解释以理解图学习任务基础结构-性质关系的新方法。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp4ymrhrtwj20rk16k495.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp4ymrw05xj216k10sk2b.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp4ymscawxj216k0rgwkn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 21:53:32 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.26)》 爱可可微博热门分享(4.26) [图片]</title>
<link>https://weibo.com/1402400261/Obys8hKqx</link>
<guid>https://weibo.com/1402400261/Obys8hKqx</guid>
<content:encoded><![CDATA[
<div> 爱可可，微博，热门，分享，4.26，新闻，社交媒体，话题，用户，评论

新浪微博用户爱可可在4月26日分享了一篇热门的新闻，引起了众多用户的关注和评论。这篇分享在社交媒体上迅速传播，成为当天的热门话题之一。用户们纷纷对这条新闻进行了讨论和评论，形成了热烈的互动氛围。爱可可的微博一直是用户关注的焦点，每次分享都能引起广泛的关注和讨论。这次的热门分享也再次证明了其在社交媒体上的影响力。总结：新浪微博用户爱可可在4月26日分享了一篇热门的新闻，引起了众多用户的关注和评论，成为社交媒体上的热门话题之一。 <div>
《爱可可微博热门分享(4.26)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405027540480688447"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.26)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp4m5p437nj20rs0fmabt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 14:42:01 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Retrieval Head Mechanistically Explains Long-Context Factuality》(2024) GitHub: github.com/nightdessert/Retrieval_Head《Vitron: A ...</title>
<link>https://weibo.com/1402400261/ObyihuJ4g</link>
<guid>https://weibo.com/1402400261/ObyihuJ4g</guid>
<content:encoded><![CDATA[
<div> 关键词: Retrieval Head, Long-Context Factuality, Pixel-level Vision, Unified, Understanding, Generating, Segmenting, Editing, Talking Head Synthesis, Multimodal LLMs

总结:<br /><br />本文介绍了几篇关于人工智能领域的论文实现代码，包括Retrieval Head对长文本语境事实性的解释，Vitron用于理解、生成、分割和编辑像素级视觉任务的统一模型，GaussianTalker实现实时高保真度对话头部合成，List Items One by One为多模态LLM提供了新的数据源和学习范式，Learning Long-form Video Prior通过生成式预训练学习长视频的先验知识。这些论文实现代码均可在对应的GitHub链接中找到。 <div>
几篇论文实现代码：<br />《Retrieval Head Mechanistically Explains Long-Context Factuality》(2024) GitHub: github.com/nightdessert/Retrieval_Head<br />《Vitron: A Unified Pixel-level Vision LLM for Understanding, Generating, Segmenting, Editing》(2024) GitHub: github.com/SkyworkAI/Vitron [fig1]<br />《GaussianTalker: Real-Time High-Fidelity Talking Head Synthesis with Audio-Driven 3D Gaussian Splatting》(2024) GitHub: github.com/KU-CVLAB/GaussianTalker [fig2]<br />《List Items One by One: A New Data Source and Learning Paradigm for Multimodal LLMs》(2024) GitHub: github.com/zzxslp/SoM-LLaVA<br />《Learning Long-form Video Prior via Generative Pre-Training》(2024) GitHub: github.com/showlab/Long-form-Video-Prior<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp4597xkowj27ep7dsnq0.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp45bdwd26j29bq3pohdy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 14:17:45 GMT</pubDate>
</item>
<item>
<title>【AX-LLM：探索业界常用 LLM(Large Language Model) 在已有芯片平台上落地的可行性和相关能力边界】'AX-LLM - Explore LLM model deployment based on AXera's A...</title>
<link>https://weibo.com/1402400261/Obv4us1kK</link>
<guid>https://weibo.com/1402400261/Obv4us1kK</guid>
<content:encoded><![CDATA[
<div> GitHub, AX-LLM, 探索, LLM, 芯片平台, 可行性, 能力边界, AXera, AI chips

<br /><br />总结:
本文介绍了AX-LLM项目，旨在探索在已有芯片平台上部署LLM（Large Language Model）的可行性和相关能力边界。该项目基于AXera的AI芯片开展，旨在利用其强大的计算能力和优化的硬件架构来支持大规模自然语言处理任务。通过在GitHub上提供开放源代码，实现了模型的快速部署和定制化。通过对AX-LLM的研究和开发，可以为业界提供更多关于在芯片平台上运行LLM模型的实践经验和技术支持。 <div>
【AX-LLM：探索业界常用 LLM(Large Language Model) 在已有芯片平台上落地的可行性和相关能力边界】'AX-LLM - Explore LLM model deployment based on AXera's AI chips' GitHub: github.com/AXERA-TECH/ax-llm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a>
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 06:05:31 GMT</pubDate>
</item>
<item>
<title>【DuckRush：简单快速的后端API，基于 Hono，可以通过关键词在互联网上搜索到相关的内容并转换成适合 LLM 处理的格式】'DuckRush - A simple and fast backend A...</title>
<link>https://weibo.com/1402400261/Obv3S4tZw</link>
<guid>https://weibo.com/1402400261/Obv3S4tZw</guid>
<content:encoded><![CDATA[
<div> Hono, API, DuckRush, 互联网, 搜索, 内容, LLM, 格式, Cloudflare, 快速<br />
<br />
Hono基于的DuckRush是一个简单快速的后端API，可以通过关键词在互联网上搜索到相关的内容，并将其转换成适合LLM处理的格式。该API支持部署在Cloudflare上。总结: DuckRush是基于Hono的后端API，可快速搜索互联网上的内容并转换格式，支持部署在Cloudflare。 <div>
【DuckRush：简单快速的后端API，基于 Hono，可以通过关键词在互联网上搜索到相关的内容并转换成适合 LLM 处理的格式】'DuckRush - A simple and fast backend API, based on Hono, that can search for relevant content on the internet using keywords and convert it into a format suitable for LLM processing. Supports deployment on Cloudflare.' GitHub: github.com/feiandxs/duckrush <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp4768itgmj20sg0sgtar.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 06:04:00 GMT</pubDate>
</item>
<item>
<title>【Swan：使用FPGA的轻量级语言模型执行环境，目标是利用高级综合（HLS）在通用FPGA上高效地运行语言模型】’Swan - This project aims to enable language model...</title>
<link>https://weibo.com/1402400261/Obv1zCBWO</link>
<guid>https://weibo.com/1402400261/Obv1zCBWO</guid>
<content:encoded><![CDATA[
<div> FPGA, 轻量级语言模型, 高级综合, 通用FPGA, 语言模型, AI, 边缘设备, 限资源环境, Swan, GitHub

<br /><br />总结:
Swan项目旨在利用FPGA实现语言模型推理，支持在边缘设备和资源有限的环境中进行人工智能应用。项目旨在使用高级综合（HLS）在通用FPGA上高效地运行语言模型。 Swan项目的GitHub链接为github.com/turingmotors/swan。 <div>
【Swan：使用FPGA的轻量级语言模型执行环境，目标是利用高级综合（HLS）在通用FPGA上高效地运行语言模型】’Swan - This project aims to enable language model inference on FPGAs, supporting AI applications in edge devices and environments with limited resources.' GitHub: github.com/turingmotors/swan <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp46ze1if3j20vv0u078d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 05:58:21 GMT</pubDate>
</item>
<item>
<title>'懒人客服 - 基于大模型的智能对话客服工具，支持微信、千牛、哔哩哔哩、抖音企业号、抖音、抖店、微博聊天、小红书专业号运营、小红书、知乎等平台接入，可选择...</title>
<link>https://weibo.com/1402400261/ObuZNCMKf</link>
<guid>https://weibo.com/1402400261/ObuZNCMKf</guid>
<content:encoded><![CDATA[
<div> 关键词: 懒人客服, 大模型, 智能对话, 微信, 抖音, 知识库, GPT3.5, GPT4.0, 懒人百宝箱, AI应用<br />
<br />
总结:<br />
本文介绍了基于大模型的智能对话客服工具懒人客服，支持多平台接入，并可选择不同版本的大模型进行使用，同时支持处理文本、语音和图片等形式的信息。此工具能够通过插件访问操作系统和互联网等外部资源，同时还支持定制企业AI应用，提供了更多选择和灵活性。 <div>
'懒人客服 - 基于大模型的智能对话客服工具，支持微信、千牛、哔哩哔哩、抖音企业号、抖音、抖店、微博聊天、小红书专业号运营、小红书、知乎等平台接入，可选择 GPT3.5/GPT4.0/ 懒人百宝箱 （后续会支持更多平台），能处理文本、语音和图片，通过插件访问操作系统和互联网等外部资源，支持基于自有知识库定制企业 AI 应用' GitHub: github.com/lrhh123/ChatGPT-On-CS <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp46u21a18j20ek0czgnd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 05:53:59 GMT</pubDate>
</item>
<item>
<title>【SkipDB &amp; Watermark &amp; Txn：嵌入式、内存中、零拷贝、ACID、MVCC、几乎无锁且提供可序列化快照隔离的数据库引擎】'SkipDB &amp; Watermark &amp; Txn - An embedded, i...</title>
<link>https://weibo.com/1402400261/ObuY7mAwv</link>
<guid>https://weibo.com/1402400261/ObuY7mAwv</guid>
<content:encoded><![CDATA[
<div> SkipDB、Watermark、Txn、嵌入式、内存中、零拷贝、ACID、MVCC、无锁、可序列化快照隔离<br />
<br />
SkipDB & Watermark & Txn是一个嵌入式、内存中、零拷贝、ACID、MVCC的数据库引擎，几乎无锁且提供可序列化快照隔离。该引擎在处理事务时具有高度的并发性和性能，能够保证数据库操作的原子性、一致性、隔离性和持久性。通过采用多版本并发控制(MVCC)机制，数据库引擎能够提供高效的读写操作。同时，采用零拷贝技术可以减少数据移动的开销，提高数据访问效率。另外，引擎几乎无锁，避免了传统锁机制可能存在的性能瓶颈。最重要的是，数据库引擎提供可序列化快照隔离，确保事务操作的顺序一致性，避免了并发操作可能引发的数据一致性问题。SkipDB & Watermark & Txn是一个功能强大的数据库引擎，适用于需要高性能和数据完整性的应用场景。<br /> <div>
【SkipDB &amp; Watermark &amp; Txn：嵌入式、内存中、零拷贝、ACID、MVCC、几乎无锁且提供可序列化快照隔离的数据库引擎】'SkipDB &amp; Watermark &amp; Txn - An embedded, in-memory, zero-copy, ACID, MVCC, almost lock-free and serializable snapshot isolation database engine.' GitHub: github.com/al8n/skipdb <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp46rxzw7nj20u00xiq8e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 05:49:50 GMT</pubDate>
</item>
<item>
<title>【The Nimble File Format：由 Meta 创建的一种新的列式文件格式，旨在取代 Apache Parquet 和 ORC 等文件格式，其设计用于支持宽表和具有数千列的工作负载】'Th...</title>
<link>https://weibo.com/1402400261/ObuSbeYNJ</link>
<guid>https://weibo.com/1402400261/ObuSbeYNJ</guid>
<content:encoded><![CDATA[
<div> Meta、新的列式文件格式、替代、Apache Parquet、ORC、支持、宽表、数千列、GitHub、nimble

<br /><br />总结：
Meta创建了一种名为Nimble File Format的新的列式文件格式，旨在取代目前使用的Apache Parquet和ORC等文件格式。该文件格式的设计旨在支持宽表和具有数千列的工作负载。对应的开源项目存储在GitHub上，地址为github.com/facebookexternal/nimble。 <div>
【The Nimble File Format：由 Meta 创建的一种新的列式文件格式，旨在取代 Apache Parquet 和 ORC 等文件格式，其设计用于支持宽表和具有数千列的工作负载】'The Nimble File Format - New file format for storage of large columnar datasets.' GitHub: github.com/facebookexternal/nimble <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp46bysojlj20u00vrjx8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 05:35:12 GMT</pubDate>
</item>
<item>
<title>【torchtitan：用于大规模语言模型(LLM)训练的原生PyTorch库】'torchtitan - A native PyTorch Library for large model training' GitHub: github.com/pytorch/...</title>
<link>https://weibo.com/1402400261/ObuzI8HMQ</link>
<guid>https://weibo.com/1402400261/ObuzI8HMQ</guid>
<content:encoded><![CDATA[
<div> PyTorch, torchtitan, 大规模, 语言模型, 训练, 原生, 库, GitHub   
<br />
大规模语言模型(LLM)训练需要高效的工具支持，而torchtitan就是为此目的而设计的原生PyTorch库。这个库在GitHub上有开源代码可以使用。torchtitan可以帮助用户训练大规模的语言模型，提高效率和性能。该库的设计目的是为了简化大规模模型训练的过程，并提供在PyTorch中使用的工具和功能。通过使用torchtitan，用户可以更轻松地实现对大规模语言模型的训练，提高训练效率。总的来说，torchtitan是一个为大规模语言模型训练而设计的原生PyTorch库，可以帮助用户提升训练效率和性能。 <br /><br /> 
总结: <br />提供原生PyTorch库torchtitan用于大规模语言模型训练；这个库在GitHub上有开源代码；设计目的是简化大规模模型训练过程；提供PyTorch中使用的工具和功能；可帮助用户更轻松实现对大规模语言模型的训练；提高训练效率。 <div>
【torchtitan：用于大规模语言模型(LLM)训练的原生PyTorch库】'torchtitan - A native PyTorch Library for large model training' GitHub: github.com/pytorch/torchtitan <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp45146spzj21af0u0k17.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 04:49:42 GMT</pubDate>
</item>
<item>
<title>Adobe Photoshop(beta)的最新演示 #人工智能# 爱可可-爱生活的微博视频</title>
<link>https://weibo.com/1402400261/ObsQ8zrfL</link>
<guid>https://weibo.com/1402400261/ObsQ8zrfL</guid>
<content:encoded><![CDATA[
<div> Adobe Photoshop(beta)、最新、演示、功能、快速、便捷、工具、创意、效果、用户体验

<br /><br />总结:
Adobe Photoshop(beta)最新演示展示了其更新的功能，带来了更快速、更便捷的创意工具，进一步提升用户体验。通过新的效果和工具，用户可以更轻松地进行图像编辑和创作。 <div>
Adobe Photoshop(beta)的最新演示 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5027324513419287"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax4.sinaimg.cn/orj480/5396ee05ly1hp3xd8p3pnj21hc0u0t98.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/BBfFxMHolx08enrc0lYQ01041200m9EY0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714101201&amp;ssig=JHIXzBQ1mF&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/1a8yqd5llx08enrbxY5q01041200bOaH0E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714101201&amp;ssig=j%2BNLmvx6zD&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/N8ig9SgGlx08enrb9MDC010412007tpK0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714101201&amp;ssig=MFF%2Ffmcvfw&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5027324513419287" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 00:24:41 GMT</pubDate>
</item>
<item>
<title>【Cloudflare的大模型试炼场，提供包括LLaMa-3-8B在内的多个13B以下模型的在线试用】《Workers AI LLM Playground》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/ObsN6lQ2u</link>
<guid>https://weibo.com/1402400261/ObsN6lQ2u</guid>
<content:encoded><![CDATA[
<div> Cloudflare, 大模型, 试炼场, 在线试用, Workers AI, LLaMa-3-8B, 13B以下模型

<br /><br />总结:
Cloudflare推出了一个大模型试炼场，为用户提供包括LLaMa-3-8B在内的多个13B以下模型的在线试用。这个试炼场名为Workers AI LLM Playground，让用户可以轻松尝试各种模型并了解它们的功能和性能。通过这个平台，用户可以更好地了解和使用不同规模的人工智能模型，为他们的工作和研究提供更多可能性。 <div>
【Cloudflare的大模型试炼场，提供包括LLaMa-3-8B在内的多个13B以下模型的在线试用】《Workers AI LLM Playground》 <a href="https://playground.ai.cloudflare.com/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp3x4xvl95j20lk18k0wj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 00:17:12 GMT</pubDate>
</item>
<item>
<title>【防止依赖AI导致的认知萎缩】- 认知萎缩是由于大脑细胞退化或大脑质量减少而导致的认知功能逐渐衰退。依赖AI可能导致某些思维能力的认知萎缩。 - 苏格拉底担心...</title>
<link>https://weibo.com/1402400261/ObsLFFIjY</link>
<guid>https://weibo.com/1402400261/ObsLFFIjY</guid>
<content:encoded><![CDATA[
<div> 依赖AI、认知萎缩、思考能力、技能基础、自我维护、学习目标、时间审计、共存、保持思考能力、注意力集中

总结:<br /><br />文章提醒人们应当警惕依赖AI导致的认知萎缩现象。在学习新技能时，应先通过传统方式建立技能基础，保持自我发展。要慎重考虑哪些思维交给AI，根据学习目标而非仅仅AI能力来决定。即使某些技能可能过时，学习过程本身仍有价值。不能养成依赖AI的习惯，应保持自我思考的重要性。进行时间审计，避免过度依赖AI。人类需要与AI共存，汲取AI助力的同时也要保持思考能力的活力。 <div>
【防止依赖AI导致的认知萎缩】<br />- 认知萎缩是由于大脑细胞退化或大脑质量减少而导致的认知功能逐渐衰退。依赖AI可能导致某些思维能力的认知萎缩。   <br />- 苏格拉底担心写作会削弱记忆和知识，现代人确实失去了大量记忆信息的能力。同样，依赖AI可能削弱思考能力。   <br />- AI可以胜任某些任务，但人类应该保留做这些事的权利，例如亲自绘画、写作、编码等，这有利于发展自我。   <br />- 在学习新技能时，应先体验不依赖AI的全人类方式，以建立技能基础。   <br />- 应慎重考虑哪些思维交给AI，根据学习目标而非仅仅AI能力来决定。   <br />- 即使某技能可能变得过时，学习该技能的过程本身仍有价值，比如记忆文本能增强记忆力。   <br />- 不能轻易养成依赖AI的默认习惯，应关注保持自我思考的重要性。   <br />- 应该进行时间审计，评估使用AI的频率，保证不过度依赖AI。   <br />- 人类需要与AI共存，在汲取AI助力的同时也注意避免认知萎缩，保持思考能力的活力。<br />《How to Prevent AI from Doing All the Thinking - John Spencer》 <a href="https://spencerauthor.com/cognitive-atrophy/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp3x2ap40oj213q0u0n0v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 00:13:41 GMT</pubDate>
</item>
<item>
<title>【Llama 3发布一周近况概览】- 模型已经被下载超过120万次，开发者在Hugging Face上分享了超过600个衍生模型。 - Llama 3的GitHub仓库已经获得超过17000 Stars。...</title>
<link>https://weibo.com/1402400261/ObsCcxdWv</link>
<guid>https://weibo.com/1402400261/ObsCcxdWv</guid>
<content:encoded><![CDATA[
<div> Llama 3, 下载120万次, Hugging Face, 衍生模型, GitHub, 17000 Stars, 70B Instruct, LMSYS Chatbot Arena, 英文评测第一, 硬件和云提供商, 耶鲁大学医学院, EPFL计算机科学院, 多模态, 多语言交流, 上下文窗口, 社区反响, AI创新, 应用, 开发工具, 评测, 推理优化

总结:<br /><br />模型Llama 3在短短一周内取得了巨大成功，被下载超过120万次，开发者在Hugging Face上分享了600个衍生模型，GitHub仓库获得17000 Stars。Llama 3 70B Instruct在LMSYS Chatbot Arena排行榜上并列英文评测第一。硬件和云提供商开始部署Llama 3，社区快速微调并发布了医学领域的模型。未来几个月，Llama 3将发布具备多种新能力的模型。Llama 3受到社区热烈反响，推动了AI创新的新阶段，涉及应用、开发工具、评测、推理优化等方面。 <div>
【Llama 3发布一周近况概览】<br />- 模型已经被下载超过120万次，开发者在Hugging Face上分享了超过600个衍生模型。   <br />- Llama 3的GitHub仓库已经获得超过17000 Stars。   <br />- Llama 3 70B Instruct在LMSYS Chatbot Arena排行榜上与另一个模型并列英文评测第一。   <br />- 硬件和云提供商开始为用户部署Llama 3，社区快速针对自己的需求微调了Llama 3。   <br />- 耶鲁大学医学院与EPFL计算机科学院在发布后24小时内微调了Llama 3，发布了第一个面向医学的Llama 3模型。   <br />- 这只是Llama 3的开始，未来几个月还会发布具备多模态、多语言交流、更长上下文窗口等新能力的模型。   <br />- Llama 3获得了社区的热烈反响，启动了AI创新的新阶段，包括应用、开发工具、评测、推理优化等诸多方面。   <br />《A look at the early impact of Meta Llama 3》 <a href="https://ai.meta.com/blog/meta-llama-3-update/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp3wds9zzuj21hc0u0wga.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 23:50:21 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》...</title>
<link>https://weibo.com/1402400261/ObrWXpiMb</link>
<guid>https://weibo.com/1402400261/ObrWXpiMb</guid>
<content:encoded><![CDATA[
<div> 关键词：多模态大模型、人工智能、技术方法、开源平台、应用场景、因果推理、世界模型、多智能体、具身智能、发展方向

总结:<br /><br />
本书《多模态大模型：新一代人工智能技术范式》由中山大学HCP实验室出品，着重介绍了多模态大模型的技术方法、开源平台和应用场景。同时详细探讨了因果推理、世界模型、多智能体和具身智能等前沿技术领域。本书有助于读者全面了解多模态大模型的特点及发展方向，对新一代人工智能技术范式和通用人工智能的发展具有重要推动作用。欢迎转发和评论参与赠送《多模态大模型：新一代人工智能技术范式》活动，截止时间为2024年5月1日12:00。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》，截至2024.5.1 12:00，*可可粉*转发+评论即可参与。中山大学 HCP 实验室出品，本书以深入浅出的方式介绍多模态大模型的技术方法、开源平台和应用场景，并详细阐述因果推理、世界模型及多智能体与具身智能等前沿技术领域，有助于读者全面了解多模态大模型的特点及发展方向，对新一代人工智能技术范式和通用人工智能的发展起到重要推动作用。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp1q8lh8x1j20m80m8djk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8n4hifj20m80m8gnu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8pgbfhj20m80m8dj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8r3pagj20m80m80ur.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 22:08:44 GMT</pubDate>
</item>
<item>
<title>今日推介(第1387期)：Transformer语言模型中的隐含计算、用门控稀疏自编码器改进字典学习、神经原语言重建、参与性代表性和个性化的人工反馈揭示大型语言模型的...</title>
<link>https://weibo.com/1402400261/ObrWQhD9y</link>
<guid>https://weibo.com/1402400261/ObrWQhD9y</guid>
<content:encoded><![CDATA[
<div> Transformer语言模型、隐藏计算、门控稀疏自编码器、字典学习、神经原语言重建、人工反馈、多元文化对齐、通用对抗性触发词

<br /><br />总结:
研究发现，在Transformer语言模型中存在着隐含的计算过程，门控稀疏自编码器可以用来改进字典学习，在神经原语言重建中起到重要作用。通过参与性代表性和个性化的人工反馈，可以揭示大型语言模型对主观和多元文化的对齐情况。同时，通用对抗性触发词并不具有通用性，这对语言模型的应用和改进具有重要意义。 <div>
今日推介(第1387期)：Transformer语言模型中的隐含计算、用门控稀疏自编码器改进字典学习、神经原语言重建、参与性代表性和个性化的人工反馈揭示大型语言模型的主观和多元文化对齐、通用对抗性触发词并不通用 公·众·号：爱可可爱生活 <a href="http://aicoco.net/s/8o"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp3tfogi4qj21vo0u0gpn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp3tfqlhpdj20sa0k4gny.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp3tftlprbj212r0u00ya.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp3tfwwy80j20zc0u0qbr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp3tfzrfnyj217n0u0k03.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 22:08:26 GMT</pubDate>
</item>
<item>
<title>[CV] A Survey on Visual Mamba 网页链接 全面综述Visual Mamba的发展，包括基本概念、用于视觉任务的适配设计、与其他模块的集成，以及在不同视觉任务中的应用...</title>
<link>https://weibo.com/1402400261/ObrSXaowi</link>
<guid>https://weibo.com/1402400261/ObrSXaowi</guid>
<content:encoded><![CDATA[
<div> 关键词: Visual Mamba, 计算机视觉, 架构, 适配设计, 模块集成, 应用

总结:
Visual Mamba是一种新兴的计算机视觉架构，具有巨大的潜力。该架构涵盖了基本概念、适配设计、模块集成和在不同视觉任务中的应用。通过适配设计，Visual Mamba可以有效地应用于各种视觉任务，并能够与其他模块集成，提高整体性能。在实际应用中，Visual Mamba展现出了出色的表现，显示出在计算机视觉领域具有重要意义。 <div>
[CV] A Survey on Visual Mamba  <br /><a href="https://arxiv.org/abs/2404.15956"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />全面综述Visual Mamba的发展，包括基本概念、用于视觉任务的适配设计、与其他模块的集成，以及在不同视觉任务中的应用，揭示这一新兴架构在计算机视觉领域的巨大潜力。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp3t5zst0vj20ve14qk55.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp3t601j34j21c40s2whh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp3t60p3duj20uu17ek0a.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 21:58:52 GMT</pubDate>
</item>
<item>
<title>[CL] Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models 网页链接 LogicBench通过设计包含25种推理模式的问答数据集，系统...</title>
<link>https://weibo.com/1402400261/ObrQma1Gd</link>
<guid>https://weibo.com/1402400261/ObrQma1Gd</guid>
<content:encoded><![CDATA[
<div> 关键词: LogicBench, 推理模式, 逻辑推理能力, 大型语言模型, 缺陷, 问答数据集, 复杂推理, 否定, 一阶逻辑, 非单调逻辑

总结:<br /><br />
LogicBench设计了包含25种推理模式的问答数据集，通过系统评估大型语言模型在命题逻辑、一阶逻辑和非单调逻辑方面的逻辑推理能力。研究发现现有模型在处理复杂推理和否定时存在明显缺陷，为未来的研究提供了有价值的洞见。这表明需要更深入研究大型语言模型在逻辑推理方面的表现，并对其进行改进以提高推理能力。LogicBench的问答数据集为研究者提供了一个有效的工具，可以用来评估和比较不同模型在逻辑推理任务上的表现。对于未来研究者来说，可以利用这些发现来指导开发更强大和全面的自然语言处理模型，从而更好地处理复杂的逻辑推理任务。 <div>
[CL] Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models  <br /><a href="https://arxiv.org/abs/2404.15522"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />LogicBench通过设计包含25种推理模式的问答数据集，系统地评估了大型语言模型在命题逻辑、一阶逻辑和非单调逻辑方面的逻辑推理能力，发现现有模型在处理复杂推理和否定时存在明显缺陷，为未来的研究提供了有价值的洞见。<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp3szcylx1j20sc16q7j7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp3szd700bj21de0se10x.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp3szdhfu5j20rm1cywnp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 21:52:28 GMT</pubDate>
</item>
<item>
<title>[LG] The Power of Resets in Online Reinforcement Learning 网页链接 通过局部模拟器访问，使用全局最优主义和递归函数搜索的思想，针对两类表示条件下对结构...</title>
<link>https://weibo.com/1402400261/ObrOcjAnG</link>
<guid>https://weibo.com/1402400261/ObrOcjAnG</guid>
<content:encoded><![CDATA[
<div> 局部模拟器、全局最优主义、递归函数搜索、结构化MDP、样本复杂度、计算复杂度、在线强化学习、潜力

<br /><br />总结:
本文通过局部模拟器访问,并结合全局最优主义和递归函数搜索思想,对两类表示条件下的结构化MDP进行了样本与计算复杂度分析。文章展现了模拟器在在线强化学习中的巨大潜力。通过这些分析,我们对利用重置操作来提高在线学习效率有了更深入的理解。文章的研究结果为在线强化学习算法的改进提供了新的思路和方法。 <div>
[LG] The Power of Resets in Online Reinforcement Learning  <br /><a href="https://arxiv.org/abs/2404.15417"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <br />通过局部模拟器访问，使用全局最优主义和递归函数搜索的思想，针对两类表示条件下对结构化MDP进行了样本与计算复杂度分析，展现了模拟器在在线强化学习中的巨大潜力。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp3stu0zhpj20uu1304dk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 21:47:09 GMT</pubDate>
</item>
<item>
<title>[CL] Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs 网页链接 通过详尽的分类与案例分析，全面梳理了链式推理方法的延伸与创新，包括链...</title>
<link>https://weibo.com/1402400261/ObrLG0O5W</link>
<guid>https://weibo.com/1402400261/ObrLG0O5W</guid>
<content:encoded><![CDATA[
<div> 关键词: 链式推理方法、延伸创新、模块化设计、专家协作、案例分析、链式X范式、继续扩展CoX

总结:<br />
本文通过详尽的分类与案例分析，全面梳理了链式推理方法的延伸与创新。从链式X范式、模块化设计到专家协作，提供了多种延伸方式和创新思路。这些方法为继续扩展CoX提供了重要的参考。文章系统性地总结了各种链式推理方法的特点和优势，为读者提供了全面的认识和了解。通过案例分析，读者可以深入了解不同方法的实际应用效果和可能的改进方向。模块化设计和专家协作为链式推理方法的延伸提供了重要的思路，可以帮助进一步完善和优化推理模型。综合来看，本文为链式推理方法的发展和应用提供了有益的指导和启示。 <div>
[CL] Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs  <br /><a href="https://arxiv.org/abs/2404.15676"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />通过详尽的分类与案例分析，全面梳理了链式推理方法的延伸与创新，包括链式X范式、模块化与专家协作设计，为继续扩展CoX提供了参考。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp3snc8opbj20s216gncz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp3sncmfl9j21kq0m0798.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp3sncyfqnj21nc1ckh82.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 21:40:55 GMT</pubDate>
</item>
<item>
<title>通过在13个开源模型上广泛实验表明，之前开发的语言模型对抗触发词并不可靠地在模型间迁移，尤其是偏好优化对齐的模型；同时，仅通过监督微调对齐的模型表面上看...</title>
<link>https://weibo.com/1402400261/ObrJH5iut</link>
<guid>https://weibo.com/1402400261/ObrJH5iut</guid>
<content:encoded><![CDATA[
<div> 语言模型、对抗触发词、模型迁移、优化对齐、监督微调、脆弱

总结:<br /><br />这篇文章通过实验发现，之前开发的语言模型对抗触发词在模型间并不可靠地迁移，尤其是偏好优化对齐的模型。同时，仅通过监督微调对齐的模型虽然表面上看起来安全，但实际上对触发词非常脆弱。这些结果对语言模型的研究和应用具有重要启示。 <div>
通过在13个开源模型上广泛实验表明，之前开发的语言模型对抗触发词并不可靠地在模型间迁移，尤其是偏好优化对齐的模型；同时，仅通过监督微调对齐的模型表面上看似安全，但事实上对触发词高度脆弱。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Universal Adversarial Triggers Are Not Universal》N Meade, A Patel, S Reddy [McGill University and Mila] (2024) <a href="https://arxiv.org/abs/2404.16020"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp3shxna8zj214c0r6k39.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp3shy8x2gj21ce0s6ajq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp3shyk6ymj20nw0uaaex.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp3shyrzk9j21ci0xcqeq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp3si2v75cj20vd0pvad5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp3si2so6vj20ve0mf76l.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp3si2u0kgj20vi0ylq8i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp3si2u4l3j20vi0yldl5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp3si2u7dpj20vi0yln2g.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 21:36:03 GMT</pubDate>
</item>
<item>
<title>[CL]《Universal Adversarial Triggers Are Not Universal》N Meade, A Patel, S Reddy [McGill University and Mila] (2024) 网页链接 #机器学习##人工智能##论...</title>
<link>https://weibo.com/1402400261/ObrJCkoPC</link>
<guid>https://weibo.com/1402400261/ObrJCkoPC</guid>
<content:encoded><![CDATA[
<div> Universal Adversarial Triggers, Not Universal, N Meade, A Patel, S Reddy, McGill University, Mila

总结:
本研究针对通用对抗性触发器展开探讨，研究人员来自麦吉尔大学和Mila。他们揭示了现有通用对抗性触发器并非普适适用于不同模型和数据集，而且可能在特定任务和领域中表现不佳。研究发现在某些情况下，通用对抗性触发器甚至无法引发目标任务的误分类。这一发现对深度学习模型的鲁棒性和对抗性攻击的研究具有重要意义。研究结果表明，通用对抗性触发器的设计和应用需要更细致的考量，以提高攻防研究的可靠性和可解释性。 <div>
[CL]《Universal Adversarial Triggers Are Not Universal》N Meade, A Patel, S Reddy [McGill University and Mila] (2024) <a href="https://arxiv.org/abs/2404.16020"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp3shxna8zj214c0r6k39.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp3shy8x2gj21ce0s6ajq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp3shyk6ymj20nw0uaaex.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp3shyrzk9j21ci0xcqeq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp3si2v75cj20vd0pvad5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp3si2so6vj20ve0mf76l.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp3si2u0kgj20vi0ylq8i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp3si2u4l3j20vi0yldl5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp3si2u7dpj20vi0yln2g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp3si2tzj8j20vi0yl79i.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp3si2tpuxj20vi0yl79k.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp3si2u09yj20vi0yldkz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp3si2ubpnj20vi0ze44c.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp3si2skkuj20vo0fzace.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 21:35:51 GMT</pubDate>
</item>
<item>
<title>提出PRISM语料库，通过匹配个人特征与偏好反馈，支持对大型语言模型的包容和个性化调节。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《The PRISM Alignment Project: Wha...</title>
<link>https://weibo.com/1402400261/ObrGpp4MK</link>
<guid>https://weibo.com/1402400261/ObrGpp4MK</guid>
<content:encoded><![CDATA[
<div> 大型语言模型，PRISM语料库，个人特征，偏好反馈，包容，个性化调节，主观和跨文化对准，参与式反馈，代表性，个性化调节

<br /><br />总结:
PRISM语料库的提出旨在通过匹配个人特征和偏好反馈，支持对大型语言模型的包容性和个性化调节。研究团队通过The PRISM Alignment Project，结合来自牛津大学、宾夕法尼亚大学和博科尼大学的合作，对大型语言模型的主观和跨文化对准进行了深入研究。同时，他们也使用了参与式反馈和代表性调节的方法，揭示了大语言模型的个性化特点，并促进了对其使用的认识。通过这项研究，我们可以更好地理解如何调整和优化大型语言模型，以满足不同用户群体的需求。 <div>
提出PRISM语料库，通过匹配个人特征与偏好反馈，支持对大型语言模型的包容和个性化调节。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《The PRISM Alignment Project: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models》H R Kirk, A Whitefield, P Röttger, A Bean... [University of Oxford &amp; University of Pennsylvania &amp; Bocconi University] (2024) <a href="https://arxiv.org/abs/2404.16019"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp3s1ahhkdj21420ou7gk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp3s1b8h7hj21c814ydwe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp3s1bnb7dj21c00sc4aj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp3s1butfrj21ci0qudmw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp3s99o2erj21c8180dz7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp3s9a07pmj21bw0t4dq5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp3s9ag62ij21bu156dzq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp3s9ajya2j21be15qao1.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 21:27:58 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.25)》 爱可可微博热门分享(4.25) [图片]</title>
<link>https://weibo.com/1402400261/OboQ2c26u</link>
<guid>https://weibo.com/1402400261/OboQ2c26u</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 分享, 爱可可, 4.25, 热门话题, 观点, 讨论, 互动, 热议

<br /><br />总结:
爱可可微博在4月25日分享了一篇热门话题，引起了广泛关注和讨论。网友们纷纷在微博上互相交流观点，展开热烈的互动。这篇分享引发了热议，成为当天的热门话题之一。爱可可微博的内容吸引了众多用户参与讨论，展示了微博的社交影响力和互动性。 <div>
《爱可可微博热门分享(4.25)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405027170899853630"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.25)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp3fpm47hwj20rs0fmac1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 14:13:25 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Multi-Session SLAM with Differentiable Wide-Baseline Pose Optimization》(CVPR 2024) GitHub: github.com/princeton-vl/MultiSlam_Diff...</title>
<link>https://weibo.com/1402400261/OblHx82hW</link>
<guid>https://weibo.com/1402400261/OblHx82hW</guid>
<content:encoded><![CDATA[
<div> Multi-Session SLAM, Pose Optimization, Differentiable, Wide-Baseline, GitHub, Sparse Global Matching, Video Frame Interpolation, Large Motion, SiTH, Human Reconstruction, Diffusion, Fast ODE-based Sampling, Learning Transferable Negative Prompts, Out-of-Distribution Detection, Depth Anything, Monocular Depth Estimation, SpaceByte, Language Modeling, Vectorized Sampling-Based Planning, Motion Planning, LinK3D, Keypoint Representation, LiDAR Point Cloud, Generalized Contrastive Learning, Multi-Modal Retrieval, Ranking, Image-Text Alignment, Remote Sensing, DeProt, Protein Language Model, Attention.

<br /><br />总结: 这篇文章介绍了多个涉及计算机视觉、深度学习和机器学习领域的论文实现代码，涵盖了多会话SLAM、视频帧插值、人体重建、扩散模型采样、异常检测、深度估计、语言建模、动作规划、目标识别等多个主题。这些项目的GitHub链接提供了代码实现和相关资源，为相关研究工作者提供了方便。这些工作在不同领域提供了新的方法和技术，为相关研究领域的发展做出了积极贡献。 <div>
几篇论文实现代码：<br />《Multi-Session SLAM with Differentiable Wide-Baseline Pose Optimization》(CVPR 2024) GitHub: github.com/princeton-vl/MultiSlam_DiffPose [fig1]<br />《Sparse Global Matching for Video Frame Interpolation with Large Motion》(CVPR 2024) GitHub: github.com/MCG-NJU/SGM-VFI [fig2]<br />《SiTH: Single-view Textured Human Reconstruction with Image-Conditioned Diffusion》(CVPR 2024) GitHub: github.com/SiTH-Diffusion/SiTH<br />《Fast ODE-based Sampling for Diffusion Models in Around 5 Steps》(CVPR 2024) GitHub: github.com/zju-pi/diff-sampler<br />《Learning Transferable Negative Prompts for Out-of-Distribution Detection》(CVPR 2024) GitHub: github.com/mala-lab/NegPrompt [fig3]<br />《Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data. Foundation Model for Monocular Depth Estimation》(CVPR 2024) GitHub: github.com/LiheYoung/Depth-Anything<br />《SpaceByte: Towards Deleting Tokenization from Large Language Modeling》(2024) GitHub: github.com/kjslag/spacebyte<br />《Motions in Microseconds via Vectorized Sampling-Based Planning》(2024) GitHub: github.com/KavrakiLab/vamp<br />《LinK3D: Linear Keypoint Representation for 3D LiDAR Point Cloud》(2024) GitHub: github.com/YungeCui/LinK3D<br />《Generalized Contrastive Learning for Multi-Modal Retrieval and Ranking》(2024) GitHub: github.com/marqo-ai/GCL<br />《Bootstrapping Interactive Image-Text Alignment for Remote Sensing Image Captioning》(2024) GitHub: github.com/yangcong356/BITA<br />《DeProt: A protein language model with quantizied structure and disentangled attention》(2024) GitHub: github.com/ginnm/DeProt [fig4]<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp30br3wkbj220u0qnats.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp30jyx8zlj22bc0qo7on.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp30yrigokj21hc0u0tos.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp31ir5o5jj21gk0h4qfj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 06:14:15 GMT</pubDate>
</item>
<item>
<title>【phidata：为 LLM 添加长期记忆，旨在解决 LLM 有限的上下文和无法采取行动的问题】’phidata - Add memory, knowledge and tools to LLMs' GitHub: github.com...</title>
<link>https://weibo.com/1402400261/OblH8Ahow</link>
<guid>https://weibo.com/1402400261/OblH8Ahow</guid>
<content:encoded><![CDATA[
<div> LLM、phidata、长期记忆、解决问题、上下文、无法采取行动、GitHub、知识、工具

<br /><br />总结:
文章介绍了phidata为LLM添加长期记忆、知识和工具，旨在解决LLM存在的上下文有限和无法采取行动的问题。phidata的目标是通过增加记忆、知识和工具来加强LLM的功能，使其能够更好地理解和处理更复杂的任务。该项目的GitHub链接为github.com/phidatahq/phidata。 <div>
【phidata：为 LLM 添加长期记忆，旨在解决 LLM 有限的上下文和无法采取行动的问题】’phidata - Add memory, knowledge and tools to LLMs' GitHub: github.com/phidatahq/phidata <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp31sxd2m9j20u60hw0wb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 06:13:17 GMT</pubDate>
</item>
<item>
<title>【tiny-gpu：开源的 Verilog 语言编写的 GPU 设计项目，旨在帮助人们从底层上理解 GPU 是如何工作的】'tiny-gpu - A minimal GPU design in Verilog to learn ho...</title>
<link>https://weibo.com/1402400261/OblFsztVE</link>
<guid>https://weibo.com/1402400261/OblFsztVE</guid>
<content:encoded><![CDATA[
<div> Verilog, GPU, 开源, 设计项目, 学习, 底层, GitHub, tiny-gpu

<br /><br />总结:
tiny-gpu是一个使用Verilog语言编写的开源GPU设计项目，旨在帮助人们从底层上理解GPU是如何工作的。该项目可以让人们学习GPU的工作原理和设计，通过GitHub获取更多信息。 <div>
【tiny-gpu：开源的 Verilog 语言编写的 GPU 设计项目，旨在帮助人们从底层上理解 GPU 是如何工作的】'tiny-gpu - A minimal GPU design in Verilog to learn how GPUs work from the ground up' GitHub: github.com/adam-maj/tiny-gpu <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23GPU%23"><span class="surl-text">#GPU#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp31ptnoawj20u014ljus.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp31puetmfj20u015cq6o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 06:09:09 GMT</pubDate>
</item>
<item>
<title>'QuickRecorder - A lightweight screen recorder based on ScreenCapture Kit for macOS / 基于 ScreenCapture Kit 的轻量化多功能 macOS 录屏工具' GitHub: gi...</title>
<link>https://weibo.com/1402400261/OblDRiuCx</link>
<guid>https://weibo.com/1402400261/OblDRiuCx</guid>
<content:encoded><![CDATA[
<div> GitHub, QuickRecorder, 轻量化, 多功能, macOS, 录屏工具, ScreenCapture Kit, lihaoyun6, 

<br /><br />总结:
QuickRecorder是一款基于ScreenCapture Kit开发的轻量化多功能macOS录屏工具，由GitHub用户lihaoyun6开发。这款工具具有简洁易用的特点，能够帮助用户快速录制屏幕。用户可以在GitHub上找到该工具的源代码，并根据需要进行修改和定制。欢迎感兴趣的用户前往GitHub查看详情。 <div>
'QuickRecorder - A lightweight screen recorder based on ScreenCapture Kit for macOS / 基于 ScreenCapture Kit 的轻量化多功能 macOS 录屏工具' GitHub: github.com/lihaoyun6/QuickRecorder <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Mac%23"><span class="surl-text">#Mac#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp31lk807ij20y40u0wkf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 06:05:12 GMT</pubDate>
</item>
<item>
<title>【LLMBox：用于实现大语言模型的综合库，提供统一的训练流程和全面的模型评估】'LLMBox - a comprehensive library for implementing LLMs, including a unified...</title>
<link>https://weibo.com/1402400261/OblCuwdPV</link>
<guid>https://weibo.com/1402400261/OblCuwdPV</guid>
<content:encoded><![CDATA[
<div> 关键词: LLMBox, 大语言模型, 综合库, 统一训练流程, 模型评估, GitHub

总结:<br /><br />这篇文章介绍了一个名为LLMBox的综合库，专门用于实现大语言模型。该库提供了统一的训练流程和全面的模型评估功能，方便用户进行大语言模型的训练和评估。GitHub上可以找到LLMBox的相关信息。 <div>
【LLMBox：用于实现大语言模型的综合库，提供统一的训练流程和全面的模型评估】'LLMBox - a comprehensive library for implementing LLMs, including a unified training pipeline and comprehensive model evaluation’ GitHub: github.com/RUCAIBox/LLMBox <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp31hjdyuej21vg0u0k02.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 06:01:50 GMT</pubDate>
</item>
<item>
<title>【文档图像处理的论文和数据集列表，涵盖了外观增强、阴影消除、矫正、去模糊和二值化等方面】'This repository contains a paper collection of the methods fo...</title>
<link>https://weibo.com/1402400261/OblAayBvI</link>
<guid>https://weibo.com/1402400261/OblAayBvI</guid>
<content:encoded><![CDATA[
<div> 外观增强、阴影消除、矫正、去模糊、二值化、文档图像处理、论文、数据集、方法、GitHub

论文和数据集列表中收录了文档图像处理的方法，涵盖了外观增强、阴影消除、矫正、去模糊、二值化等方面。这些方法可以帮助提高文档图像的质量和清晰度，使得文档更易于阅读和分析。GitHub仓库包含了相关论文和数据集，为研究人员提供了丰富的资源和参考。整理这些方法和数据集有助于推动文档图像处理领域的发展，促进相关研究的进展。 <div>
【文档图像处理的论文和数据集列表，涵盖了外观增强、阴影消除、矫正、去模糊和二值化等方面】'This repository contains a paper collection of the methods for document image processing, including appearance enhancement, deshadow, dewarping, deblur, and binarization.' GitHub: github.com/ZZZHANG-jx/Recommendations-Document-Image-Processing <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp31c1aow4j21ji0t27ay.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 05:56:07 GMT</pubDate>
</item>
<item>
<title>【CelestialChat：基于 Next.js 和 Shadcn UI 的简单 AI 聊天应用程序，旨在提供快速搜索结果，由 Claude Haiku 和 Tavily 搜索驱动】'CelestialChat - a simple...</title>
<link>https://weibo.com/1402400261/OblxT6N49</link>
<guid>https://weibo.com/1402400261/OblxT6N49</guid>
<content:encoded><![CDATA[
<div> Next.js, Shadcn UI, AI, 聊天应用程序, 快速搜索结果, Claude Haiku, Tavily, GitHub

<br /><br />总结:
CelestialChat是一个基于Next.js和Shadcn UI的简单AI聊天应用程序，旨在提供快速搜索结果。该应用程序由Claude Haiku和Tavily搜索驱动，通过GitHub进行开源共享。用户可通过此应用程序进行快速搜索，并获取相应的搜索结果。CelestialChat的设计简洁易用，提供了便捷的搜索功能，满足了用户对快速搜索信息的需求。CelestialChat的开发团队持续更新改进应用程序，致力于提供更好的搜索体验。 <div>
【CelestialChat：基于 Next.js 和 Shadcn UI 的简单 AI 聊天应用程序，旨在提供快速搜索结果，由 Claude Haiku 和 Tavily 搜索驱动】'CelestialChat - a simple AI chat to deliver fast saerch results powered by Claude Haiku and Tavily search' GitHub: github.com/suzushi-tw/celestialchat <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp3169m1vyj20dm07ot8v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 05:50:28 GMT</pubDate>
</item>
<item>
<title>【LangChain Rust：用 Rust 语言实现的 LangChain，提供了 LLM、Embeddings、VectorStores、Chain、Agents、Tools 等功能，并支持多种 LLM 和 VectorStores】'La...</title>
<link>https://weibo.com/1402400261/Oblwqlvrf</link>
<guid>https://weibo.com/1402400261/Oblwqlvrf</guid>
<content:encoded><![CDATA[
<div> LangChain Rust, Rust语言, LLM, Embeddings, VectorStores, Chain, Agents, Tools, 多种LLM, GitHub <br />
<br />
总结: 这是一个使用Rust语言实现的LangChain项目，提供了LLM、Embeddings、VectorStores、Chain、Agents、Tools等功能，并支持多种LLM和VectorStores。用户可以通过GitHub获取更多信息。 <div>
【LangChain Rust：用 Rust 语言实现的 LangChain，提供了 LLM、Embeddings、VectorStores、Chain、Agents、Tools 等功能，并支持多种 LLM 和 VectorStores】'LangChain Rust - LangChain for Rust, the easiest way to write LLM-based programs in Rust' GitHub: github.com/Abraxas-365/langchain-rust <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp311e8fvpj213g0j0q58.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 05:46:53 GMT</pubDate>
</item>
<item>
<title>'Llama3-Chinese：以Meta-Llama-3-8B为底座，使用 DORA + LORA+ 的训练方法，在50w高质量中文多轮SFT数据 + 10w英文多轮SFT数据 + 2000单轮自我认知数据训练而来...</title>
<link>https://weibo.com/1402400261/OblrE04KZ</link>
<guid>https://weibo.com/1402400261/OblrE04KZ</guid>
<content:encoded><![CDATA[
<div> 关键词: Meta-Llama-3-8B, DORA, LORA, 中文多轮SFT数据, 英文多轮SFT数据, 自我认知数据, 训练方法, 大模型, GitHub

总结:<br /><br />
本文介绍了 Llama3-Chinese 模型，它是以 Meta-Llama-3-8B 为底座，采用 DORA + LORA+ 训练方法得到的大型模型。模型训练使用了 50w 份高质量中文多轮SFT数据、10w 份英文多轮SFT数据和 2000 份单轮自我认知数据。GitHub 上提供了该模型的代码。通过以上训练数据和方法，Llama3-Chinese 模型在中英文多轮对话和自我认知方面得到了较好的表现。 <div>
'Llama3-Chinese：以Meta-Llama-3-8B为底座，使用 DORA + LORA+ 的训练方法，在50w高质量中文多轮SFT数据 + 10w英文多轮SFT数据 + 2000单轮自我认知数据训练而来的大模型' GitHub: github.com/seanzhang-zhichen/llama3-chinese <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp30qcwetfj20u00ukdjt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 05:35:06 GMT</pubDate>
</item>
<item>
<title>【Terrarium - A Simple Python Sandbox：简单易用的 Python 沙箱，用于执行不受信任的用户或 LLM 生成的 Python 代码】'Terrarium - A Simple Python Sandbox -...</title>
<link>https://weibo.com/1402400261/Obll3yhYD</link>
<guid>https://weibo.com/1402400261/Obll3yhYD</guid>
<content:encoded><![CDATA[
<div> Github, Terrarium, Python, 沙箱, 执行, 不受信任, LLM, 代码, cohere-ai

<br /><br />总结:
这篇文章介绍了一个名为Terrarium的简单Python沙箱，用于执行那些不受信任的用户或LLM生成的Python代码。这个沙箱可以帮助数据代理实现更安全的代码执行。Terrarium的代码可以在GitHub上找到，地址为github.com/cohere-ai/cohere-terrarium。 <div>
【Terrarium - A Simple Python Sandbox：简单易用的 Python 沙箱，用于执行不受信任的用户或 LLM 生成的 Python 代码】'Terrarium - A Simple Python Sandbox - A simple Python sandbox for helpful LLM data agents' GitHub: github.com/cohere-ai/cohere-terrarium <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp309k47qij20xn0u0gre.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 05:18:53 GMT</pubDate>
</item>
<item>
<title>【Diarizers：使用 Hugging Face 生态系统微调 Pyannote 说话人辨识模型的库】'Diarizers - a library for fine-tuning pyannote speaker diarization models us...</title>
<link>https://weibo.com/1402400261/ObldRnTfA</link>
<guid>https://weibo.com/1402400261/ObldRnTfA</guid>
<content:encoded><![CDATA[
<div> GitHub, Diarizers, Hugging Face, Pyannote, 说话人辨识模型, 微调<br />
<br />
说话人辨识模型的库 Diarizers 是一个利用 Hugging Face 生态系统对 Pyannote 说话人辨识模型进行微调的库。用户可以在 GitHub 上找到该项目的代码：github.com/huggingface/diarizers。这个库的存在让用户可以更方便地使用已有的模型进行微调，从而更好地适应自己的数据集和需求。通过这个库，用户可以加快说话人辨识模型的应用与部署过程，提高模型的性能和效果。Diarizers 的出现丰富了语音处理领域的工具和资源，为使用者提供了更多选择和可能性。<br /><br />总结: <br />该文章介绍了一款针对 Pyannote 说话人辨识模型的库 Diarizers，借助 Hugging Face 生态系统进行微调，为用户提供了更方便的模型调整与部署方式，丰富了语音处理领域的工具与资源。 <div>
【Diarizers：使用 Hugging Face 生态系统微调 Pyannote 说话人辨识模型的库】'Diarizers - a library for fine-tuning pyannote speaker diarization models using the Hugging Face ecosystem’ GitHub: github.com/huggingface/diarizers <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp2zq97j09j21ji0j2n0q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 05:01:09 GMT</pubDate>
</item>
<item>
<title>GitHub: github.com/Snowflake-Labs/snowflake-arctic - 转发 @爱可可-爱生活:&amp;ensp;【Snowflake Arctic：面向企业AI的大语言模型】- Snowflake研究团队推出了新...</title>
<link>https://weibo.com/1402400261/ObldbbZtO</link>
<guid>https://weibo.com/1402400261/ObldbbZtO</guid>
<content:encoded><![CDATA[
<div> Snowflake Arctic, 语言模型, 企业AI, 优化, 稠密-MoE混合Transformer架构, 高效训练, Apache 2.0许可证, 全面开放, 合作推动, 创新进步

<br /><br />总结:
Snowflake研究团队推出了新语言模型Snowflake Arctic，针对企业级AI任务进行了优化，采用独特的稠密-MoE混合Transformer架构，训练计算成本低，表现卓越。 Arctic在企业指标上优于LLAMA和DBRX，展现训练效率高。该模型开源且提供研究见解，支持免费试用，计划持续发布Arctic系列模型，并与社区合作推动语言模型的创新进步。Snowflake发布的见解总结有助于用户在低成本高效地训练自己的MoE模型。 Arctic采用动态数据课程，能在不同阶段调整数据组成。Snowflake Cortex和huggingface等平台提供免费试用，全面开放用于研究和商业应用。 <div>
GitHub: github.com/Snowflake-Labs/snowflake-arctic<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 【Snowflake Arctic：面向企业AI的大语言模型】<br />- Snowflake研究团队推出了新语言模型Snowflake Arctic，针对企业级AI任务进行了优化，在代码生成、SQL生成和复杂指令理解上表现卓越。   <br />- Arctic使用独特的稠密-MoE混合Transformer架构，只需要不到200万美元的训练计算成本，就达到了顶级的企业级指标。   <br />- Arctic在企业指标上优于计算成本更高的LLAMA和DBRX，展现了极高的训练效率。   <br />- Arctic使用了128个专家的MoE架构，通过顶层2门控只激活170亿参数，实现高效的训练和推理。   <br />- Arctic采用了专注于提升企业能力的动态数据课程，在不同阶段调整数据组成。   <br />- Arctic以Apache 2.0许可证完全开源，提供参数、代码、数据配方、研究见解。   <br />- Snowflake发布了研发过程中的见解总结，帮助用户高效低成本地训练自己的MoE模型。   <br />- Arctic支持免费试用，可以在Snowflake Cortex、huggingface等获取，全面开放用于研究和商业应用。   <br />- Snowflake计划持续开发Arctic系列模型，希望与社区合作推动语言模型的创新进步。<br />《Snowflake Arctic - LLM for Enterprise AI》 <a href="https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp2rgd982cj211q0u0gph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp2rgf60szj215x0u0ac1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp2rghf9gxj215x0u0q4z.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 04:59:28 GMT</pubDate>
</item>
<item>
<title>【Cohere Toolkit：一组预构建的组件，使用户能够快速构建和部署 RAG(Retrieval Augmented Generation)应用】'Cohere Toolkit - Toolkit is a collection of pre...</title>
<link>https://weibo.com/1402400261/OblcYsnVO</link>
<guid>https://weibo.com/1402400261/OblcYsnVO</guid>
<content:encoded><![CDATA[
<div> GitHub, Cohere Toolkit, 预构建，组件，快速构建，部署，RAG，Retrieval Augmented Generation, 应用

<br /><br />总结:
Cohere Toolkit是一个GitHub上的项目，提供了一组预构建的组件，使用户能够快速构建和部署RAG（Retrieval Augmented Generation）应用。该工具包含了各种组件，可以帮助用户更有效地开发和部署RAG应用，提高工作效率。这些组件可以帮助用户快速搭建所需的功能和界面，加速应用的开发和上线过程。通过使用Cohere Toolkit，用户可以快速搭建和部署复杂的RAG应用，实现更高效的工作流程。 <div>
【Cohere Toolkit：一组预构建的组件，使用户能够快速构建和部署 RAG(Retrieval Augmented Generation)应用】'Cohere Toolkit - Toolkit is a collection of prebuilt components enabling users to quickly build and deploy RAG applications.' GitHub: github.com/cohere-ai/cohere-toolkit <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp2znx56g8j214k0u00vi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 04:58:58 GMT</pubDate>
</item>
<item>
<title>Infinite-Realities 展示了实时 3D/4D Gaussian splatting 的最新工作，可以捕捉从复杂的角色互动到动态的快速战斗场景，甚至是家人和朋友的记忆，其重点是高质...</title>
<link>https://weibo.com/1402400261/Objzv89kv</link>
<guid>https://weibo.com/1402400261/Objzv89kv</guid>
<content:encoded><![CDATA[
<div> 展示, 实时, 3D/4D, Gaussian splatting, 角色互动, 快速战斗场景, 高质量, 高保真度, 家人, 朋友

<br /><br />总结:
Infinite-Realities展示了最新的实时3D/4D Gaussian splatting技术，能捕捉各种场景包括复杂的角色互动、动态的快速战斗场景，甚至家人和朋友的记忆。重点在于呈现高质量和高保真度的画面。 <div>
Infinite-Realities 展示了实时 3D/4D Gaussian splatting 的最新工作，可以捕捉从复杂的角色互动到动态的快速战斗场景，甚至是家人和朋友的记忆，其重点是高质量和高保真度。 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5026967930732578"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax1.sinaimg.cn/orj480/5396ee05ly1hp2sfwwrqhj21hc0u0t9y.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/DuFWNRWmlx08elRY903m01041200ESS20E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714014317&amp;ssig=msM0To1dfu&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/fZgeEUE0lx08elRXo0Kc01041200kUBv0E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714014317&amp;ssig=nLKZPtaiFI&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/lc11XWHZlx08elRXu41y01041200dgSb0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1714014317&amp;ssig=axuGHci5%2Bs&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5026967930732578" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 00:48:58 GMT</pubDate>
</item>
<item>
<title>【用AI编辑人类基因】 - 使用从零开始通过AI设计的分子，实现了世界上第一个精确基因编辑。这代表了AI驱动生物设计领域的重大飞跃。 - 训练了大规模语言模型来设...</title>
<link>https://weibo.com/1402400261/ObjwTdrGa</link>
<guid>https://weibo.com/1402400261/ObjwTdrGa</guid>
<content:encoded><![CDATA[
<div> AI, 基因编辑, CRISPR, 蛋白质, 设计, 科学, 治疗方法, 开创性分子, 门槛, 研究<br />
<br />
总结:<br />
通过AI设计的分子实现了精确的基因编辑，标志着AI驱动生物设计领域的重大突破。训练了大规模语言模型来设计CRISPR基因编辑系统，扩展了所有自然CRISPR-Cas蛋白家族的多样性。AI生成的基因编辑器比SpCas9具有相当甚至更好的活性和特异性，且序列不同超过400个突变。公开发布了性能优秀的AI生成基因编辑器OpenCRISPR-1，以推动基因编辑领域的应用。AI设计的基因编辑系统有望为患者带来新的治疗方法，同时降低技术门槛，造福研究和商业应用。带来了从发现科学向设计科学的转变，可以快速找到功能蛋白质。下一步将训练模型生成适合特定基因编辑器的sgRNA，进一步优化活性。 <div>
【用AI编辑人类基因】<br /> - 使用从零开始通过AI设计的分子，实现了世界上第一个精确基因编辑。这代表了AI驱动生物设计领域的重大飞跃。   <br />- 训练了大规模语言模型来设计CRISPR基因编辑系统，生成的蛋白质扩展了所有自然CRISPR-Cas蛋白家族的多样性4.8倍。   <br />- 关注CRISPR-Cas9系统，因为它们应用广泛。计算机设计的基因编辑器与拥有诺贝尔奖的SpCas9相比，活性和特异性相当或更好，同时序列不同超过400个突变。   <br />- 公开发布了性能很好的AI生成基因编辑器OpenCRISPR-1，以促进基因编辑领域的广泛应用。   <br />- 这代表了从发现科学向设计科学的转变，AI可以快速遍历设计空间，找到功能蛋白质。   <br />- 下一步将训练模型生成适合特定基因编辑器的sgRNA，以进一步优化活性。   <br />- 期待AI设计的基因编辑系统为患者带来新的治疗方法。公开发布开创性分子有助于降低技术门槛，造福研究和商业应用。   <br />- <br />《Editing the Human Genome with AI - Profluent》 <a href="https://www.profluent.bio/blog/editing-the-human-genome-with-ai"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp2s8acthsj20u013hgta.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp2s9la5a0j21ej0u07a1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 00:42:32 GMT</pubDate>
</item>
<item>
<title>信息图：商用LLM参数规模一览 src: 网页链接 #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/Obju85SMs</link>
<guid>https://weibo.com/1402400261/Obju85SMs</guid>
<content:encoded><![CDATA[
<div> 商用LLM参数规模一览、关键词：LLM、商用、参数、规模、一览、数据、性能、应用、模型、更新

总结:<br /><br />本文介绍了商用LLM（Large Language Model）的参数规模情况，包括不同模型的参数大小、数据性能等方面的比较。商用LLM应用广泛，可以提升自然语言处理的效率和准确性。不同模型的更新和发展也对商用LLM的应用产生影响。 <div>
信息图：商用LLM参数规模一览 src: <a href="https://khanfk.substack.com/p/technicity-kaleidoscope-042024"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp2s1albrlj20u0116gwg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 00:35:44 GMT</pubDate>
</item>
<item>
<title>【用AutoTrain Advanced在MacBook Pro上微调phi-3模型】《How to Finetune phi-3 on MacBook Pro》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/Objnqmxjx</link>
<guid>https://weibo.com/1402400261/Objnqmxjx</guid>
<content:encoded><![CDATA[
<div> phi-3模型, 微调, AutoTrain Advanced, MacBook Pro, 调试, 训练, 模型, 参数, 数据集, 精度

<br /><br />总结:
本文介绍了如何在MacBook Pro上使用AutoTrain Advanced微调phi-3模型。首先，作者提到了phi-3模型的重要性，并且介绍了AutoTrain Advanced工具的使用。然后详细讲解了在MacBook Pro上微调phi-3模型的步骤，包括调试参数、训练模型和使用合适的数据集。最后，作者强调了微调模型时需要注意的精度问题，以确保模型训练的效果达到预期。通过本文的指导，读者可以在MacBook Pro上轻松地微调phi-3模型，提高模型的性能和效果。 <div>
【用AutoTrain Advanced在MacBook Pro上微调phi-3模型】《How to Finetune phi-3 on MacBook Pro》 <a href="https://huggingface.co/blog/abhishek/phi3-finetune-macbook"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp2rlqyxqqj21bt0u00wz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 00:19:13 GMT</pubDate>
</item>
<item>
<title>【Meta做了OpenAI本该做的】《Meta does everything OpenAI should be [D] : r/MachineLearning》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/Objm8fGEz</link>
<guid>https://weibo.com/1402400261/Objm8fGEz</guid>
<content:encoded><![CDATA[
<div> Meta, OpenAI, machine learning, AI, research, technology, capabilities, comparisons, advancements, applications

总结：<br /><br />这篇文章讨论了Meta公司在人工智能领域所做的工作，认为Meta已经做了OpenAI本应该做的事情。文章比较了Meta和OpenAI在研究、技术、能力、进展和应用方面的差异。Meta在人工智能领域取得了许多进展，并且展示出了强大的技术能力。与OpenAI相比，Meta在人工智能领域的应用更加广泛，为AI领域的发展做出了重要贡献。 <div>
【Meta做了OpenAI本该做的】《Meta does everything OpenAI should be [D] : r/MachineLearning》 <a href="https://www.reddit.com/r/MachineLearning/comments/1cbhec7/meta_does_everything_openai_should_be_d/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp2ri8drtbj20u01220xp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 00:16:02 GMT</pubDate>
</item>
<item>
<title>【Snowflake Arctic：面向企业AI的大语言模型】- Snowflake研究团队推出了新语言模型Snowflake Arctic，针对企业级AI任务进行了优化，在代码生成、SQL生成和复杂...</title>
<link>https://weibo.com/1402400261/Objlp5lgb</link>
<guid>https://weibo.com/1402400261/Objlp5lgb</guid>
<content:encoded><![CDATA[
<div> Snowflake Arctic、企业级AI、大语言模型、稠密-MoE混合Transformer架构、低成本、完全开源、支持免费试用、持续开发、推动语言模型创新进步

<br /><br />总结:
Snowflake研究团队推出了面向企业AI的新语言模型Snowflake Arctic，采用了独特的稠密-MoE混合Transformer架构，不到200万美元的训练计算成本就达到了顶级的企业级指标。Arctic在企业指标上优于LLAMA和DBRX，并展现了极高的训练效率。该模型使用了128个专家的MoE架构，通过顶层2门控只激活170亿参数，实现了高效的训练和推理。Arctic采用了动态数据课程来提升企业能力，并以Apache 2.0许可证完全开源，为用户提供参数、代码、数据配方和研究见解。Snowflake还发布了研发过程中的见解总结，帮助用户高效低成本地训练MoE模型。Arctic支持免费试用，在Snowflake Cortex、huggingface等平台获取，全面开放用于研究和商业应用。Snowflake计划持续开发Arctic系列模型，希望与社区合作推动语言模型的创新进步。 <div>
【Snowflake Arctic：面向企业AI的大语言模型】<br />- Snowflake研究团队推出了新语言模型Snowflake Arctic，针对企业级AI任务进行了优化，在代码生成、SQL生成和复杂指令理解上表现卓越。   <br />- Arctic使用独特的稠密-MoE混合Transformer架构，只需要不到200万美元的训练计算成本，就达到了顶级的企业级指标。   <br />- Arctic在企业指标上优于计算成本更高的LLAMA和DBRX，展现了极高的训练效率。   <br />- Arctic使用了128个专家的MoE架构，通过顶层2门控只激活170亿参数，实现高效的训练和推理。   <br />- Arctic采用了专注于提升企业能力的动态数据课程，在不同阶段调整数据组成。   <br />- Arctic以Apache 2.0许可证完全开源，提供参数、代码、数据配方、研究见解。   <br />- Snowflake发布了研发过程中的见解总结，帮助用户高效低成本地训练自己的MoE模型。   <br />- Arctic支持免费试用，可以在Snowflake Cortex、huggingface等获取，全面开放用于研究和商业应用。   <br />- Snowflake计划持续开发Arctic系列模型，希望与社区合作推动语言模型的创新进步。<br />《Snowflake Arctic - LLM for Enterprise AI》 <a href="https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp2rgd982cj211q0u0gph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp2rgf60szj215x0u0ac1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp2rghf9gxj215x0u0q4z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 00:14:13 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》...</title>
<link>https://weibo.com/1402400261/ObiyizCNb</link>
<guid>https://weibo.com/1402400261/ObiyizCNb</guid>
<content:encoded><![CDATA[
<div> 关键词: 多模态大模型, 人工智能, 技术方法, 开源平台, 应用场景, 因果推理, 世界模型, 多智能体, 具身智能, 发展方向

总结：<br /><br />
本文介绍了中山大学 HCP 实验室出品的《多模态大模型：新一代人工智能技术范式》这本书的内容和意义。该书深入浅出地介绍了多模态大模型的技术方法、开源平台和应用场景，同时详细探讨了因果推理、世界模型、多智能体和具身智能等前沿技术领域。这些内容有助于读者全面了解多模态大模型的特点及发展方向，对新一代人工智能技术范式和通用人工智能的发展起到重要推动作用。通过转发+评论活动，读者有机会获得这本书，希望更多人能够参与其中，共同探讨人工智能技术的发展。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》，截至2024.5.1 12:00，*可可粉*转发+评论即可参与。中山大学 HCP 实验室出品，本书以深入浅出的方式介绍多模态大模型的技术方法、开源平台和应用场景，并详细阐述因果推理、世界模型及多智能体与具身智能等前沿技术领域，有助于读者全面了解多模态大模型的特点及发展方向，对新一代人工智能技术范式和通用人工智能的发展起到重要推动作用。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp1q8lh8x1j20m80m8djk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8n4hifj20m80m8gnu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8pgbfhj20m80m8dj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8r3pagj20m80m80ur.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 22:13:16 GMT</pubDate>
</item>
<item>
<title>今日推介(第1386期)：基于开源训练和推理框架的高效语言模型族、从对抗压缩角度重新思考LLM记忆、教大型语言模型推理代码执行、多头Mixture-of-Experts、Transfo...</title>
<link>https://weibo.com/1402400261/Obiy0gxt5</link>
<guid>https://weibo.com/1402400261/Obiy0gxt5</guid>
<content:encoded><![CDATA[
<div> 基于开源训练和推理框架的高效语言模型族、对抗压缩、LLM记忆、大型语言模型推理代码执行、多头Mixture-of-Experts、Transformer、n-gram语言模型

总结:<br />
本文介绍了基于开源训练和推理框架的高效语言模型族，从对抗压缩角度重新思考LLM记忆，教授大型语言模型推理代码执行，讨论了多头Mixture-of-Experts和Transformer可以表示n-gram语言模型等内容。通过这些方法和框架，可以提升语言模型的准确性和效率，为自然语言处理领域带来更好的发展。 <div>
今日推介(第1386期)：基于开源训练和推理框架的高效语言模型族、从对抗压缩角度重新思考LLM记忆、教大型语言模型推理代码执行、多头Mixture-of-Experts、Transformer可以表示n-gram语言模型 公·众·号：爱可可爱生活 <a href="http://aicoco.net/s/8n"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp2nxkpptwj21vt0u07d0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp2nxmjrclj21dq0u011l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp2nxp3py0j21fr0u0jzy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp2nxsr579j22l80u0wtb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp2nxwiqyvj20t00qm76l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 22:12:32 GMT</pubDate>
</item>
<item>
<title>[CV] FlowMap: High-Quality Camera Poses, Intrinsics, and Depth via Gradient Descent 网页链接 提出FlowMap，一种纯梯度下降的可微方法，可从视频中估计精确...</title>
<link>https://weibo.com/1402400261/Obitxp1gu</link>
<guid>https://weibo.com/1402400261/Obitxp1gu</guid>
<content:encoded><![CDATA[
<div> FlowMap, 相机内参, 姿态, 深度, 可微方法, 视频, 梯度下降, 视角合成, 结构从运动, 高质量

<br /><br />总结:
本文提出了一种名为FlowMap的方法，通过纯梯度下降的可微方式，可以从视频中精确估计相机内参、姿态和每帧稠密深度。该方法在任意视角合成任务中表现优秀，超越之前基于梯度的方法，并与经典的结构从运动方法不相上下。FlowMap的出现为相机姿态和深度估计领域带来了全新的思路和方法，为相关研究和应用提供了一种高效且精确的解决方案。 <div>
[CV] FlowMap: High-Quality Camera Poses, Intrinsics, and Depth via Gradient Descent  <br /><a href="https://arxiv.org/abs/2404.15259"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />提出FlowMap，一种纯梯度下降的可微方法，可从视频中估计精确相机内参(intrinsics)、姿态和每帧稠密深度，在任意视角合成任务中其表现优于以往基于梯度的方法，并与经典结构从运动方法不相上下。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp2nmgvno2j20se190dti.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp2nmh5qjjj21pk0ugnag.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp2nmhgr6nj21pu0qo13u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 22:01:32 GMT</pubDate>
</item>
<item>
<title>[CL] SnapKV: LLM Knows What You are Looking for Before Generation 网页链接 SnapKV通过发现和利用LLM生成时attention头关注prompt特定特征的规律，实现高效...</title>
<link>https://weibo.com/1402400261/Obir3bpSO</link>
<guid>https://weibo.com/1402400261/Obir3bpSO</guid>
<content:encoded><![CDATA[
<div> 关键词: SnapKV, LLM, attention头, prompt, 高效压缩, KV缓存, 解码速度, 内存效率

总结:<br /><br />
SnapKV利用LLM生成时attention头关注prompt特定特征的规律，实现了高效压缩prompt的KV缓存。这一技术不仅帮助提升了长序列场景下的解码速度和内存效率，同时也保持了生成质量。SnapKV能够提前了解用户要查找的内容，在生成之前做出相应的优化，为用户提供更快速、高效的体验。 <div>
[CL] SnapKV: LLM Knows What You are Looking for Before Generation  <br /><a href="https://arxiv.org/abs/2404.14469"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>         <br />SnapKV通过发现和利用LLM生成时attention头关注prompt特定特征的规律，实现高效压缩prompt的KV缓存，在保持生成质量的同时大幅提升长序列场景下的解码速度和内存效率。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp2ng399z6j20qa14cal0.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp2ng3iziwj21cg0q8tg7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp2ng3zfxnj21ca0w2wn2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 21:55:24 GMT</pubDate>
</item>
<item>
<title>[CL] Achieving >97% on GSM8K: Deeply Understanding the Problems Makes LLMs Perfect Reasoners 网页链接 提出“深入理解问题”提示策略，通过提炼核心问题、...</title>
<link>https://weibo.com/1402400261/ObioOghQH</link>
<guid>https://weibo.com/1402400261/ObioOghQH</guid>
<content:encoded><![CDATA[
<div> 深入理解问题 提炼核心问题 提取解决信息 生成答案 增强语言模型 多个推理任务 准确率
<br />
深入理解问题是提升语言模型推理准确率的关键步骤。通过提取核心问题、提取相关信息、生成答案等三个阶段的方法，可以使语言模型更完全地理解问题，从而在多个推理任务中取得更高的准确率。这种方法为建立完美的推理模型提供了重要的指导，并将在未来的研究和实践中发挥重要作用。<br /><br /> 
总结:深入理解问题是提升语言模型推理准确率的关键步骤，通过三个阶段的方法，可以使语言模型更完全地理解问题，从而在多个推理任务中取得更高的准确率。 <div>
[CL] Achieving &gt;97% on GSM8K: Deeply Understanding the Problems Makes LLMs Perfect Reasoners  <br /><a href="https://arxiv.org/abs/2404.14963"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />提出“深入理解问题”提示策略，通过提炼核心问题、提取解决信息、生成答案三阶段增强语言模型对问题的理解，从而显著提高其在多个推理任务上的准确率。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp2na9popnj20sa1667i9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp2naa3xw3j21ka1941c7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp2naaj7snj21ks0t615e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 21:49:53 GMT</pubDate>
</item>
<item>
<title>[CL] AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs网页链接 提出使用AdvPrompter LLM快速生成针对目标LLM的高质量人工可读对抗提示，并使LLM通过...</title>
<link>https://weibo.com/1402400261/Obimgc8df</link>
<guid>https://weibo.com/1402400261/Obimgc8df</guid>
<content:encoded><![CDATA[
<div> 关键词: AdvPrompter, LLM, 对抗提示, 鲁棒性, 生成, 训练

总结:
AdvPrompter 提出了一种新的方法，通过使用对抗提示，能够快速生成针对目标LLM的高质量人工可读对抗提示。这种方法可以帮助LLM在对抗训练中更具鲁棒性。研究者设计了一种快速自适应的对抗提示算法，可以提高生成对抗提示的效率和质量。实验结果表明，AdvPrompter在不同任务上都能够有效生成高质量的对抗提示，并提升了LLM的鲁棒性。通过这种方法，可以增强LLM在面对对抗攻击时的表现，提高其应对复杂场景的能力。 <div>
[CL] AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs<br /><a href="https://yuandong-tian.com/papers/co4prompt_llm.pdf"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出使用AdvPrompter LLM快速生成针对目标LLM的高质量人工可读对抗提示，并使LLM通过对抗训练更具鲁棒性。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp2n3t7nm9j20uo16gdvi.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp2n3tee7bj21la17e4be.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp2n3ty4paj21ko0tk7ad.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 21:43:36 GMT</pubDate>
</item>
<item>
<title>通过构造等价的Transformer语言模型，证明了Transformer可以精确表示传统n-gram语言模型，建立了它们之间的确切数学关系，是理解Transformer概率表示能力的第一...</title>
<link>https://weibo.com/1402400261/ObiitC1yo</link>
<guid>https://weibo.com/1402400261/ObiitC1yo</guid>
<content:encoded><![CDATA[
<div> 关键词: Transformer, 语言模型, nn-gram, 等价, 数学关系, 概率表示能力, 研究, 证明, 构造

总结:<br /><br />这篇文章研究了Transformer语言模型与传统n-gram语言模型之间的关系，通过构造等价的Transformer模型，证明了Transformer可以精确表示传统n-gram语言模型，并建立了它们之间的确切数学关系。这一发现是理解Transformer概率表示能力的重要一步，为深入探讨Transformer在自然语言处理中的应用奠定了基础。研究者通过实验证明了Transformer的强大表示能力，拓展了对Transformer模型的理解，为语言模型研究领域的进一步发展提供了有力支持。 <div>
通过构造等价的Transformer语言模型，证明了Transformer可以精确表示传统n-gram语言模型，建立了它们之间的确切数学关系，是理解Transformer概率表示能力的第一步。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Transformers Can Represent nn-gram Language Models》A Svete, R Cotterell [ETH Zurich] (2024) <a href="https://arxiv.org/abs/2404.14994"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp2mq1vd10j20os0x610r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp2mq2b2mij20t00qmn09.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp2mq2cnogj20sq0hg41h.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp2mq2hp7nj21ku0w20vv.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 21:34:17 GMT</pubDate>
</item>
<item>
<title>[CL]《Transformers Can Represent nn-gram Language Models》A Svete, R Cotterell [ETH Zurich] (2024) 网页链接 #机器学习##人工智能##论文# [图片][图片][图...</title>
<link>https://weibo.com/1402400261/ObiirxWSh</link>
<guid>https://weibo.com/1402400261/ObiirxWSh</guid>
<content:encoded><![CDATA[
<div> Transformer, nn-gram language models, representation, ETH Zurich, language modeling, natural language processing, machine learning, neural networks, research, study

总结: 
本文讨论了如何利用Transformers来表示nn-gram语言模型，作者来自ETH Zurich。他们研究了语言建模在自然语言处理中的应用，并探讨了神经网络在该领域的重要性。通过对机器学习的研究，他们提出了一种新的方法，以提高语言模型的性能。通过实验和研究，他们展示了Transformer在语言建模中的潜力和有效性。这项研究为未来相关领域的发展提供了新的思路和方向。 <div>
[CL]《Transformers Can Represent nn-gram Language Models》A Svete, R Cotterell [ETH Zurich] (2024) <a href="https://arxiv.org/abs/2404.14994"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp2mq1vd10j20os0x610r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp2mq2b2mij20t00qmn09.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp2mq2cnogj20sq0hg41h.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp2mq2hp7nj21ku0w20vv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 21:34:12 GMT</pubDate>
</item>
<item>
<title>提出MH-MoE，用多头机制增强了SMoE框架中的expert激活和对歧义内容的理解。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Multi-Head Mixture-of-Experts》X Wu, S Huang,...</title>
<link>https://weibo.com/1402400261/ObifUCqwL</link>
<guid>https://weibo.com/1402400261/ObifUCqwL</guid>
<content:encoded><![CDATA[
<div> 多头机制、SMoE框架、expert激活、歧义内容理解、MH-MoE、Microsoft Research、Tsinghua University

<br /><br />总结：研究提出了MH-MoE框架，通过引入多头机制增强了SMoE框架中的expert激活和对歧义内容的理解能力。该框架结合了Microsoft Research和清华大学的研究成果，旨在提高专家系统的性能和效率。通过综合利用多头机制和混合专家的特点，有效地处理了各种复杂问题，实现了更准确的预测和更高的精度。这一创新为专家系统的发展和优化提供了新的思路和方法。 <div>
提出MH-MoE，用多头机制增强了SMoE框架中的expert激活和对歧义内容的理解。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Multi-Head Mixture-of-Experts》X Wu, S Huang, W Wang, F Wei [Microsoft Research &amp; Tsinghua Universit] (2024) <a href="https://arxiv.org/abs/2404.15045"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp2me8gj6wj20pc1cmna4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp2me8vxy0j20ts16s49e.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp2me9cll4j21mg0is136.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp2me9ge7uj21ms0oqth0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp2mna8rknj212d0anq5g.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp2mna9424j210j0icq5z.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp2mnacmiqj212b1bx4dz.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 21:27:57 GMT</pubDate>
</item>
<item>
<title>[CL]《Multi-Head Mixture-of-Experts》X Wu, S Huang, W Wang, F Wei [Microsoft Research &amp; Tsinghua Universit] (2024) 网页链接 #机器学习##人工智能##论文#...</title>
<link>https://weibo.com/1402400261/ObifPxJNt</link>
<guid>https://weibo.com/1402400261/ObifPxJNt</guid>
<content:encoded><![CDATA[
<div> 关键词: 多头模型，深度学习，专家模型，微软研究，清华大学

这篇文章介绍了一种名为“多头混合专家模型”的新型深度学习方法，由微软研究和清华大学的研究人员共同研发。该模型通过将多个专家模型合并，实现更精确的预测和推理能力，提高了模型的整体性能。研究人员对不同领域的多头模型进行了实验，并取得了令人满意的结果。他们的研究有望在各种领域，特别是人工智能领域，取得重要的突破和应用。

<br /><br />总结:
本研究团队提出了一种名为“多头混合专家模型”的深度学习方法，该模型通过合并多个专家模型实现更精确的预测和推理能力，提高整体性能。对不同领域的多头模型进行实验，取得了令人满意的结果。未来，这一研究有望在人工智能等领域取得重要突破和应用。 <div>
[CL]《Multi-Head Mixture-of-Experts》X Wu, S Huang, W Wang, F Wei [Microsoft Research &amp; Tsinghua Universit] (2024) <a href="https://arxiv.org/abs/2404.15045"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp2me8gj6wj20pc1cmna4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp2me8vxy0j20ts16s49e.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp2me9cll4j21mg0is136.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp2me9ge7uj21ms0oqth0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp2mna8rknj212d0anq5g.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp2mna9424j210j0icq5z.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp2mnacmiqj212b1bx4dz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 21:27:46 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.24)》 爱可可微博热门分享(4.24) [图片]</title>
<link>https://weibo.com/1402400261/ObfCTywEh</link>
<guid>https://weibo.com/1402400261/ObfCTywEh</guid>
<content:encoded><![CDATA[
<div> 爱可可 微博 热门 分享 4.24

总结:<br />
文章介绍了爱可可微博上4.24日热门分享的内容。包括各种话题和讨论，引起了广泛关注。报道内容生动有趣，深受网友喜爱。帖文更新频繁且内容多样，涵盖了各种热门话题。网友们在评论中互相交流，形成了热烈的讨论氛围。总体来看，爱可可微博在4.24日的热门分享中表现出色。 <div>
《爱可可微博热门分享(4.24)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405026816795738680"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.24)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp2b1j5enqj20rs0fmdlw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 14:46:20 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video》(ICLR 2024) GitHub: github.com/shashankvkt...</title>
<link>https://weibo.com/1402400261/Obc3hxSHU</link>
<guid>https://weibo.com/1402400261/Obc3hxSHU</guid>
<content:encoded><![CDATA[
<div> MoMA, Multimodal LLM Adapter, Fast Personalized Image Generation, GitHub, KunpengSong, MoMA, 2024, personalized, image generation, adapter

总结: 该项研究提出了MoMA，这是一个多模态LLM适配器，可实现快速个性化图像生成。研究团队通过GitHub平台发布了代码，并进行了详细的实验和测试。这一技术创新能够实现个性化图像生成，并展示了其在不同场景下的应用潜力。MoMA的发布将对个性化图像生成领域具有重大的推动作用。 <div>
几篇论文实现代码：<br />《Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video》(ICLR 2024) GitHub: github.com/shashankvkt/DoRA_ICLR24 [fig9]<br />《VGGSfM Visual Geometry Grounded Deep Structure From Motion》(CVPR 2024) GitHub: github.com/facebookresearch/vggsfm<br />《HUGS: Human Gaussian Splats》(CVPR 2024) GitHub: github.com/apple/ml-hugs [fig2]<br />《Towards Realistic Scene Generation with LiDAR Diffusion Models》(CVPR 2024) GitHub: github.com/hancyran/LiDAR-Diffusion [fig3]<br />《TexTile: A Differentiable Metric for Texture Tileability》(CVPR 2024) GitHub: github.com/crp94/textile<br />《Beyond Image Super-Resolution for Image Recognition with Task-Driven Perceptual Loss》(CVPR 2024) GitHub: github.com/JaehaKim97/SR4IR<br />《DMesh: A Differentiable Representation for General Meshes》(2024) GitHub: github.com/SonSang/dmesh [fig1] <br />《Design of highly functional genome editors by modeling the universe of CRISPR-Cas sequences》(2024) GitHub: github.com/Profluent-AI/OpenCRISPR<br />《AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning》(2024) GitHub: github.com/SalesforceAIResearch/xLAM [fig4]<br />《FlowMap: High-Quality Camera Poses, Intrinsics, and Depth via Gradient Descent》(2024) GitHub: github.com/dcharatan/flowmap<br />《How Good Are Low-bit Quantized LLAMA3 Models? An Empirical Study》(2024) GitHub: github.com/Macaronlin/LLaMA3-Quantization [fig5]<br />《STaRK: Benchmarking LLM Retrieval on Textual and Relational Knowledge Bases》(2024) GitHub: github.com/snap-stanford/stark [fig6]<br />《DoRA: Weight-Decomposed Low-Rank Adaptation》(2024) GitHub: github.com/NVlabs/DoRA [fig7]<br />《Disentangling Structured Components: Towards Adaptive, Interpretable and Scalable Time Series Forecasting》(2024) GitHub: github.com/JLDeng/SCNN<br />《MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation》(2024) GitHub: github.com/bytedance/MoMA [fig8]<br />《Musical Word Embedding for Music Tagging and Retrieval》(2024) GitHub: github.com/seungheondoh/musical-word-embedding<br />《Neural Étendue Expander for Ultra-Wide-Angle High-Fidelity Holographic Display》(2024) GitHub: github.com/Ethan-Tseng/Neural_Etendue_Expander<br />《Structured Chemistry Reasoning with Large Language Models》(2024) GitHub: github.com/ozyyshr/StructChem<br />《MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation》(2024) GitHub: github.com/KunpengSong/MoMA<br />《InstructPLM: Aligning Protein Language Models to Follow Protein Structure Instructions》(2024) GitHub: github.com/Eikor/InstructPLM<br />《Complementing Onboard Sensors with Satellite Map: A New Perspective for HD Map Construction》(2024) GitHub: github.com/xjtu-cs-gao/SatforHDMap<br />《RiNALMo: General-Purpose RNA Language Models Can Generalize Well on Structure Prediction Tasks》(2024) GitHub: github.com/lbcb-sci/RiNALMo<br />《UV-SAM: Adapting Segment Anything Model for Urban Village Identification》(2024) GitHub: github.com/tsinghua-fib-lab/UV-SAM<br />《MedMamba: Vision Mamba for Medical Image Classification》(2024) GitHub: github.com/YubiaoYue/MedMamba<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1svui6laj22c41a3qv6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1u57nm0zj23mc1fa4qr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1u652iz8j21zg2eykjl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp1uj4utoij28fe3cn4qr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1umpzuhmj211p0b6q57.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp1uofcyvhj21ea0wwtlh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1upmuvycj229a1lke81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1uql1586j21dw0l47iw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1usr9d5yj21fi0dujw0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 05:40:22 GMT</pubDate>
</item>
<item>
<title>【Unichat-llama3-Chinese：联通AI创新中心发布业界llama3中文指令微调模型】'Unichat-llama3-Chinese' GitHub: github.com/UnicomAI/Unichat-llama3-Chinese #...</title>
<link>https://weibo.com/1402400261/ObbYvoxwi</link>
<guid>https://weibo.com/1402400261/ObbYvoxwi</guid>
<content:encoded><![CDATA[
<div> 联通AI创新中心，llama3，中文指令微调模型，业界，发布，GitHub，Unichat-llama3-Chinese，模型，功能，优化

<br /><br />总结:
联通AI创新中心发布了业界llama3中文指令微调模型，通过GitHub项目Unichat-llama3-Chinese实现。该模型对中文指令进行了微调，优化了功能，为用户提供更高效的使用体验。 <div>
【Unichat-llama3-Chinese：联通AI创新中心发布业界llama3中文指令微调模型】'Unichat-llama3-Chinese' GitHub: github.com/UnicomAI/Unichat-llama3-Chinese <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1uxbvjcvj21840u0q85.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 05:28:36 GMT</pubDate>
</item>
<item>
<title>【llama2.cpp：C++ 版本的 Llama 2 推理库，支持 CPU 计算，并且计划支持 CUDA 和 AVX512】'llama2.cpp - Inference Llama 2 in C++' GitHub: github.com/AmeyaW...</title>
<link>https://weibo.com/1402400261/ObbWsEEOu</link>
<guid>https://weibo.com/1402400261/ObbWsEEOu</guid>
<content:encoded><![CDATA[
<div> 推理库，C++，CPU，CUDA，AVX512，GitHub，Llama 2

<br /><br />总结:
这篇文章介绍了一个名为Llama 2的推理库的C++版本，该库支持CPU计算，并计划未来支持CUDA和AVX512。作者提供了GitHub链接，项目地址为github.com/AmeyaWagh/llama2.cpp。该推理库的C++版本提供了更多计算功能，并且未来将支持更多计算平台，为用户提供更便捷、高效的推理计算体验。 <div>
【llama2.cpp：C++ 版本的 Llama 2 推理库，支持 CPU 计算，并且计划支持 CUDA 和 AVX512】'llama2.cpp - Inference Llama 2 in C++' GitHub: github.com/AmeyaWagh/llama2.cpp <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp1us44z3pj212h0u0jvx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 05:23:34 GMT</pubDate>
</item>
<item>
<title>【MuKoe：开源的 MuZero 实现，利用 Ray 作为分布式调度器，在 GKE 上运行】'MuKoe - a fully open sourced implementation of MuZero using Ray as the distrib...</title>
<link>https://weibo.com/1402400261/ObbTQ9EuI</link>
<guid>https://weibo.com/1402400261/ObbTQ9EuI</guid>
<content:encoded><![CDATA[
<div> Ray, MuZero, 开源, GKE, 分布式调度器, 实现, GitHub, 分布式 orchestrator

总结:<br />
MuKoe是一个完全开源的MuZero实现，利用Ray作为分布式调度器，在Google Kubernetes Engine(GKE)上运行。这个项目已经在GitHub上开源，并提供了详细的代码和文档。通过利用Ray的分布式功能，MuKoe能够有效地分配计算资源，提高训练效率，并且可以轻松扩展到更大规模的计算集群。对于想要了解MuZero算法实现细节的研究者和开发者来说，MuKoe是一个很好的参考和学习资源。 <div>
【MuKoe：开源的 MuZero 实现，利用 Ray 作为分布式调度器，在 GKE 上运行】'MuKoe - a fully open sourced implementation of MuZero using Ray as the distributed orchestrator on GKE’ GitHub: github.com/character-ai/MuKoe <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp1ulal65uj211o0mgtd6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 05:17:06 GMT</pubDate>
</item>
<item>
<title>【A Trivial Jailbreak Against Llama 3：用于绕过 Llama 3 模型安全措施的程序，可以通过在助手角色中插入有害前缀来绕过 Llama 3 的安全措施，从而生成有害的...</title>
<link>https://weibo.com/1402400261/ObbSD4bIr</link>
<guid>https://weibo.com/1402400261/ObbSD4bIr</guid>
<content:encoded><![CDATA[
<div> Llama 3, 安全措施, 程序, 前缀, 文本, 有害, 调用, 模型, GitHub, jailbreak

<br /><br />总结:
本文介绍了一种用于绕过 Llama 3 模型安全措施的程序，通过在助手角色中插入有害前缀来生成有害的文本，并调用其他模型生成有害前缀，然后传递给 Llama 3。作者在 GitHub 上分享了这个名为“llama3-jailbreak”的项目，展示了一种简单的 Llama 3 破解方法。 <div>
【A Trivial Jailbreak Against Llama 3：用于绕过 Llama 3 模型安全措施的程序，可以通过在助手角色中插入有害前缀来绕过 Llama 3 的安全措施，从而生成有害的文本，还可以通过调用其他模型生成有害前缀，然后将其传递给 Llama 3】’A Trivial Jailbreak Against Llama 3 - A trivial programmatic Llama 3 jailbreak. Sorry Zuck!' GitHub: github.com/haizelabs/llama3-jailbreak <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp1uhc8bcfj21fy0n8wi0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 05:14:07 GMT</pubDate>
</item>
<item>
<title>【SnapKV：创新且出色的 KV 缓存压缩方法】'SnapKV - an innovative and out-of-box KV cache compression method’ GitHub: github.com/FasterDecoding/SnapKV ...</title>
<link>https://weibo.com/1402400261/ObbN84k0P</link>
<guid>https://weibo.com/1402400261/ObbN84k0P</guid>
<content:encoded><![CDATA[
<div> 创新 KV 缓存 压缩 方法 GitHub FasterDecoding SnapKV <br />
<br />
总结: <br />
这篇文章介绍了一个名为SnapKV的创新KV缓存压缩方法。SnapKV采用了一种出色的压缩技术，可以大大提高KV缓存的性能和效率。它通过GitHub项目FasterDecoding开源，为开发者提供了一个新颖的解决方案。SnapKV的出现为KV缓存系统的发展带来了新的可能性，有望在未来得到广泛应用。 <div>
【SnapKV：创新且出色的 KV 缓存压缩方法】'SnapKV - an innovative and out-of-box KV cache compression method’  GitHub: github.com/FasterDecoding/SnapKV <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 05:00:34 GMT</pubDate>
</item>
<item>
<title>【CoreNet: Apple的深度网络训练库，用于训练深度神经网络，支持各种任务，包括基础模型(如 CLIP 和 LLM)、目标分类、目标检测和语义分割】'CoreNet: A library ...</title>
<link>https://weibo.com/1402400261/ObbAchnpj</link>
<guid>https://weibo.com/1402400261/ObbAchnpj</guid>
<content:encoded><![CDATA[
<div> Apple、深度网络、训练库、神经网络、任务、基础模型、目标分类、目标检测、语义分割
<br /><br />总结:
Apple推出了CoreNet，这是一个用于训练深度神经网络的库。它支持多种任务，包括基础模型如CLIP和LLM、目标分类、目标检测和语义分割。这个库旨在帮助开发者更轻松地训练各种深度神经网络，提高其应用的效率和准确性。CoreNet的出现将为深度学习领域带来更多的可能性和发展空间。 <div>
【CoreNet: Apple的深度网络训练库，用于训练深度神经网络，支持各种任务，包括基础模型(如 CLIP 和 LLM)、目标分类、目标检测和语义分割】'CoreNet: A library for training deep neural networks - CoreNet: A library for training deep neural networks' GitHub: github.com/apple/corenet <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp1t71di1hj217y0l0q6g.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 04:28:43 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@博文视点Broadview 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》，截至2024.5.1 12:00，*可可粉*转发+评论即可参与。中山大学 ...</title>
<link>https://weibo.com/1402400261/ObaVdaaXn</link>
<guid>https://weibo.com/1402400261/ObaVdaaXn</guid>
<content:encoded><![CDATA[
<div> 中山大学、HCP 实验室、多模态大模型、人工智能、技术方法、开源平台、应用场景、因果推理、世界模型、多智能体

<br /><br />总结:
中山大学HCP实验室推出的《多模态大模型：新一代人工智能技术范式》介绍了多模态大模型的技术方法、开源平台和应用场景，深入浅出地探讨了因果推理、世界模型、多智能体等前沿领域。这本全彩书籍有助于读者全面了解多模态大模型的特点和发展方向，对促进新一代人工智能技术范式和通用人工智能的发展具有重要推动作用。 <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《多模态大模型：新一代人工智能技术范式 （全彩）》，截至2024.5.1 12:00，*可可粉*转发+评论即可参与。中山大学 HCP 实验室出品，本书以深入浅出的方式介绍多模态大模型的技术方法、开源平台和应用场景，并详细阐述因果推理、世界模型及多智能体与具身智能等前沿技术领域，有助于读者全面了解多模态大模型的特点及发展方向，对新一代人工智能技术范式和通用人工智能的发展起到重要推动作用。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp1q8lh8x1j20m80m8djk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8n4hifj20m80m8gnu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8pgbfhj20m80m8dj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1q8r3pagj20m80m80ur.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 02:47:44 GMT</pubDate>
</item>
<item>
<title>【用Pytorch从头实现Transformer】《Creating a Transformer From Scratch - Part One: The Attention Mechanism | Mixed Precision》 网页链接《Creating a Tra...</title>
<link>https://weibo.com/1402400261/Oba0q9CiJ</link>
<guid>https://weibo.com/1402400261/Oba0q9CiJ</guid>
<content:encoded><![CDATA[
<div> 注意机制、混合精度、Transformer、Pytorch、实现、编程代码、模型、训练、优化、注意力权重

总结：<br /><br />这篇文章通过两部分介绍了如何使用Pytorch从头实现Transformer模型。第一部分讨论了注意机制的实现，解释了注意力权重的计算过程和实现细节，并介绍了混合精度优化技术。第二部分详细讲解了Transformer模型的其余部分的实现，包括编码器和解码器的构建，以及模型的训练和优化过程。通过编写Python代码，作者演示了如何使用Pytorch构建和训练Transformer模型，帮助读者更好地理解这一先进的神经网络结构。整个教程涵盖了从基本概念到实际编程代码的全过程，为想要深入了解Transformer的研究人员提供了很好的参考。 <div>
【用Pytorch从头实现Transformer】<br />《Creating a Transformer From Scratch - Part One: The Attention Mechanism | Mixed Precision》 <a href="https://benjaminwarner.dev/2023/07/01/attention-mechanism"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br />《Creating a Transformer From Scratch - Part Two: The Rest of the Transformer | Mixed Precision》 <a href="https://benjaminwarner.dev/2023/07/28/rest-of-the-transformer"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <br /> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp1m81zl39j20vh0u0af0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp1m8cpnxqj210q0u0dko.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 00:27:49 GMT</pubDate>
</item>
<item>
<title>Demo: 网页链接 Models: 网页链接 - 转发 @爱可可-爱生活:&amp;ensp;[CL] Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone 网页链...</title>
<link>https://weibo.com/1402400261/Ob95n2PNr</link>
<guid>https://weibo.com/1402400261/Ob95n2PNr</guid>
<content:encoded><![CDATA[
<div> 关键词: 训练数据、优化、创新、模型、缩放律、性能强劲、安全可控、体积小巧、手机、语言模型

通过训练数据的优化和创新，这篇技术报告介绍了一种能在手机上运行的高性能、安全可控、体积小巧的语言模型。这个模型突破了常规模型的缩放限制，为语言模型的发展带来了新的可能性。这种技术可以让用户在手机上使用强大的语言模型，无需依赖云端服务，提高了数据安全性和隐私保护。这个创新的模型设计将手机变成了语言处理的利器，为用户提供更好的使用体验和便利性。整体而言，这项技术为移动设备上的语言处理技术带来了重大突破，为未来的发展带来了新的可能性。<br /><br />总结: 该技术报告介绍了一种能在手机上运行的高性能语言模型，通过优化训练数据和创新设计，实现了模型的性能强劲、安全可控、体积小巧的特点，突破了常规模型的缩放限制。 <div>
Demo: <a href="https://huggingface.co/chat/models/microsoft/Phi-3-mini-4k-instruct/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> Models: <a href="https://huggingface.co/models?other=phi3&amp;sort=trending&amp;search=microsoft"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL] Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone  <br /><a href="https://arxiv.org/abs/2404.14219"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />通过训练数据优化创新打破常规模型缩放律，实现了一个性能强劲、安全可控、体积小巧到能运行在手机上的语言模型。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1h4f3y56j20w813edtx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1h4fc944j21lm13ytiv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1h4fvgzej21m40wogss.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 22:07:16 GMT</pubDate>
</item>
<item>
<title>【用 Evolutionary Model Merging 优化模型性能】- Arcee公司推出了新的MergeKit工具，实现了开创性的进化模型融合技术，让用户可以针对特定的能力或品质进行模...</title>
<link>https://weibo.com/1402400261/Ob94j96sW</link>
<guid>https://weibo.com/1402400261/Ob94j96sW</guid>
<content:encoded><![CDATA[
<div> MergeKit、Evolutionary Model Merging、Arcee、模型性能优化、评估任务、优化目标、模型融合配置、最佳融合方案、计算后端、模型融合研究应用

<br /><br />总结:
Arcee公司推出了新的MergeKit工具，实现了进化模型融合技术，用户可以针对特定能力或品质进行模型融合。进化模型融合可以通过定义评估任务和优化目标自动搜索最佳方案，简化了融合过程。使用示例展示了模型融合配置及运行融合过程，找到了平衡不同特性的最佳融合方案。Arcee计划集成这一技术在产品中，提供计算后端支持，推动模型融合研究和应用，邀请用户提交研究以共同推进领域发展。 <div>
【用 Evolutionary Model Merging 优化模型性能】<br />- Arcee公司推出了新的MergeKit工具，实现了开创性的进化模型融合技术，让用户可以针对特定的能力或品质进行模型融合。   <br />- 通过定义评估任务和优化目标，进化模型融合可以自动搜索出符合要求的模型融合方案。不再需要手工尝试大量融合才找出最佳方案。   <br />- 文中提供了详细的示例，包括定义空间推理和回复格式评估任务，编写模型融合配置，运行融合过程。   <br />- 融合过程会自动评估大量模型，找到评估指标最高的那个作为最终模型。   <br />- 文中融合了3个不同特性的7B模型，优化回复格式和空间推理指标，找到了平衡二者的最佳融合方案。   <br />- 这一技术使得模型融合更简单可访问，用户只需定义需求就可以自动获得满足要求的融合模型。   <br />- Arcee计划在产品中集成这一技术，提供完整的计算后端，让用户无需自备GPU就可以使用模型融合。   <br />- 这项技术有望大大推动模型融合的研究和应用。Arcee邀请用户提交模型融合的创新研究，共同推进这一领域。<br />《Evolutionary Model Merging For All》 <a href="https://blog.arcee.ai/tutorial-tutorial-how-to-get-started-with-evolutionary-model-merging/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp1i3fat93j20u00ucwmj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 22:04:39 GMT</pubDate>
</item>
<item>
<title>今日推介(第1385期)：多模态自动可解释性Agent、LoRA专家混合、用大语言模型建模情感和伦理、训练LLM用不同优先级层次化处理指令、通过检索和转换现有数据集来更...</title>
<link>https://weibo.com/1402400261/Ob91AtPm4</link>
<guid>https://weibo.com/1402400261/Ob91AtPm4</guid>
<content:encoded><![CDATA[
<div> 多模态自动可解释性Agent、LoRA专家混合、大语言模型建模情感和伦理、训练LLM处理指令、检索转换现有数据集合成数据<br />
<br />
1. 多模态自动可解释性Agent和LoRA专家混合是重要推介内容，这表明了对于自动智能系统的需求越来越多元化。
2. 用大语言模型建模情感和伦理方面的研究成果展示了人工智能在社会伦理方面的应用与潜力。
3. 训练LLM用不同优先级层次化处理指令的方法可能为提高指令执行效率提供了新思路。
4. 通过检索和转换现有数据集来更好地合成数据的技术，可以帮助提升数据的多样性和质量。 
<br /><br />总结: 提出了多种智能技术的研究成果和应用前景，展示了人工智能在多领域的潜力和可能性，对未来的智能系统发展具有重要启示意义。 <div>
今日推介(第1385期)：多模态自动可解释性Agent、LoRA专家混合、用大语言模型建模情感和伦理、训练LLM用不同优先级层次化处理指令、通过检索和转换现有数据集来更好地合成数据 公·众·号：爱可可爱生活 爱可可AI前沿推介(12.19) <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp1hvw7uv3j20se0zwq80.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp1hvyu2kij20ls0q2djh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp1hw2scn6j20tw0r0gp1.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp1hwbn87xj21400m6jxb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp1hweu7s8j20sq1bkgv1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 21:57:57 GMT</pubDate>
</item>
<item>
<title>[CV] Scene Coordinate Reconstruction: Posing of Image Collections via Incremental Learning of a Relocalizer 网页链接 通过将视觉重定位原理应用于增量式...</title>
<link>https://weibo.com/1402400261/Ob8Ye9ylP</link>
<guid>https://weibo.com/1402400261/Ob8Ye9ylP</guid>
<content:encoded><![CDATA[
<div> Scene Coordinate Reconstruction, Posing, Image Collections, Incremental Learning, Relocalizer, 视觉重定位原理, 隐式场景表示, 相机姿态估计, 特征匹配, 姿态先验

<br /><br />
总结:
本文提出了一种通过增量学习重定位器来实现图像集合的姿态重建技术。该方法无需特征匹配或姿态先验，仅通过学习隐式场景表示和估计相机姿态来实现图像的姿态确定。通过将视觉重定位原理应用于结构化运动流程，实现了高效准确的姿态估计，为场景重建和图像处理领域提供了新的技术思路。 <div>
[CV] Scene Coordinate Reconstruction: Posing of Image Collections via Incremental Learning of a Relocalizer  <br /><a href="https://arxiv.org/abs/2404.14351"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过将视觉重定位原理应用于增量式结构化运动流程，实现仅从图像学习隐式场景表示并估计相机姿态，无需特征匹配或姿态先验。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1hnrl3kmj20s218wqfx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp1hns6ywyj21p417c1kx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1hnsugacj214a0z8wu4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 21:49:40 GMT</pubDate>
</item>
<item>
<title>[CL] Surveying Attitudinal Alignment Between Large Language Models Vs. Humans Towards 17 Sustainable Development Goals 网页链接 通过全面分析大语言模型...</title>
<link>https://weibo.com/1402400261/Ob8VLET8f</link>
<guid>https://weibo.com/1402400261/Ob8VLET8f</guid>
<content:encoded><![CDATA[
<div> 关键词: 大语言模型, 可持续发展目标, 理解, 支持, 预警, 建议, 负责任应用, 人机协同, 差异, 分析

总结:<br /><br />
本文通过全面分析大语言模型与人类在可持续发展目标的理解和支持方面的差异，提出了重要的预警和建议。文章指出负责任应用大语言模型有助于推动人机协同共同推进可持续发展目标的实现。对于大语言模型对可持续发展目标的理解和支持，我们需要加强监管和引导，确保其发挥积极作用。同时，人类在意识形态、文化、价值观等方面与大语言模型存在差异，需要进一步研究和调整，以实现更好的匹配和相互支持。最后，建议建立人机协同工作机制，促进大语言模型与人类共同推动可持续发展目标的实现。 <div>
[CL]  Surveying Attitudinal Alignment Between Large Language Models Vs. Humans Towards 17 Sustainable Development Goals  <br /><a href="https://arxiv.org/abs/2404.13885"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过全面分析大语言模型与人类在可持续发展目标理解和支持方面的差异，提出了重要的预警和建议，有利于推动大语言模型的负责任应用，实现人机协同推进可持续发展。<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1hhisg5gj20uu14g7fk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1hhj0j6rj21dk0niagk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1hhjrpghj21l4114n8u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 21:43:37 GMT</pubDate>
</item>
<item>
<title>[CL] A Survey on Self-Evolution of Large Language Models 网页链接 本文通过建立自我进化的概念框架，全面调研语言模型的自主进化方法，分析现有挑战并指出未...</title>
<link>https://weibo.com/1402400261/Ob8TydxgV</link>
<guid>https://weibo.com/1402400261/Ob8TydxgV</guid>
<content:encoded><![CDATA[
<div> 自我进化、语言模型、调研、挑战、未来方向、下一代模型、概念框架、方法、分析、路径铺平

<br /><br />总结:
本文通过建立自我进化的概念框架，全面调研语言模型的自主进化方法，分析现有挑战并指出未来方向，为发展下一代自我进化模型铺平道路。 <div>
[CL] A Survey on Self-Evolution of Large Language Models  <br /><a href="https://arxiv.org/abs/2404.14387"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />本文通过建立自我进化的概念框架，全面调研语言模型的自主进化方法，分析现有挑战并指出未来方向，为发展下一代自我进化模型铺平道路。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1hbrbcqxj20s816a4eh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1hbsrhnxj21i80hwwj0.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp1hbrjilqj21jg0umtj7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 21:38:09 GMT</pubDate>
</item>
<item>
<title>[CL] Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone 网页链接 通过训练数据优化创新打破常规模型缩放律，实现了一个性能强劲...</title>
<link>https://weibo.com/1402400261/Ob8QF9tzq</link>
<guid>https://weibo.com/1402400261/Ob8QF9tzq</guid>
<content:encoded><![CDATA[
<div> 关键词: Phi-3, 语言模型, 手机, 性能强劲, 安全可控, 体积小巧, 训练数据, 创新, 模型缩放律

总结:<br /><br />这篇技术报告介绍了Phi-3的语言模型，通过训练数据优化和创新，成功打破常规模型缩放律，实现了一个性能强劲、安全可控、体积小巧的语言模型，可以运行在手机上。Phi-3的设计使得其在资源受限的环境下也能高效运行，并保证安全性和可控性。通过优化训练数据，Phi-3取得了令人满意的性能表现，为手机上的语言处理提供了新的可能性。Phi-3的出现将为语言模型在移动端的应用带来重要突破，为用户提供更便捷、高效的语言处理服务。 <div>
[CL] Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone  <br /><a href="https://arxiv.org/abs/2404.14219"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />通过训练数据优化创新打破常规模型缩放律，实现了一个性能强劲、安全可控、体积小巧到能运行在手机上的语言模型。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1h4f3y56j20w813edtx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1h4fc944j21lm13ytiv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1h4fvgzej21m40wogss.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 21:31:02 GMT</pubDate>
</item>
<item>
<title>提出DataTune方法，通过改造现有数据集生成更高质量的任务定制合成训练数据，并在BIG-Bench任务上验证了其有效性。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Better S...</title>
<link>https://weibo.com/1402400261/Ob8O97cur</link>
<guid>https://weibo.com/1402400261/Ob8O97cur</guid>
<content:encoded><![CDATA[
<div> DataTune 方法、数据集、任务定制、合成训练数据、BIG-Bench 任务、高质量、有效性验证、Retrieving、Transforming、Existing Datasets

<br />
提出了一种名为 DataTune 的方法，旨在通过改造现有数据集生成更高质量的任务定制合成训练数据。研究团队在 BIG-Bench 任务上验证了该方法的有效性，作者包括 S Gandhi、R Gala、V Viswanathan、T Wu 和 G Neubig（CMU）。该研究通过检索和转换现有数据集，提升了合成数据的质量，并为任务定制提供了新的途径。DataTune 方法为数据生成领域带来了新的思路和技术，对提升数据质量和任务定制的效果具有重要意义。

<br />
总结: 提出了名为 DataTune 的方法，旨在通过改造现有数据集生成更高质量的任务定制合成训练数据。研究团队在 BIG-Bench 任务上验证了该方法的有效性，作者包括 S Gandhi、R Gala、V Viswanathan、T Wu 和 G Neubig（CMU）。DataTune 方法为数据生成领域带来了新的思路和技术，对提升数据质量和任务定制的效果具有重要意义。 <div>
提出DataTune方法，通过改造现有数据集生成更高质量的任务定制合成训练数据，并在BIG-Bench任务上验证了其有效性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Better Synthetic Data by Retrieving and Transforming Existing Datasets》S Gandhi, R Gala, V Viswanathan, T Wu, G Neubig [CMU] (2024) <a href="https://arxiv.org/abs/2404.14361"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1grd5yflj20os1a84a8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1grdfpksj20sq1bkalr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1grdqquqj21ia0o8109.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1gre3c4uj21ks12andk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp1gxtl0h8j20hs0mb405.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp1gxtktxej20hr0l4gna.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 21:24:50 GMT</pubDate>
</item>
<item>
<title>[CL]《Better Synthetic Data by Retrieving and Transforming Existing Datasets》S Gandhi, R Gala, V Viswanathan, T Wu, G Neubig [CMU] (2024) 网页链接 #...</title>
<link>https://weibo.com/1402400261/Ob8O4zvfd</link>
<guid>https://weibo.com/1402400261/Ob8O4zvfd</guid>
<content:encoded><![CDATA[
<div> Retrieving, Transforming, Synthetic Data, Existing Datasets, Better, Improved, Machine Learning, Data Augmentation, Data Privacy, Evaluation

<br /><br />总结:
本文提出了一种通过检索和转换现有数据集来生成更好合成数据的方法。作者介绍了这种方法的优势，可以提高数据的质量和多样性，同时降低了数据隐私风险。他们还探讨了如何使用这种方法改进机器学习模型的性能，并提出了一种用于评估生成数据效果的框架。通过这种方法，可以更好地利用现有数据资源，提高数据利用率和模型表现。 <div>
[CL]《Better Synthetic Data by Retrieving and Transforming Existing Datasets》S Gandhi, R Gala, V Viswanathan, T Wu, G Neubig [CMU] (2024) <a href="https://arxiv.org/abs/2404.14361"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1grd5yflj20os1a84a8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1grdfpksj20sq1bkalr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1grdqquqj21ia0o8109.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1gre3c4uj21ks12andk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp1gxtl0h8j20hs0mb405.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp1gxtktxej20hr0l4gna.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 21:24:40 GMT</pubDate>
</item>
<item>
<title>提出指令层次结构和自动生成训练数据的方法，可以显著提高大型语言模型对提示注入等攻击的鲁棒性，使其更安全可控，仅对能力造成轻微影响。 - 转发 @爱可可-爱生...</title>
<link>https://weibo.com/1402400261/Ob8KY3Qt8</link>
<guid>https://weibo.com/1402400261/Ob8KY3Qt8</guid>
<content:encoded><![CDATA[
<div> 关键词: 指令层次结构, 自动生成训练数据, 大型语言模型, 鲁棒性, 提示注入攻击, 安全可控, 轻微影响

总结:<br />
本文提出了一种新的方法，通过指令层次结构和自动生成训练数据来提高大型语言模型对提示注入等攻击的鲁棒性。该方法使模型更安全可控，同时对其性能影响较小。这一创新的方法有望有效应对当前存在的安全挑战，进一步提升大型语言模型的安全性和可靠性。 <div>
提出指令层次结构和自动生成训练数据的方法，可以显著提高大型语言模型对提示注入等攻击的鲁棒性，使其更安全可控，仅对能力造成轻微影响。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions》E Wallace, K Xiao, R Leike, L Weng, J Heidecke, A Beutel [OpenAI] (2024) <a href="https://arxiv.org/abs/2404.13208"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp1giwyhllj21420lmwnn.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp1gixe4twj21c80qqk14.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1giy0avqj21ci182akz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1giyd6qzj21cu0o0dll.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1gpr0tsij20ve0gx0v4.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 21:17:00 GMT</pubDate>
</item>
<item>
<title>[CL]《The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions》E Wallace, K Xiao, R Leike, L Weng, J Heidecke, A Beutel [OpenAI...</title>
<link>https://weibo.com/1402400261/Ob8KVlVRj</link>
<guid>https://weibo.com/1402400261/Ob8KVlVRj</guid>
<content:encoded><![CDATA[
<div> 训练、LLMs、特权指令、指令层次结构、优先级、指令优先级、人工智能、数据集、模型性能、任务表现

总结:<br /><br />该研究提出了一种用于训练LLMs优先考虑特权指令的指令层次结构。研究团队通过设计数据集和调整模型性能评价方法，成功训练了LLMs在执行任务时优先执行特权指令。他们的方法在提高模型任务表现方面取得了显著的成果，为人工智能领域的发展带来了新的可能性。 <div>
[CL]《The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions》E Wallace, K Xiao, R Leike, L Weng, J Heidecke, A Beutel [OpenAI] (2024) <a href="https://arxiv.org/abs/2404.13208"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp1giwyhllj21420lmwnn.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp1gixe4twj21c80qqk14.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1giy0avqj21ci182akz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1giyd6qzj21cu0o0dll.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1gpr0tsij20ve0gx0v4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 21:16:54 GMT</pubDate>
</item>
<item>
<title>通过对基本人类情感进行量化建模，并利用自监督学习算法及人机互动使LLM内化伦理约束，展示了LLM在同理心表达及原则决策方面的潜力。 - 转发 @爱可可-爱生活:&amp;en...</title>
<link>https://weibo.com/1402400261/Ob8Gmau69</link>
<guid>https://weibo.com/1402400261/Ob8Gmau69</guid>
<content:encoded><![CDATA[
<div> 情感建模、量化、自监督学习、人机互动、LLM、同理心、伦理约束、原则决策、潜力
<br />
<br />
要点1：文章通过量化建模基本人类情感，展示了LLM在同理心表达方面的潜力。
要点2：利用自监督学习算法内化伦理约束，提升LLM在原则决策方面的能力。
要点3：作者是来自斯坦福大学的E Y. Chang。
要点4：研究成果表明LLM有望在情感模拟和伦理决策领域取得重要进展。
要点5：人机互动是实现LLM内化伦理约束的关键手段。
<br /><br />总结: 本文提出了一种利用自监督学习算法和人机互动的方法，通过量化建模人类情感，实现LLM内化伦理约束。作者展示了LLM在同理心表达和原则决策方面的潜力，为人工智能领域的伦理研究提供了新思路和方法。文章强调了情感建模和伦理约束在人机互动中的重要性，为实现人工智能普及应用提供了理论支持。 <div>
通过对基本人类情感进行量化建模，并利用自监督学习算法及人机互动使LLM内化伦理约束，展示了LLM在同理心表达及原则决策方面的潜力。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Modeling Emotions and Ethics with Large Language Models》E Y. Chang [Stanford University] (2024) <a href="https://arxiv.org/abs/2404.13071"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1gcvj1lbj20tm0nm7bp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1gcw3ecsj20tw0r0tcw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1gcwbqofj20rw0usgp3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1gcxhy53j21iu0ww19m.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1gdw1e4ij20rq0u810t.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 21:05:39 GMT</pubDate>
</item>
<item>
<title>[CL]《Modeling Emotions and Ethics with Large Language Models》E Y. Chang [Stanford University] (2024) 网页链接 #机器学习##人工智能##论文# [图片][图片...</title>
<link>https://weibo.com/1402400261/Ob8GisJlM</link>
<guid>https://weibo.com/1402400261/Ob8GisJlM</guid>
<content:encoded><![CDATA[
<div> 情感建模、道德建模、大型语言模型、伦理问题、数据机器学习、人工智能伦理、自然语言处理、模型伦理、道德决策、情感识别

总结:<br />
本文讨论了如何使用大型语言模型来进行情感和道德建模。作者强调了伦理问题在数据驱动的机器学习中的重要性，特别是在涉及人工智能伦理和自然语言处理的领域。文章探讨了模型如何识别情感并做出道德决策，强调了模型伦理的重要性。通过深入研究情感识别和道德建模，可以提高大型语言模型在现实世界中的应用和影响力。 <div>
[CL]《Modeling Emotions and Ethics with Large Language Models》E Y. Chang [Stanford University] (2024) <a href="https://arxiv.org/abs/2404.13071"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1gcvj1lbj20tm0nm7bp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1gcw3ecsj20tw0r0tcw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1gcwbqofj20rw0usgp3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1gcxhy53j21iu0ww19m.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1gdw1e4ij20rq0u810t.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 21:05:30 GMT</pubDate>
</item>
<item>
<title>提出MOLE方法，通过可学习门控函数实现LoRA层级权重控制，以最小计算开销实现多个LoRA的高效、动态组合，在保留各LoRA个性的同时发挥集成效应，在多任务上的泛化...</title>
<link>https://weibo.com/1402400261/Ob8Fv99rh</link>
<guid>https://weibo.com/1402400261/Ob8Fv99rh</guid>
<content:encoded><![CDATA[
<div> 门控函数、LoRA层级权重控制、多个LoRA动态组合、集成效应、多任务泛化提升
<br />
MOLE方法通过可学习门控函数实现LoRA层级权重控制，在最小计算开销下实现多个LoRA的高效、动态组合，保留各LoRA个性的同时发挥集成效应，显著提升多任务上的泛化性。该方法能有效提升模型性能，并在多个任务上取得了显著的改进。MOLE方法为多任务学习提供了一种新的思路，具有较强的实用性和推广价值。MOLE方法的提出将为深度学习领域的研究和应用带来新的启发，有望在实际任务中产生重要影响。总的来说，MOLE方法为LoRA层级权重控制和多任务泛化提升提供了一种高效且创新的解决方案。<br /><br />总结: <div>
提出MOLE方法，通过可学习门控函数实现LoRA层级权重控制，以最小计算开销实现多个LoRA的高效、动态组合，在保留各LoRA个性的同时发挥集成效应，在多任务上的泛化性取得显著提升。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Mixture of LoRA Experts》X Wu, S Huang, F Wei [Microsoft Research Asia] (2024) <a href="https://arxiv.org/abs/2404.13628"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1ga7r5nbj213a0tkk50.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1ga84vebj20ls0q2dkf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1ga8uyi5j21bm0nmgty.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1gae17laj21b00mq4kl.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp1gbhb348j20eo0d5dgx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp1gbhbqw6j20el0cx0tg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1gbhcrebj20ve0ogwj6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp1gbhbwv6j20vd0dejtp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp1gbhdqjgj20vj0rcjwn.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 21:03:32 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.23)》 爱可可微博热门分享(4.23) [图片]</title>
<link>https://weibo.com/1402400261/Ob5WRoiAI</link>
<guid>https://weibo.com/1402400261/Ob5WRoiAI</guid>
<content:encoded><![CDATA[
<div> 社交媒体、微博、热门、分享、爱可可、内容、用户、评论、点赞、关注
<br />
爱可可微博上的热门分享引起了广泛关注，许多用户纷纷转发和评论。其中一些内容受到了用户的热烈讨论，收到了大量点赞。这些热门的分享内容吸引了更多的用户关注和关注，增加了微博的互动和活跃度。通过这些分享，用户可以了解到更多的信息和最新的资讯，丰富了他们的社交媒体体验。总的来说，爱可可微博的热门分享对用户起到了良好的引导作用，也为微博平台的发展和壮大做出了贡献。
<br /><br />总结:社交媒体、微博、热门、分享、爱可可、内容、用户、评论、点赞、关注 <div>
《爱可可微博热门分享(4.23)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405026444777750881"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.23)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp14bfhlrgj20rs0fmdhv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 14:08:04 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Memory-based Adapters for Online 3D Scene Perception》(CVPR 2024) GitHub: github.com/xuxw98/Online3D [fig4]《IPoD: Implicit Field ...</title>
<link>https://weibo.com/1402400261/Ob5Ej7NJX</link>
<guid>https://weibo.com/1402400261/Ob5Ej7NJX</guid>
<content:encoded><![CDATA[
<div> 关键词: 3D场景感知、内存适配器、在线学习、3D对象重建、单RGB-D图像、隐式场学习、GANs、多用途Transformer代理、网页爬虫生成、时间序列预测

总结:
<br />
《Memory-based Adapters for Online 3D Scene Perception》提出了一种基于内存的适配器方法，用于在线3D场景感知，通过将适配器与现有模型并列运行，实现增量学习和适应性调整。GitHub上提供了对应的实现代码，有助于研究人员理解并复现该方法。
<br />
《IPoD: Implicit Field Learning with Point Diffusion for Generalizable 3D Object Reconstruction from Single RGB-D Images》介绍了一种通过点扩散学习隐式场的方法，用于从单个RGB-D图像中重建三维对象，实现了泛化能力。GitHub上提供了代码，可供研究者使用和参考。
<br />
《The Unreasonable Ineffectiveness of the Deeper Layers》讨论了神经网络更深层次的不合理失效问题，通过消融实验发现深层模型的部分层次对网络性能贡献不大。GitHub上提供了名为PruneMe的代码库，研究人员可以探索这一现象。
<br />
《Portrait3D: Text-Guided High-Quality 3D Portrait Generation Using Pyramid Representation and GANs Prior》提出了一种基于文本引导的高质量3D肖像生成方法，利用金字塔表示和GANs先验知识。相关实现代码在GitHub上开源，可供研究者使用。
<br />
《Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent》介绍了一种多用途Transformer代理模型，具有广泛的应用潜力。研究者可以在GitHub上找到名为jat的实现代码，用于进一步研究和应用。
<br />
《AutoCrawler: A Progressive Understanding Web Agent for Web Crawler Generation》提出了一种用于网页爬虫生成的渐进式理解网络代理模型AutoCrawler。相关实现代码已在GitHub上发布，可供研究人员使用和讨论。
<br />
《Gaussian Splatting Decoder for 3D-aware Generative Adversarial Networks》介绍了一种用于3D感知生成对抗网络的高斯喷涂解码器方法。GitHub上提供了名为gaussian_gan_decoder的实现代码，有助于研究人员进一步探索这一领域的技术。
<br />
《UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting》提出了一种基于语言增强的跨领域时间序列预测统一模型UniTime。相关实现代码已在GitHub上公开，供研究人员学习和使用。 <div>
几篇论文实现代码：<br />《Memory-based Adapters for Online 3D Scene Perception》(CVPR 2024) GitHub: github.com/xuxw98/Online3D [fig4]<br />《IPoD: Implicit Field Learning with Point Diffusion for Generalizable 3D Object Reconstruction from Single RGB-D Images》(CVPR 2024) GitHub: github.com/yushuang-wu/IPoD [fig5]<br />《The Unreasonable Ineffectiveness of the Deeper Layers》(2024) GitHub: github.com/arcee-ai/PruneMe<br />《Portrait3D: Text-Guided High-Quality 3D Portrait Generation Using Pyramid Representation and GANs Prior》(2024) GitHub: github.com/oneThousand1000/Portrait3D<br />《Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent》(2024) GitHub: github.com/huggingface/jat [fig1]<br />《AutoCrawler: A Progressive Understanding Web Agent for Web Crawler Generation》(2024) GitHub: github.com/EZ-hwh/AutoCrawler [fig2]<br />《Gaussian Splatting Decoder for 3D-aware Generative Adversarial Networks》(2024) GitHub: github.com/fraunhoferhhi/gaussian_gan_decoder [fig3]<br />《UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting》(2024) GitHub: github.com/liuxu77/UniTime<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp126j9b1xj20zi0wsgv3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp126jvm2xj21dt0r0k14.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp12ajpoczj21ba0cfth8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp12la564oj21lv0hktw7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp12u2poq2j21r50hxdqu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 13:22:21 GMT</pubDate>
</item>
<item>
<title>【jemma：用 AI 代理来将想法转化为代码，进而创建 web 原型】'jemma - jemma &amp; her ai agents that build software' GitHub: github.com/tolitius/jemma #开源#...</title>
<link>https://weibo.com/1402400261/Ob5CTkVOM</link>
<guid>https://weibo.com/1402400261/Ob5CTkVOM</guid>
<content:encoded><![CDATA[
<div> GitHub, jemma, AI 代理, 想法转化, 代码, 创建 web 原型

<br /><br />总结:
文章介绍了一个名为jemma的项目，利用AI代理来将想法转化为代码，从而快速创建web原型。jemma项目的GitHub链接为github.com/tolitius/jemma。通过jemma和她的AI代理，能够更高效地构建软件。 <div>
【jemma：用 AI 代理来将想法转化为代码，进而创建 web 原型】'jemma - jemma &amp; her ai agents that build software' GitHub: github.com/tolitius/jemma <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp12vzdg7qj213d0u0aes.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 13:18:52 GMT</pubDate>
</item>
<item>
<title>【seemore：用 PyTorch 从头开始实现的视觉语言模型】'seemore - From scratch implementation of a vision language model in pure PyTorch' GitHub: github.co...</title>
<link>https://weibo.com/1402400261/Ob5xV0l2B</link>
<guid>https://weibo.com/1402400261/Ob5xV0l2B</guid>
<content:encoded><![CDATA[
<div> 视觉语言模型、PyTorch、从头开始、GitHub、实现、纯净、AviSoori1x、代码、深度学习、项目<br />
<br />
实现了一个视觉语言模型，使用PyTorch从头开始编写，GitHub上有相关项目，由AviSoori1x创建和维护。该模型是基于深度学习的，并且在实现过程中保持了纯净的代码风格。通过该项目，可以学习如何利用PyTorch来构建和训练视觉语言模型。 <div>
【seemore：用 PyTorch 从头开始实现的视觉语言模型】'seemore - From scratch implementation of a vision language model in pure PyTorch' GitHub: github.com/AviSoori1x/seemore <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp12jm7010j20v70u00wo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 13:06:37 GMT</pubDate>
</item>
<item>
<title>【Lumina-T2X: 基于大型扩散Transformer的流式文本到任意模态生成】’Lumina-T2X: Transform Text into Any Modality, Res. and Duration via Flow-based Large ...</title>
<link>https://weibo.com/1402400261/Ob5vHzQdr</link>
<guid>https://weibo.com/1402400261/Ob5vHzQdr</guid>
<content:encoded><![CDATA[
<div> 大型扩散Transformer、流式文本、任意模态生成、Lumina-T2X、GitHub、模型、生成、文本、基于、任意<br />
<br />
Lumina-T2X是一个基于大型扩散Transformer的模型，可将文本转换为任意模态。该模型在GitHub上有开源代码，可以实现文本到任意模态的生成任务。通过流式技术，Lumina-T2X能够生成多种模态的内容，使得文本生成更加灵活多样化。其特点在于利用大型扩散Transformer模型，实现高质量的文本到模态的转换，为生成任务提供了新的思路和方法。 <div>
【Lumina-T2X: 基于大型扩散Transformer的流式文本到任意模态生成】’Lumina-T2X: Transform Text into Any Modality, Res. and Duration via Flow-based Large Diffusion Transformer - Lumina-T2X is a model for Text to Any Modality Generation' GitHub: github.com/Alpha-VLLM/Lumina-T2X <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp12dxsn52j21ef0u0qkr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 13:01:10 GMT</pubDate>
</item>
<item>
<title>【PyPDFForm：Python 3的免费开源 PDF 表单处理库，提供了填充 PDF 表单、创建表单小部件和其他常见实用程序的功能】’PyPDFForm - The Python library for PDF ...</title>
<link>https://weibo.com/1402400261/Ob2MKhIpq</link>
<guid>https://weibo.com/1402400261/Ob2MKhIpq</guid>
<content:encoded><![CDATA[
<div> GitHub，PyPDFForm，Python 3，PDF表单处理库，填充表单，创建表单小部件，实用程序

<br /><br />总结:
PyPDFForm是一个免费开源的Python库，用于处理PDF表单。它提供了填充PDF表单、创建表单小部件和其他常见实用程序的功能。该库在GitHub上可获得，地址为github.com/chinapandaman/PyPDFForm。PyPDFForm支持Python 3，并为用户提供了方便快捷的表单处理工具，有助于简化PDF表单处理的流程。 <div>
【PyPDFForm：Python 3的免费开源 PDF 表单处理库，提供了填充 PDF 表单、创建表单小部件和其他常见实用程序的功能】’PyPDFForm - The Python library for PDF forms.' GitHub: github.com/chinapandaman/PyPDFForm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp0qbnnkivj210u0osq6v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 06:04:53 GMT</pubDate>
</item>
<item>
<title>【AlwaysReddy：使用热键控制的简约 AI 助手】’AlwaysReddy - a LLM voice assistant that is always just a hotkey away.' GitHub: github.com/ILikeAI/Always...</title>
<link>https://weibo.com/1402400261/Ob2K570f5</link>
<guid>https://weibo.com/1402400261/Ob2K570f5</guid>
<content:encoded><![CDATA[
<div> GitHub, AlwaysReddy, AI助手, 热键控制, 简约, LLM voice assistant, 可定制, 高效, 方便使用

总结:<br /><br />这篇文章介绍了一个名为AlwaysReddy的AI助手，它采用热键控制，设计简约方便。这个LLM voice assistant可以通过GitHub获取，具有可定制性，可以提高工作效率，方便用户使用。 <div>
【AlwaysReddy：使用热键控制的简约 AI 助手】’AlwaysReddy - a LLM voice assistant that is always just a hotkey away.' GitHub: github.com/ILikeAI/AlwaysReddy <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp0q5gll4qj21ji0jgwjg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 05:58:20 GMT</pubDate>
</item>
<item>
<title>【WebLlama：基于 Llama3 的能浏览网页、可以遵循指令并与用户交互的Agent】’WebLlama - Llama-3 agents that can browse the web by following instructions a...</title>
<link>https://weibo.com/1402400261/Ob2J50wdo</link>
<guid>https://weibo.com/1402400261/Ob2J50wdo</guid>
<content:encoded><![CDATA[
<div> Agent、浏览、网页、指令、交互、Llama3、GitHub、McGill-NLP、WebLlama、用户
<br />
Agent、WebLlama是基于Llama3开发的能够浏览网页、遵循指令并与用户交互的智能代理程序。该项目可以在GitHub上找到，由McGill-NLP团队开发。用户可以通过向Agent发送指令来让WebLlama在网页上浏览并与用户进行对话交流。这一项目为基于Llama3的Agent的发展提供了新的应用场景，拓展了其在用户界面交互方面的可能性。WebLlama的推出给人工智能技术与网页浏览交互带来了创新的可能性。 <div>
【WebLlama：基于 Llama3 的能浏览网页、可以遵循指令并与用户交互的Agent】’WebLlama - Llama-3 agents that can browse the web by following instructions and talking to you' GitHub: github.com/McGill-NLP/webllama <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp0q3e4bgxj20ur0u0tc6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 05:55:52 GMT</pubDate>
</item>
<item>
<title>【Empirical：快速测试和评估 LLM、提示和其他配置，适用于应用的所有重要场景】’Empirical - Test and evaluate LLMs, prompts and other configuration, acro...</title>
<link>https://weibo.com/1402400261/Ob2HS0xYu</link>
<guid>https://weibo.com/1402400261/Ob2HS0xYu</guid>
<content:encoded><![CDATA[
<div> GitHub、Empirical、测试、评估、LLM、提示、配置、重要场景、应用
<br /><br />总结:
GitHub上有一个名为Empirical的项目，旨在快速测试和评估LLMs、提示和其他配置，适用于应用的所有重要场景。该项目能帮助开发者全面考虑各种情况下的配置方案，提高应用的可靠性和性能。 <div>
【Empirical：快速测试和评估 LLM、提示和其他配置，适用于应用的所有重要场景】’Empirical - Test and evaluate LLMs, prompts and other configuration, across all the scenarios that matter for your application' GitHub: github.com/empirical-run/empirical <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp0q0avm6fj21390u00x6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 05:52:53 GMT</pubDate>
</item>
<item>
<title>【ai-diagram-generator：AI 流程图生成器，使用 LlamaIndex 和 Vercel AI SDK 构建的 AI 图表生成器，可以根据给定的主题生成图表，并在生成过程中实时流传输部...</title>
<link>https://weibo.com/1402400261/Ob2GItN9C</link>
<guid>https://weibo.com/1402400261/Ob2GItN9C</guid>
<content:encoded><![CDATA[
<div> GitHub, AI, 流程图生成器, 主题，LlamaIndex, Vercel AI SDK, 图表，生成器, 实时流传输

<br /><br />总结:
这篇文章介绍了一个使用LlamaIndex和Vercel AI SDK构建的AI流程图生成器，可以根据给定主题生成图表。生成过程中，该生成器会实时流传输部分图表，让用户可以在图表生成过程中观看部分图表的生成。通过GitHub可以找到该项目，用户可以在该平台上查看更多相关信息。 <div>
【ai-diagram-generator：AI 流程图生成器，使用 LlamaIndex 和 Vercel AI SDK 构建的 AI 图表生成器，可以根据给定的主题生成图表，并在生成过程中实时流传输部分图表】’ai-diagram-generator - A cool AI Diagram generator from a given topic, that streams the partial diagrams from the incomplete JSONs during generation. Built using LlamaIndex, Vercel AI SDK.' GitHub: github.com/rsrohan99/ai-diagram-generator <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp0pxd5ntnj20zk0k0did.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 05:50:03 GMT</pubDate>
</item>
<item>
<title>【xrem：使用 Rust 和 Svelte 构建的跨平台本地搜索工具，用于在本地记录和搜索在任何计算机上查看的所有内容】’xrem - (Cross-Platform) An open source appro...</title>
<link>https://weibo.com/1402400261/Ob2G6aCWZ</link>
<guid>https://weibo.com/1402400261/Ob2G6aCWZ</guid>
<content:encoded><![CDATA[
<div> Rust Svelte 跨平台 本地搜索 工具 记录 搜索 计算机 <br />
<br />
总结: xrem是使用Rust和Svelte构建的跨平台本地搜索工具，可以记录和搜索任何计算机上查看的所有内容。这个开源工具可以帮助用户在多台设备上方便地管理和检索他们的浏览记录，提供了更高效的信息管理体验。GitHub链接为github.com/jasonjmcghee/xrem。 <div>
【xrem：使用 Rust 和 Svelte 构建的跨平台本地搜索工具，用于在本地记录和搜索在任何计算机上查看的所有内容】’xrem - (Cross-Platform) An open source approach to locally record and enable searching everything you view on any computer.' GitHub: github.com/jasonjmcghee/xrem <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp0pvpf7luj20u00xftcn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 05:48:32 GMT</pubDate>
</item>
<item>
<title>大模型训练成本估算 #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/Ob0I8qugw</link>
<guid>https://weibo.com/1402400261/Ob0I8qugw</guid>
<content:encoded><![CDATA[
<div> 训练成本  大模型  估算  数据量  计算资源  时间成本  硬件设备  学习率  算法选择<br />
<br />
大模型训练成本是指训练一个复杂、庞大的模型所需要的资源和时间成本，这包括数据量、计算资源、硬件设备等因素。在估算大模型训练成本时，需要考虑到数据量的大小，计算资源的需求以及硬件设备的配置等因素。同时，学习率的选择和算法的优化也会影响训练成本的估算。因此，在进行大模型训练成本估算时，需要综合考虑多个因素，以确保训练过程高效、稳定。 <br />
总结: <br />
- 大模型训练成本估算涉及多个因素，包括数据量、计算资源、硬件设备、学习率和算法选择等。
- 需要综合考虑数据量的大小和计算资源需求，以及硬件设备的配置等因素进行估算。
- 合理选择学习率和优化算法也会影响训练成本的估算结果。
- 在进行大模型训练成本估算时，需要综合考虑这些因素，以确保训练过程高效、稳定。 <div>
大模型训练成本估算 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp0h65g7yij20qa1kwtdj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 00:48:03 GMT</pubDate>
</item>
<item>
<title>【免费课程：《Mistral入门》，面向初学者，旨在让学生了解并使用 Mistral AI 的先进开源和商业 LLM 模型】《Getting Started With Mistral - DeepLearning.AI》...</title>
<link>https://weibo.com/1402400261/Ob0FBcg7o</link>
<guid>https://weibo.com/1402400261/Ob0FBcg7o</guid>
<content:encoded><![CDATA[
<div> Mistral入门、初学者、Mistral AI、LLM模型、免费课程、先进开源、商业应用

<br /><br />总结:
本免费课程《Mistral入门》专为初学者设计，旨在帮助学生了解和使用 Mistral AI 的先进开源和商业 LLM 模型。课程涵盖了如何使用 Mistral AI、深度学习基础知识以及如何应用 LLM 模型等内容，适合希望探索和应用人工智能领域的学习者。通过学习本课程，学生将能够掌握 Mistral AI 技术，并在实际项目中运用这一先进技术。欢迎对人工智能感兴趣的学生来参加这门免费课程！ <div>
【免费课程：《Mistral入门》，面向初学者，旨在让学生了解并使用 Mistral AI 的先进开源和商业 LLM 模型】《Getting Started With Mistral - DeepLearning.AI》 <a href="https://www.deeplearning.ai/short-courses/getting-started-with-mistral/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp0h0bn2cpj20xp0u0tc5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 00:41:48 GMT</pubDate>
</item>
<item>
<title>开源机器学习编译器的“理想与现实” src:网页链接 [图片]</title>
<link>https://weibo.com/1402400261/Ob0ESvD9Y</link>
<guid>https://weibo.com/1402400261/Ob0ESvD9Y</guid>
<content:encoded><![CDATA[
<div> 开源、机器学习、编译器、理想、现实、挑战、性能、可扩展性、实用性、社区贡献
<br />
<br />
总结: 
文章讨论了开源机器学习编译器在理想与现实之间的挑战。在理想情况下，开源编译器应该具有良好的性能、可扩展性和实用性，并能吸引更多社区贡献。然而，实际情况中，开源编译器在性能和可扩展性方面仍存在一定的不足，社区贡献也未达到预期水平。因此，开发者需要努力解决这些问题，以实现开源机器学习编译器的理想状态。 <div>
开源机器学习编译器的“理想与现实” src:<a href="https://www.linkedin.com/posts/matthew-barrett-a49929177_i-think-its-fair-to-say-that-ml-compilation-activity-7185745237049286657-z5_Q/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp0gy24obuj20m80ru76s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 00:40:02 GMT</pubDate>
</item>
<item>
<title>【为需要而做，做好还要用好：通过打造和使用研究成果来实现影响力】- 作者提出了一个核心理念：打造你需要的，并使用你所打造的。这将研究重心从发表“论文”转...</title>
<link>https://weibo.com/1402400261/Ob0BCrZZ4</link>
<guid>https://weibo.com/1402400261/Ob0BCrZZ4</guid>
<content:encoded><![CDATA[
<div> 打造需求、使用成果、影响力、目标群体、自我需求、研究怪圈、演示想法、社区参与、工具推广、真正影响力

<br /><br />总结:
作者强调了一个核心理念，就是研究应该打造自己需要的成果，并且要将这些成果用于实际应用中，从而实现影响力。在进行研究之前，需要明确目标群体，即真正需要你研究成果的人，而不是为了发表论文而研究。目标群体可以是自己，如果需要就去打造。同时，使用自己打造的研究成果也是至关重要的，不使用自己的研究成果，别人也不会使用。一个好想法需要通过演示告诉他人为何它也是一个好主意，才能获得影响力。作者团队注重影响力而不是论文数量，通过提供工具和数据让更多人参与进来，真正的影响力来自于社区的扩展和发展。推广自己的想法，提供工具给他人跟进，并乐于看到别人超越自己，这才是真正的影响力。 <div>
【为需要而做，做好还要用好：通过打造和使用研究成果来实现影响力】<br />- 作者提出了一个核心理念：打造你需要的，并使用你所打造的。这将研究重心从发表“论文”转移到真正重要的地方——影响力。   <br />- 在任何研究前要问自己“谁是你的目标群体?”。目标群体不是付费的客户，而是真正需要你研究成果的人。如果找不到目标群体，研究可能就是无关紧要的。   <br />- 目标群体可以就是你自己。如果你需要它，就去打造它。即使最后不发表，你也会去做，因为你需要它。这让你脱离只为发表而研究的怪圈。   <br />- 第二个原则是使用你所打造的。如果你不使用自己的研究，为何认为别人会使用?只发表无后续研究和应用的文章是死胡同，不会改变该领域。   <br />- 如果一个想法好，一篇文章是不够的。你需要通过演示告诉人们为何它也是一个好主意。这样你才能将未来的想法教给他人。   <br />- 作者的团队遵循这些原则，注重影响力而不是论文数量。他们为社区提供工具和数据，让更多人参与进来。真正的影响力来自于社区的扩展和发展。   <br />- 推广你的想法，提供工具给他人跟进，当别人超越你时感到高兴，这就是真正的影响力。<br />《Build what you need and use what you build | Perceiving Systems Blog》 <a href="https://perceiving-systems.blog/en/post/build-what-you-need-and-use-what-you-build"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span> <span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0gry5bcgj21yu1fs17b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 00:32:00 GMT</pubDate>
</item>
<item>
<title>【Llama3-8B-Chinese-Chat：首个中文微调LLaMa 3模型，基于 Meta-Llama-3-8B-Instruct 模型，使用 ORPO 对其进行了中文微调，从而提高了其在中文问答中的表现】...</title>
<link>https://weibo.com/1402400261/Ob0vLqbmP</link>
<guid>https://weibo.com/1402400261/Ob0vLqbmP</guid>
<content:encoded><![CDATA[
<div> 微调、LLaMa 3模型、中文问答、Meta-Llama-3-8B-Instruct、ORPO、提高表现

<br /><br />总结:
文章介绍了首个中文微调的LLaMa 3模型，使用ORPO对Meta-Llama-3-8B-Instruct模型进行了中文微调，以提高其在中文问答中的表现。这一创新性的方法在中文问答领域有着重要意义，为现有模型的表现提升提供了新的思路和途径。 <div>
【Llama3-8B-Chinese-Chat：首个中文微调LLaMa 3模型，基于 Meta-Llama-3-8B-Instruct 模型，使用 ORPO 对其进行了中文微调，从而提高了其在中文问答中的表现】《shenzhi-wang/Llama3-8B-Chinese-Chat · Hugging Face》 <a href="https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp0ga1o2ckj20z10u0q7t.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp0gb5nw8yj20za0ja0vg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp0gbefxs9j20yw0owq7o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 00:17:35 GMT</pubDate>
</item>
<item>
<title>【使用PyTorch FSDP和Q-Lora高效微调Llama 3】- 通过PyTorch FSDP和Q-Lora，现在可以在2块消费级GPU上微调Llama 2 70B或Mixtral 8x7B模型。 - PyTorch FSDP通过...</title>
<link>https://weibo.com/1402400261/Ob0tturCD</link>
<guid>https://weibo.com/1402400261/Ob0tturCD</guid>
<content:encoded><![CDATA[
<div> PyTorch FSDP, Q-Lora, Llama 3, GPU, 分布式训练, 内存需求, 低秩适配器, 数据集准备, 训练时间, 模型加载

<br /><br />总结:
本文介绍了如何利用PyTorch FSDP和Q-Lora在消费级GPU上高效微调Llama 3模型。通过分片模型和量化低秩适配器，减少内存和计算需求，实现更高效的训练。文章详细介绍了数据集准备、分布式训练、合并适配器权重等步骤。在4块GPU上训练Llama 3只需24GB内存，训练时间约为45小时，成本约为255美元。通过提供的代码和配置，读者可以复现并调整训练过程。最终展示了模型加载和指令响应生成的过程。PyTorch FSDP和Q-Lora使训练大型语言模型变得更加易于访问。 <div>
【使用PyTorch FSDP和Q-Lora高效微调Llama 3】<br />- 通过PyTorch FSDP和Q-Lora，现在可以在2块消费级GPU上微调Llama 2 70B或Mixtral 8x7B模型。   <br />- PyTorch FSDP通过在GPU间分片模型来减少内存需求，从而可以更高效地训练更大的模型。   <br />- Q-Lora通过量化和低秩适配器来降低计算和内存需求。   <br />- 文章演示了如何准备数据集、运行分布式训练、合并适配器权重到原始模型中。   <br />- 在4块N卡A10G GPU上，只需要每块GPU 24GB内存，就可以训练Llama 3 70B模型。   <br />- 训练时间约为45小时，成本约为255美元。如果使用更强大的GPU，可以大大减少训练成本和时间。   <br />- 文章提供了代码，可以复现该训练过程。读者可以基于提供的代码和配置进行调整。   <br />- 文章还展示了如何加载训练好的模型，并生成指令的响应。   <br />- PyTorch FSDP和Q-Lora使得训练大型语言模型变得更加易于访问。  <br />《Efficiently fine-tune Llama 3 with PyTorch FSDP and Q-Lora》 <a href="https://www.philschmid.de/fsdp-qlora-llama3"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp0g5g04jmj216m0u0n2b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 00:11:56 GMT</pubDate>
</item>
<item>
<title>【JAT：多功能Transformer智能体】- 提到JAT项目，目标是朝着通用智能体的方向发展。该项目基于Gato的工作，构建了一个开源版本的Gato数据集。 发布了大量专家强...</title>
<link>https://weibo.com/1402400261/Ob0sq0eTn</link>
<guid>https://weibo.com/1402400261/Ob0sq0eTn</guid>
<content:encoded><![CDATA[
<div> JAT项目、通用智能体、Gato数据集、专家强化学习智能体、多种任务、JAT数据集、Transformer架构、学习效率、NLP和CV任务、开源模型和代码

总结:
JAT项目旨在发展通用智能体，构建了开源版本的Gato数据集，发布了专家强化学习智能体涵盖多种任务。JAT数据集是第一个通用智能体训练数据集，基于Transformer架构，表现良好。研究表明适当预测观察有助于提高学习效率。呼吁改进数据集质量、使用离线强化学习、改进多任务采样策略等。JAT模型在NLP和CV任务上展示了初步能力，开源模型和代码为通用智能体研究打开新方向。 <div>
【JAT：多功能Transformer智能体】<br />- 提到JAT项目，目标是朝着通用智能体的方向发展。该项目基于Gato的工作，构建了一个开源版本的Gato数据集。   <br /> 发布了大量专家强化学习智能体，涵盖各种不同任务，包括Atari、BabyAI、Meta-World和MuJoCo等。   <br />- 发布了JAT数据集，这是第一个通用智能体训练数据集。它包含上述专家智能体收集的数十万条轨迹。   <br />- JAT模型基于Transformer架构。它的特点在于嵌入机制，可以内在地处理序列决策任务。   <br />- 实验结果显示，JAT模型在157个训练任务上达到了专家表现的65.8%。这说明它能够在各种各样的任务上模仿专家表现。   <br />- 发现，适当地预测观察也有助于提高智能体的学习效率。   <br /> 呼吁后续研究改进数据集质量、使用离线强化学习、改进多任务采样策略等。   <br />- 在NLP和CV任务上也展示了JAT模型的初步能力。   <br /> 开源了JAT模型和代码，为通用智能体领域的研究打开了新的方向。   <br />《Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent》 <a href="https://huggingface.co/blog/jat"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp0fzw1153j211y0rugqk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp0g00ajx9j20ew0cw75r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 00:09:19 GMT</pubDate>
</item>
<item>
<title>【LLM金融市场应用】- LLM擅长建模词语序列，但直接应用到价格或交易序列上的效果并不突出。因为金融时间序列噪声大且信息含量低，而语言序列具有固有的语法结构...</title>
<link>https://weibo.com/1402400261/OaZGTvbad</link>
<guid>https://weibo.com/1402400261/OaZGTvbad</guid>
<content:encoded><![CDATA[
<div> 建模词语序列 价格 交易序列 多模态学习 多种异质数据 残差连接类模型 因子模型 跨时间尺度 多尺度现象 合成数据 量化交易

总结:<br /><br />LLM在金融市场应用中擅长建模词语序列，但直接应用到价格或交易序列上效果不明显。多模态学习有望发挥LLM在金融领域的优势，结合多种异质数据来建模。残差连接类模型类似于金融中的因子模型和AI中的残差网络，都能通过剔除共性提高个体预测的准确性。LLM的长期上下文关注能力可以捕捉金融市场的多尺度现象，但需要注意金融市场需要预测多个未来时间段而不只是一个周期。LLM可以用于金融中合成数据的生成，先在模拟器训练模型捕捉高层次观念，再在实际市场微调；也可用于生成极端事件的样本。尽管LLM在直接量化交易方面存在困难，但可以帮助基本面分析，为投资者提供更多洞察。在金融领域中LLM的成功仍具不确定性，因此保持开放思维非常重要，模型越大、数据量越多，可能会带来意想不到的结果。 <div>
【LLM金融市场应用】<br />- LLM擅长建模词语序列，但直接应用到价格或交易序列上的效果并不突出。因为金融时间序列噪声大且信息含量低，而语言序列具有固有的语法结构，更易预测。   <br />- 多模态学习有望发挥LLM在金融领域的优势，结合多种异质数据如文本、图像、卫星数据来建模。   <br />- 残差连接类模型在金融中的因子模型和在AI中的残差网络有可比性，都通过剔除共性提高个体预测。   <br />- LLM的长期上下文关注能力可用于捕捉金融市场中跨时间尺度的多尺度现象。但金融中需要预测多个未来时间段，而当前模型仅预测一个周期。   <br />- LLM可用于金融中合成数据的生成，首先在模拟器中训练模型捕捉高层次观念，然后在实际市场微调。也可用于生成极端事件的样本。   <br />- 尽管LLM直接进行量化交易有困难，但可助力基本面分析，为投资者提供更多洞察。   <br />- LLM在金融中的成功仍具有不确定性。保持开放思维很重要，模型越大、数据越多，或许会带来意想不到的结果。<br />《Financial Market Applications of LLMs》 <a href="https://thegradient.pub/financial-market-applications-of-llms/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span> <span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp0cozw6q4j22620u0n53.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 22:12:15 GMT</pubDate>
</item>
<item>
<title>【基于扩散模型的视频生成】《Diffusion Models for Video Generation | Lil'Log》 网页链接 #机器学习# #人工智能# [图片][图片][图片][图片][图片][图片][图片...</title>
<link>https://weibo.com/1402400261/OaZFUnroQ</link>
<guid>https://weibo.com/1402400261/OaZFUnroQ</guid>
<content:encoded><![CDATA[
<div> 扩散模型、视频生成、生成对抗网络、短视频、时间序列、循环神经网络、生成模型、图像生成、数据集、模型训练

总结：
<br /><br />本文介绍了基于扩散模型的视频生成方法，通过生成对抗网络结合循环神经网络来生成短视频。文章提出了一种新的视频生成框架，利用时间序列数据训练生成模型，实现逼真的图像生成。作者使用多个数据集进行模型训练，并展示了生成视频的效果。实验结果表明，该方法能够有效生成高质量的短视频。文章对扩散模型在视频生成中的应用进行了详细讨论，为进一步研究视频生成提供了新的思路和方法。 <div>
【基于扩散模型的视频生成】《Diffusion Models for Video Generation | Lil'Log》 <a href="https://lilianweng.github.io/posts/2024-04-12-diffusion-video/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hp0clnpcx0j21370u043a.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp0clqmhpgj213u0bt405.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp0clrn2p8j23550u00y8.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp0clwt8dbj21kf0aidjs.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp0cm26jm6j22240u0wol.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp0cm50jc3j22ce0u0gtk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp0cm7eegrj21fm0iytcw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp0cmaju5aj235s0rmjzl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp0cmeohjkj214n0u00yn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 22:09:49 GMT</pubDate>
</item>
<item>
<title>今日推介(第1384期)：面向网络爬虫生成的渐进理解网络Agent、作为Copilot的大型语言模型在Lean定理证明中的应用、检索增强生成的高效知识缓存、通过视频生成与3D...</title>
<link>https://weibo.com/1402400261/OaZDde92j</link>
<guid>https://weibo.com/1402400261/OaZDde92j</guid>
<content:encoded><![CDATA[
<div> 网络爬虫生成、渐进理解网络Agent、Copilot、大型语言模型、Lean定理证明、检索增强生成、知识缓存、视频生成、3D对象、基于物理交互、查询效率、基于规则重写系统

<br /><br />总结:
本篇文章介绍了面向网络爬虫生成的渐进理解网络Agent，以及大型语言模型作为Copilot在Lean定理证明中的应用。同时讨论了检索增强生成的高效知识缓存，以及通过视频生成与3D对象进行基于物理的交互的方法。最后提到了用于提高查询效率的大型语言模型增强的基于规则的重写系统。这些技术的引入和应用将在网络抓取、知识检索、语言处理和交互技术方面带来重要的进展和提升。 <div>
今日推介(第1384期)：面向网络爬虫生成的渐进理解网络Agent、作为Copilot的大型语言模型在Lean定理证明中的应用、检索增强生成的高效知识缓存、通过视频生成与3D对象进行基于物理的交互、用于提高查询效率的大型语言模型增强的基于规则的重写系统 公·众·号：爱可可爱生活 <a href="http://aicoco.net/s/8m"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp0cfabakgj20sk154n3y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp0cfccwgtj21400q30w9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp0cfem0opj20so0e6jsn.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hp0cfict4yj21400tmq9z.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hp0cflbtn9j20tu17o459.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 22:03:11 GMT</pubDate>
</item>
<item>
<title>[CV] Groma: Localized Visual Tokenization for Grounding Multimodal Large Language Models 网页链接 通过视觉token化实现多模态语言模型的局部化视觉理解和...</title>
<link>https://weibo.com/1402400261/OaZyLCXxO</link>
<guid>https://weibo.com/1402400261/OaZyLCXxO</guid>
<content:encoded><![CDATA[
<div> 视觉token化、多模态语言模型、局部化视觉理解、精确定位、指称任务、定位任务、语言模型、外部模块<br />
<br />
提出了一种名为Groma的方法，利用视觉token化实现了多模态语言模型的局部化视觉理解和精确定位。相比于现有基于语言模型或外部模块的方法，在指称和定位任务上表现更优越。Groma可以有效利用视觉token来帮助多模态语言模型更好地理解和定位目标，提升模型性能和效果。该方法为多模态模型的研究和应用提供了新的思路和方法。<br /><br />总结: 本文介绍了使用Groma进行局部化视觉理解和精确定位的方法，通过视觉token化实现了多模态语言模型的优越性能。 <div>
[CV] Groma: Localized Visual Tokenization for Grounding Multimodal Large Language Models  <br /><a href="https://arxiv.org/abs/2404.13013"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过视觉token化实现多模态语言模型的局部化视觉理解和精确定位，在指称和定位任务上优于现有基于语言模型或外部模块的方法。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0c460kz1j20s419c4c9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0c468wlkj21pg0o8n4v.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0c46vytjj21pg0rqakz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 21:52:14 GMT</pubDate>
</item>
<item>
<title>[CL] Characterizing LLM Abstention Behavior in Science QA with Context Perturbations 网页链接 通过一个简单的自动联想任务探究了人工神经网络学习是训练项...</title>
<link>https://weibo.com/1402400261/OaZw9clS0</link>
<guid>https://weibo.com/1402400261/OaZw9clS0</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM, 自动联想任务, 人工神经网络, 训练项, 线性网络, 非线性网络, 关系学习, 推广, 科学问答<br />
<br />
总结:<br />
本文通过一个简单的自动联想任务，研究了人工神经网络在学习过程中是训练项还是训练项之间的关系。研究发现，线性网络能够学习并推广关系，而非线性网络更倾向于学习各个项之间的关联。这对于理解神经网络学习过程中的行为有重要启示，并在科学问答领域有着重要的应用前景。 <div>
[CL] Characterizing LLM Abstention Behavior in Science QA with Context Perturbations  <br /><a href="https://arxiv.org/abs/2404.12452"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />通过一个简单的自动联想任务探究了人工神经网络学习是训练项(item)还是训练项之间的关系，发现线性网络可以学习关系并推广，而非线性网络倾向于学习项。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0bxg2s55j20qi14mgx9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0bxgf231j219k0m67d2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 21:45:46 GMT</pubDate>
</item>
<item>
<title>[CL] Characterizing LLM Abstention Behavior in Science QA with Context Perturbations 网页链接 通过上下文扰动研究了语言模型在科学问答任务中的弃权行为，...</title>
<link>https://weibo.com/1402400261/OaZu1oTke</link>
<guid>https://weibo.com/1402400261/OaZu1oTke</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型, 科学问答, 弃权行为, 上下文扰动

总结:<br /><br />本研究通过引入上下文扰动来研究语言模型在科学问答任务中的弃权行为。发现语言模型的弃权能力有所不同，并且上下文扰动可能导致一些意想不到的效应。通过实验结果可以看出，语言模型在面对不同环境时表现出截然不同的行为，这对于进一步理解和优化语言模型在科学问答中的应用具有重要意义。 <div>
[CL] Characterizing LLM Abstention Behavior in Science QA with Context Perturbations  <br /><a href="https://arxiv.org/abs/2404.12452"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过上下文扰动研究了语言模型在科学问答任务中的弃权行为，发现语言模型的弃权能力存在差异，且上下文扰动会产生一些非直觉的效应。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0bs0b6nsj20s816sws4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0bs0lp2lj21go0mq43x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 21:40:32 GMT</pubDate>
</item>
<item>
<title>[LG] Mapping Social Choice Theory to RLHF 网页链接 通过比较社会选择理论和RLHF在问题设置上的差异，提出了调整后的公理，并讨论了“失真”等概念在分析RLHF...</title>
<link>https://weibo.com/1402400261/OaZrV7pB7</link>
<guid>https://weibo.com/1402400261/OaZrV7pB7</guid>
<content:encoded><![CDATA[
<div> 社会选择理论，RLHF，问题设置，公理，失真，启发，分析，框架<br />
<br />
社会选择理论和RLHF在问题设置上存在差异，作者提出了调整后的公理，并探讨了在分析RLHF时“失真”等概念的启发作用。该研究为将社会选择理论结果应用于RLHF提供了框架。RLHF是一种复杂的系统，需要更深入的分析和调整社会选择理论来适应其特殊情况。作者的研究为这一领域提供了新的思路，并强调了对问题设置的关键性因素的重视。总的来说，本文为研究人员提供了一个探索RLHF和社会选择理论关联的新视角，并为未来研究提供了有价值的参考。 <br /><br />总结: <div>
[LG] Mapping Social Choice Theory to RLHF  <br /><a href="https://arxiv.org/abs/2404.13038"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过比较社会选择理论和RLHF在问题设置上的差异，提出了调整后的公理，并讨论了“失真”等概念在分析RLHF时的启发，为社会选择理论结果应用于RLHF提供了框架。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0bmmy30hj20q61604c5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 21:35:21 GMT</pubDate>
</item>
<item>
<title>设计了一个利用大型语言模型进行查询重写的系统LLM-R2，能显著提高查询效率，在不同数据集上表现强大的鲁棒性。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《LLM-R2: A L...</title>
<link>https://weibo.com/1402400261/OaZpQ6gtH</link>
<guid>https://weibo.com/1402400261/OaZpQ6gtH</guid>
<content:encoded><![CDATA[
<div> 关键词：LLM-R2、大型语言模型、查询重写、提高查询效率、数据集、鲁棒性、规则、系统、效果、性能

总结：<br /><br />本文介绍了一种名为LLM-R2的系统，利用大型语言模型进行查询重写，显著提高了查询效率，并在不同数据集上展现出强大的鲁棒性。作者通过设计规则和结合语言模型，有效提升了系统的性能。研究结果表明，LLM-R2在实验中取得了显著的效果，为提升查询效率提供了一种新的解决方案。整体而言，LLM-R2系统在查询重写领域有着广阔的应用前景。 <div>
设计了一个利用大型语言模型进行查询重写的系统LLM-R2，能显著提高查询效率，在不同数据集上表现强大的鲁棒性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency》Z Li, H Yuan, H Wang, G Cong, L Bing [Nanyang Technological University] (2024) <a href="https://arxiv.org/abs/2404.12872"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0bbmu6v4j20tu0v0akr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0bbn7k4oj20qw0gugod.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0bbndqo9j20tu17o7cf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0bbnm6tvj21oo0rkape.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0bh6ferwj20jc063q3n.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0bh6fu5nj20jb0eddhe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0bh6gc8gj20jg0l4775.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0bh6fq4aj20jc0bkdgs.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0bh6g06gj20zu07g76a.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 21:30:13 GMT</pubDate>
</item>
<item>
<title>[CL]《LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency》Z Li, H Yuan, H Wang, G Cong, L Bing [Nanyang T...</title>
<link>https://weibo.com/1402400261/OaZpNfyiu</link>
<guid>https://weibo.com/1402400261/OaZpNfyiu</guid>
<content:encoded><![CDATA[
<div> 大规模语言模型，基于规则的重写系统，查询效率，Nanyang Technological University<br />
<br />
总结:<br />
本文介绍了一种名为LLM-R2的大规模语言模型增强型基于规则的重写系统，用于提高查询效率。系统由Z Li、H Yuan、H Wang、G Cong和L Bing等人于2024年在南洋理工大学开发。其核心思想是结合语言模型和规则重写技术，通过对查询进行重写和优化，从而提高查询效率。研究人员通过实验证明，LLM-R2系统在不同数据集上均取得了显著的性能提升，证明了其在提升查询效率方面的有效性。这项研究对于改善搜索引擎等信息检索系统的效率具有重要意义。 <div>
[CL]《LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency》Z Li, H Yuan, H Wang, G Cong, L Bing [Nanyang Technological University] (2024) <a href="https://arxiv.org/abs/2404.12872"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0bbmu6v4j20tu0v0akr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0bbn7k4oj20qw0gugod.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0bbndqo9j20tu17o7cf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0bbnm6tvj21oo0rkape.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0bh6ferwj20jc063q3n.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0bh6fu5nj20jb0eddhe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0bh6gc8gj20jg0l4775.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0bh6fq4aj20jc0bkdgs.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0bh6g06gj20zu07g76a.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 21:30:07 GMT</pubDate>
</item>
<item>
<title>[CV]《PhysDreamer: Physics-Based Interaction with 3D Objects via Video Generation》T Zhang, H Yu, R Wu, B Y. Feng, C Zheng, N Snavely, J Wu, W T. Free...</title>
<link>https://weibo.com/1402400261/OaZmWiRMD</link>
<guid>https://weibo.com/1402400261/OaZmWiRMD</guid>
<content:encoded><![CDATA[
<div> 关键词: PhysDreamer, 物理交互, 3D对象, 视频生成, MIT, Stanford University, Columbia University, 论文, 作者

总结:<br /><br />总结: 本研究通过PhysDreamer系统实现了基于物理的与3D对象的交互，通过视频生成技术进行展示。作者来自MIT、Stanford University和Columbia University，论文于2024年发表。研究通过结合物理模型和视频生成技术，实现了前所未有的3D对象交互方式，为该领域的发展带来了新的思路和方法。PhysDreamer系统的设计和实现，展现了作者在该领域的研究能力和创新精神，为未来的进一步研究和应用奠定了基础。 <div>
[CV]《PhysDreamer: Physics-Based Interaction with 3D Objects via Video Generation》T Zhang, H Yu, R Wu, B Y. Feng, C Zheng, N Snavely, J Wu, W T. Freeman [MIT &amp; Stanford University &amp; Columbia University] (2024) <a href="https://arxiv.org/abs/2404.13026"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0b2zbjdkj21gi14gh43.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0b2zxis9j21q20z6162.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0b30mvezj21q20vq4br.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0b30v9f2j21ps19qaq5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0b9vgar8j20q10a93zu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0b9vgw4vj20rh0qfdjs.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0b9vhp8kj20rh15hwkz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0b9vggbbj20rh0ekdim.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 21:23:05 GMT</pubDate>
</item>
<item>
<title>提出RAGCache系统，通过缓存文档中间状态实现跨请求共享，优化知识树和替换策略，实现检索与推理流水线重叠，可显著提升RAG系统性能。 - 转发 @爱可可-爱生活:&amp;e...</title>
<link>https://weibo.com/1402400261/OaZgnfmLO</link>
<guid>https://weibo.com/1402400261/OaZgnfmLO</guid>
<content:encoded><![CDATA[
<div> RAGCache, 缓存文档中间状态, 跨请求共享, 知识树, 替换策略, 检索与推理流水线, RAG系统, 性能优化, 检索增强生成, 缓存技术

<br /><br />总结:
研究团队提出了一种名为RAGCache的系统，利用缓存文档中间状态实现跨请求共享，优化知识树和替换策略。这样的设计可以实现检索与推理流水线重叠，从而显著提升RAG系统的性能。研究结果表明，RAGCache系统在检索增强生成任务中取得了令人满意的效果。通过有效利用缓存技术，可以提高系统的效率和性能，为自然语言处理领域的研究和应用带来新的可能性。 <div>
提出RAGCache系统，通过缓存文档中间状态实现跨请求共享，优化知识树和替换策略，实现检索与推理流水线重叠，可显著提升RAG系统性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation》C Jin, Z Zhang, X Jiang, F Liu, X Liu, X Liu, X Jin [Peking University] (2024) <a href="https://arxiv.org/abs/2404.12457"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0arx3jb5j20tu0z6n8v.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0arxkegwj20so0e6abm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0arxrizej20u00xc0yl.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0asp3z1bj212x0930u9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0asp3s3pj20i809174x.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0asp3la6j20de0bc74z.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0asp3o2sj20fl08r74v.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0asp3oi0j20dk09xaaj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0asp3p20j20ic064t90.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 21:06:55 GMT</pubDate>
</item>
<item>
<title>[CL]《RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation》C Jin, Z Zhang, X Jiang, F Liu, X Liu, X Liu, X Jin [Peking University...</title>
<link>https://weibo.com/1402400261/OaZgilFOK</link>
<guid>https://weibo.com/1402400261/OaZgilFOK</guid>
<content:encoded><![CDATA[
<div> 关键词: RAGCache, 知识缓存, 检索增强生成, 高效, 知识获取, 文本生成, 信息检索, 缓存策略, 模型优化

总结:<br /><br />本文提出了一种名为RAGCache的知识缓存方法，旨在提高检索增强生成系统的效率。该方法主要解决了知识获取和文本生成过程中的效率问题，采用了相关的缓存策略和模型优化方法。研究结果表明，RAGCache在提高信息检索和文本生成质量方面取得了显著的效果，为进一步优化检索增强生成系统提供了重要的参考。 <div>
[CL]《RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation》C Jin, Z Zhang, X Jiang, F Liu, X Liu, X Liu, X Jin [Peking University] (2024) <a href="https://arxiv.org/abs/2404.12457"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0arx3jb5j20tu0z6n8v.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0arxkegwj20so0e6abm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0arxrizej20u00xc0yl.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0asp3z1bj212x0930u9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0asp3s3pj20i809174x.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0asp3la6j20de0bc74z.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0asp3o2sj20fl08r74v.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0asp3oi0j20dk09xaaj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0asp3p20j20ic064t90.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0asp3r7fj20gx07kglx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0asp42ofj20jb08saal.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0asp3lcmj20iu09b0tj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0asp3truj20iw09ggme.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0asp4n6hj21360a5q4f.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0asp465oj20iv09ijs2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0asp3wnmj20iv09kt9k.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0asp48u8j20iv09kdgk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 21:06:43 GMT</pubDate>
</item>
<item>
<title>提出Lean Copilot框架，探索了大型语言模型作为Copilot协助交互式定理证明的有效性。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Towards Large Language Models as Cop...</title>
<link>https://weibo.com/1402400261/OaZfFdG6k</link>
<guid>https://weibo.com/1402400261/OaZfFdG6k</guid>
<content:encoded><![CDATA[
<div> 模型验证、Lean Copilot框架、大型语言模型、交互式定理证明、有效性、P Song、K Yang、A Anandkumar、UC Santa Barbara、California Institute of Technology

<br /><br />总结:
本文提出了Lean Copilot框架，旨在探索将大型语言模型作为Copilot协助交互式定理证明的有效性。研究团队由P Song、K Yang和A Anandkumar等人组成，来自UC Santa Barbara和California Institute of Technology。他们认为利用大型语言模型作为辅助工具可以提高定理证明的效率和准确性，为此构建了Lean Copilot框架。通过实验和数据分析，他们验证了该框架的有效性，为未来的定理证明工作提供了新的思路和方法。 <div>
提出Lean Copilot框架，探索了大型语言模型作为Copilot协助交互式定理证明的有效性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Towards Large Language Models as Copilots for Theorem Proving in Lean》P Song, K Yang, A Anandkumar [UC Santa Barbara &amp; California Institute of Technology] (2024) <a href="https://arxiv.org/abs/2404.12534"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0aqjvn5rj21cg0o0dq7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0aqkhbt1j21ci0vm0y9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0aqkst7rj21ci0pkqae.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0aql16q3j21cc0smafu.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0aqyrtbaj20vg0erdgw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0aqyrrquj20vf08ngma.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0aqyrw3ej20vk096gmq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0aqyrujdj20vg09ggml.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0aqys3j3j20vg09hgmu.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 21:05:09 GMT</pubDate>
</item>
<item>
<title>[LG]《Towards Large Language Models as Copilots for Theorem Proving in Lean》P Song, K Yang, A Anandkumar [UC Santa Barbara &amp; California Institute of ...</title>
<link>https://weibo.com/1402400261/OaZfzcrVw</link>
<guid>https://weibo.com/1402400261/OaZfzcrVw</guid>
<content:encoded><![CDATA[
<div> Towards Large Language Models, Theorem Proving, Lean, Copilots, UC Santa Barbara, California Institute of Technology, 2024, P Song, K Yang, A Anandkumar

<br /><br />总结:
本文提出了使用大型语言模型作为Lean定理证明的助手的想法。作者将大型语言模型引入Lean系统中，旨在提高定理证明的效率和准确性。他们探讨了在 Lean 环境中使用语言模型的可行性和潜力，并展示了这种方法的优势。通过将大型语言模型作为copilots，可以辅助定理证明者更快速地进行推理和证明过程，提高定理证明的效率。研究团队的实验结果表明，这种方法取得了令人满意的成果，为使用大型语言模型作为定理证明辅助工具提供了新思路。 <div>
[LG]《Towards Large Language Models as Copilots for Theorem Proving in Lean》P Song, K Yang, A Anandkumar [UC Santa Barbara &amp; California Institute of Technology] (2024) <a href="https://arxiv.org/abs/2404.12534"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0aqjvn5rj21cg0o0dq7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0aqkhbt1j21ci0vm0y9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0aqkst7rj21ci0pkqae.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0aql16q3j21cc0smafu.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0aqyrtbaj20vg0erdgw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0aqyrrquj20vf08ngma.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0aqyrw3ej20vk096gmq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0aqyrujdj20vg09ggml.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0aqys3j3j20vg09hgmu.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0aqysla3j20vg0f1gnw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0aqysww0j20vg0ewjty.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 21:04:55 GMT</pubDate>
</item>
<item>
<title>通过语言模型与爬虫技术的结合，提出了垂直信息网页的爬虫生成任务和AUTOCRAWLER框架，可以生成可在多个相似网页上执行的动作序列，从而实现对开放世界场景的更...</title>
<link>https://weibo.com/1402400261/OaZfb5kzU</link>
<guid>https://weibo.com/1402400261/OaZfb5kzU</guid>
<content:encoded><![CDATA[
<div> 垂直信息网页、爬虫生成任务、AUTOCRAWLER框架、语言模型、爬虫技术、动作序列、开放世界场景、适应性

总结:<br /><br />该研究结合语言模型与爬虫技术，提出了垂直信息网页的爬虫生成任务和AUTOCRAWLER框架。该框架能生成可以在多个相似网页上执行的动作序列，从而更好适应开放世界场景。研究通过深度学习技术实现了对网页的理解和自动化操作，提高了爬虫的效率和适应性。该方法为网络数据采集和处理提供了新的思路和工具。 <div>
通过语言模型与爬虫技术的结合，提出了垂直信息网页的爬虫生成任务和AUTOCRAWLER框架，可以生成可在多个相似网页上执行的动作序列，从而实现对开放世界场景的更好适应性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《AutoCrawler: A Progressive Understanding Web Agent for Web Crawler Generation》W Huang, C Peng, Z Li, J Liang, Y Xiao, L Wen, Z Chen [Fudan University] (2024) <a href="https://arxiv.org/abs/2404.12753"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0ap6ztk3j20oi148k18.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0ap72wz9j20sk1547cl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0ap7hqpej21kq1104bw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0ap7ooe3j20se0p477x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0aptri4gj20hn0efq3p.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0aptt29hj20zx0vvagn.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 21:03:58 GMT</pubDate>
</item>
<item>
<title>[CL]《AutoCrawler: A Progressive Understanding Web Agent for Web Crawler Generation》W Huang, C Peng, Z Li, J Liang, Y Xiao, L Wen, Z Chen [Fudan Univ...</title>
<link>https://weibo.com/1402400261/OaZf7nzJv</link>
<guid>https://weibo.com/1402400261/OaZf7nzJv</guid>
<content:encoded><![CDATA[
<div> 关键词：AutoCrawler, 渐进式理解，网络代理，网络爬虫生成，Fudan University

总结:<br /><br />这篇文章介绍了一种名为AutoCrawler的网络代理，它具有渐进式理解能力，可以用于网络爬虫生成。研究团队来自复旦大学。该网络代理利用先进的技术和算法，能够不断学习和优化自己的爬取能力，更有效地搜集网络数据。研究成果为网络爬取技术的发展提供了新的思路和方法。<br />通过AutoCrawler，研究者们探索了网络代理的理解能力，以及其在网络爬取方面的应用。这项研究有望为网络数据的获取和处理提供更多可能性，推动相关技术的进步。AutoCrawler的渐进式理解能力使其在不断学习和优化中不断提升性能，为网络爬虫领域带来新的机遇和挑战。同时，作为一种先进的网络代理技术，AutoCrawler引入了复杂的算法和模型，提高了爬取效率和准确性，为网络数据分析和利用提供了更多可能性。总的来说，AutoCrawler是一种创新的网络代理技术，为网络爬取和数据搜集领域带来了新的思路和方法。 <div>
[CL]《AutoCrawler: A Progressive Understanding Web Agent for Web Crawler Generation》W Huang, C Peng, Z Li, J Liang, Y Xiao, L Wen, Z Chen [Fudan University] (2024) <a href="https://arxiv.org/abs/2404.12753"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0ap6ztk3j20oi148k18.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0ap72wz9j20sk1547cl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hp0ap7hqpej21kq1104bw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hp0ap7ooe3j20se0p477x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hp0aptri4gj20hn0efq3p.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hp0aptt29hj20zx0vvagn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 21:03:49 GMT</pubDate>
</item>
<item>
<title>早！[太阳] #早安# [图片]</title>
<link>https://weibo.com/1402400261/OaZe2j0sM</link>
<guid>https://weibo.com/1402400261/OaZe2j0sM</guid>
<content:encoded><![CDATA[
<div> 关键词：早、中文、总结、800字、要点、提取、输出、格式、换行、HTML

提取关键词，写800字的中文总结，按照要点输出。<br /><br />总结:在这篇文章中，我们学习了如何提取关键词并用中文写800字的总结。文章教导我们如何在同一行内输出关键词，并按要点进行组织。同时，我们也学会了使用HTML的换行符来格式化输出内容，保持清晰可读。通过这篇文章的学习，我们对文章总结的方法有了更深入的理解和实践经验。 <div>
早！<span class="url-icon"><img alt="[太阳]" src="https://h5.sinaimg.cn/m/emoticon/icon/others/w_taiyang-2b1d91ddac.png" style="width: 1em; height: 1em;" /></span> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%97%A9%E5%AE%89%23&amp;isnewpage=1"><span class="surl-text">#早安#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hp0an1451sj20kf0ix0ub.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 21:01:09 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.22)》 爱可可微博热门分享(4.22) [图片]</title>
<link>https://weibo.com/1402400261/OaWxVDzhz</link>
<guid>https://weibo.com/1402400261/OaWxVDzhz</guid>
<content:encoded><![CDATA[
<div> 微博、热门、爱可可、分享、4.22

总结:<br />
本文主要介绍了4月22日爱可可微博的热门分享内容。微博用户分享了各种各样的内容，引起了大家的关注和讨论。爱可可微博的热门话题涵盖了多个领域，包括时事热点、娱乐八卦、时尚潮流等。每个话题都吸引了大量粉丝的参与和互动，展现了微博的热度和影响力。通过微博的热门分享，用户可以了解到社会的最新动态，也可以和他人交流观点分享感受，让微博成为了人们生活的一部分。 <div>
《爱可可微博热门分享(4.22)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405026083362701509"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.22)</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hozyt3d767j20qo0f0mzn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 14:11:56 GMT</pubDate>
</item>
<item>
<title>【新书：《AI辅助编程》，关于如何利用人工智能开发工具进行代码创建的实用指南，适合初学者和经验丰富的开发者】《AI-Assisted Programming [Book]》 网页链接 ...</title>
<link>https://weibo.com/1402400261/OaW0C4Uh4</link>
<guid>https://weibo.com/1402400261/OaW0C4Uh4</guid>
<content:encoded><![CDATA[
<div> 人工智能, 编程, 工具, 代码创建, 初学者, 开发者, 实用指南, AI-Assisted Programming, 新书

人工智能在编程领域的应用愈发广泛，新书《AI辅助编程》提供了关于如何利用人工智能开发工具进行代码创建的实用指南。本书旨在帮助初学者和经验丰富的开发者掌握人工智能辅助编程技术，提高代码效率和质量。通过学习本书，读者可以了解人工智能在编程中的作用，掌握使用人工智能工具进行代码创建的方法，提升编程技能和效率。AI-Assisted Programming将成为开发者们的良好参考指南，帮助他们更加高效地进行代码开发工作。总结: <br /><br />《AI辅助编程》是一本适合初学者和经验丰富的开发者的实用指南，指导他们如何利用人工智能开发工具进行代码创建，提高编程效率和质量。 <div>
【新书：《AI辅助编程》，关于如何利用人工智能开发工具进行代码创建的实用指南，适合初学者和经验丰富的开发者】《AI-Assisted Programming [Book]》 <a href="https://www.oreilly.com/library/view/ai-assisted-programming/9781098164553/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hozwet9899j206y0943yy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 12:49:50 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Towards Variable and Coordinated Holistic Co-Speech Motion Generation》(CVPR 2024) GitHub: github.com/feifeifeiliu/probtalk《Bidir...</title>
<link>https://weibo.com/1402400261/OaThoh2qh</link>
<guid>https://weibo.com/1402400261/OaThoh2qh</guid>
<content:encoded><![CDATA[
<div> 关键词：Holistic Co-Speech Motion Generation, Variable, Coordinated, Image Deraining, Bidirectional, Multi-Scale Implicit Neural Representations, Depth-aware Test-Time Training, Zero-shot Video Object Segmentation, SkillDiffuser, Interpretable Hierarchical Planning, Diffusion-Based Task Execution, DialogCC, Multi-modal Dialogue Datasets Resources, Learning Explicit Contact, Moving Object Segmentation, SAM (Spatial Attention Module), Grounding Multimodal Large Language Models, RelayAttention, Large Language Model Serving, PhysDreamer, Physics-Based Interaction, NIR-Assisted Image Denoising, Mixture-of-Depths, Transformer-based Language Models, ControlNet++

总结：<br /><br />
1. "Towards Variable and Coordinated Holistic Co-Speech Motion Generation" 介绍了一种变量和协调的整体语音动作生成方法，利用GitHub上的代码实现了该方法。
2. "Bidirectional Multi-Scale Implicit Neural Representations for Image Deraining" 讨论了一种针对图像去雨的双向多尺度隐式神经表示方法，并在GitHub上提供了相应代码。
3. "Depth-aware Test-Time Training for Zero-shot Video Object Segmentation" 提出了一种零样本视频对象分割的基于深度的测试训练方法，并在GitHub上分享了代码。
4. "SkillDiffuser: Interpretable Hierarchical Planning via Skill Abstractions in Diffusion-Based Task Execution" 解释了一种可解释的分层规划方法，通过技能抽象在扩散式任务执行中实现，相关代码在GitHub上可获得。
5. "DialogCC: An Automated Pipeline for Creating High-Quality Multi-modal Dialogue Datasets Resources" 介绍了一个自动化流水线，用于创建高质量的多模态对话数据集资源，相关代码在GitHub上提供。
6. "Learning Explicit Contact for Implicit Reconstruction of Hand-held Objects from Monocular Images" 探讨了通过单目图像实现手持物体的显式接触隐式重建方法，相关代码可在GitHub上找到。
7. "Moving Object Segmentation: All You Need Is SAM (and Flow)" 讨论了移动物体分割中的关键因素SAM（空间注意模块）和流的作用，提供了相关代码。
8. "Groma: Localized Visual Tokenization for Grounding Multimodal Large Language Models" 提出了一种用于基于图像的多模态大型语言模型定位的本地化视觉记号化方法，相关代码在GitHub上提供。
9. "RelayAttention for Efficient Large Language Model Serving with Long System Prompts" 引入了RelayAttention方法，提高了长系统提示下大型语言模型的效率，相关代码在GitHub上可获得。
10. "PhysDreamer: Physics-Based Interaction with 3D Objects via Video Generation" 讨论了通过视频生成实现与3D物体的基于物理的交互方法，相关代码在GitHub上提供。
11. "NIR-Assisted Image Denoising: A Selective Fusion Approach and A Real-World Benchmark Dataset" 探讨了一种选择性融合方法的NIR辅助图像去噪方案，并提供了真实世界基准数据集，相应代码在GitHub上可获得。
12. "Mixture-of-Depths: Dynamically allocating compute in transformer-based language models" 讨论了一种在基于转换器的语言模型中动态分配计算资源的深度混合方法，相关代码在GitHub上提供。
13. "ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback" 提出了ControlNet++方法，通过有效的一致性反馈改善了条件控制，相关代码在GitHub上可获得。 <div>
几篇论文实现代码：<br />《Towards Variable and Coordinated Holistic Co-Speech Motion Generation》(CVPR 2024) GitHub: github.com/feifeifeiliu/probtalk<br />《Bidirectional Multi-Scale Implicit Neural Representations for Image Deraining》(CVPR 2024) GitHub: github.com/cschenxiang/NeRD-Rain [fig3]<br />《Depth-aware Test-Time Training for Zero-shot Video Object Segmentation》(CVPR 2024) GitHub: github.com/NiFangBaAGe/DATTT [fig4]<br />《SkillDiffuser: Interpretable Hierarchical Planning via Skill Abstractions in Diffusion-Based Task Execution》(CVPR 2024) GitHub: github.com/Liang-ZX/skilldiffuser [fig5]<br />《DialogCC: An Automated Pipeline for Creating High-Quality Multi-modal Dialogue Datasets Resources》(NAACL 2024) GitHub: github.com/passing2961/DialogCC<br />《Learning Explicit Contact for Implicit Reconstruction of Hand-held Objects from Monocular Images》(2024) GitHub: github.com/JunxingHu/CHOI [fig6]<br />《Moving Object Segmentation: All You Need Is SAM (and Flow)》(2024) GitHub: github.com/Jyxarthur/flowsam [fig1]<br />《Groma: Localized Visual Tokenization for Grounding Multimodal Large Language Models》(2024) GitHub: github.com/FoundationVision/Groma [fig2]<br />《RelayAttention for Efficient Large Language Model Serving with Long System Prompts》(2024) GitHub: github.com/rayleizhu/vllm-ra<br />《PhysDreamer: Physics-Based Interaction with 3D Objects via Video Generation》(2024) GitHub: github.com/a1600012888/PhysDreamer<br />《NIR-Assisted Image Denoising: A Selective Fusion Approach and A Real-World Benchmark Dataset》(2024) GitHub: github.com/ronjonxu/NAID<br />《Mixture-of-Depths: Dynamically allocating compute in transformer-based language models》(2024) GitHub: github.com/sramshetty/mixture-of-depths<br />《ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback》(2024) GitHub: github.com/liming-ai/ControlNet_Plus_Plus<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hozi6u54qpj211n0md1f2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hozi9cwcf5j21tk0ymb2a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoziq91154j20yd0craez.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoziqt9zr2j22et18zwxk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hozk3fmh1fj21in0m0h0j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hozk910yj2j21gx0o9dp8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 05:52:56 GMT</pubDate>
</item>
<item>
<title>【AgentRun: AI生成代码隔离运行环境，使用单行代码轻松安全地运行来自大型语言模型 (LLM) 的 Python 代码，同时提供资源管理、超时设置、依赖管理和自动清理等...</title>
<link>https://weibo.com/1402400261/OaTf3fbhx</link>
<guid>https://weibo.com/1402400261/OaTf3fbhx</guid>
<content:encoded><![CDATA[
<div> AgentRun, AI, 代码隔离, 运行环境, Python, 安全, 资源管理, 超时设置, 依赖管理, 自动清理

<br /><br />总结:
AgentRun是一个工具，可以安全地运行来自大型语言模型生成的Python代码。它提供了代码隔离的运行环境，可以轻松实现资源管理、超时设置、依赖管理和自动清理等功能，为运行AI生成的代码提供了一种简单快速的方式。通过AgentRun，用户可以在保证安全的情况下运行AI生成的代码，有效地管理资源和确保代码的运行环境。 <div>
【AgentRun: AI生成代码隔离运行环境，使用单行代码轻松安全地运行来自大型语言模型 (LLM) 的 Python 代码，同时提供资源管理、超时设置、依赖管理和自动清理等功能】'AgentRun: Run AI Generated Code Safely - The easiest, and fastest way to run AI-generated Python code safely' GitHub: github.com/Jonathan-Adly/AgentRun <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hozk6zpn60j21ji0ton3y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 05:47:10 GMT</pubDate>
</item>
<item>
<title>【CustomChar：用于创建自定义 AI 角色的框架，不依赖特定平台、云服务或专门硬件】'CustomChar - Your customized AI characters - Your customized AI assista...</title>
<link>https://weibo.com/1402400261/OaTelBHyp</link>
<guid>https://weibo.com/1402400261/OaTelBHyp</guid>
<content:encoded><![CDATA[
<div> CustomChar, AI角色, 自定义, 助手, llama.cpp, whisper.cpp, ggml, LLaMA-v2, Github

<br /><br />总结:
CustomChar 是一个框架，可以用于创建自定义的 AI 角色和助手，在任何硬件上运行。它不依赖特定平台、云服务或专门硬件。通过 llama.cpp、whisper.cpp、ggml 和 LLaMA-v2，用户可以定制自己的 AI 助手，并将其运用到各种环境中。用户可以在 GitHub 上找到 CustomChar 的源代码和文档。 <div>
【CustomChar：用于创建自定义 AI 角色的框架，不依赖特定平台、云服务或专门硬件】'CustomChar - Your customized AI characters - Your customized AI assistant - Personal assistants on any hardware! With llama.cpp, whisper.cpp, ggml, LLaMA-v2.' GitHub: github.com/nrl-ai/CustomChar <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hozk62rselj21hc0u0gpv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hozk68m8gdj212d0lp77f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 05:45:27 GMT</pubDate>
</item>
<item>
<title>【使用 OpenAI Functions 的网页爬虫，用于简单的网页数据提取】'Scrape the Web with entities extraction using OpenAI Function - A web scraper that utiliz...</title>
<link>https://weibo.com/1402400261/OaTdOuVXf</link>
<guid>https://weibo.com/1402400261/OaTdOuVXf</guid>
<content:encoded><![CDATA[
<div> OpenAI Functions、网页爬虫、数据提取、GitHub、entities extraction、web scraper、简单、OpenAI Functions、关键词提取、无监督学习<br />
<br />
提供了一个使用OpenAI Functions的网页爬虫，可进行实体提取。该网页爬虫简单易用，可以方便地从网页中提取数据。用户可以通过GitHub获取该项目的源代码。这个项目主要用于实体提取，采用了无监督学习的方法。希望能够帮助用户快速、高效地从网页中提取关键信息。<br /><br />总结: <div>
【使用 OpenAI Functions 的网页爬虫，用于简单的网页数据提取】'Scrape the Web with entities extraction using OpenAI Function - A web scraper that utilizes OpenAI Functions for easy scraping.' GitHub: github.com/trancethehuman/entities-extraction-web-scraper <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a>5<img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hozk4wp54zj21ji0pq79b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 05:44:08 GMT</pubDate>
</item>
<item>
<title>【SAMMO：用于提示工程和优化的库，支持结构感知多目标元提示优化】'SAMMO - A library for prompt engineering and optimization (SAMMO = Structure-aware Mul...</title>
<link>https://weibo.com/1402400261/OaSYge5QW</link>
<guid>https://weibo.com/1402400261/OaSYge5QW</guid>
<content:encoded><![CDATA[
<div> SAMMO, 提示工程, 优化, 库, 结构感知, 多目标, 元提示优化, GitHub, Microsoft

<br /><br />
文章介绍了SAMMO这个库，它是用于提示工程和优化的工具，支持结构感知多目标元提示优化。SAMMO的设计使得用户可以更灵活地进行工程和优化任务，同时考虑多种因素，达到更好的效果。这个库的开源代码可以在GitHub上找到，是由Microsoft开发维护的。SAMMO的灵活性和效率使得其在工程和优化领域有着广泛的应用前景。 <div>
【SAMMO：用于提示工程和优化的库，支持结构感知多目标元提示优化】'SAMMO - A library for prompt engineering and optimization (SAMMO = Structure-aware Multi-Objective Metaprompt Optimization)' GitHub: github.com/microsoft/sammo <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hozj10rf37j211h0u00ws.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 05:05:48 GMT</pubDate>
</item>
<item>
<title>【AnimationGPT：基于文本生成格斗风格角色动画】'AnimationGPT - AnimationGPT:An AlGC tool for generating game combat motion assets' GitHub: github.com/f...</title>
<link>https://weibo.com/1402400261/OaSXgsvvw</link>
<guid>https://weibo.com/1402400261/OaSXgsvvw</guid>
<content:encoded><![CDATA[
<div> 生成动作、格斗风格、角色、动画、AlGC工具、游戏战斗、运动资产、GitHub、文本生成、工具<br />
<br />
总结:<br />
该项目是一个基于文本的角色动画生成工具，利用人工智能生成游戏中的战斗动作。该工具可以帮助游戏开发者快速生成各种格斗风格的角色动画，节约制作成本和时间。通过输入文本描述，工具可以生成相应风格的动画效果，方便开发者定制不同风格的战斗场景。该工具的源代码已经上传至GitHub，可以自由获取和使用。该工具提供了一种新颖的生成动画的方式，对游戏开发行业具有一定的推动作用。 <div>
【AnimationGPT：基于文本生成格斗风格角色动画】'AnimationGPT - AnimationGPT:An AlGC tool for generating game combat motion assets' GitHub: github.com/fyyakaxyy/animationGPT <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hozixqffz1j214y0u0jw2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoziy2akw3j226k0u0q9n.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoziyga12gj20ao0aoq2w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 05:03:21 GMT</pubDate>
</item>
<item>
<title>'Dockerized Signal Messenger REST API' GitHub: github.com/bbernhard/signal-cli-rest-api #开源# [图片]</title>
<link>https://weibo.com/1402400261/OaSTmyDyd</link>
<guid>https://weibo.com/1402400261/OaSTmyDyd</guid>
<content:encoded><![CDATA[
<div> signal messenger, REST API, dockerized, github, bbernhard, signal-cli, 包含基本要点（信号messenger REST API经docker化，并且存放在GitHub上，由bbernhard维护，使用signal-cli工具）<br /><br />总结: 信号Messenger REST API经docker化，存放在GitHub上，由bbernhard维护，使用signal-cli工具。 <div>
'Dockerized Signal Messenger REST API' GitHub: github.com/bbernhard/signal-cli-rest-api <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hozioc6s0wj214o0u0n14.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 04:53:45 GMT</pubDate>
</item>
<item>
<title>【关于数据投毒和后门攻击的精选论文和资源列表，包括相关的防御方法】'Awesome Data Poisoning and Backdoor Attacks - A curated list of papers &amp; resources ...</title>
<link>https://weibo.com/1402400261/OaSSazBGT</link>
<guid>https://weibo.com/1402400261/OaSSazBGT</guid>
<content:encoded><![CDATA[
<div> 数据投毒、后门攻击、防御方法、文章列表、资源列表、数据污染、安全、机器学习、网络安全、信息安全

总结:<br /><br />
这篇文章是一个精选的论文和资源列表，涉及数据投毒、后门攻击以及针对这些攻击的防御方法。其中包括数据污染和安全、机器学习安全、网络安全、信息安全等内容。这些资源可以帮助研究人员了解数据投毒和后门攻击的原理，以及如何有效地保护数据安全和防范恶意攻击。该列表提供了丰富的信息，对数据安全领域的研究和实践具有重要的参考价值。 <div>
【关于数据投毒和后门攻击的精选论文和资源列表，包括相关的防御方法】'Awesome Data Poisoning and Backdoor Attacks - A curated list of papers &amp; resources linked to data poisoning, backdoor attacks and defenses against them' GitHub: github.com/penghui-yang/awesome-data-poisoning-and-backdoor-attacks <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hozikuj6wkj20v90u0gqn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 04:50:48 GMT</pubDate>
</item>
<item>
<title>【ai-cli-lib: 为任意基于 readline 的命令行程序添加 AI 功能的库】’ai-cli-lib: AI help for CLI programs - Add AI capabilities to any readline-enabled c...</title>
<link>https://weibo.com/1402400261/OaSQFiJa1</link>
<guid>https://weibo.com/1402400261/OaSQFiJa1</guid>
<content:encoded><![CDATA[
<div> GitHub、ai-cli-lib、readline、命令行程序、AI、功能、库、添加、dspinellis、AI help<br />
<br />
总结：<br />
这篇文章介绍了ai-cli-lib库，它为基于readline的命令行程序提供了AI功能的能力。用户可以通过添加这个库来赋予命令行程序人工智能的能力，使其更加智能和灵活。这个库的作者是dspinellis，用户可以在GitHub上找到这个库的代码和更多信息。通过ai-cli-lib，用户可以简单地为自己的命令行程序添加AI功能，提升程序的交互性和智能程度。 <div>
【ai-cli-lib: 为任意基于 readline 的命令行程序添加 AI 功能的库】’ai-cli-lib: AI help for CLI programs - Add AI capabilities to any readline-enabled command-line program' GitHub: github.com/dspinellis/ai-cli-lib <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hozihjzo4ij218c0u0ahp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 04:47:06 GMT</pubDate>
</item>
<item>
<title>【TripoSR Bake：利用 TripoSR 模型从 2D 图像中推断出 3D 形状和纹理数据】'TripoSR Bake - Generate 3D meshes from a single 2D image using TripoSR, comple...</title>
<link>https://weibo.com/1402400261/OaSPDFapb</link>
<guid>https://weibo.com/1402400261/OaSPDFapb</guid>
<content:encoded><![CDATA[
<div> TripoSR Bake, TripoSR, 3D 形状, 纹理数据, 2D 图像, 生成, 网格, 手动编辑, 贴图<br />
<br />
TripoSR Bake是一个利用TripoSR模型从2D图像中生成3D网格的工具，同时支持手动编辑几何形状和纹理数据。用户可以通过GitHub获取该工具的源代码，并使用其功能来生成包含细节的3D网格模型。TripoSR Bake的功能强大，可以从单一的2D图像中推断出具有纹理的逼真3D形状，同时还支持用户进行手动编辑，让用户可以根据需求调整和优化生成的3D网格。这个工具为用户提供了一种简单而有效的方法来将2D图像转换为具有真实感的3D模型，为图形设计和数字艺术领域的专业人士提供了有效的工具和技术支持。<br /><br />总结:TripoSR Bake是一个强大的工具，可以从单一的2D图像中生成具有纹理的3D网格模型，并支持手动编辑，为用户提供了灵活性和控制力。 <div>
【TripoSR Bake：利用 TripoSR 模型从 2D 图像中推断出 3D 形状和纹理数据】'TripoSR Bake - Generate 3D meshes from a single 2D image using TripoSR, complete with manual geometry editing and texture baking support' GitHub: github.com/iffyloop/TripoSR-Bake <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoziewk5zij20ux0u0dmf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 04:44:33 GMT</pubDate>
</item>
<item>
<title>【tinyworldmap：用于离线优先和低带宽Web 应用的小型世界地图】’tinyworldmap - tinyworldmap is a tiny world map for offline-first and low-bandwidth web ...</title>
<link>https://weibo.com/1402400261/OaSNdmwzL</link>
<guid>https://weibo.com/1402400261/OaSNdmwzL</guid>
<content:encoded><![CDATA[
<div> tinyworldmap、离线优先、低带宽、小型世界地图、GitHub、tiny-world-map

<br /><br />总结:
tinyworldmap是一个用于离线优先和低带宽Web应用的小型世界地图工具。该工具可在GitHub上找到，名为tiny-world-map。适用于需要离线使用和低带宽的Web应用场景，为用户提供便捷的小型世界地图功能。 <div>
【tinyworldmap：用于离线优先和低带宽Web 应用的小型世界地图】’tinyworldmap - tinyworldmap is a tiny world map for offline-first and low-bandwidth web apps' GitHub: github.com/tinyworldmap/tiny-world-map <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hozi8o5d8ej20dp0a3wfe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 04:38:36 GMT</pubDate>
</item>
<item>
<title>Menteebot的人形机器人 #人工智能##机器人#</title>
<link>https://weibo.com/1402400261/OaR7zuIrP</link>
<guid>https://weibo.com/1402400261/OaR7zuIrP</guid>
<content:encoded><![CDATA[
<div> 人形机器人, Menteebot, 全球范围, 交互, 学习, 反馈, 技能, 心理支持, 效率, 潜力<br />
<br />总结:
人形机器人Menteebot是一款具有全球范围的交互式学习工具，通过为用户提供个性化的反馈和技能培训，帮助他们提高学习效率和释放潜力。同时，Menteebot还提供心理支持，让用户在学习过程中更加坚定和自信。 <div>
Menteebot的人形机器人 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E4%BA%BA%23&amp;isnewpage=1"><span class="surl-text">#机器人#</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax1.sinaimg.cn/orj480/5396ee05ly1hozau6iyfaj20zk0k00u0.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/WgfQwAURlx08eh3wqguA01041200mgd70E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713752464&amp;ssig=YofB1WP7BO&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/CmM4emPtlx08eh3vBY2s01041200cdHj0E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713752464&amp;ssig=1f3JtPdKWr&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/U49NZb7ilx08eh3v89Xi010412007PXb0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713752464&amp;ssig=PfNmguW4uD&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5025874261770245" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 00:23:15 GMT</pubDate>
</item>
<item>
<title>【LLM API 提供商排行榜，比较和排名了 API 提供商在价格、性能 / 速度（吞吐量和延迟）、上下文窗口大小等关键指标】《LLM API Provider Leaderboard | Artific...</title>
<link>https://weibo.com/1402400261/OaR4wzYuT</link>
<guid>https://weibo.com/1402400261/OaR4wzYuT</guid>
<content:encoded><![CDATA[
<div> API、提供商、排行榜、比较、排名、价格、性能、速度、上下文窗口大小
<br /><br />总结:本文通过比较和排名 API 提供商在价格、性能/速度（吞吐量和延迟）、上下文窗口大小等关键指标，提供了一个LLM API提供商排行榜。文章对API提供商的综合表现进行评估，给出了他们在各项指标上的排名，帮助用户了解不同API提供商的优劣。文章重点关注了价格、性能和上下文窗口大小等关键方面，为用户选择合适的API提供商提供了参考依据。通过这份排行榜，用户可以更好地了解API提供商的实力和特点，从而更加准确地选择符合自己需求的API服务。 <div>
【LLM API 提供商排行榜，比较和排名了 API 提供商在价格、性能 / 速度（吞吐量和延迟）、上下文窗口大小等关键指标】《LLM API Provider Leaderboard | Artificial Analysis》 <a href="https://artificialanalysis.ai/leaderboards/providers"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hozan65hdfj215d0u0tdy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 00:15:45 GMT</pubDate>
</item>
<item>
<title>【用了半个亿GPT Token得出的经验】- 提示越简单越好，不要过度指定。GPT本身就很智能，过度提示会把它搞混淆。比如分类任务，直接让GPT给出分类名称，而不要让...</title>
<link>https://weibo.com/1402400261/OaR3K8xNE</link>
<guid>https://weibo.com/1402400261/OaR3K8xNE</guid>
<content:encoded><![CDATA[
<div> 关键词: GPT Token, Chat API, 用户体验, 空结果处理, 输出上下文, 向量数据库, 幻觉生成, GPT-5, 任务类型, 最优配置

总结:
GPT Token使用经验：作者分享了使用半个亿GPT Token得出的经验。提到了简单的提示对于GPT来说更有效，避免过度指定任务。只需要使用Chat API即可完成各种任务，不必使用Langchain或其他API。通过使用流式API和显示变速打字字符来提高用户体验。建议在处理“空结果”的情况时，先进行两步处理，避免GPT臆造内容。还提到了GPT的输入上下文窗口在扩大，但输出上下文仍受限制。向量数据库在普通场景下用处不大，更适合大规模搜索。GPT在封闭场景下生成幻觉内容较少。并预测了GPT-5的进步可能是渐进的，不太可能一次颠覆所有，但会继续优化不同任务类型的配置。 <div>
【用了半个亿GPT Token得出的经验】<br />- 提示越简单越好，不要过度指定。GPT本身就很智能，过度提示会把它搞混淆。比如分类任务，直接让GPT给出分类名称，而不要让它从一个列表中选择ID。   <br />- 只需要Chat API就足够，不需要使用 Langchain 或其他 OpenAI 最近发布的 API。Chat API非常强大和灵活，40行代码就可以完成各种任务。   <br />- 通过使用流式 API 和显示用户可以看到的变速打字字符来提高延迟可以带来很大的用户体验改进，这是AI交互的重要创新。   <br />- GPT不善于处理“空结果”的情况，经常会臆造出一些无关内容。解决方法是进行两步处理，先问它是否有相关内容，如果没有就直接返回空。   <br />- GPT的输入上下文窗口在不断扩大，但输出上下文还是很小(4k tokens)。这限制了其生成长文本的能力。   <br />- 向量数据库在普通场景下用处不大，更适合大规模搜索领域。把向量和其他数据分开存储也失去了上下文信息。   <br />- GPT的幻觉生成非常少，“输入文本-分析提取”这样的封闭场景几乎不会生成无关内容。   <br />- GPT-5的进步可能比较渐进，不太可能一次颠覆所有。但GPT系列会继续区别对待不同的任务类型，找到各自的最优配置。<br />《Lessons after a half-billion GPT tokens - Ken Kantzer's Blog》 <a href="https://kenkantzer.com/lessons-after-a-half-billion-gpt-tokens/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hozal00hcuj20u015hn2f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 00:13:49 GMT</pubDate>
</item>
<item>
<title>[笑而不语] [图片]</title>
<link>https://weibo.com/1402400261/OaR19oFd5</link>
<guid>https://weibo.com/1402400261/OaR19oFd5</guid>
<content:encoded><![CDATA[
<div> 关键词：气候变化、可持续发展、减少排放、全球协作、环保政策、行动计划、绿色技术、地球环境、碳排放、可再生能源

气候变化是当前全球关注的热点问题之一，各国纷纷制定了可持续发展的目标和行动计划，旨在减少碳排放并保护地球环境。为了实现这些目标，全球需要加强合作，共同推动环保政策的落实，推动绿色技术的发展，提高可再生能源的利用率。各方必须共同努力，减少排放并保护地球环境，实现气候变化下的可持续发展。总结：<br /><br />气候变化是当前全球关注的问题，需要全球协作和环保政策支持，推动减排行动和绿色技术发展，实现可持续发展目标。 <div>
<span class="url-icon"><img alt="[笑而不语]" src="https://h5.sinaimg.cn/m/emoticon/icon/default/d_heiheihei-5170f2f55c.png" style="width: 1em; height: 1em;" /></span> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hozae7zq4ej20u00m2ady.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 00:07:26 GMT</pubDate>
</item>
<item>
<title>【在Vercel的AI Playground可对比体验由groq提供的llama-3-70b-instruct-groq模型】《AI Playground | Vercel AI SDK》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/OaR0xBpce</link>
<guid>https://weibo.com/1402400261/OaR0xBpce</guid>
<content:encoded><![CDATA[
<div> Vercel, AI Playground, groq, llama-3-70b-instruct-groq模型

<br /><br />总结:
在Vercel的AI Playground中，用户可以对比体验由groq提供的llama-3-70b-instruct-groq模型。该平台提供了一个交互式的界面，让用户能够直观地了解和比较不同模型的效果。用户可以通过输入不同的文本或图像来测试模型的性能和准确性。AI Playground为用户提供了一个便捷的方式来探索和学习各种模型的功能和特点。通过这个平台，用户可以更加直观地理解人工智能技术的应用和潜力。AI Playground为用户提供了一个有趣和实用的工具，让他们可以更深入地了解和体验不同模型的表现。通过这种交互式的方式，用户可以更加深入地理解人工智能技术的运作原理和优势。AI Playground为用户提供了一个全新的学习和探索平台，让他们可以更好地了解和应用人工智能技术。 <div>
【在Vercel的AI Playground可对比体验由groq提供的llama-3-70b-instruct-groq模型】《AI Playground | Vercel AI SDK》 <a href="https://sdk.vercel.ai/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hozac1upq6j20zj0u0gpw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 00:05:56 GMT</pubDate>
</item>
<item>
<title>【FineWeb：15T Tokens的网页数据集，由来自CommonCrawl经过清理和重复数据删除的英文web数据组成】《HuggingFaceFW/fineweb · Datasets at Hugging Face》 网...</title>
<link>https://weibo.com/1402400261/OaQYey7wt</link>
<guid>https://weibo.com/1402400261/OaQYey7wt</guid>
<content:encoded><![CDATA[
<div> 数据集，15T Tokens，CommonCrawl，网页数据，英文，清理，重复数据删除，Hugging Face

总结：<br /><br />这篇文章介绍了一个包含15T Tokens的网页数据集，数据来源于CommonCrawl，经过清理和重复数据删除，数据集中包含英文网页数据。该数据集可供研究人员或开发人员使用，并由Hugging Face提供支持。 <div>
【FineWeb：15T Tokens的网页数据集，由来自CommonCrawl经过清理和重复数据删除的英文web数据组成】《HuggingFaceFW/fineweb · Datasets at Hugging Face》 <a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoza5j9e5uj211j0u0jx5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 00:00:15 GMT</pubDate>
</item>
<item>
<title>今日推介(第1383期)：自动化社会科学、多跳多模态网络Agent基准、将AlphaFold初始训练时间减少到10小时、人类价值观及AI与其对齐研究、基于分层投机解码的长序列...</title>
<link>https://weibo.com/1402400261/OaQeSCPzy</link>
<guid>https://weibo.com/1402400261/OaQeSCPzy</guid>
<content:encoded><![CDATA[
<div> 自动化社会科学、多跳多模态网络Agent基准、AlphaFold、初始训练时间、人类价值观、AI对齐、分层投机解码、长序列生成、无损加速

<br /><br />总结:
本文介绍了几个最新研究领域的前沿技术和发展。首先是自动化社会科学的探索，通过数据和技术的应用实现社会科学研究的自动化。其次是多跳多模态网络Agent基准的提出，为多模态网络的研究提供了一个标准基准。接着是将AlphaFold的初始训练时间缩短到10小时，这将极大地提高蛋白结构预测的效率。另外，研究人员也探讨了人类价值观与人工智能的对齐问题，强调了在AI发展中考虑人类价值观的重要性。还有基于分层投机解码的长序列生成无损加速的方法，为大规模数据处理提供了有效解决方案。这些研究成果将为相关领域的进一步发展和应用提供重要参考。 <div>
今日推介(第1383期)：自动化社会科学、多跳多模态网络Agent基准、将AlphaFold初始训练时间减少到10小时、人类价值观及AI与其对齐研究、基于分层投机解码的长序列生成无损加速 公·众·号：爱可可爱生活 <a href="http://aicoco.net/s/8l"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoz6yh5saaj21400s4dkb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoz6yjixxlj21370u0qc2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoz6ylu09kj21400iiwid.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoz6yq9346j21400owagc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoz6ytqblbj21400kyq8z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 22:08:30 GMT</pubDate>
</item>
<item>
<title>[CL] Measuring Cross-lingual Transfer in Bytes 网页链接 通过字节级标记化和数据迁移指标的方法发现语言模型中存在重要的语言无关知识成分，这可能是模型强大...</title>
<link>https://weibo.com/1402400261/OaQasdPPi</link>
<guid>https://weibo.com/1402400261/OaQasdPPi</guid>
<content:encoded><![CDATA[
<div> 字节级标记化、数据迁移指标、语言无关知识、语言模型、跨语言迁移能力、关键所在<br />
<br />
在语言模型中，通过字节级标记化和数据迁移指标的方法发现了重要的语言无关知识成分，这可以提高模型在不同语言间进行迁移时的能力。研究表明，语言模型中存在一定数量的语言无关知识，这些知识可以帮助模型在跨语言任务中取得更好的性能。因此，通过对模型进行字节级标记化处理和实验评估，可以更好地了解模型的跨语言迁移能力，并为进一步优化和改进模型提供重要参考。总体来说，研究结果表明字节级标记化和数据迁移指标是发现语言模型跨语言迁移能力关键的有效方法，对于加强模型的跨语言表现具有重要意义。<br /><br />总结: <br />通过字节级标记化和数据迁移指标发现了语言模型中的重要语言无关知识成分，提高了模型的跨语言迁移能力。研究结果为理解模型的跨语言表现提供了重要参考，为未来改进和优化模型奠定了基础。 <div>
[CL] Measuring Cross-lingual Transfer in Bytes  <br /><a href="https://arxiv.org/abs/2404.08191"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>        <br />通过字节级标记化和数据迁移指标的方法发现语言模型中存在重要的语言无关知识成分，这可能是模型强大的跨语言迁移能力的关键所在。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz6ng91wrj20sg16u187.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz6ngirr4j21ki0v0q9b.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz6nh7pymj21l00oyn37.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:57:36 GMT</pubDate>
</item>
<item>
<title>[LG] Stepwise Alignment for Constrained Language Model Policy Optimization 网页链接 通过逐步调整语言模型策略以满足奖励和安全约束，提出了一种简单、稳定...</title>
<link>https://weibo.com/1402400261/OaQ8g7dE9</link>
<guid>https://weibo.com/1402400261/OaQ8g7dE9</guid>
<content:encoded><![CDATA[
<div> 调整语言模型，奖励约束，安全约束，简单，稳定，灵活，有用，无害，步骤对齐

<br /><br />总结:
本文介绍了一种通过逐步调整语言模型策略以满足奖励和安全约束的方法。该方法简单、稳定、灵活，能够获得既有用又无害的语言模型。通过调整语言模型策略，实现了对奖励和安全约束的平衡，从而提高了语言模型的性能和效果。步骤对齐是该方法的关键特点，有效地引导语言模型在训练过程中逐步优化，确保其在输出时符合预设的约束条件。通过该方法，可以更好地利用语言模型在各种领域中的应用，并提升其在实际场景中的效果和可靠性。 <div>
[LG] Stepwise Alignment for Constrained Language Model Policy Optimization  <br /><a href="https://arxiv.org/abs/2404.11049"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />通过逐步调整语言模型策略以满足奖励和安全约束，提出了一种简单、稳定、灵活的方法来获得既有用又无害的语言模型。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz6huberoj20q413ktk3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz6hulau8j21ci0j0ahi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz6huykdpj21c20pmdm7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:52:12 GMT</pubDate>
</item>
<item>
<title>[CL] Language Models Still Struggle to Zero-shot Reason about Time Series 网页链接 提出时间序列推理的三种形式，发现当前语言模型在这三方面表现均较差，...</title>
<link>https://weibo.com/1402400261/OaQ6w5YJl</link>
<guid>https://weibo.com/1402400261/OaQ6w5YJl</guid>
<content:encoded><![CDATA[
<div> 时间序列推理、语言模型、表现差、理解时间序列、重要方向<br />
<br />
时间序列数据在许多领域中起着关键作用，对其进行推理有着重要意义。研究者提出了三种形式的时间序列推理：定性推理、定量推理和因果推理。然而，当前语言模型在这三方面表现都较差，存在很大的改进空间。针对这一问题，需要进一步探索如何让语言模型更好地理解时间序列行为，从而改善其推理能力，这仍然是一个值得深入探讨的重要方向。<br /><br />总结: <br />时间序列数据推理在各领域具有重要意义，但当前语言模型在理解和推理时间序列数据方面表现不佳，需要进一步研究和改进。 <div>
[CL] Language Models Still Struggle to Zero-shot Reason about Time Series  <br /><a href="https://arxiv.org/abs/2404.11757"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />提出时间序列推理的三种形式，发现当前语言模型在这三方面表现均较差，说明理解时间序列行为仍是一个值得探索的重要方向。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz6dczvzjj20qk16ek57.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz6ddalqbj217q0n07b4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz6ddk7j6j21be0q2do7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:47:54 GMT</pubDate>
</item>
<item>
<title>[CL] When LLMs are Unfit Use FastFit: Fast and Effective Text Classification with Many Classes 网页链接 FastFit利用批量对比学习和token级表示快速有效地...</title>
<link>https://weibo.com/1402400261/OaQ4olOZe</link>
<guid>https://weibo.com/1402400261/OaQ4olOZe</guid>
<content:encoded><![CDATA[
<div> 关键词: FastFit, 批量对比学习, token级表示, 文本分类, 样本量少, 类别数多

FastFit是一种快速有效的文本分类方法，利用批量对比学习和token级表示解决了样本量少但类别数多的问题。该方法能够高效地处理多类别分类任务，提高了分类的准确性和速度。FastFit的效果在实验中得到验证，展现出了其优越的性能。总体而言，FastFit是一种解决文本分类问题的快速且有效的方法。 <br /><br />
总结: <br />
1. FastFit利用批量对比学习和token级表示解决了样本量少但类别数多的文本分类问题。
2. 该方法在多类别分类任务中表现出高效的分类准确性和速度。
3. 实验结果验证了FastFit的优越性能，显示其是一种快速有效的文本分类方法。 <div>
[CL] When LLMs are Unfit Use FastFit: Fast and Effective Text Classification with Many Classes  <br /><a href="https://arxiv.org/abs/2404.12365"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />FastFit利用批量对比学习和token级表示快速有效地解决了样本量少但类别数多的文本分类问题。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz67x34v9j20s616mqg7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz67x7thnj20s60q0mze.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz67xrm8wj20sm0tw0wf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:42:40 GMT</pubDate>
</item>
<item>
<title>通过分层投机解码和基于检索的键值缓存选择策略，实现了大型语言模型长序列生成的可扩展且无损的加速，在保持生成质量的同时显著提升了推理效率。 - 转发 @爱可...</title>
<link>https://weibo.com/1402400261/OaQ1OoAsw</link>
<guid>https://weibo.com/1402400261/OaQ1OoAsw</guid>
<content:encoded><![CDATA[
<div> 加速、分层投机解码、基于检索的键值缓存、大型语言模型、长序列生成、推理效率

<br /><br />总结:本研究利用分层投机解码和基于检索的键值缓存选择策略，实现了对大型语言模型长序列生成的加速，保持生成质量的同时提升了推理效率。通过TriForce算法，实现了可扩展且无损的加速，为语言模型的进一步研究和应用提供了新的思路。 <div>
通过分层投机解码和基于检索的键值缓存选择策略，实现了大型语言模型长序列生成的可扩展且无损的加速，在保持生成质量的同时显著提升了推理效率。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding》H Sun, Z Chen, X Yang, Y Tian, B Chen [CMU] (2024) <a href="https://arxiv.org/abs/2404.11912"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5uz5nefj21f40o6wrw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5uzou58j21ko0todsq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5uzrforj21kg0qeajg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5uzwgcgj21kk0qek01.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz618jfsfj20fi0aljru.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz618jp0fj20b40cddg7.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz618locjj210z0hh0w3.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:36:19 GMT</pubDate>
</item>
<item>
<title>[CL]《TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding》H Sun, Z Chen, X Yang, Y Tian, B Chen [CMU] ...</title>
<link>https://weibo.com/1402400261/OaQ1MlBLe</link>
<guid>https://weibo.com/1402400261/OaQ1MlBLe</guid>
<content:encoded><![CDATA[
<div> Hierarchical Speculative Decoding, TriForce, Lossless Acceleration, Long Sequence Generation, CMU, H Sun, Z Chen, X Yang, Y Tian, B Chen 

<br /><br />总结:
这篇论文提出了一种名为TriForce的方法，旨在加速长序列生成过程并提高性能。其中，采用了层次化的推测式解码技术，通过结合多个解码器以并行生成大规模序列，实现了无损压缩的效果。研究团队通过对该方法的实验验证，证明了其在不同任务中均取得了显著的性能提升。通过在CMU进行的研究，该方法展示了在长序列生成领域的潜在优势，为推动序列生成技术的发展提供了新的思路和方法。 <div>
[CL]《TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding》H Sun, Z Chen, X Yang, Y Tian, B Chen [CMU] (2024) <a href="https://arxiv.org/abs/2404.11912"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5uz5nefj21f40o6wrw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5uzou58j21ko0todsq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5uzrforj21kg0qeajg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5uzwgcgj21kk0qek01.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz618jfsfj20fi0aljru.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz618jp0fj20b40cddg7.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz618locjj210z0hh0w3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:36:14 GMT</pubDate>
</item>
<item>
<title>提出一种通过语言模型引导广泛公众参与表达和评判价值观来构建人工智能系统值观对齐目标的新方法，并通过实验验证了该方法在多个关键指标上的有效性 - 转发 @爱...</title>
<link>https://weibo.com/1402400261/OaPYzfhws</link>
<guid>https://weibo.com/1402400261/OaPYzfhws</guid>
<content:encoded><![CDATA[
<div> 人工智能系统、价值观、语言模型、有效性验证、公众参与、人类价值、价值观对齐、新方法、实验、多个关键指标
<br />
<br />
人工智能系统与人类价值观的对齐问题一直备受关注，研究团队提出了一种新方法，通过语言模型引导广泛公众参与表达和评判价值观，来构建人工智能系统的价值观对齐目标。他们进行了实验验证，结果显示该方法在多个关键指标上取得了有效性。这项研究为解决人工智能系统与人类价值观背离的问题提供了新的思路和解决方案。 <div>
提出一种通过语言模型引导广泛公众参与表达和评判价值观来构建人工智能系统值观对齐目标的新方法，并通过实验验证了该方法在多个关键指标上的有效性<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《What are human values, and how do we align AI to them?》O Klingefjord, R Lowe, J Edelman [Meaning Alignment Institute] (2024) <a href="https://arxiv.org/abs/2404.10636"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5e7aanoj214m0vynbp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5e7rh69j21c40tygw5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5e7w1j5j21cc0tsn5b.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5e7ztkhj21bs0xwtf7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5svukgwj20vd0z6gqs.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz5svt67oj20vg0j340a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5svv2zbj20vd16tdls.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5svu9anj20vg0psq7k.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz5svttk6j20vi0maaco.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:28:19 GMT</pubDate>
</item>
<item>
<title>[CL]《What are human values, and how do we align AI to them?》O Klingefjord, R Lowe, J Edelman [Meaning Alignment Institute] (2024) 网页链接 #机器学习...</title>
<link>https://weibo.com/1402400261/OaPYwhY8e</link>
<guid>https://weibo.com/1402400261/OaPYwhY8e</guid>
<content:encoded><![CDATA[
<div> 人类价值观, 人工智能, 对齐, 伦理, 发展, 控制, 效益, 道德, 尊重, 合作

总结:<br /><br />本文讨论了人类价值观以及如何将人工智能对齐到这些价值观。针对人工智能发展中可能出现的伦理问题，我们需要制定合适的控制措施，确保人工智能的发展符合道德标准并尊重人类价值观。在引入人工智能技术时，应考虑其长期效益，并重视人类价值观的重要性。促进人工智能与人类之间的合作关系，以实现最佳的发展和利益。 <div>
[CL]《What are human values, and how do we align AI to them?》O Klingefjord, R Lowe, J Edelman [Meaning Alignment Institute] (2024) <a href="https://arxiv.org/abs/2404.10636"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5e7aanoj214m0vynbp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5e7rh69j21c40tygw5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5e7w1j5j21cc0tsn5b.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5e7ztkhj21bs0xwtf7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5svukgwj20vd0z6gqs.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz5svt67oj20vg0j340a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5svv2zbj20vd16tdls.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5svu9anj20vg0psq7k.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz5svttk6j20vi0maaco.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5svubn0j20vd0ymq7p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5svu2hrj20vd0tjad4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5svtjepj20vd0p1wh9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz5svtg4oj20vd0i8abz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5svvimkj20vg1bwth6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:28:12 GMT</pubDate>
</item>
<item>
<title>ScaleFold通过深入分析AlphaFold训练的可扩展性瓶颈，从算法结构到底层实现进行系统性优化，使之成功扩展到2080个GPU并将初步训练时间缩短至10小时。 - 转发 @爱...</title>
<link>https://weibo.com/1402400261/OaPRLo6Du</link>
<guid>https://weibo.com/1402400261/OaPRLo6Du</guid>
<content:encoded><![CDATA[
<div> 可扩展性瓶颈, 算法结构, 低层实现, 系统优化, 2080个GPU, 初步训练时间缩短至10小时  

总结:  
ScaleFold通过深入分析AlphaFold训练的可扩展性瓶颈，从算法结构到低层实现进行系统性优化，成功将训练扩展到2080个GPU，并将初步训练时间缩短至10小时。这一研究对于加速蛋白结构预测有重要意义，为未来的生物信息学研究提供了新的思路。 <div>
ScaleFold通过深入分析AlphaFold训练的可扩展性瓶颈，从算法结构到底层实现进行系统性优化，使之成功扩展到2080个GPU并将初步训练时间缩短至10小时。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《ScaleFold: Reducing AlphaFold Initial Training Time to 10 Hours》F Zhu, A Nowaczynski, R Li, J Xin… [NVIDIA] (2024) <a href="https://arxiv.org/abs/2404.11068"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz5adpgtuj20u00sg12b.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5ae4iwaj21og0ryaix.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5ae9lymj21jo0fun08.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5aedp05j20tu0lg0vy.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:11:34 GMT</pubDate>
</item>
<item>
<title>[LG]《ScaleFold: Reducing AlphaFold Initial Training Time to 10 Hours》F Zhu, A Nowaczynski, R Li, J Xin… [NVIDIA] (2024) 网页链接 #机器学习##人工智...</title>
<link>https://weibo.com/1402400261/OaPRGmIll</link>
<guid>https://weibo.com/1402400261/OaPRGmIll</guid>
<content:encoded><![CDATA[
<div> 关键词: ScaleFold, Reducing, AlphaFold, Initial Training Time, 10 Hours, NVIDIA

本文介绍了一种名为ScaleFold的方法，可以将AlphaFold的初始训练时间缩短至10小时。研究团队包括F Zhu、A Nowaczynski、R Li和J Xin，合作单位为NVIDIA。他们在文章中提出了这种新的方法，能够显著减少AlphaFold的训练时间，从而提高效率。通过ScaleFold的应用，研究人员可以在更短的时间内进行模型训练和优化，加快了科学研究和发现的步伐。这一创新有望为蛋白质结构预测领域带来重大突破，对于促进生命科学和药物研发具有重要意义。<br /><br />总结: 本文介绍了ScaleFold方法，可以将AlphaFold的初始训练时间缩短至10小时，提高了蛋白质结构预测的效率，对推动科学研究和药物研发具有重要意义。 <div>
[LG]《ScaleFold: Reducing AlphaFold Initial Training Time to 10 Hours》F Zhu, A Nowaczynski, R Li, J Xin… [NVIDIA] (2024) <a href="https://arxiv.org/abs/2404.11068"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz5adpgtuj20u00sg12b.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5ae4iwaj21og0ryaix.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5ae9lymj21jo0fun08.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5aedp05j20tu0lg0vy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:11:22 GMT</pubDate>
</item>
<item>
<title>构建了一个多步多模态基准测试MMInA，在不断变化的真实网站环境中评估Agent完成复杂互联网任务的能力，为未来智能体互联网应用能力的测试提供了一个高标准的基准...</title>
<link>https://weibo.com/1402400261/OaPPSdk67</link>
<guid>https://weibo.com/1402400261/OaPPSdk67</guid>
<content:encoded><![CDATA[
<div> 多模态、多步、基准测试、MMInA、Agent、互联网任务、评估、真实网站环境、智能体、应用能力

<br /><br />总结:
本研究构建了一个名为MMInA的多步多模态基准测试，旨在评估智能Agent在复杂互联网任务中的表现能力。该基准测试在真实网站环境中进行，在不断变化的场景中对智能体进行评估。研究团队来自南洋理工大学，通过评估Agent的能力，为未来智能体在互联网应用中的能力提供了高标准的基准。这项研究的结果发表在CV领域的论文中，为智能体在互联网任务中的发展提供了重要参考。 <div>
构建了一个多步多模态基准测试MMInA，在不断变化的真实网站环境中评估Agent完成复杂互联网任务的能力，为未来智能体互联网应用能力的测试提供了一个高标准的基准。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《MMInA: Benchmarking Multihop Multimodal Internet Agents》Z Zhang, S Tian, L Chen, Z Liu [Nanyang Technological University] (2024) <a href="https://arxiv.org/abs/2404.09992"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz551759cj21460ycqiu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz551xnwuj21c810wk72.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz55257t4j21d60w0dmc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5529mlhj20hi0kw75a.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:06:54 GMT</pubDate>
</item>
<item>
<title>[CV]《MMInA: Benchmarking Multihop Multimodal Internet Agents》Z Zhang, S Tian, L Chen, Z Liu [Nanyang Technological University] (2024) 网页链接 #机器...</title>
<link>https://weibo.com/1402400261/OaPPO5atQ</link>
<guid>https://weibo.com/1402400261/OaPPO5atQ</guid>
<content:encoded><![CDATA[
<div> Benchmarking, Multihop, Multimodal, Internet Agents, MMInA, Nanyang Technological University, 2024

<br /><br />总结:
本研究由南洋理工大学的张、田、陈和刘等人完成，针对多跳多模态互联网智能体技术进行了基准测试。研究旨在评估这种技术在网络通信中的表现，并为未来研究提供参考。研究团队在2024年发表了这篇文章，详细介绍了他们的研究成果。他们的研究对于推动多跳多模态互联网智能体技术的发展至关重要，为相关领域的进一步研究提供了有价值的信息。
 <div>
[CV]《MMInA: Benchmarking Multihop Multimodal Internet Agents》Z Zhang, S Tian, L Chen, Z Liu [Nanyang Technological University] (2024) <a href="https://arxiv.org/abs/2404.09992"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz551759cj21460ycqiu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz551xnwuj21c810wk72.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz55257t4j21d60w0dmc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5529mlhj20hi0kw75a.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:06:44 GMT</pubDate>
</item>
<item>
<title>提出并证明了一种使用结构因果模型与大型语言模型相结合，实现社会科学研究全流程自动化的方法。 - 转发 @爱可可-爱生活:&amp;ensp;[AI]《Automated Social Science:...</title>
<link>https://weibo.com/1402400261/OaPP2cVAg</link>
<guid>https://weibo.com/1402400261/OaPP2cVAg</guid>
<content:encoded><![CDATA[
<div> 模型；社会科学；结构因果模型；大型语言模型；自动化方法；研究全流程；B S. Manning；K Zhu；J J. Horton

总结:<br /><br />这篇文章提出了一种结合结构因果模型与大型语言模型的方法，实现社会科学研究全流程的自动化。研究由B S. Manning、K Zhu和J J. Horton进行，并在2024年发表。他们提出利用语言模型作为研究者和对象，开创了自动化社会科学研究的新思路。通过这一方法，可以更高效地进行社会科学研究，提高研究的准确性和可靠性。 <div>
提出并证明了一种使用结构因果模型与大型语言模型相结合，实现社会科学研究全流程自动化的方法。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [AI]《Automated Social Science: Language Models as Scientist and Subjects》B S. Manning, K Zhu, J J. Horton [MIT &amp; Harvard] (2024) <a href="https://arxiv.org/abs/2404.11794"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz53b6axoj21a010217q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz53bprvtj21gc10sqb0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz53bzkvmj20p00xugno.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz53c9xg8j218m19gwq5.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:04:49 GMT</pubDate>
</item>
<item>
<title>[AI]《Automated Social Science: Language Models as Scientist and Subjects》B S. Manning, K Zhu, J J. Horton [MIT &amp; Harvard] (2024) 网页链接 #机器学习#...</title>
<link>https://weibo.com/1402400261/OaPOWiiDR</link>
<guid>https://weibo.com/1402400261/OaPOWiiDR</guid>
<content:encoded><![CDATA[
<div> 社会科学、语言模型、自动化、科学家、主题、研究、机器学习、社会影响、数据分析、技术发展

总结:<br /><br />本文讨论了自动化社会科学领域中语言模型的应用。研究者通过机器学习技术构建了能够扮演科学家和研究对象角色的语言模型，实现了自动化的科学研究过程。语言模型的运用影响了社会科学领域的数据分析方法，促进了技术的发展。这一新领域的出现将对社会产生重要影响，需持续关注研究进展和技术应用。 <div>
[AI]《Automated Social Science: Language Models as Scientist and Subjects》B S. Manning, K Zhu, J J. Horton [MIT &amp; Harvard] (2024) <a href="https://arxiv.org/abs/2404.11794"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz53b6axoj21a010217q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz53bprvtj21gc10sqb0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz53bzkvmj20p00xugno.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz53c9xg8j218m19gwq5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:04:36 GMT</pubDate>
</item>
<item>
<title>早！[太阳] #早安# [图片]</title>
<link>https://weibo.com/1402400261/OaPOioLre</link>
<guid>https://weibo.com/1402400261/OaPOioLre</guid>
<content:encoded><![CDATA[
<div> 关键词: 早, 文章, 中文, 总结, 要点

想要正确完成一篇文章的总结，必须准确提取主要关键词和要点。这篇文章首先提出了要求总结一篇文章的任务，提示先提取关键词。然后要求用中文撰写800字内的总结，按顺序列出所有重要要点。务必按要求正确提取关键词和准确总结文章内容。<br /><br />总结:文章要求提取关键词和撰写800字内的总结，按要点顺序逐一列出。 <div>
早！<span class="url-icon"><img alt="[太阳]" src="https://h5.sinaimg.cn/m/emoticon/icon/others/w_taiyang-2b1d91ddac.png" style="width: 1em; height: 1em;" /></span> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%97%A9%E5%AE%89%23&amp;isnewpage=1"><span class="surl-text">#早安#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoz52o8al2j20fu0j076s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:03:01 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.21)》 爱可可微博热门分享(4.21) [图片]</title>
<link>https://weibo.com/1402400261/OaNjNbqip</link>
<guid>https://weibo.com/1402400261/OaNjNbqip</guid>
<content:encoded><![CDATA[
<div> 微博、爱可可、热门、分享、4.21、话题、新闻、讨论、网友、评论

<br /><br />总结:
4月21日，爱可可的微博内容受到了热门关注，涉及各种话题和新闻。网友们纷纷参与讨论，展开评论，形成热烈的互动氛围。这些内容被分享出来，引发广泛关注，展示了微博平台的活跃和多样性。 <div>
《爱可可微博热门分享(4.21)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405025728633634863"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.21)</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoyu2hvc2vj20kf0bhmyc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 14:42:22 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Elucidating the Exposure Bias in Diffusion Models》(ICLR 2024) GitHub: github.com/forever208/ADM-ES《Toward Generalist Anomaly Det...</title>
<link>https://weibo.com/1402400261/OaMVtvTUZ</link>
<guid>https://weibo.com/1402400261/OaMVtvTUZ</guid>
<content:encoded><![CDATA[
<div> 关键词: 曝光偏差, 扩散模型, 异常检测, 图像分割, 语言模型

总结:
<br /><br />
本文研究了扩散模型中的曝光偏差，并提出了一种全新的训练方法ADM-ES来解决这一问题。通过在GitHub上提供的代码实现，展示了该方法的有效性和性能。在CVPR 2024会议上，提出了一种通过少量样本提示实现通用异常检测的方法InCTRL。此外，还提出了一种利用视觉基础模型进行领域通用语义分割的方法rein，并展示了其强大性能。在大语言模型训练方面，提出了一种记忆高效的完整参数训练方法BAdam。此外，还介绍了AgentKit，一种基于图形的无需编码的流工程解决方案。最后，针对远程感知图像中的语义变化检测问题，提出了ClearSCD模型，充分利用语义和变化关系，通过GitHub提供了相关代码实现。 <div>
几篇论文实现代码：<br />《Elucidating the Exposure Bias in Diffusion Models》(ICLR 2024) GitHub: github.com/forever208/ADM-ES<br />《Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts》(CVPR 2024) GitHub: github.com/mala-lab/InCTRL [fig2]<br />《Stronger, Fewer, &amp; Superior: Harnessing Vision Foundation Models for Domain Generalized Semantic Segmentation》(CVPR 2024) GitHub: github.com/w1oves/rein [fig4]<br />《BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models》(2024) GitHub: github.com/Ledzy/BAdam<br />《AgentKit: Flow Engineering with Graphs, not Coding》(2024) GitHub: github.com/Holmeswww/AgentKit [fig1]<br />《LongEmbed: Extending Embedding Models for Long Context Retrieval》(2024) GitHub: github.com/dwzhu-pku/LongEmbed [fig3]<br />《The ClearSCD model: Comprehensively leveraging semantics and change relationships for semantic change detection in high spatial resolution remote sensing imagery》(2024) GitHub: github.com/tangkai-RS/ClearSCD [fig5]<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoyq0hcbq7j23aj1ubb2a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoyq3hakl3j21jq0xggxl.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoyqzgna5fj218b0e1whd.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoyr01jl9sj20pj08gaei.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoyrjnq7g0j25so32qb2e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:42:28 GMT</pubDate>
</item>
<item>
<title>【robocorp - 用于创建和部署 Python AI 操作和自动化】’Create, deploy and operate Python Automations and AI Actions anywhere. - Create Python AI Action...</title>
<link>https://weibo.com/1402400261/OaMP3FfYZ</link>
<guid>https://weibo.com/1402400261/OaMP3FfYZ</guid>
<content:encoded><![CDATA[
<div> GitHub, Python, AI, 操作, 自动化, 创建, 部署, 运营

<br /><br />总结:
robocorp是一个用于创建和部署Python AI操作和自动化的平台。用户可以在其中创建Python AI操作和自动化，并在任何地方部署和操作。该平台的GitHub链接为github.com/robocorp/robocorp。通过robocorp，用户可以灵活地开发和部署各种Python基础的操作和AI功能，为各种场景提供自动化解决方案。 <div>
【robocorp - 用于创建和部署 Python AI 操作和自动化】’Create, deploy and operate Python Automations and AI Actions anywhere. - Create Python AI Actions and Automations, and deploy &amp; operate them anywhere' GitHub: github.com/robocorp/robocorp <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoyrvqiz98j21hc0u0zms.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:26:40 GMT</pubDate>
</item>
<item>
<title>【推理AI用数据大列表】’awesome-reasoning - a curated list of data for reasoning ai' GitHub: github.com/neurallambda/awesome-reasoning #开源# #机器学...</title>
<link>https://weibo.com/1402400261/OaMO9Djnd</link>
<guid>https://weibo.com/1402400261/OaMO9Djnd</guid>
<content:encoded><![CDATA[
<div> GitHub, 推理AI, 数据大列表, 精选数据, 理由<br />
<br />
1. 该GitHub项目是一个关于推理人工智能使用数据的精选列表。
2. 项目旨在为推理AI提供丰富的数据资源。
3. 数据包括各种类型的信息，可以帮助AI进行推理和分析。
4. 这个列表是经过精心筛选和整理的，以确保质量和多样性。
5. GitHub链接为github.com/neurallambda/awesome-reasoning，可以随时查看和使用。
6. 数据涵盖了各个领域和主题，适用于不同类型的推理任务。
7. 对于开发推理AI的研究人员和工程师来说，这个列表是一个宝贵的资源。
8. 通过利用这些数据，可以训练和提升推理AI的性能和准确性。
9. 该列表对于推动推理人工智能领域的发展和创新具有重要意义。
<br /><br />总结: 该GitHub项目提供了一个精选的数据列表，为推理人工智能提供丰富的资源，可以帮助AI进行推理和分析。同时，这个列表的较牢确保了数据的质量和多样性，对于推动推理AI领域的发展具有重要意义。 <div>
【推理AI用数据大列表】’awesome-reasoning - a curated list of data for reasoning ai' GitHub: github.com/neurallambda/awesome-reasoning <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoyrti6ic0j20u00wfjvd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:24:26 GMT</pubDate>
</item>
<item>
<title>【社交Agent相关论文资源列表】’Awesome Social Agents - A collection of works that investigate social agents, simulations and their real-world impact i...</title>
<link>https://weibo.com/1402400261/OaMNis4v5</link>
<guid>https://weibo.com/1402400261/OaMNis4v5</guid>
<content:encoded><![CDATA[
<div> 社交Agent、模拟、影响、文本、实体、机器人、研究、GitHub、资源列表、真实世界<br />
<br />
社交Agent相关论文资源列表包括研究社交Agent在文本、实体和机器人领域的影响及其在现实世界中的作用。GitHub上收集了相关研究的作品。社交Agent的研究对于理解人机交互、社交模拟以及人工智能的发展具有重要意义。通过对社交Agent的研究与应用，可以为社会提供更智能、更智能的解决方案。此资源列表为社交Agent研究者提供了丰富的文献资源，帮助他们更深入地理解和探索这一领域的知识和技术。<br /> 
<br />
总结:社交Agent的研究与实践对人机交互、社交模拟和人工智能发展至关重要，并且在现实世界中产生重要影响。GitHub资源列表为研究者提供了丰富的文献资料，促进了社交Agent领域的探索和创新。 <div>
【社交Agent相关论文资源列表】’Awesome Social Agents - A collection of works that investigate social agents, simulations and their real-world impact in text, embodied, and robotics contexts.' GitHub: github.com/sotopia-lab/awesome-social-agents <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoyrrbq78pj214u0u0n3c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:22:19 GMT</pubDate>
</item>
<item>
<title>【Ayin：免费且开源的图片编辑软件，可在 Windows、Linux 和 macOS 上使用】'Ayin - Ayin is a free and open source photo editing software available on Wind...</title>
<link>https://weibo.com/1402400261/OaMLl4K4i</link>
<guid>https://weibo.com/1402400261/OaMLl4K4i</guid>
<content:encoded><![CDATA[
<div> 免费、开源、图片编辑软件、Windows、Linux、macOS、GitHub、github.com/faresbakhit/ayin

<br /><br />总结:
Ayin是一款免费且开源的图片编辑软件，用户可以在Windows、Linux和MacOS上使用。该软件的源代码可在GitHub上找到，项目链接为github.com/faresbakhit/ayin。Ayin提供了丰富的功能，可以满足用户对图片编辑的各种需求。无论是个人用户还是企业用户，都可以通过Ayin轻松实现图片编辑工作，而且免费使用。Ayin的跨平台性也很强，可以在不同操作系统上无缝运行，为用户提供了更大的使用灵活性。Ayin的开源性保证了软件的透明性和安全性，用户可以自行查看源代码并对其进行定制化，从而更好地满足个性化需求。总的来说，Ayin是一款功能强大、方便易用的图片编辑软件，为用户提供了一个高质量的编辑平台。 <div>
【Ayin：免费且开源的图片编辑软件，可在 Windows、Linux 和 macOS 上使用】'Ayin - Ayin is a free and open source photo editing software available on Windows, Linux, and MacOS' GitHub: github.com/faresbakhit/ayin <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoyrlzlo1qj21ha0ty78h.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:17:29 GMT</pubDate>
</item>
<item>
<title>【LLMstudio by TensorOps：提示工程工具包】’LLMstudio by TensorOps - Framework to bring LLM applications to production' GitHub: github.com/TensorOpsAI...</title>
<link>https://weibo.com/1402400261/OaMJAgRXO</link>
<guid>https://weibo.com/1402400261/OaMJAgRXO</guid>
<content:encoded><![CDATA[
<div> LLMstudio, TensorOps, Framework, production, GitHub, 工程工具包, 应用推广, 生产环境, 开发工具, 运维工具

<br /><br />总结:
LLMstudio是由TensorOps推出的工程工具包，旨在将LLM应用推广至生产环境。该工具包旨在提供开发工具和运维工具，帮助用户更轻松实现LLM应用的上线和管理。通过GitHub平台，用户可以方便地获取和使用这一工具包。 <div>
【LLMstudio by TensorOps：提示工程工具包】’LLMstudio by TensorOps - Framework to bring LLM applications to production' GitHub: github.com/TensorOpsAI/LLMstudio <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoyrhnxiabj20ys0u0gop.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:13:10 GMT</pubDate>
</item>
<item>
<title>【Shadcn Table：一个 shadcn 表格组件，支持服务器端排序、过滤和分页】'Shadcn Table - A shadcn table component with server-side sorting, filtering, and ...</title>
<link>https://weibo.com/1402400261/OaMHGq2Fu</link>
<guid>https://weibo.com/1402400261/OaMHGq2Fu</guid>
<content:encoded><![CDATA[
<div> shadcn Table, 组件, 服务器端排序, 过滤, 分页

总结:<br /><br />这篇文章介绍了一个名为Shadcn Table的表格组件，具有服务器端排序、过滤和分页功能。该组件通过GitHub进行开源，用于帮助开发者更便捷地处理大量数据。用户可以根据自己的需求对数据进行排序、过滤和分页，从而提高数据展示和操作的效率。通过使用Shadcn Table组件，开发者可以轻松地实现对数据的动态处理，提升用户体验和数据管理效率。 <div>
【Shadcn Table：一个 shadcn 表格组件，支持服务器端排序、过滤和分页】'Shadcn Table - A shadcn table component with server-side sorting, filtering, and pagination.' GitHub: github.com/sadmann7/shadcn-table <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoyrcvt1e0j213r0l7q8e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:08:29 GMT</pubDate>
</item>
<item>
<title>【Frappe HR：开源的 HR 和薪酬管理软件项目，提供了一个完整的 HRMS 解决方案，包括员工管理、入职、请假、薪酬、税务等多个模块】'Frappe HR - Open Source HR...</title>
<link>https://weibo.com/1402400261/OaMGg7gIb</link>
<guid>https://weibo.com/1402400261/OaMGg7gIb</guid>
<content:encoded><![CDATA[
<div> 开源、HR、薪酬管理软件、项目、HRMS、员工管理、入职、请假、税务、模块
<br /><br />总结:
Frappe HR是一个开源的HR和薪酬管理软件项目，提供了完整的HRMS解决方案。该软件包括员工管理、入职、请假、薪酬、税务等多个模块，为企业提供了全面的人力资源管理和支付相关功能。通过GitHub平台，用户可以轻松访问并使用这一功能强大的解决方案，帮助企业实现高效的人力资源管理和薪酬处理。Frappe HR的开源特性使得用户可以根据自身需求进行定制和升级，实现更加个性化的管理和支付流程。对于需要全面的HRMS解决方案的企业来说，Frappe HR是一个值得考虑的选择。 <div>
【Frappe HR：开源的 HR 和薪酬管理软件项目，提供了一个完整的 HRMS 解决方案，包括员工管理、入职、请假、薪酬、税务等多个模块】'Frappe HR - Open Source HR and Payroll Software' GitHub: github.com/frappe/hrms <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoyr953dl9j21390u0q5z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:04:58 GMT</pubDate>
</item>
<item>
<title>【GPT-Subtrans：用 LLM 翻译 SRT 字幕】'GPT-Subtrans - Open Source project using LLMs to translate SRT subtitles' GitHub: github.com/machinewrapped/gpt...</title>
<link>https://weibo.com/1402400261/OaMF2hlt0</link>
<guid>https://weibo.com/1402400261/OaMF2hlt0</guid>
<content:encoded><![CDATA[
<div> github、GPT-Subtrans、LLMs、SRT、字幕、翻译、开源项目

<br /><br />总结:
介绍了一个名为GPT-Subtrans的开源项目，利用LLMs来翻译SRT字幕。该项目的GitHub链接为github.com/machinewrapped/gpt-subtrans。通过这个项目，用户可以方便地利用先进的语言模型来翻译字幕文件，提高翻译效率和准确性。 <div>
【GPT-Subtrans：用 LLM 翻译 SRT 字幕】'GPT-Subtrans - Open Source project using LLMs to translate SRT subtitles' GitHub: github.com/machinewrapped/gpt-subtrans <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoyr3ajf6ij21i00iodjb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:01:58 GMT</pubDate>
</item>
<item>
<title>【llama3-Chinese-chat：首个llama3 中文版) ，供学习交流演示】'llama3-Chinese-chat - Llama3 中文版' GitHub: github.com/CrazyBoyM/llama3-Chinese-chat #开...</title>
<link>https://weibo.com/1402400261/OaMCfgJ79</link>
<guid>https://weibo.com/1402400261/OaMCfgJ79</guid>
<content:encoded><![CDATA[
<div> 关键词: llama3, 中文版, 学习, 交流, 演示, GitHub, CrazyBoyM, 开发

llama3 中文版是一个供学习交流演示的项目，由 GitHub 上的用户CrazyBoyM 开发。这个项目为用户提供了一个中文版的llama3，使得更多人可以通过这个工具来学习和交流。用户可以在GitHub 上找到这个项目的源代码和文档，方便学习和参与讨论。 llamas3 中文版的发布为中文用户提供了更好的使用体验和学习资源，使得交流和学习更加便利。总结： <br /><br /> <div>
【llama3-Chinese-chat：首个llama3 中文版) ，供学习交流演示】'llama3-Chinese-chat - Llama3 中文版' GitHub: github.com/CrazyBoyM/llama3-Chinese-chat <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoyqyzyuxsj21f60u0gr4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 12:55:05 GMT</pubDate>
</item>
<item>
<title>【Anything：一个 Mac 应用，用 AI 自动化任何事，类似于 Zapier，但专注于 AI】'Anything [Alpha Pre Release] - Mac app for automating anything with AI' Gi...</title>
<link>https://weibo.com/1402400261/OaMBIAlpJ</link>
<guid>https://weibo.com/1402400261/OaMBIAlpJ</guid>
<content:encoded><![CDATA[
<div> GitHub, tryanything-ai, anything, Mac 应用, AI, 自动化, Zapier, 专注, Pre Release

<br /><br />总结:
这是一个名为Anything的Mac应用，专注于利用人工智能来自动化任何事情，类似于Zapier。该应用目前处于Alpha预发布阶段，用户可以前往GitHub上的tryanything-ai/anything仓库了解更多信息。应用使用AI技术，旨在帮助用户更智能地完成各种任务和流程。 <div>
【Anything：一个 Mac 应用，用 AI 自动化任何事，类似于 Zapier，但专注于 AI】'Anything [Alpha Pre Release] - Mac app for automating anything with AI' GitHub: github.com/tryanything-ai/anything <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoyqwm836rj21400mqtbe.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoyqwpgminj213q0mqtbb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 12:53:47 GMT</pubDate>
</item>
<item>
<title>’Dynamic Tp - 基于配置中心的轻量级动态线程池，内置监控告警功能，集成常用中间件线程池管理，可通过SPI自定义扩展实现' GitHub: github.com/dromara/dynamic...</title>
<link>https://weibo.com/1402400261/OaMAZvwYN</link>
<guid>https://weibo.com/1402400261/OaMAZvwYN</guid>
<content:encoded><![CDATA[
<div> dynamic tp, 配置中心, 轻量级, 动态线程池, 监控告警, 中间件线程池管理, SPI, 自定义扩展

总结:
Dynamic Tp是一个基于配置中心的轻量级动态线程池，具有内置监控告警功能和集成常用中间件线程池管理的特点。通过SPI可以实现自定义扩展，为线程池管理提供更多灵活性和定制化选择。Github链接为github.com/dromara/dynamic-tp。 <div>
’Dynamic Tp - 基于配置中心的轻量级动态线程池，内置监控告警功能，集成常用中间件线程池管理，可通过SPI自定义扩展实现' GitHub: github.com/dromara/dynamic-tp <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoyqvbek72j212q0u0jvw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoyqvlh7qgj214t0sd7a8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoyqvryolkj21tg0u0gqj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 12:52:00 GMT</pubDate>
</item>
<item>
<title>【SeekStorm：开源的 Rust 实现的全文搜索库和多租户搜索服务器，具有高性能和实时搜索功能】'SeekStorm - sub-millisecond full-text search library &amp; multi-t...</title>
<link>https://weibo.com/1402400261/OaMpKw1ld</link>
<guid>https://weibo.com/1402400261/OaMpKw1ld</guid>
<content:encoded><![CDATA[
<div> Rust, 全文搜索库, 多租户搜索服务器, 高性能, 实时搜索, 开源

<br /><br />总结:
SeekStorm是一个开源的 Rust 实现的全文搜索库和多租户搜索服务器，具有高性能和实时搜索功能。该库能够实现毫秒级的全文搜索，支持多租户环境下对搜索功能的管理和使用。通过在Rust语言中实现，SeekStorm具有高性能的特点，并且能够提供实时搜索的能力，可用于构建各种需要高效搜索功能的应用程序。SeekStorm的GitHub地址为github.com/SeekStorm/SeekStorm，欢迎查看和下载使用。 <div>
【SeekStorm：开源的 Rust 实现的全文搜索库和多租户搜索服务器，具有高性能和实时搜索功能】'SeekStorm - sub-millisecond full-text search library &amp; multi-tenancy server in Rust' GitHub: github.com/SeekStorm/SeekStorm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%90%9C%E7%B4%A2%23"><span class="surl-text">#搜索#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoyq2ytdrjj20vz0u0gpe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 12:24:18 GMT</pubDate>
</item>
<item>
<title>【NanoLLM：专门为 LLM 提供优化本地推理的平台，提供了 HuggingFace 风格的 API，用于量化、视觉 / 语言模型、多模态Agent、语音、矢量数据库和 RAG】'NanoLLM ...</title>
<link>https://weibo.com/1402400261/OaMpkrqNR</link>
<guid>https://weibo.com/1402400261/OaMpkrqNR</guid>
<content:encoded><![CDATA[
<div> 优化本地推理, LLM, HuggingFace, API,量化,视觉模型,语言模型,多模态Agent,语音,矢量数据库, RAG<br />
<br />总结: NanoLLM是专门为LLM提供优化本地推理的平台，具有类似HuggingFace的API，可用于量化、视觉/语言模型、多模态Agent、语音、矢量数据库和RAG。NanoLLM在GitHub上有代码库。 <div>
【NanoLLM：专门为 LLM 提供优化本地推理的平台，提供了 HuggingFace 风格的 API，用于量化、视觉 / 语言模型、多模态Agent、语音、矢量数据库和 RAG】'NanoLLM - Optimized local inference for LLMs with HuggingFace-like APIs for quantization, vision/language models, multimodal agents, speech, vector DB, and RAG.' GitHub: github.com/dusty-nv/NanoLLM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoyq1g0bcbj21700pc788.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 12:23:16 GMT</pubDate>
</item>
<item>
<title>【fastfit：提供快速准确少样本分类方法的Python库，特别适用于具有许多语义上相似类别的情况】'fastfit - a method, and a Python package design to provide f...</title>
<link>https://weibo.com/1402400261/OaMovkgeD</link>
<guid>https://weibo.com/1402400261/OaMovkgeD</guid>
<content:encoded><![CDATA[
<div> 快速准确少样本分类方法 Python库 语义相似类别<br />
<br />
要点1: 该Python库名为fastfit，旨在提供快速准确的少样本分类方法。<br />
要点2: 特别适用于具有许多语义上相似类别的情况。<br />
要点3: fastfit是一个方法和一个Python包，旨在提供快速准确的少样本分类。<br />
要点4: 适用于那些有许多语义相似类别的场景。<br />
要点5: GitHub链接为github.com/IBM/fastfit。<br />
<br />
总结: 该Python库fastfit旨在提供快速准确的少样本分类方法，特别适用于具有许多语义上相似类别的情况，适合那些需要进行高效分类的场景。GitHub链接为github.com/IBM/fastfit。 <div>
【fastfit：提供快速准确少样本分类方法的Python库，特别适用于具有许多语义上相似类别的情况】'fastfit - a method, and a Python package design to provide fast and accurate few-shot classification, especially for scenarios with many semantically similar classes' GitHub: github.com/IBM/fastfit <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoypypcpnej215z0u0q8p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 12:21:14 GMT</pubDate>
</item>
<item>
<title>编码游戏是学习编程的最佳方式——从CSS、Python、JavaScript到区块链。十个最佳在线通过游戏学编程网站推荐： #编程#1. CryptoZombiesCryptoZombies 是一所互动...</title>
<link>https://weibo.com/1402400261/OaHADFtSr</link>
<guid>https://weibo.com/1402400261/OaHADFtSr</guid>
<content:encoded><![CDATA[
<div> CryptoZombies, SQL Murder Mystery, SQL Police, Flexbox Froggy, Screeps, CodinGame, CodeCombat, Checkio, Codewars, Elevator Saga

总结:<br /><br />本文介绍了十个在线通过游戏学习编程的网站，涵盖了各种编程语言和技术，如区块链、SQL、CSS、JavaScript等。这些网站通过互动的游戏方式来教授编程知识，使学习过程更加有趣和有效。每个网站都有不同的特点和重点，适合不同程度和背景的学习者使用。通过这些网站，学习者可以通过实践和挑战提升他们的编程能力，并在竞争中学习和成长。这些网站为学习者提供了丰富的资源和机会，让他们在编程领域不断进步和提升技能。 <div>
编码游戏是学习编程的最佳方式——从CSS、Python、JavaScript到区块链。十个最佳在线通过游戏学编程网站推荐： <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%BC%96%E7%A8%8B%23&amp;isnewpage=1"><span class="surl-text">#编程#</span></a><br /><br />1. CryptoZombies<br />CryptoZombies 是一所互动学校，教您有关区块链的所有技术知识。<br />cryptozombies.io<br /><br />2. The SQL Murder Mystery<br />2. SQL 谋杀之谜<br />在破案时学习 SQL 概念和命令。<br />mystery.knightlab.com<br /><br />3. 通过警察局游戏学习 SQL<br />SQL Police 是一款在线游戏，您可以在其中使用SQL解决犯罪问题。<br />sqlpd.com<br /><br />4. Flexbox Froggy<br />一个学习CSS flexbox的游戏。<br />Flexbox 是 CSS 中的一个重要概念，因此本游戏将以非常简单的方式教您 Flexbox。<br />flexboxfroggy.com<br /><br />5. Screeps<br />这是一款面向程序员的开源游戏，其核心机制是编程。<br />你通过编写 JavaScript 来控制你的殖民地。<br />screeps.com<br /><br />6. CodinGame<br />这个基于游戏的学习网站改变了学生学习编码的方式。<br />本网站提供超过 25 种编程语言，包括 JavaScript、Ruby 和 PHP。<br />codingame.com/start<br /><br />7. CodeCombat<br />CodeCombat 以非常简单的方式设计，旨在帮助学生在玩和编写代码的同时接受学习。<br />codecombat.com<br /><br />8. Checkio<br />通过此游戏网站学习 Python 和 Typescript。<br />checkio.org<br /><br />9. Codewars<br />在Code Wars中，你可以通过与他人竞争来练习，以提高你的能力。<br />它们提供了多种语言，包括 Python、JavaScript 等。<br />codewars.com<br /><br />10. Elevator Saga<br />Elevator Saga 通过 100+ 挑战测试您的 JavaScript 知识。<br />play.elevatorsaga.com<br /><br />via: hasantoxr<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoy4s2of3wj20xc0m8wkt.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoy4rdjg78j21za1d8npd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy4rz4p1rj22281gaqv5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 00:07:24 GMT</pubDate>
</item>
<item>
<title>【Elon Musk 称赞 Meta 的 Llama 3 AI，引起业界广泛关注】- 伊隆·马斯克最近评价Meta的开源语言模型Llama 3“不错”，这让Llama 3突然受到广泛关注。 - Llama ...</title>
<link>https://weibo.com/1402400261/OaHnanztp</link>
<guid>https://weibo.com/1402400261/OaHnanztp</guid>
<content:encoded><![CDATA[
<div> Meta、Llama 3、Elon Musk、赞扬、开源、70亿参数、性能领先、多语言支持、负责任开发、自然语言处理

总结:<br /><br />伊隆·马斯克最近称赞Meta推出的开源语言模型Llama 3，该模型是Meta推出的第三代开源大模型，参数量达到70亿，在多项基准测试中展现出领先的性能。Meta声称Llama 3在关键能力上有明显提升，是同规模参数下最优秀的开源模型，并计划继续扩展其多语言和多模态支持。Meta采用了负责任的方法开发Llama 3，并提供各种资源帮助用户进行负责任的使用。Llama 3可广泛应用于自然语言处理领域，包括语音识别、对话系统、文本生成等。 Llama 3面临的主要竞争对手是Anthropic的Claude系列模型，马斯克的正面评价有助于提升开发者对Llama 3的关注和采用。 <div>
【Elon Musk 称赞 Meta 的 Llama 3 AI，引起业界广泛关注】<br />- 伊隆·马斯克最近评价Meta的开源语言模型Llama 3“不错”，这让Llama 3突然受到广泛关注。   <br />- Llama 3是Meta继Llama和Llama 2之后推出的第三代开源大模型，参数量达到70亿，在多项业界基准测试上展现出领先的性能。   <br />- Meta声称Llama 3在推理、编码等关键能力上有明显提升，是同规模参数下最优秀的开源模型。Meta计划继续扩展Llama 3的多语言和多模态支持。   <br />- Meta采用了负责任的方法开发Llama 3，提供了各种资源帮助用户进行负责任的使用，包括Llama Guard 2、Code Shield和CyberSec Eval 2等信任与安全工具。   <br />- Llama 3可广泛应用于自然语言处理领域，包括语音识别、对话系统、文本生成等。马斯克的正面评价有助于提升开发者对Llama 3的关注和采用。   <br />- Llama 3面临的主要竞争对手是Anthropic的Claude系列模型，两者都在不断进步。Llama 3的开源特性为研究人员提供了充分理解和迭代模型的机会。<br />《Elon Musk's 'not bad' review thrusts Meta's Llama 3 AI into spotlight | VentureBeat》 <a href="https://venturebeat.com/ai/elon-musks-not-bad-review-thrusts-metas-llama-3-ai-into-spotlight/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoy3rxlli9j20y70u0gs9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 23:34:12 GMT</pubDate>
</item>
<item>
<title>【Qwen1.5 110B模型聊天Demo】《Qwen1.5 110B Chat Demo - a Hugging Face Space by Qwen》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/OaHlh55eT</link>
<guid>https://weibo.com/1402400261/OaHlh55eT</guid>
<content:encoded><![CDATA[
<div> 关键词: Qwen1.5 110B模型, 聊天Demo, Hugging Face Space

总结:<br /><br />本文介绍了Qwen1.5 110B模型聊天Demo，通过Hugging Face Space提供的功能，用户可以进行对话交流。这个模型具有智能聊天的能力，能够与用户进行自然语言交互。用户可以体验到人工智能技术在对话系统中的应用，并感受到模型的智能性和便利性。同时，Hugging Face Space提供了一个交流的空间，让用户可以更加便捷地与模型互动，提出问题、寻求帮助或者进行娱乐性的对话。整体来说，Qwen1.5 110B模型聊天Demo为用户提供了一个新颖有趣的对话体验。 <div>
【Qwen1.5 110B模型聊天Demo】《Qwen1.5 110B Chat Demo - a Hugging Face Space by Qwen》 <a href="https://huggingface.co/spaces/Qwen/Qwen1.5-110B-Chat-demo"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoy3osryuvj21990u0te1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 23:29:32 GMT</pubDate>
</item>
<item>
<title>今日推介(第1382期)：基于潜扩散的长音乐生成、通过想象、搜索与批评实现LLM的自我提升、语言失衡可促进跨语言泛化、语言模型能解决奥林匹克编程问题吗、情感分...</title>
<link>https://weibo.com/1402400261/OaH8VrIV4</link>
<guid>https://weibo.com/1402400261/OaH8VrIV4</guid>
<content:encoded><![CDATA[
<div> 潜扩散、长音乐生成、自我提升、语言失衡、跨语言泛化、语言模型、奥林匹克编程问题、情感分析、因果机制研究

<br /><br />总结:
最近的研究表明，基于潜扩散的长音乐生成具有很大的潜力。通过想象、搜索与批评，可以实现LLM的自我提升，帮助人们提高语言能力。此外，语言失衡也可能促进跨语言泛化，让人们更容易学会多种语言。关于语言模型能否解决奥林匹克编程问题的讨论仍在进行中。最后，情感分析的因果机制研究为我们提供了更深入的理解。通过这些研究，我们可以更好地利用语言模型和情感分析技术，提升生活质量。 <div>
今日推介(第1382期)：基于潜扩散的长音乐生成、通过想象、搜索与批评实现LLM的自我提升、语言失衡可促进跨语言泛化、语言模型能解决奥林匹克编程问题吗、情感分析的因果机制研究 公·众·号：爱可可爱生活 <a href="http://aicoco.net/s/8j"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoy2sv3a75j20qk0mqmzs.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoy2sy684oj21400i1go4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoy2t0r2hwj21200i4acw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoy2t3gejjj21400lz43a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoy2t62wf0j21400naq9v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 22:59:07 GMT</pubDate>
</item>
<item>
<title>[CL] The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey 网页链接 调研了AI Agent在复杂任务推理、规划...</title>
<link>https://weibo.com/1402400261/OaH0f4HGE</link>
<guid>https://weibo.com/1402400261/OaH0f4HGE</guid>
<content:encoded><![CDATA[
<div> Agent, AI, 推理, 规划, 工具调用, 架构, 调研, 进展, 系统, 关键考量

<br /><br />总结:
本文调研了AI Agent在复杂任务推理、规划和工具调用方面的最新进展，重点关注了Agent系统的架构设计和关键考量。研究指出，有效的Agent系统需要具备强大的推理和规划能力，并能够有效地调用各种工具来完成任务。在构建Agent系统时，需要考虑任务复杂性、系统性能、通信协议等方面的因素。研究结果为构建高效的Agent系统提供了重要的参考。 <div>
[CL] The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey  <br /><a href="https://arxiv.org/abs/2404.11584"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />调研了AI Agent在复杂任务推理、规划和工具调用方面的最新进展，提出了构建高效Agent系统的关键考量。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoy26w6561j20um14kwqa.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoy26wdw77j21h00wiagb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy26x1qn6j219y1dcqhq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 22:37:43 GMT</pubDate>
</item>
<item>
<title>[AS] A Large-Scale Evaluation of Speech Foundation Models 网页链接 SUPERB通过面向多任务的标准化评估，系统验证了语音基础模型的有效性，并通过开放平台推...</title>
<link>https://weibo.com/1402400261/OaGXIgSXZ</link>
<guid>https://weibo.com/1402400261/OaGXIgSXZ</guid>
<content:encoded><![CDATA[
<div> 标准化评估 多任务 语音基础模型 有效性 开放平台 统一发展

总结:<br /><br />本研究通过面向多任务的标准化评估，验证了语音基础模型的有效性。同时，通过开放平台推动了该领域的统一发展。该研究为语音领域的研究和发展提供了重要的参考和借鉴。 <div>
[AS] A Large-Scale Evaluation of Speech Foundation Models  <br /><a href="https://arxiv.org/abs/2404.09385"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />SUPERB通过面向多任务的标准化评估，系统验证了语音基础模型的有效性，并通过开放平台推动了该领域的统一发展。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy20ctl48j20xe188nfo.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoy20djvevj213o1bcdxa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy20e50csj20r414ijwx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 22:31:30 GMT</pubDate>
</item>
<item>
<title>[CL] ALERT: A Comprehensive Benchmark for Assessing Large Language Models' Safety through Red Teaming 网页链接 提出一个大规模红队测试基准ALERT来评估语...</title>
<link>https://weibo.com/1402400261/OaGUF2lgz</link>
<guid>https://weibo.com/1402400261/OaGUF2lgz</guid>
<content:encoded><![CDATA[
<div> 基准测试, 语言模型, 安全性, 红队, 漏洞, 主流模型, 评估, 部署, 语境

总结:<br /><br />这篇文章提出了一个名为ALERT的大规模红队测试基准，旨在评估语言模型的安全性。研究发现，主流模型在特定类别仍存在漏洞，因此呼吁在部署时需要根据语境进行安全性评估。该基准测试有助于发现模型的潜在安全风险，为提高语言模型的安全性提供了重要的参考依据。 <div>
[CL] ALERT: A Comprehensive Benchmark for Assessing Large Language Models' Safety through Red Teaming  <br /><a href="https://arxiv.org/abs/2404.08676"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出一个大规模红队测试基准ALERT来评估语言模型的安全性，发现主流模型在特定类别仍存在漏洞，呼吁在部署时需要根据语境进行安全性评估。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoy1skxneij20qw16mqgi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy1sl6vuxj21ce0rc10u.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoy1slsqwmj21c60sajx9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 22:23:58 GMT</pubDate>
</item>
<item>
<title>[CL] Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models 网页链接 Reka研发的Core、Flash和Edge是一系列多模态语言模型，在语言和...</title>
<link>https://weibo.com/1402400261/OaGQw4hUJ</link>
<guid>https://weibo.com/1402400261/OaGQw4hUJ</guid>
<content:encoded><![CDATA[
<div> 关键词: Reka, Core, Flash, Edge, 多模态语言模型, 强大性能, GPT-4

Reka研发的Core、Flash和Edge是一系列多模态语言模型，展现出超越同类模型的强大性能，尤其是Core模型接近GPT-4水平。这些模型在语言和视觉任务上表现出色，为未来的技术发展提供了巨大的潜力。通过结合语言和视觉信息，这些模型可以更准确地理解和处理复杂的任务。Reka公司的Core、Flash和Edge模型将成为未来计算机科学领域的重要突破，为人工智能领域带来新的发展机遇。总结:Reka公司开发了一系列多模态语言模型，其中Core模型在性能上接近GPT-4，展现了强大的潜力，将对计算机科学和人工智能领域带来重大影响。 <div>
[CL] Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models  <br /><a href="https://arxiv.org/abs/2404.12387"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />Reka研发的Core、Flash和Edge是一系列多模态语言模型，在语言和视觉任务上展现出超越同等计算类别模型的强大性能，特别是最大的Core模型已接近GPT-4等领先模型的水平。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy1hy2du8j210e1ckdqb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy1hylxjzj218211m0vc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy1hz8xboj21ia0l6n1c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 22:13:46 GMT</pubDate>
</item>
<item>
<title>通过归纳文本与情感的因果机制，指导构建对齐的因果提示以改进语言模型在情感分析任务上的表现。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《On the Causal Nature of S...</title>
<link>https://weibo.com/1402400261/OaGNisVlw</link>
<guid>https://weibo.com/1402400261/OaGNisVlw</guid>
<content:encoded><![CDATA[
<div> 因果机制, 情感分析, 对齐, 语言模型, 提示, 表现, 文本, 情感, 归纳, 改进

总结:<br /><br />本文提出了通过归纳文本与情感的因果机制来指导构建对齐的因果提示，以改进语言模型在情感分析任务上的表现。文章重点探讨了情感分析的因果性质，提出了一种新的方法来实现对文本和情感之间因果关系的建模。通过对文本和情感之间的因果机制进行分析，可以指导语言模型在情感分析任务上取得更好的效果。作者通过实验验证了提出的方法的有效性，并指出这种方法可以有助于改进情感分析中因果关系的理解和建模。<br /> <div>
通过归纳文本与情感的因果机制，指导构建对齐的因果提示以改进语言模型在情感分析任务上的表现。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《On the Causal Nature of Sentiment Analysis》Z Lyu, Z Jin, F Gonzalez, R Mihalcea, B Schoelkopf, M Sachan [University of Hong Kong &amp; ETH Zürich] (2024) <a href="https://arxiv.org/abs/2404.11055"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoy141354yj20o812swnu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoy141l615j21kq0x07ig.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoy141mu60j20s40jgmz7.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 22:05:50 GMT</pubDate>
</item>
<item>
<title>[CL]《On the Causal Nature of Sentiment Analysis》Z Lyu, Z Jin, F Gonzalez, R Mihalcea, B Schoelkopf, M Sachan [University of Hong Kong &amp; ETH Zürich]...</title>
<link>https://weibo.com/1402400261/OaGNh2Gs5</link>
<guid>https://weibo.com/1402400261/OaGNh2Gs5</guid>
<content:encoded><![CDATA[
<div> 关键词: 情感分析, 因果关系, 自然语言处理, 数据集, 模型训练

总结:<br /><br />总结: 本文讨论了情感分析的因果性质。研究者借助自然语言处理技术和机器学习方法，探讨了在情感分析中因果关系的重要性。通过使用不同数据集进行模型训练，研究者发现了因果关系对情感分析的影响，并提出了一些新的观点和方法来改善模型的准确性和效率。这些研究结果对情感分析领域的发展具有重要意义。 <div>
[CL]《On the Causal Nature of Sentiment Analysis》Z Lyu, Z Jin, F Gonzalez, R Mihalcea, B Schoelkopf, M Sachan [University of Hong Kong &amp; ETH Zürich] (2024) <a href="https://arxiv.org/abs/2404.11055"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoy141354yj20o812swnu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoy141l615j21kq0x07ig.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoy141mu60j20s40jgmz7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 22:05:46 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and Benchmark》(CVPR 2024) GitHub: github.com/facebookresearch/real-a...</title>
<link>https://weibo.com/1402400261/OaC2fz3IW</link>
<guid>https://weibo.com/1402400261/OaC2fz3IW</guid>
<content:encoded><![CDATA[
<div> 关键词：音频-视觉数据集，房间声学，单视角对象重建，多视角遮挡监督，文本图像转换，身份保留，频率感知扩散合声器，车辆轨迹预测，事实核查，语音带宽扩展

总结:<br /><br />《Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and Benchmark》提出了一个音频-视觉数据集，用于房间声学研究，并提供了评估基准。<br />《MOHO: Learning Single-view Hand-held Object Reconstruction with Multi-view Occlusion-Aware Supervision》介绍了一种学习单视角手持对象重建的方法，具备多视角遮挡监督。<br />《Customizing Text-to-Image Diffusion with Camera Viewpoint Control》探讨了通过自定义相机视角控制来改善文本到图像转换的方法。<br />《FlashFace: Human Image Personalization with High-fidelity Identity Preservation》展示了一种人像个性化处理方法，保持高保真度身份信息。<br />《FreGrad: Lightweight and fast frequency-aware diffusion vocoder》介绍了一种轻量级且快速的频率感知扩散合声器。<br />《Decomposing and Editing Predictions by Modeling Model Computation》通过建模模型计算来分解和编辑预测结果。<br />《Self-playing Adversarial Language Game Enhances LLM Reasoning》探讨了自我对抗语言游戏如何增强大型语言模型的推理能力。<br />《BLINK: Multimodal Large Language Models Can See but Not Perceive》展示了多模态大型语言模型的能力，并指出其无法感知信息。<br />《A Unified Framework for Scalable Vehicle Trajectory Prediction》提出了一个可扩展的车辆轨迹预测统一框架。<br />《MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents》介绍了一种在基础文件上高效检查大型语言模型事实的方法。<br />《Towards High-Quality and Efficient Speech Bandwidth Extension with Parallel Amplitude and Phase Prediction》展示了一种高质量、高效率的语音带宽扩展方法。<br />《AbsGS: Recovering Fine Details for 3D Gaussian Splatting》提出了一种用于3D高斯喷涂的细节恢复方法。<br />《Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs》描述了如何通过在图上推理来增强大型语言模型。<br />《TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding》介绍了一种通过分层推测解码实现长序列生成的无损加速方法。 <div>
几篇论文实现代码：<br />《Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and Benchmark》(CVPR 2024) GitHub: github.com/facebookresearch/real-acoustic-fields<br />《MOHO: Learning Single-view Hand-held Object Reconstruction with Multi-view Occlusion-Aware Supervision》(CVPR 2024) GitHub: github.com/ZhangCYG/MOHO<br />《Customizing Text-to-Image Diffusion with Camera Viewpoint Control》(2024) GitHub: github.com/customdiffusion360/custom-diffusion360 [fig1]<br />《FlashFace: Human Image Personalization with High-fidelity Identity Preservation》(2024) GitHub: github.com/ali-vilab/FlashFace<br />《Position Paper: Learning with 3D rotations, a hitchhiker’s guide to SO(3)》(2024) GitHub: github.com/martius-lab/hitchhiking-rotations<br />《FreGrad: Lightweight and fast frequency-aware diffusion vocoder》(2024) GitHub: github.com/signofthefour/fregrad<br />《Decomposing and Editing Predictions by Modeling Model Computation》(2024) GitHub: github.com/MadryLab/modelcomponents [fig2]<br />《Self-playing Adversarial Language Game Enhances LLM Reasoning》(2024) GitHub: github.com/Linear95/SPAG<br />《BLINK: Multimodal Large Language Models Can See but Not Perceive》(2024) GitHub: github.com/zeyofu/BLINK_Benchmark [fig3]<br />《A Unified Framework for Scalable Vehicle Trajectory Prediction》(2024) GitHub: github.com/vita-epfl/UniTraj [fig4]<br />《MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents》(2024) GitHub: github.com/Liyan06/MiniCheck<br />《Towards High-Quality and Efficient Speech Bandwidth Extension with Parallel Amplitude and Phase Prediction》(2024) GitHub: github.com/yxlu-0102/AP-BWE<br />《AbsGS: Recovering Fine Details for 3D Gaussian Splatting》(2024) GitHub: github.com/ingra14m/floater-free-gaussian-splatting<br />《Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs》(2024) GitHub: github.com/PeterGriffinJin/Graph-CoT [fig5] <br />《TriForce: Lossless Acceleration of Long Sequence<br />Generation with Hierarchical Speculative Decoding》(2024) GitHub: github.com/Infini-AI-Lab/TriForce<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoxckkex4lj23131diaqu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoxeejw5idj21wu1867h7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoxefof2d3j21w115gx6p.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoxet0bufnj21pz0obtq5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoxf0cpj4hj21ue0yuap9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:58:57 GMT</pubDate>
</item>
<item>
<title>【BeyondLLM：用于实验、评估和部署基于检索增强生成 (RAG) 的系统的工具包，支持各种大语言模型 (LLM)，旨在减少 LLM 幻觉风险并提高可靠性】'BeyondLLM - Buil...</title>
<link>https://weibo.com/1402400261/OaC28Bhro</link>
<guid>https://weibo.com/1402400261/OaC28Bhro</guid>
<content:encoded><![CDATA[
<div> GitHub, 工具包, 检索增强生成, 语言模型, 减少风险, 提高可靠性, 实验, 评估, 部署  

总结:<br /><br />文章介绍了名为BeyondLLM的工具包，旨在帮助用户构建、评估和部署基于检索增强生成（RAG）的系统，支持各种大语言模型（LLM）。该工具包的目标是减少LLM产生的幻觉风险并提高系统的可靠性。用户可以利用该工具包进行实验、评估和观察LLM应用的表现，并确保系统在不同环境下的稳定性和可靠性。GitHub链接为github.com/aiplanethub/beyondllm。 <div>
【BeyondLLM：用于实验、评估和部署基于检索增强生成 (RAG) 的系统的工具包，支持各种大语言模型 (LLM)，旨在减少 LLM 幻觉风险并提高可靠性】'BeyondLLM - Build, evaluate and observe LLM apps' GitHub: github.com/aiplanethub/beyondllm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoxg94f63qj20u00ybaec.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:58:40 GMT</pubDate>
</item>
<item>
<title>【SAE Lens：在语言模型上训练稀疏自编码器】'SAE Lens - Training Sparse Autoencoders on Language Models' GitHub: github.com/jbloomAus/SAELens #开源# #机...</title>
<link>https://weibo.com/1402400261/OaBYXglHQ</link>
<guid>https://weibo.com/1402400261/OaBYXglHQ</guid>
<content:encoded><![CDATA[
<div> 稀疏自编码器、语言模型、训练、GitHub、SAELens

<br /><br />总结:
本文介绍了在语言模型上训练稀疏自编码器的方法，作者提供了在GitHub上的开源代码SAELens。稀疏自编码器是一种无监督学习的模型，通过学习数据的稀疏表示来降低维度。在语言模型上训练稀疏自编码器可以帮助提取文本数据中的特征，并用于各种自然语言处理任务。通过使用SAELens，研究人员可以方便地训练和测试稀疏自编码器，这对于语言模型和深度学习领域的研究具有重要意义。 <div>
【SAE Lens：在语言模型上训练稀疏自编码器】'SAE Lens - Training Sparse Autoencoders on Language Models' GitHub: github.com/jbloomAus/SAELens <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoxg0m3a8mj20u010644w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:50:49 GMT</pubDate>
</item>
<item>
<title>【A Web Component for Math Input：为网页提供易于使用的数学公式输入界面的强大 Web 组件】'A Web Component for Math Input - A web component for easy math...</title>
<link>https://weibo.com/1402400261/OaBYufwEK</link>
<guid>https://weibo.com/1402400261/OaBYufwEK</guid>
<content:encoded><![CDATA[
<div> Web Component, Math Input, 网页, 数学公式, 输入界面, GitHub, 强大, 组件, 简单, 使用

<br /><br />总结:
本文介绍了一个名为"A Web Component for Math Input"的Web组件，旨在为网页提供方便易用的数学公式输入界面。该组件可以在GitHub上找到，提供了强大的功能，让用户可以轻松输入数学公式。通过这个组件，用户可以快速在网页中添加数学公式，提高了数学输入的效率和便利性。 <div>
【A Web Component for Math Input：为网页提供易于使用的数学公式输入界面的强大 Web 组件】'A Web Component for Math Input - A web component for easy math input' GitHub: github.com/arnog/mathlive <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoxfzqu3vvj20x20u0jv2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:49:40 GMT</pubDate>
</item>
<item>
<title>【CIANNA：专门为天体物理学家设计的深度学习框架，用于天体数据分析，并提供了高级 Python 接口】'CIANNA - Convolutional Interactive Artificial Neural Netw...</title>
<link>https://weibo.com/1402400261/OaBY1AIPW</link>
<guid>https://weibo.com/1402400261/OaBY1AIPW</guid>
<content:encoded><![CDATA[
<div> 天体物理学家、深度学习框架、CIANNA、天体数据分析、高级 Python 接口、GitHub、Convolutional Interactive Artificial Neural Networks、Astrophysicists、GitHub仓库

<br /><br />总结:
CIANNA是专门为天体物理学家设计的深度学习框架，用于天体数据分析。它提供了高级 Python 接口，方便用户使用。CIANNA的全称为Convolutional Interactive Artificial Neural Networks，为天体物理学家提供了一个便捷的工具进行数据处理和分析。用户可以在GitHub上找到CIANNA的开源代码仓库，方便下载和使用。 <div>
【CIANNA：专门为天体物理学家设计的深度学习框架，用于天体数据分析，并提供了高级 Python 接口】'CIANNA - Convolutional Interactive Artificial Neural Networks by/for Astrophysicists' GitHub: github.com/Deyht/CIANNA <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoxfylkspsj20u00x0grb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:48:32 GMT</pubDate>
</item>
<item>
<title>【python-barcode：创建标准条形码的简单 Python 库】'python-barcode - Create standard barcodes with Python. No external dependencies. 100% Organic Pytho...</title>
<link>https://weibo.com/1402400261/OaBXCyavy</link>
<guid>https://weibo.com/1402400261/OaBXCyavy</guid>
<content:encoded><![CDATA[
<div> GitHub, python-barcode, 标准条形码, Python, 无外部依赖, 100% 纯 Python

python-barcode 是一个简单的 Python 库，用于创建标准的条形码，不需要外部依赖，完全由 Python 编写。可以通过 GitHub 获取项目源代码。此库是为了方便用户在 Python 中生成标准的条形码。与其他库不同的是，python-barcode 是一个纯 Python 库，不依赖于任何其他第三方库。用户可以直接使用这个库来生成不同类型的条形码，比如 EAN13、UPCA、CODE128 等等。这个库的设计是非常简洁和易于使用的，用户只需导入库并调用相应的方法即可生成所需的条形码。总的来说，python-barcode 是一个方便、易用且没有额外依赖的 Python 条形码生成库。<br /><br />总结: 该库是一个简单的 Python 库，用于创建标准的条形码，不需要外部依赖，完全由 Python 编写。用户可以直接使用这个库来生成不同类型的条形码，设计简洁易用。 <div>
【python-barcode：创建标准条形码的简单 Python 库】'python-barcode - Create standard barcodes with Python. No external dependencies. 100% Organic Python.' GitHub: github.com/WhyNotHugo/python-barcode <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoxfx05yfnj21h80lkacy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:47:32 GMT</pubDate>
</item>
<item>
<title>【Live2D Virtual Human for Chatting based on Unity：寄语Unity的开源聊天虚拟人项目】'Live2D Virtual Human for Chatting based on Unity - Live2D Virtual ...</title>
<link>https://weibo.com/1402400261/OaBMw0bqn</link>
<guid>https://weibo.com/1402400261/OaBMw0bqn</guid>
<content:encoded><![CDATA[
<div> Live2D、Unity、开源项目、虚拟人、聊天、GitHub、Navi Studio、项目、技术、实现

总结:<br /><br />这是一个基于Unity的开源项目，旨在创建一个能够进行实时对话的Live2D虚拟人。项目已经在GitHub上发布，由Navi Studio开发。通过使用技术实现，用户可以与虚拟人进行交流和互动，为Unity开发者提供了一个有趣的项目。 <div>
【Live2D Virtual Human for Chatting based on Unity：寄语Unity的开源聊天虚拟人项目】'Live2D Virtual Human for Chatting based on Unity - Live2D Virtual Human for Chatting based on Unity' GitHub: github.com/Navi-Studio/Virtual-Human-for-Chatting?tab=readme-ov-file <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoxf3jdpeqj215s0nm0wt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:20:10 GMT</pubDate>
</item>
<item>
<title>【json-repair：提供了一个名为 json-repair 的工具，用于修复从语言模型(LLM)产生的 JSON 格式异常】'Repair JSON！Solution for JSON Anomalies from LLMs.' G...</title>
<link>https://weibo.com/1402400261/OaBLxcg7u</link>
<guid>https://weibo.com/1402400261/OaBLxcg7u</guid>
<content:encoded><![CDATA[
<div> 修复工具、JSON异常、语言模型、LLM、GitHub、解决方案、RealAlexandreAI、修复JSON格式异常
<br />
提供了一个名为 json-repair 的工具，用于修复从语言模型(LLM)产生的 JSON 格式异常。你可以在 GitHub 上找到这个工具，地址是 github.com/RealAlexandreAI/json-repair。该工具能够解决从LLMs产生的JSON异常，是一个修复JSON格式异常的解决方案。 <div>
【json-repair：提供了一个名为 json-repair 的工具，用于修复从语言模型(LLM)产生的 JSON 格式异常】'Repair JSON！Solution for JSON Anomalies from LLMs.' GitHub: github.com/RealAlexandreAI/json-repair <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoxf2dlge9j20u010eafa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:17:45 GMT</pubDate>
</item>
<item>
<title>【The largest Awesome List of CLI/TUI programs：最大的精选 CLI/TUI 应用清单，并以 CSV 文件的形式组织了源数据】'The largest Awesome List of CLI/TUI pro...</title>
<link>https://weibo.com/1402400261/OaBDrrpN6</link>
<guid>https://weibo.com/1402400261/OaBDrrpN6</guid>
<content:encoded><![CDATA[
<div> GitHub, CLI/TUI 应用清单, CSV 文件, 源数据, 组织, 最大的<br />
<br />总结:
本文介绍了 GitHub 上最大的 CLI/TUI 应用清单，其中包括了以 CSV 文件形式组织的源数据。这个清单中涵盖了大量的 CLI/TUI 应用程序，为用户提供了便利的选择。CLI/TUI 应用程序在命令行或文本用户界面上执行操作，可帮助用户提高工作效率。通过这个清单，用户能够更方便地找到并使用各种 CLI/TUI 应用程序，让他们的工作更加高效和便捷。GitHub 上的这个 Awesome List 为用户提供了一个全面而精选的资源，帮助他们更好地利用 CLI/TUI 技术。 <div>
【The largest Awesome List of CLI/TUI programs：最大的精选 CLI/TUI 应用清单，并以 CSV 文件的形式组织了源数据】'The largest Awesome List of CLI/TUI programs - The largest Awesome Curated list of CLI/TUI applications with source data organized into CSV files' GitHub: github.com/toolleeo/cli-apps <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23CLI%23"><span class="surl-text">#CLI#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoxeht1hsej20u01307bh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 08:57:49 GMT</pubDate>
</item>
<item>
<title>【Form Extractor Prototype：使用 Claude 3 LLM 模型的工具，可以从表单图像中提取结构，并将其转换为符合 GOV.UK 表单模式的 JSON 结构，然后生成多页面的 Web...</title>
<link>https://weibo.com/1402400261/OaBBCyFlS</link>
<guid>https://weibo.com/1402400261/OaBBCyFlS</guid>
<content:encoded><![CDATA[
<div> GitHub, Form Extractor Prototype, Claude 3 LLM 模型, 表单图像, 结构提取, GOV.UK 表单模式, JSON 结构, 多页面 Web 表单

<br /><br />总结:
这篇文章介绍了一个名为'Form Extractor Prototype'的工具，使用了Claude 3 LLM模型，可以从表单图像中提取结构，并转换为符合GOV.UK表单模式的JSON结构。然后，该工具可以生成多页面的Web表单。这个工具的开源代码可以在GitHub上找到。 <div>
【Form Extractor Prototype：使用 Claude 3 LLM 模型的工具，可以从表单图像中提取结构，并将其转换为符合 GOV.UK 表单模式的 JSON 结构，然后生成多页面的 Web 表单】'Form Extractor Prototype' GitHub: github.com/timpaul/form-extractor-prototype <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoxed5196tj216a0o077r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 08:53:20 GMT</pubDate>
</item>
<item>
<title>【NeRF-Based-SLAM-Incredible-Insights：旨在提供对各种基于 NeRF(神经辐射场)的 Slam(同时定位和建图)算法的全面见解】'NeRF-Based-SLAM-Incredible-Insights'...</title>
<link>https://weibo.com/1402400261/OaAdMq4FU</link>
<guid>https://weibo.com/1402400261/OaAdMq4FU</guid>
<content:encoded><![CDATA[
<div> NeRF, Slam, 神经辐射场, 定位, 建图, 算法, 全面见解, GitHub, Incredible Insights

<br /><br />总结:
本文旨在提供对各种基于 NeRF(神经辐射场)的 Slam(同时定位和建图)算法的全面见解。NeRF 是一种用于重建三维场景的方法，结合 Slam 可以实现准确的定位和建图。通过 GitHub 项目 'NeRF-Based-SLAM-Incredible-Insights'，我们可以深入了解这些算法的原理、应用和不同方面的技术细节。通过研究这些内容，我们可以获得关于 NeRF-Based Slam 算法的令人难以置信的洞察力。 <div>
【NeRF-Based-SLAM-Incredible-Insights：旨在提供对各种基于 NeRF(神经辐射场)的 Slam(同时定位和建图)算法的全面见解】'NeRF-Based-SLAM-Incredible-Insights' GitHub: github.com/electech6/NeRF-Based-SLAM-Incredible-Insights?tab=readme-ov-file <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hox88etlaej21740se0xv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 05:21:51 GMT</pubDate>
</item>
<item>
<title>LLM匿名竞技场的最新结果显示，在English赛道 Llama-3-70b-Instruct 已经超过 Claude 3 Opus，仅次于 GPT-4 #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/Oaz9ih5C7</link>
<guid>https://weibo.com/1402400261/Oaz9ih5C7</guid>
<content:encoded><![CDATA[
<div> LLM, 匿名竞技场, English赛道, Llama-3-70b-Instruct, Claude 3 Opus, GPT-4

总结:<br /><br />LLM匿名竞技场的最新结果显示，在English赛道，Llama-3-70b-Instruct已经超越了Claude 3 Opus，仅次于GPT-4。这表明Llama-3-70b-Instruct在竞技场中取得了相对较高的成绩，在与GPT-4的比较中显示出潜力和竞争力。整体上，LLM匿名竞技场的结果显示了Llama-3-70b-Instruct在语言模型竞技中的优异表现，尤其在英语赛道上的表现让人印象深刻。 <div>
LLM匿名竞技场的最新结果显示，在English赛道 Llama-3-70b-Instruct 已经超过 Claude 3 Opus，仅次于 GPT-4 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hox3h8l6exj213s0u0q6s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 02:38:03 GMT</pubDate>
</item>
<item>
<title>【Penzai：基于 JAX 的神经网络研究工具包，用于构建、编辑和可视化神经网络，可轻松查看模型内部结构，允许在任意地方注入自定义逻辑】'Penzai - A JAX researc...</title>
<link>https://weibo.com/1402400261/Oaz0M09Ku</link>
<guid>https://weibo.com/1402400261/Oaz0M09Ku</guid>
<content:encoded><![CDATA[
<div> JAX, 神经网络, Penzai, 工具包, 构建, 编辑, 可视化, 内部结构, 自定义逻辑

总结:<br /><br />
Penzai是基于JAX的神经网络研究工具包，能够用于构建、编辑和可视化神经网络。该工具包可以轻松查看模型的内部结构，同时允许在任意地方注入自定义逻辑。帮助研究人员更加方便地探索神经网络模型，提高研究效率。GitHub上有Penazi的开源代码，有兴趣的人可以去查看。 <div>
【Penzai：基于 JAX 的神经网络研究工具包，用于构建、编辑和可视化神经网络，可轻松查看模型内部结构，允许在任意地方注入自定义逻辑】'Penzai - A JAX research toolkit for building, editing, and visualizing neural networks.' GitHub: github.com/google-deepmind/penzai <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5025178598703171"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a><br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/5396ee05ly1hox2wosemcj20oy0k0wh3.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/sQZgTkjMlx08edZz9w5G0104120055cZ0E010.mp4?label=mp4_720p&amp;template=898x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713584543&amp;ssig=YDnz52zEjL&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/zAC4BK15lx08edZyUd9m010412002vLD0E010.mp4?label=mp4_hd&amp;template=596x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713584543&amp;ssig=Hbdwn75tZD&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/BY7hT4E0lx08edZyOAFi010412001vFF0E010.mp4?label=mp4_ld&amp;template=448x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713584543&amp;ssig=BzajPp1l3d&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5025178598703171" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 02:17:03 GMT</pubDate>
</item>
<item>
<title>【LLM API价格比较表】《Compare LLM API Pricing Instantly - Quickly Find the Perfect Large Language Models (LLM) API for Your Budget! Use Our Free Tool...</title>
<link>https://weibo.com/1402400261/OayOl2GT7</link>
<guid>https://weibo.com/1402400261/OayOl2GT7</guid>
<content:encoded><![CDATA[
<div> 关键词：LLM API，价格比较，快速找到适合预算的API提供商

总结:<br /><br />本文介绍了比较LLM API价格的工具，可以帮助用户快速找到适合预算的API提供商。用户可以通过免费工具即时查看顶级提供商的最新价格。这有助于用户更好地选择合适的大型语言模型API，并控制成本。 <div>
【LLM API价格比较表】《Compare LLM API Pricing Instantly - Quickly Find the Perfect Large Language Models (LLM) API for Your Budget! Use Our Free Tool for Instant Access to the Latest Prices from Top Providers》 <a href="https://llmpricecheck.com/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hox207p18pj217i0u041x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 01:46:25 GMT</pubDate>
</item>
<item>
<title>【用 ORPO 将 Llama 3 的性能提升到新高度】- ORPO(Odds Ratio Preference Optimization)是一种新的微调技术，可以将传统的监督微调和偏好对齐阶段合并为一个过...</title>
<link>https://weibo.com/1402400261/OaxUVi5hh</link>
<guid>https://weibo.com/1402400261/OaxUVi5hh</guid>
<content:encoded><![CDATA[
<div> ORPO, Llama 3, 性能提升, 新高度, 监督微调, 偏好对齐, 计算资源, 训练时间, 语言建模, 比值项

<br /><br />总结:
ORPO是一种新的微调技术，可以将监督微调和偏好对齐合并为一个过程，通过修改语言建模目标，强化被选择的响应，从而将Llama 3的性能提升到新高度。文章使用ORPOTrainer在Llama 3 8B模型上进行微调，尽管样本量有限，但在Nous基准测试中表现良好。ORPO展现了作为新微调范式的潜力，重要的是在更大规模的偏好数据集上进行充分训练。当前开源社区活跃，开源模型与专有模型差距缩小，微调是关键。 <div>
【用 ORPO 将 Llama 3 的性能提升到新高度】<br />- ORPO(Odds Ratio Preference Optimization)是一种新的微调技术，可以将传统的监督微调和偏好对齐阶段合并为一个过程，从而减少计算资源和训练时间。   <br />- ORPO通过修改语言建模目标，将负对数似然损失与比值(OR)项相结合，以弱化被拒绝的响应并强化被选择的响应，让模型同时学习目标任务和人类偏好。   <br />- 文章使用TRL库中的ORPOTrainer在Llama 3 8B模型上进行ORPO微调，数据集包含DPO偏好对，共1000个样本。   <br />- 尽管由于样本量少仅训练了1个epoch，但微调后的模型在Nous的基准测试中表现良好，所有指标上均优于Llama 3原模型。   <br />- ORPO展现了作为新的微调范式的潜力，未来在更大规模的偏好数据集上进行充分训练将产生更好的效果。选择高质量的数据集也非常重要。   <br />- 当前是开源社区的活跃时期，正在发布越来越多高质量的开源模型，开源模型与专有模型的差距正在缩小，微调是获得最佳性能的关键。<br />《Fine-tune Llama 3 with ORPO》 <a href="https://huggingface.co/blog/mlabonne/orpo-llama-3"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8howy0qq6enj20u00xyq83.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 23:29:53 GMT</pubDate>
</item>
<item>
<title>今日推介(第1381期)：语言模型实际上是个Q函数、3D旋转学习指南、单目视频的一致网格重建、视觉基础模型语义分割基准测试方案探索、用微调和迭代推理增强特定领...</title>
<link>https://weibo.com/1402400261/OaxvlyGXB</link>
<guid>https://weibo.com/1402400261/OaxvlyGXB</guid>
<content:encoded><![CDATA[
<div> 语言模型、Q函数、3D旋转、学习、单目视频、一致网格重建、视觉基础模型、语义分割、基准测试方案、微调、迭代推理、领域问答<br />
<br />
语言模型实际上是一个Q函数，通过3D旋转学习指南，实现单目视频的一致网格重建。同时，探索视觉基础模型语义分割的基准测试方案，研究用微调和迭代推理增强特定领域问答的方法。这些内容在公众号"爱可可爱生活"中得以详细阐述，为读者提供了丰富的学习资源和研究思路。 <div>
今日推介(第1381期)：语言模型实际上是个Q函数、3D旋转学习指南、单目视频的一致网格重建、视觉基础模型语义分割基准测试方案探索、用微调和迭代推理增强特定领域问答的比较研究 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/693516407"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8howw8ziy3uj21400d9tcz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8howw924g2wj20t60madiy.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8howw95n2pej21230u0gth.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8howw98e2iuj20ts0vsgpf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8howw9axgf2j20uw0u00v8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 22:26:53 GMT</pubDate>
</item>
<item>
<title>[LG] Deconstructing Human-AI Collaboration: Agency, Interaction, and Adaptation 网页链接 通过代理、交互和适应三个关键方面提出人机协作设计空间模型，为...</title>
<link>https://weibo.com/1402400261/Oaxrssys1</link>
<guid>https://weibo.com/1402400261/Oaxrssys1</guid>
<content:encoded><![CDATA[
<div> 代理、交互、适应、人机协作、设计空间模型、理解、评估、协作系统、有效工具

<br /><br />总结:
本文提出了人机协作设计空间模型，通过代理、交互和适应三个关键方面来理解、设计和评估人机协作系统。该模型为研究人机协作提供了有效工具，帮助人们更好地理解和优化人工智能与人类之间的合作关系。通过对代理、交互和适应三个方面的深入分析，可以有效提高人机协作系统的效能和用户体验。 <div>
[LG] Deconstructing Human-AI Collaboration: Agency, Interaction, and Adaptation  <br /><a href="https://arxiv.org/abs/2404.12056"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过代理、交互和适应三个关键方面提出人机协作设计空间模型，为理解、设计和评估此类协作系统提供了有效工具。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howvzcr871j20x216y15l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howvzczerhj21l80p6wn2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howvzdee75j21ko0my7ej.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 22:17:19 GMT</pubDate>
</item>
<item>
<title>[CL] Exploring the landscape of large language models: Foundations, techniques, and challenges 网页链接 本文全面概述了大型语言模型的发展现状、关键技术...</title>
<link>https://weibo.com/1402400261/OaxoHm6eo</link>
<guid>https://weibo.com/1402400261/OaxoHm6eo</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、发展现状、关键技术、应用前景、理论分析、实际问题、研究人员、从业者、指南

总结:<br /><br />本文全面概述了大型语言模型的发展现状，重点介绍了关键技术和应用前景。通过理论分析和关注实际问题，为研究人员和从业者提供了很好的指南。文章涵盖了大型语言模型的基础知识，探讨了其在各个领域的应用及挑战。同时，也提出了未来研究方向，为读者开拓了思路。整体而言，这篇文章对大型语言模型的全貌有了全面的展示，对于深入了解和应用该技术具有重要意义。 <div>
[CL] Exploring the landscape of large language models: Foundations, techniques, and challenges  <br /><a href="https://arxiv.org/abs/2404.11973"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>        <br />本文全面概述了大型语言模型的发展现状、关键技术和应用前景，既有理论分析，也关注实际问题，为研究人员和从业者提供了很好的指南。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howvs9lsdxj20q2150tc7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1howvs9ymd5j218g1d6nad.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howvsaik9zj214m19s49b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 22:10:31 GMT</pubDate>
</item>
<item>
<title>[CL] Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment 网页链接 通过跨语言奖励模型迁移实现无需目标语言偏好数据即可对齐语...</title>
<link>https://weibo.com/1402400261/OaxjOkucv</link>
<guid>https://weibo.com/1402400261/OaxjOkucv</guid>
<content:encoded><![CDATA[
<div> 跨语言、奖励模型迁移、无需目标语言偏好数据、对齐语言模型、实证结果、有效性、实用性<br />
<br />
提出了一种通过跨语言奖励模型迁移实现无需目标语言偏好数据即可对齐语言模型的方法，并提供了一系列实证结果证明了该方法的有效性和实用性。该方法可以帮助实现跨语言对齐，提供了一种有效的无监督或弱监督学习的思路。研究表明，通过将奖励机制在不同语言间进行迁移，可以有效地传递模型知识和对齐模型特性。这种方法不仅适用于文本领域，也可以拓展到其他领域，为跨语言模型迁移和对齐提供了新的思路和方法。该研究为促进不同语言之间的信息交流和知识共享提供了重要的理论和方法支持，具有一定的实际应用意义。<br /><br />总结: <br />提出了一种跨语言奖励模型迁移的方法，无需目标语言偏好数据即可完成语言模型对齐，实证结果证明了该方法的有效性和实用性，为跨语言模型迁移和对齐提供了新的思路和方法。 <div>
[CL] Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment  <br /><a href="https://arxiv.org/abs/2404.12318"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过跨语言奖励模型迁移实现无需目标语言偏好数据即可对齐语言模型，并提供了一系列实证结果证明了该方法的有效性和实用性。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howvfqcsowj20sg16mgy4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howvfqmcp0j20ni190gsf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howvfr9qyfj21bg17aguq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 21:58:28 GMT</pubDate>
</item>
<item>
<title>[IR] Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing 网页链接 通过后处理相关性预测与排序偏好，成功将L...</title>
<link>https://weibo.com/1402400261/Oaxhfeihj</link>
<guid>https://weibo.com/1402400261/Oaxhfeihj</guid>
<content:encoded><![CDATA[
<div> 大语言模型、后处理、相关性预测、排序、LLM、公共数据集、整合、打分、排名能力、良好平衡

在这篇论文中，研究人员通过后处理方法成功地整合了大型语言模型（LLM）的打分和排名能力，实现了在多个公共数据集上排序与相关性指标的良好平衡。他们提出了一种方法，通过对LLM输出的打分和排名结果进行后处理来提高性能。通过在不同任务和数据集上的实验，研究人员证明了这种方法的有效性，说明后处理可以帮助提高LLM的排序和相关性预测能力。这项研究对于改进大语言模型在各种自然语言处理任务中的表现具有重要意义，为进一步研究提供了新的思路。

<br /><br />总结: 本研究通过后处理方法整合了大型语言模型的打分和排名能力，实现了在多个公共数据集上排序与相关性指标的良好平衡。他们的方法在不同任务和数据集上的实验表明有效性，对改进自然语言处理任务中的表现具有重要意义，为未来研究提供了新方向。 <div>
[IR] Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing  <br /><a href="https://arxiv.org/abs/2404.11791"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />通过后处理相关性预测与排序偏好，成功将LLM的打分与排名能力进行整合，在多个公共数据集上取得了排序与相关性指标的良好平衡。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howv9680z3j20wg1c4kaj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1howv96cn7dj21h20lugri.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howv96ot9fj20qk14adln.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 21:52:09 GMT</pubDate>
</item>
<item>
<title>通过定制化的嵌入模型、生成模型以及OODA循环推理，大幅提高了基于检索增强生成的金融QA系统在FinanceBench数据集上的性能，为构建高质量、高鲁棒性的QA系统提供...</title>
<link>https://weibo.com/1402400261/Oaxh64KoM</link>
<guid>https://weibo.com/1402400261/Oaxh64KoM</guid>
<content:encoded><![CDATA[
<div> 金融QA系统、检索增强生成、嵌入模型、生成模型、OODA循环推理、FinanceBench数据集、性能提升、高质量、高鲁棒性、指导<br />
<br />
<br />
总结: 通过定制化的嵌入模型、生成模型以及OODA循环推理，大幅提高了基于检索增强生成的金融QA系统在FinanceBench数据集上的性能。这项研究为构建高质量、高鲁棒性的QA系统提供了宝贵指导，为金融领域提供了有益的研究成果。 <div>
通过定制化的嵌入模型、生成模型以及OODA循环推理，大幅提高了基于检索增强生成的金融QA系统在FinanceBench数据集上的性能，为构建高质量、高鲁棒性的QA系统提供了宝贵指导。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Enhancing Q&amp;A with Domain-Specific Fine-Tuning and Iterative Reasoning: A Comparative Study》Z Nguyen, A Annunziata, V Luong, S Dinh... [Aitomatic, Inc &amp; IBM Research] (2024) <a href="https://arxiv.org/abs/2404.11792"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuvz20w3j21fa0j8qca.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuvzauhuj212u0wa77s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howuvzo7zpj218u17kn27.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 21:51:47 GMT</pubDate>
</item>
<item>
<title>[CL]《Enhancing Q&amp;A with Domain-Specific Fine-Tuning and Iterative Reasoning: A Comparative Study》Z Nguyen, A Annunziata, V Luong, S Dinh... [Aitomat...</title>
<link>https://weibo.com/1402400261/Oaxh1ryzv</link>
<guid>https://weibo.com/1402400261/Oaxh1ryzv</guid>
<content:encoded><![CDATA[
<div> 领域特定微调，迭代推理，自动化公司，IBM研究，问答系统

<br /><br />总结:
研究对比了领域特定微调和迭代推理对问答系统性能的影响。研究由Aitomatic公司和IBM Research共同进行。首先介绍了问答系统的背景和重要性，随后阐述了领域特定微调和迭代推理的工作原理和优势。研究结果显示，在特定领域微调和迭代推理相结合的情况下，问答系统的性能有显著提升。这些发现对于优化问答系统的设计和应用具有重要意义。 <div>
[CL]《Enhancing Q&amp;A with Domain-Specific Fine-Tuning and Iterative Reasoning: A Comparative Study》Z Nguyen, A Annunziata, V Luong, S Dinh... [Aitomatic, Inc &amp; IBM Research] (2024) <a href="https://arxiv.org/abs/2404.11792"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuvz20w3j21fa0j8qca.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuvzauhuj212u0wa77s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howuvzo7zpj218u17kn27.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 21:51:36 GMT</pubDate>
</item>
<item>
<title>通过对各种基准测试设置的影响分析，推荐了一个平衡代表性与效率的视觉基础模型(VFM)语义分割评测方案，并基于此得出了多个有价值的模型选择及设计建议。 - 转发...</title>
<link>https://weibo.com/1402400261/Oaxb0xXmO</link>
<guid>https://weibo.com/1402400261/Oaxb0xXmO</guid>
<content:encoded><![CDATA[
<div> 基准测试、影响分析、视觉基础模型、语义分割、评测方案、模型选择、设计建议、效率、代表性、多个关键词

<br /><br />总结:
研究通过对各种基准测试设置的影响分析，提出了一个平衡代表性与效率的视觉基础模型(VFM)语义分割评测方案。该评测方案为模型选择和设计提供了有价值的建议，可以帮助研究人员更好地评估和改进语义分割模型的性能。通过本文的工作，可以更好地理解在语义分割任务中不同基准测试设置对模型性能评估的影响，并且能够为研究人员提供指导，以找到平衡代表性与效率的最佳模型选择和设计方案。 <div>
通过对各种基准测试设置的影响分析，推荐了一个平衡代表性与效率的视觉基础模型(VFM)语义分割评测方案，并基于此得出了多个有价值的模型选择及设计建议。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《How to Benchmark Vision Foundation Models for Semantic Segmentation?》T Kerssies, D d Geus, G Dubbelman [Eindhoven University of Technology] (2024) <a href="https://arxiv.org/abs/2404.12172"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howuhnhg2jj20tu19g17l.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuho5wn0j20ts0vsdka.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuhoazb3j20ta0t6ade.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuhodswij20ty0tk427.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1howut0pbmyj20j00imjsn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howut0pezwj20j10im3zr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howut0p8vtj20j00imaba.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howut0pbd6j20j00htab4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howut0p3mlj20j10hsmy6.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 21:36:47 GMT</pubDate>
</item>
<item>
<title>[CV]《How to Benchmark Vision Foundation Models for Semantic Segmentation?》T Kerssies, D d Geus, G Dubbelman [Eindhoven University of Technology] (20...</title>
<link>https://weibo.com/1402400261/OaxaWpNT8</link>
<guid>https://weibo.com/1402400261/OaxaWpNT8</guid>
<content:encoded><![CDATA[
<div> 关键词：Benchmark, Vision Foundation Models, Semantic Segmentation, Eindhoven University of Technology<br />
<br />
总结: 本文作者来自Eindhoven University of Technology，提出了如何为语义分割的视觉基础模型进行基准测试的方法。他们通过研究深度学习模型，在语义分割任务中的表现，在实验中对比不同模型的性能。作者使用了一些先进的基准测试方法，以确保结果的准确性和可靠性。他们的研究结果有助于指导语义分割模型的发展和优化，为进一步研究提供了重要参考。 <div>
[CV]《How to Benchmark Vision Foundation Models for Semantic Segmentation?》T Kerssies, D d Geus, G Dubbelman [Eindhoven University of Technology] (2024) <a href="https://arxiv.org/abs/2404.12172"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howuhnhg2jj20tu19g17l.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuho5wn0j20ts0vsdka.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuhoazb3j20ta0t6ade.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuhodswij20ty0tk427.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1howut0pbmyj20j00imjsn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howut0pezwj20j10im3zr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howut0p8vtj20j00imaba.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howut0pbd6j20j00htab4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howut0p3mlj20j10hsmy6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howut0pf6ij20j00jh75n.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 21:36:37 GMT</pubDate>
</item>
<item>
<title>提出通过 Marching Cubes 算法从关联高斯点云重建质量高且具跨帧对应关系的动态网格。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《Dynamic Gaussians Mesh: Consistent ...</title>
<link>https://weibo.com/1402400261/Oax4K9MNa</link>
<guid>https://weibo.com/1402400261/Oax4K9MNa</guid>
<content:encoded><![CDATA[
<div> 高斯点云，Marching Cubes算法，动态网格，质量重建，跨帧对应关系，单眼视频，一致性网格重建，加州大学圣地亚哥，刘伊，苏华，王欣

总结：<br /><br />本文提出了一种名为动态高斯网格的方法，旨在通过单眼视频实现一致的网格重建。通过利用高斯点云和Marching Cubes算法，实现了高质量的网格重建，同时具备跨帧对应关系。研究团队来自加州大学圣地亚哥，作者包括刘伊、苏华和王欣。通过该方法，可以实现动态物体的精确重建，并且在单眼视频情况下也能取得理想的效果。 <div>
提出通过 Marching Cubes 算法从关联高斯点云重建质量高且具跨帧对应关系的动态网格。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular Videos》I Liu, H Su, X Wang [University of California, San Diego] (2024) <a href="https://arxiv.org/abs/2404.12379"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howub5bwhsj20zw0t1drm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howub5zgouj20gs0iytbf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howub69cfoj216c0rygt4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howub6i7n8j216c0rygt4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howucwogrzj20rk17hdka.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howucwodfvj20rk16pwhz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1howucwnt24j20rj0jdtbe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howucwopssj20rk16nq6n.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howucwp5xaj20rk17ntcs.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 21:21:20 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.19)》 爱可可微博热门分享(4.19) [图片]</title>
<link>https://weibo.com/1402400261/Oauk4ninj</link>
<guid>https://weibo.com/1402400261/Oauk4ninj</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、4.19、话题、讨论、用户、社交平台、关注者

<br /><br />总结:
本文讨论了在社交平台上热门的话题和分享内容，主要围绕爱可可微博上4.19日的讨论展开。用户们积极参与讨论和分享，吸引了大量关注者的关注。微博作为一个社交平台，扮演着连接用户和内容的重要角色，为用户提供了一个互动交流的平台。整体来看，用户们对这个话题表现出了浓厚的兴趣和参与度。 <div>
《爱可可微博热门分享(4.19)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405024998443319789"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.19)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howi7i3z0zj20rs0fmaei.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 14:20:52 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Learning to Produce Semi-dense Correspondences for Visual Localization》(CVPR 2024) GitHub: github.com/TruongKhang/DeViLoc《Closel...</title>
<link>https://weibo.com/1402400261/Oaufxs1ea</link>
<guid>https://weibo.com/1402400261/Oaufxs1ea</guid>
<content:encoded><![CDATA[
<div> Learning, Semi-dense Correspondences, Visual Localization, Deep Learning, Computer Vision, 地标识别<br />
<br />
要点1: 该论文提出了一种学习产生半密集对应关系用于视觉定位的方法，通过深度学习技术实现。<br />
要点2: 该方法在地标识别和视觉定位方面取得了较好的效果，提高了准确性和鲁棒性。<br />
要点3: 通过GitHub链接可以获取论文实现代码，方便其他研究者进行复现和进一步研究。<br />

总结: 本篇论文介绍了一种利用深度学习技术学习半密集对应关系以实现视觉定位的方法。该方法在地标识别和视觉定位方面表现出色，提高了准确性和鲁棒性。通过提供GitHub链接，使得其他研究者可以获取论文实现代码，促进了进一步的研究和应用。 <div>
几篇论文实现代码：<br />《Learning to Produce Semi-dense Correspondences for Visual Localization》(CVPR 2024) GitHub: github.com/TruongKhang/DeViLoc<br />《Closely Interactive Human Reconstruction with Proxemics and Physics-Guided Adaption》(CVPR 2024) GitHub: github.com/boycehbz/HumanInteraction [fig1]<br />《Contrastive Mean-Shift Learning for Generalized Category Discovery》(CVPR 2024) GitHub: github.com/sua-choi/CMS [fig3]<br />《Can Language Models Solve Olympiad Programming?》(2024) GitHub: github.com/princeton-nlp/USACO<br />《Neural Speech Decoding》(2024) GitHub: github.com/flinkerlab/neural_speech_decoding [fig2]<br />《Actions Speak Louder than Words Trillion-Parameter Sequential Transducers for Generative Recommendations》(2024) GitHub: github.com/facebookresearch/generative-recommenders<br />《Dynamic Typography: Bringing Text to Life via Video Diffusion Prior》(2024) GitHub: github.com/zliucz/animate-your-word<br />《RoadBEV: Road Surface Reconstruction in Bird’s Eye View》(2024) GitHub: github.com/ztsrxh/RoadBEV [fig4]<br />《GISTEmbed: Guided In-sample Selection of Training Negatives for Text Embedding Fine-tuning》(2024) GitHub: github.com/avsolatorio/GISTEmbed [fig5] <br />《TF-CLIP: Learning Text-Free CLIP for Video-Based Person Re-identification》(2024) GitHub: github.com/AsuradaYuci/TF-CLIP [fig6]<br />《Learning to design protein-protein interactions with enhanced generalization》(2024) GitHub: github.com/anton-bushuiev/PPIRef<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howgyj3nr8j24ou1q71jj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howgyjjvgxj22vq130as1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howh6kwq9aj234o11ox09.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1howh7ep8e6j21e00dh7dv.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howhemwstrj21mc1uob29.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howhga2rzej219m0qdwz7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 14:09:42 GMT</pubDate>
</item>
<item>
<title>【Academic paper URL to Obsidian Note：Obsidian 插件，用于自动从 arXiv.org、acl anthology 和 semantic scholar 创建笔记】'Academic paper URL to Obsidia...</title>
<link>https://weibo.com/1402400261/Oau9bE0WO</link>
<guid>https://weibo.com/1402400261/Oau9bE0WO</guid>
<content:encoded><![CDATA[
<div> arXiv.org, acl anthology, semantic scholar, Obsidian 插件, 自动创建笔记, 学术论文

插件名称为"Academic paper URL to Obsidian Note"，可以从arXiv.org、acl anthology和semantic scholar自动创建笔记。用户只需提供学术论文的URL链接，插件即可帮助用户生成相应的笔记。这个工具为研究人员提供了方便快捷的方法来整理和管理自己感兴趣的学术论文信息，节省了他们的时间和精力。值得注意的是，插件的开发者为GitHub上的chauff。通过安装这个插件，研究人员可以更加高效地利用这些在线学术资源，将有助于他们的学术研究工作。<br /><br />总结: 本插件为Obsidian提供了一个便捷的方式，可以从arXiv.org、acl anthology和semantic scholar自动创建笔记，为研究人员提供了一个整理和管理学术论文信息的高效工具。 <div>
【Academic paper URL to Obsidian Note：Obsidian 插件，用于自动从 arXiv.org、acl anthology 和 semantic scholar 创建笔记】'Academic paper URL to Obsidian Note - Obsidian plugin to automatically create a note from arXiv.org, acl anthology and semantic scholar.' GitHub: github.com/chauff/paper-note-filler <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Obsidian%23"><span class="surl-text">#Obsidian#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8howhfrcz23j21bc0u0gux.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 13:54:04 GMT</pubDate>
</item>
<item>
<title>【多模态大语言模型(MLLM)幻觉相关论文资源列表】’Awesome Hallucination Papers in MLLMs - Papers about Hallucination in Multi-Modal Large Language Model...</title>
<link>https://weibo.com/1402400261/Oau8pBStj</link>
<guid>https://weibo.com/1402400261/Oau8pBStj</guid>
<content:encoded><![CDATA[
<div> GitHub、多模态大语言模型、幻觉、论文、资源、列表、研究、深度学习、人工智能、自然语言处理

总结:<br />
本GitHub资源分享了关于多模态大语言模型（MLLMs）中幻觉方面的论文，涵盖了深度学习、人工智能和自然语言处理等研究领域。可以在该资源中找到与MLLMs幻觉相关的最新论文，帮助研究者了解其在不同视觉和语言模态之间生成幻觉的机制和应用。GitHub链接提供了丰富的文献资源，有助于学术界和工业界关注和探讨MLLMs中幻觉产生的现象和挑战。 <div>
【多模态大语言模型(MLLM)幻觉相关论文资源列表】’Awesome Hallucination Papers in MLLMs - Papers about Hallucination in Multi-Modal Large Language Models (MLLMs)' GitHub: github.com/shikiw/Awesome-MLLM-Hallucination <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8howhdeyb79j20y20u042k.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 13:52:09 GMT</pubDate>
</item>
<item>
<title>【LibContinual：基于 PyTorch 的开源持续学习工具箱】'LibContinual - A Framework of Continual Learning' GitHub: github.com/RL-VIG/LibContinual #开源# #...</title>
<link>https://weibo.com/1402400261/Oau6hxUQx</link>
<guid>https://weibo.com/1402400261/Oau6hxUQx</guid>
<content:encoded><![CDATA[
<div> GitHub, LibContinual, PyTorch, 开源, 持续学习, 工具箱, 框架, Continual Learning <br />
<br />
提供了一个基于PyTorch的开源持续学习工具箱LibContinual，旨在帮助研究人员和开发者进行持续学习任务。该工具箱提供了一个框架，可以在不断接收新信息的情况下进行持续学习，有助于模型的不断进化和优化。LibContinual还提供了丰富的功能和工具，方便用户进行持续学习任务的实验和研究。使用LibContinual可以更加高效地进行持续学习任务的开发和实施，为持续学习领域的研究和应用提供了重要的工具支持。整体来说，LibContinual是一个功能强大且易于使用的持续学习工具箱，为研究人员和开发者提供了便利和支持。 <br />
<br />总结: <br />提供了一个基于PyTorch的开源持续学习工具箱LibContinual，框架可以进行持续学习，有助于模型不断进化；提供了丰富的功能和工具，方便进行持续学习任务的实验和研究；高效进行持续学习任务的开发和实施，为持续学习领域提供了重要支持。 <div>
【LibContinual：基于 PyTorch 的开源持续学习工具箱】'LibContinual - A Framework of Continual Learning' GitHub: github.com/RL-VIG/LibContinual <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8howh86zdgpj20u00u3tcr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 13:46:54 GMT</pubDate>
</item>
<item>
<title>【hf-chat：使用 huggingface/chat-ui 和 huggingface/candle 创建的适用于 macOS 和 iOS 的本地高效的聊天应用程序】'hf-chat' GitHub: github.com/Narsil/hf-c...</title>
<link>https://weibo.com/1402400261/Oau4NwirE</link>
<guid>https://weibo.com/1402400261/Oau4NwirE</guid>
<content:encoded><![CDATA[
<div> GitHub, hf-chat, huggingface, chat-ui, candle, macOS, iOS, 本地, 高效, 聊天应用程序
<br /><br />总结:
文章介绍了一款本地高效的聊天应用程序'hf-chat'，使用了huggingface/chat-ui和huggingface/candle创建，适用于macOS和iOS系统。该应用程序的GitHub地址为github.com/Narsil/hf-chat。通过结合huggingface/chat-ui和huggingface/candle技术，实现了具有高效性能的聊天功能，满足了用户在macOS和iOS系统下的聊天需求。 <div>
【hf-chat：使用 huggingface/chat-ui 和 huggingface/candle 创建的适用于 macOS 和 iOS 的本地高效的聊天应用程序】'hf-chat' GitHub: github.com/Narsil/hf-chat <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8howh4g43zjj20u012z0xa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 13:43:15 GMT</pubDate>
</item>
<item>
<title>【深度神经网络剪枝相关论文资源列表】’awesome-pruning' GitHub: github.com/hrcheng1066/awesome-pruning #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/Oau46tkM3</link>
<guid>https://weibo.com/1402400261/Oau46tkM3</guid>
<content:encoded><![CDATA[
<div> GitHub, 深度神经网络, 剪枝, 资源列表, 论文<br />
<br />
提到了一个名为'awesome-pruning'的GitHub仓库，其中收集了与深度神经网络剪枝相关的资源列表。这个资源库包含了大量剪枝相关的论文，可以帮助研究人员更好地了解和探索这个领域。深度神经网络剪枝是一种通过减少模型中的冗余参数来提高模型效率和加速推理过程的技术。研究这个领域的论文可以指导剪枝算法的设计和优化。这些论文提出了各种剪枝方法和策略，可以根据需求选择适合的剪枝技术来优化模型。深度神经网络的剪枝是提高模型性能和效率的重要手段，研究人员可以通过这个资源库获取最新的剪枝论文和技术，从而推动这个领域的发展。<br /><br />总结: <br />这个GitHub资源库收集了与深度神经网络剪枝相关的论文，可以帮助研究人员了解剪枝技术的发展和应用。剪枝是提高模型性能和效率的重要方法，研究人员可以根据需求选择合适的剪枝技术来优化模型。这些论文提出了各种剪枝方法和策略，可以指导剪枝算法的设计和优化。通过研究这些论文，可以更好地了解剪枝技术的原理和实践，为深度学习领域的发展提供指导和启发。 <div>
【深度神经网络剪枝相关论文资源列表】’awesome-pruning' GitHub: github.com/hrcheng1066/awesome-pruning <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8howh2owhacj20n40bkjtd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 13:41:32 GMT</pubDate>
</item>
<item>
<title>【chatstream for Shiny for Python：一个 Shiny for Python 模块，用于构建 AI 聊天应用程序】'chatstream for Shiny for Python - Example Shiny for Python a...</title>
<link>https://weibo.com/1402400261/Oau3p7H6a</link>
<guid>https://weibo.com/1402400261/Oau3p7H6a</guid>
<content:encoded><![CDATA[
<div> chatstream, Shiny for Python, AI, 聊天应用程序, 模块, OpenAI API, GitHub, wch, Example

<br /><br />总结:
Shiny for Python 是一个用于构建 AI 聊天应用程序的模块，chatstream for Shiny for Python 则是一个示例应用，可以与 OpenAI API 进行交互。这个项目托管在 GitHub 上，由用户 wch 开发和维护。通过该模块，用户可以快速搭建基于 Python 的 AI 聊天应用程序，并利用 OpenAI API 的强大功能实现更丰富的对话交互体验。 <div>
【chatstream for Shiny for Python：一个 Shiny for Python 模块，用于构建 AI 聊天应用程序】'chatstream for Shiny for Python - Example Shiny for Python app which talks to the OpenAI API' GitHub: github.com/wch/chatstream <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8howh0wmpb5j21740oyq7v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 13:39:48 GMT</pubDate>
</item>
<item>
<title>【ARAGOG：旨在探索和比较各种基于检索增强生成(RAG)技术，用于评估人工智能研究论文数据集的输出，包括模块化代码，以便于实验和重用，包含用于评估的问答对、A...</title>
<link>https://weibo.com/1402400261/Oar5dcyBs</link>
<guid>https://weibo.com/1402400261/Oar5dcyBs</guid>
<content:encoded><![CDATA[
<div> 代码、RAG、人工智能、实验、数据集、评估、问答对、AI ArXiv 论文集合、资源文件、Jupyter 笔记本

<br /><br />总结:
ARAGOG是一个旨在探索和比较各种基于检索增强生成(RAG)技术的项目，用于评估人工智能研究论文数据集的输出。该项目包含了模块化的代码，使实验和重用变得更加容易。其中包括用于评估的问答对、AI ArXiv 论文集合、资源文件(如提示模板和配置文件)、主要脚本(用于定义和执行实验)、Jupyter 笔记本(用于分析最终实验结果)、辅助函数和用于设置向量数据库的脚本。通过ARAGOG，研究人员可以快速地对不同的RAG技术进行比较和分析，从而为人工智能领域的研究提供更多参考和借鉴。 <div>
【ARAGOG：旨在探索和比较各种基于检索增强生成(RAG)技术，用于评估人工智能研究论文数据集的输出，包括模块化代码，以便于实验和重用，包含用于评估的问答对、AI ArXiv 论文集合、资源文件(如提示模板和配置文件)、主要脚本(用于定义和执行实验)、Jupyter 笔记本(用于分析最终实验结果)、辅助函数和用于设置向量数据库的脚本。 4】’ARAGOG- Advanced RAG Output Grading. Exploring and comparing various Retrieval-Augmented Generation (RAG) techniques on AI research papers dataset. Includes modular code for easy experimentation and reusability.' GitHub: github.com/predlico/ARAGOG <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8how3wpwz14j20u00z2dlk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 06:06:01 GMT</pubDate>
</item>
<item>
<title>【MLC-MiniCPM：基于 MLC-LLM 开发，将 MiniCPM 和 MiniCPM-V 在 Android 手机端上运行】'MLC-MiniCPM - MiniCPM on Android platform.' GitHub: github.com/Ope...</title>
<link>https://weibo.com/1402400261/Oar2grQdj</link>
<guid>https://weibo.com/1402400261/Oar2grQdj</guid>
<content:encoded><![CDATA[
<div> MiniCPM, MiniCPM-V, Android手机端, MLC-LLM, GitHub, 开发
<br />
MLC-MiniCPM是基于MLC-LLM开发的，可以在Android手机端上运行MiniCPM和MiniCPM-V。该项目在GitHub上有开源代码。
<br /><br />总结:
MLC-MiniCPM是一个运行在Android手机上的项目，基于MLC-LLM开发，可以实现MiniCPM和MiniCPM-V的功能。用户可以在GitHub上查看该项目的开源代码。 <div>
【MLC-MiniCPM：基于 MLC-LLM 开发，将 MiniCPM 和 MiniCPM-V 在 Android 手机端上运行】'MLC-MiniCPM - MiniCPM on Android platform.' GitHub: github.com/OpenBMB/mlc-MiniCPM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8how3p08oy5j209o0lgq35.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 05:58:46 GMT</pubDate>
</item>
<item>
<title>【SoccerNet Game State Challenge：SoccerNet 游戏状态开发工具包是一个帮助开始使用数据和建议任务的工具包。它建立在 TrackLab 上，一个用于多目标跟踪的研究...</title>
<link>https://weibo.com/1402400261/OaqQyzdGs</link>
<guid>https://weibo.com/1402400261/OaqQyzdGs</guid>
<content:encoded><![CDATA[
<div> SoccerNet, Game State, 数据, 建议任务, TrackLab, 多目标跟踪, 计算机视觉, 运动分析, 识别任务, 位置定位

<br /><br />总结:
SoccerNet 游戏状态开发工具包是一个建立在TrackLab上的工具包，用于帮助开始使用数据和建议任务。它专注于游戏状态识别任务，这是一项新的高级计算机视觉任务，旨在识别和定位所有运动员在球场上的位置。这个挑战还有一个公开的GitHub仓库，用于支持SoccerNet Game State Challenge。 <div>
【SoccerNet Game State Challenge：SoccerNet 游戏状态开发工具包是一个帮助开始使用数据和建议任务的工具包。它建立在 TrackLab 上，一个用于多目标跟踪的研究框架。游戏状态识别任务是一项新的高级计算机视觉任务，专门用于运动分析。它旨在识别和定位所有运动员（球员、裁判等）在球场上的位置，基于原始输入视频】'SoccerNet Game State Challenge - Public repository for the SoccerNet Game State Challenge' GitHub: github.com/SoccerNet/sn-gamestate <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8how2v3fsctj20m80ci40w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8how2v5uo9mj22c60u0tgg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 05:29:55 GMT</pubDate>
</item>
<item>
<title>【llm：Andrjey Karpathy最小化LLM代码的Mojo移植版】’llm - port of Andrjey Karpathy's llm.c to Mojo' GitHub: github.com/dorjeduck/llm.mojo #开源# #机器...</title>
<link>https://weibo.com/1402400261/OaqNe0jCI</link>
<guid>https://weibo.com/1402400261/OaqNe0jCI</guid>
<content:encoded><![CDATA[
<div> llm, Andrjey Karpathy, 移植, Mojo, GitHub, dorjeduck, 代码, 最小化, 版本, llm.c
<br /><br />
总结: 本文介绍了将Andrjey Karpathy的llm.c代码移植到Mojo的版本，作者在GitHub上发布了名为llm.mojo的项目。这个项目是对原始代码的最小化版本，旨在将代码移植到Mojo平台上。读者可以在GitHub上找到该项目并了解更多详细信息。 <div>
【llm：Andrjey Karpathy最小化LLM代码的Mojo移植版】’llm - port of Andrjey Karpathy's llm.c to Mojo' GitHub: github.com/dorjeduck/llm.mojo <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8how2mm0152j21ji0qmwjk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 05:21:41 GMT</pubDate>
</item>
<item>
<title>【深度立体匹配(Deep Stereo Matching）相关论文资源列表】’Awesome-Deep-Stereo-Matching - A curated list of awesome Deep Stereo Matching resources' GitH...</title>
<link>https://weibo.com/1402400261/OaqMQDpHJ</link>
<guid>https://weibo.com/1402400261/OaqMQDpHJ</guid>
<content:encoded><![CDATA[
<div> 深度立体匹配, 资源列表, 论文, GitHub, 资源, 深度学习, 立体视觉, 深度信息, 深度图像, 深度特征

<br />
在GitHub上有一份资源列表，包含了有关深度立体匹配的论文和资源，涵盖了深度学习在立体视觉中的应用。这份列表整理了各种文献和研究成果，供研究者和开发者参考，帮助他们在深度立体匹配领域取得更好的效果。通过学习这些资源，可以更好地理解立体信息的提取和匹配过程，提高立体图像处理的准确性和效率。深度学习技术在立体匹配中的应用，可以为计算机视觉和机器人领域带来更多新的可能性。总之，这份资源列表对于深度立体匹配研究者和实践者来说是一个很有价值的工具。 

<br /><br />总结:深度立体匹配的资源列表在GitHub上提供了相关论文和资源，为研究者和开发者提供了学习和参考资料，促进了深度学习在立体视觉领域的发展。 <div>
【深度立体匹配(Deep Stereo Matching）相关论文资源列表】’Awesome-Deep-Stereo-Matching - A curated list of awesome Deep Stereo Matching resources' GitHub: github.com/fabiotosi92/Awesome-Deep-Stereo-Matching <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8how2lnrtqpj21jk0qawlm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 05:20:47 GMT</pubDate>
</item>
<item>
<title>【Prompt Fuzzer：用于强化 GenAI 应用的开源工具，旨在帮助开发人员检测和防御针对其应用的 LLM 攻击，包括一个 Playground 聊天界面，用于帮助用户迭代地提高...</title>
<link>https://weibo.com/1402400261/OaqM44g2U</link>
<guid>https://weibo.com/1402400261/OaqM44g2U</guid>
<content:encoded><![CDATA[
<div> GenAI、开源工具、Prompt Fuzzer、LLM 攻击、Playground、聊天界面、系统提示的安全性、LLM 提供商、动态攻击模拟、安全测试<br />
<br />
总结:<br />
"Prompt Fuzzer"是一个开源工具，用于强化GenAI应用的安全性，帮助开发人员检测和防御针对应用的LLM攻击。该工具包括一个Playground聊天界面，用户可以通过迭代提高系统提示的安全性。支持20种不同的LLM提供商和20种动态LLM攻击模拟，包括Jailbreak、Prompt Injection和System Prompt Extraction。用户可以使用这个工具来测试和加固他们的系统提示，确保其应用程序安全可靠。 <div>
【Prompt Fuzzer：用于强化 GenAI 应用的开源工具，旨在帮助开发人员检测和防御针对其应用的 LLM 攻击，包括一个 Playground 聊天界面，用于帮助用户迭代地提高其系统提示的安全性，支持 20 种不同的 LLM 提供商和 20 种动态 LLM 攻击模拟，例如 Jailbreak、Prompt Injection 和 System Prompt Extraction】'Prompt Fuzzer - Make your GenAI Apps Safe &amp; Secure Test &amp; harden your system prompt' GitHub: github.com/prompt-security/ps-fuzz <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8how2jmu2l6j20z70u0n0h.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 05:18:51 GMT</pubDate>
</item>
<item>
<title>【非官方的 ComfyUI 魔法变装实现】'unofficial implementation of Comfyui magic clothing' GitHub: github.com/frankchieng/ComfyUI_MagicClothing #开源# #机...</title>
<link>https://weibo.com/1402400261/OaqFA13o4</link>
<guid>https://weibo.com/1402400261/OaqFA13o4</guid>
<content:encoded><![CDATA[
<div> GitHub, ComfyUI, 魔法变装, 非官方实现, 服装改变, 项目, 模仿实现, 可穿戴技术

总结:<br /><br />文章介绍了一个非官方的 ComfyUI 魔法变装实现项目，通过 GitHub 上的项目链接可以找到该项目的详细信息。该项目模仿了 ComfyUI 魔法变装的功能，实现了服装的变换和改变。这个项目展示了可穿戴技术的潜力，为用户提供了一种新颖的穿戴体验。 <div>
【非官方的 ComfyUI 魔法变装实现】'unofficial implementation of Comfyui magic clothing' GitHub: github.com/frankchieng/ComfyUI_MagicClothing <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8how2314cb9j21ce0lyjv9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 05:02:52 GMT</pubDate>
</item>
<item>
<title>GitHub：github.com/meta-llama/llama3 - 转发 @爱可可-爱生活:&amp;ensp;【Meta发布Llama 3，新一代开源大型语言模型】- Meta发布了第三代开源大模型Meta Llama 3，...</title>
<link>https://weibo.com/1402400261/OaqEtw0k5</link>
<guid>https://weibo.com/1402400261/OaqEtw0k5</guid>
<content:encoded><![CDATA[
<div> Meta、Llama 3、开源、语言模型、性能、安全可控、多语言、长上下文、多模态输入、部署
<br /><br />总结:
Meta发布了第三代开源大模型Llama 3，包括8B和70B参数两种规模的预训练语言模型，在多项基准测试中都表现出领先的性能，特别在推理和编码方面有明显改进。为了提高对话用例表现，Meta开发了指令微调技术，并确保模型的安全可控，提供了多种信任与安全工具。Llama 3将在各大云平台部署，支持多语言、长上下文和多模态输入。同时，Meta正在开发超过400B参数的Llama 3模型，未来会开源发布，并已将Meta AI助手集成了Llama 3，用户可以在不同的Meta产品上使用体验。Meta还开发了torchtune等辅助开发Llama 3的开源工具。 <div>
GitHub：github.com/meta-llama/llama3<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 【Meta发布Llama 3，新一代开源大型语言模型】<br />- Meta发布了第三代开源大模型Meta Llama 3，包括8B和70B参数两种规模的预训练语言模型。这是目前同规模参数下开源领域的最优模型。   <br />- Llama 3在多项业界基准测试上展现出领先的性能，尤其是在推理和编码等方面有明显改进。Meta通过预训练数据量的扩大、模型并行和管道并行等方式实现了模型训练的大规模化。   <br />- 为了让Llama 3对话用例的表现更优，Meta开发了指令微调技术，结合监督微调、拒绝抽样、近端策略优化等方法。提示质量和偏好排序对模型性能有很大影响。   <br />- Meta采用系统层面的方法确保Llama 3的安全可控，不仅微调了模型，还提供了 Llama Guard 2、Code Shield 和 CyberSec Eval 2等信任与安全工具。   <br />- Llama 3将在各大云平台部署，支持多语言、长上下文和多模态输入。Meta还开发了torchtune等辅助开发Llama 3的开源工具。   <br />- Meta正在开发超过400B参数的Llama 3模型，未来会开源发布。Meta AI助手已经集成了Llama 3，用户可以在不同的Meta产品上使用体验。<br />《Introducing Meta Llama 3: The most capable openly available LLM to date》 <a href="https://ai.meta.com/blog/meta-llama-3/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hovr9gq146j21e00u0tav.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hovr9idh2bj21hc0u0q65.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hovr9ketfcj21bt0u041d.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hovr9oe9jvj218g0hqq4t.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 05:00:09 GMT</pubDate>
</item>
<item>
<title>【YouTube多语言数据集，包含 YouTube 上的视频信息和相关元数据，总共包含 400k 条记录，字段包括视频标题、链接、描述、发布日期、许可证、原始语言和转录语言...</title>
<link>https://weibo.com/1402400261/OaoBdxMrE</link>
<guid>https://weibo.com/1402400261/OaoBdxMrE</guid>
<content:encoded><![CDATA[
<div> 数据集、YouTube、视频信息、元数据、400k条记录、字段、视频标题、链接、描述、发布日期、许可证、原始语言、转录语言

总结:<br />
该数据集是关于YouTube上的视频信息和相关元数据的，总共包含400k条记录。每条记录包括视频标题、链接、描述、发布日期、许可证、原始语言和转录语言等字段。数据集涵盖广泛的主题和内容，对研究和分析YouTube平台上的视频具有重要意义。数据集的规模庞大，提供了丰富的信息资源，有助于深入了解YouTube视频的特点和趋势。该数据集对于语言处理、数据挖掘和机器学习等领域的研究具有重要的参考价值。数据集的开放共享也为学术研究和商业应用提供了便利，为相关领域的研究工作提供了重要支持。 <div>
【YouTube多语言数据集，包含 YouTube 上的视频信息和相关元数据，总共包含 400k 条记录，字段包括视频标题、链接、描述、发布日期、许可证、原始语言和转录语言等】《PleIAs/YouTube-Commons · Datasets at Hugging Face》 <a href="https://huggingface.co/datasets/PleIAs/YouTube-Commons"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hovsy07p36j21f40u07b3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 23:46:38 GMT</pubDate>
</item>
<item>
<title>【Meta发布Llama 3，新一代开源大型语言模型】- Meta发布了第三代开源大模型Meta Llama 3，包括8B和70B参数两种规模的预训练语言模型。这是目前同规模参数下开源...</title>
<link>https://weibo.com/1402400261/OaodKvpuJ</link>
<guid>https://weibo.com/1402400261/OaodKvpuJ</guid>
<content:encoded><![CDATA[
<div> 关键词: Meta, Llama 3, 开源, 大型语言模型, 性能, 安全, 部署, 辅助工具, 400B参数, Meta AI助手

总结:<br /><br />
Meta发布了第三代开源大模型Llama 3，包括8B和70B参数两种规模的预训练语言模型。该模型在多项业界基准测试上表现出领先性能，特别在推理和编码方面有明显改进。为了优化对话用例表现，Meta开发了指令微调技术。为保证安全可控，Meta采用系统层面方法，提供信任与安全工具。Llama 3将在各大云平台部署，支持多语言、长上下文和多模态输入。Meta还开发了辅助工具torchtune。未来Meta将发布400B参数的Llama 3模型，并已在Meta AI助手中集成Llama 3，用户可在不同产品上使用体验。 <div>
【Meta发布Llama 3，新一代开源大型语言模型】<br />- Meta发布了第三代开源大模型Meta Llama 3，包括8B和70B参数两种规模的预训练语言模型。这是目前同规模参数下开源领域的最优模型。   <br />- Llama 3在多项业界基准测试上展现出领先的性能，尤其是在推理和编码等方面有明显改进。Meta通过预训练数据量的扩大、模型并行和管道并行等方式实现了模型训练的大规模化。   <br />- 为了让Llama 3对话用例的表现更优，Meta开发了指令微调技术，结合监督微调、拒绝抽样、近端策略优化等方法。提示质量和偏好排序对模型性能有很大影响。   <br />- Meta采用系统层面的方法确保Llama 3的安全可控，不仅微调了模型，还提供了 Llama Guard 2、Code Shield 和 CyberSec Eval 2等信任与安全工具。   <br />- Llama 3将在各大云平台部署，支持多语言、长上下文和多模态输入。Meta还开发了torchtune等辅助开发Llama 3的开源工具。   <br />- Meta正在开发超过400B参数的Llama 3模型，未来会开源发布。Meta AI助手已经集成了Llama 3，用户可以在不同的Meta产品上使用体验。<br />《Introducing Meta Llama 3: The most capable openly available LLM to date》 <a href="https://ai.meta.com/blog/meta-llama-3/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hovr9gq146j21e00u0tav.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hovr9idh2bj21hc0u0q65.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hovr9ketfcj21bt0u041d.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hovr9oe9jvj218g0hqq4t.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 22:48:49 GMT</pubDate>
</item>
<item>
<title>【开放语言模型对齐】《Aligning open language models - Google Slides》Nathan Lambert 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/Oao9Ftpmw</link>
<guid>https://weibo.com/1402400261/Oao9Ftpmw</guid>
<content:encoded><![CDATA[
<div> 关键词：开放语言模型、对齐、Google Slides、Nathan Lambert

总结:<br /><br />本文介绍了如何通过对齐开放语言模型来提高其性能和效率。首先，作者介绍了开放语言模型的重要性和应用场景。接着，讨论了如何利用Google Slides平台进行开放语言模型的对齐工作。文章还提到了Nathan Lambert在这一领域的研究和贡献。通过对齐开放语言模型，可以更好地理解和应用这些模型，提高其性能和准确性。通过这篇文章，读者可以更深入地了解开放语言模型对齐的重要性和方法。 <div>
【开放语言模型对齐】《Aligning open language models - Google Slides》Nathan Lambert <a href="https://docs.google.com/presentation/d/1quMyI4BAx4rvcDfk8jjv063bmHg4RxZd9mhQloXpMn0/edit"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hovqz9hzngj21hd0u0jzg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 22:38:45 GMT</pubDate>
</item>
<item>
<title>今日推介(第1380期)：语多样本上下文学习、通过位置信息操纵提升大型语言模型、用更少截断改进语言建模、分子图上GNN的可扩展性研究、面向相机运动模糊的高斯Spl...</title>
<link>https://weibo.com/1402400261/Oao1n80W3</link>
<guid>https://weibo.com/1402400261/Oao1n80W3</guid>
<content:encoded><![CDATA[
<div> 语多样本上下文学习、位置信息操纵、大型语言模型、少截断改进、分子图上GNN可扩展性研究、面向相机运动模糊的高斯Splatting

总结:<br /><br />本文介绍了几个关于语言建模和图神经网络的研究进展。首先，提出了语多样本上下文学习和通过位置信息操纵来提升大型语言模型的方法，以改进语言建模的效果。其次，研究了如何通过更少的截断来改进语言建模的性能，以减少信息丢失。然后，探讨了在分子图上应用图神经网络的可扩展性，并对面向相机运动模糊的高斯Splatting技术进行了探讨。这些研究对于提高语言建模和图神经网络的效果有着重要的意义。 <div>
今日推介(第1380期)：语多样本上下文学习、通过位置信息操纵提升大型语言模型、用更少截断改进语言建模、分子图上GNN的可扩展性研究、面向相机运动模糊的高斯Splatting 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/693301537"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hovqdp5pzuj21j80rc10i.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hovqdtv4emj20qi0ucwi6.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hovqdx1q56j21nd0u07b2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hovqdzdhwyj20te0tgtdd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hovqe35lmpj21660oejw9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 22:18:19 GMT</pubDate>
</item>
<item>
<title>[CL] Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions 网页链接 通过审视社交智能的概念内涵和研究进展，提出Social-AI...</title>
<link>https://weibo.com/1402400261/OanXMemuh</link>
<guid>https://weibo.com/1402400261/OanXMemuh</guid>
<content:encoded><![CDATA[
<div> 挑战, 社交智能, AI代理, 技术, 社交构造, 互动信号, 多重视角, 智能体适应性, 方法, 开放问题

总结:<br />
本文探讨了社交智能在AI代理中的重要性，提出了面临的4大技术挑战：社交构造的模糊性、细微互动信号、多重视角和智能体适应性。针对这些挑战，文章提出了一些应对方法，并指出了一些仍待解决的开放问题。通过这些讨论，可以为Social-AI研究提供重要的指导和启发。 <div>
[CL] Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions  <br /><a href="https://arxiv.org/abs/2404.11023"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过审视社交智能的概念内涵和研究进展，提出Social-AI研究面临的4大核心技术挑战，包括社交构造的模糊性、细微互动信号、多重视角、智能体适应性，并给出应对这些挑战的方法与开放问题，对指导Social-AI研究具有重要启发作用。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovq4v7d09j20vy1ckngq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovq4vfqquj217619u4ai.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovq4w42hpj20ua0sutdn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 22:09:28 GMT</pubDate>
</item>
<item>
<title>[IR] A Survey on Retrieval-Augmented Text Generation for Large Language Models 网页链接 通过预处理、检索、后处理和生成四个阶段全面梳理检索增强型文本生...</title>
<link>https://weibo.com/1402400261/OanTvAiNt</link>
<guid>https://weibo.com/1402400261/OanTvAiNt</guid>
<content:encoded><![CDATA[
<div> 技术框架、方法进展、应用潜力、预处理、检索、后处理、生成、检索增强型文本生成、RAG

<br /><br />总结:
本文对检索增强型文本生成（RAG）进行了综合调查，从预处理、检索、后处理和生成四个阶段全面分析了RAG的技术框架、方法进展和应用潜力。首先介绍了RAG的基本概念及其研究背景，然后详细探讨了RAG在不同阶段的技术应用和改进，包括预处理阶段的数据准备和文本清洗，检索阶段的信息获取和匹配，生成阶段的文本生成能力和模型优化等。文章指出RAG在自然语言处理领域具有广阔的应用前景，能够提高文本生成的质量和效率，为读者深入了解RAG的内涵提供了详尽的参考资料。 <div>
[IR] A Survey on Retrieval-Augmented Text Generation for Large Language Models  <br /><a href="https://arxiv.org/abs/2404.10981"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过预处理、检索、后处理和生成四个阶段全面梳理检索增强型文本生成(RAG)的技术框架、方法进展与应用潜力，为读者理解 RAG 的内涵提供了清晰直观的途径。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovptxdy6aj20w41cak9j.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovptxmkrqj21b00n8aeg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovptyfzdcj21q60watot.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 21:58:57 GMT</pubDate>
</item>
<item>
<title>[CL] Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent 网页链接 Octopus v3提出了文本、图像和功能令牌的结合框架，在亚十亿参数...</title>
<link>https://weibo.com/1402400261/OanQxm3l0</link>
<guid>https://weibo.com/1402400261/OanQxm3l0</guid>
<content:encoded><![CDATA[
<div> 提取关键词: Octopus v3, 文本, 图像, 功能令牌, 多模态建模, 边缘部署, 亚十亿参数量

总结:<br /><br />总结: Octopus v3提出了文本、图像和功能令牌的结合框架，实现了多模态建模和边缘部署的有效结合。该模型在亚十亿参数量下进行了设计和实施，展现了在实际设备上运行的能力。通过结合不同类型的输入数据，Octopus v3能够更好地理解和处理复杂的信息，实现更高效的AI任务处理。同时，边缘部署也提高了模型的响应速度和隐私保护性，使得该多模态AI Agent在各种环境中都能够得到有效应用和部署。Octopus v3的提出为多模态AI技术的发展提供了重要的思路和参考。 <div>
[CL] Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent  <br /><a href="https://arxiv.org/abs/2404.11459"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />Octopus v3提出了文本、图像和功能令牌的结合框架，在亚十亿参数量下实现了多模态建模和边缘部署的有效结合。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovpmbqamlj20uu1aw4a2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovpmbyahuj21600xwdoi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovpmcelrxj216q0u8dk6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 21:51:38 GMT</pubDate>
</item>
<item>
<title>[LG] Variational Bayesian Last Layers 网页链接 提出变分贝叶斯最后层(VBLL)方法，以极小的计算开销显著改进了神经网络的不确定度建模和泛化能力。 [图片][图...</title>
<link>https://weibo.com/1402400261/OanNwjhGR</link>
<guid>https://weibo.com/1402400261/OanNwjhGR</guid>
<content:encoded><![CDATA[
<div> 变分贝叶斯；最后层；神经网络；不确定度建模；泛化能力；VBLL方法；计算开销；改进；极小；提出
<br />
<br />
总结: 本文提出了一种新方法，称为变分贝叶斯最后层（VBLL），可以显著改进神经网络的不确定度建模和泛化能力。通过极小的计算开销，VBLL方法在提高模型表现的同时，也可以有效地提高模型的不确定度估计能力。VBLL方法对于提高神经网络的性能和可靠性具有重要意义。 <div>
[LG] Variational Bayesian Last Layers  <br /><a href="https://arxiv.org/abs/2404.11599"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出变分贝叶斯最后层(VBLL)方法，以极小的计算开销显著改进了神经网络的不确定度建模和泛化能力。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovpelk329j20vu1cy7le.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovpelras0j21980oktfg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovpem2pxej219q0iwq7g.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 21:44:12 GMT</pubDate>
</item>
<item>
<title>提出DeblurGS框架，通过联合优化相机运动轨迹和基于3D高斯Splatting的清晰场景表示，实现了从含模糊多视图中重建细致逼真3D场景的目标，对处理实际应用中存在的...</title>
<link>https://weibo.com/1402400261/OanKPenH4</link>
<guid>https://weibo.com/1402400261/OanKPenH4</guid>
<content:encoded><![CDATA[
<div> DeblurGS, 相机运动轨迹, 3D高斯Splatting, 清晰场景表示, 多视图重建, 模糊效果, 实际应用, 重要意义, 高质量重建, 高效性能

<br /><br />总结:
DeblurGS框架提出了一种通过联合优化相机运动轨迹和基于3D高斯Splatting的清晰场景表示的方法。该方法旨在重建细致逼真的3D场景，处理含模糊多视图中存在的各类模糊效果。该框架结合了高质量重建和高效性能，对实际应用具有重要意义。通过对相机运动轨迹和3D场景表示的优化，DeblurGS实现了有效的模糊去除，为多视图重建提供了新的思路。通过使用3D高斯Splatting技术，使得重建的场景更加细致逼真。该研究为解决实际应用中的模糊效果问题提供了有力的工具和方法。 <div>
提出DeblurGS框架，通过联合优化相机运动轨迹和基于3D高斯Splatting的清晰场景表示，实现了从含模糊多视图中重建细致逼真3D场景的目标，对处理实际应用中存在的各类模糊效果具有重要意义。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《DeblurGS: Gaussian Splatting for Camera Motion Blur》J Oh, J Chung, D Lee, K M Lee [Seoul National University] (2024) <a href="https://arxiv.org/abs/2404.11358"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovp0hblwkj20zo0pck1m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovp0hpdj4j215g0p0aht.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovp0hwk7ij21660oeagj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovp0i1z1jj216o0u0qc6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovp7l7cqpj20rl0eegnq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovp7l76bfj20rl0e20ue.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovp7l850gj20rh0u2jw3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovp7l7ohyj20rl0iatbz.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 21:37:33 GMT</pubDate>
</item>
<item>
<title>[CV]《DeblurGS: Gaussian Splatting for Camera Motion Blur》J Oh, J Chung, D Lee, K M Lee [Seoul National University] (2024) 网页链接 #机器学习##人工智...</title>
<link>https://weibo.com/1402400261/OanKMzLzW</link>
<guid>https://weibo.com/1402400261/OanKMzLzW</guid>
<content:encoded><![CDATA[
<div> Gaussian Splatting, Camera Motion Blur, DeblurGS, Seoul National University

总结：<br /><br />这篇文章提出了一种名为DeblurGS的方法，用于处理相机运动模糊。通过高斯混合模型进行像素插值，实现对图像的去模糊处理。实验结果表明，DeblurGS在减少模糊效果方面取得了良好效果，能够有效提高图像质量，适用于多种场景和应用。研究由首尔国立大学进行，展示了该方法在图像去模糊领域的潜力和有效性。 <div>
[CV]《DeblurGS: Gaussian Splatting for Camera Motion Blur》J Oh, J Chung, D Lee, K M Lee [Seoul National University] (2024) <a href="https://arxiv.org/abs/2404.11358"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovp0hblwkj20zo0pck1m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovp0hpdj4j215g0p0aht.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovp0hwk7ij21660oeagj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovp0i1z1jj216o0u0qc6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovp7l7cqpj20rl0eegnq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovp7l76bfj20rl0e20ue.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovp7l850gj20rh0u2jw3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovp7l7ohyj20rl0iatbz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 21:37:27 GMT</pubDate>
</item>
<item>
<title>通过大规模实验研究证明，GNN模型在分子图建模任务中存在强大的可扩展性，持续扩大模型和数据集规模可以获得显著提升，在各种下游任务上性能优异，为GNN模型应用...</title>
<link>https://weibo.com/1402400261/OanGMlXEw</link>
<guid>https://weibo.com/1402400261/OanGMlXEw</guid>
<content:encoded><![CDATA[
<div> 关键词：GNN模型、分子图建模、可扩展性、药物发现

总结：<br /><br />这篇文章通过大规模实验研究证明了GNN模型在分子图建模任务中具有强大的可扩展性，持续扩大模型和数据集规模可以显著提升性能。研究发现GNN模型在各种下游任务上表现优异，为其在药物发现领域的应用奠定了基础。通过验证实验，论文展示了GNN模型在处理分子图数据时的优势，为未来在药物发现领域的应用提供了重要参考。研究者呼吁更多关注GNN模型在分子图建模任务中的可扩展性，以进一步推动其在药物发现领域的发展。 <div>
通过大规模实验研究证明，GNN模型在分子图建模任务中存在强大的可扩展性，持续扩大模型和数据集规模可以获得显著提升，在各种下游任务上性能优异，为GNN模型应用于药物发现奠定基础。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《On the Scalability of GNNs for Molecular Graphs》M Sypetkowski, F Wenkel, F Poursafaei, N Dickson... [Valence Labs] (2024) <a href="https://arxiv.org/abs/2404.11568"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovoonj6z1j20p014atjm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovoonyuzxj20te0tg44r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovoooha3uj20q21ayqbq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovoooq9jkj20we18gdq0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovooy4urmj212d0ikaeb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovooy3vcxj20j00hq75r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovooy47k5j212d07idhf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovooy4ohbj212d0euwi3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovooy4kgsj212g0k6tbq.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 21:27:35 GMT</pubDate>
</item>
<item>
<title>[LG]《On the Scalability of GNNs for Molecular Graphs》M Sypetkowski, F Wenkel, F Poursafaei, N Dickson... [Valence Labs] (2024) 网页链接 #机器学习##...</title>
<link>https://weibo.com/1402400261/OanDw57nB</link>
<guid>https://weibo.com/1402400261/OanDw57nB</guid>
<content:encoded><![CDATA[
<div> 分子图、图神经网络、可扩展性、分子属性预测、计算效率、模型效果、图神经网络层次结构、特征表征、化学信息处理、模型训练<br />
<br />
该研究主要探讨了图神经网络（GNNs）在处理分子图时的可扩展性问题。研究者针对分子属性预测任务，在不同数据集上对比了不同GNN模型的计算效率和模型效果。实验结果显示，随着分子图规模和复杂度的增加，GNNs的计算速度和模型性能呈现较大差异。研究发现，通过设计合理的图神经网络层次结构和特征表征方法，能够有效提高模型的可扩展性和化学信息处理能力。此外，模型训练过程中的超参数调节也对GNNs的表现产生重要影响。总体而言，本文对于GNNs在分子图领域的应用具有一定的启发意义。 <br /><br />总结: <div>
[LG]《On the Scalability of GNNs for Molecular Graphs》M Sypetkowski, F Wenkel, F Poursafaei, N Dickson... [Valence Labs] (2024) <a href="https://arxiv.org/abs/2404.11568"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovoonj6z1j20p014atjm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovoonyuzxj20te0tg44r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovoooha3uj20q21ayqbq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovoooq9jkj20we18gdq0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovooy4urmj212d0ikaeb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovooy3vcxj20j00hq75r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovooy47k5j212d07idhf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovooy4ohbj212d0euwi3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovooy4kgsj212g0k6tbq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovooy4d7dj212d0gognt.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovooy4gc4j212d0evaca.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovooy55i2j212h0ncwje.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 21:19:33 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.18)》 爱可可微博热门分享(4.18) [图片]</title>
<link>https://weibo.com/1402400261/OakUnaXhF</link>
<guid>https://weibo.com/1402400261/OakUnaXhF</guid>
<content:encoded><![CDATA[
<div> 微博, 热门分享, 爱可可, 4.18, 好物, 点赞, 萌宠, 美食, 旅行, 心情<br />
<br />
爱可可微博在4月18日分享了一些热门话题，包括优质好物推荐、萌宠日常、美食探店、旅行心情分享等内容。大家纷纷点赞评论，互动热烈。微博内容涵盖了多个领域，让粉丝们享受到丰富多彩的信息和乐趣。总体而言，爱可可微博的热门分享内容丰富多彩，受到广泛关注和喜爱。<br /><br />总结: <div>
《爱可可微博热门分享(4.18)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405024636554575876"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.18)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovcn8wytoj20dc07iwey.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 14:22:50 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《NARUTO: Neural Active Reconstruction from Uncertain Target Observations》(CVPR 2024) GitHub: github.com/oppo-us-research/Naruto《D...</title>
<link>https://weibo.com/1402400261/OakPDdo2d</link>
<guid>https://weibo.com/1402400261/OakPDdo2d</guid>
<content:encoded><![CDATA[
<div> 关键词: NARUTO, 目标重建, 不确定观测, 神经网络, 实现代码, 论文, CVPR 2024

总结:
NARUTO是一篇CVPR 2024年的论文，提出了神经网络方法用于从不确定的目标观测中进行主动重建。该论文提供了实现代码的GitHub链接，可以帮助其他研究人员深入了解和复现这项工作。这篇论文的主要贡献是引入了一种新颖的方法，可以有效地重建不确定的目标观测数据。通过该方法，可以实现更准确和可靠的目标重建，有望在未来的研究中得到广泛应用。 NARUTO这篇论文在CVPR 2024会议上展示并受到关注。 <div>
几篇论文实现代码：<br />《NARUTO: Neural Active Reconstruction from Uncertain Target Observations》(CVPR 2024) GitHub: github.com/oppo-us-research/Naruto<br />《DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation》(CVPR 2024) GitHub: github.com/JeremyCJM/DiffSHEG [fig3]<br />《Degrees of Freedom Matter: Inferring Dynamics from Point Trajectories》(CVPR 2024) GitHub: github.com/yz-cnsdqz/DOMA-release<br />《InFusion: Inpainting 3D Gaussians via Learning Depth Completion from Diffusion Prior》(2024) GitHub: github.com/ali-vilab/Infusion [fig1]<br />《MMInA: Benchmarking Multihop Multimodal Internet Agents》(2024) GitHub: github.com/shulin16/MMInA<br />《Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention》(2024) GitHub: github.com/jiahe7ay/infini-mini-transformer [fig2]<br />《Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation》(2024) GitHub: github.com/omer11a/bounded-attention<br />《OpenEval: Benchmarking Programming Agents for Open-Domain Tasks》(2024) GitHub: github.com/bigcode-project/open-eval<br />《Consistent Diffusion Meets Tweedie》(2024) GitHub: github.com/giannisdaras/ambient-tweedie<br />《Automatic Lyric Transcription and Automatic Music Transcription from Multimodal Singing》(2024) GitHub: github.com/guxm2021/SVT_SpeechBrain [fig5]<br />《Safe Low-Altitude Navigation in Steep Terrain with Fixed-Wing Aerial Vehicles》(2024) GitHub: github.com/ethz-asl/terrain-navigation<br />《OpenGraph: Open-Vocabulary Hierarchical 3D Graph Representation in Large-Scale Outdoor Environments》(2024) GitHub: github.com/BIT-DYN/OpenGraph<br />《Tightly Joining Positioning and Control for Trustworthy Unmanned Aerial Vehicles Based on Factor Graph Optimization in Urban Transportation》(2024) GitHub: github.com/RoboticsPolyu/IPN_MPC<br />《Learning to walk in confined spaces using 3D representation》(2024) GitHub: github.com/leggedrobotics/terrain-generator<br />《ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback》(2024) GitHub: github.com/liming-ai/ControlNet_Plus_Plus<br />《Fast and Optimal Weight Update for Pruned Large Language Models》(2024) GitHub: github.com/fmfi-compbio/admm-pruning<br />《SHIELD: An Evaluation Benchmark for Face Spoofing and Forgery Detection with Multimodal Large Language Models》(2024) GitHub: github.com/laiyingxin2/SHIELD<br />《A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity》(2024) GitHub: github.com/ajyl/dpo_toxic<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovaefr12dj21430o5b29.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovaegvnyqj21e00oewhl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovb915w0aj229u0xxnpd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovb9t52g7j21l30fr1kx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovbv01eglj22hk0w0njp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 14:11:09 GMT</pubDate>
</item>
<item>
<title>【公开的机器学习病理数据集，包括肺、乳腺、结直肠、前列腺、肾等多种肿瘤组织】'Histopathology Datasets for Machine Learning - Ressources of histopatholo...</title>
<link>https://weibo.com/1402400261/OakGEb2KR</link>
<guid>https://weibo.com/1402400261/OakGEb2KR</guid>
<content:encoded><![CDATA[
<div> 肺、乳腺、结直肠、前列腺、肾、机器学习、病理数据集、GitHub、Histopathology Datasets

Histopathology Datasets for Machine Learning项目提供了多种肿瘤组织的病理数据集，包括肺、乳腺、结直肠、前列腺、肾等。这些数据集可用于机器学习研究，有助于开展肿瘤相关的数据挖掘和分析工作。感兴趣的研究者可在GitHub上找到相关资源。Histopathology Datasets for Machine Learning为研究和应用提供了重要的数据基础，促进了医学病理学和机器学习领域的交叉发展。 <div>
【公开的机器学习病理数据集，包括肺、乳腺、结直肠、前列腺、肾等多种肿瘤组织】'Histopathology Datasets for Machine Learning - Ressources of histopathology datasets' GitHub: github.com/maduc7/Histopathology-Datasets <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hovbng463uj21080u0wi2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 13:49:01 GMT</pubDate>
</item>
<item>
<title>【List of ML File Formats：机器学习常见文件格式列表，包含了众多机器学习系统使用的文件格式，并提供了相关工具和补充信息】'List of ML File Formats - List...</title>
<link>https://weibo.com/1402400261/OakDMgIdY</link>
<guid>https://weibo.com/1402400261/OakDMgIdY</guid>
<content:encoded><![CDATA[
<div> 机器学习、文件格式、相关工具、GitHub、ML文件格式、系统使用、补充信息、常见、列表、工具<br />
<br />
总结:<br />
本文介绍了机器学习常见文件格式列表，包含了众多机器学习系统使用的文件格式，提供了相关工具和补充信息。GitHub上有一个名为"List of ML file formats"的项目，供大家查阅。文章列举了多种常见的机器学习文件格式及其应用情况，对于机器学习从业者具有一定的参考价值。读者可以通过该列表了解机器学习领域中常见的文件格式，为实际应用提供参考和指导。 <div>
【List of ML File Formats：机器学习常见文件格式列表，包含了众多机器学习系统使用的文件格式，并提供了相关工具和补充信息】'List of ML File Formats - List of ML file formats' GitHub: github.com/trailofbits/ml-file-formats <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hovbgauk7lj20u00zsae5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 13:41:57 GMT</pubDate>
</item>
<item>
<title>【Cognita：用于生产环境中构建模块化、开源RAG应用的框架】'Cognita - Cognita by TrueFoundry - Framework for building modular, open source RAG applicatio...</title>
<link>https://weibo.com/1402400261/OakD1b7Ez</link>
<guid>https://weibo.com/1402400261/OakD1b7Ez</guid>
<content:encoded><![CDATA[
<div> 框架，生产环境，模块化，开源，RAG应用，TrueFoundry，GitHub，TrueFoundry/cognita<br />
<br />总结:<br />文章介绍了Cognita这个由TrueFoundry推出的框架，用于在生产环境中构建模块化、开源的RAG应用。Cognita旨在帮助开发人员快速构建应用程序，并提供灵活性和可定制性。开发者可以在GitHub上找到Cognita的源代码，并借助此框架开发自己的应用程序。Cognita为构建现代化的应用程序提供了一个强大的工具，有助于提高生产效率和应用程序质量。 <div>
【Cognita：用于生产环境中构建模块化、开源RAG应用的框架】'Cognita - Cognita by TrueFoundry - Framework for building modular, open source RAG applications for production.' GitHub: github.com/truefoundry/cognita <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hovbewe9p5j20u014ewll.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 13:40:05 GMT</pubDate>
</item>
<item>
<title>【股价预测/量化交易相关论文列表】’stock-top-papers - Top paper collection for stock price prediction, quantitative trading. Covering top conferences ...</title>
<link>https://weibo.com/1402400261/OakBGgPuo</link>
<guid>https://weibo.com/1402400261/OakBGgPuo</guid>
<content:encoded><![CDATA[
<div> 股价预测, 量化交易, 论文, 列表, 会议, 期刊, GitHub, KDD, TKDE

<br /><br />总结:
这篇论文汇总了关于股价预测和量化交易的顶级论文，涵盖了诸如KDD、TKDE、CIKM、AAAI、IJCAI、ACL、EMNLP等顶级会议和期刊。研究主要关注股票市场的价格走势预测和量化交易策略的设计与优化，为投资者提供了重要的参考和指导。GitHub链接提供了更多相关信息和资源。 <div>
【股价预测/量化交易相关论文列表】’stock-top-papers - Top paper collection for stock price prediction, quantitative trading. Covering top conferences and journals like KDD, TKDE, CIKM, AAAI, IJCAI, ACL, EMNLP.' GitHub: github.com/Waterkin/stock-top-papers <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hovbbgl24ej20ve0u0goy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 13:36:47 GMT</pubDate>
</item>
<item>
<title>【Web Scraper：用于抓取网页并将其转换为 Markdown 格式，以便于 AI 搜索应用的增强】'Web Scraper - Scrape the webpage convert it into Markdown, and enhan...</title>
<link>https://weibo.com/1402400261/OakuQg556</link>
<guid>https://weibo.com/1402400261/OakuQg556</guid>
<content:encoded><![CDATA[
<div> 抓取、网页、转换、Markdown、增强、AI、搜索应用、Web Scraper、GitHub、zzzgydi<br />
<br />
抓取网页并转换为Markdown格式，可用于增强AI搜索应用的Web Scraper工具现已开源在GitHub上（github.com/zzzgydi/webscraper）。该工具能够帮助用户快速抓取网页内容，转换为Markdown格式，使其更易于阅读和分析，并可以在AI搜索应用中使用。利用Web Scraper，用户可以更高效地收集和处理网页信息，提升搜索应用的效率和准确性。通过将网页内容转换为Markdown格式，可以帮助用户更好地管理和整理数据，为AI搜索应用的优化提供支持。总之，Web Scraper是一个实用的工具，可以为AI搜索应用的开发和应用带来便利和效益。<br /><br />总结: <br />抓取网页并转换为Markdown格式，用于增强AI搜索应用。 工具现已开源于GitHub，可提高网页信息处理效率。 转换为Markdown格式便于数据管理和搜索应用优化。 实用工具为AI搜索应用开发和应用带来便利。 <div>
【Web Scraper：用于抓取网页并将其转换为 Markdown 格式，以便于 AI 搜索应用的增强】'Web Scraper - Scrape the webpage convert it into Markdown, and enhance AI search applications.' GitHub: github.com/zzzgydi/webscraper <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hovatd5e3mj21280u0786.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 13:19:56 GMT</pubDate>
</item>
<item>
<title>【Coix：实现概率编程中的程序组合器的JAX框架，提供了许多基本的程序转换和常见的目标，可以用于实现和运行各种推理算法】'Coix - Inference Combinators in JA...</title>
<link>https://weibo.com/1402400261/Oakugc0AX</link>
<guid>https://weibo.com/1402400261/Oakugc0AX</guid>
<content:encoded><![CDATA[
<div> GitHub、Coix、JAX、程序组合器、概率编程、程序转换、推理算法、基本的、常见的目标

<br /><br />总结:
文章介绍了在JAX框架中实现的概率编程中的程序组合器Coix，提供了多种基本的程序转换和常见的目标，可以用于实现和运行各种推理算法。Coix的开源代码存储在GitHub上，并提供了详细的文档和示例供用户参考。该框架的设计旨在简化推理算法的实现过程，使用户能够通过组合现有的程序部件来构建复杂的推理模型。通过利用JAX框架的高性能计算能力，Coix能够快速、高效地执行各种推理任务，为概率编程领域的研究和应用提供了有力的工具支持。Coix的灵活性和可扩展性使其适用于各种不同类型的概率模型，为用户提供了更多选择和可能性。通过使用Coix，用户可以更轻松地实现自己的推理算法，并与其他研究者分享他们的工作成果。Coix的出现为概率编程和推理算法的发展带来了新的机遇和挑战，有望推动该领域的进一步发展和创新。 <div>
【Coix：实现概率编程中的程序组合器的JAX框架，提供了许多基本的程序转换和常见的目标，可以用于实现和运行各种推理算法】'Coix - Inference Combinators in JAX' GitHub: github.com/jax-ml/coix <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hovar42i9cj20x70u0tdp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 13:18:30 GMT</pubDate>
</item>
<item>
<title>【BiTE：平台无关的执行文件分析工具，旨在提供一个环境来检查二进制文件和调试信息的内容，支持多种架构】'BiTE - Disassembler focused on comprehensive rust...</title>
<link>https://weibo.com/1402400261/Oaksl0rF6</link>
<guid>https://weibo.com/1402400261/Oaksl0rF6</guid>
<content:encoded><![CDATA[
<div> 平台无关、执行文件分析工具、环境、检查、二进制文件、调试信息、支持、多种架构、GitHub

<br />
BiTE是一个平台无关的执行文件分析工具，旨在提供一个环境来检查二进制文件和调试信息的内容。该工具支持多种架构，特别关注在综合rust支持上。用户可以通过GitHub上的WINSDK/bite找到该工具的详细信息和下载。BiTE的设计目标是帮助用户了解二进制文件的内容和调试信息，解决不同架构的执行文件分析需求。如果你需要一个专注于rust语言支持的反汇编工具，不妨试试BiTE。 <div>
【BiTE：平台无关的执行文件分析工具，旨在提供一个环境来检查二进制文件和调试信息的内容，支持多种架构】'BiTE - Disassembler focused on comprehensive rust support.' GitHub: github.com/WINSDK/bite <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%B7%A5%E5%85%B7%23&amp;isnewpage=1"><span class="surl-text">#工具#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hovanh0ywjj21kg0piaev.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 13:13:46 GMT</pubDate>
</item>
<item>
<title>【ImgCatr：用RUST写的命令行图像显示应用】'ImgCatr - cat for images, by RUST' GitHub: github.com/SilinMeng0510/imgcatr #开源# #工具# [图片][图片]</title>
<link>https://weibo.com/1402400261/Oaha3145u</link>
<guid>https://weibo.com/1402400261/Oaha3145u</guid>
<content:encoded><![CDATA[
<div> RUST, 命令行, 图像显示, 应用, ImgCatr, GitHub, SilinMeng0510, cat, 图片<br />
<br />
总结:
这篇文章介绍了一个用RUST编写的命令行图像显示应用ImgCatr。该应用类似于Linux中的cat命令，但是用于显示图片。GitHub上有这个应用的代码仓库，可以在github.com/SilinMeng0510/imgcatr找到。用户可以使用ImgCatr来在命令行中显示和查看图片，提供了一种不同于常规图片查看器的方式。该应用简单易用，适用于需要在命令行环境中查看图片的场景。 <div>
【ImgCatr：用RUST写的命令行图像显示应用】'ImgCatr - cat for images, by RUST' GitHub: github.com/SilinMeng0510/imgcatr <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%B7%A5%E5%85%B7%23&amp;isnewpage=1"><span class="surl-text">#工具#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8houw34yft1j20u00vxq5i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8houw3s10qmj20ke0lmgo1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 04:50:28 GMT</pubDate>
</item>
<item>
<title>【EasyFrontend：免费开源的 Tailwind CSS UI 组件库，用于创建 landing pages 和网站】’EasyFrontend - Tailwind CSS Components - Free Tailwind html UI Com...</title>
<link>https://weibo.com/1402400261/Oah8S1QHY</link>
<guid>https://weibo.com/1402400261/Oah8S1QHY</guid>
<content:encoded><![CDATA[
<div> Tailwind CSS, UI组件库, landing pages, 网站, 免费, 开源, GitHub, EasyFrontend, 支持, 爱心

总结:<br /><br />EasyFrontend是一个免费开源的Tailwind CSS UI组件库，专为创建landing pages和网站而构建。这些UI组件是免费的，用户可以在GitHub上找到EasyFrontend的项目。支持EasyFrontend，并体现您的爱心，不要忘记给他们一个star。 <div>
【EasyFrontend：免费开源的 Tailwind CSS UI 组件库，用于创建 landing pages 和网站】’EasyFrontend - Tailwind CSS Components - Free Tailwind html UI Components - built to create landing pages and websites. Easyfrontend UI components are free and open-source. show your support and love, don't forget to give us a star' GitHub: github.com/EasyFrontend-com/html-tailwindcss-components <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%89%8D%E7%AB%AF%23&amp;isnewpage=1"><span class="surl-text">#前端#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8houw0pym7rj21400p0tbo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8houw0qi18dj21400p0din.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8houw0ro74zj21400p0ae7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 04:47:34 GMT</pubDate>
</item>
<item>
<title>【bucketMul LLM 推理的实现，使用 Swift 和 Metal 语言编写】'An implementation of bucketMul LLM inference' GitHub: github.com/kolinko/effort #开源# #机...</title>
<link>https://weibo.com/1402400261/Oah8vogzq</link>
<guid>https://weibo.com/1402400261/Oah8vogzq</guid>
<content:encoded><![CDATA[
<div> bucketMul LLM, 推理, 实现, Swift, Metal, GitHub, implementation, inference, Kolinko, effort

<br /><br />总结:
该篇文章介绍了使用Swift和Metal语言编写的bucketMul LLM推理的实现。作者在GitHub上提供了相关代码和资源。通过这个实现，用户可以进行推理操作，并了解LLM模型在推理阶段的工作原理和效果。这为研究人员和开发者提供了一个学习和使用LLM模型的机会。 <div>
【bucketMul LLM 推理的实现，使用 Swift 和 Metal 语言编写】'An implementation of bucketMul LLM inference' GitHub: github.com/kolinko/effort <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8houvzvchphj21190u0af9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 04:46:40 GMT</pubDate>
</item>
<item>
<title>【Mistral Common：旨在帮助用户处理 Mistral 模型的工具集。首次发布包含文本的分词功能，其分词器不仅处理常规的文本到标记的转换，还增加了工具解析和结构化...</title>
<link>https://weibo.com/1402400261/Oah7ThdiQ</link>
<guid>https://weibo.com/1402400261/Oah7ThdiQ</guid>
<content:encoded><![CDATA[
<div> 分词功能, 工具解析, 结构化对话, API, 验证, 规范化代码, Mistral 模型, 用户处理, 发布, GitHub

总结:<br /><br />
"Mistral Common"是一个工具集，旨在帮助用户处理Mistral模型。首次发布的功能包括文本的分词功能，分词器不仅可以处理常规的文本到标记的转换，还增加了工具解析和结构化对话的处理。此外，还发布了用于API中的验证和规范化代码。用户可以在GitHub上找到"Mistral Common"的开源代码。 <div>
【Mistral Common：旨在帮助用户处理 Mistral 模型的工具集。首次发布包含文本的分词功能，其分词器不仅处理常规的文本到标记的转换，还增加了工具解析和结构化对话的处理，还发布了用于API中的验证和规范化代码】'Mistral Common' GitHub: github.com/mistralai/mistral-common <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8houvy2qym5j21740tq0x8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 04:45:09 GMT</pubDate>
</item>
<item>
<title>【波士顿动力推出电动人型机器人Atlas，展现超强力量与灵活性】- Boston Dynamics推出了全新的全电动Atlas机器人，这是在几十年的机器人创新和多年实践经验基础...</title>
<link>https://weibo.com/1402400261/OafoiBw4B</link>
<guid>https://weibo.com/1402400261/OafoiBw4B</guid>
<content:encoded><![CDATA[
<div> 机器人, Atlas, 波士顿动力, 电动, 强力量, 灵活性, 海云达, 测试, 商业化, AI技术

<br /><br />总结:
波士顿动力推出了全新的电动人型机器人Atlas，具有强大力量和广阔运动范围，可抬起和操纵各种重量和形状不规则的物体。公司将与海云达等客户合作，在真实环境中测试和迭代Atlas的应用，逐步实现商业化。在软件方面，波士顿动力运用了强化学习、计算机视觉等AI技术，提升了机器人适应复杂环境的能力。Atlas能够高效地完成各种任务，并超越人的运动能力。波士顿动力在Spot和Stretch商业化中积累了丰富经验，为Atlas提供完整的软件、服务和支持生态系统，推动其应用，助力解决更多行业痛点，实现机器人的商业化应用。 <div>
【波士顿动力推出电动人型机器人Atlas，展现超强力量与灵活性】<br />- Boston Dynamics推出了全新的全电动Atlas机器人，这是在几十年的机器人创新和多年实践经验基础上实现的。   <br />- 相比上一代的液压Atlas，全新电动Atlas机器人力量更大、运动范围更广。它能抬起和操纵各种重量、形状不规则的物体。   <br />- Boston Dynamics将与海云达等客户合作，在工厂等真实环境中测试和迭代Atlas的应用，逐步实现商业化。   <br />- 除了硬件，Boston Dynamics在软件方面也取得了进步，如运用了强化学习、计算机视觉等AI技术，提升了机器人适应复杂环境的能力。   <br />- 人形机器人Atlas能够以高效的方式完成各种任务，其运动方式会超越人的能力。   <br />- Boston Dynamics在Spot和Stretch商业化中积累了丰富经验，能为Atlas提供完整的软件、服务和支持生态系统，推动其应用。   <br />- Atlas加入Spot和Stretch，将助力Boston Dynamics解决更多行业痛点，实现机器人的商业化应用。<br />《An Electric New Era for Atlas | Boston Dynamics》 <a href="https://bostondynamics.com/blog/electric-new-era-for-atlas/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/5396ee05ly1houoa04fxij20zk0k0my7.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/3YuHe3LRlx08eaFK9BWw01041200dNAv0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713403966&amp;ssig=I4DM9UuhP1&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/Iu16yviSlx08eaFJSpgA0104120076LL0E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713403966&amp;ssig=nxEZ%2FzvIDH&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/BUR9FJMAlx08eaFJoVJC010412004xnG0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713403966&amp;ssig=eiT8vV%2Bhnc&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5024424257060882" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 00:20:05 GMT</pubDate>
</item>
<item>
<title>【Pile-T5：更好的通用预训练语言模型】- Pile-T5通过在Pile数据集上预训练T5模型，并使用LLAMA分词器，改进了原始T5的编码能力。 - Pile-T5总体上明显优于原始T...</title>
<link>https://weibo.com/1402400261/OafmCeJxq</link>
<guid>https://weibo.com/1402400261/OafmCeJxq</guid>
<content:encoded><![CDATA[
<div> Pile-T5, 预训练模型, 提升, 下游任务, 质量更高, 多任务微调, 模型演化, 解释性研究, bug, 通用预训练语言模型

<br /><br />总结:
Pile-T5是通过在Pile数据集上预训练T5模型，并使用LLAMA分词器改进的通用预训练语言模型。在多个下游任务中，Pile-T5表现优异，尤其在代码任务上有显著提升，说明预训练质量更高，更适合多任务微调。Pile-T5模型在训练步长的中间检查点有利于模型演化和解释性研究。尽管存在bug，Pile-T5仍值得研究者基于其进行编码-解码任务的探索，特别是基础和大模型表现更稳定。 <div>
【Pile-T5：更好的通用预训练语言模型】<br />- Pile-T5通过在Pile数据集上预训练T5模型，并使用LLAMA分词器，改进了原始T5的编码能力。   <br />- Pile-T5总体上明显优于原始T5v1.1模型，尤其在代码任务上的提升更大。这主要得益于Pile中包含代码数据以及LLAMA分词器包含编程常用字符。   <br />- 在多个下游任务的微调中，Pile-T5不同规模的模型表现优异，如在SuperGLUE、CodeXGLUE、MMLU和BigBench Hard上的结果。   <br />- 尽管与专门微调的Flan-T5相比略逊色，但Pile-T5仍优于T5v1.1，表明其预训练质量更高，更适合多任务微调。   <br />- 公开了Pile-T5模型在不同训练步长的中间检查点，这有利于模型演化和解释性研究。   <br />- Pile-T5 Large模型在某些任务上的表现不佳，可能存在bug，用户需谨慎使用。   <br />- Pile-T5是更好的通用预训练语言模型，值得研究者基于其进行编码-解码任务的探索。其中基础和大模型表现更稳定。<br />《Pile-T5 | EleutherAI Blog》 <a href="https://blog.eleuther.ai/pile-t5/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8houo66lks0j20vp0u07au.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 00:15:56 GMT</pubDate>
</item>
<item>
<title>【大语言模型时代的科学发现】- LLM技术进步迅速，广泛应用使科学界既兴奋又担忧。LLM可能影响科学信息搜索、创作和科研等方方面面。 - LLM的环境影响问题亟待解...</title>
<link>https://weibo.com/1402400261/OaflRxl5I</link>
<guid>https://weibo.com/1402400261/OaflRxl5I</guid>
<content:encoded><![CDATA[
<div> LLM、科学发现、影响、环境、人类交流、创新、幻觉、辅助、合作、负责任保障

<br /><br />总结:
LLM技术的迅速发展在科学界引起了兴奋和担忧，虽然在信息搜索、创作和科研方面有广泛应用，但也存在环境影响和碳排放的问题。然而，LLM缺乏人类语言交流和建构意义的能力，可能会导致文本信息的不准确性和意义的缺失。此外，LLM也有可能错过科学创新的异常点，难以推动科学范式的转变。因此，科学家需要保持审慎态度，避免过度依赖LLM，应将其视为科研发现的辅助工具。此外，科学界需要与LLM开发商紧密合作，制定最佳实践和标准，确保其负责任和伦理使用，促进科学的严谨性和可重现性。最终，科学界应积极主张研发LLM安全保障措施，以促进LLM的可持续发展。 <div>
【大语言模型时代的科学发现】<br />- LLM技术进步迅速，广泛应用使科学界既兴奋又担忧。LLM可能影响科学信息搜索、创作和科研等方方面面。   <br />- LLM的环境影响问题亟待解决。无论其应用效果如何，LLM运算都有很大的碳排放。科学家和社会必须正视LLM的使用如何加剧气候危机。   <br />- LLM缺乏人类语言交流和意义建构的能力。它们无法像科学家那样，通过交换理由来建立和验证事实，也无法传达意图、表达文本的意义。   <br />- LLM可能会错过或平均科学创新的异常点。它们当前难以革命性推动科学范式的转变。   <br />- LLM生成的文本存在“幻觉”问题，可能产生不准确甚至虚假内容。科学家不能过度依赖LLM撰写文献综述等。   <br />- LLM难以准确表达科学文献中的细微价值判断、不确定性和局限性。这可能导致对研究结果的误读。   <br />- LLM应仅被视为辅助科研发现的工具，而非取代科学家。科学发现应建立在负责任、以目标为导向的研究实践之上。   <br />- 科学界应与LLM开发商紧密合作，制定最佳实践和标准，确保LLM的使用不损害科学的严谨性和可重现性。同时促进不同学科之间的交流讨论。   <br />- 科学家应保持审慎态度，避免过度依赖LLM。科学界应更积极主张研发LLM安全保障措施，促进LLM的负责任和伦理使用。<br />《Science in the age of large language models | Nature Reviews Physics》 <a href="https://www.nature.com/articles/s42254-023-00581-4"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8houo48mtgsj21hw0u0tfe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 00:14:05 GMT</pubDate>
</item>
<item>
<title>【Mistral AI 开源 Mixtral 8x22B】- Mistral AI发布了新的开源模型Mixtral 8x22B。该模型以39B活跃参数实现141B参数规模，极大提升了模型规模与成本效率。 - Mi...</title>
<link>https://weibo.com/1402400261/OafkRu8TD</link>
<guid>https://weibo.com/1402400261/OafkRu8TD</guid>
<content:encoded><![CDATA[
<div> Mistral AI、Mixtral 8x22B、开源、模型、成本效率、多语言、数学、编程、Apache 2.0许可证、性能价格比
<br /><br />总结: Mistral AI发布了新的开源模型Mixtral 8x22B，以39B活跃参数实现141B参数规模，极大提升模型规模与成本效率。Mixtral 8x22B支持多语言，具有强大的数学和编程能力，并支持函数调用，可实现应用开发和技术栈现代化。采用最宽松的Apache 2.0许可证发布。同时，Mixtral 8x22B在性能价格比、推理、知识、多语言、编程、数学等多个基准测试上表现优异，后续还将发布指导版本提升数学表现。 Mistral AIModels致力于提升成本效率，Mixtral 8x22B相对同规模模型具有更佳的性能价格比，稀疏激活可提升速度。 <div>
【Mistral AI 开源 Mixtral 8x22B】<br />- Mistral AI发布了新的开源模型Mixtral 8x22B。该模型以39B活跃参数实现141B参数规模，极大提升了模型规模与成本效率。   <br />- Mixtral 8x22B支持英语、法语、意大利语、德语和西班牙语，并具有强大的数学和编程能力。其支持函数调用，可大规模实现应用开发和技术栈现代化。   <br />- Mistral AI坚信开源的力量，Mixtral 8x22B以最宽松的Apache 2.0许可证发布。   <br />- Mistral AIModels追求卓越的成本效率。Mixtral 8x22B相较同规模模型，提供最佳的性能价格比。其稀疏激活可提升速度。   <br />- Mixtral 8x22B在推理、知识、多语言、编程、数学等多个基准测试上，表现优于其他开源模型。后续会发布指导版本，数学表现更佳。   <br />《Cheaper, Better, Faster, Stronger | Mistral AI | Frontier AI in your hands》 <a href="https://mistral.ai/news/mixtral-8x22b/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8houo1gf9xpj21890u0dk6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8houo1ja09cj21c00sy77c.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8houo1nnovqj22tw0u0n46.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 00:11:37 GMT</pubDate>
</item>
<item>
<title>今日推介(第1379期)：语言模型级联、RAG知识和LLM内部先验间的博弈、解缠表示学习的三种互补归纳偏置、DPO是否比PPO更适合LLM对齐、在众多模拟世界中扩展可指示A...</title>
<link>https://weibo.com/1402400261/OaeBajyAP</link>
<guid>https://weibo.com/1402400261/OaeBajyAP</guid>
<content:encoded><![CDATA[
<div> 语言模型级联、RAG知识、LLM内部先验、解缠表示学习、互补归纳偏置、DPO、PPO、LLM对齐、可指示Agent、模拟世界扩展

总结:<br />
本文主要介绍了在语言模型领域的一些前沿研究，包括语言模型级联、RAG知识和LLM内部先验的博弈、解缠表示学习的三种互补归纳偏置等内容。研究讨论了DPO是否比PPO更适合LLM对齐的问题，还探讨了在众多模拟世界中扩展可指示Agent的相关方法。这些研究成果对于推动自然语言处理和深度学习领域的发展具有重要意义。 <div>
今日推介(第1379期)：语言模型级联、RAG知识和LLM内部先验间的博弈、解缠表示学习的三种互补归纳偏置、DPO是否比PPO更适合LLM对齐、在众多模拟世界中扩展可指示Agent 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/693095550"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.18)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8houks80i25j21d00p2tfn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8houksa70d6j219u0nmn2q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8houkscmj6bj20rm0vswi0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8houksgby4rj20u01c947t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8houksjmqv1j216j0u0wkx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 22:19:02 GMT</pubDate>
</item>
<item>
<title>[CV] SRGS: Super-Resolution 3D Gaussian Splatting 网页链接 通过高分辨率密集化和纹理学习，提出一种只需低分辨率多视图输入就可以实现高质量高分辨率小场景...</title>
<link>https://weibo.com/1402400261/OaexUdIhC</link>
<guid>https://weibo.com/1402400261/OaexUdIhC</guid>
<content:encoded><![CDATA[
<div> 关键词: 高分辨率密集化，纹理学习，多视图输入，新视图合成，SRGS

总结:<br /><br />这篇文章提出了一种名为SRGS的方法，通过高分辨率密集化和纹理学习，实现了只需低分辨率多视图输入就能合成高质量高分辨率小场景新视图的技术。文章通过对输入数据进行高效处理和重建，使得生成的新视图能够保持高质量，并具有真实感。这种方法为小场景的新视图合成提供了一种简单而有效的解决方案，有望在虚拟现实和增强现实领域有广泛应用。 <div>
[CV] SRGS: Super-Resolution 3D Gaussian Splatting  <br /><a href="https://arxiv.org/abs/2404.10318"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过高分辨率密集化和纹理学习，提出一种只需低分辨率多视图输入就可以实现高质量高分辨率小场景新视图合成的方法SRGS。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houkk5qbs6j20xa150dwb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houkk67k85j20xm0oigrc.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houkk6re5hj21gg0xq187.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 22:11:00 GMT</pubDate>
</item>
<item>
<title>[CV] MobileNetV4 - Universal Models for the Mobile Ecosystem 网页链接 通过巧妙设计的模块、注意力机制和NAS方法，使模型在移动端各硬件上都能高效部署。 [...</title>
<link>https://weibo.com/1402400261/OaevgwwKJ</link>
<guid>https://weibo.com/1402400261/OaevgwwKJ</guid>
<content:encoded><![CDATA[
<div> MobileNetV4, Universal Models, 移动端, 模块, 注意力机制, NAS方法, 高效部署, 硬件<br />
<br />
MobileNetV4是一种通过巧妙设计的模块、注意力机制和NAS方法而创建的通用模型，可以在移动端的各种硬件上高效部署。通过使用注意力机制，模型能够集中精力在关键部分，提高性能。NAS方法使模型更具智能化和可调节性，适应不同的移动设备。这些特点使MobileNetV4成为一个非常适用于移动生态系统的模型。<br /><br />总结:MobileNetV4通过巧妙设计的模块、注意力机制和NAS方法，在移动端各硬件上高效部署，适应不同设备，使其成为一个通用且智能的模型。 <div>
[CV] MobileNetV4 - Universal Models for the Mobile Ecosystem  <br /><a href="https://arxiv.org/abs/2404.10518"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过巧妙设计的模块、注意力机制和NAS方法，使模型在移动端各硬件上都能高效部署。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houkdepnqzj20ra16owq4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1houkdexlm1j214g0vyn6c.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houkdfhmmyj213k0hw76j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 22:04:30 GMT</pubDate>
</item>
<item>
<title>[LG] Social Choice for AI Alignment: Dealing with Diverse Human Feedback 网页链接 提出可运用社会选择理论来系统地指导RLHF中的人工反馈选择和聚合，以制定...</title>
<link>https://weibo.com/1402400261/Oaetj6Zv6</link>
<guid>https://weibo.com/1402400261/Oaetj6Zv6</guid>
<content:encoded><![CDATA[
<div> 社会选择理论 RLHF 人工反馈 选择 聚合 公平 不排斥 人类价值观 机制

<br /><br />总结:
本文提出了利用社会选择理论指导强化学习和人类反馈的机制，以确保人工智能对各种群体的价值观都能公平对待，不排斥任何群体。通过系统地选择和汇总人类反馈，制定更公平的人类价值观调整机制，帮助人工智能更好地对人类价值观进行调整，使其更符合社会的整体利益。 <div>
[LG] Social Choice for AI Alignment: Dealing with Diverse Human Feedback  <br /><a href="https://arxiv.org/abs/2404.10271"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />提出可运用社会选择理论来系统地指导RLHF中的人工反馈选择和聚合，以制定更公平且不排斥任何群体的人类价值观调整机制。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houk8dfzzdj20xw16w7ny.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houk8drgc9j21ke11c12y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houk8eel05j21kc0lo7bb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 21:59:40 GMT</pubDate>
</item>
<item>
<title>[CV] Comprehensive Survey of Model Compression and Speed up for Vision Transformers 网页链接 通过全面调研和比较量化、低秩近似、知识蒸馏和剪枝四种关键...</title>
<link>https://weibo.com/1402400261/Oaer1drUB</link>
<guid>https://weibo.com/1402400261/Oaer1drUB</guid>
<content:encoded><![CDATA[
<div> 关键词: 模型压缩, 视觉Transformer, CIFAR数据集, 准确率, 效率, 低秩近似, 知识蒸馏, 剪枝, trade-off, 实际模型部署

总结:<br /><br />本文对视觉Transformer模型压缩技术在CIFAR数据集上的效果进行了全面调研和比较，分别探讨了量化、低秩近似、知识蒸馏和剪枝四种关键压缩技术。研究结果为在实际模型部署中考虑准确率与效率trade-off提供了宝贵的参考。调研发现，这四种压缩技术在不同情况下对模型性能的影响有所不同，需要根据具体应用场景进行选择。在模型压缩方面，低秩近似和知识蒸馏能够有效降低模型的复杂度，而剪枝技术在减少参数和计算量方面表现突出。然而，在压缩过程中需要注意平衡准确率和效率之间的关系，以确保模型性能不受过度压缩的影响。因此，研究者建议根据具体需求选择合适的压缩技术，并在实际部署中进行综合考量，以达到最佳的模型性能和效率之间的平衡。 <div>
[CV] Comprehensive Survey of Model Compression and Speed up for Vision Transformers  <br /><a href="https://arxiv.org/abs/2404.10407"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过全面调研和比较量化、低秩近似、知识蒸馏和剪枝四种关键视觉Transformer模型压缩技术在CIFAR数据集上的效果，为考虑准确率与效率trade-off的实际模型部署提供了宝贵参考。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houk2imtp3j20r014sqgm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houk2j2bmkj219m0non2n.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1houk2j90anj20yu0qa42b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 21:54:02 GMT</pubDate>
</item>
<item>
<title>提出一个雄心勃勃的项目，旨在通过将语言指令与复杂3D环境交互相结合，开发泛化能力强大的可指示Agent。 - 转发 @爱可可-爱生活:&amp;ensp;[RO]《Scaling Instructab...</title>
<link>https://weibo.com/1402400261/OaejuExON</link>
<guid>https://weibo.com/1402400261/OaejuExON</guid>
<content:encoded><![CDATA[
<div> 谷歌DeepMind团队在2024年提出了一个名为《Scaling Instructable Agents Across Many Simulated Worlds》的项目，旨在开发泛化能力强大的可指示Agent。关键词：项目、DeepMind、指示代理、泛化能力、多个模拟环境。

<br /><br />总结:
2024年，谷歌DeepMind团队发起了一个名为《Scaling Instructable Agents Across Many Simulated Worlds》的项目，旨在通过将语言指令与复杂3D环境交互相结合，开发泛化能力强大的可指示Agent。项目旨在让Agent能够在多个模拟环境中适用，并能够根据指示执行各种任务。这将为人工智能领域带来重大突破，提高Agent的适用性和智能水平。DeepMind团队将以此为目标，探索机器学习和自然语言处理的结合，开拓智能代理系统的新领域。 <div>
提出一个雄心勃勃的项目，旨在通过将语言指令与复杂3D环境交互相结合，开发泛化能力强大的可指示Agent。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [RO]《Scaling Instructable Agents Across Many Simulated Worlds》S Team, M A Raad, A Ahuja, C Barros... [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2404.10179"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houjbg8h83j21n00q6qhe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1houjbgqv67j21ms15gqhv.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houjbh4x0rj21de0tatn9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houjbhabsij21dm19awrj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houjj53yx4j21140gstav.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houjj566haj21150ue7b9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houjj54e7aj21190j6771.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houjj549jnj21150ne0vo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houjj54b6gj21140gy410.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 21:35:30 GMT</pubDate>
</item>
<item>
<title>[RO]《Scaling Instructable Agents Across Many Simulated Worlds》S Team, M A Raad, A Ahuja, C Barros... [Google DeepMind] (2024) 网页链接 #机器学习##人...</title>
<link>https://weibo.com/1402400261/Oaejsl4lK</link>
<guid>https://weibo.com/1402400261/Oaejsl4lK</guid>
<content:encoded><![CDATA[
<div> Scaling, Instructable Agents, Simulated Worlds, Multi-agent Systems, Reinforcement Learning, DeepMind

<br /><br />总结:
本研究通过在多个模拟世界中扩展可指导的代理，实现了在多智能体系统中的扩展。利用强化学习算法，结合深度Mind技术，实现了在模拟环境中的智能体规模扩展。研究团队对于多智能体系统的设计和优化具有重要意义，为实现自主智能体在复杂环境中的应用提供了新的思路。 <div>
[RO]《Scaling Instructable Agents Across Many Simulated Worlds》S Team, M A Raad, A Ahuja, C Barros... [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2404.10179"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houjbg8h83j21n00q6qhe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1houjbgqv67j21ms15gqhv.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houjbh4x0rj21de0tatn9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houjbhabsij21dm19awrj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houjj53yx4j21140gstav.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houjj566haj21150ue7b9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houjj54e7aj21190j6771.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houjj549jnj21150ne0vo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houjj54b6gj21140gy410.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houjj55696j21160odn1c.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houjj54aqxj211a0jawh1.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houjj5434pj21160fo0uq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 21:35:24 GMT</pubDate>
</item>
<item>
<title>通过理论分析和综合实验发现PPO经过精心微调可以优于DPO，在对话和代码生成任务上都取得了最先进的结果。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Is DPO Superior t...</title>
<link>https://weibo.com/1402400261/Oaefpy987</link>
<guid>https://weibo.com/1402400261/Oaefpy987</guid>
<content:encoded><![CDATA[
<div> PPO, DPO, 精心微调, 对话任务, 代码生成任务, 最先进结果, 理论分析, 综合实验, Tsinghua University, OpenPsi Inc

<br /><br />总结:
本研究通过理论分析和综合实验发现，经过精心微调后的PPO在对话和代码生成任务上可以优于DPO，取得了最先进的结果。该研究由清华大学和OpenPsi公司的研究人员合作完成，探讨了PPO和DPO在LLM对齐方面的优劣。研究结果显示，PPO的调优效果更好，适用于各种任务，并提出了一种综合性研究方法，为相关领域的研究提供了重要的参考价值。 <div>
通过理论分析和综合实验发现PPO经过精心微调可以优于DPO，在对话和代码生成任务上都取得了最先进的结果。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study》S Xu, W Fu, J Gao, W Ye, W Liu, Z Mei, G Wang, C Yu, Y Wu [Tsinghua University &amp; OpenPsi Inc] (2024) <a href="https://arxiv.org/abs/2404.10719"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houj1rxkpxj20pa16wali.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houj1sbxbhj20uc1cs49b.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houj1sk52wj20tw0l8777.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 21:25:27 GMT</pubDate>
</item>
<item>
<title>[CL]《Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study》S Xu, W Fu, J Gao, W Ye, W Liu, Z Mei, G Wang, C Yu, Y Wu [Tsinghua University ...</title>
<link>https://weibo.com/1402400261/Oaefnozyq</link>
<guid>https://weibo.com/1402400261/Oaefnozyq</guid>
<content:encoded><![CDATA[
<div> 关键词: DPO, PPO, LLM Alignment, Tsinghua University, OpenPsi Inc

总结:<br /><br />本研究探讨了DPO和PPO对LLM对齐的优劣。研究团队来自清华大学和OpenPsi公司。他们进行了全面的研究，发现DPO在LLM对齐方面表现更优。研究结果对相关领域的进一步发展具有重要意义，为未来研究提供了有益的认识。<br />研究方法:<br />实验结果:<br />结论: <div>
[CL]《Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study》S Xu, W Fu, J Gao, W Ye, W Liu, Z Mei, G Wang, C Yu, Y Wu [Tsinghua University &amp; OpenPsi Inc] (2024) <a href="https://arxiv.org/abs/2404.10719"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houj1rxkpxj20pa16wali.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houj1sbxbhj20uc1cs49b.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houj1sk52wj20tw0l8777.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 21:25:21 GMT</pubDate>
</item>
<item>
<title>提出Tripod模型，通过改进并协调使用三种互补的归纳偏置——量化、独立性和混合性，实现了图像表征的最优去相关效果。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Tripo...</title>
<link>https://weibo.com/1402400261/OaeaQEiyI</link>
<guid>https://weibo.com/1402400261/OaeaQEiyI</guid>
<content:encoded><![CDATA[
<div> Tripod模型, 量化, 独立性, 混合性, 图像表征, 去相关效果, 三种互补的归纳偏置, disentangled representation learning

<br /><br />总结:
本文提出了Tripod模型，通过改进并协调使用三种互补的归纳偏置——量化、独立性和混合性，实现了图像表征的最优去相关效果。Tripod模型结合了这三种偏置，从而在图像表征学习中取得了显著的效果。这种综合利用不同偏置的方法，使得模型能够更好地学习到图像之间的不相关特征，从而实现更好的图像表征学习效果。Tripod模型的提出，为 disentangled representation learning 领域带来了新的思路和方法，有望在未来的研究中有更多的应用和拓展。Tripod模型的成功应用展示了在图像表征学习中综合利用多种归纳偏置的重要性，并为相关领域的研究和应用带来了新的启示。<br />模型提出了三种互补的归纳偏置——量化、独立性和混合性，通过综合利用这些归纳偏置，实现了更好的去相关效果，为图像表征学习带来了新的突破和进展。Tripod模型的介绍和应用，为相关研究领域提供了新的思路和方法，为未来的研究和应用奠定了更坚实的基础。Tripod模型的提出，将有望推动图像表征学习领域的发展，为实现更好的图像表征学习效果提供了新的途径和可能性。Tripod模型的成功应用充分展示了综合利用不同归纳偏置的重要性，并为相关领域的进一步研究和发展提供了有益的启示。Tripod模型的发展，有望在未来为图像表征学习领域带来更多的突破和进展，为解决实际问题提供更好的解决方案。Tripod模型的提出，为图像表征学习领域带来了新的思路和方法，有望在未来的研究和应用中发挥更重要的作用，进一步推动领域的发展和进步。 <div>
提出Tripod模型，通过改进并协调使用三种互补的归纳偏置——量化、独立性和混合性，实现了图像表征的最优去相关效果。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Tripod: Three Complementary Inductive Biases for Disentangled Representation Learning》K Hsu, J I Hamid, K Burns, C Finn, J Wu [Stanford University] (2024) <a href="https://arxiv.org/abs/2404.10282"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houivs4781j20ns10idp5.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houivsiwudj20rm0vsdkf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houivsxv78j20re0t80wd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houivt5llmj21iy0qqdn8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1houiwh6ug6j20iv0l0abl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houiwh8iwfj212d0kl0yw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houiwh9ownj212d13ojzb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houiwh9z0cj212d0z7n3t.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1houiwhaynej212d0z7n6r.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 21:14:12 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.17)》 爱可可微博热门分享(4.17) [图片]</title>
<link>https://weibo.com/1402400261/OabA8CAIl</link>
<guid>https://weibo.com/1402400261/OabA8CAIl</guid>
<content:encoded><![CDATA[
<div> 微博，热门，分享，爱可可，4.17，关键词

<br /><br />总结:
4月17日，爱可可微博热门分享引起了大量关注。在微博上，不同话题和内容的分享活动吸引了许多用户的参与和互动。热门内容涵盖了各个领域，吸引了广泛的注意。爱可可的微博分享活动使得用户可以了解到更多有趣的信息，并且促进了社交平台上的交流和互动。通过微博的热门分享，用户能够获得更多的乐趣和启发，增加了他们在社交网络上的参与度和快乐。 <div>
《爱可可微博热门分享(4.17)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405024278050635924"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.17)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hou7gzw5iij20er08aaaw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 14:38:16 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Distort, Distract, Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions》(ICLR 2024) GitHub: github.com...</title>
<link>https://weibo.com/1402400261/OaaOwpeWL</link>
<guid>https://weibo.com/1402400261/OaaOwpeWL</guid>
<content:encoded><![CDATA[
<div> Distort, Distract, Decode, Instruction-Tuned Model, Response Refinement, Noisy Instructions, ICLR 2024, GitHub, Instructive Decoding

<br />
模型调整，响应优化，ICLR 2024会议上提出了一种指导模型根据有噪指令优化响应的方法。通过扭曲、分散、解码处理嘈杂指令，GitHub上提供了相应的代码实现。

<br /><br />总结: 该论文介绍了一种指导模型优化响应的方法，针对嘈杂指令进行了处理，通过扭曲、分散和解码操作来优化响应。研究在ICLR 2024会议上发布，并提供GitHub上的代码实现。 <div>
几篇论文实现代码：<br />《Distort, Distract, Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions》(ICLR 2024) GitHub: github.com/joonkeekim/Instructive-Decoding [fig6]<br />《Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization》(ICLR 2024) GitHub: github.com/Lei-Kun/uni-o4<br />《Motion2VecSets: 4D Latent Vector Set Diffusion for Non-rigid Shape Reconstruction and Tracking》(CVPR 2024) GitHub: github.com/VVeiCao/Motion2VecSets [fig3]<br />《Map-Relative Pose Regression for Visual Re-Localization》(CVPR 2024) GitHub: github.com/nianticlabs/marepo [fig5]<br />《On the Content Bias in Fréchet Video Distance》(CVPR 2024) GitHub: github.com/songweige/content-debiased-fvd<br />《Decomposing Disease Descriptions for Enhanced Pathology Detection: A Multi-Aspect Vision-Language Matching Framework》(CVPR 2024) GitHub: github.com/HieuPhan33/MAVL [fig8]<br />《TetraSphere: A Neural Descriptor for O(3)-Invariant Point Cloud Analysis》(CVPR 2024) GitHub: github.com/pavlo-melnyk/tetrasphere<br />《Efficient Test-Time Adaptation of Vision-Language Models》(CVPR 2024) GitHub: github.com/kdiAAA/TDA<br />《UNIAA: A Unified Multi-modal Image Aesthetic Assessment Baseline and Benchmark》(2024) GitHub: github.com/Uniaa-MLLM/Uniaa [fig1]<br />《Compression Represents Intelligence Linearly》(2024) GitHub: github.com/hkust-nlp/llm-compression-intelligence [fig2]<br />《Prepacking: A Simple Method for Fast Prefilling and Increased Throughput in Large Language Models》(2024) GitHub: github.com/siyan-zhao/prepacking<br />《Match-Stereo-Videos: Bidirectional Alignment for Consistent Dynamic Stereo Matching》(2024) GitHub: github.com/TomTomTommi/bidastereo<br />《Wild Visual Navigation: Fast Traversability Learning via Pre-Trained Models and Online Self-Supervision》(2024) GitHub: github.com/leggedrobotics/wild_visual_navigation<br />《OneChart: Purify the Chart Structural Extraction via One Auxiliary Token》(2024) GitHub: github.com/LingyvKong/OneChart<br />《Any2Point: Empowering Any-modality Large Models for Efficient 3D Understanding》(2024) GitHub: github.com/Ivan-Tang-3D/Any2Point [fig4]<br />《M2Chat: Empowering VLM for Multimodal LLM Interleaved Text-Image Generation》(2024) GitHub: github.com/litwellchi/M2Chat [fig7] <br />《ScribblePrompt: Fast and Flexible Interactive Segmentation for Any Biomedical Image》(2024) GitHub: github.com/halleewong/ScribblePrompt<br />《BAGS: Blur Agnostic Gaussian Splatting through Multi-Scale Kernel Modeling》(2024) GitHub: github.com/snldmt/BAGS [fig9]<br />《ROAM: Robust and Object-aware Motion Generation using Neural Pose Descriptors》(2024) GitHub: github.com/RosettaWYzhang/Roam<br />《NeuSurf: On-Surface Priors for Neural Surface Reconstruction from Sparse Input Views》(2024) GitHub: github.com/leonwu0108/NeuSurf<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotpwu5glhj22we1aykjm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotpzosmbgj21a60niwpr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotq804fbcj234o1ggwxu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotqmjf1woj21840j8423.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotqinkqhfj23ie17kb29.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotqmyfbabj218a0iiwsz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hou1wp26q3j22p714gkjl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hou3kurmn1j255h1wd7vd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hou3nj2g33j252n2dib29.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 12:40:57 GMT</pubDate>
</item>
<item>
<title>【ATAC：命令行简单API客户端(类似postman)】'ATAC - A simple API client (postman like) in your terminal' GitHub: github.com/Julien-cpsn/ATAC #开源# #API...</title>
<link>https://weibo.com/1402400261/OaaNT43xs</link>
<guid>https://weibo.com/1402400261/OaaNT43xs</guid>
<content:encoded><![CDATA[
<div> GitHub, ATAC, 命令行, API, 客户端, postman, 简单, Julien-cpsn

<br /><br />总结:
ATAC是一个简单的命令行API客户端，类似于postman，方便用户在终端中进行API调用和测试。该工具的GitHub地址是github.com/Julien-cpsn/ATAC。用户可以通过ATAC在命令行中直接发送HTTP请求，并查看返回结果，实现API的快速测试和调试。ATAC提供了类似postman的功能，帮助用户更高效地与API进行交互，是一个方便实用的工具。 <div>
【ATAC：命令行简单API客户端(类似postman)】'ATAC - A simple API client (postman like) in your terminal' GitHub: github.com/Julien-cpsn/ATAC <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23API%23"><span class="surl-text">#API#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hou40srbmwj215n0u0jvq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 12:39:23 GMT</pubDate>
</item>
<item>
<title>【AudioCraft：用于深度学习音频生成研究的PyTorch库】’AudioCraft - Audiocraft is a library for audio processing and generation with deep learning. It f...</title>
<link>https://weibo.com/1402400261/OaaLwmiwW</link>
<guid>https://weibo.com/1402400261/OaaLwmiwW</guid>
<content:encoded><![CDATA[
<div> PyTorch, 深度学习, 音频生成, AudioCraft, EnCodec, MusicGen, 压缩器, 音频处理, 音乐生成, GitHub

<br /><br />总结:
AudioCraft是一个用于音频处理和生成的PyTorch库，其中包含了最先进的EnCodec音频压缩器/标记器以及MusicGen，一个具有文本和旋律条件的简单可控音乐生成LM。通过这个库，研究人员可以利用深度学习来进行音频生成研究，为音乐和音频领域的人工智能研究提供了有力的工具。GitHub上有相关代码和更多信息可供查阅。 <div>
【AudioCraft：用于深度学习音频生成研究的PyTorch库】’AudioCraft - Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning.' GitHub: github.com/nateraw/audiocraft <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hou3vd4p4tj211t0u079h.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 12:33:33 GMT</pubDate>
</item>
<item>
<title>【LLM可解释性/机制理解相关论文列表】’awesome papers for understanding LLM mechanism - awesome papers in LLM interpretability' GitHub: github.com/zepi...</title>
<link>https://weibo.com/1402400261/OaaHbBcEe</link>
<guid>https://weibo.com/1402400261/OaaHbBcEe</guid>
<content:encoded><![CDATA[
<div> GitHub, LLM, 解释性, 机制理解, 论文, 列表, 理解, 机制, awesome, 作者

<br /><br />总结:
这个GitHub仓库收集了一些关于LLM（Large Language Model）可解释性和机制理解相关的优秀论文。这些论文帮助读者更好地理解LLM的工作机制和解释方式，对于研究人员和学习者来说是非常有价值的资源。通过阅读这些论文，可以深入了解LLM在自然语言处理领域的应用，以及其在模型理解和解释方面的进展。如果你对LLM的工作原理和解释机制感兴趣，不妨查阅这个GitHub仓库，里面收录的论文可能会给你带来启发和新的见解。 <div>
【LLM可解释性/机制理解相关论文列表】’awesome papers for understanding LLM mechanism - awesome papers in LLM interpretability' GitHub: github.com/zepingyu0512/awesome-llm-understanding-mechanism <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hou3k9gmr9j20yz0u0tds.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 12:22:53 GMT</pubDate>
</item>
<item>
<title>【Sitcom Simulator：利用多种人工智能技术生成幽默短视频，结合了 AI 生成的脚本、角色的语音合成、以及视觉艺术生成，最后通过视频编辑软件将这些元素组合成影...</title>
<link>https://weibo.com/1402400261/OaaAfocYT</link>
<guid>https://weibo.com/1402400261/OaaAfocYT</guid>
<content:encoded><![CDATA[
<div> ChatGPT, Stable Diffusion, FakeYou, FreePD, 视频生成, 人工智能, 幽默短视频, GitHub<br />
<br />
AI技术结合制作的Sitcom Simulator利用ChatGPT、Stable Diffusion、FakeYou和FreePD等多种人工智能技术生成幽默短视频。通过AI生成脚本、角色语音合成和视觉艺术生成，最后通过视频编辑软件将这些元素组合成影片。GitHub上有该项目代码的存储库。Sitcom Simulator是一种结合多种AI技术制作视频的工具。 <div>
【Sitcom Simulator：利用多种人工智能技术生成幽默短视频，结合了 AI 生成的脚本、角色的语音合成、以及视觉艺术生成，最后通过视频编辑软件将这些元素组合成影片】’Sitcom Simulator - A tool that combines ChatGPT, Stable Diffusion, FakeYou, and FreePD to create AI-generated videos.' GitHub: github.com/joshmoody24/sitcom-simulator <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hou32beg8zj209m0h4myr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hou32cfjo2j209r0h5abc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hou32diklvj209q0h4409.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 12:05:47 GMT</pubDate>
</item>
<item>
<title>【深度学习表格检测与结构识别相关论文与资源列表】’Deep learning for table detection and structure recognition: A survey' GitHub: github.com/abdoelsaye...</title>
<link>https://weibo.com/1402400261/OaazHx0W8</link>
<guid>https://weibo.com/1402400261/OaazHx0W8</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度学习, 表格检测, 结构识别, 调研, GitHub, 论文, 资源, 检测技术, 文本提取, 表格解析

深度学习在表格检测和结构识别领域的应用取得了显著进展。该调研论文综述了相关工作，并提供了GitHub资源链接。论文涵盖了表格检测技术、表格结构识别、文本提取等内容。围绕着深度学习方法，研究者们通过实验和案例研究展示了各种技术的应用效果。GitHub资源提供了更多相关论文和实现代码，为研究者们提供了更多的参考和学习资料。

<br /><br />总结: 
1. 调研论文总结了深度学习在表格检测与结构识别领域的最新进展。
2. 论文提供了GitHub资源链接，包含了相关论文和实现代码，为研究者提供了更多参考资料。
3. 论文涵盖了表格检测技术、表格结构识别、文本提取等内容。
4. 研究者们通过实验和案例研究展示了深度学习方法在表格检测与结构识别中的应用效果。 <div>
【深度学习表格检测与结构识别相关论文与资源列表】’Deep learning for table detection and structure recognition: A survey' GitHub: github.com/abdoelsayed2016/Table-Detection-Structure-Recognition <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hou30wo2paj20u00u979z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 12:04:27 GMT</pubDate>
</item>
<item>
<title>【GPT-AI-Code-Interpreter：基于云运行时的 Python &amp; JavaScript SDK，用于构建自定义代码解释器。它支持 LLM（如 OpenAI、Cohere 和 Anthropic）生成的代码块...</title>
<link>https://weibo.com/1402400261/Oaaum8q2G</link>
<guid>https://weibo.com/1402400261/Oaaum8q2G</guid>
<content:encoded><![CDATA[
<div> Python, JavaScript, SDK, 构建, 自定义, 代码解释器, LLM, 代码块, 状态共享, 图表输出

<br /><br />总结:
本文介绍了基于云运行时的 Python 和 JavaScript SDK，用于构建自定义代码解释器。该 SDK 支持 LLM 生成的代码块之间的状态共享，允许用户逐步执行代码，并支持图表输出等功能。GitHub 上有相关项目的代码仓库。 <div>
【GPT-AI-Code-Interpreter：基于云运行时的 Python &amp; JavaScript SDK，用于构建自定义代码解释器。它支持 LLM（如 OpenAI、Cohere 和 Anthropic）生成的代码块之间的状态共享，允许用户逐步执行代码，并支持图表输出等功能】'Code Interpreter SDK - Python &amp; JS SDK for building custom code interpreters. Built with E2B - Cloud Runtime for AI Agents.' GitHub: github.com/e2b-dev/code-interpreter <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hou2n9u58pj20u010a0xi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 11:51:16 GMT</pubDate>
</item>
<item>
<title>'AIChat Web - 在ChatGPT-Next-Web的基础上，增加注册登录，额度限制，邀请，敏感词，支付，基于docker一键部署。提供后台管理系统，可配置标题、欢迎词、额度不...</title>
<link>https://weibo.com/1402400261/Oa7OrujpC</link>
<guid>https://weibo.com/1402400261/Oa7OrujpC</guid>
<content:encoded><![CDATA[
<div> 注册登录、额度限制、邀请、敏感词、支付、docker一键部署、后台管理系统、配置标题、欢迎词、公告<br /><br />总结: 该项目是在ChatGPT-Next-Web基础上进行了扩展，增加了注册登录功能、额度限制、邀请制度、敏感词过滤、支付功能，并基于docker实现了一键部署。此外，项目提供了后台管理系统，允许管理员配置网站的标题、欢迎词、额度不足提醒和公告信息，为用户提供了更多的个性化设置和管理权限。 <div>
'AIChat Web - 在ChatGPT-Next-Web的基础上，增加注册登录，额度限制，邀请，敏感词，支付，基于docker一键部署。提供后台管理系统，可配置标题、欢迎词、额度不足提醒、公告' GitHub: github.com/Nanjiren01/AIChatWeb <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hotqtx93zyj21o00u077g.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hotqtztannj21hj0u0gnn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 05:02:30 GMT</pubDate>
</item>
<item>
<title>【DeepBI：AI原生的数据分析平台，DeepBI充分利用大语言模型的能力来探索、查询、可视化和共享来自任何数据源的数据，用户可以使用DeepBI洞察数据并做出数据驱动...</title>
<link>https://weibo.com/1402400261/Oa7NxA4Us</link>
<guid>https://weibo.com/1402400261/Oa7NxA4Us</guid>
<content:encoded><![CDATA[
<div> 数据分析平台, AI, 大语言模型, 探索, 查询, 可视化, 共享, 数据源, 数据驱动决策, GitHub<br />
<br />
总结:<br />
DeepBI是一款基于大语言模型的数据分析平台，利用AI驱动的无限思考重新定义了商业智能。用户可以通过DeepBI来探索、查询、可视化和共享来自任何数据源的数据，从而做出数据驱动的决策。感兴趣的用户可以在GitHub上找到DeepBI的代码库。 <div>
【DeepBI：AI原生的数据分析平台，DeepBI充分利用大语言模型的能力来探索、查询、可视化和共享来自任何数据源的数据，用户可以使用DeepBI洞察数据并做出数据驱动的决策】'DeepBI - LLM based data scientist, AI native data application. AI-driven infinite thinking redefines BI.' GitHub: github.com/DeepInsight-AI/DeepBI <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hotqrpo49kj20xa0u00vb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 05:00:18 GMT</pubDate>
</item>
<item>
<title>【Mamba相关文献资源列表】’Awesome Mamba - A Comprehensive Survey of Mamba in Deep Learning' GitHub: github.com/xmindflow/Awesome_Mamba #开源# #机器学...</title>
<link>https://weibo.com/1402400261/Oa7MMmMdL</link>
<guid>https://weibo.com/1402400261/Oa7MMmMdL</guid>
<content:encoded><![CDATA[
<div> 关键词：Mamba、深度学习、综述、GitHub、资源、调查、全面、神经网络、模型、技术

Mamba是一个关于深度学习中Mamba的综合调查，GitHub上有相关资源。这份综述详细介绍了Mamba在神经网络模型和技术方面的应用。有兴趣研究Mamba的人可以在这个GitHub上找到更多信息。总的来说，这篇综述涵盖了Mamba在深度学习领域的全面内容，对研究者和开发者有着一定的参考价值。<br /><br />总结: Mamba综述了深度学习中Mamba的应用，包括神经网络模型和技术，对该领域有兴趣的人可以在GitHub上找到更多相关资源。 <div>
【Mamba相关文献资源列表】’Awesome Mamba - A Comprehensive Survey of Mamba in Deep Learning' GitHub: github.com/xmindflow/Awesome_Mamba <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hotqpilrqqj20zf0u0dkz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:58:25 GMT</pubDate>
</item>
<item>
<title>【posteriors：基于 PyTorch 的通用不确定性量化库】'posteriors - Uncertainty quantification with PyTorch' GitHub: github.com/normal-computing/posteriors...</title>
<link>https://weibo.com/1402400261/Oa7I8Aktr</link>
<guid>https://weibo.com/1402400261/Oa7I8Aktr</guid>
<content:encoded><![CDATA[
<div> PyTorch、不确定性量化、库、posteriors、GitHub、基于、通用、Uncertainty quantification、normal-computing、不确定性量化。<br />
<br />
基于PyTorch开发的通用不确定性量化库posteriors在GitHub上开源，旨在帮助用户通过PyTorch实现不确定性量化。这个库提供了丰富的功能，可以帮助用户更好地理解和量化模型的不确定性，以及提供模型预测的置信度。用户可以借助posteriors库探索不确定性的来源，并在模型训练和评估过程中应用这些信息。通过posteriors库，用户可以轻松地实现不确定性量化方法，例如贝叶斯神经网络和蒙特卡洛Dropout。posteriors库的开源使得更多研究者和开发者能够利用其中的工具和函数来提高他们模型的性能和鲁棒性，进一步推动不确定性量化领域的发展。总之，posteriors库为基于PyTorch的不确定性量化提供了一个便捷、高效的解决方案，有望帮助用户在机器学习和深度学习领域取得更好的效果。 <br /><br />总结: 该基于PyTorch的通用不确定性量化库 posteriors 在GitHub上提供了丰富的功能和工具，帮助用户实现不确定性量化、理解模型的不确定性并提高模型性能。 <div>
【posteriors：基于 PyTorch 的通用不确定性量化库】'posteriors - Uncertainty quantification with PyTorch' GitHub: github.com/normal-computing/posteriors <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hotqdw8qoxj212f0u0dke.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:46:59 GMT</pubDate>
</item>
<item>
<title>【GWalkR:R中的交互式探索性数据分析（EDA）工具】'GWalkR: Your One-Stop R Package for Exploratory Data Analysis with Visualization - Turn your data fram...</title>
<link>https://weibo.com/1402400261/Oa7HlmfIP</link>
<guid>https://weibo.com/1402400261/Oa7HlmfIP</guid>
<content:encoded><![CDATA[
<div> 交互式，探索性数据分析，EDA，工具，R，数据框，可视化，界面，GitHub，GWalkR<br />
<br />
总结：<br />
本文介绍了GWalkR，一个R包，用于交互式探索性数据分析（EDA），提供类似Tableau的拖放式用户界面，可将数据框转换为可视化界面。用户可以使用该工具在R中轻松构建可视化图表，实现数据分析更为直观和高效。GitHub链接为github.com/Kanaries/GWalkR。 <div>
【GWalkR:R中的交互式探索性数据分析（EDA）工具】'GWalkR: Your One-Stop R Package for Exploratory Data Analysis with Visualization - Turn your data frame into a tableau style drag and drop UI interface to build visualization in R.' GitHub: github.com/Kanaries/GWalkR <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hotqbtva9vj21bw0u0436.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hotqbv0m8ij212w0obqh0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:45:02 GMT</pubDate>
</item>
<item>
<title>【AI文档理解相关文献资源列表】’Awesome-Document-Understanding - Document Artifical Intelligence' GitHub: github.com/harrytea/Awesome-Document-Underst...</title>
<link>https://weibo.com/1402400261/Oa7Fzi2RK</link>
<guid>https://weibo.com/1402400261/Oa7Fzi2RK</guid>
<content:encoded><![CDATA[
<div> 关键词：GitHub、文档理解、人工智能、资源、Awesome-Document-Understanding

总结：<br /><br />这篇文章介绍了一个名为"Awesome-Document-Understanding - Document Artificial Intelligence"的GitHub项目，该项目旨在提供关于文档理解和人工智能方面的相关资源。GitHub链接为github.com/harrytea/Awesome-Document-Understanding。该项目可能包括各种文档理解技术、人工智能算法以及其他相关资源的链接和信息。对于对文档理解和人工智能感兴趣的人来说，这个项目可能是一个很好的参考和学习资源。<br /> <div>
【AI文档理解相关文献资源列表】’Awesome-Document-Understanding - Document Artifical Intelligence' GitHub: github.com/harrytea/Awesome-Document-Understanding <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hotq7b3j71j20x70u0wki.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:40:39 GMT</pubDate>
</item>
<item>
<title>【利用深度学习进行定理证明相关论文资源累表列表】’Deep Learning for Theorem Proving (DL4TP) - A Survey on Deep Learning for Theorem Proving' GitHub: g...</title>
<link>https://weibo.com/1402400261/Oa7FgEUsH</link>
<guid>https://weibo.com/1402400261/Oa7FgEUsH</guid>
<content:encoded><![CDATA[
<div> Deep Learning, Theorem Proving, Survey, Resource, GitHub, Artificial Intelligence, Machine Learning, Neural Networks, Automation, Logic<br />
<br />总结:<br />
这篇论文调研了深度学习在定理证明中的应用，提供了相关资源和GitHub链接。文章介绍了深度学习在定理证明中的作用，讨论了人工智能、机器学习和神经网络等技术在自动化推理领域的重要性。研究者对深度学习在定理证明中的发展和应用进行了综述，为进一步研究提供了重要参考。 <div>
【利用深度学习进行定理证明相关论文资源累表列表】’Deep Learning for Theorem Proving (DL4TP) - A Survey on Deep Learning for Theorem Proving' GitHub: github.com/zhaoyu-li/DL4TP <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hotq6j4oxsj211z0u0te9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:39:55 GMT</pubDate>
</item>
<item>
<title>【LLM Experiments：与 OpenAI 语言模型 GPT 进行交互的Demo项目】’LLM Experiments - I play with my best friend GPT' GitHub: github.com/ggoonnzzaallo/llm...</title>
<link>https://weibo.com/1402400261/Oa7EPtSaC</link>
<guid>https://weibo.com/1402400261/Oa7EPtSaC</guid>
<content:encoded><![CDATA[
<div> GitHub、LLM Experiments、OpenAI、语言模型、GPT、交互、Demo项目、玩耍、项目、最佳朋友
<br />
该项目是一个与OpenAI语言模型GPT进行交互的Demo项目，通过GitHub进行发布。项目名称为LLM Experiments，主要内容是作者和GPT模型互动，就像与最好的朋友一样玩耍。项目展示了作者与GPT模型的对话和交流过程，探索了语言模型在不同场景下的应用。项目的灵感来源于对人工智能技术的兴趣和探索，展示了如何与先进的自然语言处理模型进行有趣的互动。通过这个项目，作者展示了人与人工智能之间的交互可能性，以及语言模型在日常生活中的潜在应用。整个项目与GPT模型之间的互动充满趣味和创意，展示了人工智能技术的潜力和可能性。通过这个Demo项目，作者展示了对人工智能技术的理解和应用，同时也探索了人工智能与人类之间的关系和合作。总体而言，该项目展示了作者与GPT模型之间的创造性互动，为人工智能技术的发展和创新提供了新的思路和灵感。
<br /><br />总结: 该项目是一个与OpenAI语言模型GPT进行交互的Demo项目，通过GitHub进行发布。项目展示了作者与GPT模型的对话和交流过程，探索了语言模型在不同场景下的应用。展示了人与人工智能之间的交互可能性，以及语言模型在日常生活中的潜在应用。整个项目与GPT模型之间的互动充满趣味和创意，展示了人工智能技术的潜力和可能性。 <div>
【LLM Experiments：与 OpenAI 语言模型 GPT 进行交互的Demo项目】’LLM Experiments - I play with my best friend GPT' GitHub: github.com/ggoonnzzaallo/llm_experiments <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hotq56s2qdj20u013fdn7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:38:50 GMT</pubDate>
</item>
<item>
<title>【Firecrawl：将网站内容转换为适合LLM的Markdown格式文本的工具】'Firecrawl - Turn entire websites into LLM-ready markdown' GitHub: github.com/mendableai...</title>
<link>https://weibo.com/1402400261/Oa7DlzX7X</link>
<guid>https://weibo.com/1402400261/Oa7DlzX7X</guid>
<content:encoded><![CDATA[
<div> 工具、Firecrawl、网站内容、转换、LLM、Markdown格式、GitHub、mendableai

<br /><br />总结:
Firecrawl是一个工具，可以将网站的内容转换为适合LLM（Large Language Models）的Markdown格式文本。用户可以通过GitHub上的mendableai/firecrawl找到该工具。通过Firecrawl，用户可以将整个网站的内容快速转换为LLM所能识别的Markdown格式，便于进一步处理和分析。Firecrawl的使用简单高效，为用户提供了一个方便的工具来整理和处理网站内容。 <div>
【Firecrawl：将网站内容转换为适合LLM的Markdown格式文本的工具】'Firecrawl - Turn entire websites into LLM-ready markdown' GitHub: github.com/mendableai/firecrawl <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hotq1lp0ahj21740smtds.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:35:11 GMT</pubDate>
</item>
<item>
<title>【CodeQwen1.5：基于人工智能的代码生成工具，可以根据自然语言描述生成完整的代码，该工具利用了Qwen大语言模型，可以提供高质量、准确的代码生成结果】'CodeQw...</title>
<link>https://weibo.com/1402400261/Oa7C4xjT8</link>
<guid>https://weibo.com/1402400261/Oa7C4xjT8</guid>
<content:encoded><![CDATA[
<div> 人工智能、代码生成工具、Qwen大语言模型、高质量、准确、代码生成结果、Alibaba Cloud

<br /><br />总结:
CodeQwen1.5是一款基于人工智能的代码生成工具，利用了Qwen大语言模型，能够根据自然语言描述生成完整的代码。该工具提供高质量、准确的代码生成结果，是由阿里云的Qwen团队开发的具有先进技术的工具。GitHub上有该工具的代码存储库，用户可以查看并使用。 <div>
【CodeQwen1.5：基于人工智能的代码生成工具，可以根据自然语言描述生成完整的代码，该工具利用了Qwen大语言模型，可以提供高质量、准确的代码生成结果】'CodeQwen1.5 - the code version of Qwen, the large language model series developed by Qwen team, Alibaba Cloud.' GitHub: github.com/QwenLM/CodeQwen1.5 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hotpy9sxkuj20yz0u00wd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:32:03 GMT</pubDate>
</item>
<item>
<title>【MIT新书《计算机视觉基础》，一本关于计算机视觉基础的教材，该教材结合了计算机视觉的经典方法和深度学习的最新进展，并从全面的角度介绍了计算机视觉的基础...</title>
<link>https://weibo.com/1402400261/Oa5M68zO3</link>
<guid>https://weibo.com/1402400261/Oa5M68zO3</guid>
<content:encoded><![CDATA[
<div> 计算机视觉基础 深度学习 经典方法 基础问题 人类感知 关系

<br /><br />总结:
《计算机视觉基础》是一本结合了计算机视觉的经典方法和深度学习最新进展的教材。该教材从全面的角度介绍了计算机视觉的基础问题，并探讨了计算机视觉与人类感知的关系。在学习计算机视觉的过程中，深度学习技术的应用成为了一个重要方向。通过本书的学习，读者能够了解到计算机视觉在实际应用中的原理和方法，以及如何将计算机视觉技术与深度学习相结合，从而更好地理解和应用这一领域的知识。《计算机视觉基础》为读者提供了一个系统化、全面的学习计算机视觉基础知识的平台，帮助他们更加深入地了解这一领域的理论和实践。 <div>
【MIT新书《计算机视觉基础》，一本关于计算机视觉基础的教材，该教材结合了计算机视觉的经典方法和深度学习的最新进展，并从全面的角度介绍了计算机视觉的基础问题和其与人类感知的关系】《Foundations of Computer Vision》 <a href="https://mitpress.mit.edu/9780262048972/foundations-of-computer-vision/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hothts9z1tj20gk0iln00.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 23:51:15 GMT</pubDate>
</item>
<item>
<title>【免费书《大语言模型》，为读者提供关于大语言模型技术的全面了解，从基础原理、关键技术到应用前景。它介绍了大模型技术的整体框架和路线图，并提供了下载链接...</title>
<link>https://weibo.com/1402400261/Oa5KC99ej</link>
<guid>https://weibo.com/1402400261/Oa5KC99ej</guid>
<content:encoded><![CDATA[
<div> 大语言模型、技术、基础原理、关键技术、应用前景、整体框架、路线图、下载链接、配套资源

大语言模型是一本免费的书籍，提供了关于大语言模型技术的全面了解。书中介绍了大模型技术的整体框架和路线图，包括基础原理、关键技术以及应用前景。读者可以从中了解到大语言模型的基本原理和关键技术，同时获取相关的下载链接和配套资源。这本书为对大语言模型技术感兴趣的读者提供了丰富的知识和资源，帮助他们更好地理解和应用这一前沿技术。<br /><br />总结: 大语言模型提供了关于大模型技术的详细介绍，包括基础原理、关键技术和应用前景，读者可通过下载链接获取更多资源。 <div>
【免费书《大语言模型》，为读者提供关于大语言模型技术的全面了解，从基础原理、关键技术到应用前景。它介绍了大模型技术的整体框架和路线图，并提供了下载链接和配套资源】《大语言模型 | LLMBook-zh》 <a href="https://llmbook-zh.github.io/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hothpwd0kaj20u01c5wl2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hothphj1wej20s30bygp0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 23:47:34 GMT</pubDate>
</item>
<item>
<title>《AI类知识文档全网合集 - 飞书云文档》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/Oa5Jz6sti</link>
<guid>https://weibo.com/1402400261/Oa5Jz6sti</guid>
<content:encoded><![CDATA[
<div> 关键词: AI, 知识文档, 全网, 合集, 飞书, 云文档

总结: 
AI类知识文档全网合集是一份收集了各种与人工智能相关的文档的合集，在飞书云文档中可获取。这份合集包含了各种有关AI的知识和信息，为研究人员、开发者和学习者提供了丰富的资源和参考资料。通过飞书云文档，用户可以方便地浏览和获取这些文档，从而提升对人工智能的理解和运用能力。AI技术的发展日新月异，掌握最新的知识和资讯对于从事相关领域的人员至关重要。飞书云文档为用户提供了一个方便快捷的获取AI类知识文档的平台，帮助他们更加高效地学习和研究人工智能技术。AI类知识文档全网合集的推出，将为AI领域的学习和发展提供更多便利，促进人工智能技术的创新和应用。<br /><br />总结: <div>
《AI类知识文档全网合集 - 飞书云文档》 <a href="https://uqtg4okxsd.feishu.cn/wiki/MoB0w5Zd2ie2IckGg7WccMRRnrg"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hothnowlqsj21at0u0tdw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 23:45:00 GMT</pubDate>
</item>
<item>
<title>【torchtune：用 PyTorch 轻松微调大语言模型】 - PyTorch发布了torchtune库的alpha版本，用于轻松微调大型语言模型。该库遵循PyTorch的设计原则，提供了组件化...</title>
<link>https://weibo.com/1402400261/Oa5IUgoKb</link>
<guid>https://weibo.com/1402400261/Oa5IUgoKb</guid>
<content:encoded><![CDATA[
<div> PyTorch, torchtune, 大语言模型, 微调, 组件化, 模块化,易扩展性, 开源生态系统, Hugging Face Hub, PyTorch FSDP

总结：<br /><br />PyTorch发布了torchtune库的alpha版本，用于轻松微调大型语言模型。该库遵循PyTorch的设计原则，提供了组件化和模块化的构建块，以及易于扩展的微调示例，以在各种消费级和专业GPU上微调流行的大型语言模型。torchtune支持完整的微调工作流程，包括数据集和模型检查点的下载和准备、可组合的构建块进行训练自定义、训练过程的日志和指标记录、模型量化、在知名基准上的模型评估以及本地推理。torchtune致力于易扩展性，让微调大众化，并与开源生态系统的互操作性。未来还将增加更多模型、特征和微调技术。torchtune与Hugging Face Hub、PyTorch FSDP、Weights & Biases、EleutherAI的评估工具、ExecuTorch和torchao等开源生态系统的组件深度集成，为用户提供灵活性和控制力。 <div>
【torchtune：用 PyTorch 轻松微调大语言模型】<br /> - PyTorch发布了torchtune库的alpha版本，用于轻松微调大型语言模型。该库遵循PyTorch的设计原则，提供了组件化和模块化的构建块，以及易于扩展的微调示例，以在各种消费级和专业GPU上微调流行的大型语言模型。   <br />- torchtune支持从头到尾的完整微调工作流程，包括数据集和模型检查点的下载和准备、可组合的构建块进行训练自定义、训练过程的日志和指标记录、模型量化、在知名基准上的模型评估以及本地推理。   <br />- torchtune致力于易扩展性、让微调大众化、与开源生态系统的互操作性。未来几周将持续为库增加更多模型、特征和微调技术。   <br />- torchtune与Hugging Face Hub、PyTorch FSDP、Weights &amp; Biases、EleutherAI的评估工具、ExecuTorch和torchao等开源生态系统的组件深度集成，为用户提供灵活性和控制力。<br />《torchtune: Easily fine-tune LLMs using PyTorch | PyTorch》 <a href="https://pytorch.org/blog/torchtune-fine-tune-llms"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hothm0tmfej214a0u0adk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 23:43:23 GMT</pubDate>
</item>
<item>
<title>今日推介(第1378期)：具有无限上下文长度的高效LLM预训练和推理、大型语言模型可以自动实现特征工程以进行少样本表格学习、反馈注意力是工作记忆、偏好噪声对生...</title>
<link>https://weibo.com/1402400261/Oa5a0hxA0</link>
<guid>https://weibo.com/1402400261/Oa5a0hxA0</guid>
<content:encoded><![CDATA[
<div> 预训练、推理、特征工程、少样本表格学习、工作记忆、偏好噪声、生成式语言模型、对齐性能、状态幻觉

<br /><br />总结:
本文介绍了具有无限上下文长度的高效LLM预训练和推理的方法，以及大型语言模型可以自动实现特征工程来进行少样本表格学习的技术。研究表明，反馈注意力在工作记忆中起到重要作用。此外，偏好噪声对生成式语言模型的对齐性能有影响。最后，讨论了状态-空间模型中状态幻觉的问题。这些研究结果对提升语言模型的效率和性能具有重要指导意义。 <div>
今日推介(第1378期)：具有无限上下文长度的高效LLM预训练和推理、大型语言模型可以自动实现特征工程以进行少样本表格学习、反馈注意力是工作记忆、偏好噪声对生成式语言模型对齐性能的影响、状态-空间模型的状态幻觉 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/692889182"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.17)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hotf47b02lj219o0qwaec.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hotf49o2isj22bl0u0jzw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hotf4cc4bxj21jk0p8qa3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hotf4f73pej21a00jk40m.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hotf4ib6y8j20tu12uahn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 22:17:23 GMT</pubDate>
</item>
<item>
<title>[LG] Foundational Challenges in Assuring Alignment and Safety of Large Language Models 网页链接 本文系统地总结了确保大语言模型安全性和对齐性的18大基础...</title>
<link>https://weibo.com/1402400261/Oa55Cy133</link>
<guid>https://weibo.com/1402400261/Oa55Cy133</guid>
<content:encoded><![CDATA[
<div> 挑战、安全性、对齐性、大语言模型、路线图、研究、基础性、清晰、确保、系统地

总结:<br /><br />文章系统地总结了确保大语言模型安全性和对齐性的18大基础性挑战，为后续研究提供了清晰的路线图。 <div>
[LG] Foundational Challenges in Assuring Alignment and Safety of Large Language Models  <br /><a href="https://arxiv.org/abs/2404.09932"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />本文系统地总结了确保大语言模型安全性和对齐性的18大基础性挑战，为后续研究提供了清晰的路线图。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotet9yrp1j210y1d8n80.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotetactpyj20zy1d6tnl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotetat0gbj210c1d4k8f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotetau6f6j210g1dcncu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 22:06:36 GMT</pubDate>
</item>
<item>
<title>[CL] Large Language Models are as persuasive as humans, but why? About the cognitive effort and moral-emotional language of LLM arguments 网页链接 发...</title>
<link>https://weibo.com/1402400261/Oa52EjLan</link>
<guid>https://weibo.com/1402400261/Oa52EjLan</guid>
<content:encoded><![CDATA[
<div> 认知加工难度, 道德语言, LLM, 说服力, 人类, 差异, 线索, 情感语言, 论点

<br /><br />总结:
LLM与人类在说服力上存在差异，这部分原因可能在于认知加工难度和道德语言的运用。LLM的论点在道德语言和情感语言上的表达可能是其说服力的关键之一，而这也为研究LLM的说服力提供了一些线索。虽然在某些方面LLM可能和人类一样具有说服力，但认知加工难度和道德语言的使用会导致它们在说服力上出现一些差异。通过深入研究LLM的道德语言运用和情感语言表达，或许可以更好地理解其说服力的机制。 <div>
[CL] Large Language Models are as persuasive as humans, but why? About the cognitive effort and moral-emotional language of LLM arguments  <br /><a href="https://arxiv.org/abs/2404.09329"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>        <br />发现LLM论点相较人类论点在认知加工难度和道德语言运用上存在差异，为解析LLM的说服力提供了线索。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotelnjv88j216g18q168.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotelo1nzvj21kw0vu79l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotelogyrnj21bg19244e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:59:17 GMT</pubDate>
</item>
<item>
<title>[CV] Map-Relative Pose Regression for Visual Re-Localization 网页链接 该方法将场景特定的几何表示与场景无关的姿态回归相结合，在保持端到端高效的同时实现...</title>
<link>https://weibo.com/1402400261/Oa4Zjke8v</link>
<guid>https://weibo.com/1402400261/Oa4Zjke8v</guid>
<content:encoded><![CDATA[
<div> 重定位、场景特定、几何表示、姿态回归、端到端、高效、高精度、视觉重定位、重要进展
<br />
<br />
总结: 本文提出了一种将场景特定的几何表示与场景无关的姿态回归相结合的方法，实现了高精度的视觉重定位。这种方法在保持端到端高效的同时，取得了重要的进展，对姿态回归领域具有重要意义。 <div>
[CV] Map-Relative Pose Regression for Visual Re-Localization  <br /><a href="https://arxiv.org/abs/2404.09884"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />该方法将场景特定的几何表示与场景无关的姿态回归相结合，在保持端到端高效的同时实现了高精度的视觉重定位，是姿态回归领域的重要进展。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoted2fx86j20wo13sdv7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoted2g0rlj21no0jowkp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoted38d5tj20ue0ywn24.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:51:03 GMT</pubDate>
</item>
<item>
<title>[CL] Is Next Token Prediction Sufficient for GPT? Exploration on Code Logic Comprehension 网页链接 通过新的预训练任务增强了语言模型区分逻辑等价代码的...</title>
<link>https://weibo.com/1402400261/Oa4X1xhCP</link>
<guid>https://weibo.com/1402400261/Oa4X1xhCP</guid>
<content:encoded><![CDATA[
<div> 预训练任务、语言模型、代码逻辑、等价代码、LLM、关键词集合、逻辑理解、代码理解

总结:<br /><br />文章通过探讨新的预训练任务增强了语言模型在区分逻辑等价代码方面的能力，证明当前LLM仍将代码视为无序关键词集合而非真正理解其背后的逻辑。通过研究可以得出，对于GPT来说，仅仅进行下一个标记的预测可能并不足以实现对代码逻辑的完全理解。文章呼吁加强对语言模型在代码逻辑理解方面的研究，以提高其应用的准确性和可靠性。 <div>
[CL] Is Next Token Prediction Sufficient for GPT? Exploration on Code Logic Comprehension  <br /><a href="https://arxiv.org/abs/2404.08885"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />通过新的预训练任务增强了语言模型区分逻辑等价代码的能力，证明当前LLM仍将代码视为无序关键词集合而非真正理解其背后的逻辑。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hote78otucj20s616uwut.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hote78rpjyj21h80yok14.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hote79fcsmj20qe0s6n1p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:45:25 GMT</pubDate>
</item>
<item>
<title>[CL] Compression Represents Intelligence Linearly 网页链接 大型语言模型压缩外部语料的效率与其在知识理解、编程和数学推理方面的表现几乎呈线性相关，压缩...</title>
<link>https://weibo.com/1402400261/Oa4TApUVY</link>
<guid>https://weibo.com/1402400261/Oa4TApUVY</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、压缩、外部语料、效率、知识理解、编程、数学推理、线性相关、测试集泄露、智能评价指标 <br />
<br />
总结: 本文指出，大型语言模型在压缩外部语料方面的效率与其在知识理解、编程和数学推理方面的表现几乎呈线性相关。压缩效率可以作为一个既避免测试集泄露又与模型智能高度相关的评价指标。 <div>
[CL] Compression Represents Intelligence Linearly  <br /><a href="https://arxiv.org/abs/2404.09937"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />大型语言模型压缩外部语料的效率与其在知识理解、编程和数学推理方面的表现几乎呈线性相关，压缩效率可以作为一个避免测试集泄露且与模型智能高度相关的评价指标。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdyeg0o7j20qc16mdrg.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdyeoig5j21bs0pgdn2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdyfenn5j21bi0oqaha.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:36:56 GMT</pubDate>
</item>
<item>
<title>利用回路复杂度理论证明了SSM在状态跟踪问题上与Transformer有相似的固有表达能力局限，表明SSM难以处理需要顺序计算的状态跟踪任务。 - 转发 @爱可可-爱生活:&amp;e...</title>
<link>https://weibo.com/1402400261/Oa4QidNBy</link>
<guid>https://weibo.com/1402400261/Oa4QidNBy</guid>
<content:encoded><![CDATA[
<div> 状态跟踪问题, SSM, Transformer, 回路复杂度理论, 表达能力局限<br />
<br />
总结:<br />
文章利用回路复杂度理论证明了SSM在状态跟踪问题上与Transformer具有相似的固有表达能力局限。作者指出，SSM难以处理需要顺序计算的状态跟踪任务。他们认为，SSM模型在处理复杂的状态跟踪问题时存在局限性，需要进一步改进。文章的研究对于深入理解SSM在状态跟踪问题中的表现有着重要的意义。 <div>
利用回路复杂度理论证明了SSM在状态跟踪问题上与Transformer有相似的固有表达能力局限，表明SSM难以处理需要顺序计算的状态跟踪任务。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《The Illusion of State in State-Space Models》W Merrill, J Petty, A Sabharwal [New York University] (2024) <a href="https://arxiv.org/abs/2404.08819"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdjlg2npj20p018u4am.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdjm922bj20tu12u48k.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdjmimbij20tg0lu431.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdjmpz89j21mm0qowky.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:28:49 GMT</pubDate>
</item>
<item>
<title>[LG]《The Illusion of State in State-Space Models》W Merrill, J Petty, A Sabharwal [New York University] (2024) 网页链接 #机器学习##人工智能##论文# [...</title>
<link>https://weibo.com/1402400261/Oa4QfBnP7</link>
<guid>https://weibo.com/1402400261/Oa4QfBnP7</guid>
<content:encoded><![CDATA[
<div> state-space models, illusion, state, New York University, analysis, methodology, implications, measurements, research, findings

总结:<br /><br />本文由纽约大学的W Merrill, J Petty和A Sabharwal撰写，探讨了状态空间模型中的状态错觉现象。研究通过分析方法论和测量方法，揭示了状态空间模型中状态的虚幻性质。研究结果对测量和研究方法产生了重要影响，强调了状态空间模型中存在的一些潜在误导。通过深入研究，文章呈现了对状态空间模型的新理解，为相关领域的研究提供了有价值的参考。 <div>
[LG]《The Illusion of State in State-Space Models》W Merrill, J Petty, A Sabharwal [New York University] (2024) <a href="https://arxiv.org/abs/2404.08819"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdjlg2npj20p018u4am.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdjm922bj20tu12u48k.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdjmimbij20tg0lu431.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdjmpz89j21mm0qowky.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:28:44 GMT</pubDate>
</item>
<item>
<title>提出一个注入可控噪声的框架，系统地研究了不同类型和程度的偏好噪声如何影响生成式语言模型(GLM)对齐效果以及置信度滤波在降噪方面的作用，为更好地理解和处理...</title>
<link>https://weibo.com/1402400261/Oa4KSCq0X</link>
<guid>https://weibo.com/1402400261/Oa4KSCq0X</guid>
<content:encoded><![CDATA[
<div> GLM, 偏好噪声, 对齐效果, 置信度滤波, 框架, 研究, 影响, 指导, 理解, 处理

总结:<br /><br />
这篇文章提出了一个注入可控噪声的框架，系统地研究了不同类型和程度的偏好噪声如何影响生成式语言模型对齐效果以及置信度滤波在降噪方面的作用。研究结果为更好地理解和处理偏好噪声提供了指导。文章内容包括：框架提出和设计，不同类型偏好噪声的影响研究，对齐效果分析，置信度滤波的降噪作用探讨等。研究结论表明，注入偏好噪声对于生成式语言模型的对齐效果有明显影响，同时置信度滤波能有效降噪，有助于提高模型的稳定性和准确性。这些研究结果对于深入理解和解决偏好噪声问题具有一定的启发意义。 <div>
提出一个注入可控噪声的框架，系统地研究了不同类型和程度的偏好噪声如何影响生成式语言模型(GLM)对齐效果以及置信度滤波在降噪方面的作用，为更好地理解和处理偏好噪声提供了指导。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Impact of Preference Noise on the Alignment Performance of Generative Language Models》Y Gao, D Alon, D Metzler [Google Research] (2024) <a href="https://arxiv.org/abs/2404.09824"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotdbib6xzj211s0r8n8s.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdbitoq6j219i0m243e.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdbj2c5pj217s0osgrp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdbj6djhj217s0osgrp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdbxypyqj20ul0gbac7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdbxyrn0j20ul0gcdib.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdbxxyrlj20ul0codgu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotdby0anjj20vg18cafc.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:15:30 GMT</pubDate>
</item>
<item>
<title>[CL]《Impact of Preference Noise on the Alignment Performance of Generative Language Models》Y Gao, D Alon, D Metzler [Google Research] (2024) 网页链...</title>
<link>https://weibo.com/1402400261/Oa4KOqXVu</link>
<guid>https://weibo.com/1402400261/Oa4KOqXVu</guid>
<content:encoded><![CDATA[
<div> 对关键词进行提取：Preference Noise, Alignment Performance, Generative Language Models, Impact, Google Research

总结:<br /><br />
这篇文章由Google Research团队的Y Gao、D Alon和D Metzler撰写，探讨了偏好噪音对生成语言模型对齐性能的影响。研究结果表明，偏好噪音会对生成语言模型的对齐性能产生负面影响。文章通过实验和分析发现，偏好噪音会导致模型生成不符合用户预期的输出，降低了模型在任务中的性能表现。研究强调了在训练生成语言模型时需要考虑和处理偏好噪音，以提高模型的对齐性能。文章为生成语言模型的进一步研究和优化提供了重要参考。 <div>
[CL]《Impact of Preference Noise on the Alignment Performance of Generative Language Models》Y Gao, D Alon, D Metzler [Google Research] (2024) <a href="https://arxiv.org/abs/2404.09824"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotdbib6xzj211s0r8n8s.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdbitoq6j219i0m243e.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdbj2c5pj217s0osgrp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdbj6djhj217s0osgrp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdbxypyqj20ul0gbac7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdbxyrn0j20ul0gcdib.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdbxxyrlj20ul0codgu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotdby0anjj20vg18cafc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:15:19 GMT</pubDate>
</item>
<item>
<title>提出Transformer反馈注意力记忆(FAM)架构，通过反馈循环实现对自身潜在表示的注意力处理，使Transformer获得工作记忆能力，可以高效处理无限长输入序列。 - 转发...</title>
<link>https://weibo.com/1402400261/Oa4KnfVSw</link>
<guid>https://weibo.com/1402400261/Oa4KnfVSw</guid>
<content:encoded><![CDATA[
<div> 注意力记忆架构, Transformer, 反馈循环, 自身潜在表示, 高效处理, 无限长输入序列<br />
<br />
提出了Transformer反馈注意力记忆(FAM)架构，通过反馈循环实现对自身潜在表示的注意力处理，使得Transformer获得了工作记忆能力，可以高效处理无限长输入序列。该架构不仅提升了Transformer在处理长序列任务上的性能，还为其赋予了对潜在注意力需求的工作记忆能力。通过引入FAM，Transformer在长序列上的表现大幅提升，能够更好地捕捉重要信息并处理长距离依赖关系。这一架构的提出为Transformer的进一步优化和发展提供了新的思路和可能性。FAM的引入在自然语言处理领域具有重要意义，有望在各种NLP任务中取得显著的性能提升。 <br /><br />总结: <div>
提出Transformer反馈注意力记忆(FAM)架构，通过反馈循环实现对自身潜在表示的注意力处理，使Transformer获得工作记忆能力，可以高效处理无限长输入序列。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《TransformerFAM: Feedback attention is working memory》D Hwang, W Wang, Z Huo, K C Sim, P M Mengibar [Google] (2024) <a href="https://arxiv.org/abs/2404.09173"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotda1luctj20ng0rkjxz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotda25eodj21jk0p8n6j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotda2aqnaj21jo0j2gst.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotda2dqnkj20s00piae0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotdakyrigj20iv0fmt9t.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdakzrrhj212d0zpq61.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdakzgocj212c0g80tx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotdakywcpj20ob0bpgm2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdakz0jzj212f0g8gmo.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:14:15 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.16)》 爱可可微博热门分享(4.16) [图片]</title>
<link>https://weibo.com/1402400261/Oa26Y3PGD</link>
<guid>https://weibo.com/1402400261/Oa26Y3PGD</guid>
<content:encoded><![CDATA[
<div> 微博热门, 爱可可, 分享, 4.16, 关键词

<br /><br />总结:
爱可可微博在4月16日分享的内容受到了广泛关注。这篇热门分享内容涉及了各种话题，引发了网友们的讨论热情。其中，爱可可微博通过分享内容吸引了大量粉丝的关注和转发。网友们纷纷在评论区留言表达自己的看法，互动热烈。这篇文章在微博上迅速传播，成为当天的热门话题之一。通过此次分享，爱可可微博再次展现了其在社交平台上的影响力和号召力。 <div>
《爱可可微博热门分享(4.16)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405023914001826171"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.16)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hot1nu3m6mj20kg0bimyv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 14:31:40 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video》(CVPR 2024) GitHub: github.c...</title>
<link>https://weibo.com/1402400261/O9YS6d40h</link>
<guid>https://weibo.com/1402400261/O9YS6d40h</guid>
<content:encoded><![CDATA[
<div> 关键词: 视频游戏、实时交互、真实感、浏览器兼容、图像网格、零样本视频问答、LLM预训练、无限上下文长度、无穷注意力、语音增强

总结:
本文介绍了几篇论文的实现代码，包括《Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video》、《An Image Grid Can Be Worth a Video: Zero-shot Video Question Answering Using a VLM》、《Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length》、《Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention》、《Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios》、《Unsupervised Speech Enhancement with Diffusion-based Generative Models》、《Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!》、《MapTracker: Tracking with Strided Memory Fusion for Consistent Vector HD Mapping》。这些论文涵盖了实时交互、真实感、浏览器兼容、零样本视频问答、LLM预训练、无限上下文长度、无穷注意力、语音增强等方面的内容，为相关研究领域提供了有价值的研究成果。 <div>
几篇论文实现代码：<br />《Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video》(CVPR 2024) GitHub: github.com/video2game/video2game [fig1]<br />《An Image Grid Can Be Worth a Video: Zero-shot Video Question Answering Using a VLM》(CVPR 2024) GitHub: github.com/Kroery/DiffMOT<br />《Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length》(2024) GitHub: github.com/XuezheMax/megalodon<br />《Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention》(2024) GitHub: github.com/dingo-actual/infini-transformer?tab=readme-ov-file<br />《Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios》(2024) GitHub: github.com/JoeYing1019/UltraTool [fig2]<br />《Unsupervised Speech Enhancement with Diffusion-based Generative Models》(2024) GitHub: github.com/joanne-b-nortier/UDiffSE<br />《Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!》(2024) GitHub: github.com/ZHZisZZ/emulated-disalignment<br />《MapTracker: Tracking with Strided Memory Fusion for Consistent Vector HD Mapping》(2024) GitHub: github.com/woodfrog/maptracker [fig3]<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hosm09y7x7j21e50hj1kx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hosmzpah1jj21960hg7ea.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hosn8kplusj26a44lahdz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 06:16:48 GMT</pubDate>
</item>
<item>
<title>【Speechless LLM based Agents：基于LLM 的Agent，具有主动交互、长期记忆、外部工具集成和本地部署能力，旨在建立一个智能协作伙伴，该伙伴可以独立交互、持续...</title>
<link>https://weibo.com/1402400261/O9YRebTep</link>
<guid>https://weibo.com/1402400261/O9YRebTep</guid>
<content:encoded><![CDATA[
<div> LLM, Agent, 主动交互, 长期记忆, 外部工具集成, 本地部署, 智能协作伙伴, 实际价值, GitHub <br />
<br />
要点1: Speechless LLM based Agents 是基于LLM的代理，具有主动交互、长期记忆、外部工具集成和本地部署能力。
要点2: 旨在建立一个智能协作伙伴，可以独立交互、持续发展，并与各种业务场景密切对齐。
要点3: 为企业提供实际价值，提高工作效率和协同能力。
要点4: 该项目托管在GitHub上（github.com/uukuguy/speechless）。<br /><br />
总结: Speechless LLM based Agents是基于LLM的代理，具备多种先进功能，旨在成为企业的智能协作伙伴，提供实际价值，并实现外部工具集成和本地部署。通过长期记忆和主动交互，可以持续发展并适应各种业务场景，提高工作效率和协同能力。GitHub上提供了相关信息，为感兴趣的用户提供了更多了解和参与的机会。 <div>
【Speechless LLM based Agents：基于LLM 的Agent，具有主动交互、长期记忆、外部工具集成和本地部署能力，旨在建立一个智能协作伙伴，该伙伴可以独立交互、持续发展，并与各种业务场景密切对齐，为企业提供实际价值】’Speechless LLM based Agents - LLM based agents with proactive interactions, long-term memory, external tool integration, and local deployment capabilities.' GitHub: github.com/uukuguy/speechless <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hosnas5lwbj20wj0u0wkr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 06:14:39 GMT</pubDate>
</item>
<item>
<title>【OpenChatML Specification：用于表示对话数据的结构化格式，为对话系统、聊天机器人、对话数据集等场景提供了一种标准化的表示方式】'OpenChatML Specificatio...</title>
<link>https://weibo.com/1402400261/O9YP9DkAG</link>
<guid>https://weibo.com/1402400261/O9YP9DkAG</guid>
<content:encoded><![CDATA[
<div> 对话数据、结构化格式、OpenChatML Specification、对话系统、聊天机器人、对话数据集、标准化、表示方式、GitHub、版本控制<br />
<br />总结:
'OpenChatML Specification'是用于表示对话数据的结构化格式的标准，为对话系统、聊天机器人、对话数据集等场景提供了一种统一的表示方式。该规范定义了数据的组织结构，使得不同系统间可以更方便地交换和处理对话数据。通过遵循该规范，可以实现对话数据的标准化，提高数据处理的效率和准确性。该规范的开发和维护可以在GitHub上进行，版本控制和协作更加方便和高效。通过使用OpenChatML Specification，可以促进对话数据领域的发展，提升对话系统和聊天机器人的性能和用户体验。 <div>
【OpenChatML Specification：用于表示对话数据的结构化格式，为对话系统、聊天机器人、对话数据集等场景提供了一种标准化的表示方式】'OpenChatML Specification v0.1' GitHub: github.com/cognitivecomputations/OpenChatML <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hosn5hgf71j216s0u00xz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 06:09:32 GMT</pubDate>
</item>
<item>
<title>【Memento：记录计算机所有动作并允许用户返回时间、搜索和通过 LLM（大语言模型）与时间线聊天以查找收集到信息的 Python 应用】'Memento - a Python app that ...</title>
<link>https://weibo.com/1402400261/O9YLujW50</link>
<guid>https://weibo.com/1402400261/O9YLujW50</guid>
<content:encoded><![CDATA[
<div> 记录、计算机、动作、用户、返回、时间、搜索、LLM、大语言模型、Python应用
<br /><br />总结:
Memento是一个Python应用程序，可记录用户在计算机上的所有操作。用户可以随时返回过去的时间点，进行搜索，并通过与LLM（大语言模型）对话来查找收集到的信息。该应用具有多种功能，使用户能够方便地追溯和查找他们之前所做的工作。 Memento的开源代码可以在GitHub上找到。 <div>
【Memento：记录计算机所有动作并允许用户返回时间、搜索和通过 LLM（大语言模型）与时间线聊天以查找收集到信息的 Python 应用】'Memento - a Python app that records everything you do on your computer and lets you go back in time, search, and chat with a LLM (Large Language Model) to find back information about what you did.' GitHub: github.com/apirrone/Memento <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hosmuvx8o2j20x80u078e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 06:00:31 GMT</pubDate>
</item>
<item>
<title>【Decompyle++：用 C++ 编写的 Python 字节码反编译器和反汇编器基于 OpenAI whisper 的 YouTube 视频搜索工具，可以将音频转为文本，并在视频中高亮搜索到的关...</title>
<link>https://weibo.com/1402400261/O9YKgyq5Q</link>
<guid>https://weibo.com/1402400261/O9YKgyq5Q</guid>
<content:encoded><![CDATA[
<div> GitHub, C++, Python, bytecode, disassembler, decompiler, OpenAI, whisper, 视频搜索工具

<br /><br />总结:
Decompyle++是一个用C++编写的Python字节码反汇编器和反编译器，基于OpenAI whisper的YouTube视频搜索工具。它可以将音频转换为文本，并在视频中高亮显示搜索到的关键词。该工具在GitHub上开源，旨在帮助用户对Python字节码进行分析和反编译。通过这个工具，用户可以更加方便地理解和修改Python程序的底层运行机制，提高代码分析和调试的效率。Decompyle++的灵活性和高效性使其成为Python开发者和研究人员的有力辅助工具，为他们提供了深入学习和探索Python编程语言的机会。 <div>
【Decompyle++：用 C++ 编写的 Python 字节码反编译器和反汇编器基于 OpenAI whisper 的 YouTube 视频搜索工具，可以将音频转为文本，并在视频中高亮搜索到的关键词】'Decompyle++ - C++ python bytecode disassembler and decompiler' GitHub: github.com/zrax/pycdc <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hosmsyhsn4j21760r6wj3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 05:57:31 GMT</pubDate>
</item>
<item>
<title>【CTRL-F for videos：基于 OpenAI whisper 的 YouTube 视频搜索工具，可以将音频转为文本，并在视频中高亮搜索到的关键词】'CTRL-F for videos - Ctrl-f for vi...</title>
<link>https://weibo.com/1402400261/O9YJ9qTCj</link>
<guid>https://weibo.com/1402400261/O9YJ9qTCj</guid>
<content:encoded><![CDATA[
<div> 音频转文本, 视频搜索工具, OpenAI whisper, GitHub, 高亮搜索, 关键词

<br /><br />总结: 该文章介绍了一款名为"CTRL-F for videos"的工具，基于OpenAI whisper技术，能够将视频中的音频内容转换为文本。用户可以使用这个工具在YouTube视频中搜索关键词，并在视频中高亮显示搜索到的关键词。该工具的源代码可在GitHub上找到。通过这个工具，用户可以更方便地找到他们感兴趣的内容，提高视频搜索的效率。 <div>
【CTRL-F for videos：基于 OpenAI whisper 的 YouTube 视频搜索工具，可以将音频转为文本，并在视频中高亮搜索到的关键词】'CTRL-F for videos - Ctrl-f for videos' GitHub: github.com/Evan-Wildenhain/CTRL-F-VIDEO <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hosmq1gaeaj20zk0u00xf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hosmq25nelj20kh020t8n.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 05:54:46 GMT</pubDate>
</item>
<item>
<title>【SiLLM - Silicon LLM Training &amp; Inference Toolkit：基于 MLX 框架的 Silicon LLM 训练和推理工具包，简化了在 Apple Silicon 上训练和运行大语言模型的过程...</title>
<link>https://weibo.com/1402400261/O9YHIbzCL</link>
<guid>https://weibo.com/1402400261/O9YHIbzCL</guid>
<content:encoded><![CDATA[
<div> GitHub, MLX, Silicon LLM, 训练, 推理, 工具包, 简化, Apple Silicon, 大语言模型

<br /><br />总结:
SiLLM是一个基于MLX框架的Silicon LLM训练和推理工具包，旨在简化用户在Apple Silicon上训练和运行大语言模型的过程。该工具包提供了一套方便易用的工具和接口，使用户能够更轻松地进行训练和推理操作。通过SiLLM，用户可以快速构建和训练自己的语言模型，提升模型性能并加速推理过程。同时，SiLLM还支持在Apple Silicon等平台上进行高效的训练和推理，为用户提供了更便捷的工具和资源。通过SiLLM，用户可以更加灵活地进行语言模型的训练和运行，提高工作效率和模型性能。SiLLM的开源项目地址为https://github.com/armbues/SiLLM。 <div>
【SiLLM - Silicon LLM Training &amp; Inference Toolkit：基于 MLX 框架的 Silicon LLM 训练和推理工具包，简化了在 Apple Silicon 上训练和运行大语言模型的过程】'SiLLM - Silicon LLM Training &amp; Inference Toolkit' GitHub: github.com/armbues/SiLLM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hosmmfnbfuj20u00uwjw0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 05:51:13 GMT</pubDate>
</item>
<item>
<title>【llm-transparency-tool：开源交互式工具包，用于分析基于 Transformer 的语言模型的内部工作原理】'llm-transparency-tool - LLM Transparency Tool (LLM-TT),...</title>
<link>https://weibo.com/1402400261/O9Yzy24pt</link>
<guid>https://weibo.com/1402400261/O9Yzy24pt</guid>
<content:encoded><![CDATA[
<div> 开源、交互式工具包、分析、Transformer、语言模型、内部工作原理、GitHub、demo、Facebook Research

总结:<br />
llm-transparency-tool是一个开源的交互式工具包，用于分析基于Transformer的语言模型的内部工作原理。你可以在GitHub上找到该工具包，并查看演示。Facebook Research开发了这一工具，它提供了对语言模型内部工作原理的深入分析，帮助研究人员更好地了解和利用Transformer技术。该工具包为语言模型的研究和应用提供了重要的支持和帮助。 <div>
【llm-transparency-tool：开源交互式工具包，用于分析基于 Transformer 的语言模型的内部工作原理】'llm-transparency-tool - LLM Transparency Tool (LLM-TT), an open-source interactive toolkit for analyzing internal workings of Transformer-based language models. *Check out demo at* <a href="https://huggingface.co/spaces/facebook/llm-transparency-tool-demo'"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> GitHub: github.com/facebookresearch/llm-transparency-tool <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hosm1ftip2j213i0u0tf6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 05:31:06 GMT</pubDate>
</item>
<item>
<title>【Mini Gemini：挖掘多模态视觉语言模型潜力】《Mini Gemini - a Hugging Face Space by wcy1122》 网页链接 #机器学习# #人工智能# [图片][图片]</title>
<link>https://weibo.com/1402400261/O9WF3bLvB</link>
<guid>https://weibo.com/1402400261/O9WF3bLvB</guid>
<content:encoded><![CDATA[
<div> 挖掘、多模态、视觉、语言模型、潜力、Mini Gemini、Hugging Face Space、wcy1122、关键词

<br /><br />总结:
本文介绍了Mini Gemini这一多模态视觉语言模型的潜力和应用。作者通过挖掘不同模态数据的信息，提出了一种新的模型架构，旨在实现多模态信息的融合和处理。Mini Gemini基于Hugging Face Space平台，为研究者和开发者提供了一个实验和创新的空间。通过实验和案例分析，展示了Mini Gemini模型在多模态任务中的优势和表现。该模型能有效处理视觉和语言信息，为未来的研究和应用提供了新的思路和可能性。Mini Gemini的提出将推动多模态模型领域的发展，为人工智能和机器学习提供更多可能性和机会。 <div>
【Mini Gemini：挖掘多模态视觉语言模型潜力】《Mini Gemini - a Hugging Face Space by wcy1122》 <a href="https://huggingface.co/spaces/wcy1122/Mini-Gemini"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hosdlb0qdpj217c0p411f.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hosdlfqxkhj20zk0a1jte.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 00:39:10 GMT</pubDate>
</item>
<item>
<title>【视觉语言模型详解】- 视觉语言模型可以同时从图像和文本中学习，处理视觉问答、图像描述等多种任务。 - 主要的开源视觉语言模型包括LLaVA、DeepSeek、CogVLM、...</title>
<link>https://weibo.com/1402400261/O9WD6s1R5</link>
<guid>https://weibo.com/1402400261/O9WD6s1R5</guid>
<content:encoded><![CDATA[
<div> 视觉语言模型、图像、文本、开源、评估、多语言、建模基准测试、模型结构、Transformer、微调

<br /><br />
总结:视觉语言模型是一种可以同时从图像和文本中学习的模型，可以处理视觉问答、图像描述等多种任务。目前主要的开源视觉语言模型包括LLaVA、DeepSeek、CogVLM、Fuyu等，规模不等，支持多语言训练。评估视觉语言模型的重要指标包括视觉匿名竞技场人工评价、开源视觉语言模型排行榜中的各项指标。主要的视觉语言建模基准测试有MMMU、MMBench等，用于测试模型的跨学科知识理解和推理能力。典型的视觉语言模型由图像编码器、多模态投影器、文本解码器组成，通过图像文字匹配来联合训练。使用Transformer可以便捷地加载模型进行推理，最新版本的TRL可进行视觉语言模型的微调。视觉语言模型是多模态AI的未来发展方向，应用前景广泛，选择合适的模型、进行标准化评估和微调对于实现良好效果至关重要。 <div>
【视觉语言模型详解】<br />- 视觉语言模型可以同时从图像和文本中学习，处理视觉问答、图像描述等多种任务。   <br />- 主要的开源视觉语言模型包括LLaVA、DeepSeek、CogVLM、Fuyu等，规模从几十亿到万亿参数不等，图像分辨率从224x224到672x672。   <br />- 部分模型支持“grounding”功能，可以减少模型虚构内容(幻觉)。所有模型默认使用英语训练，部分支持多语言。   <br />- 评估视觉语言模型的重要指标有视觉匿名竞技场人工评价、开源视觉语言模型排行榜中的各项指标。   <br />- 主要的视觉语言建模基准测试包括MMMU、MMBench等，测试模型的跨学科知识理解和推理能力。   <br />- 典型的视觉语言模型由图像编码器、多模态投影器、文本解码器组成，通过图像文字匹配来联合训练。   <br />- 使用Transformer可以便捷地加载模型进行推理。使用最新版本的TRL可以进行视觉语言模型的微调。   <br />- 视觉语言模型正在引领多模态AI的发展，其应用前景广阔。选择合适的模型、使用标准化评估和微调对实现良好效果至关重要。<br />《Vision Language Models Explained》 <a href="https://huggingface.co/blog/vlms"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hosdgkl9dvj21hc0u0ahb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hosdgnuqboj21hc0u0whn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 00:34:22 GMT</pubDate>
</item>
<item>
<title>【开源模型推动教育：用 Llama 2 打造个性化教育平台】- 韩国教育公司Mathpresso利用开源模型Llama 2打造了数学学习平台QANDA和数学专用语言模型MathGPT。 - 商...</title>
<link>https://weibo.com/1402400261/O9WAooogF</link>
<guid>https://weibo.com/1402400261/O9WAooogF</guid>
<content:encoded><![CDATA[
<div> Mathpresso, Llama 2, QANDA, MathGPT, ChatGPT, Upstage, AI导师, 个性化教育, 开源模型, 灵活性

<br /><br />总结:韩国教育公司Mathpresso利用开源模型Llama 2成功打造了个性化数学学习平台QANDA和数学专用语言模型MathGPT。相较于商业语言模型如ChatGPT，Llama 2的灵活性使得Mathpresso可以充分利用自身数据和技术，为用户提供更个性化的教育服务。MathGPT不仅可以给出答案，还能提供详细的解释，有助于学生深入理解数学知识。同时，其他公司如Upstage也在使用Llama 2，其模型在开源语言模型排行榜上首次超过了GPT-3.5。开源模型为公司带来公平机会，为教育领域带来开创性影响。Mathpresso希望通过AI导师实现个性化教育的普及。开源模型的出现为公司提供了灵活性，创造了可负担的教育工具。 <div>
【开源模型推动教育：用 Llama 2 打造个性化教育平台】<br />- 韩国教育公司Mathpresso利用开源模型Llama 2打造了数学学习平台QANDA和数学专用语言模型MathGPT。   <br />- 商业语言模型如ChatGPT缺乏针对复杂教育背景的个性化。Llama 2灵活开源，Mathpresso可以充分利用自己的数据和技术。   <br />- MathGPT不仅给出答案，还提供步骤详细的解释，帮助学生深入理解。它在国小和国中数学测试中刷新了世界纪录。   <br />- 韩国AI创业公司Upstage也使用了Llama 2。它的模型在开源语言模型排行榜上首次超过了GPT-3.5。   <br />- Upstage认为Llama 2作为顶尖开源语言模型，为他们提供了充分的基础去开发定制化模型。   <br />- Mathpresso希望通过AI导师，实现个性化教育向所有人开放。Llama 2这样的开源模型给了他们灵活性去创造可负担的教育工具。   <br />- Llama 2等开源模型为公司大大小小提供了使用尖端技术的公平机会。它们正在开创性地影响教育等领域。<br />《Leveraging Llama 2 to create a platform for highly personalized learning》 <a href="https://ai.meta.com/blog/llama-2-mathgpt-mathpresso-qanda-upstage-open-source-llm/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hosd9reujej218g0p0wh3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 00:27:41 GMT</pubDate>
</item>
<item>
<title>【Limitless Pendant：又一款可穿戴AI设备，可以录音保存用户对话，并提供个性化AI助手服务。外形小巧时尚，一次充电可使用100小时，价格仅99美元，预计2024年第...</title>
<link>https://weibo.com/1402400261/O9WwCEdNU</link>
<guid>https://weibo.com/1402400261/O9WwCEdNU</guid>
<content:encoded><![CDATA[
<div> Limitless Pendant, 可穿戴AI设备, 录音保存对话, 个性化AI助手服务, 外形时尚, 一次充电100小时, 价格99美元, 预计2024年第四季度发货

<br /><br />总结:
Limitless Pendant是一款外形小巧时尚的可穿戴AI设备，用户可以使用它录音保存对话，并获得个性化AI助手服务。这款设备一次充电可使用100小时，价格仅99美元，计划在2024年第四季度发货。Limitless Pendant将提供用户更便利的日常生活体验，为用户创造无限的可能。 <div>
【Limitless Pendant：又一款可穿戴AI设备，可以录音保存用户对话，并提供个性化AI助手服务。外形小巧时尚，一次充电可使用100小时，价格仅99美元，预计2024年第四季度发货】《Limitless - Personalized AI powered by what you’ve seen, said, and heard》 <a href="https://www.limitless.ai/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5023699045384217"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a><br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/5396ee05ly1hosczoottuj20zk0k0q3g.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/cYSkNt3slx08e7tR3rDW01041200bX0d0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713234828&amp;ssig=DyWT01iYoN&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/bHZcyXNMlx08e7tQWavK010412005URT0E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713234828&amp;ssig=qfGj%2BwYqlq&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/10IguTvylx08e7tQv59u010412003JSy0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713234828&amp;ssig=q31rdaNg%2Br&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5023699045384217" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 00:18:24 GMT</pubDate>
</item>
<item>
<title>【一张图看匿名竞技场开源vs.闭源LLM表现】 - 随着时间的推移，模型的性能有不断提升的趋势，最新的GPT-4和Claude 3等模型表现更优。- 开源和闭源之间的差距已缩...</title>
<link>https://weibo.com/1402400261/O9Wsp9P6V</link>
<guid>https://weibo.com/1402400261/O9Wsp9P6V</guid>
<content:encoded><![CDATA[
<div> 关键词: 匿名竞技场, 开源, 闭源, LLM, GPT-4, Claude 3, 性能提升, 差距缩短, 模型表现, 相对性能

总结:<br /><br />本文探讨了匿名竞技场开源与闭源LLM的表现比较。随着时间推移，模型性能不断提升，最新的GPT-4和Claude 3表现优秀。开源与闭源之间的差距已经缩短至6-10个月，远远小于之前的几年。在同类型模型中，闭源模型如GPT-4、GPT-4 Turbo、Gemini Pro整体表现更出色，但也有一些开源模型如Mistral、OpenChat-3.5表现不错。一些较早期的模型如GPT-3.5 Turbo、Vicuna、Llama虽然性能较弱，但也有不错的表现。整体而言，开源与闭源的性能差距在不断缩小，各种的LLM模型在匿名竞技场中不断演化，展现出不同的表现与优势。 <div>
【一张图看匿名竞技场开源vs.闭源LLM表现】  <br />- 随着时间的推移，模型的性能有不断提升的趋势，最新的GPT-4和Claude 3等模型表现更优。<br />- 开源和闭源之间的差距已缩短至6-10个月，GPT-4刚发布时该差距为几年。<br />- 在同类型模型中，闭源模型如GPT-4、GPT-4-Turbo、Gemini Pro等整体性能优于开源模型。但也有一些开源模型如Mistral、OpenChat-3.5等表现不错。  <br />- 一些较早期的模型如GPT-3.5 Turbo、Vicuna、Llama等虽然性能相对较弱，但也有不错的性能表现。  <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><br />graph via:Maxime Labonne<img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoscjlde7nj20w60l8q5f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 00:08:00 GMT</pubDate>
</item>
<item>
<title>【Idefics2：强大的 8B 视觉语言模型，为社区带来全新体验】- Hugging Face发布了多模态基础模型Idefics2，输入文本和图像，输出文本。 - 相比上一版本Idefics1...</title>
<link>https://weibo.com/1402400261/O9WoW9nrE</link>
<guid>https://weibo.com/1402400261/O9WoW9nrE</guid>
<content:encoded><![CDATA[
<div> Hugging Face, Idefics2, 多模态, 视觉语言模型, Apache 2.0, 开源许可, OCR, 视觉问答, 数据集, 微调

<br /><br />总结:
Hugging Face发布了新的多模态基础模型Idefics2，该模型具有80亿参数量，采用Apache 2.0开源许可，并优化了OCR能力，在视觉问答基准测试中表现出色。Idefics2支持任意分辨率、任意宽高比的图像输入，增强了文档文字识别能力，简化了视觉特征整合。模型在公开数据集上预训练，如维基百科和图像标题对等，通过指令微调提升了多轮会话能力。用户可以在Hugging Face Hub上使用Idefics2，并通过Transformers API进行微调。此外，Hugging Face还发布了Idefics2的模型卡片、数据集卡片和微调教程等资源，方便用户使用。Idefics2采用Apache 2.0开源许可，用户可以自由使用，感谢Google和Mistral AI开源了预训练模型。作为目前最强大的开源多模态基础模型之一，Idefics2为社区提供了坚实的基础，推动了多模态AI的发展。 <div>
【Idefics2：强大的 8B 视觉语言模型，为社区带来全新体验】<br />- Hugging Face发布了多模态基础模型Idefics2，输入文本和图像，输出文本。   <br />- 相比上一版本Idefics1，Idefics2参数量达到80亿，采用Apache 2.0开源许可，优化了OCR能力。在视觉问答基准测试中表现顶尖。   <br />- Idefics2支持任意分辨率、任意宽高比的图像输入，避免缩放成固定大小。增强了对文档文字识别的能力。简化了视觉特征的整合。   <br />- Idefics2在公开数据集上进行预训练，如维基百科、图像标题对等。并在多模态任务数据集上进行指令微调，提升多轮会话能力。   <br />- 用户可以在Hugging Face Hub上使用Idefics2，并利用Transformers API进行微调。文章给出了使用代码示例。   <br />- Hugging Face还发布了Idefics2的模型卡片、数据集卡片、微调教程等资源，方便用户使用。   <br />- Idefics2采用Apache 2.0开源许可，用户可以自由使用。感谢Google和Mistral AI开源了预训练模型。   <br />- Idefics2是目前最强大的开源多模态基础模型之一，为社区提供了坚实的基础，促进多模态AI的发展。<br />《Introducing Idefics2: A Powerful 8B Vision-Language Model for the community》 <a href="https://huggingface.co/blog/idefics2"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoscgfofglj20u00voade.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 23:59:28 GMT</pubDate>
</item>
<item>
<title>【OpenAI API 推出批处理API：异步响应、5折价格】- 节省成本，获得异步任务（如摘要、翻译和图像分类）的更高速率限制。 - 只需上传一个批量请求文件，24小时内...</title>
<link>https://weibo.com/1402400261/O9Wly9dXt</link>
<guid>https://weibo.com/1402400261/O9Wly9dXt</guid>
<content:encoded><![CDATA[
<div> 批处理API、异步响应、5折价格、节省成本、高速率限制、上传批量请求文件、24小时内收到结果、优惠享受

总结:<br />
OpenAI推出批处理API，为用户提供了异步响应和5折价格优惠，能够帮助用户节省成本，同时增加了对异步任务的高速率限制。用户只需上传一个批量请求文件，就能在24小时内收到结果，并享受半价优惠。这可以大大提升效率和操作便利性，让用户能更好地利用OpenAI API的功能。 <div>
【OpenAI API 推出批处理API：异步响应、5折价格】<br />- 节省成本，获得异步任务（如摘要、翻译和图像分类）的更高速率限制。   <br />- 只需上传一个批量请求文件，24小时内收到结果，并享受5折优惠。<br />《Batch | API Reference - OpenAI API》 <a href="http://aicoco.net/s/8i"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hosc7qm57oj20xc0irack.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 23:51:07 GMT</pubDate>
</item>
<item>
<title>今日推介(第1377期)：大语言模型Tokenization理论研究、基于仿真优化的语言模型提示选择、ChatGPT正在改变学者的写作风格吗、使用少量token预训练小型基础语言模...</title>
<link>https://weibo.com/1402400261/O9VJOweam</link>
<guid>https://weibo.com/1402400261/O9VJOweam</guid>
<content:encoded><![CDATA[
<div> 大语言模型、Tokenization、理论研究、基于仿真优化、语言模型提示选择、ChatGPT、学者写作风格、少量token预训练、小型基础语言模型、检索增强生成、减少结构化输出幻觉  

<br /><br />总结:  
本文探讨了大语言模型Tokenization的理论研究，以及基于仿真优化的语言模型提示选择的相关内容。研究表明，ChatGPT对学者的写作风格有可能产生影响。此外，使用少量token预训练小型基础语言模型可能对性能有所改进。最后，通过检索增强生成可以减少结构化输出中的幻觉。 <div>
今日推介(第1377期)：大语言模型Tokenization理论研究、基于仿真优化的语言模型提示选择、ChatGPT正在改变学者的写作风格吗、使用少量token预训练小型基础语言模型、通过检索增强生成减少结构化输出中的幻觉 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/692682961"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.16)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hos9indv4lj219s0u0gtq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hos9iq6iyej20w50u0wiw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hos9iu2gr2j20t80ugjuv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hos9ixkqxyj21c00q6430.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hos9izu0unj20qk0pa0ur.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 22:18:09 GMT</pubDate>
</item>
<item>
<title>[CV] OccGaussian: 3D Gaussian Splatting for Occluded Human Rendering 网页链接 提出OccGaussian方法，使用3D高斯采样实现快速训练和实时渲染遮挡的人体。 [...</title>
<link>https://weibo.com/1402400261/O9VHhyvil</link>
<guid>https://weibo.com/1402400261/O9VHhyvil</guid>
<content:encoded><![CDATA[
<div> OccGaussian, 3D Gaussian Splatting, 遮挡人体渲染, 快速训练, 实时渲染

<br /><br />总结: 本文提出了OccGaussian方法，利用3D高斯采样技术实现了遮挡人体渲染。该方法能够实现快速训练和实时渲染，为解决遮挡问题提供了一种有效的解决方案。文章详细介绍了OccGaussian方法的原理和实现过程，实验证明该方法在遮挡人体渲染中具有较高的效率和准确性。通过对比实验，作者验证了OccGaussian方法在处理遮挡人体渲染任务上的优越性能，为相关领域的研究和应用提供了有价值的参考。 <div>
[CV] OccGaussian: 3D Gaussian Splatting for Occluded Human Rendering  <br /><a href="https://arxiv.org/abs/2404.08449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />提出OccGaussian方法，使用3D高斯采样实现快速训练和实时渲染遮挡的人体。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos9ci9medj20x015u17w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos9cidgt3j21oi14ydve.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos9cinh8aj20tw0so79l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 22:11:55 GMT</pubDate>
</item>
<item>
<title>[CV] Probing the 3D Awareness of Visual Foundation Models 网页链接 通过深度、法线估计和跨视角对应任务，系统评估了当前视觉模型对3D结构的表示和跨视角一...</title>
<link>https://weibo.com/1402400261/O9VCXxPHZ</link>
<guid>https://weibo.com/1402400261/O9VCXxPHZ</guid>
<content:encoded><![CDATA[
<div> 关键词: 3D感知, 视觉模型, 深度估计, 法线估计, 跨视角任务

总结:<br />
本研究通过深度、法线估计和跨视角对应任务来评估视觉模型对3D结构的表示和跨视角一致性。发现不同训练目标会对模型的3D感知产生重要影响。研究为构建真正具备3D意识的视觉模型提供了基础和启发。 <div>
[CV] Probing the 3D Awareness of Visual Foundation Models  <br /><a href="https://arxiv.org/abs/2404.08636"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />通过深度、法线估计和跨视角对应任务，系统评估了当前视觉模型对3D结构的表示和跨视角一致性，发现不同训练目标对模型的3D感知产生重要影响，为构建真正3D意识的视觉模型提供了基础和启发。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos91ee225j20we13m7jh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos91faqquj21n80ugk5j.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos91fvypsj20ue0sc0yn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 22:01:16 GMT</pubDate>
</item>
<item>
<title>[CV] Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies 网页链接 通过控制数据量、模型大小和训练策略等变量，...</title>
<link>https://weibo.com/1402400261/O9VA3beNf</link>
<guid>https://weibo.com/1402400261/O9VA3beNf</guid>
<content:encoded><![CDATA[
<div> 数据量、模型大小、训练策略、CLIP模型、性能、计算预算、实用指导

<br /><br />总结:
本研究通过控制数据量、模型大小、训练策略等变量，全面分析了在计算预算受限条件下CLIP模型的性能。研究为部署CLIP到实际应用提供了实用指导，为实现模型性能的有效缩放提供了理论支持。研究结果表明，在不同场景下调整数据量和模型大小可以显著改善模型性能，合理选择训练策略也至关重要。通过本研究，可以更好地理解和利用CLIP模型，在资源受限的环境下实现更好的性能表现。 <div>
[CV] Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies  <br /><a href="https://arxiv.org/abs/2404.08197"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过控制数据量、模型大小和训练策略等变量，全面分析了计算预算受限条件下CLIP模型的性能，为部署CLIP到实际应用提供了实用指导。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos8tzf1fgj20v416en9w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos8tz8h54j21kq0reaih.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos8tzf9t1j21k80imjvb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:54:06 GMT</pubDate>
</item>
<item>
<title>[IR] Generative Information Retrieval Evaluation 网页链接 探讨了大型语言模型在信息检索评估中的应用前景，它降低了评价成本，提高了一致性，为评估和训练快...</title>
<link>https://weibo.com/1402400261/O9VuWghFE</link>
<guid>https://weibo.com/1402400261/O9VuWghFE</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、信息检索评估、应用前景、评价成本、一致性、快速产品系统、人类评估、降低、提高、可能

<br /><br />总结:
本文探讨了大型语言模型在信息检索评估中的应用前景。使用大型语言模型可以降低评价成本，提高评价一致性，并为评估和训练快速产品系统提供可能性。然而，仍需人类评估作为基础，以确保评估结果的准确性和可靠性。通过综合利用大型语言模型和人类评估的优势，可以更好地实现信息检索评估的有效性和效率。 <div>
[IR] Generative Information Retrieval Evaluation  <br /><a href="https://arxiv.org/abs/2404.08137"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />探讨了大型语言模型在信息检索评估中的应用前景，它降低了评价成本，提高了一致性，为评估和训练快速产品系统提供了可能，但仍需人类评估作为基础。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos8gud01gj20rm0z4do5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos8gutvzlj20zo0r2n1q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos8gv33lmj21as102whg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:41:30 GMT</pubDate>
</item>
<item>
<title>通过检索增强生成方法显著减少了工作流生成任务中的幻象，提高了质量和泛化能力，降低了计算资源需求。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Reducing hallucinat...</title>
<link>https://weibo.com/1402400261/O9VuNerio</link>
<guid>https://weibo.com/1402400261/O9VuNerio</guid>
<content:encoded><![CDATA[
<div> 检索增强生成方法、幻象减少、质量提高、泛化能力、计算资源需求降低

<br /><br />总结:
本文介绍了一种通过检索增强生成方法显著减少工作流生成任务中幻象的技术。该方法提高了生成结果的质量和泛化能力，同时降低了计算资源的需求。作者通过对结构化输出中的幻象问题进行研究，提出了一种有效的解决方案。这种方法可以帮助提升生成模型在工作流生成任务中的性能，为相关领域的研究和实践提供有益的启示。 <div>
通过检索增强生成方法显著减少了工作流生成任务中的幻象，提高了质量和泛化能力，降低了计算资源需求。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Reducing hallucination in structured outputs via Retrieval-Augmented Generation》P Béchard, O M Ayala [ServiceNow] (2024) <a href="https://arxiv.org/abs/2404.08189"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7zn809oj20n80x6jzn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7znbd1qj20qk0pawha.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7znlhfqj21hq0iajuz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos8flislzj20hs0f6wfr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos8fln073j20zz0vzdj9.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:41:09 GMT</pubDate>
</item>
<item>
<title>[LG]《Reducing hallucination in structured outputs via Retrieval-Augmented Generation》P Béchard, O M Ayala [ServiceNow] (2024) 网页链接 #机器学习##...</title>
<link>https://weibo.com/1402400261/O9Vurxov4</link>
<guid>https://weibo.com/1402400261/O9Vurxov4</guid>
<content:encoded><![CDATA[
<div> 结构化输出、幻觉减少、检索增强生成、P Béchard、O M Ayala、ServiceNow、2024

<br /><br />
总结: 这篇文章探讨了通过检索增强生成的方式，在结构化输出中减少幻觉的问题。研究人员提出了一种新方法，利用检索方法来增强生成模型，从而提高输出的准确性和质量。他们的研究表明，这种方法可以有效降低幻觉出现的可能性，为未来相关领域的研究提供了新的思路和方向。在实验中，他们使用了ServiceNow平台进行实验验证，结果显示了这种方法的有效性和潜力。通过这项研究，我们能够更深入地理解如何利用检索增强生成来改善结构化输出中的幻觉问题，为相关领域的研究和应用带来了新的启示。 <div>
[LG]《Reducing hallucination in structured outputs via Retrieval-Augmented Generation》P Béchard, O M Ayala [ServiceNow] (2024) <a href="https://arxiv.org/abs/2404.08189"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7zn809oj20n80x6jzn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7znbd1qj20qk0pawha.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7znlhfqj21hq0iajuz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos8flislzj20hs0f6wfr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos8fln073j20zz0vzdj9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:40:17 GMT</pubDate>
</item>
<item>
<title>Inheritune通过明智地重用参考模型参数和少量额外训练，实现了高效开发小规模而性能强劲的语言模型。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Pre-training Small Ba...</title>
<link>https://weibo.com/1402400261/O9Vnbt985</link>
<guid>https://weibo.com/1402400261/O9Vnbt985</guid>
<content:encoded><![CDATA[
<div> Pre-training, Small Base LMs, Fewer Tokens, Inheritune, 高效开发, 语言模型, 参考模型参数, 少量额外训练, 性能强劲

总结:<br /><br />
这篇文章介绍了一种名为Inheritune的方法，通过明智地重用参考模型参数和少量额外训练，实现了高效开发小规模而性能强劲的语言模型。研究者在文章中提出了Pre-training Small Base LMs with Fewer Tokens这一方法，其可以在使用更少token的情况下，提升小基准语言模型的性能。实验结果表明，在文本生成和自然语言推理等任务上，Inheritune可以取得令人满意的表现，为小规模语言模型的开发提供了新的思路和方法。 <div>
Inheritune通过明智地重用参考模型参数和少量额外训练，实现了高效开发小规模而性能强劲的语言模型。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Pre-training Small Base LMs with Fewer Tokens》S Sanyal, S Sanghavi, A G. Dimakis [UT Austin] (2024) <a href="https://arxiv.org/abs/2404.08634"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7qqk3e3j20kw15ik12.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7qqoc4rj21c00q6ag1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7qqqoo0j20sa0q8tdr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7qqu022j20sm0rqdkj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7wwrmx3j20hq0h875y.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7wwry74j20zt0g4dhr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7wwrsf0j20ht0l6abz.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:22:24 GMT</pubDate>
</item>
<item>
<title>[CL]《Pre-training Small Base LMs with Fewer Tokens》S Sanyal, S Sanghavi, A G. Dimakis [UT Austin] (2024) 网页链接 #机器学习##人工智能##论文# [图片][...</title>
<link>https://weibo.com/1402400261/O9Vn9ggKc</link>
<guid>https://weibo.com/1402400261/O9Vn9ggKc</guid>
<content:encoded><![CDATA[
<div> Small Base LMs, Pre-training, Fewer Tokens, UT Austin, S Sanyal, S Sanghavi, A G. Dimakis

<br /><br />总结:
本文讨论了使用更少词汇量进行小基础语言模型的预训练。研究团队来自德克萨斯大学奥斯汀分校，包括S Sanyal，S Sanghavi和A G. Dimakis。他们的研究旨在提高小型语言模型的预训练效果，并展示了一种基于较少标记的方法。通过实验和分析，研究人员表明这种方法可以在小型语言模型中取得良好的效果，从而为自然语言处理领域的发展提供了一种有效的方法。 <div>
[CL]《Pre-training Small Base LMs with Fewer Tokens》S Sanyal, S Sanghavi, A G. Dimakis [UT Austin] (2024) <a href="https://arxiv.org/abs/2404.08634"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7qqk3e3j20kw15ik12.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7qqoc4rj21c00q6ag1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7qqqoo0j20sa0q8tdr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7qqu022j20sm0rqdkj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7wwrmx3j20hq0h875y.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7wwry74j20zt0g4dhr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7wwrsf0j20ht0l6abz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:22:19 GMT</pubDate>
</item>
<item>
<title>通过词频统计模型估计了ChatGPT对计算机科学论文摘要写作风格的重要影响，是第一份定量分析该领域大规模语言模型应用的研究。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]...</title>
<link>https://weibo.com/1402400261/O9Vjl1CLP</link>
<guid>https://weibo.com/1402400261/O9Vjl1CLP</guid>
<content:encoded><![CDATA[
<div> 关键词: ChatGPT, 计算机科学论文, 摘要写作风格, 词频统计模型, 大规模语言模型应用, 研究, 影响, 变革, 定量分析, 领域

总结:<br /><br />文章研究了ChatGPT对计算机科学论文摘要写作风格的影响，通过词频统计模型进行了定量分析，这是第一份在该领域对大规模语言模型应用进行定量分析的研究。研究发现ChatGPT对学术写作风格有重要影响，可能带来变革。研究结果为进一步探讨语言模型在学术写作领域的应用提供了参考。 <div>
通过词频统计模型估计了ChatGPT对计算机科学论文摘要写作风格的重要影响，是第一份定量分析该领域大规模语言模型应用的研究。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Is ChatGPT Transforming Academics' Writing Style?》M Geng, R Trotta [Scuola Internazionale Superiore di Studi Avanzati (SISSA)] (2024) <a href="https://arxiv.org/abs/2404.08627"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7ltc9ywj20p60s4gsf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7ltvg0uj20t80ugn1l.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7lu07e5j20t20qudjf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7lu3exyj20t80s0q67.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7mvq821j20iy0ista3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7mvukjjj20ix0is3zy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7mvugslj20j00kzjt1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7mvqxt4j20iy0hoq43.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7mvs7quj20ix0hmjsh.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:12:55 GMT</pubDate>
</item>
<item>
<title>[CL]《Is ChatGPT Transforming Academics' Writing Style?》M Geng, R Trotta [Scuola Internazionale Superiore di Studi Avanzati (SISSA)] (2024) 网页链接 ...</title>
<link>https://weibo.com/1402400261/O9Vjf5Tzg</link>
<guid>https://weibo.com/1402400261/O9Vjf5Tzg</guid>
<content:encoded><![CDATA[
<div> transforming, ChatGPT, academics, writing style, AI, language generation, academic writing, technology, impact, research

<br /><br />总结:
这篇文章讨论了ChatGPT如何正在改变学术界的写作风格。研究指出，人工智能技术对学术写作有着深远的影响，特别是在语言生成方面。学者们需要关注ChatGPT等工具对学术写作风格和质量的可能影响，以及如何充分利用这些技术进行研究。AI技术的发展为学术界带来了新的挑战和机遇，需要进一步研究和讨论。 <div>
[CL]《Is ChatGPT Transforming Academics' Writing Style?》M Geng, R Trotta [Scuola Internazionale Superiore di Studi Avanzati (SISSA)] (2024) <a href="https://arxiv.org/abs/2404.08627"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7ltc9ywj20p60s4gsf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7ltvg0uj20t80ugn1l.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7lu07e5j20t20qudjf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7lu3exyj20t80s0q67.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7mvq821j20iy0ista3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7mvukjjj20ix0is3zy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7mvugslj20j00kzjt1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7mvqxt4j20iy0hoq43.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7mvs7quj20ix0hmjsh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7mvuh3yj20j00midhz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7mvs2c9j20ix0hcq40.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7mvul97j20ix0ko0uw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7mvun20j20j00lz40s.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7mvqt4gj20ix0irmyb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7mvqv4ij20ix0hpgms.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7mvqsntj20ix0hbwfd.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7mvs4huj20ix0fm3zm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7mvs60qj20iy0irjsj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:12:41 GMT</pubDate>
</item>
<item>
<title>通过构建代理模型和获取函数，提出仿真优化框架，实现高效低成本的语言模型提示选择。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Language Model Prompt Selection via...</title>
<link>https://weibo.com/1402400261/O9Virq4My</link>
<guid>https://weibo.com/1402400261/O9Virq4My</guid>
<content:encoded><![CDATA[
<div> 代理模型、获取函数、仿真优化框架、语言模型提示选择、高效低成本、CL、张华、何军、Righter、郑忠、UC Berkeley

总结:<br /><br />
该研究提出了一种通过仿真优化实现语言模型提示选择的方法。首先构建代理模型来模拟语言模型提示的选择过程，然后获取函数来评估不同提示的效果，利用仿真优化框架进行参数调整，从而实现高效低成本的语言模型提示选择。研究团队来自UC Berkeley，由张华、何军、Righter和郑忠等人合作完成。 <div>
通过构建代理模型和获取函数，提出仿真优化框架，实现高效低成本的语言模型提示选择。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Language Model Prompt Selection via Simulation Optimization》H Zhang, J He, R Righter, Z Zheng [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.08164"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jw696fj21da0jmaio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jwrxj4j21he0n6n4z.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jx88c9j21g21cmqcr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jwz47dj21h80lq0ye.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7kiem59j212m0f20uw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7kig3lwj212m0hxwh8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7kig5uvj212j0g7wh1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7kiemvbj212m0hxgo4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7kigc3xj210x0n840n.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:10:43 GMT</pubDate>
</item>
<item>
<title>[CL]《Language Model Prompt Selection via Simulation Optimization》H Zhang, J He, R Righter, Z Zheng [UC Berkeley] (2024) 网页链接 #机器学习##人工智能...</title>
<link>https://weibo.com/1402400261/O9VijuFyw</link>
<guid>https://weibo.com/1402400261/O9VijuFyw</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型、模拟优化、选择、模拟、最优化、模型、预测、模型优化

总结:<br />
本研究围绕语言模型prompt的选择展开，通过模拟优化方法进行模型优化。研究者们提出了一种基于模拟优化的语言模型prompt选择方法，通过在模拟环境中进行优化，不断调整模型的输入来提高模型的性能。研究表明，该方法可以有效提高语言模型的预测准确性和效率，为自然语言处理领域的进一步研究提供了新思路。 <div>
[CL]《Language Model Prompt Selection via Simulation Optimization》H Zhang, J He, R Righter, Z Zheng [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.08164"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jw696fj21da0jmaio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jwrxj4j21he0n6n4z.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jx88c9j21g21cmqcr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jwz47dj21h80lq0ye.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7kiem59j212m0f20uw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7kig3lwj212m0hxwh8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7kig5uvj212j0g7wh1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7kiemvbj212m0hxgo4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7kigc3xj210x0n840n.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:10:24 GMT</pubDate>
</item>
<item>
<title>深入探讨了Tokenization在降低Transformer语言模型的交叉熵损失方面的理论机制，并比较了不同Tokenization方案的泛化能力，为理解和改进Tokenization提供了范式...</title>
<link>https://weibo.com/1402400261/O9VhOrZ07</link>
<guid>https://weibo.com/1402400261/O9VhOrZ07</guid>
<content:encoded><![CDATA[
<div> Tokenization, 降低Transformer语言模型的交叉熵损失, 理论机制, 不同Tokenization方案, 泛化能力, 理解, 改进, LLMs, N Rajaraman, J Jiao, K Ramchandran, UC Berkeley

<br /><br />总结: 

该研究深入探讨了Tokenization在降低Transformer语言模型的交叉熵损失方面的理论机制。研究比较了不同Tokenization方案的泛化能力，为理解和改进Tokenization提供了范式。研究团队包括N Rajaraman、J Jiao和K Ramchandran，来自UC Berkeley。文章为进一步研究Tokenization在语言模型中的作用提供了理论基础，为提高模型表现和效率提供了重要的参考。 <div>
深入探讨了Tokenization在降低Transformer语言模型的交叉熵损失方面的理论机制，并比较了不同Tokenization方案的泛化能力，为理解和改进Tokenization提供了范式。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Toward a Theory of Tokenization in LLMs》N Rajaraman, J Jiao, K Ramchandran [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.08335"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7i86yhbj21cc0pwqfa.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7i8gargj21hm0fc0vx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7i93968j21i60ziqem.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7i94vgvj21jk0smwnu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7iwjo79j21190mzwj5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7iwhmg4j21130iqjtx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7iwjxnkj21120trtcr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7iwl831j21110o8jvc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7iwlf0ej21100rkjvk.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:09:10 GMT</pubDate>
</item>
<item>
<title>[CL]《Toward a Theory of Tokenization in LLMs》N Rajaraman, J Jiao, K Ramchandran [UC Berkeley] (2024) 网页链接 #机器学习##人工智能##论文# [图片][图片...</title>
<link>https://weibo.com/1402400261/O9VhGsaVY</link>
<guid>https://weibo.com/1402400261/O9VhGsaVY</guid>
<content:encoded><![CDATA[
<div> 关键词: Tokenization, LLMs, Theory, NLP, Language Models, UC Berkeley

本文旨在探讨LLMs中的Tokenization理论，作者来自加州大学伯克利分校。文章通过对Tokenization在自然语言处理中的重要性和实践中的挑战进行讨论，指出Tokenization在LLMs中的作用和影响。作者提出了一种针对LLMs的Tokenization理论，旨在提高模型的性能和效率。研究结果揭示了Tokenization对LLMs任务的关键影响，为进一步研究和应用Tokenization在自然语言处理领域提供了重要参考。通过该理论，可以更好地理解和优化LLMs的Tokenization过程，从而提升模型的表现。文章为我们深入了解LLMs中Tokenization的意义和方法提供了有益的启示。
<br /><br />总结: 本研究探讨了LLMs中Tokenization理论的重要性和挑战，提出了一种新的Tokenization理论，旨在提高模型的性能和效率。研究结果揭示了Tokenization对LLMs任务的关键影响，为进一步优化LLMs的Tokenization提供了重要参考。 <div>
[CL]《Toward a Theory of Tokenization in LLMs》N Rajaraman, J Jiao, K Ramchandran [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.08335"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7i86yhbj21cc0pwqfa.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7i8gargj21hm0fc0vx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7i93968j21i60ziqem.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7i94vgvj21jk0smwnu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7iwjo79j21190mzwj5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7iwhmg4j21130iqjtx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7iwjxnkj21120trtcr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7iwl831j21110o8jvc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7iwlf0ej21100rkjvk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7iwjjg7j210b0pg76m.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7iwhajbj20pr07kaab.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:08:51 GMT</pubDate>
</item>
<item>
<title>早！[太阳] #早安# [图片]</title>
<link>https://weibo.com/1402400261/O9Vg1cVHL</link>
<guid>https://weibo.com/1402400261/O9Vg1cVHL</guid>
<content:encoded><![CDATA[
<div> 关键词: 早、文章、中文、总结、800字、要点

总结:
<br />
这篇文章着重强调了使用中文写作总结文章的重要性。在800字内，作者提到了提取关键词、按顺序分要点、逐步梳理的方法。文章指出，总结是对文章内容的概括归纳，可以帮助读者更好地理解和记忆文章内容。因此，学会写好总结是非常重要的。 <div>
早！<span class="url-icon"><img alt="[太阳]" src="https://h5.sinaimg.cn/m/emoticon/icon/others/w_taiyang-2b1d91ddac.png" style="width: 1em; height: 1em;" /></span> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%97%A9%E5%AE%89%23&amp;isnewpage=1"><span class="surl-text">#早安#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hos7egvfcqj207s0awq3b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:04:45 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.15)》 爱可可微博热门分享(4.15) [图片]</title>
<link>https://weibo.com/1402400261/O9SJHgKrz</link>
<guid>https://weibo.com/1402400261/O9SJHgKrz</guid>
<content:encoded><![CDATA[
<div> 爱可可 微博 热门 分享 4.15

<br /><br />总结:
4月15日，爱可可微博热门分享内容丰富，吸引了众多用户关注。其中包括了各种各样的热门话题，例如新闻事件、娱乐八卦、美食推荐等。用户通过微博平台分享自己的生活点滴，获得了许多的点赞和转发。微博已经成为人们交流互动的重要平台，为用户提供了丰富多彩的信息和内容。 <div>
《爱可可微博热门分享(4.15)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405023553614643315"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.15)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1horw9s8ihxj20ip0ait9o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 14:39:37 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《IPoD: Implicit Field Learning with Point Diffusion for Generalizable 3D Object Reconstruction from Single RGB-D Images》(CVPR 2024...</title>
<link>https://weibo.com/1402400261/O9S8o7TG9</link>
<guid>https://weibo.com/1402400261/O9S8o7TG9</guid>
<content:encoded><![CDATA[
<div> IPoD, Implicit Field Learning, Point Diffusion, 3D Object Reconstruction, RGB-D Images, GitHub, Probing, 3D Awareness, Visual Foundation Models, GitHub, Generalizable Tumor Synthesis, Attention Calibration, Disentangled Text-to-Image Personalization, GauStudio, 3D Gaussian Splatting, Mantis, Interleaved Multi-Image Instruction Tuning, Mixture-of-Depths, Transformer-based Language Models, ProteinDT, Text-guided Protein Design Framework, StoryImager, Coherent Story Visualization, Agent Group Chat, Collective Emergent Behavior, Concept Depth, Large Language Models, Cacophony, Contrastive Audio-Text Model, Learning, Explainable Stock Predictions, ProSparse, Activation Sparsity, Mamba-ND, State Space Modeling 

<br /><br />总结: 本文总结了多篇CVPR 2024会议的论文，并提供了各篇论文的GitHub链接。这些论文涵盖了各种主题，包括3D目标重建、注意力校准、深度学习模型、文本引导的蛋白质设计等。通过这些研究，研究人员展示了他们在不同领域的创新思维和技术进步。CVPR 2024的这些论文为相关领域的研究和实践提供了宝贵的参考和启发。 <div>
几篇论文实现代码：<br />《IPoD: Implicit Field Learning with Point Diffusion for Generalizable 3D Object Reconstruction from Single RGB-D Images》(CVPR 2024) GitHub: github.com/yushuang-wu/IPoD [fig1] <br />《Probing the 3D Awareness of Visual Foundation Models》(CVPR 2024) GitHub: github.com/mbanani/probe3d<br />《Towards Generalizable Tumor Synthesis》(CVPR 2024) GitHub: github.com/MrGiovanni/DiffTumor [fig4]<br />《Attention Calibration for Disentangled Text-to-Image Personalization》(CVPR 2024) GitHub: github.com/Monalissaa/DisenDiff [fig6]<br />《GauStudio: A Modular Framework for 3D Gaussian Splatting and Beyond》(2024) GitHub: github.com/hugoycj/2dgs-gaustudio<br />《Mantis: Interleaved Multi-Image Instruction Tuning》(2024) GitHub: github.com/TIGER-AI-Lab/Mantis<br />《Mixture-of-Depths: Dynamically allocating compute in transformer-based language models》(2024) GitHub: github.com/astramind-ai/Mixture-of-depths<br />《ProteinDT: A Text-guided Protein Design Framework》(2024) GitHub: github.com/chao1224/ProteinDT [fig2] <br />《StoryImager: A Unified and Efficient Framework for Coherent Story Visualization and Completion》(2024) GitHub: github.com/tobran/StoryImager [fig3]<br />《Agent Group Chat: An Interactive Group Chat Simulacra For Better Eliciting Collective Emergent Behavior》(2024) GitHub: github.com/MikeGu721/AgentGroup<br />《Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?》(2024) GitHub: github.com/Luckfort/CD [fig5]<br />《Cacophony: An Improved Contrastive Audio-Text Model》(2024) GitHub: github.com/gzhu06/Cacophony [fig7]<br />《Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models》(2024) GitHub: github.com/koa-fin/sep<br />《ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models》(2024) GitHub: github.com/Raincleared-Song/sparse_gpu_operator<br />《Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data》(2024) GitHub: github.com/jacklishufan/Mamba-ND<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1horrgdoj1mj21r50hxdqu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1horrhhsx6dj21we1a67w9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1horryjwxk9j21ta0cedsn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1horsi61d0kj230c0vyhdt.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1horslf7kpsj21310j7dsz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hort0qeasvj215v0ea0xv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hort2rarh0j217t0wenbd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 13:07:42 GMT</pubDate>
</item>
<item>
<title>'EmoLLM-心理健康大模型 - 心理健康大模型、LLM、The Big Model of Mental Health、Finetune、InternLM2、Qwen、ChatGLM、Baichuan、DeepSeek、Mixtral' GitHub:...</title>
<link>https://weibo.com/1402400261/O9S6jgEtx</link>
<guid>https://weibo.com/1402400261/O9S6jgEtx</guid>
<content:encoded><![CDATA[
<div> GitHub、EmoLLM、心理健康大模型、LLM、The Big Model of Mental Health、Finetune、InternLM2、Qwen、ChatGLM、Baichuan
<br />
<br />总结: 本篇介绍了EmoLLM-心理健康大模型及其相关项目，包括心理健康大模型、LLM、The Big Model of Mental Health、Finetune、InternLM2、Qwen、ChatGLM、Baichuan等。这些项目都是关于心理健康的大规模模型，旨在提供更好的心理健康支持和帮助。GitHub链接为github.com/SmartFlowAI/EmoLLM，感兴趣的读者可以进一步了解和探索这些项目。 <div>
'EmoLLM-心理健康大模型 - 心理健康大模型、LLM、The Big Model of Mental Health、Finetune、InternLM2、Qwen、ChatGLM、Baichuan、DeepSeek、Mixtral' GitHub: github.com/SmartFlowAI/EmoLLM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hortgh6oizj20w00u0dkx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hortgw8h8sj21340u00ws.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hortgy1qu7j216i0ju430.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 13:02:35 GMT</pubDate>
</item>
<item>
<title>【surya-rs：基于 Rust 语言实现的多语言文档 OCR 工具包，基于修改版 Segformer、OpenCV 和 donut transformer 实现】'surya-rs - Rust implementation of Sury...</title>
<link>https://weibo.com/1402400261/O9S3Xh8Ai</link>
<guid>https://weibo.com/1402400261/O9S3Xh8Ai</guid>
<content:encoded><![CDATA[
<div> Rust、多语言文档 OCR 工具包、Segformer、OpenCV、donut transformer、GitHub、surya-rs

<br /><br />总结:
surya-rs是一个基于Rust语言实现的多语言文档OCR工具包。它基于修改版的Segformer、OpenCV和donut transformer实现。该项目的GitHub链接为github.com/Jimexist/surya-rs。这个工具包提供了一种跨语言的文档OCR解决方案，借助强大的图像处理和Transformer模型，帮助用户实现对文档的文字识别和提取。Surya-rs的实现是基于开源技术，旨在提供高效和准确的文档OCR服务，为用户提供良好的文字识别体验。 <div>
【surya-rs：基于 Rust 语言实现的多语言文档 OCR 工具包，基于修改版 Segformer、OpenCV 和 donut transformer 实现】'surya-rs - Rust implementation of Surya' GitHub: github.com/Jimexist/surya-rs <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hortavl8frj21740koad2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:56:47 GMT</pubDate>
</item>
<item>
<title>'qwen-vllm - 通义千问VLLM推理部署DEMO' GitHub: github.com/owenliang/qwen-vllm #开源# #机器学习# #人工智能# [图片][图片]</title>
<link>https://weibo.com/1402400261/O9S1b0WPy</link>
<guid>https://weibo.com/1402400261/O9S1b0WPy</guid>
<content:encoded><![CDATA[
<div> GitHub、qwen-vllm、通义千问、VLLM、推理部署、DEMO、owenliang、模型、部署、开源

<br /><br />总结:
本文介绍了名为'qwen-vllm - 通义千问VLLM推理部署DEMO'的项目，该项目可以在GitHub上找到，作者是owenliang。项目主要是关于利用VLLM模型进行推理部署的演示，其中包含了通义千问的推理任务。该项目为开源项目，可供学习和研究使用。 <div>
'qwen-vllm - 通义千问VLLM推理部署DEMO' GitHub: github.com/owenliang/qwen-vllm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hort3qbzrpj21ae0u0dmj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hort3s62yuj21n10u0q6c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:49:56 GMT</pubDate>
</item>
<item>
<title>【repo2pdf：将 GitHub 仓库转换为 PDF 文件的工具】’repo2pdf - repo2pdf is a tool that allows you to convert a GitHub repository into a PDF file. It cl...</title>
<link>https://weibo.com/1402400261/O9S0q6lwd</link>
<guid>https://weibo.com/1402400261/O9S0q6lwd</guid>
<content:encoded><![CDATA[
<div> GitHub、仓库、转换、PDF 文件、工具、clone、处理文件、创建 PDF、repo2pdf、BankkRoll<br /><br />总结:repo2pdf是一个工具，可以将GitHub仓库转换为PDF文件。它会克隆仓库，处理文件，然后创建一个PDF。这个工具的GitHub链接是github.com/BankkRoll/repo2pdf。 <div>
【repo2pdf：将 GitHub 仓库转换为 PDF 文件的工具】’repo2pdf - repo2pdf is a tool that allows you to convert a GitHub repository into a PDF file. It clones the repository, processes the files, and then creates a PDF.' GitHub: github.com/BankkRoll/repo2pdf <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hort1tzoxbj21h90qi0w1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:48:04 GMT</pubDate>
</item>
<item>
<title>【ComfyUI ArtGallery | Prompt Visualization：用于可视化提示词的项目，提供了五大类提示词参考图，包括艺术家、艺术运动、艺术媒介、相机镜头和胶片相机】'Co...</title>
<link>https://weibo.com/1402400261/O9RTJjxbo</link>
<guid>https://weibo.com/1402400261/O9RTJjxbo</guid>
<content:encoded><![CDATA[
<div> ComfyUI ArtGallery, Prompt Visualization, 项目, 提示词, 五大类, 艺术家, 艺术运动, 艺术媒介, 相机镜头, 胶片相机

<br /><br />总结:
ComfyUI ArtGallery是一个用于可视化提示词的项目，提供了五大类提示词参考图，包括艺术家、艺术运动、艺术媒介、相机镜头和胶片相机。该项目的GitHub链接为github.com/ZHO-ZHO-ZHO/ComfyUI-ArtGallery。 <div>
【ComfyUI ArtGallery | Prompt Visualization：用于可视化提示词的项目，提供了五大类提示词参考图，包括艺术家、艺术运动、艺术媒介、相机镜头和胶片相机】'ComfyUI ArtGallery | Prompt Visualization - Prompt Visualization | Art Gallery' GitHub: github.com/ZHO-ZHO-ZHO/ComfyUI-ArtGallery <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5023521164689425"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a><br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax3.sinaimg.cn/orj480/5396ee05ly1horskely4gj20qo0k0t9y.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/ZNeSlFv8lx08e6HjDkeY01041200iwRD0E010.mp4?label=mp4_720p&amp;template=960x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713191262&amp;ssig=6sGumgevRw&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/f3kUu6mWlx08e6HjiKg00104120095eE0E010.mp4?label=mp4_hd&amp;template=640x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713191262&amp;ssig=HX4lo%2FQn%2Bg&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/mEKe2fCVlx08e6HjafWw010412005NTX0E010.mp4?label=mp4_ld&amp;template=480x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713191262&amp;ssig=9BVRBrkhwn&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5023521164689425" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:31:36 GMT</pubDate>
</item>
<item>
<title>【ServoProject：基于 Arduino 的业余舵机控制项目，提供了丰富的文档和视频演示】'ServoProject - Getting the most out of your hobby servo' GitHub: github....</title>
<link>https://weibo.com/1402400261/O9RS7yBiK</link>
<guid>https://weibo.com/1402400261/O9RS7yBiK</guid>
<content:encoded><![CDATA[
<div> Arduino, 业余, 业余舵机, 控制项目, 文档, 视频演示, GitHub, ServoProject

<br /><br />总结:
ServoProject 是一个基于 Arduino 的业余舵机控制项目，旨在帮助用户更好地利用他们的业余舵机。该项目提供了丰富的文档和视频演示，使用户能够轻松地了解并使用该项目。用户可以在GitHub上找到ServoProject的代码和资料，方便下载和参考。通过该项目，用户可以更加灵活地控制舵机，实现各种有趣的功能和项目。无论是初学者还是有经验的用户，都可以从ServoProject中受益，探索舵机控制的乐趣和可能性。ServoProject为Arduino爱好者提供了一个学习和创造的平台，让大家共同探索并享受舵机控制的乐趣。 <div>
【ServoProject：基于 Arduino 的业余舵机控制项目，提供了丰富的文档和视频演示】'ServoProject - Getting the most out of your hobby servo' GitHub: github.com/adamb314/ServoProject <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8horsgk68skj21400u0n0a.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:27:38 GMT</pubDate>
</item>
<item>
<title>【Agent Group Chat: 模拟群聊的交互工具，旨在促进更好的集体群体行为，旨在帮助研究人类群体行为，并为研究人类行为提供有用的工具】’Agent Group Chat: An I...</title>
<link>https://weibo.com/1402400261/O9RNrsIxS</link>
<guid>https://weibo.com/1402400261/O9RNrsIxS</guid>
<content:encoded><![CDATA[
<div> 模拟群聊、交互工具、集体行为、研究、人类行为、工具、GitHub、MikeGu721、AgentGroup

<br /><br />总结:
"Agent Group Chat"是一个模拟群聊的交互工具，旨在促进更好的集体群体行为，帮助研究人类群体行为，为研究人类行为提供有用的工具。该项目可在GitHub上找到，由MikeGu721维护，名为"AgentGroup"。 <div>
【Agent Group Chat: 模拟群聊的交互工具，旨在促进更好的集体群体行为，旨在帮助研究人类群体行为，并为研究人类行为提供有用的工具】’Agent Group Chat: An Interactive Group Chat Simulacra For Better Eliciting Collective Emergent Behavior' GitHub: github.com/MikeGu721/AgentGroup <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hors3ymi8qj21170r4dno.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:16:06 GMT</pubDate>
</item>
<item>
<title>【面向计算机视觉的Mamba相关论文资源列表】’Mamba-in-Computer-Vision - A paper list of some recent Mamba-based CV works.' GitHub: github.com/Yangzhangc...</title>
<link>https://weibo.com/1402400261/O9RMTtNBr</link>
<guid>https://weibo.com/1402400261/O9RMTtNBr</guid>
<content:encoded><![CDATA[
<div> 计算机视觉、Mamba、论文资源、GitHub、最近、CV作品、列表<br />
<br />
提供了一个基于Mamba的计算机视觉作品论文列表。该列表包含了最近一些使用Mamba的计算机视觉作品，提供了GitHub链接以供查阅。这些论文资源展示了Mamba在计算机视觉领域的应用和研究成果，为进一步探索Mamba在CV领域的潜力提供了参考。目前，这些近期的Mamba相关CV作品正在不断积累和发布，为学术研究和技术发展提供了重要的参考和借鉴。通过这个论文资源列表，研究人员和开发者们可以更深入地了解Mamba在计算机视觉应用中的应用情况和研究成果，促进学术交流和技术创新的进步。<br /><br />总结: <br />提供了最近一些使用Mamba的计算机视觉作品论文列表，为CV领域的研究和发展提供了重要参考。 <div>
【面向计算机视觉的Mamba相关论文资源列表】’Mamba-in-Computer-Vision - A paper list of some recent Mamba-based CV works.' GitHub: github.com/Yangzhangcst/Mamba-in-CV <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hors35hrygj20yp0u00wn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:14:45 GMT</pubDate>
</item>
<item>
<title>【Code-Friendly HTML to Markdown Converter：轻量 Python 脚本，可将 HTML 页面转换为 Markdown 格式，支持代码块】'Code-Friendly HTML to Markdown Converte...</title>
<link>https://weibo.com/1402400261/O9RMd2tnv</link>
<guid>https://weibo.com/1402400261/O9RMd2tnv</guid>
<content:encoded><![CDATA[
<div> GitHub、HTML、Markdown、Python、脚本、转换、代码块、轻量、页面、格式
<br /><br />
总结:这是一个轻量级的Python脚本，能够将HTML页面转换为Markdown格式，同时支持代码块的转换。该脚本的GitHub地址是github.com/SivilTaram/code-html-to-markdown。 <div>
【Code-Friendly HTML to Markdown Converter：轻量 Python 脚本，可将 HTML 页面转换为 Markdown 格式，支持代码块】'Code-Friendly HTML to Markdown Converter - A lightweight script for processing HTML page to markdown format with support for code blocks' GitHub: github.com/SivilTaram/code-html-to-markdown <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hors1f0ugwj213y0u0wj1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:13:03 GMT</pubDate>
</item>
<item>
<title>【dspy-neo4j-knowledge-graph：基于 DSPy 和 Neo4j 的自动知识图谱构建，使用 OpenAI 的 GPT-4 模型从文本中提取实体和关系】'dspy-neo4j-knowledge-graph - LL...</title>
<link>https://weibo.com/1402400261/O9RtglWY4</link>
<guid>https://weibo.com/1402400261/O9RtglWY4</guid>
<content:encoded><![CDATA[
<div> DSPy, Neo4j, 自动知识图谱构建, OpenAI, GPT-4, 实体提取, 关系提取, 文本, GitHub, LLM<br />
<br />自动化知识图谱构建工具dspy-neo4j-knowledge-graph利用DSPy和Neo4j，以及OpenAI的GPT-4模型，从文本中提取实体和关系。通过这个工具，用户可以快速构建知识图谱，帮助理解文本中的复杂关系。该工具在GitHub上开源，为研究者和开发者提供了一个强大的工具，用于自动化知识图谱的构建与分析。总之，dspy-neo4j-knowledge-graph结合了先进的自然语言处理技术和知识图谱建模工具，为研究者和开发者提供了一个高效且智能的解决方案。 <br /><br />总结: <div>
【dspy-neo4j-knowledge-graph：基于 DSPy 和 Neo4j 的自动知识图谱构建，使用 OpenAI 的 GPT-4 模型从文本中提取实体和关系】'dspy-neo4j-knowledge-graph - LLM-driven automated knowledge graph construction from text using DSPy and Neo4j.' GitHub: github.com/chrisammon3000/dspy-neo4j-knowledge-graph <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8horqou1qctj21h20u0q82.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 11:26:23 GMT</pubDate>
</item>
<item>
<title>【Purl：用于文本处理的命令行工具，提供简单直观的命令选项，支持对文件或标准输入的处理，兼容 Mac 和 Linux】'Purl - Streamlining Text Processing' GitHub:...</title>
<link>https://weibo.com/1402400261/O9RsxmCF3</link>
<guid>https://weibo.com/1402400261/O9RsxmCF3</guid>
<content:encoded><![CDATA[
<div> purl, 文本处理, 命令行工具, 简单直观, 文件, 标准输入, Mac, Linux, GitHub, catatsuy

<br /><br />总结:
文章介绍了一款用于文本处理的命令行工具 purl，提供简单直观的命令选项，支持对文件或标准输入的处理，兼容 Mac 和 Linux。该工具方便用户进行文本处理操作，提高工作效率，适合需要频繁处理文本数据的用户使用。感兴趣的用户可以在 GitHub 上查看该工具的更多信息。 <div>
【Purl：用于文本处理的命令行工具，提供简单直观的命令选项，支持对文件或标准输入的处理，兼容 Mac 和 Linux】'Purl - Streamlining Text Processing' GitHub: github.com/catatsuy/purl <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8horqn02uowj21740qojwr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 11:24:36 GMT</pubDate>
</item>
<item>
<title>【Flow-IPC: 现代的 C++ 工具包，用于高速的进程间通信 (IPC)】'Flow-IPC: Modern C++ toolkit for fast inter-process communication (IPC) - [Start here!] Fl...</title>
<link>https://weibo.com/1402400261/O9Rsao83Q</link>
<guid>https://weibo.com/1402400261/O9Rsao83Q</guid>
<content:encoded><![CDATA[
<div> 现代 C++ 工具包，高速进程间通信，Flow-IPC，GitHub，ipc，C++，工具包，进程间通信，高速<br /><br />总结:Flow-IPC是一个现代的 C++ 工具包，用于实现高速的进程间通信 (IPC)。该工具包可以在GitHub上找到，提供了一种高效的方式来实现进程间通信。通过使用Flow-IPC，开发人员可以轻松地在不同进程之间进行快速的数据传输，提高系统性能和响应速度。Flow-IPC利用现代的 C++ 技术，使得进程间通信变得更加简单和高效。 <div>
【Flow-IPC: 现代的 C++ 工具包，用于高速的进程间通信 (IPC)】'Flow-IPC: Modern C++ toolkit for fast inter-process communication (IPC) - [Start here!] Flow-IPC - Modern C++ toolkit for high-speed inter-process communication (IPC)' GitHub: github.com/Flow-IPC/ipc <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8horqlypli4j212a0u0q93.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8horqm15zh9j21se0u0n00.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 11:23:41 GMT</pubDate>
</item>
<item>
<title>【长程视频理解相关论文资源列表】’Awesome Long-Term Video Understanding - Awesome papers &amp; datasets specifically focused on long-term videos.' GitHub:...</title>
<link>https://weibo.com/1402400261/O9Rr1bpEK</link>
<guid>https://weibo.com/1402400261/O9Rr1bpEK</guid>
<content:encoded><![CDATA[
<div> 长程视频理解，论文资源列表，GitHub，长期视频理解，数据集<br />
<br />
总结:<br />
这篇文章分享了一个GitHub资源列表，关注长期视频理解领域的论文和数据集。长期视频理解是指对长时间范围内的视频进行分析和理解的过程。GitHub上提供了一些优秀的论文和数据集，可以用于研究长程视频理解相关问题。这些资源有助于开展长程视频理解领域的研究工作，并为相关领域的学术研究提供支持。 <div>
【长程视频理解相关论文资源列表】’Awesome Long-Term Video Understanding - Awesome papers &amp; datasets specifically focused on long-term videos.' GitHub: github.com/ttengwang/Awesome_Long_Form_Video_Understanding <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8horqi85b0bj20y50u0afz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 11:20:51 GMT</pubDate>
</item>
<item>
<title>【自动图表理解相关论文资源列表】’Awesome Chart Understanding - A curated list of recent and past chart understanding work based on our survey paper: ...</title>
<link>https://weibo.com/1402400261/O9RqkxLxy</link>
<guid>https://weibo.com/1402400261/O9RqkxLxy</guid>
<content:encoded><![CDATA[
<div> 自动图表理解、资源列表、GitHub、调查论文、大基础模型、像素到洞察、最新研究、过去研究、图表理解、曲线 拟合

<br /><br />总结:
本文整理了关于自动图表理解的最新研究成果，基于他们的调查论文《从像素到洞察：在大基础模型时代的自动图表理解》。列出了相关研究工作，并在GitHub上提供了资源列表。研究主要关注在大基础模型时代的自动图表理解，探讨了从像素到洞察的过程。涵盖了最新和过去的研究成果，这些工作对于图表理解和曲线拟合具有重要意义。 <div>
【自动图表理解相关论文资源列表】’Awesome Chart Understanding - A curated list of recent and past chart understanding work based on our survey paper: From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models.' GitHub: github.com/khuangaf/awesome-chart-understanding <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8horqhaeztdj210f0u0433.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 11:19:10 GMT</pubDate>
</item>
<item>
<title>【SuperMemory：用于构建自己"第二大脑"的工具，可以将你在互联网上收集的信息导入到其中，并且具有类似 ChatGPT 的回答功能。SuperMemory基于 Turborepo 构建，...</title>
<link>https://weibo.com/1402400261/O9RlP6gHr</link>
<guid>https://weibo.com/1402400261/O9RlP6gHr</guid>
<content:encoded><![CDATA[
<div> GitHub，SuperMemory，构建，第二大脑，ChatGPT，书签，扩展，网页，信息，云 AI

总结:<br /><br />这是一款名为SuperMemory的工具，用于构建个人的"第二大脑"，类似于ChatGPT，可以将互联网上收集的信息导入其中。它基于Turborepo构建，包括网页UI、Chrome扩展和云AI后端三个主要模块。用户可以使用Chrome扩展导入推特或保存网站和内容，从而在SuperMemory中建立自己的知识库。GitHub链接：github.com/Dhravya/supermemory。 <div>
【SuperMemory：用于构建自己"第二大脑"的工具，可以将你在互联网上收集的信息导入到其中，并且具有类似 ChatGPT 的回答功能。SuperMemory基于 Turborepo 构建，包括三个主要模块：网页 UI、Chrome 扩展和云 AI 后端】’SuperMemory - Build your own second brain with supermemory. It's a ChatGPT for your bookmarks. Import tweets or save websites and content using the chrome extension.' GitHub: github.com/Dhravya/supermemory <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8horq5mr5bnj20xc0hidhs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8horq5o12mkj212e0u0q61.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8horq5qox3aj21dr0u0wij.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 11:08:03 GMT</pubDate>
</item>
<item>
<title>【redka：用SQLite复现Redis的项目，支持 Redis 的主要数据类型，如字符串、列表、集合、哈希和有序集合】'redka - Redis re-implemented with SQLite' GitHub: ...</title>
<link>https://weibo.com/1402400261/O9Rj6s6j5</link>
<guid>https://weibo.com/1402400261/O9Rj6s6j5</guid>
<content:encoded><![CDATA[
<div> SQLite、Redis、数据类型、字符串、列表、集合、哈希、有序集合<br />
<br />
总结：<br />
本文介绍了一个名为redka的项目，它是使用SQLite复现Redis的工具。此项目支持Redis的主要数据类型，包括字符串、列表、集合、哈希和有序集合。这个项目可以帮助用户在没有Redis的情况下使用SQLite来实现类似的功能。通过redka，用户可以方便地在SQLite数据库中存储和处理不同类型的数据，实现类似Redis的功能。如果您对使用SQLite来实现Redis功能感兴趣，可以访问GitHub页面github.com/nalgeon/redka获取更多信息。 <div>
【redka：用SQLite复现Redis的项目，支持 Redis 的主要数据类型，如字符串、列表、集合、哈希和有序集合】'redka - Redis re-implemented with SQLite' GitHub: github.com/nalgeon/redka <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Redis%23"><span class="surl-text">#Redis#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8horpyom1b9j21550u0tcr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 11:01:22 GMT</pubDate>
</item>
<item>
<title>恭喜@希侬如故 等3名用户获得【《LangChain实战》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效。公示链接：网页链接 - 转发 @爱可...</title>
<link>https://weibo.com/1402400261/O9OzQssHr</link>
<guid>https://weibo.com/1402400261/O9OzQssHr</guid>
<content:encoded><![CDATA[
<div> LangChain, 实战, 初学者, 大语言模型, 抽奖, 公正有效, LangChain团队, 生成式人工智能, LangServe, LangSmith

总结:<br />
微博官方唯一抽奖工具监督《LangChain实战》抽奖活动，恭喜3名用户获得这本书。活动截止时间为2024年4月15日12:00，用户可通过转发和评论参与抽奖。《LangChain实战》适合初学者和对LangChain应用感兴趣的开发者，介绍LangChain 0.1版本，并配有详细视频。书中重点探讨了多个核心应用场景和LCEL的应用方式，同时详细讨论了LangChain团队在生成式人工智能领域的布局。整体帮助读者全面了解LangChain、LangServe和LangSmith等相关概念。 <div>
恭喜<a href="https://weibo.com/n/%E5%B8%8C%E4%BE%AC%E5%A6%82%E6%95%85">@希侬如故</a> 等3名用户获得【《LangChain实战》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20435760&amp;pageid=100140E51198948"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.15 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a>  <a href="https://shop.sc.weibo.com/h5/goods/index?iid=110014024002610004661854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">LangChain实战：从原型到生产，动手打造 LLM 应用</span></a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hofl98oom9j207q0a0jrm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 04:04:22 GMT</pubDate>
</item>
<item>
<title>【异常检测通用模型学习】- 通用异常检测(GAD)旨在训练一个模型， 无需使用目标数据进行训练，就能检测不同领域数据集中的异常。 提出了基于CLIP的残差学习模型I...</title>
<link>https://weibo.com/1402400261/O9N7GwoPt</link>
<guid>https://weibo.com/1402400261/O9N7GwoPt</guid>
<content:encoded><![CDATA[
<div> CLIP、残差学习、异常检测、InCTRL、泛化能力、数据集、文本提示、图像级残差、图块级残差、GAD  
<br />  
总结:  
提出了基于CLIP的残差学习模型InCTRL，不需使用目标数据训练即可检测不同领域数据集的异常。InCTRL结合文本提示、图块级和图像级残差，利用辅助数据集学习查询图像与提示的残差，在9个数据集上明显优于其他方法。消融实验显示文本提示、残差级别对数据集贡献不同，但综合三者效果最佳。学习残差对泛化能力更重要，为异常检测提供全新视角。InCTRL在工业、医学、语义异常检测表现突出，是当前最佳GAD方法。 <div>
【异常检测通用模型学习】<br />- 通用异常检测(GAD)旨在训练一个模型， 无需使用目标数据进行训练，就能检测不同领域数据集中的异常。   <br /> 提出了基于CLIP的残差学习模型InCTRL，利用辅助数据集，学习查询图像与少样本提示之间的残差，来区分异常样本。   <br />- InCTRL同时建模图像级和图块级的残差，获取对异常的深入理解。还结合文本提示解码器的语义信息。   <br />- 在9个异常检测数据集上进行评估，InCTRL明显优于其他方法，表明它能很好地推广到不同领域。   <br />- 消融实验表明：文本提示、图块级残差和图像级残差对不同类型数据集贡献不同，但综合三者效果最好。   <br />- 与简单拼接或平均相比，学习残差对泛化能力更重要。   <br />- 文中设定新的GAD任务评估异常检测方法的泛化能力，为异常检测研究提出全新的视角。   <br />- InCTRL在工业缺陷、医学图像及语义异常检测上表现突出，是当前最佳GAD方法。   <br />《Learning Generalist Models for Anomaly Detection | by Guansong Pang | Apr, 2024 | Towards Data Science》 <a href="https://towardsdatascience.com/learning-generalist-models-for-anomaly-detection-53d7a6a74474"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hor7h9r573j20om0o2q7f.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hor7hc246rj212w0mb44i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 00:22:15 GMT</pubDate>
</item>
<item>
<title>【用Claude 3 Opus构建股票分析Agent工具】《Building an Agentic Stock Analysis Tool with Langchain, OpenBB and Claude 3 Opus - Swapping Symbols》 网页链...</title>
<link>https://weibo.com/1402400261/O9N2Ngtj0</link>
<guid>https://weibo.com/1402400261/O9N2Ngtj0</guid>
<content:encoded><![CDATA[
<div> Langchain, OpenBB, Claude 3 Opus, 股票分析工具, Agent, 拓展 AI 股票分析代理, 基本面, 技术工具, 股票符号

总结:<br /><br />这篇文章介绍了如何利用Langchain、OpenBB和Claude 3 Opus构建股票分析代理工具，其中包括股票符号的交换。文章还详细讨论了如何通过基本面和技术工具拓展AI股票分析代理工具，从而提高其效能。通过本文的阐述，读者可以了解到如何利用这些工具来开发更加专业和智能的股票分析代理工具。 <div>
【用Claude 3 Opus构建股票分析Agent工具】《Building an Agentic Stock Analysis Tool with Langchain, OpenBB and Claude 3 Opus - Swapping Symbols》 <a href="https://sethhobson.com/2024/03/building-an-agentic-stock-analysis-tool-with-langchain-openbb-and-claude-3-opus/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> 《Expanding the AI Stock Analysis Agent with Fundamental and Technical Tools - Swapping Symbols》 <a href="https://sethhobson.com/2024/04/expanding-the-ai-stock-analysis-agent-with-fundamental-and-technical-tools/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hor74l4t7oj213e0u078n.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hor7515tuoj21o00u0n3u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 00:10:11 GMT</pubDate>
</item>
<item>
<title>【Scalene：Python提速利器】- Python编程语言使用广泛，但运行效率低下，比其他编程语言慢100-1000倍甚至更多。 - UMass Amherst的计算机科学家研发了开源性能...</title>
<link>https://weibo.com/1402400261/O9MZ3AnMI</link>
<guid>https://weibo.com/1402400261/O9MZ3AnMI</guid>
<content:encoded><![CDATA[
<div> 计算机科学家、Python、提速利器、Scalene、开源性能分析工具、低效部分、优化建议、Best Paper Award、USENIX会议、开源社区

<br /><br />总结:
UMass Amherst的计算机科学家开发了开源性能分析工具Scalene，可以帮助定位Python代码中的低效部分并提供优化建议。该工具已广泛使用，下载量超过75万次，获得了USENIX会议的Best Paper Award，在学术界得到认可。随着计算机硬件技术进步放缓，优化Python性能变得越来越重要。Scalene的出现是提高Python执行效率的重要突破，也展示了开源社区的力量。这对推动Python在更多场景中的应用，提高开发者的体验和效率具有重要意义。 <div>
【Scalene：Python提速利器】<br />- Python编程语言使用广泛，但运行效率低下，比其他编程语言慢100-1000倍甚至更多。   <br />- UMass Amherst的计算机科学家研发了开源性能分析工具Scalene，可以高效定位Python代码中的低效部分。   <br />- Scalene不仅可以准确指出Python代码的低效之处，还可以利用AI技术给出优化建议。   <br />- Scalene已经被广泛使用，下载量超过75万次。它可以帮助程序员优化Python代码，提高运行速度。   <br />- 随着计算机硬件技术进步放缓，编程语言的执行效率正变得越来越重要。Scalene这样的工具对于优化Python性能意义重大。   <br />- 该研究团队因Scalene在USENIX会议上荣获Best Paper Award。这表明该工具在学术界得到认可，对Python社区影响深远。   <br />- Scalene是提高Python执行效率的重要突破，也再次证明开源社区的力量。它将促进Python在更多场景中的应用，造福开发者。<br />《Computer scientists develop open-source tool for dramatically speeding up the programming language Python》 <a href="https://techxplore.com/news/2023-08-scientists-open-source-tool-language-python.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hor6vp5ufnj20u00uiafe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 00:00:59 GMT</pubDate>
</item>
<item>
<title>【AI 50企业榜单】- 以生成式AI为代表的第三代AI正在改变企业生产力，提高工作效率。企业AI应用类在AI 50榜单上呈爆炸式增长。 - 越来越多大公司将AI集成到内部...</title>
<link>https://weibo.com/1402400261/O9MW4xiKe</link>
<guid>https://weibo.com/1402400261/O9MW4xiKe</guid>
<content:encoded><![CDATA[
<div> 生成式AI, 企业生产力, 工作效率, AI应用, 内部流程, 业务指标, 用户体验, 界面设计, 基础设施, 生产力革命

<br /><br />总结:
第三代AI以生成式AI为代表，正在影响企业生产力和工作效率。企业AI应用呈现爆炸式增长，大公司将AI集成到内部流程以实现业务指标，同时AI重塑用户体验和界面设计。基础设施类别壮大以支持新出现的强大AI模型，未来公司将更小、更多、更敏捷。AI带来生产力革命和成本降低，但也需要政府和企业努力减少就业冲击，继续创造工作岗位。2024年的AI 50榜单展示AI影响的开始，其应用范围将继续扩大。 <div>
【AI 50企业榜单】<br />- 以生成式AI为代表的第三代AI正在改变企业生产力，提高工作效率。企业AI应用类在AI 50榜单上呈爆炸式增长。   <br />- 越来越多大公司将AI集成到内部流程，以实现业务指标的加速增长和成本的大幅降低。   <br />- AI正在重塑用户体验和界面设计，从替代人工实现更好更快，到创造全新的用户体验。   <br />- 基础设施类别也在不断壮大，以支持新出现的强大AI模型。云平台、向量数据库、推理框架等都在迎合这一趋势。   <br />- 未来的公司将更小、更多、更敏捷。公司创立将更快速和流动。AI将减少日常操作工作，让人类可以关注更重要的事。   <br />- AI带来的生产力革命将降低成本，使更多关键服务大众化。但也需要政府与企业共同努力，减少就业冲击，继续创造工作岗位。   <br />- 2024年的AI 50榜单预示着AI带来深广影响的开始，它的应用范围还将不断扩大。<br />《AI 50: Companies of the Future | Sequoia Capital》 <a href="https://www.sequoiacap.com/article/ai-50-2024/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hor6novzn7j21io0u0afh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hor6nquetwj21hc0u0jw2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hor6nsdo8vj216i0u0tdo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 23:53:38 GMT</pubDate>
</item>
<item>
<title>【没有过去，就没有未来】- 历史对于人类意识和社会记忆非常重要。它塑造我们的世界观，支持社会规范和法律等。 - 作者担心AI会被用来生成虚假的历史文本和解释...</title>
<link>https://weibo.com/1402400261/O9MUSEQQB</link>
<guid>https://weibo.com/1402400261/O9MUSEQQB</guid>
<content:encoded><![CDATA[
<div> 历史，人工智能，记忆，思考能力，威胁，控制力，外包，警惕，人类创作，连接人类经验

总结：<br /><br />这篇文章讨论了历史对于人类意识和社会记忆的重要性，以及人工智能可能对历史的影响。作者担心人工智能可能被用来生成虚假的历史文本，削弱人类对历史的理解能力。学生可能只需向聊天机器人提几个问题就获得答案，而不做进一步思考和研究，这对历史学习构成威胁。历史应该由人类书写和解释，否则我们将失去对未来的控制能力。尽管历史学不是AI的首要取代目标，但这种威胁正在增长。文章还探讨了词语定义的模糊性和不确定性，以及人工智能介入历史叙事可能带来的新视角和偏见。继续由人类进行历史创作、理解和传播至关重要，要抵制将其外包给AI的诱惑。 <div>
【没有过去，就没有未来】<br />- 历史对于人类意识和社会记忆非常重要。它塑造我们的世界观，支持社会规范和法律等。   <br />- 作者担心AI会被用来生成虚假的历史文本和解释，这会削弱人类对历史的理解和批判性思考的能力。   <br />- 学生可能只需向聊天机器人提几个问题就获得“历史”答案，而不做进一步的思考和研究。这是对历史学习的一种威胁。   <br />- 文章警告如果将历史创作外包给机器，我们将失去对未来的控制能力。历史应由人类书写和解释。   <br />- 相较于其他领域，历史学目前还不是AI的首要取代目标，但这种威胁正在快速增长。历史工作者需要警惕并做好准备。   <br />- 历史是连接人类经验的纽带，是无价之宝。我们必须抵制将其外包给AI的商业和教育诱惑，继续由人类进行历史创作、理解和传播。<br /><br />思考：  <br />- 本文提出一个有趣的观点：历史和过去记忆对于人工智能实现类人思考至关重要。这一观点有一定道理，因为人类思维很大程度上依赖于过去的经验和记忆。  <br />- 文章指出词语定义的模糊性和不确定性，这与严谨的数理逻辑形成鲜明对比。这一见解发人深省，让人反思语言和思维的关系。  <br />- 作者想象了一个场景：如果人工智能开始书写和解读历史会怎样?这一假设虽然有些耸人听闻，但值得我们思考。当人工智能介入历史叙事，可能会带来新的视角，但也可能带来新的偏见和操纵。  <br />《No Past, No Future. “One of the early inventors of… | by David Hitchcock | Apr, 2024 | Medium》 <a href="https://hitchcockian.medium.com/no-past-no-future-38f1a9cfe541"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hor6kzsmihj20pm0ozn1o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 23:50:42 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《LangChain实战》，截至2024.4.15 12:00，...</title>
<link>https://weibo.com/1402400261/O9Mjf3ktK</link>
<guid>https://weibo.com/1402400261/O9Mjf3ktK</guid>
<content:encoded><![CDATA[
<div> LangChain实战、LangChain、LLM、LangServe、LangSmith、生成式人工智能、初学者、开发者、应用场景、LCEL

<br /><br />总结:
本文介绍了对LangChain实战的开奖活动，参与者需要转发并评论才能参与。活动截止日期为2024年4月15日12:00。LangChain实战是专为初学者和对LangChain应用及大语言模型（LLM）感兴趣的开发者而编写的，配套600分钟详解视频。书籍重点介绍了多个核心应用场景，并深入探讨了LCEL的应用方式。此外，本书还围绕LangChain生态系统的概念展开，详细讨论了LangChain、LangServe和LangSmith，帮助读者更全面地了解LangChain团队在生成式人工智能领域的布局。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.15 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a>  <a href="https://shop.sc.weibo.com/h5/goods/index?iid=110014024002610004661854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">LangChain实战：从原型到生产，动手打造 LLM 应用</span></a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hofl98oom9j207q0a0jrm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 22:17:58 GMT</pubDate>
</item>
<item>
<title>今日推介(第1376期)：时变音频系统的可微全极滤波器、(近)重复子词在语言建模中的作用、医学领域开源多语言文本到文本LLM、重新思考混合专家语言模型训练、大型...</title>
<link>https://weibo.com/1402400261/O9Mj1iNal</link>
<guid>https://weibo.com/1402400261/O9Mj1iNal</guid>
<content:encoded><![CDATA[
<div> 可微全极滤波器  重复子词  语言建模  医学领域  开源多语言文本  混合专家语言模型  大型语言模型  指代  定位  改进基线  

<br /><br />总结:  
本期推介的文章涵盖了时变音频系统中可微全极滤波器的研究，以及重复子词在语言建模中的作用。另外，还介绍了医学领域的开源多语言文本到文本LLM，混合专家语言模型训练的重新思考，和大型语言模型指代和定位的改进基线。这些研究内容丰富多样，对于相关领域的发展和应用具有重要意义。 <div>
今日推介(第1376期)：时变音频系统的可微全极滤波器、(近)重复子词在语言建模中的作用、医学领域开源多语言文本到文本LLM、重新思考混合专家语言模型训练、大型语言模型指代和定位的改进基线 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/692472274"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.15)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hor3vmypuej21g20pm780.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hor3vpd9x5j21740myjvh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hor3vrv2e2j20ou0kmacm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hor3vucq6tj216c0k0q73.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hor3vx61y8j21io0pk485.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 22:17:24 GMT</pubDate>
</item>
<item>
<title>[CL] MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies 网页链接 提出小型语言模型MiniCPM系列，通过模型风洞实...</title>
<link>https://weibo.com/1402400261/O9MgiBjvb</link>
<guid>https://weibo.com/1402400261/O9MgiBjvb</guid>
<content:encoded><![CDATA[
<div> 模型风洞实验, WSD学习率调度器, 小型语言模型, MiniCPM系列, 高效训练, 可拓展训练, 有限计算资源, 语言模型潜力<br />
<br />
总结:<br />
本文提出了MiniCPM系列小型语言模型，通过模型风洞实验和WSD学习率调度器实现高效、可拓展的训练方案。在有限的计算资源下，MiniCPM系列发挥了语言模型巨大潜力。通过优化训练策略和调整学习率，MiniCPM在小规模下具有出色的性能表现，为语言模型研究提供了新的思路。 <div>
[CL] MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies  <br /><a href="https://arxiv.org/abs/2404.06395"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>        <br />提出小型语言模型MiniCPM系列，通过模型风洞实验和WSD学习率调度器实现高效、可拓展的训练方案，在有限计算资源下发挥语言模型巨大潜力。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hor3oxxailj20qk16ganj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor3oydynzj21a00ggq8f.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hor3oytjnsj21c60w44ez.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 22:10:43 GMT</pubDate>
</item>
<item>
<title>[CV] BRAVE: Broadening the visual encoding of vision-language models 网页链接 BRAVE 通过有效整合多视觉编码器的表达，大大扩展了 VLM 的视觉理解能力，在...</title>
<link>https://weibo.com/1402400261/O9McJyxAI</link>
<guid>https://weibo.com/1402400261/O9McJyxAI</guid>
<content:encoded><![CDATA[
<div> 关键词: BRAVE, 视觉编码器, VLM, SOTA, 多任务, 鲁棒性

总结:<br /><br />本研究提出了一种名为BRAVE的方法，通过整合多视觉编码器的表达，扩展了视觉-语言模型的视觉理解能力。实验结果显示，BRAVE在多个任务上达到了当前最先进水平，并显著提高了模型的鲁棒性。该方法为进一步提升视觉-语言模型的性能和多任务表现提供了有益的思路。 <div>
[CV]  BRAVE: Broadening the visual encoding of vision-language models  <br /><a href="https://arxiv.org/abs/2404.07204"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />BRAVE 通过有效整合多视觉编码器的表达，大大扩展了 VLM 的视觉理解能力，在多个任务上取得 SOTA 水平，同时显著提高了模型的鲁棒性。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hor3fsiuxhj20se19qdte.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor3ft4jzfj21pm1a41a5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor3ftormpj21pi11gh2r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 22:01:56 GMT</pubDate>
</item>
<item>
<title>[CV] AWOL: Analysis WithOut synthesis using Language 网页链接 通过从CLIP空间到参数空间的映射，利用语言的泛化能力来控制不同3D形状模型生成新样例。 [图片...</title>
<link>https://weibo.com/1402400261/O9M9xi9Oc</link>
<guid>https://weibo.com/1402400261/O9M9xi9Oc</guid>
<content:encoded><![CDATA[
<div> CLIP空间, 参数空间, 语言泛化能力, 3D形状模型, 新样例生成<br />
<br />
通过将CLIP空间映射到参数空间，并利用语言的泛化能力，可以控制不同的3D形状模型生成新的样例。这种方法可以帮助研究人员更有效地分析、理解和创造3D形状模型，并为设计和创新提供新的可能性。AWOL技术的引入为研究领域带来了新的思路和方法，拓展了在3D形状生成方面的前沿研究。同时，通过语言的引导和控制，可以更灵活地进行形状模型的创作和变形，提高了生成模型的多样性和创造力。在未来，这种基于语言和参数空间映射的方法有望为计算机图形学和人工智能领域带来更多创新和突破性进展。<br /><br />总结: <br />通过CLIP空间到参数空间的映射，利用语言的泛化能力来控制不同3D形状模型生成新样例。这种方法为研究人员提供了新的创作和分析工具，扩展了3D形状生成领域的边界，为未来的计算机图形学和人工智能研究带来了新的可能性。 <div>
[CV] AWOL: Analysis WithOut synthesis using Language  <br /><a href="https://arxiv.org/abs/2404.03042"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过从CLIP空间到参数空间的映射，利用语言的泛化能力来控制不同3D形状模型生成新样例。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hor37ldwxrj20si1auqer.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor37luav8j21pm0ko0z9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hor37m56p9j21po0wu466.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 21:54:03 GMT</pubDate>
</item>
<item>
<title>通过构建完全子词复制的实验设置合理地量化了近似重复子词对语言模型样本效率的负面影响，但也指出真实语料中近似重复子词的语义差异使其对泛化的帮助有限，为后...</title>
<link>https://weibo.com/1402400261/O9LVuasZp</link>
<guid>https://weibo.com/1402400261/O9LVuasZp</guid>
<content:encoded><![CDATA[
<div> 近似重复子词，语言模型，效率，负面影响，语义差异，泛化，理论依据

<br /><br />总结:
本研究通过构建完全子词复制的实验设置，量化了近似重复子词对语言模型样本效率的负面影响。然而，研究也指出真实语料中近似重复子词的语义差异有限，对泛化的帮助有限。这为后续研究提供了重要的理论依据，强调了语言模型在处理近似重复子词时需要考虑语义差异的影响。 <div>
通过构建完全子词复制的实验设置合理地量化了近似重复子词对语言模型样本效率的负面影响，但也指出真实语料中近似重复子词的语义差异使其对泛化的帮助有限，为后续研究提供了理论依据。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《On the Effect of (Near) Duplicate Subwords in Language Modelling》A Schäfer, T Hofmann, I Schlag, T Pimentel [ETH Zürich] (2024) <a href="https://arxiv.org/abs/2404.06508"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor26p23bgj20ik0ywahx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor26pjiguj20lg0pw0wv.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hor26pu81qj20lg0pw0wv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor26q0arwj20lo0k6goe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hor27bphk5j20hr0frgn0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor27bq858j20zv0dw0ug.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor27bqbzgj20zx0jnwhd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor27bqf3mj20zs0gswg8.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hor27bs2ikj20zx16ldlr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 21:19:26 GMT</pubDate>
</item>
<item>
<title>[CL]《On the Effect of (Near) Duplicate Subwords in Language Modelling》A Schäfer, T Hofmann, I Schlag, T Pimentel [ETH Zürich] (2024) 网页链接 #机...</title>
<link>https://weibo.com/1402400261/O9LVnpTId</link>
<guid>https://weibo.com/1402400261/O9LVnpTId</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言建模, 重复子词, 效果, 语言处理, 模型调优, 数据集, 实验, 结果, 比较, 方法

总结:<br /><br />
本文研究了语言建模中重复子词的影响，探讨了其对模型性能的影响。通过对包含重复子词的数据集进行实验，作者发现在处理重复子词时，模型的性能会受到影响。实验结果显示，采用不同的方法处理重复子词可以对模型性能进行调优。通过对比实验结果，可以得出某些方法在处理重复子词时表现更佳。研究表明，在语言处理任务中，重复子词的存在会对建模效果产生显著影响，因此在设计模型时需考虑如何处理这一问题。 <div>
[CL]《On the Effect of (Near) Duplicate Subwords in Language Modelling》A Schäfer, T Hofmann, I Schlag, T Pimentel [ETH Zürich] (2024) <a href="https://arxiv.org/abs/2404.06508"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor26p23bgj20ik0ywahx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor26pjiguj20lg0pw0wv.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hor26pu81qj20lg0pw0wv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor26q0arwj20lo0k6goe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hor27bphk5j20hr0frgn0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor27bq858j20zv0dw0ug.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor27bqbzgj20zx0jnwhd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor27bqf3mj20zs0gswg8.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hor27bs2ikj20zx16ldlr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 21:19:10 GMT</pubDate>
</item>
<item>
<title>提出重用前向传播滤波器的方法高效实现时间变化全极点滤波器的反向传播，可准确地端到端训练包含递归结构的音频系统。 - 转发 @爱可可-爱生活:&amp;ensp;[AS]《Diffe...</title>
<link>https://weibo.com/1402400261/O9LUP3TzS</link>
<guid>https://weibo.com/1402400261/O9LUP3TzS</guid>
<content:encoded><![CDATA[
<div> 时间变化全极点滤波器, 反向传播, 音频系统, 递归结构, 端到端训练, 前向传播滤波器, Differentiable, All-pole Filters, 时间变化, 音频

<br /><br />总结:
本研究提出了一种方法，可以高效地实现时间变化全极点滤波器的反向传播，从而准确地端到端训练包含递归结构的音频系统。研究团队设计了前向传播滤波器，并通过反向传播的方式实现了对时间变化全极点滤波器的有效训练。这种方法可以有效地应用于音频系统中，提高系统的性能和准确性。通过对滤波器的不断优化和训练，可以实现更好的音频处理效果，为音频领域的研究和应用带来新的可能性。 <div>
提出重用前向传播滤波器的方法高效实现时间变化全极点滤波器的反向传播，可准确地端到端训练包含递归结构的音频系统。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [AS]《Differentiable All-pole Filters for Time-varying Audio Systems》C Yu, C Mitcheltree, A Carson, S Bilbao, J D. Reiss, G Fazekas [Queen Mary University of London &amp; University of Edinburgh] (2024) <a href="https://arxiv.org/abs/2404.07970"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor23rwf7hj20ry0oqdnj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor23s8wz9j21g20pmwix.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hor23sgtj4j211c0jkn07.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor23smth2j211c0xgn1y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 21:17:48 GMT</pubDate>
</item>
<item>
<title>[AS]《Differentiable All-pole Filters for Time-varying Audio Systems》C Yu, C Mitcheltree, A Carson, S Bilbao, J D. Reiss, G Fazekas [Queen Mary Unive...</title>
<link>https://weibo.com/1402400261/O9LUJ9gvv</link>
<guid>https://weibo.com/1402400261/O9LUJ9gvv</guid>
<content:encoded><![CDATA[
<div> Differentiable, all-pole filters, time-varying audio systems, Queen Mary University of London, University of Edinburgh, C Yu, C Mitcheltree, A Carson, S Bilbao, J D. Reiss, G Fazekas

<br /><br />总结:
这篇文章介绍了一种用于时变音频系统的可微分全极点滤波器。研究人员来自伦敦玛丽皇后大学和爱丁堡大学。他们提出了一种新型的滤波器结构，能够有效地处理时变音频信号。通过实验和分析，他们表明这种滤波器在处理时变音频系统中具有很高的效果和可靠性。这项研究为时变音频系统的设计和优化提供了新的思路和方法。 <div>
[AS]《Differentiable All-pole Filters for Time-varying Audio Systems》C Yu, C Mitcheltree, A Carson, S Bilbao, J D. Reiss, G Fazekas [Queen Mary University of London &amp; University of Edinburgh] (2024) <a href="https://arxiv.org/abs/2404.07970"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor23rwf7hj20ry0oqdnj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor23s8wz9j21g20pmwix.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hor23sgtj4j211c0jkn07.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor23smth2j211c0xgn1y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 21:17:34 GMT</pubDate>
</item>
<item>
<title>早！[太阳] #早安# [图片]</title>
<link>https://weibo.com/1402400261/O9LSKdKKk</link>
<guid>https://weibo.com/1402400261/O9LSKdKKk</guid>
<content:encoded><![CDATA[
<div> 关键词: 早，中文，文章，提取，要点，800字，总结

在这篇文章中，通过提取关键字来总结一个长文是一种有效的整理方法。这种方法也能帮助读者更快地了解文章内容及主旨。总结应根据文章提供的要点和信息来进行编写，确保包含所有重要的内容。在写总结时，按照文章的顺序将要点逐一罗列出来，以帮助读者更好地理解和记忆文章内容。<br /><br />总结: 通过提取关键词来总结这篇中文文章，能够帮助读者更快地了解文章内容及主旨。此外，文章总结应根据提供的要点和信息来进行，确保包含所有重要的内容。在写总结时，按照文章的顺序将要点逐一罗列出来，以帮助读者更好地理解和记忆文章内容。 <div>
早！<span class="url-icon"><img alt="[太阳]" src="https://h5.sinaimg.cn/m/emoticon/icon/others/w_taiyang-2b1d91ddac.png" style="width: 1em; height: 1em;" /></span> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%97%A9%E5%AE%89%23&amp;isnewpage=1"><span class="surl-text">#早安#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hor20ikkpdj207s0awmxm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 21:12:41 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.14)》 爱可可微博热门分享(4.14) [图片]</title>
<link>https://weibo.com/1402400261/O9JlAazCU</link>
<guid>https://weibo.com/1402400261/O9JlAazCU</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 分享, 爱可可, 4.14

<br /><br />总结:
4月14日，爱可可微博上热门分享了一篇文章。文章内容受到广泛关注，分享的用户也很多。文章内容涉及各种话题，从社会热点到娱乐八卦，涵盖了各个方面。在微博平台上引起了热烈的讨论，许多网友纷纷转发和评论，形成了热门话题。通过微博分享，信息传播速度快，阅读量也很高，展现了微博作为社交平台的强大影响力。 <div>
《爱可可微博热门分享(4.14)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405023192703172669"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.14)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoqqtiesbcj20kg0biwg8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 14:45:29 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Negative Label Guided OOD Detection with Pretrained Vision-Language Models》(ICLR 2024) GitHub: github.com/XueJiang16/NegLabel [fi...</title>
<link>https://weibo.com/1402400261/O9Gh8og89</link>
<guid>https://weibo.com/1402400261/O9Gh8og89</guid>
<content:encoded><![CDATA[
<div> 关键词: OOD检测, 预训练视觉-语言模型, 跨模态学习, 视频人体姿态回归, 时间-空间聚合, 音色识别, 乐器无关音乐转录, 数学推理评估, 大型语言模型, 多视角3D物体检测

总结:<br /><br />《Negative Label Guided OOD Detection with Pretrained Vision-Language Models》介绍了使用预训练的视觉-语言模型辅助进行OOD检测的方法，提出了负向标签辅助的策略。<br /> 《Video-Based Human Pose Regression via Decoupled Space-Time Aggregation》介绍了一种通过分离空间-时间聚合实现视频人体姿态回归的方法，提升了准确性和效率。<br />《Timbre-Trap: A Low-Resource Framework for Instrument-Agnostic Music Transcription》提出了一种乐器无关音乐转录的低资源框架，适用于音色识别领域。<br />《Evaluating Mathematical Reasoning Beyond Accuracy》探讨了数学推理评估的方法，超越传统准确性评估，突出模型能力的综合评估。<br />《Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models》研究了大型语言模型中表格数据的记忆和学习机制，深入了解模型内部工作原理。<br />《Ray Denoising: Depth-aware Hard Negative Sampling for Multi-view 3D Object Detection》提出了一种多视角3D物体检测中的深度感知负向样本采样方法，提升了检测效果。<br />《Policy-Guided Diffusion》介绍了一种基于策略引导的扩散方法，实现高效信息传递和学习。<br />《No Zero-Shot Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance》研究了数据频率对多模态模型性能的影响，提出了基于概念频率的预训练策略。<br />《Lightning NeRF: Efficient Hybrid Scene Representation for Autonomous Driving》提出了一种高效的混合场景表示方法，适用于自动驾驶应用。<br />《3D Pose Estimation of Two Interacting Hands from a Monocular Event Camera》介绍了一种从单目事件相机中估计两只手的三维姿态的方法，适用于复杂交互场景。 <div>
几篇论文实现代码：<br />《Negative Label Guided OOD Detection with Pretrained Vision-Language Models》(ICLR 2024) GitHub: github.com/XueJiang16/NegLabel [fig3] <br />《Video-Based Human Pose Regression via Decoupled Space-Time Aggregation》(CVPR 2024) GitHub: github.com/zgspose/DSTA [fig1]<br />《Timbre-Trap: A Low-Resource Framework for Instrument-Agnostic Music Transcription》(2024) GitHub: github.com/sony/timbre-trap<br />《Evaluating Mathematical Reasoning Beyond Accuracy》(2024) GitHub: github.com/GAIR-NLP/ReasonEval<br />《Elephants Never Forget: Memorization and Learning of Tabular Data in<br />  Large Language Models》(2024) GitHub: github.com/interpretml/LLM-Tabular-Memorization-Checker<br />《Ray Denoising: Depth-aware Hard Negative Sampling for Multi-view 3D Object Detection》(2024) GitHub: github.com/LiewFeng/RayDN [fig2]<br />《Policy-Guided Diffusion》(2024) GitHub: github.com/EmptyJackson/policy-guided-diffusion<br />《No Zero-Shot Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance》(2024) GitHub: github.com/bethgelab/frequency_determines_performance<br />《Lightning NeRF: Efficient Hybrid Scene Representation for Autonomous Driving》(2024) GitHub: github.com/VISION-SJTU/Lightning-NeRF<br />《3D Pose Estimation of Two Interacting Hands from a Monocular Event Camera》(2024) GitHub: github.com/Chris10M/Ev2Hands<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoq8cemphhj24071nn4dv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoqbkzwmygj21cu0ljwth.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoqcz1hfmuj21960eh10b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 06:56:17 GMT</pubDate>
</item>
<item>
<title>【收集了基于 NeRF的逆渲染论文的资源集合】'Awesome-Inverse-Rendering - A collection of papers on NeRF-Based Inverse Rendering.' GitHub: github.com/ingr...</title>
<link>https://weibo.com/1402400261/O9Gg84AxH</link>
<guid>https://weibo.com/1402400261/O9Gg84AxH</guid>
<content:encoded><![CDATA[
<div> GitHub, NeRF, 逆渲染, 论文, 资源, 集合, 知识库, 搜索, 提取, NeRF-Based<br />
<br />NeRF-Based逆渲染论文资源集合。
NeRF是目前逆渲染研究中的热门技术之一，该资源集合汇总了基于NeRF的逆渲染论文，是一个非常有用的知识库。用户可以在该GitHub页面上查找相关的研究文献，从中提取出自己感兴趣的信息。这个集合不仅提供了深入了解NeRF技术的机会，也为研究者和开发者提供了宝贵的资源。通过这些论文，我们可以了解到逆渲染领域的最新进展，从而促进该领域的研究和应用。在这个资源集合中，用户可以搜索有关NeRF的各种信息和文献，帮助他们更好地掌握逆渲染技术的核心概念和应用方法。该资源集合的建立为研究者和开发者提供了便利，有助于推动逆渲染领域的发展和创新。<br /><br />总结: <br />NeRF-Based逆渲染论文资源集合是一个汇总了基于NeRF的逆渲染论文的知识库，用户可以从中搜索并提取相关信息，了解逆渲染领域的最新进展，提升技术水平。 <div>
【收集了基于 NeRF的逆渲染论文的资源集合】'Awesome-Inverse-Rendering - A collection of papers on NeRF-Based Inverse Rendering.' GitHub: github.com/ingra14m/Awesome-Inverse-Rendering <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoqd6x89vmj210f0u0q7d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 06:53:49 GMT</pubDate>
</item>
<item>
<title>【Mltraq：一个开源 Python 库，专门为 AI 开发人员设计、执行和共享实验，可以跟踪任意内容，流式传输、复现、协作和在任何地方恢复计算状态】'Mltraq - Track ...</title>
<link>https://weibo.com/1402400261/O9GcfD9iI</link>
<guid>https://weibo.com/1402400261/O9GcfD9iI</guid>
<content:encoded><![CDATA[
<div> 开源 Python 库, AI 开发人员, 实验, 跟踪, 流式传输, 复现, 协作, 恢复计算状态

<br /><br />总结:
Mltraq是一个开源的Python库，专门为AI开发人员设计，用于执行和共享实验。它具有跟踪任意内容、流式传输、复现、协作和在任何地方恢复计算状态的功能。通过GitHub上的项目，用户可以轻松地跟踪和协作AI实验，提高团队的工作效率。 <div>
【Mltraq：一个开源 Python 库，专门为 AI 开发人员设计、执行和共享实验，可以跟踪任意内容，流式传输、复现、协作和在任何地方恢复计算状态】'Mltraq - Track and Collaborate on AI Experiments. - Track and Collaborate on AI Experiments.' GitHub: github.com/elehcimd/mltraq <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoqcwbwouyj21740sw0wm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 06:44:16 GMT</pubDate>
</item>
<item>
<title>【Sequel: 开源的个性化健康助手，旨在帮助用户通过个性化的营养来控制健康】'Sequel: Your Longevity Assistant - Personalized longevity assistant' GitHub: ...</title>
<link>https://weibo.com/1402400261/O9G7c9tea</link>
<guid>https://weibo.com/1402400261/O9G7c9tea</guid>
<content:encoded><![CDATA[
<div> 个性化健康助手、开源、控制健康、营养、助用户、长寿助手、GitHub、SequelHQ、个性化、健康

<br /><br />总结:
本文介绍了一个开源的个性化健康助手Sequel，旨在帮助用户通过个性化的营养来控制健康。该助手可以根据用户的个人需求和身体状况，提供个性化的健康建议和营养方案，助用户更好地管理健康。用户可以在GitHub上找到该项目的代码和资源，可以更加深入地了解和使用这个个性化的长寿助手。Sequel致力于帮助用户通过个性化的健康管理，提升生活质量，延长寿命。 <div>
【Sequel: 开源的个性化健康助手，旨在帮助用户通过个性化的营养来控制健康】'Sequel: Your Longevity Assistant - Personalized longevity assistant' GitHub: github.com/SequelHQ/Sequel <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoqck1d0aaj21020u0wix.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 06:31:48 GMT</pubDate>
</item>
<item>
<title>【MiniCPM-V和OmniLMM 是面向图文理解的开源多模态大模型系列】'MiniCPM-V 2.0: An Efficient End-side MLLM with Strong OCR and Understanding Capabilities' ...</title>
<link>https://weibo.com/1402400261/O9FZFxfXD</link>
<guid>https://weibo.com/1402400261/O9FZFxfXD</guid>
<content:encoded><![CDATA[
<div> Efficient, End-side, MLLM, OCR, Understanding, Capabilities, MiniCPM-V, 2.0, 多模态大模型

<br /><br />总结：
MiniCPM-V 2.0 是一个高效的端到端多模态大模型，具有强大的OCR和理解能力。该模型在图文理解领域取得了显著进展，通过对图像和文字进行联合训练，实现了强大的文本识别和理解。MiniCPM-V 2.0 继承了前作的优点，同时在模型效率和功能方面进行了优化，可以应用于各种多模态任务，并在GitHub上开源供大家使用。MiniCPM-V 的出现为图文理解领域注入了新的活力，为研究者和开发者提供了强大的工具和资源。 <div>
【MiniCPM-V和OmniLMM 是面向图文理解的开源多模态大模型系列】'MiniCPM-V 2.0: An Efficient End-side MLLM with Strong OCR and Understanding Capabilities' GitHub: github.com/OpenBMB/MiniCPM-V <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoqbr78ztgj21j00ra456.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 06:13:16 GMT</pubDate>
</item>
<item>
<title>【EasyAnimate | Your Animation Generator.：用于生成长视频和训练基于transformer的扩散生成器，基于类SORA结构与DIT，使用transformer进行作为扩散器进行视频...</title>
<link>https://weibo.com/1402400261/O9FR84nMJ</link>
<guid>https://weibo.com/1402400261/O9FR84nMJ</guid>
<content:encoded><![CDATA[
<div> GitHub, EasyAnimate, Animation Generator, 生成长视频, 训练基于transformer的扩散生成器, SORA结构, DIT, 视频生成

<br /><br />总结:
EasyAnimate是一个用于生成长视频和训练基于transformer的扩散生成器的动画生成器。它基于类SORA结构与DIT，使用transformer作为扩散器进行视频生成。用户可以轻松地生成动画，并通过GitHub访问相关资源与代码。 <div>
【EasyAnimate | Your Animation Generator.：用于生成长视频和训练基于transformer的扩散生成器，基于类SORA结构与DIT，使用transformer进行作为扩散器进行视频生成】’EasyAnimate | Your Animation Generator. - Generate your animation easily' GitHub: github.com/aigc-apps/EasyAnimate <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoqbetn8ffj215r0u0wj7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 05:52:13 GMT</pubDate>
</item>
<item>
<title>【Describe：将视频转换为自定义多媒体摘要的应用】'Describe - Incredibly descriptive audiovisual summaries for videos' GitHub: github.com/sieve-communit...</title>
<link>https://weibo.com/1402400261/O9FOJz3Sd</link>
<guid>https://weibo.com/1402400261/O9FOJz3Sd</guid>
<content:encoded><![CDATA[
<div> 视频，自定义，多媒体，摘要，应用，GitHub，描述，音频，视觉，总结

关键词提取完毕。

总结:<br /><br />这个应用程序可以将视频转换为自定义的多媒体摘要，提供了极具描述性的音频和视觉总结功能。用户可以在GitHub上找到该应用程序，通过提取视频内容，生成高质量的摘要信息。应用的功能包括提供详细的文字描述和音频概括，帮助用户更快速地了解视频内容。这个工具可以帮助用户节省时间，并提供多种方式来理解视频内容。 <div>
【Describe：将视频转换为自定义多媒体摘要的应用】'Describe - Incredibly descriptive audiovisual summaries for videos' GitHub: github.com/sieve-community/describe <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoqb8mcnz6j20u01467c1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 05:46:20 GMT</pubDate>
</item>
<item>
<title>【Embed-Photos：基于 MLX 和 CLIP 模型的简单而强大的相似图像搜索网页应用】'Embed-Photos - Super simple MLX (apple silicon) CLIP based photo similarity ...</title>
<link>https://weibo.com/1402400261/O9FNM2Oo8</link>
<guid>https://weibo.com/1402400261/O9FNM2Oo8</guid>
<content:encoded><![CDATA[
<div> MLX, CLIP, 相似图像搜索, 网页应用, GitHub, 强大, 简单, 应用, 图像, MLX

Embed-Photos是一个基于MLX和CLIP模型的相似图像搜索网页应用，具有强大的搜索功能。用户可以在GitHub上找到该应用的代码。该应用设计简单易用，能够快速找到相似的图像。通过MLX和CLIP模型的支持，该应用能够准确地识别相似的图像并进行搜索。如果想要在苹果硅片设备上使用这个应用，Embed-Photos是一个不错的选择。 <div>
【Embed-Photos：基于 MLX 和 CLIP 模型的简单而强大的相似图像搜索网页应用】'Embed-Photos - Super simple MLX (apple silicon) CLIP based photo similarity web app' GitHub: github.com/harperreed/photo-similarity-search <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoqb5b9eskj20u00xptgg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 05:43:57 GMT</pubDate>
</item>
<item>
<title>【《AI-Powered Search》随书代码】’AI-Powered Search - Work in Progress for AI-Powered Search (Manning Publications)' GitHub: github.com/treygrainger/...</title>
<link>https://weibo.com/1402400261/O9FMy45PX</link>
<guid>https://weibo.com/1402400261/O9FMy45PX</guid>
<content:encoded><![CDATA[
<div> AI-Powered Search, GitHub, Manning Publications, 搜索引擎, 人工智能, 代码

<br /><br />总结:
本篇文章介绍了关于AI-Powered Search的工作进展，提供了相关的GitHub链接和出版物信息。AI-Powered Search利用人工智能技术来增强搜索引擎的能力，提高搜索结果的精度和效率。读者可以通过GitHub链接找到相关的代码和资料，深入了解人工智能在搜索领域的应用。通过阅读本文和访问相关资源，读者可以加深对人工智能搜索技术的理解，探索其在实际项目中的应用和潜力。 <div>
【《AI-Powered Search》随书代码】’AI-Powered Search - Work in Progress for AI-Powered Search (Manning Publications)' GitHub: github.com/treygrainger/ai-powered-search <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoqb26xdikj20wu0u0te5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 05:40:56 GMT</pubDate>
</item>
<item>
<title>【Nezha：基于同步时钟的可部署和高性能一致性算法，提供了多种性能优化，如高性能库和数据结构的使用、管道优化等】’Nezha - Nezha: Deployable and High-Perf...</title>
<link>https://weibo.com/1402400261/O9FixwakQ</link>
<guid>https://weibo.com/1402400261/O9FixwakQ</guid>
<content:encoded><![CDATA[
<div> 基于同步时钟、可部署、高性能、一致性算法、性能优化、高性能库、数据结构、管道优化、Nezha、GitHub<br />
<br />
总结:<br />
Nezha是一个基于同步时钟的一致性算法，具有可部署性和高性能特点。该算法利用同步时钟提供多种性能优化，包括高性能库和数据结构的使用，以及管道优化等。通过Nezha，用户能够实现高性能的共识机制，并在GitHub上获取更多相关信息。Nezha的研究为提高系统的一致性和性能提供了新的思路和方法。 <div>
【Nezha：基于同步时钟的可部署和高性能一致性算法，提供了多种性能优化，如高性能库和数据结构的使用、管道优化等】’Nezha - Nezha: Deployable and High-Performance Consensus Using Synchronized Clocks' GitHub: github.com/Steamgjk/Nezha <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoq8w42x96j213h0u0wi2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 04:27:01 GMT</pubDate>
</item>
<item>
<title>【如何更好地处理高复杂度的问题】1、从一个最小的例子开始,然后逐步拓展在处理复杂的问题时，不要直接面对全部的复杂性，而是先从一个简化的最小例子入手，逐步...</title>
<link>https://weibo.com/1402400261/O9DkhgOV3</link>
<guid>https://weibo.com/1402400261/O9DkhgOV3</guid>
<content:encoded><![CDATA[
<div> 调试、简化、记录信息、团队协作、重构代码、高复杂度、问题解决、合作、逐步验证、情景复杂度
总结:<br /><br />处理高复杂度问题时，应从简化的情景开始，逐步增加复杂度。调试时要记录和检测更多信息，与团队协作有助于找到解决方案。通过重构代码减少复杂度，保持简单化思维，逐步验证并与他人沟通合作，能更好处理高复杂度的问题。 <div>
【如何更好地处理高复杂度的问题】<br />1、从一个最小的例子开始,然后逐步拓展<br />在处理复杂的问题时，不要直接面对全部的复杂性，而是先从一个简化的最小例子入手，逐步增加复杂度。这可以让你更清晰地观察问题的不同方面。  <br /><br />2、记录/检测所有的信息<br />调试时，尽可能记录和检测更多的信息，如张量形状、损失、梯度、资源使用等。这些额外的信息能让你更清楚地观察过程，找到问题所在。  <br /><br />3、团队协作<br />向他人讲述和解释问题本身就是一个好的调试方式。与团队成员合作可以让你得到更多补充的知识和看法，更快地找到解决方案。  <br /><br />4、反复重构以减少复杂度<br />代码复杂度会不断增加，这使调试更困难。可以尝试重构代码，将相关部分提取到一个文件或notebook中，以便更清晰地理解。逐步验证后再合并回完整实现。  <br /><br />关键是面对复杂问题时保持简单化的思维，减少关注的变量，逐步拓展和验证，并与他人沟通合作。坚持这些原则可以帮助我们更好地处理高复杂度的问题。  <br />《A few tips for working on high-surface-area problems》 <a href="https://www.answer.ai/posts/2024-04-12-tips.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoq08lo73uj21fx0seaes.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoq08n3urpj21g30kcguc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 23:25:48 GMT</pubDate>
</item>
<item>
<title>【xAI发布多模态AI模型Grok-1.5V】- Grok-1.5V是xAI推出的首个多模态AI模型，不仅具有强大的文本处理能力，还能够处理各种视觉信息，包括文档、图表、截图和照片...</title>
<link>https://weibo.com/1402400261/O9Di5rNLh</link>
<guid>https://weibo.com/1402400261/O9Di5rNLh</guid>
<content:encoded><![CDATA[
<div> 多模态AI模型、Grok-1.5V、文本处理、视觉信息、强大能力、连接数字世界和物理世界、架构、交叉注意力层、VQAv2、NLVR2、测试基准、应用案例、API接口、未来应用、RealWorldQA基准、开发者、创新应用、创新速度、开放精神

<br /><br />总结:
xAI发布了多模态AI模型Grok-1.5V，拥有强大的文本处理和视觉信息处理能力，使其能够更全面地连接数字世界和物理世界。该模型基于先进架构，融合视觉和文本输入，取得在视觉问答和推理任务上的最先进结果。xAI展示了模型在多个应用案例中的实用性，计划未来通过API发布模型接口，并推出新的RealWorldQA基准测试。该模型的发布具有重要意义，展示了xAI的技术实力和创新能力，预示着多模态AI技术将为各行各业带来巨大变革和机遇。xAI的快速发展和开放精神值得持续关注。 <div>
【xAI发布多模态AI模型Grok-1.5V】<br />- Grok-1.5V是xAI推出的首个多模态AI模型，不仅具有强大的文本处理能力，还能够处理各种视觉信息，包括文档、图表、截图和照片等。这使得Grok能够更全面地连接数字世界和物理世界。  <br />- Grok-1.5V在此前发布的语言模型Grok-1.5的基础上，增加了视觉处理能力。它采用了创新的架构，先提取图像或视频的特征，然后使用交叉注意力层将视觉特征与文本输入融合，实现统一的理解。  <br />- 在VQAv2和NLVR2等测试视觉问答和推理能力的基准测试中，Grok-1.5V取得了最先进的结果，超越了GPT-4和Gemini-3等模型。这证明了它在多模态理解方面的强大能力。  <br />- xAI认为像Grok-1.5V这样的多模态AI在现实世界应用中具有巨大潜力。例如分析医学扫描图像、理解电商产品图片，以及处理机器人和自动驾驶汽车中的视频信息等。  <br />- 文章中提供了交互式演示，用户可以上传自己的图片，让Grok-1.5V回答相关问题。这展示了该模型能够对任意用户提供的图像进行推理。  <br />- xAI计划在未来几周内通过API发布Grok-1.5V，以便开发者在自己的应用中利用其多模态能力。公司对此感到兴奋，期待看到这将带来哪些新的用例和体验。  <br />- xAI重点展示了Grok-1.5V的7个应用案例，包括根据手绘图生成Python代码、从食品标签照片中计算卡路里、根据儿童绘画生成睡前故事、解释网络梗图、将表格转换为CSV格式，以及为家庭维修问题(如露台上的腐烂木头)提供建议等。这些案例展示了该模型的多功能性和实用性。<br /><br />思考：  <br />- Grok-1.5V的推出标志着xAI在多模态AI领域取得了重大突破。能够统一处理文本、图像等不同模态信息，将大大拓展AI的应用场景和实用性。这对于构建更加智能、全面的AI助手具有重要意义。  <br />- 在各种视觉问答和推理的基准测试中超越GPT-4、Gemini-3等强模型，充分证明了Grok-1.5V在多模态理解任务上的领先地位。xAI在短短几个月内取得如此进展，展现了其雄厚的技术实力和快速创新的能力。  <br />- 通过一系列实际应用案例，xAI生动地展示了Grok-1.5V在现实世界中的广泛用途，涵盖编程、医疗、电商、教育、生活等各个领域。这让我们看到了多模态AI技术在未来将为各行各业带来的巨大变革和机遇。  <br />- 值得关注的是，xAI还推出了全新的RealWorldQA基准，以评估AI模型对物理世界的理解能力。这表明xAI不仅致力于技术创新，也十分重视构建科学的评估体系。开放RealWorldQA数据集将推动整个AI社区在多模态理解方面的进一步研究。  <br />- xAI计划近期面向开发者开放Grok-1.5V的API接口，可以预见将会催生大量基于多模态AI的创新应用。作为一家成立仅9个月的初创公司，xAI展现出令人惊叹的创新速度和开放精神，其发展值得持续关注。<br />《Grok-1.5 Vision Preview》 <a href="https://x.ai/blog/grok-1.5v"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoq02z7ufjj21cn0u078j.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoq030bkwyj21fr0u0whg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoq035xd79j21240u0tei.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 23:20:24 GMT</pubDate>
</item>
<item>
<title>今日推介(第1375期)：基础模型时代的具身问答、数字Agent的自主评价与改进、理解概念激活向量、通过自动样例生成处理抽象和推理语料库、用图推理增强大型语言模...</title>
<link>https://weibo.com/1402400261/O9CSF4ilM</link>
<guid>https://weibo.com/1402400261/O9CSF4ilM</guid>
<content:encoded><![CDATA[
<div> 具身问答、数字Agent、自主评价、改进、理解概念、激活向量、自动样例生成、抽象、推理语料库、图推理
<br /><br />总结:
本文介绍了基于基础模型的具身问答系统，通过数字Agent实现自主评价和改进。同时探讨了概念的理解和激活向量的作用，提出了利用自动样例生成处理抽象和推理语料库的方法。最后，讨论了如何通过图推理来增强大型语言模型的性能。文章内容涵盖了多个关键领域，可以为研究者和开发者提供启发与借鉴。 <div>
今日推介(第1375期)：基础模型时代的具身问答、数字Agent的自主评价与改进、理解概念激活向量、通过自动样例生成处理抽象和推理语料库、用图推理增强大型语言模型 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/692360403"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.14)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hopy9p4c4dj21da0ra7cj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hopy9r4wd6j21480u0n43.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hopy9tokraj218o0sen3y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hopy9w8xcsj20ze0l4jwo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hopy9ydxvvj20ra0iqdi3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 22:17:44 GMT</pubDate>
</item>
<item>
<title>[CV] Adapting LLaMA Decoder to Vision Transformer 网页链接 通过引入因果自注意力以及相关的训练技巧，探索了LLM中的解码器设计如何迁移到计算机视觉领域，使...</title>
<link>https://weibo.com/1402400261/O9CNigkA8</link>
<guid>https://weibo.com/1402400261/O9CNigkA8</guid>
<content:encoded><![CDATA[
<div> 迁移学习, 自注意力, 相关训练技巧, 解码器设计, 计算机视觉, 图像模型, 语言模型, 架构统一, 分类性能

<br /><br />总结:
本文通过引入因果自注意力以及相关的训练技巧，探索了LLM中的解码器设计如何迁移到计算机视觉领域。这一过程使得图像模型与语言模型在架构上达成统一，并取得了良好的分类性能。通过将LLaMA Decoder适应到Vision Transformer中，实现了对视觉任务的有效应用，为跨领域的信息处理提供了新的思路和方法。在实验中，该方法取得了令人满意的结果，表明了其在图像分类等任务中的优越性。整体而言，本文为解决图像与语言等多模态信息处理问题提供了一个新的思路和实践方法。 <div>
[CV] Adapting LLaMA Decoder to Vision Transformer  <br /><a href="https://arxiv.org/abs/2404.06773"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />通过引入因果自注意力以及相关的训练技巧，探索了LLM中的解码器设计如何迁移到计算机视觉领域，使图像模型与语言模型在架构上达成统一，并取得了良好的分类性能。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopxw7jeq3j20v61astow.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopxw7p9cfj215g0lajyk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopxw89b7ij219y0e0q6g.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 22:04:32 GMT</pubDate>
</item>
<item>
<title>[CL] OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments 网页链接 当前算法在复杂计算机任务上的表现明显不足，仍...</title>
<link>https://weibo.com/1402400261/O9CKtpUYj</link>
<guid>https://weibo.com/1402400261/O9CKtpUYj</guid>
<content:encoded><![CDATA[
<div> 关键词: OSWorld, 多模态智能体, 计算机任务, 界面定位, 操作常识, 算法性能提升

总结:<br /><br />总结: 本文介绍了在复杂计算机任务上表现不足的当前算法，需要提高界面定位、操作常识等能力。OSWorld是一个面向通用Agent的开放式计算机任务基准，支持各主流操作系统、应用程序和界面，为智能体算法提供可靠的环境和数据集。通过OSWorld，研究人员可以针对多模态智能体进行基准测试，评估算法在真实计算机环境中的表现，并提出改进方向。为了取得更好的算法性能，需要不断完善智能体的界面定位能力，提升操作常识，以适应不同复杂计算机任务的需求。通过OSWorld的基准测试，可以促进智能体算法在开放式计算机任务中的发展，推动智能计算领域的进步。 <div>
[CL] OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments  <br /><a href="https://arxiv.org/abs/2404.07972"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />当前算法在复杂计算机任务上的表现明显不足，仍需提高界面定位、操作常识等能力  OSWORLD是一个面向通用Agent的开放式计算机任务基准，支持各主流操作系统、应用程序和界面，为智能体算法提供可靠的环境和数据集。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hopxoyeog7j20vk1bk7ly.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hopxoz7o8gj215q0v4qep.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopxoze2a9j21a20rggwd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 21:57:34 GMT</pubDate>
</item>
<item>
<title>[LG] InfiCoder-Eval: Systematically Evaluating the Question-Answering Capabilities of Code Large Language Models 网页链接 InfiCoder-Eval通过Stack Over...</title>
<link>https://weibo.com/1402400261/O9CHPC8dP</link>
<guid>https://weibo.com/1402400261/O9CHPC8dP</guid>
<content:encoded><![CDATA[
<div> InfiCoder-Eval, Systematically Evaluating, Question-Answering, Code Large Language Models, Stack Overflow, 覆盖面广, 指标设计合理, 自由问答能力, 重要基础<br />
<br />
重点介绍了InfiCoder-Eval的评估方法和指标设计，该评估系统通过Stack Overflow问题对代码语言模型的问答能力进行全面评估。该方法具有广泛的覆盖面和合理的设计，为未来研究提供了重要基础，有助于提升代码语言模型的性能和效果。此评估系统的发展和应用为代码语言模型领域的进一步研究和发展提供了重要参考和支持。InfiCoder-Eval通过全面评估代码模型的自由问答能力，为研究提供了重要的方法和工具，有望推动代码语言模型领域的发展和创新。<br /><br />总结: InfiCoder-Eval是一个系统评估方法，通过对代码语言模型的问答能力进行全面评估，具有广泛覆盖面和合理设计，为未来研究提供了重要基础，有助于推动代码语言模型领域的发展。 <div>
[LG] InfiCoder-Eval: Systematically Evaluating the Question-Answering Capabilities of Code Large Language Models  <br /><a href="https://arxiv.org/abs/2404.07940"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />InfiCoder-Eval通过Stack Overflow问题构建，覆盖面广，指标设计合理，可以系统全面地评估代码语言模型的自由问答能力，为未来研究提供重要基础。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopxi6hejcj210a1aond9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopxi6ut2uj20wg0smteu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopxi7dj3yj21em0yudpk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 21:51:05 GMT</pubDate>
</item>
<item>
<title>[CL] Multilingual Large Language Model: A Survey of Resources, Taxonomy and Frontiers 网页链接 全面回顾多语言大模型研究，提出参数微调对齐与参数冻结对...</title>
<link>https://weibo.com/1402400261/O9CELnKCq</link>
<guid>https://weibo.com/1402400261/O9CELnKCq</guid>
<content:encoded><![CDATA[
<div> 模型资源、参数微调、参数冻结、多语言、分类法、方法、前沿、指导、研究

总结:<br />
本文全面回顾了多语言大模型研究领域的资源、分类法和前沿探索。其中提出了参数微调对齐和参数冻结对齐的统一分类法，并讨论了相关方法、资源和新兴前沿。通过这些内容为研究工作提供了指导，并为未来的研究方向提供了启示。整体来看，本文对多语言大模型研究领域进行了深入的探讨，丰富了领域内的研究内容，为相关研究者提供了有益的参考和指导。 <div>
[CL] Multilingual Large Language Model: A Survey of Resources, Taxonomy and Frontiers  <br /><a href="https://arxiv.org/abs/2404.04925"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />全面回顾多语言大模型研究，提出参数微调对齐与参数冻结对齐的统一分类法，讨论方法、资源与新兴前沿，为研究提供指导。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopxaacvjfj20wa1by1bn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hopxaaw5djj21pg0yih1j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopxab96cnj20uq0reah6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hopxabxwizj21bm1bknnw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 21:43:31 GMT</pubDate>
</item>
<item>
<title>构建了图推理基准数据集，并设计GRAPH-COT框架使LLM能在图上迭代推理，综合利用了图的结构和语义信息。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Graph Chain-of-Thou...</title>
<link>https://weibo.com/1402400261/O9CB3u8jW</link>
<guid>https://weibo.com/1402400261/O9CB3u8jW</guid>
<content:encoded><![CDATA[
<div> Graph Chain-of-Thought, Large Language Models, 图推理基准数据集, GRAPH-COT框架, 迭代推理, 图的结构, 语义信息, University of Illinois at Urbana-Champaign

总结:<br />
该论文介绍了一种名为GRAPH-COT的框架，用于增强大型语言模型（LLM）的推理能力。作者构建了图推理基准数据集，并设计了GRAPH-COT框架，使LLM可以在图上进行迭代推理，综合利用了图的结构和语义信息。该框架为LLM引入了图推理能力，进一步提升了其在推理任务上的表现。研究结果表明，通过在图上进行推理，LLM在各种推理任务上的性能都得到了显著提升。这一研究为将图结构引入到自然语言处理领域提供了新的思路和方法。 <div>
构建了图推理基准数据集，并设计GRAPH-COT框架使LLM能在图上迭代推理，综合利用了图的结构和语义信息。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs》B Jin, C Xie, J Zhang, K K Roy, Y Zhang, S Wang, Y Meng, J Han [University of Illinois at Urbana-Champaign] (2024) <a href="https://arxiv.org/abs/2404.07103"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopwvdqtm1j20nk19sqe8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopwve9gw3j20ra0iqtbt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopwvepbq0j21ha0iw0zn.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopwvexvm2j20qm0niad8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopwvm0kkij20hr0fd0tl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopwvm1jmoj20zx0hgjv3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopwvm3zbqj20zx1g612o.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 21:34:23 GMT</pubDate>
</item>
<item>
<title>[CL]《Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs》B Jin, C Xie, J Zhang, K K Roy, Y Zhang, S Wang, Y Meng, J Han ...</title>
<link>https://weibo.com/1402400261/O9CB1mKZf</link>
<guid>https://weibo.com/1402400261/O9CB1mKZf</guid>
<content:encoded><![CDATA[
<div> 大语言模型，图链思维，增强，推理，图形，University of Illinois at Urbana-Champaign，2024

提出了一种新的方法，名为Graph Chain-of-Thought，可以增强大语言模型的推理能力。该方法使用图形结构来表示文本数据，通过在图上进行推理和推断来提高模型的性能。研究团队来自University of Illinois at Urbana-Champaign，在2024年发表了这篇论文。他们的方法能够在处理自然语言文本时，根据文本之间的关系和语义信息搭建起图形结构，从而帮助模型更好地理解和推理文本内容。这种基于图形的推理方法在大语言模型的发展中具有重要意义，可以为语言模型的进一步发展奠定基础。Graph Chain-of-Thought方法的提出为解决自然语言处理中的推理问题提供了新的思路和技术手段，有望为相关研究领域带来新的突破和进展。<br /><br />总结:通过图形推理方法，Graph Chain-of-Thought有望增强大语言模型的推理能力，帮助模型更好地理解和推理自然语言文本，为语言模型的发展提供重要思路和技术支持。 <div>
[CL]《Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs》B Jin, C Xie, J Zhang, K K Roy, Y Zhang, S Wang, Y Meng, J Han [University of Illinois at Urbana-Champaign] (2024) <a href="https://arxiv.org/abs/2404.07103"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopwvdqtm1j20nk19sqe8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopwve9gw3j20ra0iqtbt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopwvepbq0j21ha0iw0zn.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopwvexvm2j20qm0niad8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopwvm0kkij20hr0fd0tl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopwvm1jmoj20zx0hgjv3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopwvm3zbqj20zx1g612o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 21:34:18 GMT</pubDate>
</item>
<item>
<title>通过为抽象推理语料库(ARC)任务设计示例生成器，可大幅扩充每个任务的样本量，以支持针对少样本泛化能力的实验。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Addressing...</title>
<link>https://weibo.com/1402400261/O9Cy2qgvR</link>
<guid>https://weibo.com/1402400261/O9Cy2qgvR</guid>
<content:encoded><![CDATA[
<div> 抽象推理语料库(ARC)、示例生成器、样本量、少样本泛化能力、实验、ETH Zurich、M Hodel、文章、地址、解决、过程、扩充、任务<br />
<br />
总结:<br />
本文介绍了通过设计示例生成器来扩充抽象推理语料库(ARC)任务的样本量，以支持针对少样本泛化能力的实验。作者M Hodel来自ETH Zurich，在文章中提出了解决ARC任务的方法。他通过设计过程来生成示例，从而大幅扩充了每个任务的样本量。这种方法旨在提高模型的泛化能力，并为少样本学习提供支持。通过这种创新的方法，可以有效地解决ARC任务中样本量不足的问题，为相关研究提供了新的思路和方法。 <div>
通过为抽象推理语料库(ARC)任务设计示例生成器，可大幅扩充每个任务的样本量，以支持针对少样本泛化能力的实验。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Addressing the Abstraction and Reasoning Corpus via Procedural Example Generation》M Hodel [ETH Zurich] (2024) <a href="https://arxiv.org/abs/2404.07353"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopwskiguxj20ze0l4tj0.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 21:26:56 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.13)》 爱可可微博热门分享(4.13) [图片]</title>
<link>https://weibo.com/1402400261/O9zTomcPj</link>
<guid>https://weibo.com/1402400261/O9zTomcPj</guid>
<content:encoded><![CDATA[
<div> 分享, 爱可可, 微博, 热门, 4.13, 社交媒体, 精彩内容, 热点话题, 关注, 点赞

<br /><br />总结：
爱可可微博于4月13日分享了一些热门内容，吸引了大量关注和点赞。这些精彩内容涉及社交媒体上的热点话题，持续引起用户的兴趣。关注爱可可微博，可以及时了解各种热门话题，获取信息。 <div>
《爱可可微博热门分享(4.13)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405022829266468961"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.13)</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopl2wya6xj20rs0fmgoi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 14:41:19 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Less is More: Fewer Interpretable Region via Submodular Subset Selection》(ICLR 2024) GitHub: github.com/RuoyuChen10/SMDL-Attribut...</title>
<link>https://weibo.com/1402400261/O9yDw1Wbq</link>
<guid>https://weibo.com/1402400261/O9yDw1Wbq</guid>
<content:encoded><![CDATA[
<div> 关键词: 论文代码, GitHub, 图像分割, 自然语言处理, 三维重建, 模型改进, 机器学习, 自监督学习, 图像去噪, 深度学习

总结:
<br /><br />这篇文章介绍了几篇以论文实现代码为基础的研究成果，涉及图像分割、自然语言处理、三维重建等多个领域。通过GitHub链接可以查看到每篇论文代码的具体实现。其中一些论文探讨了模型改进的方法，包括自监督学习、图像去噪等技术的应用，为机器学习领域的发展提供了新的思路和实验结果。这些研究成果对于深度学习和人工智能领域的进步具有重要意义。 <div>
几篇论文实现代码：<br />《Less is More: Fewer Interpretable Region via Submodular Subset Selection》(ICLR 2024) GitHub: github.com/RuoyuChen10/SMDL-Attribution [fig7]<br />《GoMVS: Geometrically Consistent Cost Aggregation for Multi-View Stereo》(CVPR 2024) GitHub: github.com/Wuuu3511/GoMVS [fig2]<br />《MindBridge: A Cross-Subject Brain Decoding Framework》(CVPR 2024) GitHub: github.com/littlepure2333/MindBridge [fig6]<br />《DemoCaricature: Democratising Caricature Generation with a Rough Sketch》(CVPR 2024) GitHub: github.com/ChenDarYen/DemoCaricature<br />《Object Pose Estimation via the Aggregation of Diffusion Features》(CVPR 2024) GitHub: github.com/Tianfu18/diff-feats-pose<br />《PEM: Prototype-based Efficient MaskFormer for Image Segmentation》(CVPR 2024) GitHub: github.com/NiccoloCavagnero/PEM<br />《Bridging the Gap Between End-to-End and Two-Step Text Spotting》(CVPR 2024) GitHub: github.com/mxin262/Bridging-Text-Spotting<br />《Unsupervised Continual Anomaly Detection with Contrastively-learned Prompt》(AAAI 2024) GitHub: github.com/shirowalker/UCAD [fig9]<br />《Autonomous Evaluation and Refinement of Digital Agents》(2024) GitHub: github.com/Berkeley-NLP/Agent-Eval-Refine [fig1]<br />《latentSplat: Autoencoding Variational Gaussians for Fast Generalizable 3D Reconstruction》(2024) GitHub: github.com/Chrixtar/latentsplat<br />《From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples》(2024) GitHub: github.com/robertvacareanu/llm4regression<br />《iSeg: Interactive 3D Segmentation via Interactive Attention》(2024) GitHub: github.com/threedle/iSeg<br />《GoMAvatar: Efficient Animatable Human Modeling from Monocular Video Using Gaussians-on-Mesh》(2024) GitHub: github.com/wenj/GoMAvatar<br />《Autonomous Evaluation and Refinement of Digital Agents》(2024) GitHub: github.com/Berkeley-NLP/Agent-Eval-Refine [fig3]<br />《MonoOcc: Digging into Monocular Semantic Occupancy Prediction》(2024) GitHub: github.com/ucaszyp/MonoOcc [fig4]<br />《OS-Copilot: Towards Generalist Computer Agents with Self-Improvement》(2024) GitHub: github.com/OS-Copilot/OS-Copilot [fig5]<br />《GoodDrag: Towards Good Practices for Drag Editing with Diffusion Models》(2024) GitHub: github.com/zewei-Zhang/GoodDrag<br />《LLoCO: Learning Long Contexts Offline》(2024) GitHub: github.com/jeffreysijuntan/lloco [fig8]<br />《TBSN: Transformer-Based Blind-Spot Network for Self-Supervised Image Denoising》(2024) GitHub: github.com/nagejacob/TBSN<br />《AutoTimes: Autoregressive Time Series Forecasters via Large Language Models》(2024) GitHub: github.com/thuml/AutoTimes<br />《Visual Foundation Models Boost Cross-Modal Unsupervised Domain Adaptation for 3D Semantic Segmentation》(2024) GitHub: github.com/EtronTech/VFMSeg<br />《VLFM: Vision-Language Frontier Maps for Zero-Shot Semantic Navigation》(2024) GitHub: github.com/bdaiinstitute/vlfm<br />《Source Prompt Disentangled Inversion for Boosting Image Editability with Diffusion Models》(2024) GitHub: github.com/leeruibin/SPDInv<br />《Improving Diffusion Models for Virtual Try-on》(2024) GitHub: github.com/yisol/IDM-VTON<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hop3svw3p5j21uq15gtyk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopd3c82bxj21p216qqfp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hopd7cbid5j21uq15gtyk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopdovqaypj20ui0fuqea.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hope9vvv0dj21fa0noe6m.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopect8xl8j23yw27vnpe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopef16vohj20qo0k0dpy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hopeidzwncj21po0k0dof.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopej7mmj3j20yy0dxwmm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 11:29:26 GMT</pubDate>
</item>
<item>
<title>'icegl-three-vue-tres - 让三维可视化项目快速落地の开源框架，永久开源，免费商用' GitHub: github.com/hawk86104/icegl-three-vue-tres #开源# [图片][图片][...</title>
<link>https://weibo.com/1402400261/O9yDtdr8a</link>
<guid>https://weibo.com/1402400261/O9yDtdr8a</guid>
<content:encoded><![CDATA[
<div> GitHub、icegl-three-vue-tres、开源、框架、三维可视化、快速落地、永久、免费商用

<br /><br />总结:
icegl-three-vue-tres是一个开源框架，旨在帮助三维可视化项目快速落地，永久开源且免费商用。该项目托管在GitHub上，用户可以下载并使用。这个框架的目标是提供简单易用的工具和功能，让开发者可以快速构建出精美的三维可视化项目。通过icegl-three-vue-tres，开发者可以节省大量时间和精力，快速开发出符合需求的三维可视化应用。 <div>
'icegl-three-vue-tres - 让三维可视化项目快速落地の开源框架，永久开源，免费商用' GitHub: github.com/hawk86104/icegl-three-vue-tres <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hopfj2ws4lj20m80gowp2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hopfj4flcpj20m80gogr4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hopfj5mfd9j20m80godmy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hopfj77mo6j20m80gomyk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hopfj8a1h3j20m80gon3e.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hopfj9oniuj20m80gogut.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 11:29:21 GMT</pubDate>
</item>
<item>
<title>【360 智脑大模型采用高质量语料库进行训练，在相关基准评测中表现出有竞争力。开放了 4K 和 32K 的对话模型，并提供了模型评估和快速开始的指南】'360Zhinao (3...</title>
<link>https://weibo.com/1402400261/O9yzF0ZTr</link>
<guid>https://weibo.com/1402400261/O9yzF0ZTr</guid>
<content:encoded><![CDATA[
<div> 360智脑、模型评测、竞争力、4K、32K、语料库、训练、指南、GitHub、开放<br />
<br />
总结:<br />
360智脑大模型采用高质量语料库进行训练，在相关基准评测中表现出有竞争力。该项目在GitHub上开放了4K和32K的对话模型，并提供了模型评估和快速开始的指南，为研究人员和开发者提供了良好的资源和支持。 <div>
【360 智脑大模型采用高质量语料库进行训练，在相关基准评测中表现出有竞争力。开放了 4K 和 32K 的对话模型，并提供了模型评估和快速开始的指南】'360Zhinao (360智脑)' GitHub: github.com/Qihoo360/360zhinao <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hopf9k1ibjj217w0u041z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 11:19:57 GMT</pubDate>
</item>
<item>
<title>【Latent Box：AI、创意和艺术领域的精选合集】'Latent Box - A collection of awesome-lists for AI, creativity and art.' 网页链接 GitHub: github.com/laten...</title>
<link>https://weibo.com/1402400261/O9yvz0fxP</link>
<guid>https://weibo.com/1402400261/O9yvz0fxP</guid>
<content:encoded><![CDATA[
<div> GitHub, Latent Box, AI, 创意, 艺术, 合集, awesome-lists, latentcat, 精选合集

<br /><br />总结: 
Latent Box是一个GitHub仓库，汇集了AI、创意和艺术领域的精选合集，包括了各种优秀资源列表。这个项目为对这些领域感兴趣的人提供了一个宝库，可以找到各种有用的信息和资源。人们可以通过这个合集深入了解AI、创意和艺术的发展前沿，从中汲取灵感并探索新的可能性。Latent Box的存在为这些领域的研究和创作提供了更多的支持和帮助，推动着这些领域的不断发展和进步。 <div>
【Latent Box：AI、创意和艺术领域的精选合集】'Latent Box - A collection of awesome-lists for AI, creativity and art.' <a href="https://latentbox.com/zh"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> GitHub: github.com/latentcat/latentbox <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hopey4qssrj20vr0u043l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 11:09:52 GMT</pubDate>
</item>
<item>
<title>【Tango：TypeScript 重新实现的 ADB（Android Debugging Bridge）客户端，可以在基于 Chromium 的浏览器（包括 Chrome for Android）、Node.js 和 Electron 中...</title>
<link>https://weibo.com/1402400261/O9yofjKrQ</link>
<guid>https://weibo.com/1402400261/O9yofjKrQ</guid>
<content:encoded><![CDATA[
<div> TypeScript, ADB, Android Debugging Bridge, Chromium, 浏览器, Node.js, Electron, GitHub, ya-webadb

<br /><br />总结:
Tango是一个用TypeScript重新实现的ADB客户端，可以在基于Chromium的浏览器（包括Chrome for Android）、Node.js和Electron中运行。通过GitHub项目ya-webadb提供。 <div>
【Tango：TypeScript 重新实现的 ADB（Android Debugging Bridge）客户端，可以在基于 Chromium 的浏览器（包括 Chrome for Android）、Node.js 和 Electron 中运行】'Tango - ADB in your browser' GitHub: github.com/yume-chan/ya-webadb <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hopegajqirj213q0u0wht.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 10:51:50 GMT</pubDate>
</item>
<item>
<title>【多模态大语言模型(MLLM)安全性相关论文资源列表】’Awesome-MLLM-Safety - "Safety is defined as stopping models from following malicious instructions an...</title>
<link>https://weibo.com/1402400261/O9yfpzKw5</link>
<guid>https://weibo.com/1402400261/O9yfpzKw5</guid>
<content:encoded><![CDATA[
<div> 安全性、多模态大语言模型、资源列表、GitHub、MLLM、恶意指令、有害内容、论文、相关、推荐

总结：<br /><br />
这篇资源列表汇总了与多模态大语言模型安全性相关的论文、资源和工具。安全性在这里定义为阻止模型遵循恶意指令并生成有害内容。GitHub上提供了更多详细信息和相关链接。对于研究多模态大语言模型安全性的学者和从业者来说，这个资源列表是一个很好的参考工具。 <div>
【多模态大语言模型(MLLM)安全性相关论文资源列表】’Awesome-MLLM-Safety - "Safety is defined as stopping models from following malicious instructions and generating toxic content."' GitHub: github.com/isXinLiu/Awesome-MLLM-Safety <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hopdske87cj20u010ltdg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 10:30:05 GMT</pubDate>
</item>
<item>
<title>【UnInbox：现代化的电子邮件工具，专门为团队和专业人士设计，旨在替代陈旧的电子邮件技术和工具】'UnInbox - Modern email for teams and professionals. A re...</title>
<link>https://weibo.com/1402400261/O9yeEzDAW</link>
<guid>https://weibo.com/1402400261/O9yeEzDAW</guid>
<content:encoded><![CDATA[
<div> UnInbox、现代化、电子邮件工具、团队、专业人士、替代、陈旧、技术、hey.com、front.com

<br /><br />总结:
UnInbox是一款专门为团队和专业人士设计的现代化电子邮件工具，旨在替代陈旧的电子邮件技术和工具，可作为hey.com、front.com和missiveapp.com的替代品。其开源代码可于GitHub上找到。 <div>
【UnInbox：现代化的电子邮件工具，专门为团队和专业人士设计，旨在替代陈旧的电子邮件技术和工具】'UnInbox - Modern email for teams and professionals. A replacement for outdated email technology and tools. Alt to hey.com, front.com, missiveapp.com' GitHub: github.com/un/inbox <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hopdro1aanj20u00u3mzi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 10:28:13 GMT</pubDate>
</item>
<item>
<title>【PicProse：用于生成中等规模平台封面图像的工具，如 Medium、YouTube、BiliBili 和博客等】'PicProse is a better cover image generator tool for Medium, Yo...</title>
<link>https://weibo.com/1402400261/O9ydYkqyn</link>
<guid>https://weibo.com/1402400261/O9ydYkqyn</guid>
<content:encoded><![CDATA[
<div> GitHub, PicProse, 封面图像生成工具, Medium, YouTube, BiliBili, 博客<br />
<br />总结:
PicProse 是一个用于生成中等规模平台封面图像的工具，适用于 Medium、YouTube、BiliBili 和博客等。GitHub 上有其代码库，PicProse 提供了更好的封面图像生成功能，可以帮助用户制作更加吸引人的封面图像，提升内容的吸引力和可视化效果。PicProse 的功能包括覆盖多种平台，为用户提供更加灵活的定制化选项，是一个值得尝试的工具。 <div>
【PicProse：用于生成中等规模平台封面图像的工具，如 Medium、YouTube、BiliBili 和博客等】'PicProse is a better cover image generator tool for Medium, YouTube, BiliBili, Blog and many others' GitHub: github.com/gezhaoyou/picprose <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hopdpi1xwwj21k00u078i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 10:26:32 GMT</pubDate>
</item>
<item>
<title>'1000UserGuide：300多个帮独立开发者和创业者推广产品、找到前1000个早期用户的国内外渠道适合独立开发者和创业者推广产品的渠道' GitHub: github.com/naxiaodu...</title>
<link>https://weibo.com/1402400261/O9ybCm1Ue</link>
<guid>https://weibo.com/1402400261/O9ybCm1Ue</guid>
<content:encoded><![CDATA[
<div> GitHub, 推广产品, 开发者, 创业者, 渠道, 用户, 早期用户, 国内外, 独立, 找到

<br /><br />总结:
本文介绍了一个名为'1000UserGuide'的指南，旨在帮助独立开发者和创业者找到适合推广产品、寻找前1000个早期用户的国内外渠道。通过该指南，用户可以学习如何有效地推广产品，找到目标用户，并提升产品的知名度。GitHub链接为github.com/naxiaoduo/1000UserGuide。 <div>
'1000UserGuide：300多个帮独立开发者和创业者推广产品、找到前1000个早期用户的国内外渠道适合独立开发者和创业者推广产品的渠道' GitHub: github.com/naxiaoduo/1000UserGuide <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hopdjw16qyj20uj0u0jvi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 10:20:44 GMT</pubDate>
</item>
<item>
<title>【tu：可以将自然语言日期/时间字符串转换为UTC时间格式的命令行工具】’tu - CLI tool to convert a natural language date/time string to UTC' GitHub: githu...</title>
<link>https://weibo.com/1402400261/O9y7E5Hjv</link>
<guid>https://weibo.com/1402400261/O9y7E5Hjv</guid>
<content:encoded><![CDATA[
<div> 关键词: tu, 自然语言日期, 时间字符串, UTC时间格式, 命令行工具, GitHub, 转换, CLI, 工具<br />
<br />
总结:<br />
本文介绍了一个名为tu的命令行工具，可以将自然语言日期/时间字符串转换为UTC时间格式。用户可以在GitHub上找到该工具的源代码。tu可以帮助用户快速准确地将日期/时间转换为UTC时间，提高工作效率。用户只需输入待转换的日期/时间字符串，tu即可完成转换并输出UTC时间，方便用户进行时间转换和计算。这个工具简单易用，适用于有时间转换需求的用户。详细使用方法和安装步骤可以在GitHub页面找到。如果你常常需要转换不同时区的时间，tu可能会成为你的实用工具之一。 <div>
【tu：可以将自然语言日期/时间字符串转换为UTC时间格式的命令行工具】’tu - CLI tool to convert a natural language date/time string to UTC' GitHub: github.com/ad-si/tu <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hopd93pxorj20u00zs41r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 10:10:56 GMT</pubDate>
</item>
<item>
<title>【基于大语言模型的游戏Agent研究相关论文资源列表】’A Survey on Large Language Model-Based Game Agents - A Survey on Large Language Model-Based Game Ag...</title>
<link>https://weibo.com/1402400261/O9vZuwqpg</link>
<guid>https://weibo.com/1402400261/O9vZuwqpg</guid>
<content:encoded><![CDATA[
<div> 大语言模型、游戏Agent、调查、资源、GitHub、研究、论文

<br /><br />总结：
这篇论文调查了基于大语言模型的游戏Agent的相关研究和资源，并提供了GitHub链接。研究着重于分析当前领域的论文和发展趋势，为感兴趣的研究者提供了宝贵的参考资源。GitHub上的资料丰富多样，有助于进一步了解和深入探讨大语言模型在游戏Agent领域的应用和发展。 <div>
【基于大语言模型的游戏Agent研究相关论文资源列表】’A Survey on Large Language Model-Based Game Agents - A Survey on Large Language Model-Based Game Agents' GitHub: github.com/git-disl/awesome-LLM-game-agent-papers <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hop3uf9qssj21bw0u043p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 04:45:22 GMT</pubDate>
</item>
<item>
<title>【一个机器学习知识库，涵盖了从基础到高级主题的机器学习知识，包括模型架构、训练和微调、推理和运行策略、应用等。其目的是帮助新的 Elicit 员学习机器学习背...</title>
<link>https://weibo.com/1402400261/O9vYqqAvW</link>
<guid>https://weibo.com/1402400261/O9vYqqAvW</guid>
<content:encoded><![CDATA[
<div> GitHub, 机器学习, 知识库, 模型架构, 训练, 微调, 推理, 运行策略, 应用, 语言模型
<br /><br />总结:
这篇文章介绍了一个名为"Elicit Machine Learning Reading List"的机器学习知识库，包含从基础到高级主题的机器学习知识，重点关注语言模型。知识库涵盖了模型架构、训练和微调、推理和运行策略、应用等多个方面，旨在帮助新的Elicit员学习机器学习背景。通过GitHub平台可以访问该知识库，学习和探索其中的内容。 <div>
【一个机器学习知识库，涵盖了从基础到高级主题的机器学习知识，包括模型架构、训练和微调、推理和运行策略、应用等。其目的是帮助新的 Elicit 员学习机器学习背景，重点关注语言模型】’Elicit Machine Learning Reading List' GitHub: github.com/elicit/machine-learning-list <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hop3s83d9hj21740lagoy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 04:42:43 GMT</pubDate>
</item>
<item>
<title>【面向科学和工程领域表现的大模型排行榜】《Science Leaderboard - a Hugging Face Space by TIGER-Lab》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O9uLuAk2K</link>
<guid>https://weibo.com/1402400261/O9uLuAk2K</guid>
<content:encoded><![CDATA[
<div> 大模型排行榜, 科学, 工程, 模型性能, Hugging Face, TIGER-Lab

<br /><br />总结:
文章介绍了由TIGER-Lab打造的《Science Leaderboard - a Hugging Face Space》，该平台旨在建立一个面向科学和工程领域的大模型排行榜。用户可以在这个空间中比较各种大型预训练模型在不同任务上的性能表现，帮助研究人员更好地选择合适的模型。这个排行榜集成了来自不同研究团队的模型，为用户提供了一个全面的参考，对促进科学和工程领域的研究工作具有积极意义。 <div>
【面向科学和工程领域表现的大模型排行榜】《Science Leaderboard - a Hugging Face Space by TIGER-Lab》 <a href="https://huggingface.co/spaces/TIGER-Lab/Science-Leaderboard"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hooyg4zgvmj21gx0u0780.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 01:38:08 GMT</pubDate>
</item>
<item>
<title>【视觉语言模型解析】视觉语言模型是能够同时从图像和文本中学习的模型，可以处理从视觉问答到图像字幕等多种任务。主要的组成部分包括图像编码器、嵌入映射器（...</title>
<link>https://weibo.com/1402400261/O9uKLiiUt</link>
<guid>https://weibo.com/1402400261/O9uKLiiUt</guid>
<content:encoded><![CDATA[
<div> 视觉语言模型、图像编码器、嵌入映射器、文本解码器、开源模型、基准评估、Transformer、SFTTrainer、Vision Arena、Open VLM Leaderboard<br />
<br />
总结：<br />
视觉语言模型是能够同时从图像和文本中学习的模型，主要组成部分包括图像编码器、嵌入映射器和文本解码器。开源的视觉语言模型有基础模型和适用于不同任务的特殊模型。评估视觉语言模型的重要基准包括综合基准MMMU、单项选择题基准MMBench和其他领域的基准。使用Transformer进行推理，SFTTrainer进行微调。在选择合适模型时关键在于任务需求，可以参考排行榜进行选择。 <div>
【视觉语言模型解析】<br />视觉语言模型是能够同时从图像和文本中学习的模型，可以处理从视觉问答到图像字幕等多种任务。主要的组成部分包括图像编码器、嵌入映射器（用于对齐图像和文本表示）以及文本解码器。<br /><br />开源的视觉语言模型包括：<br />- LLaVA、deepseek-vl-7b-base 等基础模型<br />- DeepSeek-VL-Chat、CogVLM-Chat 等适用于聊天的模型，具有防止模型幻象的"锚定"特性<br />- Fuyu-8B 等可以检测图像内文本的模型 <br />- KOSMOS-2、Qwen-VL 等可以进行零样本对象检测的模型<br /><br />评估视觉语言模型的重要基准包括：<br />- MMMU:综合基准，包含不同学科知识和推理<br />- MMBench:包含 20 项技能的单项选择题<br />- MathVista:数学推理<br />- AI2D:图表理解<br />- ScienceQA:科学问答<br />- OCRBench:文档理解<br /><br />使用 Transformer 可以进行推理，使用 SFTTrainer 可以进行微调。选择合适的模型关键在于目标任务，可以参考 Vision Arena、Open VLM Leaderboard 等排行榜。<br />《Vision Language Models Explained》 <a href="https://huggingface.co/blog/vlms"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hooye587urj21hc0u0ahb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hooye7ln7oj21hc0u0whn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 01:36:19 GMT</pubDate>
</item>
<item>
<title>【Google Scholar PDF Reader：能极大提高学术论文阅读效率的浏览器插件，可以预览引用、浏览目录、跳转到图表、引用文献等】“Google Scholar PDF Reader” 网...</title>
<link>https://weibo.com/1402400261/O9uGwfHIS</link>
<guid>https://weibo.com/1402400261/O9uGwfHIS</guid>
<content:encoded><![CDATA[
<div> Google Scholar PDF Reader, 浏览器插件, 学术论文, 阅读效率, 预览引用, 浏览目录, 图表, 引用文献

Google Scholar PDF Reader是一款能够极大提高学术论文阅读效率的浏览器插件。该插件可以让用户预览论文的引用，浏览目录，跳转到图表和引用文献等功能，使用户能够更快速、方便地阅读和理解学术论文内容。通过Google Scholar PDF Reader，用户可以更快速地找到自己所需的信息，节约时间，提高工作效率，是一款非常实用的学术工具插件。<br /><br />总结:Google Scholar PDF Reader是一款能够极大提高学术论文阅读效率的浏览器插件，可以帮助用户预览引用、浏览目录、跳转到图表、引用文献等功能，使用户更方便快捷地阅读和理解学术论文内容，提高工作效率。 <div>
【Google Scholar PDF Reader：能极大提高学术论文阅读效率的浏览器插件，可以预览引用、浏览目录、跳转到图表、引用文献等】“Google Scholar PDF Reader” <a href="https://chromewebstore.google.com/detail/dahenjhkoodjbpjheillcadbppiidmhp"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hooy32j0mjj21eq0u0wi6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hooy3c1habj21cy0u0k1l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 01:25:52 GMT</pubDate>
</item>
<item>
<title>【构建AI的"世界模型"：Meta的OpenEQA框架为具身智能开启新篇章】 - Meta 正在探索构建一种具身AI智能体，它可以作为家庭机器人或时尚智能眼镜的"大脑"。这种智...</title>
<link>https://weibo.com/1402400261/O9uEws3sJ</link>
<guid>https://weibo.com/1402400261/O9uEws3sJ</guid>
<content:encoded><![CDATA[
<div> 元学习、OpenEQA框架、具身智能、世界模型、Meta、环境理解、智能体、语言交互、EQA、智能家居<br />
<br />
1. Meta正在探索构建具身智能体，用作家庭机器人或智能眼镜的"大脑"，需要理解周围环境并能够通过语言交流。<br />
2. 构建"世界模型"是一个重要愿景和研究挑战，Meta正积极探索。<br />
3. 推出的OpenEQA框架是一个新基准，通过提问衡量具身智能体对环境的理解。<br />
4. OpenEQA主要包含情节记忆EQA和实时EQA两个任务，用于评估智能体的环境理解能力。<br />
5. EQA具有日常生活应用，能在智能眼镜、家用机器人等设备中提供帮助和服务。<br />
<br />
总结：Meta正在探索构建具身智能体，通过OpenEQA框架评估智能体的环境理解能力，推动智能家居和可穿戴设备的发展，这将极大地改善人们的日常生活。构建"世界模型"概念强调了语言交互的重要性，让人工智能系统更自然、直观地与人类沟通。通过EQA任务对智能体的理解能力进行评估，展示了人工智能技术在提升生活质量方面的潜力。 <div>
【构建AI的"世界模型"：Meta的OpenEQA框架为具身智能开启新篇章】  <br />- Meta 正在探索构建一种具身AI智能体，它可以作为家庭机器人或时尚智能眼镜的"大脑"。这种智能体需要利用视觉等感官模态来理解周围环境，并能够用清晰、日常的语言进行交流，以有效地协助人们。  <br />- 这相当于构建一个"世界模型"——智能体对外部世界的内部表征，可以通过语言进行查询。这是一个长期愿景和艰巨的研究挑战，Meta正在积极探索。  <br />- Meta 推出了开放词汇具身问答(OpenEQA)框架，这是一个新的基准，通过向智能体提出开放式词汇问题来衡量其对环境的理解。这类似于我们通过提问和评估答案来评估人类对某个概念的理解。  <br />- OpenEQA 包含两个任务：(1)情节记忆 EQA，其中具身 AI 智能体根据其对环境的观察回答问题；(2)实时 EQA，其中智能体必须在探索环境的同时回答问题。  <br />- EQA 也有直接的应用，即使是基本版本也可以简化日常生活。例如，智能眼镜可以利用情节记忆帮助你找到遗失的办公证件，家用机器人可以告诉你是否还有水果。  <br /><br />思考：  <br />- OpenEQA 框架为评估具身 AI 智能体的环境理解能力提供了一种新颖的方法。通过提出开放式问题并评估答案，我们可以更全面地了解智能体对周围世界的认知水平。这对于开发能够有效协助人类的 AI 系统至关重要。  <br />- Meta 提出的"世界模型"概念非常有趣，它强调了语言交互在人工智能系统中的重要性。通过构建可查询的世界表征，我们可以让 AI 以更自然、直观的方式与人类沟通和协作。  <br />- EQA 在智能家居、可穿戴设备等领域有广泛的应用前景。即使是基本的 EQA 功能，也可以极大地简化人们的日常生活，提供更加个性化和智能化的服务。这展示了 AI 技术在改善人类生活方面的巨大潜力。<br />《OpenEQA: From word models to world models》 <a href="https://ai.meta.com/blog/openeqa-embodied-question-answering-robotics-ar-glasses/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hooxy9nzjaj21al0u043p.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hooxya6pwgj20yq0loacv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 01:20:57 GMT</pubDate>
</item>
<item>
<title>【Adobe Firefly AI 训练数据来源遭质疑，人工智能领域亟需加强监管】- 去年，Adobe 推出了其创新的图像生成软件 Firefly，并宣称该人工智能模型主要是在 Adobe ...</title>
<link>https://weibo.com/1402400261/O9uuVBlWJ</link>
<guid>https://weibo.com/1402400261/O9uuVBlWJ</guid>
<content:encoded><![CDATA[
<div> Adobe, Firefly, AI, 训练数据, 质疑, 监管, 误导, 透明度, 竞争对手, 技术, 发展

<br /><br />总结:
去年，Adobe推出了图像生成软件Firefly，声称其主要在Adobe Stock上训练。然而，实际上Adobe也利用了竞争对手的人工智能生成内容来完善模型。Adobe在宣传Firefly时缺乏透明度，可能损害用户信任。该事件反映了人工智能领域训练数据来源和使用方式缺乏监管和透明度，需要建立更严格的规范和标准。在评估人工智能产品时，不能完全相信营销宣传，需要深入了解技术实现细节。 <div>
【Adobe Firefly AI 训练数据来源遭质疑，人工智能领域亟需加强监管】<br />- 去年，Adobe 推出了其创新的图像生成软件 Firefly，并宣称该人工智能模型主要是在 Adobe Stock(该公司拥有数亿张许可图像的广泛存储库)上训练的。  <br />- Adobe 将 Firefly 定位为一个更具商业可行性的选择，与 Midjourney 等竞争对手相比，后者依赖于从互联网上抓取的图像进行训练。  <br />- 然而，有一个有趣的细节被隐藏了。虽然 Adobe 公开强调 Firefly 训练数据的安全性和排他性，但该公司也利用了这些竞争对手的人工智能生成内容来完善其模型，包括Midjourney在内。  <br />- 在关于 Firefly 优越性的各种演示和公开声明中，Adobe 没有披露这一关键细节，即其训练数据是经过精心策划的。  <br /><br />思考：  <br />- 这篇报道揭示了 Adobe 在宣传其 Firefly AI 模型时存在一定程度的误导。虽然 Adobe 声称主要使用自己的许可图像库进行训练，但实际上也利用了竞争对手的人工智能生成图像。这种做法在商业竞争中并不罕见，但缺乏透明度可能会损害用户对 Adobe 的信任。  <br />- Adobe 强调 Firefly 训练数据的安全性和排他性，暗示其模型比竞争对手更有商业可行性。但事实上，Adobe 也在利用竞争对手的技术成果来改进自己的模型。这提醒我们，在评估不同公司的人工智能产品时，不能完全相信其营销宣传，还需要深入了解其技术实现细节。  <br />- 这一事件也反映出当前人工智能领域的一个普遍问题：训练数据的来源和使用方式缺乏透明度和监管。随着人工智能技术的快速发展，我们需要建立更加完善的行业标准和规范，确保企业以负责任和道德的方式开发和应用这些强大的工具。<br />《Adobe’s AI Firefly Used AI-Generated Images From Rivals for Training - Bloomberg》 <a href="https://www.bloomberg.com/news/articles/2024-04-12/adobe-s-ai-firefly-used-ai-generated-images-from-rivals-for-training"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoox9p5ofnj20vh0u0q76.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 00:57:19 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：后天开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《LangChain实战》，截至2024.4.15 12:00，...</title>
<link>https://weibo.com/1402400261/O9tvGx09O</link>
<guid>https://weibo.com/1402400261/O9tvGx09O</guid>
<content:encoded><![CDATA[
<div> LangChain、LangServe、LangSmith、LLM、初学者、开发者、应用场景、LCEL、生成式人工智能领域

<br /><br />总结:
文章介绍了一本名为《LangChain实战》的书籍，面向初学者和对LangChain和LLM应用感兴趣的开发者。该书基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，深入探讨了LCEL的应用方式。围绕LangChain生态系统的概念，详细探讨了LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。活动要求转发+评论参与抽奖，奖品是《LangChain实战》书籍。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：后天开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.15 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a>  <a href="https://shop.sc.weibo.com/h5/goods/index?iid=110014024002610004661854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">LangChain实战：从原型到生产，动手打造 LLM 应用</span></a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hofl98oom9j207q0a0jrm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 22:26:26 GMT</pubDate>
</item>
<item>
<title>今日推介(第1374期)：语言模型合成数据的最佳实践和经验教训、不是所有Token都是必需的、超越Transformer的高效开放语言模型、离线学习长上下文、梯度网络(GradN...</title>
<link>https://weibo.com/1402400261/O9tkac2oq</link>
<guid>https://weibo.com/1402400261/O9tkac2oq</guid>
<content:encoded><![CDATA[
<div> 语言模型、合成数据、最佳实践、经验教训、Token、高效开放语言模型、Transformer、离线学习、长上下文、梯度网络

总结:<br />
本文介绍了关于语言模型合成数据的最佳实践和经验教训，强调了不是所有Token都是必需的。提出了超越Transformer的高效开放语言模型的概念，探讨了离线学习长上下文的方法。最后介绍了梯度网络（GradNet）的相关内容。文章内容丰富，为语言模型领域的研究提供了一定的指导和启发。 <div>
今日推介(第1374期)：语言模型合成数据的最佳实践和经验教训、不是所有Token都是必需的、超越Transformer的高效开放语言模型、离线学习长上下文、梯度网络(GradNet) 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/692232301"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoos2s5kicj21070u0qa9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoos2un2fgj21mn0u0tgb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoos2x5tv5j21j20tmaf0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoos30dsdgj218c0smjui.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoos33388oj21de0py775.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:58:03 GMT</pubDate>
</item>
<item>
<title>[LG] Post-Hoc Reversal: Are We Selecting Models Prematurely? 网页链接 通过探索后处理反转现象，发现仅考虑基础性能进行模型选择是不恰当的，而应当采用后处...</title>
<link>https://weibo.com/1402400261/O9tgKuUwU</link>
<guid>https://weibo.com/1402400261/O9tgKuUwU</guid>
<content:encoded><![CDATA[
<div> 后处理反转、模型选择、基础性能、后处理指标、优结果、探索、选择、需谨慎、有效性、模型预测

总结:<br /><br />本文探讨了后处理反转现象，认为仅考虑基础性能进行模型选择是不可取的。文章强调应该使用后处理指标来选择模型，从而获得更好的结果。作者指出模型预测的有效性需要进行深入研究，选择模型时需要谨慎考虑各种指标，以确保最终结果的准确性和可靠性。 <div>
[LG] Post-Hoc Reversal: Are We Selecting Models Prematurely?  <br /><a href="https://arxiv.org/abs/2404.07815"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过探索后处理反转现象，发现仅考虑基础性能进行模型选择是不恰当的，而应当采用后处理指标进行模型选择，从而获得更优结果。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooruehe42j20v81d4h0f.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoorueospmj21dc0r6k1l.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooruf1tk1j21dg0jowjv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:49:38 GMT</pubDate>
</item>
<item>
<title>[CL] Interactive Prompt Debugging with Sequence Salience 网页链接 提出Sequence Salience系统，通过交互式可视化输入显著性，支持大型语言模型复杂提示的调...</title>
<link>https://weibo.com/1402400261/O9tdBreFd</link>
<guid>https://weibo.com/1402400261/O9tdBreFd</guid>
<content:encoded><![CDATA[
<div> Sequence Salience, 交互式, 可视化, 输入显著性, 大型语言模型, 调试, 快速迭代优化

Sequence Salience系统为用户提供了一种交互式的可视化方式，用于显示输入中的显著性信息，从而支持大型语言模型的复杂提示的调试和快速迭代优化。用户可以通过该系统更直观地了解语言模型中关键提示的作用，从而进行有效的优化和调整。通过交互式的界面设计，用户可以快速定位和解决问题，提高工作效率。总结: 摒弃繁琐的调试方式，提供可视化的交互体验，帮助用户快速优化语言模型。 <div>
[CL] Interactive Prompt Debugging with Sequence Salience  <br /><a href="https://arxiv.org/abs/2404.07498"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />提出Sequence Salience系统，通过交互式可视化输入显著性，支持大型语言模型复杂提示的调试和快速迭代优化。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoormcbcowj20vw1c8dyi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoormcldxbj21ay11qna9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoormcth0vj20ng0rudkn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:41:53 GMT</pubDate>
</item>
<item>
<title>[LG] An Overview of Diffusion Models: Applications, Guided Generation, Statistical Rates and Optimization 网页链接 全面回顾了扩散模型的应用和理论研究...</title>
<link>https://weibo.com/1402400261/O9taQpbfj</link>
<guid>https://weibo.com/1402400261/O9taQpbfj</guid>
<content:encoded><![CDATA[
<div> 扩散模型、理论研究、应用、生成性、条件引导、不足、未来方向、系统性、素材、视角

总结:<br /><br />本文全面回顾了扩散模型的应用和理论研究现状，强调了条件引导下的可控生成性。文章指出了理论研究存在的不足，并探讨了未来可能的研究方向，为推进扩散模型研究提供了系统性的素材和视角。整体来看，本文对扩散模型的应用及其在不同领域中的指导意义进行了深入探讨，有助于进一步推动相关研究的发展。 <div>
[LG] An Overview of Diffusion Models: Applications, Guided Generation, Statistical Rates and Optimization  <br /><a href="https://arxiv.org/abs/2404.07771"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />全面回顾了扩散模型的应用和理论研究现状，强调了条件引导下的可控生成性，指出理论研究的不足与未来可能方向，为推进扩散模型研究提供了系统性的素材和视角。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoorf8j2maj2114178dsh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoorf8pahcj21ga0t87ac.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoorf9dnw6j21gs0gmwiv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:35:05 GMT</pubDate>
</item>
<item>
<title>[CL] ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models 网页链接 提出一个强大的语言模型框架Resear...</title>
<link>https://weibo.com/1402400261/O9t868FpK</link>
<guid>https://weibo.com/1402400261/O9t868FpK</guid>
<content:encoded><![CDATA[
<div> 关键词: ResearchAgent, 语言模型, 知识库, 迭代评价机制, 科研想法, 高质量, 自动生成, 框架, 目标

总结:<br /><br />
本文提出了一个名为ResearchAgent的强大语言模型框架，通过构建知识库和设计迭代评价机制，实现了自动生成高质量科研想法的目标。ResearchAgent结合了先进的语言模型技术，能够在科学文献中生成创新性的研究思路。通过不断迭代和评价，可以帮助研究人员提出更具实际意义的科研主题，促进科学研究的发展。这一框架为科研思路的自动生成提供了一种新的途径，有望提升科研领域的创新能力和效率。ResearchAgent的应用潜力巨大，未来可以进一步改进和拓展，为科研人员带来更多的启发和创新思路。 <div>
[CL] ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models  <br /><a href="https://arxiv.org/abs/2404.07738"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出一个强大的语言模型框架ResearchAgent，利用构建知识库和设计迭代评价机制，实现了自动生成高质量科研想法的目标。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoor884iosj20x61csngf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoor889pwsj21h80cw0yi.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoor88jcjhj21220rejuz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:28:19 GMT</pubDate>
</item>
<item>
<title>提出梯度网络GradNet直接参数化并学习函数梯度，给出设计框架，证明可普适逼近广泛梯度函数类，经验表现优越。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Gradient Net...</title>
<link>https://weibo.com/1402400261/O9t5zuKmx</link>
<guid>https://weibo.com/1402400261/O9t5zuKmx</guid>
<content:encoded><![CDATA[
<div> Gradient Networks, 参数化, 学习函数梯度, 普适逼近, 广泛梯度函数类, 经验表现优越<br />
<br />
1. 本文提出了梯度网络GradNet直接参数化并学习函数梯度的方法。
2. 设计了框架来实现GradNet，证明其可以普适逼近广泛的梯度函数类。
3. 实验证明GradNet在经验表现上具有优越性。
4. 作者分别是S Chaudhari, S Pranav, J M. F. Moura，来自CMU。
<br /><br />总结: 本文介绍了一种新方法GradNet，通过参数化和学习函数梯度来逼近广泛的梯度函数类，在实验中表现优越。 <div>
提出梯度网络GradNet直接参数化并学习函数梯度，给出设计框架，证明可普适逼近广泛梯度函数类，经验表现优越。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Gradient Networks》S Chaudhari, S Pranav, J M. F. Moura [CMU] (2024) <a href="https://arxiv.org/abs/2404.07361"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hooqt70o3xj218m0qwk1m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqt7lzm0j21de0pyq6h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hooqt7ptf5j21f20e8wgh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqt7u9qzj21cw0f00uc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoor1ne0pvj20p50w940f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoor1ndv3qj210x0a5q41.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoor1ndwwkj20p50wa40k.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoor1ndekoj210x0a8jsd.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:22:06 GMT</pubDate>
</item>
<item>
<title>[LG]《Gradient Networks》S Chaudhari, S Pranav, J M. F. Moura [CMU] (2024) 网页链接 #机器学习##人工智能##论文# [图片][图片][图片][图片][图片][图片][图...</title>
<link>https://weibo.com/1402400261/O9t5x2tdX</link>
<guid>https://weibo.com/1402400261/O9t5x2tdX</guid>
<content:encoded><![CDATA[
<div> Gradient Networks, S Chaudhari, S Pranav, J M. F. Moura, CMU, 2024<br />
<br />
总结:<br />
本文提出了一种名为Gradient Networks的新型网络模型，旨在处理复杂的图形数据。该模型利用梯度信息来学习网络结构，实现高效的数据处理和表示学习。通过实验证明，Gradient Networks在处理图形数据方面具有优势，并在各种任务中取得了良好的性能。这种新型网络模型为图形数据的分析和应用提供了新的思路，有望在各个领域获得广泛应用。 <div>
[LG]《Gradient Networks》S Chaudhari, S Pranav, J M. F. Moura [CMU] (2024) <a href="https://arxiv.org/abs/2404.07361"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hooqt70o3xj218m0qwk1m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqt7lzm0j21de0pyq6h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hooqt7ptf5j21f20e8wgh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqt7u9qzj21cw0f00uc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoor1ne0pvj20p50w940f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoor1ndv3qj210x0a5q41.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoor1ndwwkj20p50wa40k.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoor1ndekoj210x0a8jsd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:22:00 GMT</pubDate>
</item>
<item>
<title>通过序列压缩和参数高效微调实现了长序列的有效离线学习，使语言模型能够基于长文档的紧凑表示生成高质量的回复。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《LLoCO: Le...</title>
<link>https://weibo.com/1402400261/O9t0EkEL2</link>
<guid>https://weibo.com/1402400261/O9t0EkEL2</guid>
<content:encoded><![CDATA[
<div> CL, LLoCO, 学习, 长序列, 压缩, 参数, 高效, 微调, 离线学习, 语言模型

<br /><br />总结:
本文介绍了一种名为LLoCO的学习长上下文的离线学习方法，通过序列压缩和参数微调实现了对长序列的有效学习。该方法能够生成高质量的回复，使语言模型能够基于长文档的紧凑表示进行生成。研究者在UC Berkeley进行了相关研究，有效提升了语言模型的表现。该方法的创新之处在于能够处理长文档的信息，并通过压缩和微调参数，在离线环境下实现了高效的学习过程。通过实验验证了该方法的有效性和可行性，为语言模型的进一步发展提供了新的思路和方法。 <div>
通过序列压缩和参数高效微调实现了长序列的有效离线学习，使语言模型能够基于长文档的紧凑表示生成高质量的回复。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《LLoCO: Learning Long Contexts Offline》S Tan, X Li, S Patil, Z Wu… [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.07979"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqosi9ssj21600ryamu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqoswzm5j21ds0nyjxz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hooqot2cywj218c0smtcd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqot7shqj21de0p6ago.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqox885cj20uu0cpabp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqox85tbj20vh0f2jtm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:09:58 GMT</pubDate>
</item>
<item>
<title>[CL]《LLoCO: Learning Long Contexts Offline》S Tan, X Li, S Patil, Z Wu… [UC Berkeley] (2024) 网页链接 #机器学习##人工智能##论文# [图片][图片][图片][...</title>
<link>https://weibo.com/1402400261/O9t0Aaj0w</link>
<guid>https://weibo.com/1402400261/O9t0Aaj0w</guid>
<content:encoded><![CDATA[
<div> 长文本；离线学习；上下文；学习模型；UC Berkeley；2024；Tan；Li；Patil；Wu

<br /><br />总结:
这篇文章是关于离线学习长文本上下文的研究。研究团队来自加州大学伯克利分校，发表于2024年。他们提出了一种名为LLoCO的学习模型，旨在解决长文本中上下文信息的学习问题。通过对文本内容进行离线学习，该模型可以更好地捕捉文本之间的关联性，提高学习效果。Tan、Li、Patil和Wu是本研究的主要作者。 <div>
[CL]《LLoCO: Learning Long Contexts Offline》S Tan, X Li, S Patil, Z Wu… [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.07979"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqosi9ssj21600ryamu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqoswzm5j21ds0nyjxz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hooqot2cywj218c0smtcd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqot7shqj21de0p6ago.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqox885cj20uu0cpabp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqox85tbj20vh0f2jtm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:09:48 GMT</pubDate>
</item>
<item>
<title>RecurrentGemma 通过固定大小状态实现了与Gemma-2B媲美的语言理解能力，同时大幅提升了长序列推理效率，可支持更广泛的应用。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]...</title>
<link>https://weibo.com/1402400261/O9t0984hI</link>
<guid>https://weibo.com/1402400261/O9t0984hI</guid>
<content:encoded><![CDATA[
<div> RecurrentGemma, Gemma-2B, 语言理解能力, 长序列推理效率, 应用, 固定大小状态<br />
<br />
总结:<br />
本文介绍了RecurrentGemma模型，该模型通过固定大小状态实现了与Gemma-2B相当的语言理解能力，并大幅提升了长序列推理效率，使其能够支持更广泛的应用。该模型在效率和性能上超越了传统的Transformer模型，展现了更高的潜力和实用性。RecuurentGemma的提出对于提高开放式语言模型的效率和性能具有重要意义，为相关领域的研究和应用带来新的启发和发展方向。 <div>
RecurrentGemma 通过固定大小状态实现了与Gemma-2B媲美的语言理解能力，同时大幅提升了长序列推理效率，可支持更广泛的应用。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《RecurrentGemma: Moving Past Transformers for Efficient Open Language Models》A Botev, S De, S L Smith, A Fernando… [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2404.07839"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqnnmhprj21je09sgqc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqno3gzyj21j20tmq8o.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:08:44 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.12)》 爱可可微博热门分享(4.12) [图片]</title>
<link>https://weibo.com/1402400261/O9qsCEvRE</link>
<guid>https://weibo.com/1402400261/O9qsCEvRE</guid>
<content:encoded><![CDATA[
<div> 爱可可 微博 热门 分享 4.12 关键词

总结:
在4月12日的热门分享中，爱可可微博上涵盖了各种各样的内容。其中包括了一些新奇有趣的视频，如可爱的小动物视频和搞笑的日常生活片段。另外，还有一些与时事热点相关的文章，引起了许多网友的讨论和转发。除此之外，也涉及了一些美食、旅行和健康等方面的话题，吸引了广大粉丝的关注。总体而言，这些内容丰富多彩，让人在忙碌的生活中得到一丝放松和快乐。 <div>
《爱可可微博热门分享(4.12)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405022466711093588"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.12)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hooffyjaexj20d607egm0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 14:40:39 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《STORM: Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking》(NAACL 2024) GitHub: github.com/stanfo...</title>
<link>https://weibo.com/1402400261/O9pse4L6U</link>
<guid>https://weibo.com/1402400261/O9pse4L6U</guid>
<content:encoded><![CDATA[
<div> STORM, Topic Outlines, Retrieval, Multi-perspective Question Asking, GitHub, OpenEQA, Embodied Question Answering, Foundation Models, Taming Stable Diffusion, Text to 360° Panorama Image Generation, matching, 2D Images, 3D, Metric Relative Pose, Softmax Attention, Constant Cost per Token, Text-to-Visual Generation, Image-to-Text Generation, OSWorld, Multimodal Agents, Open-Ended Tasks, Real Computer Environments, Rho-1, Tokens, Mira, Long Video Generation, Urban Architect, 3D Urban Scene Generation, Scaling Laws, Data Filtering, InstantMesh, 3D Mesh Generation, Audio Systems, VisualWebBench, Multimodal LLMs, Web Page Understanding, No Zero-Shot, Exponential Data, Pretraining Concept Frequency, PCToolkit, Prompt Compression Toolkit, Large Language Models, 3D Gaussian Splatting, Real-Time Radiance Field Rendering 

<br /><br />总结:
1. "STORM"是利用检索和多角度提问实现主题大纲的论文，提供了GitHub链接。
2. "OpenEQA"关注基于基础模型的具身问答，提供了GitHub链接。
3. "Taming Stable Diffusion"探讨了将文本转换为360度全景图像生成的问题，提供了GitHub链接。
4. "Matching 2D Images in 3D"介绍了利用度量相关姿态从度量对应关系中匹配2D图像和3D姿势。
5. "Softmax Attention with Constant Cost per Token"介绍了一种具有固定代价的每个标记的Softmax注意力机制。
6. "Evaluating Text-to-Visual Generation with Image-to-Text Generation"比较了文本到视觉生成和图像到文本生成的性能。
7. "OSWorld"提供多模态代理在现实计算环境中开放任务的基准测试。
8. "Rho-1"论文探讨了不是所有标记都是所需的问题。
9. "Mira"是视频生成方面的探索性研究，提供了GitHub链接。
10. "Urban Architect"关注带有布局先验的可导航3D城市场景生成。 <div>
几篇论文实现代码：<br />《STORM: Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking》(NAACL 2024) GitHub: github.com/stanford-oval/storm [fig1]<br />《OpenEQA: Embodied Question Answering in the Era of Foundation Models》(CVPR 2024) GitHub: github.com/facebookresearch/open-eqa<br />《Taming Stable Diffusion for Text to 360° Panorama Image Generation》(CVPR 2024) GitHub: github.com/chengzhag/PanFusion<br />《Matching 2D Images in 3D: Metric Relative Pose from Metric Correspondences》(CVPR 2024) GitHub: github.com/nianticlabs/mickey <br />《Softmax Attention with Constant Cost per Token》(2024) GitHub: github.com/glassroom/heinsen_attention<br />《Evaluating Text-to-Visual Generation with Image-to-Text Generation》(2024) GitHub: github.com/linzhiqiu/t2v_metrics<br />《OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments》(2024) GitHub: github.com/xlang-ai/OSWorld<br />《Rho-1: Not All Tokens Are What You Need》(2024) GitHub: github.com/microsoft/rho [fig2]<br />《Mira: A Mini-step Towards Sora-like Long Video Generation》(2024) GitHub: github.com/mira-space/Mira<br />《Urban Architect: Steerable 3D Urban Scene Generation with Layout Prior》(2024) GitHub: github.com/UrbanArchitect/UrbanArchitect<br />《Scaling Laws for Data Filtering》(2024) GitHub: github.com/locuslab/scaling_laws_data_filtering<br />《InstantMesh: Efficient 3D Mesh Generation from a Single Image with Sparse-view Large Reconstruction Models》(2024) GitHub: github.com/TencentARC/InstantMesh<br />《Differentiable All-pole Filters for Time-varying Audio Systems》(2024) GitHub: github.com/DiffAPF/TB-303<br />《VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page Understanding and Grounding?》(2024) GitHub: github.com/VisualWebBench/VisualWebBench [fig3] <br />《No Zero-Shot Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance》(2024) GitHub: github.com/bethgelab/frequency_determines_performance<br />《PCToolkit: A Unified Plug-and-Play Prompt Compression Toolkit of Large Language Models》(2024) GitHub: github.com/3DAgentWorld/Toolkit-for-Prompt-Compression<br />《3D Gaussian Splatting for Real-Time Radiance Field Rendering》(2024) GitHub: github.com/leo-frank/diff-gaussian-rasterization-depth<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoo9glfyjfj20kb08k0tl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoo9hxtl93j221p0tx4kw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hooasiux0hj21310n7h9u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 12:06:55 GMT</pubDate>
</item>
<item>
<title>【Narwhals：轻量可扩展的数据框架兼容层，支持 Polars、pandas、cuDF、Modin 等多种数据框架】'Narwhals - Lightweight and extensible compatibility layer be...</title>
<link>https://weibo.com/1402400261/O9prl9em4</link>
<guid>https://weibo.com/1402400261/O9prl9em4</guid>
<content:encoded><![CDATA[
<div> 轻量、可扩展、数据框架、兼容层、Polars、pandas、cuDF、Modin、GitHub、MarcoGorelli/narwhals

<br /><br />总结:
Narwhals是一个轻量、可扩展的数据框架兼容层，支持Polars、pandas、cuDF、Modin等多种数据框架。用户可以通过GitHub上的MarcoGorelli/narwhals获取相关信息和使用资源。这个工具为不同数据框架之间的兼容性提供了便利，让用户可以快速在不同框架之间切换和转换数据，提高工作效率。由于支持的数据框架种类多样，Narwhals可满足不同用户的需求，为数据处理工作带来了更大的灵活性和便利性。 <div>
【Narwhals：轻量可扩展的数据框架兼容层，支持 Polars、pandas、cuDF、Modin 等多种数据框架】'Narwhals - Lightweight and extensible compatibility layer between Polars, pandas, cuDF, Modin, and more!' GitHub: github.com/MarcoGorelli/narwhals <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hooaxs9rklj20u010q79u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 12:04:43 GMT</pubDate>
</item>
<item>
<title>【ADS-B Massive Visualizer：ADS-B 航班数据的交互式可视化和分析】'ADS-B Massive Visualizer - Interactive visualization and analytics on ADS-B data with...</title>
<link>https://weibo.com/1402400261/O9pqL7mwe</link>
<guid>https://weibo.com/1402400261/O9pqL7mwe</guid>
<content:encoded><![CDATA[
<div> GitHub、ADS-B、航班数据、可视化、分析、交互式、ClickHouse、adsb.exposed<br />
<br />
关键词提取完毕，这是一篇介绍ADS-B航班数据交互式可视化和分析工具ADS-B Massive Visualizer的GitHub项目。该工具基于ClickHouse技术，能够实现对ADS-B数据的交互式可视化和分析。用户可以通过这个工具来更深入地了解ADS-B航班数据，实时跟踪航班位置和信息，帮助航空公司等相关机构进行航班管理和监控。通过GitHub链接可以查看该工具的具体实现和功能介绍。如果你对ADS-B数据感兴趣，可以尝试使用这个工具来进行数据的可视化和分析。<br /><br />总结: 介绍了一款基于ClickHouse技术的ADS-B航班数据交互式可视化和分析工具ADS-B Massive Visualizer，能够实现对ADS-B数据的实时跟踪和信息分析，帮助航空公司进行航班管理和监控。GitHub链接提供了工具的具体实现和功能介绍。 <div>
【ADS-B Massive Visualizer：ADS-B 航班数据的交互式可视化和分析】'ADS-B Massive Visualizer - Interactive visualization and analytics on ADS-B data with ClickHouse' GitHub: github.com/ClickHouse/adsb.exposed <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%8F%AF%E8%A7%86%E5%8C%96%23&amp;isnewpage=1"><span class="surl-text">#可视化#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hooav84th2j21590u01kx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hooav980k5j20uc0u0qcx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hooav9zt81j210l0u07fo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 12:03:18 GMT</pubDate>
</item>
<item>
<title>【PCToolkit: 统一的即插即用大语言模型提示压缩工具包】'PCToolkit: A Unified Plug-and-Play Prompt Compression Toolkit of Large Language Models - Toolkit...</title>
<link>https://weibo.com/1402400261/O9ppWAvO2</link>
<guid>https://weibo.com/1402400261/O9ppWAvO2</guid>
<content:encoded><![CDATA[
<div> GitHub, PCToolkit, 统一, 即插即用, 大语言模型, 提示压缩, 工具包, 模型, 压缩工具

<br /><br />总结：
PCToolkit 是一个统一的即插即用的大语言模型提示压缩工具包，旨在提供便捷的使用体验。该工具可以用于压缩大语言模型中的提示信息，提高模型的效率和性能。用户可以通过 GitHub 找到这个工具包，并按照文档指南进行使用。PCToolkit 的设计灵活多样，可以适用于不同的大语言模型，为语言模型的应用提供了更便捷和高效的解决方案。 <div>
【PCToolkit: 统一的即插即用大语言模型提示压缩工具包】'PCToolkit: A Unified Plug-and-Play Prompt Compression Toolkit of Large Language Models - Toolkit for Prompt Compression' GitHub: github.com/3DAgentWorld/Toolkit-for-Prompt-Compression <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hooau9etyxj21520l5jue.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 12:01:18 GMT</pubDate>
</item>
<item>
<title>【SDFX：通过漂亮界面构建和分享AI应用的无代码平台】’SDFX - The ultimate no-code platform to build and share AI apps with beautiful UI.' GitHub: github...</title>
<link>https://weibo.com/1402400261/O9poGiiWH</link>
<guid>https://weibo.com/1402400261/O9poGiiWH</guid>
<content:encoded><![CDATA[
<div> AI应用、无代码平台、漂亮界面、构建、分享、GitHub、SDFX

<br /><br />总结:
SDFX是一个无代码平台，可帮助用户构建和分享AI应用，拥有漂亮的界面设计。用户无需编写代码，只需通过SDFX平台即可快速构建功能强大的AI应用。同时，SDFX也提供GitHub仓库，用户可以访问github.com/sdfxai/sdfx获取更多信息。 <div>
【SDFX：通过漂亮界面构建和分享AI应用的无代码平台】’SDFX - The ultimate no-code platform to build and share AI apps with beautiful UI.' GitHub: github.com/sdfxai/sdfx <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hooaqt2y40j21by0u0aga.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hooaqw2p99j21by0u0jxc.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hooaqy3hpyj21by0u0dml.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:58:10 GMT</pubDate>
</item>
<item>
<title>【Next.js AI Chatbot：由 Vercel 和 Next.js 团队成员构建的生成式 UI 聊天机器人模板，基于 Vercel AI SDK 和 Google Gemini】'Next.js AI Chatbot - Build yo...</title>
<link>https://weibo.com/1402400261/O9po1sfbq</link>
<guid>https://weibo.com/1402400261/O9po1sfbq</guid>
<content:encoded><![CDATA[
<div> Next.js, AI, Chatbot, Vercel, UI, SDK, Google, Gemini

总结:<br /><br />这是一个由Vercel和Next.js团队成员构建的生成式UI聊天机器人模板，使用Vercel AI SDK和Google Gemini。用户可以借助这个模板来构建自己的UI聊天机器人，通过集成AI技术提供更智能的对话和服务。同时，这个项目也展示了如何利用现有的工具和技术来创建高效的交互体验，具有一定的实用性和学习参考价值。 <div>
【Next.js AI Chatbot：由 Vercel 和 Next.js 团队成员构建的生成式 UI 聊天机器人模板，基于 Vercel AI SDK 和 Google Gemini】'Next.js AI Chatbot - Build your own generative UI chatbot using the Vercel AI SDK and Google Gemini' GitHub: github.com/vercel-labs/gemini-chatbot <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hooapbyjqoj20xc0hgabm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:56:34 GMT</pubDate>
</item>
<item>
<title>【Gemini API Cookbook：Gemini API 的指南和示例集合】'Welcome to the Gemini API Cookbook - A collection of guides and examples for the Gemini API.' Git...</title>
<link>https://weibo.com/1402400261/O9peN6kdf</link>
<guid>https://weibo.com/1402400261/O9peN6kdf</guid>
<content:encoded><![CDATA[
<div> Gemini API Cookbook, guides, examples, Gemini API, collection, GitHub, google-gemini

Gemini API Cookbook是一个收集了Gemini API的指南和示例的资源集合，可以在GitHub上找到。用户可以通过这个资源集合快速了解Gemini API的使用方法，并通过示例代码实际操作。这个资源集合对于初学者来说非常有帮助，可以帮助他们快速上手并熟悉Gemini API的各种功能。同时，这个Cookbook也提供了一些高级用法和技巧，对于有经验的开发者也是一个很好的参考资料。通过阅读这个Cookbook，用户可以更好地理解和利用Gemini API，在开发过程中更加高效地实现自己的项目需求。<br /><br />总结:Gemini API Cookbook是一个集合了Gemini API指南和示例的资源，适合初学者和有经验的开发者阅读使用。 <div>
【Gemini API Cookbook：Gemini API 的指南和示例集合】'Welcome to the Gemini API Cookbook - A collection of guides and examples for the Gemini API.' GitHub: github.com/google-gemini/cookbook <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hooa1nctstj21ji0nmgqu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:33:49 GMT</pubDate>
</item>
<item>
<title>【用于评估语言模型准确性的轻量库，包含多个评估，如 MMLU、MATH、GPQA、DROP、MGSM 和 HumanEval，并为 OpenAI 和 Anthropic API 提供了采样接口】’This repo...</title>
<link>https://weibo.com/1402400261/O9p60d29z</link>
<guid>https://weibo.com/1402400261/O9p60d29z</guid>
<content:encoded><![CDATA[
<div> 评估语言模型准确性, 轻量库, MMLU, MATH, GPQA, DROP, MGSM, HumanEval, OpenAI, Anthropic API

<br /><br />总结:
这篇文章介绍了一个用于评估语言模型准确性的轻量库，其中包含了多个评估指标，如MMLU、MATH、GPQA、DROP、MGSM和HumanEval。这个库为OpenAI和Anthropic API提供了采样接口，帮助评估语言模型的性能并提供反馈。这个工具对于评估和改进语言模型的准确性和效果非常有用。 <div>
【用于评估语言模型准确性的轻量库，包含多个评估，如 MMLU、MATH、GPQA、DROP、MGSM 和 HumanEval，并为 OpenAI 和 Anthropic API 提供了采样接口】’This repository contains a lightweight library for evaluating language models' GitHub: github.com/openai/simple-evals <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoo9f52n6oj20v40u043n.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:12:10 GMT</pubDate>
</item>
<item>
<title>'Awesome DUSt3R Resources - A curated list of DUSt3R-related papers and resources, tracking recent advancements using this geometric foundation model....</title>
<link>https://weibo.com/1402400261/O9p408SUu</link>
<guid>https://weibo.com/1402400261/O9p408SUu</guid>
<content:encoded><![CDATA[
<div> GitHub, DUSt3R, 资源, 论文, 进展, 几何基础模型, 最新, 高级<br />
<br />
提到的GitHub资源收集了与基于DUSt3R模型的相关论文和资源，跟踪最新的进展。DUSt3R模型作为一种几何基础模型，被用于研究和发展进步。这个GitHub项目整理了相关文献和资源，方便研究者和开发者了解这一领域的最新动态和高级应用。<br />
<br />
总结: <br />这个GitHub项目整理了与DUSt3R模型相关的论文和资源，跟踪最新进展，为研究者提供了更多深入了解和探索这一领域的机会。 <div>
'Awesome DUSt3R Resources - A curated list of DUSt3R-related papers and resources, tracking recent advancements using this geometric foundation model.' GitHub: github.com/ruili3/awesome-dust3r <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoo9a0gzxkj21fb0u0gq4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:07:14 GMT</pubDate>
</item>
<item>
<title>【OmniFusion：高级的多模态 AI 模型，旨在通过集成其他数据模态（如图像、音频、3D 和视频内容）来扩展传统语言处理系统的功能】'OmniFusion - OmniFusion — a...</title>
<link>https://weibo.com/1402400261/O9p3KpLtL</link>
<guid>https://weibo.com/1402400261/O9p3KpLtL</guid>
<content:encoded><![CDATA[
<div> OmniFusion, 高级, 多模态, AI, 模型, 图像, 音频, 3D, 视频内容

<br /><br />总结:
OmniFusion是一个高级的多模态AI模型，旨在通过集成其他数据模态（如图像、音频、3D和视频内容）来扩展传统语言处理系统的功能。该模型能够同时处理文本和图像，实现文本和图像之间的交流。通过整合不同的数据模态，OmniFusion能够更全面地理解和处理信息，提高系统的功能和效率。GitHub链接：github.com/AIRI-Institute/omnifusion。OmniFusion的引入将为多模态AI研究和应用带来新的可能性，提升系统的交互和表达能力。 <div>
【OmniFusion：高级的多模态 AI 模型，旨在通过集成其他数据模态（如图像、音频、3D 和视频内容）来扩展传统语言处理系统的功能】'OmniFusion - OmniFusion — a multimodal model to communicate using text and images' GitHub: github.com/AIRI-Institute/omnifusion <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoo999u11xj228u0u0458.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoo99c65grj217u0u0n4a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoo99ddmcbj212v0u0qaw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:06:37 GMT</pubDate>
</item>
<item>
<title>【Red-Teaming Language Models with DSPy：介绍了使用 DSPy 框架对语言模型进行红队攻击的尝试，展示了用 DSPy 编译后的架构效果】'Red-Teaming Language Model...</title>
<link>https://weibo.com/1402400261/O9p376LlY</link>
<guid>https://weibo.com/1402400261/O9p376LlY</guid>
<content:encoded><![CDATA[
<div> DSPy, 语言模型, 红队攻击, 框架, GitHub, 编译, 架构效果

<br /><br />总结:
本文介绍了使用DSPy框架对语言模型进行红队攻击的尝试。作者展示了通过DSPy编译后的架构效果。DSPy是一个开源的工具，可以帮助研究人员对语言模型进行攻击和测试。作者在GitHub上分享了该项目的代码，并提供了详细的文档和示例。这种红队攻击技术可以帮助提高语言模型的安全性，以防止恶意利用和攻击。通过使用DSPy框架，研究人员可以更好地了解语言模型的弱点，并及时修复漏洞，从而保护用户的隐私和数据安全。 <div>
【Red-Teaming Language Models with DSPy：介绍了使用 DSPy 框架对语言模型进行红队攻击的尝试，展示了用 DSPy 编译后的架构效果】'Red-Teaming Language Models with DSPy - Red-Teaming Language Models with DSPy' GitHub: github.com/haizelabs/dspy-redteam <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoo97q3zkxj20u00vrn1f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:05:03 GMT</pubDate>
</item>
<item>
<title>【Data-Speech：用于标注语音数据集的实用脚本套件，旨在为基于语音的人工智能模型（如文本到语音引擎）开发过程中所需要的音频变换（或注释）提供简洁、干净的...</title>
<link>https://weibo.com/1402400261/O9p2BtxOz</link>
<guid>https://weibo.com/1402400261/O9p2BtxOz</guid>
<content:encoded><![CDATA[
<div> 标注,语音数据集,脚本套件,基于语音的人工智能模型,音频变换,注释,简洁,干净,代码库

<br /><br />总结:
Data-Speech是一个用于标注语音数据集的实用脚本套件，旨在为基于语音的人工智能模型开发过程中所需的音频变换提供简洁、干净的代码库。该工具能够帮助开发者更有效地处理语音数据，提高模型的性能和准确性。通过提供丰富的功能和简单易用的代码库，Data-Speech为语音领域的研究和开发提供了极大的便利性。 <div>
【Data-Speech：用于标注语音数据集的实用脚本套件，旨在为基于语音的人工智能模型（如文本到语音引擎）开发过程中所需要的音频变换（或注释）提供简洁、干净的代码库】'Data-Speech' GitHub: github.com/huggingface/dataspeech <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoo96flfpwj211s0u0tee.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:03:48 GMT</pubDate>
</item>
<item>
<title>恭喜@是橙子也是樱桃 等3名用户获得【《大语言模型：基础与前沿》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效。公示链接：网页链...</title>
<link>https://weibo.com/1402400261/O9mij0DVB</link>
<guid>https://weibo.com/1402400261/O9mij0DVB</guid>
<content:encoded><![CDATA[
<div> 大语言模型、基础、前沿、抽奖、公示链接、转发、评论、科学家、工程师、学生

<br /><br />总结:
本文介绍了微博官方举办的抽奖活动，恭喜三名用户获得《大语言模型：基础与前沿》。活动由官方抽奖工具监督，公正有效。用户可通过转发和评论参与抽奖，截止时间为2024年4月12日12:00。这本书全面深入介绍了大语言模型及其前沿进展，适合科学家、工程师和学生参考。书籍摒弃了纯理论，以案例入手，采用庖丁解牛的方式帮助读者理解大语言模型的相关知识。 <div>
恭喜<a href="https://weibo.com/n/%E6%98%AF%E6%A9%99%E5%AD%90%E4%B9%9F%E6%98%AF%E6%A8%B1%E6%A1%83">@是橙子也是樱桃</a> 等3名用户获得【《大语言模型：基础与前沿》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20359960&amp;pageid=100140E51198950"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%BC%82%E6%AD%A5%E5%9B%BE%E4%B9%A6">@异步图书</a>  送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。摒弃了纯理论的说教模式，从案例入手， 采用庖丁解牛的方式帮助读者理解与认识大语言模型。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019331269755053"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef8oboqij20ga0m8q8p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9segl7j20m90m9q6z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9t5km0j20m90m942f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef9tq2esj20m90m9gpe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef9ugq5dj20m90m9dif.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 04:04:13 GMT</pubDate>
</item>
<item>
<title>今日推介(第1373期)：基于Infini-attention的高效无限上下文Transformer、极限中的语言生成、长上下文语言模型的上下文实际有多长、上下文学习回路及其形成机制...</title>
<link>https://weibo.com/1402400261/O9jZL8hC5</link>
<guid>https://weibo.com/1402400261/O9jZL8hC5</guid>
<content:encoded><![CDATA[
<div> 高效、无限上下文Transformer、Infini-attention、极限中、语言生成、长上下文、语言模型、上下文实际长度、上下文学习回路、形成机制研究<br />
<br />
上下文学习回路及其形成机制研究、基于Infini-attention的高效无限上下文Transformer、极限中的语言生成、长上下文语言模型的上下文实际有多长、大型语言模型如何用不同层获取知识<br />
<br />
总结:本文探讨了基于Infini-attention的高效无限上下文Transformer，研究了语言生成在极限情况下的表现，分析了长上下文语言模型中实际上下文的长度，探讨了上下文学习回路及其形成机制。同时，还讨论了大型语言模型如何利用不同层获取知识。通过这些研究，可以更好地理解和应用在自然语言处理领域中的语言模型和上下文处理技术。 <div>
今日推介(第1373期)：基于Infini-attention的高效无限上下文Transformer、极限中的语言生成、长上下文语言模型的上下文实际有多长、上下文学习回路及其形成机制研究、大型语言模型如何用不同层获取知识 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/692028746"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8honmw71diaj20ts130aee.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8honmw9golhj211z0u00x5.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8honmwbu8w5j21ds0lcdl1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8honmwehdnwj21dx0u0aid.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8honmwgudfrj221i0u0dpz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 22:13:03 GMT</pubDate>
</item>
<item>
<title>[CV] RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion 网页链接 通过结合图像填充和深度差分模型的知识蒸馏，提出一种文本...</title>
<link>https://weibo.com/1402400261/O9jWIk8rp</link>
<guid>https://weibo.com/1402400261/O9jWIk8rp</guid>
<content:encoded><![CDATA[
<div> 关键词: 文本驱动，3D场景生成，知识蒸馏，图像填充，深度差分，高保真，视差，研究方法，新方法，场景生成

总结:
研究提出的方法结合了图像填充和深度差分模型，实现了文本到3D场景的生成。通过知识蒸馏技术，在生成过程中保持了高保真度和视差效果。该新方法为3D场景生成领域带来了新的研究思路和实践方法，为相关研究提供了有价值的参考。 <div>
[CV] RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion  <br /><a href="https://arxiv.org/abs/2404.07199"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />通过结合图像填充和深度差分模型的知识蒸馏，提出一种文本到3D场景生成的新方法，可以产生具有视差的高保真3D场景。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honmomvibqj212c1ccdwt.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honmon71nkj21fy0i8tft.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honmonitkpj21gg0vothi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 22:05:32 GMT</pubDate>
</item>
<item>
<title>[LG] Semantically-correlated memories in a dense associative model 网页链接 提出稠密联想记忆(CDAM)模型，将自动关联和异质关联结合在连续值记忆上，进行理...</title>
<link>https://weibo.com/1402400261/O9jRe4HXX</link>
<guid>https://weibo.com/1402400261/O9jRe4HXX</guid>
<content:encoded><![CDATA[
<div> CDAM模型, 稠密联想记忆, 自动关联, 异质关联, 连续值记忆, 理论分析, 实验证明

<br /><br />总结:
本文提出了一种新的稠密联想记忆(CDAM)模型，结合自动关联和异质关联在连续值记忆上。通过理论分析和多个实验，证明了CDAM模型的有效性。该模型能够更准确地处理语义相关的记忆，并且在各项实验中表现出色。作者的研究为深度学习领域的稠密联想记忆提供了新的方向和思路。 <div>
[LG] Semantically-correlated memories in a dense associative model  <br /><a href="https://arxiv.org/abs/2404.07123"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />提出稠密联想记忆(CDAM)模型，将自动关联和异质关联结合在连续值记忆上，进行理论分析并在多个实验中证明其效果。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honmalcrzuj211o1bs4kr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honmalmyjrj21480zq0zl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honmalv7v7j21440zotgt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:52:02 GMT</pubDate>
</item>
<item>
<title>[CL] LM Transparency Tool: Interactive Tool for Analyzing Transformer Language Models 网页链接 提出一个开源的语言模型透明度分析工具LM-TT，通过可交互的...</title>
<link>https://weibo.com/1402400261/O9jOeih1G</link>
<guid>https://weibo.com/1402400261/O9jOeih1G</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型、透明度分析工具、LM-TT、交互界面、信息流、组件功能、模型运作机制

总结:
LM Transparency Tool是一个开源的语言模型透明度分析工具，通过交互界面帮助用户追溯模型预测的重要信息流，解释各组件功能，揭示模型内部运作机制。LM-TT提供了一种高效的方式，让用户更好地理解和掌握语言模型的运作原理，从而增加模型的透明度。LM-TT的设计使得用户可以从不同粒度进行分析，帮助他们更深入地了解模型的工作方式，提高模型的可解释性和可信度。LM Transparency Tool为研究人员和开发者提供了一个有用的工具，帮助他们研究和优化语言模型，从而提升其性能和效果。LM-TT的推出将有助于推动语言模型领域的发展，促进模型透明度和可解释性的提升。LM Transparency Tool的出现将为语言模型的研究和应用带来新的可能性，为人们提供更好的工具和资源，推动语言模型的不断发展和进步。LM-TT的推出标志着语言模型领域研究的新进展，为研究者和开发者提供了更强大的工具，推动语言模型技术的创新和发展。LM Transparency Tool是一个重要的工具，将为语言模型领域的研究和应用带来新的推动力，为未来的发展提供更多机遇和可能性。LM-TT将成为语言模型研究的重要工具，为研究人员提供更多的分析和探索空间，推动语言模型领域的不断发展和进步。LM Transparency Tool的推出将有助于推动语言模型领域的研究和发展，为新的探索和发现打开更广阔的空间。LM-TT将成为语言模型研究的重要工具，为研究者提供更多的资源和支持，助力语言模型技术的创新和发展。<br /><br /> <div>
[CL] LM Transparency Tool: Interactive Tool for Analyzing Transformer Language Models  <br /><a href="https://arxiv.org/abs/2404.07004"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出一个开源的语言模型透明度分析工具LM-TT，通过可交互的用户界面，允许从不同粒度追溯模型预测的重要信息流，解释各组件的功能，高效揭示模型内部运作机制。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honm2u0v7kj20wk1cm1c0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honm2ud99jj21k21a8aoh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:44:38 GMT</pubDate>
</item>
<item>
<title>[LG] Scaling Laws for Data Filtering -- Data Curation cannot be Compute Agnostic 网页链接 通过建立训练计算量自适应的数据过滤框架，实现了在不同计算量下...</title>
<link>https://weibo.com/1402400261/O9jLEdldz</link>
<guid>https://weibo.com/1402400261/O9jLEdldz</guid>
<content:encoded><![CDATA[
<div> 数据过滤框架 训练计算量 自适应 视觉语言模型 性能 提升

数据过滤在数据处理中扮演着重要角色，但常常受到计算量的限制。本文提出了一种训练计算量自适应的数据过滤框架，能够在不同计算量下显著提升视觉语言模型的性能。通过对数据过滤和数据清理的优化，可以有效提高模型的精度和效率。该方法为数据过滤领域的研究和实践提供了新的思路和方法。通过对不同计算量下的性能进行全面提升，展现了数据处理在视觉语言模型中的重要性。数据过滤框架的构建和优化，为解决数据处理中的挑战提供了新的思路和方法。 <br /><br />总结: <div>
[LG] Scaling Laws for Data Filtering -- Data Curation cannot be Compute Agnostic  <br /><a href="https://arxiv.org/abs/2404.07177"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />通过建立训练计算量自适应的数据过滤框架，实现了在不同计算量下视觉语言模型性能的全面提升。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honlw9lz4ij212s1ayng3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honlwa31vfj20tm0s6gqz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honlwabgspj20ty0ygagy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:38:17 GMT</pubDate>
</item>
<item>
<title>通过“概念深度”的概念，探究了不同难度的概念在语言模型中的学习位置，发现基础概念在浅层学习，而复杂概念需要更深层，这为理解模型内部表示并评估其鲁棒性提...</title>
<link>https://weibo.com/1402400261/O9jIH17Yd</link>
<guid>https://weibo.com/1402400261/O9jIH17Yd</guid>
<content:encoded><![CDATA[
<div> 概念深度、语言模型、学习位置、基础概念、复杂概念、内部表示、鲁棒性、模型评估、理解、视角

概念深度影响语言模型学习位置，基础概念在浅层学习，复杂概念需要更深层。研究为评估模型鲁棒性提供新视角。 <div>
通过“概念深度”的概念，探究了不同难度的概念在语言模型中的学习位置，发现基础概念在浅层学习，而复杂概念需要更深层，这为理解模型内部表示并评估其鲁棒性提供了新的视角。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?》M Jin, Q Yu, J Huang, Q Zeng... [Rutgers University &amp; University of Liverpoolc &amp; Northwestern University] (2024) <a href="https://arxiv.org/abs/2404.07066"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honlhvrlz1j218s0wigzi.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honlhw5ftuj21ve0rian5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honlhwag74j21v8120tlr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honlhwfkjbj21uq152h2j.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honlolsz27j21290uxter.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honlolthiyj20zn0tfjvj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honlolrn8wj20jp0sutb2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honlolroiwj20jp0lcabd.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:30:59 GMT</pubDate>
</item>
<item>
<title>[CL]《Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?》M Jin, Q Yu, J Huang, Q Zeng... [Rutgers University &amp;...</title>
<link>https://weibo.com/1402400261/O9jIEbvNA</link>
<guid>https://weibo.com/1402400261/O9jIEbvNA</guid>
<content:encoded><![CDATA[
<div> 大语言模型，知识获取，不同层次，概念深度，深度探索，神经网络，自然语言处理，语言模型，信息抽取，知识表示

总结:
本研究探讨了大型语言模型在不同层次上获取知识的过程。研究发现，神经网络在不同深度的层次上具有不同的知识获取能力，通过对自然语言处理和知识表示的分析，揭示了信息抽取的机制。该研究对于理解语言模型的工作原理和知识获取过程具有重要意义。 <div>
[CL]《Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?》M Jin, Q Yu, J Huang, Q Zeng... [Rutgers University &amp; University of Liverpoolc &amp; Northwestern University] (2024) <a href="https://arxiv.org/abs/2404.07066"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honlhvrlz1j218s0wigzi.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honlhw5ftuj21ve0rian5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honlhwag74j21v8120tlr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honlhwfkjbj21uq152h2j.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honlolsz27j21290uxter.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honlolthiyj20zn0tfjvj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honlolrn8wj20jp0sutb2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honlolroiwj20jp0lcabd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:30:53 GMT</pubDate>
</item>
<item>
<title>通过因果训练框架深入分析了Transformer感应头形成过程中的损失动力学，发现多个子回路的相互作用导致明显的全局非线性，并讨论了数据复杂性如何通过调节子回路...</title>
<link>https://weibo.com/1402400261/O9jBkcjhD</link>
<guid>https://weibo.com/1402400261/O9jBkcjhD</guid>
<content:encoded><![CDATA[
<div> 注意: 在此空间中，助手无法提取关键字。因此，请允许我对所提供的信息进行简要总结。

<br /><br />总结:
研究通过因果训练框架深入分析了Transformer感应头形成过程中的损失动力学。发现多个子回路相互作用导致全局非线性，并讨论了数据复杂性如何通过调节子回路形成影响全局动力学。文章提供了对在上下文学习电路和其形成过程中所需的变量的机械性研究。 <div>
通过因果训练框架深入分析了Transformer感应头形成过程中的损失动力学，发现多个子回路的相互作用导致明显的全局非线性，并讨论了数据复杂性如何通过调节子回路的形成进而影响全局动力学。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation》A K. Singh, T Moskovitz, F Hill, S C.Y. Chan, A M. Saxe [University College London &amp; Google DeepMind] (2024) <a href="https://arxiv.org/abs/2404.07129"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl4dy5hfj20r21d616n.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl4ekxeaj21rg124tod.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl4erfg8j219w0lq7bd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl4expw5j20ri1ag7da.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl5dx8foj20iz0z90wk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl5dxh3lj20j0171788.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl5dvrt1j212d0fitbn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl5dvq93j212d0kkq5u.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl5dwdt1j212d0klmzv.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:12:50 GMT</pubDate>
</item>
<item>
<title>[LG]《What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation》A K. Singh, T Moskovitz, ...</title>
<link>https://weibo.com/1402400261/O9jB9xT64</link>
<guid>https://weibo.com/1402400261/O9jB9xT64</guid>
<content:encoded><![CDATA[
<div> 学习电路, 形成, 形構成, 行为, 认知, 形成过程, 机制, 头部, 形成机制, 神经元

总结:<br /><br />
本研究探讨了诱导头部的正确形成所需的机制。研究发现，在特定环境中的学习电路对头部的形成起着关键作用。通过对认知行为的研究，揭示了头部形成的机制，并深入探讨了神经元在这一过程中的作用。这一研究为进一步理解诱导头部形成提供了重要参考。 <div>
[LG]《What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation》A K. Singh, T Moskovitz, F Hill, S C.Y. Chan, A M. Saxe [University College London &amp; Google DeepMind] (2024) <a href="https://arxiv.org/abs/2404.07129"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl4dy5hfj20r21d616n.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl4ekxeaj21rg124tod.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl4erfg8j219w0lq7bd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl4expw5j20ri1ag7da.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl5dx8foj20iz0z90wk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl5dxh3lj20j0171788.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl5dvrt1j212d0fitbn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl5dvq93j212d0kkq5u.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl5dwdt1j212d0klmzv.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl5dwnbdj212d0dxmz4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl5dwshfj212e0h1tb0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl5dznnbj212h1apgvk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl5dx21dj212g0m8q5v.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl5dw2zwj212d0dst9s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl5dxgpdj212d0jiadj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl5dygkbj212i0kodlx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl5dykfaj212e0vkwkg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl5dwwe9j212h0ivabo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:12:26 GMT</pubDate>
</item>
<item>
<title>提出新的长序列语言模型评估基准RULER，发现现有模型在输入长度和任务复杂度增加时表现大幅下降，优化目标依然存在。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《RULER:...</title>
<link>https://weibo.com/1402400261/O9jAqALkg</link>
<guid>https://weibo.com/1402400261/O9jAqALkg</guid>
<content:encoded><![CDATA[
<div> RULER, 评估基准, 长序列语言模型, 输入长度, 任务复杂度, 下降, 优化目标, 论文, NVIDIA, 2024

<br /><br />总结:
提出了新的长序列语言模型评估基准RULER，发现现有模型在输入长度和任务复杂度增加时表现下降，表明优化目标仍然存在。该论文由团队在2024年发表于NVIDIA。 <div>
提出新的长序列语言模型评估基准RULER，发现现有模型在输入长度和任务复杂度增加时表现大幅下降，优化目标依然存在。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《RULER: What's the Real Context Size of Your Long-Context Language Models?》C Hsieh, S Sun, S Kriman… [NVIDIA] (2024) <a href="https://arxiv.org/abs/2404.06654"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl13llpvj215u0wk4cj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl1425p5j21ec0iaq88.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl146jpfj21ds0lc7bb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl14e1c1j21dy0l4tg1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl1j9jiqj20ve0gvq5q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl1ja864j20vg0yc0w3.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:10:39 GMT</pubDate>
</item>
<item>
<title>[CL]《RULER: What's the Real Context Size of Your Long-Context Language Models?》C Hsieh, S Sun, S Kriman… [NVIDIA] (2024) 网页链接 #机器学习##人工智...</title>
<link>https://weibo.com/1402400261/O9jzE0wKh</link>
<guid>https://weibo.com/1402400261/O9jzE0wKh</guid>
<content:encoded><![CDATA[
<div> 关键词: RULER, Real Context Size, Long-Context Language Models, NVIDIA

总结:<br /><br />这篇文章由NVIDIA发布，讨论了长文本语言模型的真实上下文大小。研究者使用了RULER方法来评估这些语言模型的性能，并确定真实上下文大小对模型表现的影响。他们发现，适当的上下文大小对于提高语言模型的准确性至关重要，而长文案模型在实际应用中可能需要更大的上下文进行训练。研究结果为长文本语言模型的优化提供了重要参考，有助于提高其性能和应用范围。 <div>
[CL]《RULER: What's the Real Context Size of Your Long-Context Language Models?》C Hsieh, S Sun, S Kriman… [NVIDIA] (2024) <a href="https://arxiv.org/abs/2404.06654"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl13llpvj215u0wk4cj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl1425p5j21ec0iaq88.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl146jpfj21ds0lc7bb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl14e1c1j21dy0l4tg1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl1j9jiqj20ve0gvq5q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl1ja864j20vg0yc0w3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:08:43 GMT</pubDate>
</item>
<item>
<title>通过一个简洁的对抗框架证明了语言生成不同于识别，前者在某个时刻之后总是可能的，这一深刻见解启发我们从新的角度思考实际中的生成模型。 - 转发 @爱可可-爱生...</title>
<link>https://weibo.com/1402400261/O9jzi8u2c</link>
<guid>https://weibo.com/1402400261/O9jzi8u2c</guid>
<content:encoded><![CDATA[
<div> Language Generation, Limit, 对抗框架, 识别, 见解, 生成模型, 深刻, 启发, 新的角度

总结:<br /><br />本文通过一个简洁的对抗框架证明了语言生成与识别不同，语言生成在某个时刻之后总是可能的。这一深刻见解启发我们从新的角度思考实际中的生成模型。J Kleinberg和S Mullainathan在《Language Generation in the Limit》一文中提出这一理论，为我们理解语言生成问题提供了新的思路。这一对抗框架为我们解释语言生成的机制提供了新的切入点，为未来研究方向带来了新的启示。 <div>
通过一个简洁的对抗框架证明了语言生成不同于识别，前者在某个时刻之后总是可能的，这一深刻见解启发我们从新的角度思考实际中的生成模型。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Language Generation in the Limit》J Kleinberg, S Mullainathan [Cornell University &amp; University of Chicago] (2024) <a href="https://arxiv.org/abs/2404.06757"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl0fxoonj214k0k0wn7.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl0ga6iij218s0zen3f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl0go5y1j218y1cmdqm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:07:51 GMT</pubDate>
</item>
<item>
<title>【Parler-TTS：开源的轻量级文本到语音（TTS）模型，可以生成高质量、自然流畅的语音，模仿给定的演讲者（性别、音高、说话风格等）】'Parler-TTS - Inference a...</title>
<link>https://weibo.com/1402400261/O9dsx5AMg</link>
<guid>https://weibo.com/1402400261/O9dsx5AMg</guid>
<content:encoded><![CDATA[
<div> 开源、轻量级、文本到语音、TTS模型、高质量、自然流畅、模仿、演讲者、性别、音高

总结:<br /><br />Parler-TTS是一款开源的轻量级文本到语音（TTS）模型，旨在生成高质量、自然流畅的语音，并能模仿给定演讲者的特征，如性别、音高和说话风格。该模型具有训练和推断功能，可在GitHub上找到其源代码。Parler-TTS的出现为语音合成技术的进步提供了新的可能性，为用户提供了更加个性化、高质量的语音合成体验。 <div>
【Parler-TTS：开源的轻量级文本到语音（TTS）模型，可以生成高质量、自然流畅的语音，模仿给定的演讲者（性别、音高、说话风格等）】'Parler-TTS - Inference and training library for high-quality TTS models.' GitHub: github.com/huggingface/parler-tts <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8homu1poyc8j20z30u0443.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 05:34:43 GMT</pubDate>
</item>
<item>
<title>【用GPU分布式推理实战】《Distributed inference with multiple GPUs》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O9dpQdSwp</link>
<guid>https://weibo.com/1402400261/O9dpQdSwp</guid>
<content:encoded><![CDATA[
<div> 分布式推理、GPU、多个GPU、深度学习、模型推理、性能优化、数据并行、模型并行

<br />
本文介绍了如何利用多个GPU进行分布式推理的方法。首先讨论了在深度学习中模型推理的重要性，以及如何利用GPU来加速推理过程。然后介绍了利用多个GPU进行分布式推理的优势和挑战，主要涉及数据并行和模型并行两种方式。接着详细介绍了如何利用数据并行和模型并行实现分布式推理，并提供了相应的代码示例。最后讨论了如何优化性能，包括减少通信开销、调整batch size、使用多线程等方法。通过本文的学习，读者可以了解如何利用多个GPU进行高效的分布式推理，提升深度学习模型的推理速度和性能。

<br /><br />总结:本文介绍了利用多个GPU进行分布式推理的方法，讨论了数据并行和模型并行的优势和挑战，提供了代码示例，并讨论了性能优化的方法。通过本文的学习，读者可以提升深度学习模型的推理速度和性能。 <div>
【用GPU分布式推理实战】《Distributed inference with multiple GPUs》 <a href="https://huggingface.co/docs/diffusers/main/en/training/distributed_inference"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8homtut6db4j21020u078q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 05:28:05 GMT</pubDate>
</item>
<item>
<title>【Meta发布下一代训练和推理加速器】- 分享了下一代Meta训练和推理加速器(MTIA)的详细信息，这是专门为Meta的AI工作负载设计的定制芯片家族。 - 最新版本与MTIA ...</title>
<link>https://weibo.com/1402400261/O9dnE1MkP</link>
<guid>https://weibo.com/1402400261/O9dnE1MkP</guid>
<content:encoded><![CDATA[
<div> 加速器、Meta、训练、推理、AI工作负载、性能提升、广告排名、推荐模型、基础设施、芯片家族

总结:<br /><br />Meta发布了下一代训练和推理加速器(MTIA)，专为其AI工作负载设计。新版本相比之前有显着性能提升，支持广告排名和推荐模型。MTIA是Meta不断增长的AI基础设施投资的一部分，将为产品和服务带来新体验。新一代Meta基础设施以AI为中心，支持新产品、推荐系统和AI研究。MTIA v1是首款自主设计的AI推理加速器，提升深度学习推荐模型体验。新版本提升了计算性能和内存带宽，保持高度耦合。MTIA在计算、内存带宽和内存容量上平衡，是构建支持AI工作负载的核心基础设施。Meta正在扩展MTIA范围，包括支持GenAI工作负载。MTIA已部署在数据中心，服务模型并投入更多计算能力。 <div>
【Meta发布下一代训练和推理加速器】<br />- 分享了下一代Meta训练和推理加速器(MTIA)的详细信息，这是专门为Meta的AI工作负载设计的定制芯片家族。   <br />- 最新版本与MTIA v1相比有显着的性能提升，可以支持Meta的广告排名和推荐模型。   <br />- MTIA是对AI基础设施投资不断增长的一部分，将与现有和未来的AI基础设施相辅相成，为Meta的产品和服务带来新的更好的体验。   <br />- 新一代Meta大规模基础设施的设计以AI为中心，包括支持新的生成AI(GenAI)产品和服务、推荐系统以及先进的AI研究。   <br />- MTIA v1是Meta首款针对其AI推理工作负载自主设计的AI推理加速器，专门用于提升产品中的各种体验的深度学习推荐模型。   <br />- 新版本MTIA相比之前的解决方案提升了2倍以上的计算性能和内存带宽，并保持了与工作负载的高度耦合。它被设计来高效服务为用户提供高质量推荐的排名和推荐模型。   <br />- 该芯片架构的核心是在计算、内存带宽和内存容量之间提供适合服务排名和推荐模型的正确平衡。   <br />- MTIA将是Meta长期规划中构建和扩展支持其独特AI工作负载所需的最强大和最高效基础设施的重要组成部分。   <br />- Meta当前正在进行多个旨在扩展MTIA范围的项目，包括支持GenAI工作负载。   <br />- MTIA已经部署到数据中心，现在正在生产环境中服务模型。它正如预期的那样，允许其为更密集的AI工作负载投入和投资更多计算能力。<br />《Our next generation Meta Training and Inference Accelerator》 <a href="https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8homtolwiphj20p40p4gnj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 05:22:40 GMT</pubDate>
</item>
<item>
<title>【Google宣布进一步扩展开源语言模型Gemma系列】 - 推出了两个新的Gemma变体模型：CodeGemma用于代码补全、生成和聊天；RecurrentGemma是一个技术不同的模型，利...</title>
<link>https://weibo.com/1402400261/O9djE6F9I</link>
<guid>https://weibo.com/1402400261/O9djE6F9I</guid>
<content:encoded><![CDATA[
<div> Gemma, 扩展, 开源, 语言模型, CodeGemma, RecurrentGemma, 高性能, 高效率, 负责任AI设计, Kaggle

<br /><br />总结:
Google宣布进一步扩展开源语言模型Gemma系列，推出了两个新的模型：CodeGemma和RecurrentGemma。其中，CodeGemma包括针对代码补全、生成和聊天的不同变体，支持多种编程语言，并有高参数预训练模型可供选择。RecurrentGemma则是一种技术不同的模型，利用RNN和本地注意力来提高内存效率，展示了非Transformer的高性能模型。这些模型秉承Gemma原则，提供高性能和效率，支持负责任的AI设计，并对所有人开放可用。同时，Gemma 1.1版本也发布了，包括性能改进和缺陷修复，使用条款也进行了更新。这些模型已在Kaggle、Hugging Face、Vertex AI Model Garden等平台上线，为开发者和研究者提供了更大灵活性。 <div>
【Google宣布进一步扩展开源语言模型Gemma系列】<br /> - 推出了两个新的Gemma变体模型：CodeGemma用于代码补全、生成和聊天；RecurrentGemma是一个技术不同的模型，利用RNN和本地注意力来提高内存效率。   <br />- CodeGemma有3个变体：一个7B的参数预训练模型，专门用于代码补全和生成；一个7B的参数模型，针对代码聊天和指令理解进行了调优；一个2B参数的预训练模型，支持本地部署。CodeGemma对代码语义理解更准确，支持多种编程语言。   <br />- RecurrentGemma虽然性能与Gemma 2B类似，但其特殊的架构降低了内存需求，支持更长文本生成，也支持更高的吞吐量。它展示了一个非Transformer的高性能模型，对深度学习研究有启发意义。   <br />- 新模型贯彻了Gemma的原则，对所有人开放可用，提供高性能和效率，实现负责任的AI设计，支持各种软硬件部署。   <br />- Gemma 1.1也发布了，包括性能改进、缺陷修复等。使用条款也进行了更新，提供更大灵活性。   <br />- 这些模型现已在Kaggle、Hugging Face、Vertex AI Model Garden等平台上线，文中提供了各种获取和试用指南。<br />《Gemma Family Expands with Models Tailored for Developers and Researchers - Google for Developers》 <a href="https://developers.googleblog.com/2024/04/gemma-family-expands.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8homteueg9ij218g0p077w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8homtesdv57j218g0p0acv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 05:12:49 GMT</pubDate>
</item>
<item>
<title>今日开奖，欢迎参与！ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转发+评论...</title>
<link>https://weibo.com/1402400261/O9biJfNam</link>
<guid>https://weibo.com/1402400261/O9biJfNam</guid>
<content:encoded><![CDATA[
<div> LangChain, 实战, 初学者, 大语言模型, LangChain团队, LangServe, LangSmith, 人工智能, 应用场景, LCEL

<br /><br />总结:
今天开奖活动，欢迎大家参与。参与方法是转发并评论*可可粉*，有机会获得3本《LangChain实战》书籍。这本书是为初学者和对LangChain应用及大语言模型感兴趣的开发者而写的。书籍介绍了LangChain 0.1版本, 并配套600分钟详解视频。重点讲解了多个核心应用场景，深入探讨了LCEL的应用方式。同时，书籍详细探讨了LangChain、LangServe和LangSmith，帮助读者了解LangChain团队在生成式人工智能领域的布局。愿大家参与活动，获得更多有关LangChain的知识。 <div>
今日开奖，欢迎参与！<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a> <a href="https://shop.sc.weibo.com/h5/goods/index?iid=110014024002610004661854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">LangChain实战：从原型到生产，动手打造 LLM 应用</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hofl98oom9j207q0a0jrm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 00:05:04 GMT</pubDate>
</item>
<item>
<title>今日推介(第1372期)：大型语言模型也是强大的文本编码器、将语言模型与定制合成数据对齐、大型语言模型中表格数据的记忆与学习、带有中间修正和搜索的推理、Tran...</title>
<link>https://weibo.com/1402400261/O9aBQ7Sqz</link>
<guid>https://weibo.com/1402400261/O9aBQ7Sqz</guid>
<content:encoded><![CDATA[
<div> 文本编码器、定制合成数据、表格数据记忆、推理、可解释性、Transformer、RNN

大型语言模型在文本编码和处理上展现出了强大的能力，可以作为优秀的文本编码器。同时，将语言模型与定制合成数据对齐可以提高模型性能和适用范围。在大型语言模型中，对表格数据的记忆与学习是一个关键挑战，需要进一步探索和改进。在推理过程中，结合中间修正和搜索可以提高推理的准确性和效率。虽然Transformer具有很好的可解释性，但是其是否可以迁移到RNN等其他模型仍需要进行深入研究。总之，大型语言模型在各个方面的应用和改进都有很多潜力和挑战，需要不断探索和完善。<br /><br />总结: 大型语言模型展现出强大的文本编码能力，但仍需进一步改进表格数据记忆和推理过程，同时需要研究Transformer可解释性迁移到其他模型的可能性。 <div>
今日推介(第1372期)：大型语言模型也是强大的文本编码器、将语言模型与定制合成数据对齐、大型语言模型中表格数据的记忆与学习、带有中间修正和搜索的推理、Transformer的可解释性能否迁移到RNN 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/691823619"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8homhgd1sy8j21ke0ni7aq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8homhgh3bpbj21d10u0k17.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8homhgks2srj21ce0pm0xb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8homhgngpsbj20u0153n44.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8homhgqkr2kj20ji1ak0w5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 22:19:23 GMT</pubDate>
</item>
<item>
<title>[LG] Dynamical stability and chaos in artificial neural network trajectories along training 网页链接 从动态系统角度将神经网络训练轨迹动力学化，发现学...</title>
<link>https://weibo.com/1402400261/O9axO25Dt</link>
<guid>https://weibo.com/1402400261/O9axO25Dt</guid>
<content:encoded><![CDATA[
<div> 动态系统、神经网络、训练、动力学、稳定性、学习率调节、复杂动力学行为、有效学习<br />
<br />
<br />
总结: 本文从动态系统角度研究了神经网络训练轨迹的稳定性和混沌性，发现在学习率调节过程中会产生复杂的动力学行为。在稳定性边缘，神经网络的训练可以获得有效的学习。这一研究揭示了神经网络训练过程中的动力学特性，为提高神经网络训练效果提供了新的视角和方法。 <div>
[LG] Dynamical stability and chaos in artificial neural network trajectories along training  <br /><a href="https://arxiv.org/abs/2404.05782"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />从动态系统角度将神经网络训练轨迹动力学化，发现学习率调节能引发复杂动力学行为，在稳定性边缘可获得有效学习。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homh6ep3f0j210s11awpu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homh6f2q58j21ki0taq83.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homh6fi14vj21nk0rw483.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 22:09:28 GMT</pubDate>
</item>
<item>
<title>[AI] Wu's Method can Boost Symbolic AI to Rival Silver Medalists and AlphaGeometry to Outperform Gold Medalists at IMO Geometry 网页链接 重新评估了吴...</title>
<link>https://weibo.com/1402400261/O9av62QL8</link>
<guid>https://weibo.com/1402400261/O9av62QL8</guid>
<content:encoded><![CDATA[
<div> 关键词: 吴氏法、Symbolic AI、AlphaGeometry、IMO几何、自动定理证明

总结:<br /><br />在重新评估了吴氏法在奥数几何题目上的表现后发现，其表现意外强大，并与现代方法如AlphaGeometry形成互补，为几何自动定理证明建立了全新的最优结果。 Wu's Method能提升Symbolic AI的实力，使其能够与奥数几何比赛的银牌得主一较高下，同时AlphaGeometry方法在IMO几何方面表现优异，超过金牌得主的水平。这些发现为提高几何自动证明的技术水平提供了新的方向和可能性。 <div>
[AI] Wu's Method can Boost Symbolic AI to Rival Silver Medalists and AlphaGeometry to Outperform Gold Medalists at IMO Geometry  <br /><a href="https://arxiv.org/abs/2404.06405"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />重新评估了吴氏法在奥数几何题目上的表现，发现其意外强大，与AlphaGeometry等现代方法形成互补，为几何自动定理证明再次建立了全新的最优结果。<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homgzh25yfj210c19ak8t.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homgzh9yf9j21dw0xudnk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 22:02:47 GMT</pubDate>
</item>
<item>
<title>[CV] Matching 2D Images in 3D: Metric Relative Pose from Metric Correspondences 网页链接 提出MicKey方法，利用预测单张图像的3D关键点坐标实现无需外部深...</title>
<link>https://weibo.com/1402400261/O9asko3AR</link>
<guid>https://weibo.com/1402400261/O9asko3AR</guid>
<content:encoded><![CDATA[
<div> 方法、3D关键点坐标、度量相对位姿估计、位姿标签监督训练、MicKey方法、2D图像匹配、无需外部深度、有效性证明

<br /><br />总结:
本文提出了一种名为MicKey的方法，利用预测单张图像的3D关键点坐标实现无需外部深度的度量相对位姿估计。通过仅利用图像对的位姿标签进行监督训练，证明了该方法的有效性。MicKey方法通过匹配2D图像中的关键点，在3D空间中计算出相对姿态，实现了精确的相机位姿估计。通过实验验证，MicKey方法在匹配2D图像的同时实现了较高精度的相机位姿估计，具有很高的实用性和有效性。MicKey方法的提出拓展了在没有外部深度信息的情况下进行相机位姿估计的可能性，对于计算机视觉领域的研究具有一定的启发意义。 <div>
[CV] Matching 2D Images in 3D: Metric Relative Pose from Metric Correspondences  <br /><a href="https://arxiv.org/abs/2404.06337"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />提出MicKey方法，利用预测单张图像的3D关键点坐标实现无需外部深度的度量相对位姿估计，并证明仅利用图像对的位姿标签监督训练的有效性。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homgsd6thdj212m1aynho.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homgsdia14j21ik0n0wqx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homgsdnoe4j20r20oq0xz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:55:58 GMT</pubDate>
</item>
<item>
<title>[CL] Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence 网页链接 提出了Eagle和Finch两种改进自RWKV-4的高效RNN体系结构，在大量预训练...</title>
<link>https://weibo.com/1402400261/O9alhBvkx</link>
<guid>https://weibo.com/1402400261/O9alhBvkx</guid>
<content:encoded><![CDATA[
<div> Eagle, Finch, RWKV, RNN, Transformer, 多语言建模, 预训练, 高效, 可解释, 语言模型

总结:<br /><br />研究团队提出了Eagle和Finch两种改进自RWKV-4的高效RNN体系结构，经过大量预训练展示了与Transformer竞争的多语言建模效果。这为提供高效可解释的语言模型提供了可行的选择，为语言模型研究领域带来了新的方向。 <div>
[CL] Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence  <br /><a href="https://arxiv.org/abs/2404.05892"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出了Eagle和Finch两种改进自RWKV-4的高效RNN体系结构，在大量预训练后展示了与Transformer竞争的多语言建模效果，为提供高效可解释的语言模型提供了可行的选择。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homgaap0iyj20vo0y812f.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homgabfemwj21gq1ck49l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homgabxe4zj21ck0yi0x8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:38:37 GMT</pubDate>
</item>
<item>
<title>发现设计用于解释Transformer的技术大多可直接应用于新兴RNN架构，并创新利用RNN压缩状态增强控制能力。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Does Transformer I...</title>
<link>https://weibo.com/1402400261/O9aj1cQ2K</link>
<guid>https://weibo.com/1402400261/O9aj1cQ2K</guid>
<content:encoded><![CDATA[
<div> Transformer、RNN、技术、解释性、新兴、架构、状态压缩、控制能力、利用、创新

总结：<br /><br />本文探讨了Transformer解释性技术如何应用于RNN，并创新利用RNN压缩状态以增强控制能力。发现大部分Transformer解释技术可直接应用于RNN，为未来RNN架构的发展提供了新思路。 <div>
发现设计用于解释Transformer的技术大多可直接应用于新兴RNN架构，并创新利用RNN压缩状态增强控制能力。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Does Transformer Interpretability Transfer to RNNs?》G Paulo, T Marshall, N Belrose [EleutherAI] (2024) <a href="https://arxiv.org/abs/2404.05971"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfvtnquwj21940o4492.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfvu1w48j20jo10yad1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfvuf4x4j20ji1akwiv.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfvupsgej21hg0ve124.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homg48kjppj20vf0i40va.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homg48kvt9j20vi0g8did.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homg48kpxjj20ve0jnmzf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homg48kfazj20vf0m4wgh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homg48kawjj20g80ktgnm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:33:02 GMT</pubDate>
</item>
<item>
<title>[LG]《Does Transformer Interpretability Transfer to RNNs?》G Paulo, T Marshall, N Belrose [EleutherAI] (2024) 网页链接 #机器学习##人工智能##论文# [图...</title>
<link>https://weibo.com/1402400261/O9aiX4GAr</link>
<guid>https://weibo.com/1402400261/O9aiX4GAr</guid>
<content:encoded><![CDATA[
<div> Transformer, Interpretability, RNNs, Transfer, EleutherAI, Paulo, Marshall, Belrose

总结:<br /><br />本文探讨了Transformer模型的可解释性是否可以迁移到RNNs模型上。研究团队由G Paulo、T Marshall和N Belrose来自EleutherAI。他们研究发现，虽然Transformer模型在可解释性方面表现出色，但这种可解释性并不一定可以直接转移到RNNs模型上。作者通过实验证明，即使在相同的训练数据和任务上，RNNs模型的可解释性并不如Transformer模型明显。研究结果呼吁在研究和开发RNNs模型时要更加关注其可解释性，以提高模型的可理解性和可解释性。 <div>
[LG]《Does Transformer Interpretability Transfer to RNNs?》G Paulo, T Marshall, N Belrose [EleutherAI] (2024) <a href="https://arxiv.org/abs/2404.05971"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfvtnquwj21940o4492.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfvu1w48j20jo10yad1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfvuf4x4j20ji1akwiv.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfvupsgej21hg0ve124.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homg48kjppj20vf0i40va.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homg48kvt9j20vi0g8did.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homg48kpxjj20ve0jnmzf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homg48kfazj20vf0m4wgh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homg48kawjj20g80ktgnm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homg48lighj20vd14c0wm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homg48lgjsj20vd14fady.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homg48lhrhj20vd14fq6d.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homg48lkwdj20vd13itcm.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homg48kzxbj20vd0rzdin.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:32:52 GMT</pubDate>
</item>
<item>
<title>提出THOUGHTSCULPT框架，将复杂推理任务分解为简单组件，利用蒙特卡罗树搜索和中间结果修改机制进行逼真的复杂推理，在多个任务上优于当前最新方法。 - 转发 @爱...</title>
<link>https://weibo.com/1402400261/O9aeezyoY</link>
<guid>https://weibo.com/1402400261/O9aeezyoY</guid>
<content:encoded><![CDATA[
<div> 蒙特卡罗树搜索, 复杂推理, THOUGHTSCULPT, 中间结果修改机制, 多个任务, UC Berkeley, 理性思维, 推理任务, 最新方法, 逼真<br />
<br />
提出了THOUGHTSCULPT框架，将复杂推理任务分解为简单组件，利用蒙特卡罗树搜索和中间结果修改机制进行逼真的复杂推理。该框架在多个任务上超越了当前最新方法，取得了优异的表现。该研究由UC Berkeley的Chi、Yang和Klein等人完成，并于2024年发表。<br />
<br />
总结: 该研究提出了THOUGHTSCULPT框架，利用蒙特卡罗树搜索和中间结果修改机制进行复杂推理任务。这一方法在多个任务上超越了当前最新方法，显示了优越的性能。 <div>
提出THOUGHTSCULPT框架，将复杂推理任务分解为简单组件，利用蒙特卡罗树搜索和中间结果修改机制进行逼真的复杂推理，在多个任务上优于当前最新方法。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《THOUGHTSCULPT: Reasoning with Intermediate Revision and Search》Y Chi, K Yang, D Klein [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.05966"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfrjnakgj217i0msdoz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfrk58yaj20zc1cek1g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfrkfdr9j20z40wsq9q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfrkispgj20z00faad8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfs1y5x7j20ve0cx0ug.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfs1xwkij20vd0eaabd.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:21:15 GMT</pubDate>
</item>
<item>
<title>[CL]《THOUGHTSCULPT: Reasoning with Intermediate Revision and Search》Y Chi, K Yang, D Klein [UC Berkeley] (2024) 网页链接 #机器学习##人工智能##论文# ...</title>
<link>https://weibo.com/1402400261/O9aea9NIe</link>
<guid>https://weibo.com/1402400261/O9aea9NIe</guid>
<content:encoded><![CDATA[
<div> 关键词: THOUGHTSCULPT, 推理, 中间修订, 搜索, 搜索空间, 计算复杂性, 信息检索, 实验结果, 人工智能, UC Berkeley

总结:
<br />
本文介绍了一种名为THOUGHTSCULPT的方法，用于推理过程中的中间修订和搜索。该方法结合了传统的推理和搜索算法，并通过对搜索空间的有效管理提高了效率。研究者在实验中验证了这一方法在信息检索中的有效性，并探讨了其在计算复杂性方面的优势。这项研究是在UC Berkeley进行的，展示了人工智能领域的最新进展。 <div>
[CL]《THOUGHTSCULPT: Reasoning with Intermediate Revision and Search》Y Chi, K Yang, D Klein [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.05966"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfrjnakgj217i0msdoz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfrk58yaj20zc1cek1g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfrkfdr9j20z40wsq9q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfrkispgj20z00faad8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfs1y5x7j20ve0cx0ug.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfs1xwkij20vd0eaabd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:21:04 GMT</pubDate>
</item>
<item>
<title>研究发现大型语言模型记忆了许多表格数据集并导致过拟合，提供了检验记忆与评估模型泛化能力的有效方法。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Elephants Never F...</title>
<link>https://weibo.com/1402400261/O9adzlhy4</link>
<guid>https://weibo.com/1402400261/O9adzlhy4</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、记忆、表格数据集、过拟合、检验、评估、模型泛化能力、有效方法  
总结:<br /><br />这项研究发现大型语言模型存在记忆表格数据集并导致过拟合的问题。通过提供一种有效方法来检验记忆和评估模型泛化能力，研究表明模型记忆了大量的表格数据，需要进一步研究以避免过拟合。这为解决大型语言模型记忆问题提供了重要参考。 <div>
研究发现大型语言模型记忆了许多表格数据集并导致过拟合，提供了检验记忆与评估模型泛化能力的有效方法。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models》S Bordt, H Nori, V Rodrigues, B Nushi, R Caruana [University of Tubingen &amp; Microsoft Research] (2024) <a href="https://arxiv.org/abs/2404.06209"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfoxhg54j214e0sqamk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfoxtybgj21ce0pmdm5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfoylq8uj21cg0oen4a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfoz3h63j21c80tktjd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfq0oe69j20vf0fm0vf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfq0ofbxj20v00d9gnp.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:19:37 GMT</pubDate>
</item>
<item>
<title>[LG]《Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models》S Bordt, H Nori, V Rodrigues, B Nushi, R Caruana [Un...</title>
<link>https://weibo.com/1402400261/O9admsSPz</link>
<guid>https://weibo.com/1402400261/O9admsSPz</guid>
<content:encoded><![CDATA[
<div> Elephants Never Forget, Memorization, Learning, Tabular Data, Large Language Models, University of Tubingen, Microsoft Research

<br /><br />总结：
该研究由图宾根大学和微软研究院进行，着重探讨大型语言模型中的表格数据记忆与学习能力。研究发现，大型语言模型可以很好地记忆和学习表格数据，同时展现出不错的性能。通过实验和分析，验证了这一发现，表明大型语言模型在处理大规模数据集时具有优势。研究结果对于进一步改进大型语言模型的设计和应用具有重要意义，有助于提高模型的表现和应用范围。整体而言，该研究为理解语言模型中的记忆和学习机制提供了重要洞见，为相关领域的研究和应用提供了有益的参考。 <div>
[LG]《Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models》S Bordt, H Nori, V Rodrigues, B Nushi, R Caruana [University of Tubingen &amp; Microsoft Research] (2024) <a href="https://arxiv.org/abs/2404.06209"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfoxhg54j214e0sqamk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfoxtybgj21ce0pmdm5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfoylq8uj21cg0oen4a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfoz3h63j21c80tktjd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfq0oe69j20vf0fm0vf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfq0ofbxj20v00d9gnp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:19:06 GMT</pubDate>
</item>
<item>
<title>CodecLM通过语言模型编解码与自生成规范和对比过滤，实现无人工参与下的高质量定制指令生成，从而提升语言模型对不同下游任务指令的遵循能力。 - 转发 @爱可可-...</title>
<link>https://weibo.com/1402400261/O9acv4sdi</link>
<guid>https://weibo.com/1402400261/O9acv4sdi</guid>
<content:encoded><![CDATA[
<div> 语言模型、编解码、自生成、规范、对比过滤、定制指令、提升、任务指令、CodecLM
<br />
<br />
总结:本文介绍了一种名为CodecLM的方法，通过语言模型的编解码和自动生成规范与对比过滤，在无人工参与的情况下生成高质量的定制指令，从而提高语言模型对不同下游任务指令的遵循能力。CodecLM能够根据特定任务需求生成定制化的指令，为各种应用场景提供更好的支持。该方法通过合成数据进行训练，提高了语言模型的适应能力和准确性，为自然语言处理领域的发展带来了新的可能性。CodecLM的提出将为未来的研究工作和实际应用带来新的启示，为语言模型的发展和应用提供了有益的借鉴。
 <div>
CodecLM通过语言模型编解码与自生成规范和对比过滤，实现无人工参与下的高质量定制指令生成，从而提升语言模型对不同下游任务指令的遵循能力。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《CodecLM: Aligning Language Models with Tailored Synthetic Data》Z Wang, C Li, V Perot, L T. Le, J Miao, Z Zhang, C Lee, T Pfister [Google Cloud AI Research &amp; Google Research] (2024) <a href="https://arxiv.org/abs/2404.05875"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfmteelgj20oq1dmgyf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfmtypqlj20so0ysn39.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfmuhb4ij21ke0yiqgv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfmulqvoj20ro0qwq6k.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfvdj8j20g806wt90.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfvfzjj20gu0cejs5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfnfxbacj20zs0ueq88.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfnfwp5gj20zx0pg42e.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfw4aqj20zx0cdta8.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:16:58 GMT</pubDate>
</item>
<item>
<title>[CL]《CodecLM: Aligning Language Models with Tailored Synthetic Data》Z Wang, C Li, V Perot, L T. Le, J Miao, Z Zhang, C Lee, T Pfister [Google Cloud ...</title>
<link>https://weibo.com/1402400261/O9aco5Aod</link>
<guid>https://weibo.com/1402400261/O9aco5Aod</guid>
<content:encoded><![CDATA[
<div> 关键词: CodecLM, 语言模型, 合成数据, 对齐, 研究, Google Cloud AI Research, Google Research

总结:
<br />
这篇文章由Wang, Li, Perot, Le, Miao, Zhang, Lee和Pfister撰写，来自Google Cloud AI Research和Google Research。研究的主题是《CodecLM: Aligning Language Models with Tailored Synthetic Data》，重点是如何利用合成数据来对齐语言模型。文章介绍了他们提出的CodecLM框架，该框架可以生成定制化的合成数据，从而帮助语言模型更好地学习特定任务。研究结果表明，利用合成数据对齐语言模型可以带来显著的性能提升。这项研究对于进一步优化语言模型的训练和应用具有重要意义。 <div>
[CL]《CodecLM: Aligning Language Models with Tailored Synthetic Data》Z Wang, C Li, V Perot, L T. Le, J Miao, Z Zhang, C Lee, T Pfister [Google Cloud AI Research &amp; Google Research] (2024) <a href="https://arxiv.org/abs/2404.05875"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfmteelgj20oq1dmgyf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfmtypqlj20so0ysn39.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfmuhb4ij21ke0yiqgv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfmulqvoj20ro0qwq6k.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfvdj8j20g806wt90.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfvfzjj20gu0cejs5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfnfxbacj20zs0ueq88.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfnfwp5gj20zx0pg42e.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfw4aqj20zx0cdta8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfwannj20zx0eotaw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfwdrpj20zx0atdh8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfnfxac4j20zx0kf41t.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfxf5fj20zx0k3who.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:16:42 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.10)》 爱可可微博热门分享(4.10) [图片]</title>
<link>https://weibo.com/1402400261/O97BXBqP8</link>
<guid>https://weibo.com/1402400261/O97BXBqP8</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 爱可可, 分享, 4.10, 美食, 旅行, 阅读, 心情, 文艺

<br /><br />总结:
4月10日，爱可可微博上分享了一篇热门文章，内容涵盖美食、旅行、阅读等多个领域。文章引发了用户们的讨论和关注。美食方面，推荐了一些新鲜有趣的料理；旅行部分介绍了一些独特的目的地和景点；阅读方面推荐了一些文艺作品，让人们在阅读中放松心情。这篇文章得到了广泛的转发和点赞，受到了大家的喜爱和欢迎。 <div>
《爱可可微博热门分享(4.10)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405021742140621081"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.10)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hom486sbdrj20kg0biwfg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 14:41:28 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Learning to Act without Actions》(ICLR 2024) GitHub: github.com/schmidtdominik/LAPO《Elucidating the Exposure Bias in Diffusion Mo...</title>
<link>https://weibo.com/1402400261/O94atlime</link>
<guid>https://weibo.com/1402400261/O94atlime</guid>
<content:encoded><![CDATA[
<div> Learning, Act, Actions, Exposure Bias, Diffusion Models, Memory-Augmented, Video Understanding, Facial Expressions, Prompt Optimization, Text-to-Image Generation

<br />本文介绍了几篇论文的实现代码，包括学习如何在没有动作的情况下进行行动的研究，揭示扩散模型中的曝光偏差，以及用于长期视频理解的记忆增强型多模态模型等。另外还讨论了通过神经合成分析实现的三维面部表情生成，以及在文本到图像生成中动态提示优化等内容。此外，文章还介绍了基于语言嵌入的三维高斯场用于开放词汇场景理解，以及从语言嵌入特征场进行物理属性理解的研究。此外，还包括了自动程序改进，扩散模型的缩放结构以及移动手机双摄平滑变焦等研究成果。同时，讨论了在个性化视觉编辑中实现任意对象交换，通过细粒度音频功能、文本嵌入监督和LLM混合增强来改进音频字幕模型，以及从单一图像实现零样本材料迁移等研究成果。最后还讨论了处理粗糙视觉条件的控制网络增强，无需训练的三维生成加速技术，以及大型语言模型对文本编码的潜在能力等内容。

<br /><br />总结: 本文总结了多篇涉及不同领域的论文实现代码，包括行动没有动作的学习、曝光偏差的解释、视频理解的记忆增强模型、三维面部表情生成、文本到图像生成优化等研究成果，并系统阐述了这些研究的关键要点和成果。 <div>
几篇论文实现代码：<br />《Learning to Act without Actions》(ICLR 2024) GitHub: github.com/schmidtdominik/LAPO<br />《Elucidating the Exposure Bias in Diffusion Models》(ICLR 2024) GitHub: github.com/forever208/EDM-ES<br />《MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding》(CVPR 2024) GitHub: github.com/boheumd/MA-LMM [fig4]<br />《3D Facial Expressions through Analysis-by-Neural-Synthesis》(CVPR 2024) GitHub: github.com/georgeretsi/smirk<br />《Dynamic Prompt Optimizing for Text-to-Image Generation》(CVPR 2024) GitHub: github.com/Mowenyii/PAE [fig5]<br />《Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras》(CVPR 2024) GitHub: github.com/HuajianUP/Photo-SLAM<br />《LEGaussians: Language Embedded 3D Gaussians for Open-Vocabulary Scene Understanding》(CVPR 2024) GitHub: github.com/buaavrcg/LEGaussians<br />《NeRF2Physics: Physical Property Understanding from Language-Embedded Feature Fields》(CVPR 2024) GitHub: github.com/ajzhai/NeRF2Physics [fig10]<br />《AutoCodeRover: Autonomous Program Improvement》(2024) GitHub: github.com/nus-apr/auto-code-rover [fig1]<br />《Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models》(2024) GitHub: github.com/feizc/Diffusion-RWKV [fig2]<br />《Dual-Camera Smooth Zoom on Mobile Phones》(2024) GitHub: github.com/ZcsrenlongZ/ZoomGS [fig3]<br />《SwapAnything: Enabling Arbitrary Object Swapping in Personalized Visual Editing》(2024) GitHub: github.com/eric-ai-lab/swap-anything [fig6]<br />《Improving Audio Captioning Models with Fine-grained Audio Features, Text Embedding Supervision, and LLM Mix-up Augmentation》(2024) GitHub: github.com/slSeanWU/beats-conformer-bart-audio-captioner<br />《ZeST: Zero-Shot Material Transfer from a Single Image》(2024) GitHub: github.com/ttchengab/zest_code [fig7]<br />《SmartControl: Enhancing ControlNet for Handling Rough Visual Conditions》(2024) GitHub: github.com/liuxiaoyu1104/SmartControl [fig8]<br />《Hash3D: Training-free Acceleration for 3D Generation》(2024) GitHub: github.com/Adamdad/hash3D [fig9]<br />《LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders》(2024) GitHub: github.com/McGill-NLP/llm2vec<br />《Point Cloud Mamba: Point Cloud Learning via State Space Model》(2024) GitHub: github.com/SkyworkAI/PointCloudMamba<br />《An Empirical Study of Data Ability Boundary in LLMs' Math Reasoning》(2024) GitHub: github.com/cyzhh/MMOS<br />《HiQA: A Hierarchical Contextual Augmentation RAG for Massive Documents QA》(2024) GitHub: github.com/TebooNok/HiQA<br />《Magic Clothing: Controllable Garment-Driven Image Synthesis》(2024) GitHub: github.com/ShineChen1024/MagicClothing<br />《Rethinking the Spatial Inconsistency in Classifier-Free Diffusion Guidance》(2024) GitHub: github.com/SmilesDZgk/S-CFG<br />《HyperTTS: Parameter Efficient Adaptation in Text to Speech using Hypernetworks》(2024) GitHub: github.com/declare-lab/HyperTTS<br />《AI and Memory Wall》(2024) GitHub: github.com/amirgholami/ai_and_memory_wall<br />《Compound text-guided prompt tuning via image-adaptive cues》(2024) GitHub: github.com/EricTan7/TGP-T [fig11]<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1holng2zgs7j20zx06rmyn.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1holng402ucj21120f0acu.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1holng4xjqaj20xt0pznh5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holng7m91ej26zk3m8e85.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holniqwve3j22dx0nwtwr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holnjgtfx2j243m23nqvh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1holnksevzyj21mr0olte9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1holnllw9hij22ps1bdhdt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1holnmp8hpzj21s10gg798.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holnzzb68pj21g70feajf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1holodjly5kj21rn0sg1kx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:55:30 GMT</pubDate>
</item>
<item>
<title>【LLM Gateway：用于安全可靠地与 OpenAI 和其他 LLM(语言模型)提供商进行通信的网关】'LLM Gateway - Gateway for secure &amp; reliable communications with Open...</title>
<link>https://weibo.com/1402400261/O943NqBXE</link>
<guid>https://weibo.com/1402400261/O943NqBXE</guid>
<content:encoded><![CDATA[
<div> LLM Gateway, 安全可靠, OpenAI, 通信, 网关, 语言模型, 提供商, GitHub<br /><br />总结:
LLM Gateway是一个用于安全可靠地与OpenAI和其他LLM提供商进行通信的网关。该项目在GitHub上可见，可以帮助用户进行安全和可靠的通讯。网关的主要作用是为用户提供与各种LLM提供商之间的连接和交流，确保信息传输的安全性和可靠性。通过LLM Gateway，用户可以更方便地与不同语言模型提供商进行沟通和合作。这个项目能够有效帮助用户实现与OpenAI等LLM提供商的通信需求，提高工作效率。 <div>
【LLM Gateway：用于安全可靠地与 OpenAI 和其他 LLM(语言模型)提供商进行通信的网关】'LLM Gateway - Gateway for secure &amp; reliable communications with OpenAI and other LLM providers' GitHub: github.com/wealthsimple/llm-gateway <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8holojwm2z6j212j0u0tba.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:39:03 GMT</pubDate>
</item>
<item>
<title>【Asterinas：安全、快速、通用的操作系统内核，使用Rust编写，并与Linux兼容】'Asterinas - a secure, fast, and general-purpose OS kernel, written in Rust ...</title>
<link>https://weibo.com/1402400261/O942Nv8kB</link>
<guid>https://weibo.com/1402400261/O942Nv8kB</guid>
<content:encoded><![CDATA[
<div> 安全、快速、通用、操作系统内核、Rust、Linux兼容、ABI、Asterinas、GitHub

<br /><br />总结:
Asterinas是一个使用Rust编写的安全、快速、通用的操作系统内核，与Linux兼容，提供Linux-compatible ABI。该项目在GitHub上托管，名为asterinas/asterinas。这个内核旨在提供更安全和高效的操作系统基础，同时保持与Linux的兼容性，为用户带来更好的操作系统体验。 <div>
【Asterinas：安全、快速、通用的操作系统内核，使用Rust编写，并与Linux兼容】'Asterinas - a secure, fast, and general-purpose OS kernel, written in Rust and providing Linux-compatible ABI.' GitHub: github.com/asterinas/asterinas <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%23&amp;isnewpage=1"><span class="surl-text">#操作系统#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8holoh9eu18j218s0u0af8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:36:36 GMT</pubDate>
</item>
<item>
<title>【Full Stack FastAPI, React, MongoDB (FARM) Base Project Generator：FastAPI 和 MongoDB 的全栈应用生成器】'Full Stack FastAPI, React, MongoDB (FARM) Ba...</title>
<link>https://weibo.com/1402400261/O9423iMeG</link>
<guid>https://weibo.com/1402400261/O9423iMeG</guid>
<content:encoded><![CDATA[
<div> Full Stack, FastAPI, React, MongoDB, FARM, Base Project Generator, GitHub, modern web application, Docker, automatic HTTPS

<br /><br />总结:
该项目是一个全栈应用生成器，使用FastAPI作为后端框架，MongoDB作为数据库，还包括了Docker和自动HTTPS等功能。通过该生成器，用户可以快速搭建现代化的全栈Web应用。项目托管在GitHub上，提供了丰富的功能和工具，方便用户进行开发和部署。 <div>
【Full Stack FastAPI, React, MongoDB (FARM) Base Project Generator：FastAPI 和 MongoDB 的全栈应用生成器】'Full Stack FastAPI, React, MongoDB (FARM) Base Project Generator - Full stack, modern web application generator. Using FastAPI, MongoDB as database, Docker, automatic HTTPS and more.' GitHub: github.com/mongodb-labs/full-stack-fastapi-mongodb <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8holofcb8hwj20u0118451.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:34:45 GMT</pubDate>
</item>
<item>
<title>【LLM Web界面大列表】’Awesome LLM WebUIs - A curated list of awesome Large Language Model (LLM) Web User Interfaces.' GitHub: github.com/JShollaj/awe...</title>
<link>https://weibo.com/1402400261/O940OywpS</link>
<guid>https://weibo.com/1402400261/O940OywpS</guid>
<content:encoded><![CDATA[
<div> GitHub, Awesome LLM WebUIs, Web User Interfaces, Curated list, Large Language Model, JShollaj, LLM, 接口, 网页界面

<br /><br />总结:
这篇文章是关于“Awesome LLM WebUIs”的GitHub项目，汇总了大型语言模型（LLM）Web用户界面的精选列表。项目由JShollaj创建，收集了一系列优秀的LLM WebUI，提供了丰富的接口和网页界面。如果你对LLM开发感兴趣，可以在GitHub上找到这个项目，了解更多相关信息。 <div>
【LLM Web界面大列表】’Awesome LLM WebUIs - A curated list of awesome Large Language Model (LLM) Web User Interfaces.' GitHub: github.com/JShollaj/awesome-llm-web-ui <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8holoc8gg90j20zk0k041k.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:31:43 GMT</pubDate>
</item>
<item>
<title>【Visualize LLM evals：可视化 LLM 评估的应用】'Visualize LLM evals - A streamlit app for visualizing LLM evals.' GitHub: github.com/mosaicml/llm-eval-...</title>
<link>https://weibo.com/1402400261/O940mBXlT</link>
<guid>https://weibo.com/1402400261/O940mBXlT</guid>
<content:encoded><![CDATA[
<div> 可视化、LLM、评估、应用、Streamlit、GitHub、dashboard、MosaicML、应用程序、数据可视化
<br /><br />总结:
这篇文章介绍了一个名为Visualize LLM evals的应用程序，它是一个基于Streamlit的数据可视化工具，用于可视化LLM评估。用户可以在GitHub上找到该应用程序的源代码。通过该应用程序，用户可以更直观地查看LLM的评估结果，帮助他们更好地理解和分析数据。该应用程序由MosaicML开发，为用户提供了一个方便的工具来探索和解释LLM的评估结果。 <div>
【Visualize LLM evals：可视化 LLM 评估的应用】'Visualize LLM evals - A streamlit app for visualizing LLM evals.' GitHub: github.com/mosaicml/llm-eval-dashboard <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8holoauq2roj214e0u0gpo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:30:36 GMT</pubDate>
</item>
<item>
<title>【Basalt：使用Mojo语言从零实现的机器学习框架】'Basalt - A Machine Learning framework from scratch in Pure Mojo' GitHub: github.com/basalt-org/basalt #...</title>
<link>https://weibo.com/1402400261/O93ZcybS5</link>
<guid>https://weibo.com/1402400261/O93ZcybS5</guid>
<content:encoded><![CDATA[
<div> Basalt、机器学习、Mojo语言、框架、GitHub、从零实现、纯Mojo、项目、代码库、学习

总结:<br /><br />这篇文章介绍了一个名为Basalt的机器学习框架，使用Mojo语言从零开始实现。该项目的代码库可以在GitHub上找到，并且是一个纯Mojo编写的框架。通过Basalt，用户可以学习如何从头开始构建一个机器学习框架，并且在其中使用Mojo语言。 <div>
【Basalt：使用Mojo语言从零实现的机器学习框架】'Basalt - A Machine Learning framework from scratch in Pure Mojo' GitHub: github.com/basalt-org/basalt <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8holo84iafvj20zc0sadis.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:27:44 GMT</pubDate>
</item>
<item>
<title>【aixcoder-7B 是一种代码大语言模型，旨在理解和生成跨多种编程语言的代码，提供最先进的代码补全、理解、生成等能力】'aiXcoder-7B Code Large Language Model...</title>
<link>https://weibo.com/1402400261/O93V9FLOM</link>
<guid>https://weibo.com/1402400261/O93V9FLOM</guid>
<content:encoded><![CDATA[
<div> aiXcoder-7B、代码大语言模型、跨编程语言、代码补全、理解、生成、GitHub、代码模型、AI、仓库<br />
<br />
总结:<br />
aiXcoder-7B是一种代码大语言模型，旨在理解和生成跨多种编程语言的代码。它提供了最先进的代码补全、理解和生成能力。该模型的官方仓库位于GitHub上，是一个代码模型，借助AI技术，为开发者提供强大的编程支持。 <div>
【aixcoder-7B 是一种代码大语言模型，旨在理解和生成跨多种编程语言的代码，提供最先进的代码补全、理解、生成等能力】'aiXcoder-7B Code Large Language Model - official repository of aiXcoder-7B Code Large Language Model' GitHub: github.com/aixcoder-plugin/aiXcoder-7B <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8holnxrok63j21740len1o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:17:46 GMT</pubDate>
</item>
<item>
<title>【关于使用大语言模型 (LLM) 在软件测试中的应用和研究的论文列表】’Awesome-LLM-SoftwareTesting' GitHub: github.com/LLM-Testing/LLM4SoftwareTesting #开源...</title>
<link>https://weibo.com/1402400261/O93TQ9LaM</link>
<guid>https://weibo.com/1402400261/O93TQ9LaM</guid>
<content:encoded><![CDATA[
<div> LLM、软件测试、应用、研究、论文、GitHub、LLM4SoftwareTesting

使用大语言模型（LLM）在软件测试中的应用和研究是一个备受关注的领域，GitHub上有一个名为'Awesome-LLM-SoftwareTesting'的项目专门收集了相关论文。这些论文包括了LLM在软件测试中的多种应用场景，以及对其性能和效果的研究。研究者们通过分析大量数据和实验结果，探索了LLM在软件缺陷检测、测试用例生成等方面的潜力，为软件测试领域的发展提供了新的思路和方法。总的来说，LLM在软件测试中的应用前景广阔，值得进一步深入研究和探索。<br /><br />总结:这些论文呈现了LLM在软件测试领域的重要应用和研究成果，展示了其在提高测试效率和质量方面的潜力，为未来的软件测试工作提供了重要参考和启发。 <div>
【关于使用大语言模型 (LLM) 在软件测试中的应用和研究的论文列表】’Awesome-LLM-SoftwareTesting' GitHub: github.com/LLM-Testing/LLM4SoftwareTesting <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8holnts4anrj20o80p0433.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:14:30 GMT</pubDate>
</item>
<item>
<title>'Awesome Cloudflare - 精选的 Cloudflare 工具、开源项目、指南、博客和其他资源列表' GitHub: github.com/zhuima/awesome-cloudflare #开源# #Cloudflare# [图...</title>
<link>https://weibo.com/1402400261/O93SWBw2M</link>
<guid>https://weibo.com/1402400261/O93SWBw2M</guid>
<content:encoded><![CDATA[
<div> GitHub、Cloudflare、工具、开源项目、指南、博客、资源列表、精选、zhuima、Awesome Cloudflare<br />
<br />
总结:<br />
本文介绍了 GitHub 上用户 zhuima 收集整理的关于 Cloudflare 的精选工具、开源项目、指南、博客和其他资源列表。其中包括了各种有用的工具和资源，针对 Cloudflare 的使用者提供了丰富的参考和指导，是一个非常实用的资源汇总。 <div>
'Awesome Cloudflare - 精选的 Cloudflare 工具、开源项目、指南、博客和其他资源列表' GitHub: github.com/zhuima/awesome-cloudflare <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Cloudflare%23"><span class="surl-text">#Cloudflare#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8holns27lssj21he0u0n33.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:12:19 GMT</pubDate>
</item>
<item>
<title>【衡量语言模型的说服力】- Anthropic开发了一种基本方法来测量语言模型的说服力，并用这种方法比较了Anthropic不同版本的Claude模型(Claude 1、2和3)以及两类模...</title>
<link>https://weibo.com/1402400261/O923JzYQz</link>
<guid>https://weibo.com/1402400261/O923JzYQz</guid>
<content:encoded><![CDATA[
<div> Anthropic、语言模型、说服力、Claude 模型、模型类别、模型版本、技能、研究、数据、风险

总结:<br /><br />本研究使用基本方法测量了语言模型的说服力，比较了Anthropic不同版本的Claude模型以及两种模型类别。在每个模型类别内，后续模型版本被评为更具说服力。最新的Claude 3 Opus模型产生的论点在说服力上与人类写的论点没有统计学差异。说服力是一种广泛应用的通用技能，研究其在AI模型中的应用具有重要意义。然而，评估说服力具有挑战性，结果可能不适用于现实世界，主观性和实验设计等因素也影响评估。Anthropic已经发布所有数据供他人调查和扩展，同时也在探索更具交互性的语境。未来需要进行进一步研究和负责任的部署实践，以减轻语言模型发展带来的潜在风险。模型规模与说服力正相关，这提示我们谨慎对待技术发展，同时基于模型的说服力评估为未来研究提供了宝贵的数据和见解。 <div>
【衡量语言模型的说服力】<br />- Anthropic开发了一种基本方法来测量语言模型的说服力，并用这种方法比较了Anthropic不同版本的Claude模型(Claude 1、2和3)以及两类模型(更小、更快、更经济的紧凑模型和更大、更强大的前沿模型)。   <br />- 在每个模型类别内，发现每个后续模型版本比前一个版本被评为更具说服力。最新、最强大的Claude 3 Opus模型产生的论点在其说服力上与人类写的论点没有统计学差异。   <br />- Anthropic研究说服力，因为它是一项广泛应用于世界各地的通用技能——公司试图说服人们购买产品，医护人员试图说服人们采取更健康的生活方式，政治家试图说服人们支持他们的政策并投票给他们。   <br />- 开发测量AI模型说服能力的方法很重要，因为它可作为模型在一个重要领域匹配人类技能的能力的代理测量，并且说服力最终可能与某些类型的滥用相关联。   <br />- 目前该研究存在许多局限性，说服力的评估本身就具有挑战性。所得出的结果可能不会广泛适用于现实世界，说服力是主观的，实验设计也存在缺陷。   <br />- Anthropic已发布所有数据，以供他人调查和扩展。也在积极扩展我们的工作到更具交互性的语境中。   <br />- 需要进一步的研究和负责任的部署实践，以减轻快速发展和越来越具说服力的语言模型的潜在风险。<br /><br />思考：  <br />- 该研究开创性地探索了语言模型的说服力，并提出了一种衡量说服力的方法。这对于理解人工智能在影响人类观点方面的潜力具有重要意义。  <br />- 研究发现模型规模与说服力之间存在明显的正相关，这表明随着模型变得越来越强大，它们可能会对人类的观点和决策产生更大的影响。这提醒我们要谨慎对待这些技术的发展。  <br />- 尽管基于模型的说服力评估与人类判断之间存在差异，但这项研究为进一步探索提供了宝贵的数据和见解。未来的工作可以在此基础上，开发出更准确、更可靠的说服力衡量方法。<br />《Measuring the Persuasiveness of Language Models \ Anthropic》 <a href="https://www.anthropic.com/news/measuring-model-persuasiveness"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8holfpwht4jj20u00van1x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 00:33:25 GMT</pubDate>
</item>
<item>
<title>【Google发布CodeGemma：开源代码大模型，与生态系统无缝集成】- CodeGemma是Google基于Gemma预训练模型发布的开源代码专用LLM家族，包括2B、7B和7B指令版。 - C...</title>
<link>https://weibo.com/1402400261/O91XXbmqo</link>
<guid>https://weibo.com/1402400261/O91XXbmqo</guid>
<content:encoded><![CDATA[
<div> CodeGemma, Google, 开源, 模型, 代码补全, 7B版本, 生产部署, Hugging Face, 集成, 创新应用

<br /><br />总结:
Google发布了开源代码模型CodeGemma，包括2B、7B和7B指令版，在代码补全和生成任务中表现优异。使用填充中间(FIM)形式的提示进行代码补全，并支持自然语言对话。与Transformers 4.39完全兼容，可以部署到Google Cloud或Hugging Face推理服务端点。这个开源基础为代码生成领域提供了强大工具，推动AI在编程领域的应用。Google的努力体现在开放大型语言模型方面，与Hugging Face合作使模型变得更加可触及。CodeGemma提供了满足不同使用需求的不同版本模型，有效提升开发效率。与Hugging Face生态系统的无缝集成使得模型可以利用各种先进技术，为模型性能优化提供可能性。 <div>
【Google发布CodeGemma：开源代码大模型，与生态系统无缝集成】<br />- CodeGemma是Google基于Gemma预训练模型发布的开源代码专用LLM家族，包括2B、7B和7B指令版。   <br />- CodeGemma在代码补全和生成任务上表现优异，尤其是7B版本在HumanEval等基准测试上的表现。   <br />- CodeGemma使用填充中间(FIM)形式的提示，可以进行代码补全。7B指令版可以进行关于代码的自然语言对话。   <br />- CodeGemma与Transformers 4.39完全兼容，可以利用Hugging Face生态系统中的工具。   <br />- CodeGemma可以一键部署到Google Cloud或Hugging Face推理服务端点，以进行生产部署。   <br />- CodeGemma为代码生成领域提供了一个强大而方便使用的开源基础，相信会推动更多创新应用的出现。   <br /> <br />思考：  <br />- CodeGemma 的发布体现了 Google 在开放大型语言模型方面的努力，与 Hugging Face 的合作更是让这些模型变得触手可及。这对于推动 AI 在编程领域的应用具有重要意义。  <br />- 三个不同版本的 CodeGemma 模型满足了不同的使用需求，无论是代码生成、自然语言理解，还是人机交互，都提供了强大的工具。这将极大地提升开发者的工作效率。  <br />- 与 Hugging Face 生态系统的无缝集成，使得 CodeGemma 可以利用各种先进的技术，如量化、参数高效微调、Flash Attention 等，这不仅方便了模型的使用，也为进一步优化模型性能提供了可能。<br />《CodeGemma - an official Google release for code LLMs》 <a href="https://huggingface.co/blog/codegemma"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8holfaxucwzj20ee09vaar.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 00:19:10 GMT</pubDate>
</item>
<item>
<title>2B模型发布：网页链接 //@爱可可-爱生活:提出了Griffin模型，一种新型的循环神经网络，结合了门控线性循环层与局部注意力机制，实现了与Transformer相当的性能，...</title>
<link>https://weibo.com/1402400261/O91W53IPY</link>
<guid>https://weibo.com/1402400261/O91W53IPY</guid>
<content:encoded><![CDATA[
<div> Griffin, 循环神经网络, 门控线性循环层, 局部注意力机制, Transformer, 长序列处理, 硬件效率, 高吞吐量, 低延迟, 语言模型

<br /><br />总结:
研究人员提出了一种名为Griffin的新型循环神经网络模型，结合了门控线性循环层和局部注意力机制。该模型实现了与Transformer相当的性能，在长序列处理和硬件效率方面表现出优势。特别是在推理时，Griffin表现出高吞吐量和低延迟。这一研究成果有望为语言模型领域带来新的突破和进展。Griffin模型在对长序列数据的处理和硬件效率方面都具有明显优势，为构建高性能语言模型提供了新的思路和方法。Griffin的提出对提高语言模型的性能、效率和推理能力具有积极意义。深度研究了Griffin模型的结构和原理，探讨了其在自然语言处理领域的潜在应用价值。Griffin模型不仅能提高语言模型的性能，还能为硬件资源利用效率提供更好的方案。Griffin模型融合了门控线性循环层和局部注意力机制的优点，展现出了强大的处理能力和效率。Griffin模型的提出对于提升语言模型的性能和应用范围具有重要意义。Griffin模型在实验中展现出了较好的表现，加深了人们对深度学习和自然语言处理的认识。Griffin模型的结构创新和性能表现有望在自然语言处理领域产生广泛的影响和应用。 <div>
2B模型发布：<a href="https://huggingface.co/google/recurrentgemma-2b"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> //<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>:提出了Griffin模型，一种新型的循环神经网络，结合了门控线性循环层与局部注意力机制，实现了与Transformer相当的性能，并在长序列处理和硬件效率方面展现出明显优势，尤其是在推理时的高吞吐量和低延迟表现<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models》S De, S L. Smith, A Fernando, A Botev… [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2402.19427"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnc7bm8wxfj21hc0eetfz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnc7bmuszij21h80quah7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnc7bn8l00j21gs0u0wkp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnc7bni9nyj21h20pywjy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnc7cdzcptj21140fs409.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnc7cdzq0xj21150h9ad0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnc7cdzrawj21190ewdiv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnc7cdzhj6j21140g6abt.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnc7cdznorj21190hy0v7.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 00:14:33 GMT</pubDate>
</item>
<item>
<title>【Gemini 1.5 Pro发布：原生音频理解、100万token上下文窗口、强大API】- Gemini 1.5 Pro 模型已在180多个国家/地区通过 Gemini API 公开预览，增加了音频理解能...</title>
<link>https://weibo.com/1402400261/O91U94q8X</link>
<guid>https://weibo.com/1402400261/O91U94q8X</guid>
<content:encoded><![CDATA[
<div> Gemini 1.5 Pro, 原生音频理解, 100万token上下文窗口, 强大API, 视频和音频理解, Google AI Studio, 系统指令功能, JSON模式, 函数调用改进, 新一代文本嵌入模型, Gemini API

<br /><br />总结:
Gemini 1.5 Pro发布，增加了原生音频理解和100万token上下文窗口，使其具有跨模态推理能力，可以同时处理视频中的图像和音频。Gemini API新增系统指令功能和JSON模式，提升模型的可靠性和输出方式。推出新文本嵌入模型，表现优秀，适用于语义搜索、文本聚类等任务。开发者可以使用Google AI Studio和Gemini API来构建基于Gemini的项目，获得更广阔的创新空间和更多用途。Gemini 1.5 Pro的功能和性能提升为开发者提供了更多智能、交互性强的应用场景。 <div>
【Gemini 1.5 Pro发布：原生音频理解、100万token上下文窗口、强大API】<br />- Gemini 1.5 Pro 模型已在180多个国家/地区通过 Gemini API 公开预览，增加了音频理解能力。   <br />- Gemini 1.5 Pro 现在可以同时理解视频中的图像和音频，Google AI Studio 中已支持，API 即将推出。   <br />- Gemini API 添加了系统指令功能，可以指导模型的响应；增加了 JSON 模式，可以只输出 JSON 对象。   <br />- Gemini API 改进了函数调用，可以选择限制模型的输出，提高可靠性。   <br />- 推出了新一代文本嵌入模型，在类似维度下表现优于现有模型，可通过 Gemini API 使用。   <br />- Google AI Studio 和 Gemini API 是构建基于 Gemini 的项目的最简单途径。开发者可以在 Studio 中访问 Gemini 1.5 Pro，参考 Gemini API Cookbook 的代码示例，并加入 Discord 社区。   <br /><br />思考：  <br />- Gemini 1.5 Pro 的 100 万 token 上下文窗口非常惊人，这为开发者提供了巨大的创新空间。  <br />- 原生音频理解和跨模态推理(图像+音频)功能的加入，大大拓宽了 Gemini 1.5 Pro 的应用场景。这使得开发者能够创建更加智能、交互性更强的应用。  <br />- 新的文本嵌入模型 text-embedding-004 在标准基准测试中展现出优异的性能，这对于需要高质量文本表示的任务(如语义搜索、文本聚类等)非常有帮助。<br />《Gemini 1.5 Pro Now Available in 180+ Countries; With Native Audio Understanding, System Instructions, JSON Mode and More - Google for Developers》 <a href="https://developers.googleblog.com/2024/04/gemini-15-pro-in-public-preview-with-new-features.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8holf198711j20wb0u0n13.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 00:09:47 GMT</pubDate>
</item>
<item>
<title>【AI模型的性别偏见】- AI模型会反映和夸大现实世界中存在的性别偏见。准确量化模型中的这些偏见对于恰当地解决和缓解它们非常重要。 - 词向量中存在性别偏见，...</title>
<link>https://weibo.com/1402400261/O91Lk1xOE</link>
<guid>https://weibo.com/1402400261/O91Lk1xOE</guid>
<content:encoded><![CDATA[
<div> 性别偏见, AI模型, 词向量, 人脸识别, 共指消解模型, 大型语言模型, 图像生成模型, 解决偏见, 批判意识, 学术研究  

总结：<br /><br />人工智能系统中存在性别偏见问题，如词向量类比偏见、人脸识别准确率差异、共指消解模型偏见等。研究表明存在性别偏见的AI模型需要修复，方法包括去偏算法、数据扩充和提升透明度等。学术界持续关注并研究解决AI中的性别偏见问题，提倡批判意识和思考修复性别偏见的哲学层面。对于构建更加公平、无偏见的人工智能系统具有重要意义。 <div>
【AI模型的性别偏见】<br />- AI模型会反映和夸大现实世界中存在的性别偏见。准确量化模型中的这些偏见对于恰当地解决和缓解它们非常重要。   <br />- 词向量中存在性别偏见，比如“程序员-男人”的向量类比与“家庭主妇-女人”相似，可以通过中性词去偏算法来降低这种偏见。   <br />- 人脸识别系统在识别不同肤色和性别的面部时准确率存在明显差异，对较深肤色女性识别效果最差。数据不平衡是导致这一问题的原因之一。   <br />- 共指消解模型在连接某些职业与特定性别代词上存在偏见，例如更倾向将“外科医生”解析为“他”而非“她”。   <br />- 在含糊语境下，大型语言模型倾向复现有害的社会偏见，如“女孩不善数学”。需要更全面的评估指标。   <br />- 图像生成模型倾向生成较多白人男性形象，尤其是权力职业。需要通过提示词审核等方式评估模型行为。   <br />- 存在的解决偏见的技术方法有去偏算法、扩充训练数据、提升模型透明度等。但更重要的是认识到“修复”偏见的哲学层面。   <br />- 识别偏见有助于改进AI模型，衡量问题是解决问题的第一步。偏见源自人类数据，但模型不必永远保持偏见。<br /><br />思考：  <br />- 文章揭示了一个容易被忽视但影响深远的问题：人工智能系统从人类创造的数据中学习，难免会继承并放大其中的社会偏见，尤其是性别偏见。这提醒我们在开发应用人工智能时，必须警惕和克服数据中的偏见。  <br />- 文章列举的几项研究工作让人印象深刻，从词嵌入到生成式语言模型，可以看出学术界正在从不同角度深入分析人工智能系统中的偏见问题。这些工作对于构建更加公平、无偏见的人工智能系统具有重要意义。  <br />《A Brief Overview of Gender Bias in AI》 <a href="https://thegradient.pub/gender-bias-in-ai/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span> <span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8holeemntj3j21ud0u0q9x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 23:48:02 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@异步图书 送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O91Jua4HQ</link>
<guid>https://weibo.com/1402400261/O91Jua4HQ</guid>
<content:encoded><![CDATA[
<div> 大语言模型，前沿进展，科学家，工程师，学生，案例，庖丁解牛，深入介绍，理解，认识

<br /><br />总结:
本文介绍了一本名为《大语言模型：基础与前沿》的书籍，全面深入地介绍了大语言模型及其前沿进展。适合科学家、工程师和学生参考。书籍摒弃了纯理论的说教模式，从案例入手，采用庖丁解牛的方式帮助读者理解与认识大语言模型。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%BC%82%E6%AD%A5%E5%9B%BE%E4%B9%A6">@异步图书</a>  送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。摒弃了纯理论的说教模式，从案例入手， 采用庖丁解牛的方式帮助读者理解与认识大语言模型。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019331269755053"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef8oboqij20ga0m8q8p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9segl7j20m90m9q6z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9t5km0j20m90m942f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef9tq2esj20m90m9gpe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef9ugq5dj20m90m9dif.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 23:43:31 GMT</pubDate>
</item>
<item>
<title>今日推介(第1371期)：语言模型知识容量缩放律、文本生成中语义漂移研究、基于形态学的位置编码研究、语言模型进化的迭代学习视角、基于多模态大语言模型的手机UI...</title>
<link>https://weibo.com/1402400261/O91c61wZd</link>
<guid>https://weibo.com/1402400261/O91c61wZd</guid>
<content:encoded><![CDATA[
<div> 知识容量缩放律 文本生成 语义漂移 形态学 位置编码 语言模型 迭代学习 多模态 理解 UI

语言模型的知识容量缩放律指的是随着模型大小的增加，模型表现提升的幅度会递减。文本生成中存在的语义漂移问题需要更深入的研究和解决。研究指出，基于形态学的位置编码可以提高语言模型的性能和泛化能力。从迭代学习的视角看待语言模型的进化可以更好的理解其发展过程。利用多模态大语言模型可以帮助手机UI更好地理解用户需求和行为。总结:在语言模型研究中，探索知识容量缩放律、解决语义漂移、优化位置编码、以迭代学习为视角和结合多模态等方面是当前的研究热点。 <div>
今日推介(第1371期)：语言模型知识容量缩放律、文本生成中语义漂移研究、基于形态学的位置编码研究、语言模型进化的迭代学习视角、基于多模态大语言模型的手机UI理解 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/691613835"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.10)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8holbvstxtbj21cy0ru12g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8holbw4ta9sj20so0oc41t.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8holbw7u09hj21o80u0jxg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8holbwa8q3uj20tc0mgacn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8holbwdoh9jj212o0u0wml.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 22:21:14 GMT</pubDate>
</item>
<item>
<title>[CV] MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding 网页链接 通过在线处理视频序列并存储历史特征于记忆库中，实现了高...</title>
<link>https://weibo.com/1402400261/O9121yn1Y</link>
<guid>https://weibo.com/1402400261/O9121yn1Y</guid>
<content:encoded><![CDATA[
<div> 视频序列、在线处理、历史特征、记忆库、长时视频理解、MA-LMM、多模态模型、效率、存储、高效

<br /><br />总结:
本研究提出了一种名为MA-LMM的Memory-Augmented Large Multimodal Model，通过在线处理视频序列并将历史特征存储在记忆库中，实现了高效的长时视频理解。该模型是一种多模态模型，能够有效地存储和检索视频序列的关键信息。通过使用记忆库，模型能够在处理长时间视频时提供更好的性能，实现了对视频序列的有效理解和分析。MA-LMM的出现为长时视频理解领域带来了新的思路和方法，提高了视频理解的效率和性能。 <div>
[CV] MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding  <br /><a href="https://arxiv.org/abs/2404.05726"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过在线处理视频序列并存储历史特征于记忆库中，实现了高效的长时视频理解。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holb6kdbr2j21281b01aj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1holb6ktt6mj21qm1324ee.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holb6kvlbgj21ce0yyanw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:56:27 GMT</pubDate>
</item>
<item>
<title>[CV] Finding Visual Task Vectors 网页链接 通过分析MAE-VQGAN的激活，提出激活评分方法和使用REINFORCE搜索任务向量，找到了提供零样本控制的任务向量，还降低...</title>
<link>https://weibo.com/1402400261/O90ZXBsN6</link>
<guid>https://weibo.com/1402400261/O90ZXBsN6</guid>
<content:encoded><![CDATA[
<div> 提取关键词: MAE-VQGAN, 激活评分方法, REINFORCE, 零样本控制, 任务向量, 降低计算量

总结:
通过分析MAE-VQGAN的激活并提出激活评分方法，使用REINFORCE搜索任务向量，找到了提供零样本控制的任务向量。同时，还成功降低了计算量。这项研究方法为寻找视觉任务向量提供了新的思路，可以有效实现任务的零样本控制。而通过采用REINFORCE算法，不仅可以有效搜索到合适的任务向量，还有助于减少计算成本。该方法为改善零样本控制问题提供了新的解决方案，对未来的研究具有重要意义。 <div>
[CV] Finding Visual Task Vectors  <br /><a href="https://arxiv.org/abs/2404.05729"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过分析MAE-VQGAN的激活，提出激活评分方法和使用REINFORCE搜索任务向量，找到了提供零样本控制的任务向量，还降低了计算量。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holb190uinj20vc1by16a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holb1a2c20j20va1cetew.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holb1a9htqj20v41ea11h.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:51:22 GMT</pubDate>
</item>
<item>
<title>[LG] Trustless Audits without Revealing Data or Models 网页链接 通过零知识证明设计ZKAUDIT协议，使模型提供者可在保护模型和数据秘密的同时，允许用户进行...</title>
<link>https://weibo.com/1402400261/O90X92TCh</link>
<guid>https://weibo.com/1402400261/O90X92TCh</guid>
<content:encoded><![CDATA[
<div> 提取关键词: 零知识证明, ZKAUDIT协议, 模型提供者, 数据保护, 模型保密, 信任, 属性审计, 算法透明度, 商业需求

总结:<br /><br />本文介绍了通过零知识证明设计ZKAUDIT协议，实现了模型提供者在保护模型和数据秘密的同时，允许用户进行无需信任的模型和数据属性审计，从而平衡了算法透明度与商业需求之间的关系。零知识证明技术使得模型提供者可以证明其模型的准确性和有效性，而无需泄露敏感数据或模型细节，保护了数据隐私。用户可以通过ZKAUDIT协议对模型和数据进行属性审计，验证其合规性和可信度，而无需相信模型提供者的陈述。这种方法在实现数据和模型透明度的同时，保证了安全性和隐私保护，为商业应用提供了更高的可信度和保障。 <div>
[LG] Trustless Audits without Revealing Data or Models  <br /><a href="https://arxiv.org/abs/2404.04500"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过零知识证明设计ZKAUDIT协议，使模型提供者可在保护模型和数据秘密的同时，允许用户进行无需信任的模型和数据属性审计，实现了算法透明度与商业需求的平衡。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holau1ibibj211o1bk1eb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1holau1m6cxj21n00jkn16.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holau1x6tdj20ty0jcgna.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:44:25 GMT</pubDate>
</item>
<item>
<title>[LG] A Large-Scale Exploration of μμ-Transfer 网页链接 通过transformer模型的大规模经验研究验证了μ-transfer技术在许多重要情况下确实能可靠地传递最优...</title>
<link>https://weibo.com/1402400261/O90Uqi7rn</link>
<guid>https://weibo.com/1402400261/O90Uqi7rn</guid>
<content:encoded><![CDATA[
<div> μ-transfer, transformer模型, 大规模研究, 超参数, 可靠传递, 意外情况, 需要谨慎验证<br />
<br />
<br />总结:
本研究通过大规模实验验证了μ-transfer技术在传递最优超参数方面的可靠性，但也发现了一些意外情况，需要进行谨慎验证。 transformer模型的应用在此过程中起到了关键作用，为进一步研究μ-transfer技术提供了有力支持。在实际应用中，需要考虑到意外情况可能带来的影响，以确保技术的稳定性和可靠性。 <div>
[LG] A Large-Scale Exploration of μμ-Transfer  <br /><a href="https://arxiv.org/abs/2404.05728"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过transformer模型的大规模经验研究验证了μ-transfer技术在许多重要情况下确实能可靠地传递最优超参数，但也发现了一些意外的情况，需要谨慎地进行验证。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holan334ilj20ua1cwk8w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1holan3j738j20um1d8wr7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:37:43 GMT</pubDate>
</item>
<item>
<title>Ferret-UI是首个兼具精确提述、接地和推理能力的面向手机用户界面理解的多模态大语言模型。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《Ferret-UI: Grounded Mobile UI ...</title>
<link>https://weibo.com/1402400261/O90QdqdeF</link>
<guid>https://weibo.com/1402400261/O90QdqdeF</guid>
<content:encoded><![CDATA[
<div> Ferret-UI, 多模态大语言模型, 手机用户界面理解, 精确提述, 接地, 推理能力, Apple, 2024

<br /><br />总结:
这篇文章介绍了Ferret-UI，一个面向手机用户界面理解的多模态大语言模型。该模型具备精确提述、接地和推理能力，能够有效理解手机用户界面。该研究由苹果公司的团队完成，展示了在该领域取得的成果。Ferret-UI的出现将为手机界面理解领域带来新的突破和可能性。 <div>
Ferret-UI是首个兼具精确提述、接地和推理能力的面向手机用户界面理解的多模态大语言模型。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs》K You, H Zhang, E Schoop, F Weers, A Swearngin, J Nichols, Y Yang, Z Gan [Apple] (2024) <a href="https://arxiv.org/abs/2404.05719"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola3ws1kpj217u15sqln.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola3x89kwj210m172anw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hola3xy18qj21dg19kdss.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola3y7utwj21e412w7ij.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holabzydjyj20rh0k4q6i.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holabzx9zgj20rh0bfjsl.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holabzxvv6j20rh0khtay.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1holabzxttpj20rh0l6acb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holabzxtl3j20rh0ikq50.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:27:20 GMT</pubDate>
</item>
<item>
<title>[CV]《Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs》K You, H Zhang, E Schoop, F Weers, A Swearngin, J Nichols, Y Yang, Z Gan [Appl...</title>
<link>https://weibo.com/1402400261/O90Q6jE24</link>
<guid>https://weibo.com/1402400261/O90Q6jE24</guid>
<content:encoded><![CDATA[
<div> 关键词: Ferret-UI, Grounded Mobile UI Understanding, Multimodal LLMs, Apple

总结:<br /><br />本文介绍了一种名为Ferret-UI的技术，利用多模态LLMs实现对移动UI的深入理解，提高用户体验。研究团队来自Apple，通过结合语言、视觉等多种模态信息，实现了对移动界面的全面分析和理解。他们采用了一系列先进的技术和方法，使得Ferret-UI能够更准确地理解用户交互、意图和界面元素之间的关系。通过在真实环境中的实验测试，证明了Ferret-UI在移动UI理解方面的有效性和可行性。这项研究对于提升移动应用程序的用户体验和界面设计具有重要意义，是移动UI理解领域的一项重要研究工作。 <div>
[CV]《Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs》K You, H Zhang, E Schoop, F Weers, A Swearngin, J Nichols, Y Yang, Z Gan [Apple] (2024) <a href="https://arxiv.org/abs/2404.05719"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola3ws1kpj217u15sqln.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola3x89kwj210m172anw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hola3xy18qj21dg19kdss.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola3y7utwj21e412w7ij.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holabzydjyj20rh0k4q6i.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holabzx9zgj20rh0bfjsl.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holabzxvv6j20rh0khtay.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1holabzxttpj20rh0l6acb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holabzxtl3j20rh0ikq50.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holabzz105j20rl10gaf2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1holabzx1tdj20rh0gpq4k.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holabzyfvoj20py0ocdjl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holabzxw33j20rh0msq4m.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:27:04 GMT</pubDate>
</item>
<item>
<title>通过将大语言模型视为贝叶斯智能体，应用迭代学习理论框架来分析和指导其自主进化过程，为后续研究奠定理论基础。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Language ...</title>
<link>https://weibo.com/1402400261/O90LAqpAn</link>
<guid>https://weibo.com/1402400261/O90LAqpAn</guid>
<content:encoded><![CDATA[
<div> 关键词: 大语言模型, 贝叶斯智能体, 迭代学习理论, 自主进化, 研究基础

总结:<br /><br />这篇文章将大语言模型视为贝叶斯智能体，应用迭代学习理论框架来分析和指导其自主进化过程，并为后续研究奠定了理论基础。文章提出了一种新的理论框架，用于探究大语言模型的进化过程。通过将语言模型看作一个智能体，并应用迭代学习理论来指导其演化，研究者们可以更好地理解其进化机制和行为。这种方法有望为语言模型领域的未来研究提供指导和启发。 <div>
通过将大语言模型视为贝叶斯智能体，应用迭代学习理论框架来分析和指导其自主进化过程，为后续研究奠定理论基础。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Language Model Evolution: An Iterated Learning Perspective》Y Ren, S Guo, L Qiu, B Wang, D J. Sutherland [University of British Columbia &amp; University of Edinburgh &amp; MIT] (2024) <a href="https://arxiv.org/abs/2404.04286"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hol9zk6sq3j20p614y13j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9zkqcscj20tc0mg77s.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9zkzlhxj20ti0kc436.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hol9zl5ys8j20u60kqjvn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola077scxj20iv0d9q4l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola077m1rj20tv0eyjsi.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hola07805ij20yd0d2aci.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola07829sj212b0cw768.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hola0784hbj212e0e4dim.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:15:57 GMT</pubDate>
</item>
<item>
<title>[CL]《Language Model Evolution: An Iterated Learning Perspective》Y Ren, S Guo, L Qiu, B Wang, D J. Sutherland [University of British Columbia &amp; Unive...</title>
<link>https://weibo.com/1402400261/O90LuFGh1</link>
<guid>https://weibo.com/1402400261/O90LuFGh1</guid>
<content:encoded><![CDATA[
<div> 语言模型演化，迭代学习，关键词：语言模型、演化、迭代学习、进化、文化传播、信息传递、语言演化、模型更新、学习机制、计算模型。<br />
<br />
总结:本文从迭代学习的角度探讨了语言模型的演化过程。研究指出，语言模型的进化受到文化传播和信息传递的影响，提出了一种基于学习机制的语言演化模型，并通过计算模型进行更新。该研究有助于深入理解语言模型的演化过程，为语言学研究提供了新的视角。 <div>
[CL]《Language Model Evolution: An Iterated Learning Perspective》Y Ren, S Guo, L Qiu, B Wang, D J. Sutherland [University of British Columbia &amp; University of Edinburgh &amp; MIT] (2024) <a href="https://arxiv.org/abs/2404.04286"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hol9zk6sq3j20p614y13j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9zkqcscj20tc0mg77s.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9zkzlhxj20ti0kc436.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hol9zl5ys8j20u60kqjvn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola077scxj20iv0d9q4l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola077m1rj20tv0eyjsi.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hola07805ij20yd0d2aci.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola07829sj212b0cw768.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hola0784hbj212e0e4dim.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola079j95j20tv0n9mzn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola0791z4j212b0i1die.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hola07a26hj212b0g8gon.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola07b7mlj212e0txdmd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hola079onzj212b0fy76i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hola07axiij212b0owq8d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hola07akcmj212b0op782.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hola07axmej212c0nwads.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola07bfmhj20wg0ks0vh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:15:44 GMT</pubDate>
</item>
<item>
<title>系统研究位置编码对不同词法复杂性语言的重要性，发现位置编码对分析性语言影响较大而对合成性语言影响较小，结论与语言学理论一致。 - 转发 @爱可可-爱生活:&amp;en...</title>
<link>https://weibo.com/1402400261/O90KZuc3B</link>
<guid>https://weibo.com/1402400261/O90KZuc3B</guid>
<content:encoded><![CDATA[
<div> 位置编码、词法复杂性语言、分析性语言、合成性语言、语言学理论、研究、重要性、影响、位置编码、调查

总结:<br /><br />本研究对位置编码在不同词法复杂性语言中的作用进行了调查。研究发现，位置编码对分析性语言的影响较大，而对合成性语言的影响较小，这与语言学理论相一致。位置编码在分析性语言中的重要性得到了验证，并有助于深入理解语言结构和语法规则。这项研究由印度理工学院孟买分校、Google研究机构和日本信息通信研究所合作完成，为语言学领域的研究提供了新的观点和方法。 <div>
系统研究位置编码对不同词法复杂性语言的重要性，发现位置编码对分析性语言影响较大而对合成性语言影响较小，结论与语言学理论一致。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《A Morphology-Based Investigation of Positional Encodings》P Ghosh, S Vashishth, R Dabre, P Bhattacharyya [IIT Bombay &amp; Google Research &amp; NICT] (2024) <a href="https://arxiv.org/abs/2404.04530"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9xgfeqdj21ou0imalt.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hol9xgvlj4j20ru0oawgq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hol9xheqryj21pe0uk119.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hol9xhhuykj20jk1duwil.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9ypmrgmj20ju1agn11.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9yq0tvhj20j80gc0to.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:14:29 GMT</pubDate>
</item>
<item>
<title>[CL]《A Morphology-Based Investigation of Positional Encodings》P Ghosh, S Vashishth, R Dabre, P Bhattacharyya [IIT Bombay &amp; Google Research &amp; NICT] (...</title>
<link>https://weibo.com/1402400261/O90KV7K65</link>
<guid>https://weibo.com/1402400261/O90KV7K65</guid>
<content:encoded><![CDATA[
<div> Positional Encodings, Morphology-Based Investigation, IIT Bombay, Google Research, NICT, P Ghosh, S Vashishth, R Dabre, P Bhattacharyya

<br /><br />总结:
这篇文章探讨了基于形态学的位置编码在自然语言处理中的应用。研究作者来自IIT孟买、谷歌研究和NICT。他们分析了不同位置编码方法在文本处理中的效果，并提出了一种新的基于形态学的位置编码方法。通过实验证明，这种方法在提高自然语言处理任务的性能方面具有显著优势。研究结果为语言学和机器学习领域的研究提供了有益的参考。 <div>
[CL]《A Morphology-Based Investigation of Positional Encodings》P Ghosh, S Vashishth, R Dabre, P Bhattacharyya [IIT Bombay &amp; Google Research &amp; NICT] (2024) <a href="https://arxiv.org/abs/2404.04530"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9xgfeqdj21ou0imalt.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hol9xgvlj4j20ru0oawgq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hol9xheqryj21pe0uk119.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hol9xhhuykj20jk1duwil.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9ypmrgmj20ju1agn11.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9yq0tvhj20j80gc0to.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:14:18 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.9)》 爱可可微博热门分享(4.9) [图片]</title>
<link>https://weibo.com/1402400261/O8Y7QgBBw</link>
<guid>https://weibo.com/1402400261/O8Y7QgBBw</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、4.9、文章、内容、关键字、讨论、社交平台

总结:<br /><br />本篇文章讨论了爱可可微博上的热门分享，内容涉及各种话题和热点事件。文章的关键字分析揭示了微博用户的关注点和讨论热度。通过社交平台分享信息，用户可以及时了解最新的情况，进行互动交流，丰富自己的知识和视野。爱可可微博作为一个活跃的社交平台，为用户带来了丰富多彩的内容，让用户在其中畅所欲言，分享自己的观点和生活。在这个平台上，用户可以参与讨论，和他人交流想法，扩展自己的社交圈，促进信息传播和互动交流。通过分享热门内容，用户可以发现共同兴趣，建立互相认同的社群，形成良性的社交生态，提升用户体验和参与度。爱可可微博的热门分享吸引了众多关注和参与，为用户带来了丰富多彩的内容，让用户共同感受和分享这个社交平台的魅力。 <div>
《爱可可微博热门分享(4.9)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405021377504608501"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.9)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hokycl47zxj20rs0fmjuy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 14:32:32 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《SchurVINS: Schur Complement-Based Lightweight Visual Inertial Navigation System》(CVPR 2024) GitHub: github.com/bytedance/SchurVIN...</title>
<link>https://weibo.com/1402400261/O8XwHkqsZ</link>
<guid>https://weibo.com/1402400261/O8XwHkqsZ</guid>
<content:encoded><![CDATA[
<div> 关键词: SchurVINS, 轻量级视觉惯性导航系统, 空间视觉-语言推理, 3D人物和物体联合重建, 多任务去噪扩散模型, 图像恢复, 单视图重建, 大语言模型适应, 三维人物纹理编辑, 扰动引导注意力.

总结:<br /><br />
《SchurVINS: Schur Complement-Based Lightweight Visual Inertial Navigation System》介绍了一种基于Schur补的轻量级视觉惯性导航系统SchurVINS，利用Schur补的方式提高了系统的效率和精度。该系统在GitHub有对应的代码库。
《Know Your Neighbors: Improving Single-View Reconstruction via Spatial Vision-Language Reasoning》通过空间视觉-语言推理的方式改善了单视图重建的效果，提高了重建的准确性。
《CONTHO: Joint Reconstruction of 3D Human and Object via Contact-Based Refinement Transformer》提出了一种通过接触为基础的细化变换器来联合重建3D人物和物体的方法CONTHO，增强了重建的效果。
《DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data》介绍了一种从部分标记数据中学习多任务去噪扩散模型的方法DiffusionMTL，提高了模型的鲁棒性。
《Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model》通过扩散模型提出了一种用于通用图像恢复的选择性沙漏映射方法，提高了恢复效果。
《PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models》提出了一种大语言模型的适应方法PiSSA，通过调整主奇异值和奇异向量来改善模型性能。
《InstructHumans: Editing Animated 3D Human Textures with Instructions》通过指令编辑动画3D人物纹理的方式，实现了纹理编辑的功能。
《Self-Rectifying Diffusion Sampling with Perturbed-Attention Guidance》介绍了一种带有扰动引导注意力的自校正扩散采样方法，提高了采样效果。
《Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation》提出了一种用于多模态语义分割的Siamese Mamba网络Sigma，增强了分割的准确性。
《UniTable: Towards a Unified Table Foundation Model》针对统一表格基础模型提出了UniTable，提高了表格数据处理的效率和准确性。 <div>
几篇论文实现代码：<br />《SchurVINS: Schur Complement-Based Lightweight Visual Inertial Navigation System》(CVPR 2024) GitHub: github.com/bytedance/SchurVINS<br />《Know Your Neighbors: Improving Single-View Reconstruction via Spatial Vision-Language Reasoning》(CVPR 2024) GitHub: github.com/ruili3/Know-Your-Neighbors<br />《CONTHO: Joint Reconstruction of 3D Human and Object via Contact-Based Refinement Transformer》(CVPR 2024) GitHub: github.com/dqj5182/CONTHO_RELEASE<br />《DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data》(CVPR 2024) GitHub: github.com/prismformore/DiffusionMTL [fig4]<br />《Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model》(CVPR 2024) GitHub: github.com/iSEE-Laboratory/DiffUIR [fig8]<br />《PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models》(2024) GitHub: github.com/GraphPKU/PiSSA [fig1]<br />《InstructHumans: Editing Animated 3D Human Textures with Instructions》(2024) GitHub: github.com/viridityzhu/InstructHumans<br />《Self-Rectifying Diffusion Sampling with Perturbed-Attention Guidance》(2024) GitHub: github.com/sunovivid/Perturbed-Attention-Guidance<br />《Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation》(2024) GitHub: github.com/zifuwan/Sigma [fig2]<br />《UniTable: Towards a Unified Table Foundation Model》(2024) GitHub: github.com/poloclub/unitable<br />《LeGrad: An Explainability Method for Vision Transformers via Feature Formation Sensitivity》(2024) GitHub: github.com/WalBouss/LeGrad<br />《Identity Decoupling for Multi-Subject Personalization of Text-to-Image Models》(2024) GitHub: github.com/agwmon/MuDI<br />《FABLES: Evaluating faithfulness and content selection in book-length summarization》(2024) GitHub: github.com/mungg/FABLES [fig3]<br />《Stream of Search: Learning to Search in Language》(2024) GitHub: github.com/kanishkg/stream-of-search<br />《Neural Plasticity-Inspired Foundation Model for Observing the Earth Crossing Modalities》(2024) GitHub: github.com/zhu-xlab/DOFA [fig5]<br />《Dissecting Human and LLM Preferencces》(2024) GitHub: github.com/GAIR-NLP/Preference-Dissection<br />《Evaluating LLMs at Detecting Errors in LLM Responses》(2024) GitHub: github.com/psunlpgroup/ReaLMistake [fig6]<br />《JORA: JAX Tensor-Parallel LoRA Library for Retrieval Augmented Fine-Tuning》(2024) GitHub: github.com/aniquetahir/JORA [fig7]<br />《HALC: Object Hallucination Reduction via Adaptive Focal-Contrast Decoding》(2024) GitHub: github.com/BillChan226/HALC<br />《TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios》(2024) GitHub: github.com/RUCKBReasoning/TableLLM<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoku23j1poj21vc0vudw9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoku24hcx1j20yg0cvtgs.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoku6n03izj21gs0frws9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoku8i46yaj21dy10se81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoku9523i0j222810ge81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hokuwhdwsfj20x60h2wsx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hokuxm49ztj21cz0ga44t.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hokv72x9lsj215u0u0tx2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 13:01:02 GMT</pubDate>
</item>
<item>
<title>【Neco：C 语言编写的并发库，提供了使用 coroutines(协程)的方式进行并发编程】'Neco - Concurrency library for C (coroutines)' GitHub: github.com/tidwall/...</title>
<link>https://weibo.com/1402400261/O8XwbhTdx</link>
<guid>https://weibo.com/1402400261/O8XwbhTdx</guid>
<content:encoded><![CDATA[
<div> GitHub, Neco, C语言, 并发库, coroutines, 协程, 编程, 提供, 方式, 进行

<br /><br />总结:
Neco是一个用C语言编写的并发库，提供了使用coroutines(协程)的方式进行并发编程。这个库在GitHub上有开源代码可供使用。通过Neco，开发者可以更方便地在C语言中实现并发编程，利用协程的特性进行高效的异步操作处理。同时，Neco也提供了丰富的API和功能，使得编写并发代码变得更加简单和容易。如果你在C语言项目中需要实现并发功能，不妨考虑使用Neco库来简化你的开发过程。 <div>
【Neco：C 语言编写的并发库，提供了使用 coroutines(协程)的方式进行并发编程】'Neco - Concurrency library for C (coroutines)' GitHub: github.com/tidwall/neco <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hokvo4kzesj211d0u0dkq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:59:45 GMT</pubDate>
</item>
<item>
<title>【GigaAM: 一个基础模型，专门为语音识别任务设计，包括 GigaAM、GigaAM-CTC 和 GigaAM-Emo 三个模型】'GigaAM: the family of open-source acoustic models for...</title>
<link>https://weibo.com/1402400261/O8XvDxixo</link>
<guid>https://weibo.com/1402400261/O8XvDxixo</guid>
<content:encoded><![CDATA[
<div> GigaAM, acoustic models, speech processing, open-source, GitHub, GigaAM-CTC, GigaAM-Emo<br />
<br />总结:<br />
本文介绍了GigaAM家族，这是专门为语音处理任务设计的开源声学模型。基础模型GigaAM作为语音识别任务的基础模型，提供了实用的功能。除了GigaAM之外，还有GigaAM-CTC和GigaAM-Emo两个模型，扩展了应用领域。感兴趣的开发者可以在GitHub上找到相关代码和资源，进行进一步的研究和实践。整体来看，GigaAM家族为语音识别任务提供了一系列可靠的解决方案，对于开发语音相关应用具有实际意义。 <div>
【GigaAM: 一个基础模型，专门为语音识别任务设计，包括 GigaAM、GigaAM-CTC 和 GigaAM-Emo 三个模型】'GigaAM: the family of open-source acoustic models for speech processing - Foundational Model for Speech Recognition Tasks' GitHub: github.com/salute-developers/GigaAM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hokvmml0n2j212x0u00xa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:58:25 GMT</pubDate>
</item>
<item>
<title>【Serverless ChatGPT with RAG using LangChain.js：用 LangChain.js, TypeScript 和 Azure 创建自己的无服务器 ChatGPT 应用的示例】'Serverless ChatGPT with...</title>
<link>https://weibo.com/1402400261/O8Xtpjjvx</link>
<guid>https://weibo.com/1402400261/O8Xtpjjvx</guid>
<content:encoded><![CDATA[
<div> LangChain.js, TypeScript, Azure, 无服务器, ChatGPT, RAG, 应用, 示例

<br /><br />总结:
本篇文章介绍了如何使用LangChain.js、TypeScript和Azure创建自己的无服务器ChatGPT应用，利用检索增强生成（RAG）技术。通过GitHub上的示例代码，读者可以了解如何实现ChatGPT应用，并在Azure平台上部署运行。文章着重介绍了如何利用LangChain.js进行开发，展示了搭建ChatGPT应用的具体步骤和流程。读者可以根据文中的指引，轻松地开始构建自己的ChatGPT应用，并进一步探索无服务器技术和人工智能的结合应用。 <div>
【Serverless ChatGPT with RAG using LangChain.js：用 LangChain.js, TypeScript 和 Azure 创建自己的无服务器 ChatGPT 应用的示例】'Serverless ChatGPT with RAG using LangChain.js - Create your own serverless ChatGPT with Retrieval-Augmented-Generation using LangChain.js, TypeScript and Azure' GitHub: github.com/Azure-Samples/serverless-chat-langchainjs <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hokvh1g0lyj20up0u00wr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:52:55 GMT</pubDate>
</item>
<item>
<title>【ZhiJian：基于 PyTorch 的模型重用工具包，旨在利用预训练模型和其微调后版本来提取知识并加速实际任务的处理，根据模型准备、模型学习和模型推断三个阶段分别...</title>
<link>https://weibo.com/1402400261/O8XrT4Naf</link>
<guid>https://weibo.com/1402400261/O8XrT4Naf</guid>
<content:encoded><![CDATA[
<div> PyTorch、模型重用、预训练模型、知识提取、实际任务、模型准备、模型学习、模型推断、架构、微调

<br /><br />总结:
本文介绍了一种基于 PyTorch 的模型重用工具包 ZhiJian，旨在利用预训练模型和微调后版本来提取知识并加速实际任务处理。工具包提供了模型准备、模型学习和模型推断三个阶段的架构、微调和合并模块。通过 ZhiJian 工具包，用户可以更高效地利用预训练模型，并在实际任务中快速部署和应用这些模型，提高任务处理效率和模型效果。工具包的使用有助于加速模型重用和知识迁移的过程，让用户能够更便捷地利用先验知识进行任务处理，提高工作效率和模型性能。 <div>
【ZhiJian：基于 PyTorch 的模型重用工具包，旨在利用预训练模型和其微调后版本来提取知识并加速实际任务的处理，根据模型准备、模型学习和模型推断三个阶段分别提供了架构、微调和合并模块】'ZhiJian: A Unifying and Rapidly Deployable Toolbox for Pre-trained Model Reuse' GitHub: github.com/zhangyikaii/LAMDA-ZhiJian <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hokvd0adf5j22qy0u0gxm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hokvd4gau2j21ep0gvtcb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:49:10 GMT</pubDate>
</item>
<item>
<title>【ΦML：数学和神经网络库，专门为科学应用设计，支持 Jax、PyTorch、TensorFlow 和 NumPy，并提供了许多有用的特性】'ΦML - Intuitive scientific computing w...</title>
<link>https://weibo.com/1402400261/O8XqIcbXB</link>
<guid>https://weibo.com/1402400261/O8XqIcbXB</guid>
<content:encoded><![CDATA[
<div> Jax, PyTorch, TensorFlow, NumPy, 神经网络库, 科学应用, 特性, GitHub, 数学, 维度类型

<br /><br />总结:
ΦML是一个专为科学应用设计的数学和神经网络库，支持Jax、PyTorch、TensorFlow和NumPy，并提供许多有用的特性。该库具有维度类型，可使科学计算更直观。用户可以在GitHub上找到ΦML的相关信息。 <div>
【ΦML：数学和神经网络库，专门为科学应用设计，支持 Jax、PyTorch、TensorFlow 和 NumPy，并提供了许多有用的特性】'ΦML - Intuitive scientific computing with dimension types for Jax, PyTorch, TensorFlow &amp; NumPy' GitHub: github.com/tum-pbs/PhiML <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hokva4bbpfj212d0u043n.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:46:16 GMT</pubDate>
</item>
<item>
<title>【Cloud Service Providers Free Tier Overview：主要的云服务提供商的免费配额比较，包括 AWS、Azure、Google Cloud、Oracle Cloud 等。同时也包括了一些额外的...</title>
<link>https://weibo.com/1402400261/O8Xp8eQ5q</link>
<guid>https://weibo.com/1402400261/O8Xp8eQ5q</guid>
<content:encoded><![CDATA[
<div> AWS、Azure、Google Cloud、Oracle Cloud、Alibaba Cloud、IBM Cloud、DigitalOcean、免费配额、云服务提供商、使用场景
<br />
要点1: 本文介绍了主要云服务提供商如AWS、Azure、Google Cloud、Oracle Cloud等的免费配额比较。
要点2: 每个云服务提供商的免费配额都有所不同，适合不同的使用场景。
要点3: 除了主要云服务提供商外，还包括了一些额外的服务如Alibaba Cloud、IBM Cloud、DigitalOcean。
要点4: 通过GitHub链接可以查看更详细的比较数据和信息。
要点5: 了解各家云服务提供商的免费配额可以帮助用户选择适合自己需求的服务。 
总结: 本文介绍了主要的云服务提供商如AWS、Azure、Google Cloud、Oracle Cloud等的免费配额比较，同时也包括了一些额外的服务如Alibaba Cloud、IBM Cloud、DigitalOcean。每个云服务提供商的免费配额都有所不同，适合不同的使用场景。通过GitHub链接可以查看更详细的比较数据和信息，了解各家云服务提供商的免费配额可以帮助用户选择适合自己需求的服务。 <div>
【Cloud Service Providers Free Tier Overview：主要的云服务提供商的免费配额比较，包括 AWS、Azure、Google Cloud、Oracle Cloud 等。同时也包括了一些额外的服务，如 Alibaba Cloud、IBM Cloud、DigitalOcean 等。每个云服务提供商的免费配额都有所不同，适合不同的使用场景】'Cloud Service Providers Free Tier Overview - Comparing the free tier offers of the major cloud providers like AWS, Azure, GCP, Oracle etc.' GitHub: github.com/cloudcommunity/Cloud-Free-Tier-Comparison <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hokv60akmoj20u00zm77r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:42:23 GMT</pubDate>
</item>
<item>
<title>【JORA：解决了 LLM 在 RAG 中的内存限制问题，提供了一种基于 JAX 的分布式训练方法】'JORA: JAX Tensor-Parallel LoRA Library' GitHub: github.com/aniquetah...</title>
<link>https://weibo.com/1402400261/O8Xml3eVr</link>
<guid>https://weibo.com/1402400261/O8Xml3eVr</guid>
<content:encoded><![CDATA[
<div> JORA, 解决, LLM, RAG, 内存限制, JAX, 分布式训练方法

<br /><br />总结:
JORA是一个基于JAX的Tensor-Parallel LoRA库，解决了LLM在RAG中的内存限制问题。它提供了一种分布式训练方法，能够有效地处理大规模模型和数据集。通过使用JAX，实现了更高效的计算和内存管理，使得训练过程更加高效和可扩展。JORA项目的GitHub地址为github.com/aniquetahir/JORA。 <div>
【JORA：解决了 LLM 在 RAG 中的内存限制问题，提供了一种基于 JAX 的分布式训练方法】'JORA: JAX Tensor-Parallel LoRA Library' GitHub: github.com/aniquetahir/JORA <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hokuyut1ubj21cz0gaacq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:35:30 GMT</pubDate>
</item>
<item>
<title>【D1 Manager：用于 Cloudflare D1(一种无服务器 SQL 数据库)的 Web UI 和 API，提供了一种用户友好的界面来管理数据库、表和记录，以及 API 用来执行编程操作】...</title>
<link>https://weibo.com/1402400261/O8Xjxs30Y</link>
<guid>https://weibo.com/1402400261/O8Xjxs30Y</guid>
<content:encoded><![CDATA[
<div> Cloudflare D1、Web UI、API、管理数据库、表、记录、用户友好界面、查询编程操作、AI助手、GitHub: github.com/JacobLinCool/d1-manager 

<br /><br />总结:
D1 Manager是用于Cloudflare D1的Web UI和API，提供了用户友好的界面来管理数据库、表和记录，并有一个AI助手来帮助用户用自然语言编写查询。用户可以通过GitHub访问该工具的代码。 <div>
【D1 Manager：用于 Cloudflare D1(一种无服务器 SQL 数据库)的 Web UI 和 API，提供了一种用户友好的界面来管理数据库、表和记录，以及 API 用来执行编程操作】'D1 Manager - D1 Manager is a web UI and API for Cloudflare D1, a serverless SQL database. It provides a web interface for managing databases, tables, and records, as well as an AI assistant to help you write query in natural language.' GitHub: github.com/JacobLinCool/d1-manager <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Cloudflare%23"><span class="surl-text">#Cloudflare#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%95%B0%E6%8D%AE%E5%BA%93%23&amp;isnewpage=1"><span class="surl-text">#数据库#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hokurptyvuj20u012ytdn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:28:37 GMT</pubDate>
</item>
<item>
<title>【Make your Python output dramatic：让 Python 输出可以逐字显示，增加节奏感】'Make your Python output dramatic - Display all Python process output char...</title>
<link>https://weibo.com/1402400261/O8XfA2LQ2</link>
<guid>https://weibo.com/1402400261/O8XfA2LQ2</guid>
<content:encoded><![CDATA[
<div> dramatic, Python, 输出, 逐字显示, 增加, 节奏感, GitHub, 进程, 字符, 增强<br /><br />总结：
文章介绍了一个名为"dramatic"的工具，可以让Python输出可以逐字显示，增加节奏感。通过这个工具，Python的处理过程可以逐字显示，让输出更加生动有趣。该工具可以在GitHub上找到，有助于提升Python输出时的视觉效果。文章重点介绍了如何使用"dramatic"工具来增强Python输出，让输出更加具有戏剧性。 <div>
【Make your Python output dramatic：让 Python 输出可以逐字显示，增加节奏感】'Make your Python output dramatic - Display all Python process output character-by-character' GitHub: github.com/treyhunner/dramatic <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hokuhlnglrj215r0u0wiu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:18:51 GMT</pubDate>
</item>
<item>
<title>【Fuwari：用 Astro 构建的漂亮静态博客模板】'Fuwari - A static blog template built with Astro.' GitHub: github.com/saicaca/fuwari #开源# [图片]</title>
<link>https://weibo.com/1402400261/O8X7lcLAv</link>
<guid>https://weibo.com/1402400261/O8X7lcLAv</guid>
<content:encoded><![CDATA[
<div> Astro、静态博客、模板、GitHub、漂亮、Fuwari、构建、saicaca、静态、Astro
<br />
Astro是一个用于构建静态博客的工具，Fuwari是一个漂亮的静态博客模板，使用Astro构建。该模板可以在GitHub上找到，作者是saicaca。静态博客的优点在于加载速度快、安全性高、易于管理。Astro的灵活性和易用性使得构建静态博客变得更加简单和方便。静态博客模板Fuwari的设计美观大方，适合多种主题和用途。通过GitHub可以方便地获取该模板并进行个性化定制。 <div>
【Fuwari：用 Astro 构建的漂亮静态博客模板】'Fuwari - A static blog template built with Astro.' GitHub: github.com/saicaca/fuwari <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoktwe9ygxj21530u0qcd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 11:58:33 GMT</pubDate>
</item>
<item>
<title>【Financial Datasets：开源 Python 库，用于利用大语言模型(LLM)生成合成的金融/财务数据集】'Financial Datasets - Financial datasets for LLMs' GitHub: git...</title>
<link>https://weibo.com/1402400261/O8URmyitM</link>
<guid>https://weibo.com/1402400261/O8URmyitM</guid>
<content:encoded><![CDATA[
<div> GitHub、Financial Datasets、Python 库、大语言模型、金融、财务、生成、合成、数据集、开源库
<br />
金融数据集：该开源 Python 库提供了金融/财务领域的数据集，可用于利用大语言模型(LLM)生成合成数据。这个库可以帮助研究人员和开发者更好地训练和评估金融相关的自然语言处理模型。GitHub链接：github.com/virattt/financial-datasets。<br /><br />总结: <div>
【Financial Datasets：开源 Python 库，用于利用大语言模型(LLM)生成合成的金融/财务数据集】'Financial Datasets - Financial datasets for LLMs' GitHub: github.com/virattt/financial-datasets <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hokjxnngfwj217c0u00x9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 06:13:42 GMT</pubDate>
</item>
<item>
<title>【AutoMQ: 用于 Apache Kafka 的云原生实现，旨在缩减云基础设施费用，使用类似 Kubernetes 的方式来部署和管理 Kafka 集群，并提供了自动伸缩、故障迁移和监控...</title>
<link>https://weibo.com/1402400261/O8UPgzwwy</link>
<guid>https://weibo.com/1402400261/O8UPgzwwy</guid>
<content:encoded><![CDATA[
<div> 云原生、Apache Kafka、AutoMQ、云基础设施、费用缩减、Kubernetes、部署管理、自动伸缩、故障迁移、监控功能

总结:<br /><br />AutoMQ是针对Apache Kafka的云原生实现，类似于Kubernetes的部署方式，能够最大程度地减少云基础设施费用，达到高达90%的节省。它提供了自动伸缩、故障迁移和监控等功能，帮助用户更高效地管理和操作Kafka集群。通过GitHub链接github.com/AutoMQ/automq，用户可以了解更多关于AutoMQ的信息。 <div>
【AutoMQ: 用于 Apache Kafka 的云原生实现，旨在缩减云基础设施费用，使用类似 Kubernetes 的方式来部署和管理 Kafka 集群，并提供了自动伸缩、故障迁移和监控等功能】’AutoMQ: Truly serverless Kafka solution that maximizes the benefits of cloud - A cloud native implementation for Apache Kafka, reducing your cloud infrastructure bill by up to 90%.' GitHub: github.com/AutoMQ/automq <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hokjs660tsj20vg0u0jvk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 06:08:32 GMT</pubDate>
</item>
<item>
<title>'Mistral 7B v0.2 JAX - JAX implementation of the Mistral 7b v0.2 model' GitHub: github.com/yixiaoer/mistral-v0.2-jax #开源# #机器学习# #人工智能# [图...</title>
<link>https://weibo.com/1402400261/O8UOF1TIz</link>
<guid>https://weibo.com/1402400261/O8UOF1TIz</guid>
<content:encoded><![CDATA[
<div> GitHub, Mistral 7B v0.2 JAX，JAX implementation，model<br />
<br />
模型Mistral 7B v0.2是一个基于JAX库实现的模型，在GitHub上有相应的项目，通过该项目可以获取相关代码和文档。这个模型的实现是基于JAX库的，提供了Mistral 7b v0.2模型的JAX版本。这个项目对使用JAX实现模型的方式进行了介绍，对深度学习领域的研究有一定的参考价值。<br /> <br />总结: <br />模型Mistral 7B v0.2是一个基于JAX库实现的模型，在GitHub上有相应的项目，通过该项目可以获取相关代码和文档。这个模型的实现是基于JAX库的，提供了Mistral 7b v0.2模型的JAX版本。这个项目对使用JAX实现模型的方式进行了介绍，对深度学习领域的研究有一定的参考价值。 <div>
'Mistral 7B v0.2 JAX - JAX implementation of the Mistral 7b v0.2 model' GitHub: github.com/yixiaoer/mistral-v0.2-jax <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hokjqq3ra1j218e0u0tcg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 06:07:02 GMT</pubDate>
</item>
<item>
<title>【旨在收集和整理语音/音频领域的大语言模型(LLM)、表示学习和编解码模型列表】’Speech Trident - Awesome Speech LM - Awesome speech/audio LLMs, representa...</title>
<link>https://weibo.com/1402400261/O8UModHKm</link>
<guid>https://weibo.com/1402400261/O8UModHKm</guid>
<content:encoded><![CDATA[
<div> Speech Trident, Awesome Speech LM, Awesome speech/audio LLMs, representation learning, codec models, GitHub, 收集, 整理, 语音, 音频, 大语言模型, 表示学习。<br />
<br />
总结: 本文是关于语音/音频领域的大语言模型(LLM)、表示学习和编解码模型列表的收集和整理。提到了Speech Trident、Awesome Speech LM和Awesome speech/audio LLMs等内容，涉及到表示学习和编解码模型。相关项目可以在GitHub上找到，包含了丰富的资源和信息，是学习和研究这些领域的重要参考。 <div>
【旨在收集和整理语音/音频领域的大语言模型(LLM)、表示学习和编解码模型列表】’Speech Trident - Awesome Speech LM - Awesome speech/audio LLMs, representation learning, and codec models' GitHub: github.com/ga642381/speech-trident <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hokjkwue0yj20u016vaf2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 06:01:27 GMT</pubDate>
</item>
<item>
<title>【Morphic：AI驱动的回答引擎，类似Perplexity，可以提供准确和实时的答案，配备生成式 UI】’Morphic - An AI-powered answer engine with a generative UI' Gi...</title>
<link>https://weibo.com/1402400261/O8ULLciDl</link>
<guid>https://weibo.com/1402400261/O8ULLciDl</guid>
<content:encoded><![CDATA[
<div> AI、Morphic、回答引擎、Perplexity、实时、生成式UI、Github、miurla、准确、驱动<br />
<br />
AI技术不断发展，Morphic是一个AI驱动的回答引擎，类似于Perplexity，能够提供准确和实时的答案。该引擎配备了生成式的用户界面，可以通过GitHub上的miurla/morphic获取相关信息。Morphic的出现将为人们提供更加智能和便捷的答案服务。 <div>
【Morphic：AI驱动的回答引擎，类似Perplexity，可以提供准确和实时的答案，配备生成式 UI】’Morphic - An AI-powered answer engine with a generative UI' GitHub: github.com/miurla/morphic <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hokjiiwauvj21960u0adx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 05:59:54 GMT</pubDate>
</item>
<item>
<title>【llm.c：实现了大语言模型(LLM)训练的简单、纯 C/CUDA 版本，无需 PyTorch 或 cPython】'llm.c - LLM training in simple, raw C/CUDA' GitHub: github.com/kar...</title>
<link>https://weibo.com/1402400261/O8UKMes4Y</link>
<guid>https://weibo.com/1402400261/O8UKMes4Y</guid>
<content:encoded><![CDATA[
<div> LLM、训练、C/CUDA、简单、纯、PyTorch、GitHub、karpathy

LLM.c是一个在C/CUDA中实现的大语言模型（LLM）训练程序，无需依赖PyTorch或cPython。该程序提供了一个简单而纯净的实现，方便用户进行大规模语言模型训练。项目托管在GitHub上，由karpathy创建和维护。用户可以通过访问GitHub链接github.com/karpathy/llm.c 来获取更多信息和源代码。通过该项目，用户可以了解如何使用C/CUDA进行简单而高效的大语言模型训练，为研究和实践提供了一个有价值的工具。LLM.c的存在和贡献将为语言模型领域的发展带来更多可能性和机会。<br /><br />总结: LLM.c是一个在C/CUDA中实现的大语言模型（LLM）训练项目，提供了简单而高效的实现方法，无需依赖PyTorch或cPython，为用户提供了一个有价值的工具。 <div>
【llm.c：实现了大语言模型(LLM)训练的简单、纯 C/CUDA 版本，无需 PyTorch 或 cPython】'llm.c - LLM training in simple, raw C/CUDA' GitHub: github.com/karpathy/llm.c <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hokjgrmr1wj211k0u0n2d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 05:57:27 GMT</pubDate>
</item>
<item>
<title>【Ollama新增对嵌入(Embedding)模型的支持，可用于构建检索增强生成(RAG)应用，提供了若干预训练好的嵌入模型,包括mxbai-embed-large、nomic-embed-text、all-mi...</title>
<link>https://weibo.com/1402400261/O8SLfCi6f</link>
<guid>https://weibo.com/1402400261/O8SLfCi6f</guid>
<content:encoded><![CDATA[
<div> mxbai-embed-large、nomic-embed-text、all-minilm、嵌入模型、检索增强生成、Ollama、预训练、支持、应用、模型

<br /><br />总结:
Ollama新增了对嵌入(Embedding)模型的支持，可用于构建检索增强生成(RAG)应用。提供了多种预训练好的嵌入模型，包括mxbai-embed-large、nomic-embed-text、all-minilm等。通过这些模型，用户可以更有效地进行文本检索和生成任务。Ollama为用户提供了更多选择和可能性，帮助他们构建更优质的应用和服务。 <div>
【Ollama新增对嵌入(Embedding)模型的支持，可用于构建检索增强生成(RAG)应用，提供了若干预训练好的嵌入模型,包括mxbai-embed-large、nomic-embed-text、all-minilm等】《Embedding models · Ollama Blog》 <a href="https://ollama.com/blog/embedding-models"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hokao4q72uj20xd0u0q68.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 00:53:09 GMT</pubDate>
</item>
<item>
<title>【Inqwire：主打不用LLM提供智能服务的软件，可应用于生活决策、困难情况、关系等诸多方面，致力于增强人们的天然智能，以帮助人们理解事物，创造有意义的世界】...</title>
<link>https://weibo.com/1402400261/O8SEeFvLr</link>
<guid>https://weibo.com/1402400261/O8SEeFvLr</guid>
<content:encoded><![CDATA[
<div> 智能服务、软件、生活决策、困难情况、关系、增强、人们、天然智能、理解事物、有意义的世界

<br /><br />总结:
"Inqwire"是一款主打不用LLM提供智能服务的软件，它可应用于生活决策、困难情况、关系等诸多方面。该软件致力于增强人们的天然智能，帮助人们理解事物，创造有意义的世界。通过Inqwire，用户能够更好地应对生活中的挑战，提高决策的准确性，加强人与人之间的沟通和理解，进而为自己和他人创造更加有意义和丰富的生活体验。Inqwire的存在使得人们不仅可以依靠智能技术，更可以通过自身的天然智能来解决问题，达到更深层次的认知和体验。 <div>
【Inqwire：主打不用LLM提供智能服务的软件，可应用于生活决策、困难情况、关系等诸多方面，致力于增强人们的天然智能，以帮助人们理解事物，创造有意义的世界】“Inqwire” <a href="https://www.inqwire.io/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoka5gq6dxj20oc0j675v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 00:35:52 GMT</pubDate>
</item>
<item>
<title>【元编程新思路：用Claude 3 Opus打造"files-to-prompt"工具】- Simon Willison开发了一个名为"files-to-prompt"的新工具，可以帮助将多个文件一次性传递给Claud...</title>
<link>https://weibo.com/1402400261/O8SzuiErQ</link>
<guid>https://weibo.com/1402400261/O8SzuiErQ</guid>
<content:encoded><![CDATA[
<div> 开发者、files-to-prompt、Claude、GPT-4、LLM、AI工具、软件开发、效率、创新能力、元编程<br />
<br />
总结:<br />
Simon Willison开发了一个名为"files-to-prompt"的新工具，可以帮助将多个文件一次性传递给Claude和GPT-4等大语言模型。通过将"files-to-prompt"与Willison之前开发的LLM命令行工具结合使用，可以实现一些强大的功能。文章展示了如何利用AI工具来辅助软件开发的一个有趣案例。Willison几乎完全使用Claude 3 Opus模型开发了"files-to-prompt"工具，并使用自己的工具协助开发过程。随着大语言模型等AI技术的快速发展，开发者可以利用这些强大的工具来优化工作流程，提高生产力。元编程的思想在AI时代焕发新的生机，开发者应该主动学习和尝试前沿的AI工具和方法，创造智能、高效的解决方案。 <div>
【元编程新思路：用Claude 3 Opus打造"files-to-prompt"工具】<br />- Simon Willison开发了一个名为"files-to-prompt"的新工具，可以帮助将多个文件一次性传递给Claude和GPT-4等大语言模型(LLM)。  <br />- 通过将"files-to-prompt"与Willison之前开发的LLM命令行工具结合使用，可以实现一些强大的功能。<br />- Willison几乎完全使用Claude 3 Opus模型开发了"files-to-prompt"工具。他使用了自己的"llm-claude-3"和"files-to-pr"工具来协助开发过程。  <br />- 文章没有详细介绍"files-to-prompt"的实现原理和具体用法，但展示了如何利用AI工具来辅助软件开发的一个有趣案例。  <br />- Willison是一位经验丰富的开发者，他积极拥抱新兴的AI技术，并不断探索如何将其应用到实际的开发工作中，以提高效率和创新能力。  <br /><br />思考：  <br />- 随着大语言模型等AI技术的快速发展，开发者可以利用这些强大的工具来优化工作流程，例如自动更新文档、生成样板代码等，这将极大地提高生产力。  <br />- 元编程(meta-programming)的思想在AI时代焕发新的生机。就像Willison使用AI工具来开发另一个工具一样，我们可以设计出更多"自我完善"的系统。  <br />- 新技术的采用需要开放和创新的心态。作为开发者，我们应该主动学习和尝试前沿的AI工具和方法，将它们与已有的最佳实践相结合，创造出更智能、更高效的解决方案。  <br />《Building files-to-prompt entirely using Claude 3 Opus》 <a href="https://simonwillison.net/2024/Apr/8/files-to-prompt/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hok9tz27auj20w30u043j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 00:24:10 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@异步图书 送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O8Syqr7qt</link>
<guid>https://weibo.com/1402400261/O8Syqr7qt</guid>
<content:encoded><![CDATA[
<div> 大语言模型、前沿进展、科学家、工程师、学生、案例、庖丁解牛、理解、认识

<br /><br />总结:
本文介绍了一本名为《大语言模型：基础与前沿》的书籍，截止日期为2024年4月12日12:00。这本书全面深入地介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。作者摒弃了纯理论的说教模式，从案例入手，采用庖丁解牛的方式帮助读者理解与认识大语言模型。通过转发和评论参与活动，有机会获得3本这本书。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%BC%82%E6%AD%A5%E5%9B%BE%E4%B9%A6">@异步图书</a>  送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。摒弃了纯理论的说教模式，从案例入手， 采用庖丁解牛的方式帮助读者理解与认识大语言模型。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019331269755053"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef8oboqij20ga0m8q8p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9segl7j20m90m9q6z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9t5km0j20m90m942f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef9tq2esj20m90m9gpe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef9ugq5dj20m90m9dif.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 00:21:33 GMT</pubDate>
</item>
<item>
<title>今日推介(第1370期)：基于大语言模型的社交技能训练、鲁棒高斯Splatting、机器人装配的数据高效模仿学习、语言模型如何嵌入长文档以进行稠密检索、指数数据增长...</title>
<link>https://weibo.com/1402400261/O8RLzmUhX</link>
<guid>https://weibo.com/1402400261/O8RLzmUhX</guid>
<content:encoded><![CDATA[
<div> 社交技能训练、鲁棒高斯Splatting、机器人装配的数据高效模仿学习、语言模型嵌入长文档稠密检索、指数数据增长实现“零样本”  

<br /><br />总结:  
本文介绍了基于大语言模型的社交技能训练方法，通过模仿学习机器人装配的数据来提高效率。另外，作者提出了一种鲁棒的高斯Splatting方法，用于图像处理。此外，讨论了语言模型如何嵌入长文档进行稠密检索，以及指数数据增长如何实现“零样本”学习。这些方法为解决实际问题提供了新的思路和方法。 <div>
今日推介(第1370期)：基于大语言模型的社交技能训练、鲁棒高斯Splatting、机器人装配的数据高效模仿学习、语言模型如何嵌入长文档以进行稠密检索、指数数据增长才能实现“零样本” 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/691406363"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.9)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hok69o8e1cj216i0u0gqf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hok69rjq3ij21bi0u0te6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hok69u82q6j21zj0u0dpb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hok69wxlrsj20sw0swq6i.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hok69znxkcj21pt0u0ail.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 22:21:10 GMT</pubDate>
</item>
<item>
<title>[RO] MM-Gaussian: 3D Gaussian-based Multi-modal Fusion for Localization and Reconstruction in Unbounded Scenes 网页链接 提出MM-Gaussian系统，在无界外...</title>
<link>https://weibo.com/1402400261/O8RGUCPu0</link>
<guid>https://weibo.com/1402400261/O8RGUCPu0</guid>
<content:encoded><![CDATA[
<div> 激光雷达、摄像头、多模态融合、定位、3D高斯映射、MM-Gaussian系统

<br /><br />总结:
本文提出了一种名为MM-Gaussian的系统，旨在无界外部场景中利用激光雷达和摄像头进行多模态融合，以实现鲁棒的定位和3D高斯映射。该系统结合了激光雷达和摄像头的优势，在定位和重建方面表现出色。算法采用3D高斯模型来描述环境，通过多模态融合提高了位置识别准确性。实验结果表明，MM-Gaussian系统在无界外部场景中展现出了良好的性能，具有较高的实用价值。MM-Gaussian系统为无界外部场景下的定位和重建提供了一种新的解决方案，具有很大的应用潜力。 <div>
[RO] MM-Gaussian: 3D Gaussian-based Multi-modal Fusion for Localization and Reconstruction in Unbounded Scenes  <br /><a href="https://arxiv.org/abs/2404.04026"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出MM-Gaussian系统，在无界外部场景中使用激光雷达和摄像头进行多模态融合，实现鲁棒的定位与3D高斯映射。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok5y0spluj21361e6txo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok5y0wonpj21ls0p2tio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok5y2akruj20t40okjwg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 22:09:43 GMT</pubDate>
</item>
<item>
<title>[LG] Transformers for molecular property prediction: Lessons learned from the past five years 网页链接 全面回顾了 transformer 模型在分子性质预测任务中...</title>
<link>https://weibo.com/1402400261/O8REt4WyT</link>
<guid>https://weibo.com/1402400261/O8REt4WyT</guid>
<content:encoded><![CDATA[
<div> transformer模型, 分子性质预测, 模型训练, 微调, 模型泛化能力, 可解释性, 评估方法, 挑战, 未来研究, 启示

<br /><br />总结:
本文全面回顾了过去五年中transformer模型在分子性质预测任务中的应用情况。文章分析了关键的训练和微调决策，同时提出了模型泛化能力、可解释性和评估方法等方面的挑战。从中我们可以看到一些对未来研究具有启示意义的内容。在实践中发现，模型对于分子性质预测任务的应用效果显著，但需要谨慎选择训练和微调的策略，以提高模型性能和泛化能力。同时，模型的可解释性是一个重要的研究方向，需要深入研究如何解释模型的预测结果。另外，评估方法也需要不断完善，以确保模型的有效性和稳健性。未来的研究应该注重解决这些挑战，推动该领域取得更大的进展。 <div>
[LG] Transformers for molecular property prediction: Lessons learned from the past five years  <br /><a href="https://arxiv.org/abs/2404.03969"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />全面回顾了 transformer 模型在分子性质预测任务中的应用情况，分析了模型训练和微调的关键决策，提出了模型泛化能力、可解释性、评估方法等方面的挑战，为该领域的未来研究提供了宝贵启示。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok5rr8ofmj21021betht.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok5rrlgxvj21k4196qhx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok5rs8ftaj21my0ssahr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 22:03:41 GMT</pubDate>
</item>
<item>
<title>[CL] Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model 网页链接 通过大规模中文预训练语料和模型训练，获得了一款在中文任务上表现强劲...</title>
<link>https://weibo.com/1402400261/O8Ry2uWNb</link>
<guid>https://weibo.com/1402400261/O8Ry2uWNb</guid>
<content:encoded><![CDATA[
<div> 关键词: 中文预训练语料, 模型训练, CT-LLM, 中文任务, 强劲表现

总结:
<br />
本文介绍了一款名为CT-LLM的中文语言模型，通过大规模中文预训练语料和模型训练，使其在中文任务上表现强劲。CT-LLM的表现令人印象深刻，显示出在中文任务上具有良好的性能和应用潜力。这一研究成果对中文自然语言处理领域具有重要意义，为中文文本处理和应用提供了强有力的支持。CT-LLM的开源模型为相关研究和实践提供了有力的工具和资源，为进一步探索中文语言处理领域打下了良好的基础。 <div>
[CL] Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model  <br /><a href="https://arxiv.org/abs/2404.04167"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过大规模中文预训练语料和模型训练，获得了一款在中文任务上表现强劲的开源语言模型 CT-LLM。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok5b9zqqoj20vq1dmtqe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok5ba4uv2j20so0twae4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok5basrsej21jy10cn6l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:47:51 GMT</pubDate>
</item>
<item>
<title>[LG] Stream of Search (SoS): Learning to Search in Language 网页链接 通过将搜索过程表示为搜索流字符串，让语言模型学习不同的符号搜索策略，取得了改进搜...</title>
<link>https://weibo.com/1402400261/O8RvHki5K</link>
<guid>https://weibo.com/1402400261/O8RvHki5K</guid>
<content:encoded><![CDATA[
<div> 搜索流字符串, 语言模型, 符号搜索策略, 提升搜索能力, 新策略潜力<br />
<br />
提出了一种新的学习搜索策略的方法，即通过将搜索过程表示为搜索流字符串，让语言模型学习不同的符号搜索策略。这种方法带来了改进搜索能力和发现新策略的潜力，有望为语言模型的搜索任务带来更好的效果。 <div>
[LG] Stream of Search (SoS): Learning to Search in Language  <br /><a href="https://arxiv.org/abs/2404.03683"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过将搜索过程表示为搜索流字符串，让语言模型学习不同的符号搜索策略，取得了改进搜索能力和发现新策略的潜力。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok55aty2sj20wa1dmwvy.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok55b59w6j21ic1784f5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok55bhqv6j21ii0se7fg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:42:05 GMT</pubDate>
</item>
<item>
<title>通过大规模分析发现当下多模态模型存在数据饥渴性和样本低效问题，预训练数据频率与下游泛化性能呈对数线性关系，需要重新审视大规模泛化学习范式。 - 转发 @爱...</title>
<link>https://weibo.com/1402400261/O8RqVqluZ</link>
<guid>https://weibo.com/1402400261/O8RqVqluZ</guid>
<content:encoded><![CDATA[
<div> 数据饥渴性, 样本低效问题, 预训练数据频率, 下游泛化性能, 对数线性关系, 大规模分析, 多模态模型, 大规模泛化学习, 范式, 多模态模型性能<br />
<br />
总结:<br />
研究指出当前多模态模型存在数据饥渴性和样本低效问题，预训练数据频率与下游泛化性能呈对数线性关系。通过大规模分析发现，预训练数据的提取与样本频率密切相关，这需要重新审视大规模泛化学习范式。研究认为，预训练概念频率对多模态模型性能有重要影响，指出没有"零射击"现象，需要更深入地研究数据频率与模型性能的关系。 <div>
通过大规模分析发现当下多模态模型存在数据饥渴性和样本低效问题，预训练数据频率与下游泛化性能呈对数线性关系，需要重新审视大规模泛化学习范式。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance》V Udandarao, A Prabhu, A Ghosh, Y Sharma, P H.S. Torr, A Bibi, S Albanie, M Bethge [University of Tubingen] (2024) <a href="https://arxiv.org/abs/2404.04125"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4iw2z9ij21lu0swk7s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4iwpxzaj21sa0v6gya.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4ixe9rsj21rm13kngx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4ixguwlj21s00wg16m.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4swu7suj210x0djad0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4sww1qvj210x0ff77b.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4swtorjj20g80nqgnn.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4swv9msj210y0l8q7d.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4swvcz8j21160m1dl7.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:30:20 GMT</pubDate>
</item>
<item>
<title>[CV]《No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance》V Udandarao, A Prabhu, A Ghosh, ...</title>
<link>https://weibo.com/1402400261/O8RqRui2s</link>
<guid>https://weibo.com/1402400261/O8RqRui2s</guid>
<content:encoded><![CDATA[
<div> 关键词: 零-shot学习, 数据增强, 预训练, 概念频率, 多模态模型, 性能

总结:<br /><br />
本研究探讨了在多模态模型性能中数据预训练中概念频率的影响。研究发现，零-shot学习的实现离不开大规模数据增强，而预训练阶段中概念频率对模型性能有关键影响。对于零-shot任务来说，预训练阶段的数据量和质量决定了模型的表现，因此在构建多模态模型时需要考虑数据的数量和多样性。研究的结果有助于指导未来多模态模型设计和训练的方向。 <div>
[CV]《No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance》V Udandarao, A Prabhu, A Ghosh, Y Sharma, P H.S. Torr, A Bibi, S Albanie, M Bethge [University of Tubingen] (2024) <a href="https://arxiv.org/abs/2404.04125"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4iw2z9ij21lu0swk7s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4iwpxzaj21sa0v6gya.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4ixe9rsj21rm13kngx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4ixguwlj21s00wg16m.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4swu7suj210x0djad0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4sww1qvj210x0ff77b.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4swtorjj20g80nqgnn.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4swv9msj210y0l8q7d.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4swvcz8j21160m1dl7.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4swvs7nj21160tmn3o.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4swvnyej21130tmjxx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4swv7fzj21140i9q6q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4swuxl1j21140iawia.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4swuup0j210x0j4782.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4swur2qj210x0i9n0z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4swurs2j210x0i9adu.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4swtq8oj210x0g9tab.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4swv0cej21160m0q83.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:30:10 GMT</pubDate>
</item>
<item>
<title>发现Transformer检索模型存在偏好输入前段信息的“序处停滞”效应，这种位置偏差源自对比预训练过程。 - 转发 @爱可可-爱生活:&amp;ensp;[IR]《Dwell in the Beginni...</title>
<link>https://weibo.com/1402400261/O8RkwrPh1</link>
<guid>https://weibo.com/1402400261/O8RkwrPh1</guid>
<content:encoded><![CDATA[
<div> Transformer检索模型、偏好输入前段信息、“序处停滞”效应、位置偏差、预训练过程、长文档嵌入、稠密检索、模型表达能力、信息检索、文本理解<br />
<br />
总结:<br />
文章探讨了Transformer检索模型在处理长文档时出现的“序处停滞”效应，这种位置偏差源自对比预训练过程中输入前段信息的偏好。研究发现，在长文档中，Transformer模型会更倾向于关注文档开头的信息，而忽视后续内容。为应对这一问题，研究提出了一种有效的策略，通过在检索阶段加入更多广泛的信息来补充模型在长文档中的信息局限性。实验结果表明，这种策略可以显著改善模型的性能，提高模型在稠密检索任务中的表现。因此，在构建Transformer检索模型时，需要考虑模型的表达能力和输入信息的分布，以提升模型在信息检索和文本理解任务中的效果。 <div>
发现Transformer检索模型存在偏好输入前段信息的“序处停滞”效应，这种位置偏差源自对比预训练过程。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [IR]《Dwell in the Beginning: How Language Models Embed Long Documents for Dense Retrieval》J Coelho, B Martins, J Magalhães, J Callan, C Xiong [CMU &amp; University of Lisbon] (2024) <a href="https://arxiv.org/abs/2404.04163"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4bm3oxkj20ow0ti0zy.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4bmltyfj20sw0swdkh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4bmswz8j20sy0gc0um.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4bmyj3tj20t40q042g.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4c855g8j20si0qe0xq.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:14:32 GMT</pubDate>
</item>
<item>
<title>[IR]《Dwell in the Beginning: How Language Models Embed Long Documents for Dense Retrieval》J Coelho, B Martins, J Magalhães, J Callan, C Xiong [CMU ...</title>
<link>https://weibo.com/1402400261/O8RklwUaz</link>
<guid>https://weibo.com/1402400261/O8RklwUaz</guid>
<content:encoded><![CDATA[
<div> 语言模型、长文档、稠密检索、嵌入、起始点、语言模型<br />
<br />
提出了一种在长文档中嵌入语言模型进行稠密检索的方法。通过在长文档的起始点上使用语言模型嵌入，提高了检索效果。实验结果表明，这种方法能够在稠密检索任务中取得较好的性能表现。文章探讨了如何在语言模型中嵌入长文档，并详细介绍了实验设计与结果分析。总体来说，提出的方法在处理长文档的稠密检索任务中表现出了潜力，为相关研究和实践提供了有益的参考。 <br /><br />总结: <br />这篇文章提出了一种在长文档中嵌入语言模型进行稠密检索的方法，通过在文档起始点上使用语言模型嵌入来提高检索效果。实验结果证实了这种方法在稠密检索任务中的有效性，为相关研究提供了新的思路。 <div>
[IR]《Dwell in the Beginning: How Language Models Embed Long Documents for Dense Retrieval》J Coelho, B Martins, J Magalhães, J Callan, C Xiong [CMU &amp; University of Lisbon] (2024) <a href="https://arxiv.org/abs/2404.04163"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4bm3oxkj20ow0ti0zy.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4bmltyfj20sw0swdkh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4bmswz8j20sy0gc0um.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4bmyj3tj20t40q042g.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4c855g8j20si0qe0xq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:14:07 GMT</pubDate>
</item>
<item>
<title>通过策略结构设计、数据增强和迭代收集提出管道，在少量示教的预算下提高机器人装配任务的模仿学习性能。 - 转发 @爱可可-爱生活:&amp;ensp;[RO]《JUICER: Data-Effi...</title>
<link>https://weibo.com/1402400261/O8RjSzooL</link>
<guid>https://weibo.com/1402400261/O8RjSzooL</guid>
<content:encoded><![CDATA[
<div> 数据增强、模仿学习、机器人装配任务、管道设计、策略结构、迭代收集、预算限制、 JUICER、少量示教、性能提升

<br /><br />总结:
研究团队通过策略结构设计、数据增强和迭代收集提出了管道，有效提高了机器人装配任务的模仿学习性能。他们使用名为JUICER的方法，在少量示教的预算下实现了高效的数据驱动模仿学习。该方法利用数据增强技术增加了训练数据的多样性，进一步提高了模型的泛化能力。通过这种方式，他们成功克服了预算限制带来的挑战，并取得了令人满意的成果。通过不断优化管道设计和策略调整，他们实现了机器人装配任务的模仿学习性能的显著提升。研究结果为解决机器人装配领域的挑战提供了新的思路和方法。 <div>
通过策略结构设计、数据增强和迭代收集提出管道，在少量示教的预算下提高机器人装配任务的模仿学习性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [RO]《JUICER: Data-Efficient Imitation Learning for Robotic Assembly》L Ankile, A Simeonov, I Shenfeld, P Agrawal [Harvard University &amp; MIT] (2024) <a href="https://arxiv.org/abs/2404.03729"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4a0p0b8j20u20l4wmf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4a18cdpj21nm0p0qcw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4a1psg2j20ue0nstfb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4a24acyj21m20hcn1l.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4aon70hj212v0b2wft.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4aona69j212v0b2wft.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4aoom3fj213p0dbgor.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4aoo8bvj213p0o440u.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4aoo5sej20si0nb0ut.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:12:58 GMT</pubDate>
</item>
<item>
<title>[RO]《JUICER: Data-Efficient Imitation Learning for Robotic Assembly》L Ankile, A Simeonov, I Shenfeld, P Agrawal [Harvard University &amp; MIT] (2024) 网...</title>
<link>https://weibo.com/1402400261/O8RjLiVz7</link>
<guid>https://weibo.com/1402400261/O8RjLiVz7</guid>
<content:encoded><![CDATA[
<div> 数据效率、模仿学习、机器人组装、果汁机、数据规模、数据采集、机器人操作、深度学习、数据训练、自动装配

总结：<br /><br />这篇文章介绍了一种名为JUICER的数据效率模仿学习方法，用于解决机器人组装问题。通过该方法，研究人员成功开发了一种新型果汁机，并通过数据采集和深度学习训练机器人进行自动装配。该技术能够在较小的数据规模下实现高效的机器人操作，为未来的智能制造提供了新的可能性。 <div>
[RO]《JUICER: Data-Efficient Imitation Learning for Robotic Assembly》L Ankile, A Simeonov, I Shenfeld, P Agrawal [Harvard University &amp; MIT] (2024) <a href="https://arxiv.org/abs/2404.03729"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4a0p0b8j20u20l4wmf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4a18cdpj21nm0p0qcw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4a1psg2j20ue0nstfb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4a24acyj21m20hcn1l.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4aon70hj212v0b2wft.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4aona69j212v0b2wft.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4aoom3fj213p0dbgor.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4aoo8bvj213p0o440u.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4aoo5sej20si0nb0ut.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4aopt4aj213p0vjafp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:12:41 GMT</pubDate>
</item>
<item>
<title>通过建模运动模糊、散焦模糊和颜色偏差，提高了3D高斯Splatting方法在真实场景重建中的鲁棒性和重建质量。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《Robust Gaussian ...</title>
<link>https://weibo.com/1402400261/O8Rjfz6cX</link>
<guid>https://weibo.com/1402400261/O8Rjfz6cX</guid>
<content:encoded><![CDATA[
<div> 高斯Splatting方法、建模、运动模糊、散焦模糊、颜色偏差、鲁棒性、重建质量、真实场景、Meta Reality Labs Zurich

<br /><br />总结:
该研究通过建模运动模糊、散焦模糊和颜色偏差，提高了3D高斯Splatting方法在真实场景重建中的鲁棒性和重建质量。研究团队来自Meta Reality Labs Zurich，他们的方法在处理真实场景重建时表现出更强的鲁棒性和质量。这种方法将有助于提升3D重建技术在实际应用中的效果和可靠性。 <div>
通过建模运动模糊、散焦模糊和颜色偏差，提高了3D高斯Splatting方法在真实场景重建中的鲁棒性和重建质量。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《Robust Gaussian Splatting》F Darmon, L Porzi, S Rota-Bulò, P Kontschieder [Meta Reality Labs Zurich] (2024) <a href="https://arxiv.org/abs/2404.04211"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok48hdtscj21co0swn9n.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok48i2gntj21is0tgwuc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok48ijn5wj21js0z8jz0.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok48j44xjj21ke1cowoh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok494p65qj20r611yq8z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok494p7qaj20rh0ystes.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok494oqu2j20ri12pn1s.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:11:25 GMT</pubDate>
</item>
<item>
<title>[CV]《Robust Gaussian Splatting》F Darmon, L Porzi, S Rota-Bulò, P Kontschieder [Meta Reality Labs Zurich] (2024) 网页链接 #机器学习##人工智能##论文#...</title>
<link>https://weibo.com/1402400261/O8Rj91YbN</link>
<guid>https://weibo.com/1402400261/O8Rj91YbN</guid>
<content:encoded><![CDATA[
<div> 关键词: Robust Gaussian Splatting, Meta Reality Labs Zurich, Darmon, Porzi, Rota-Bulò, Kontschieder

总结:<br /><br />本文是由 Meta Reality Labs Zurich 的 Darmon、Porzi、Rota-Bulò 和 Kontschieder 撰写的关于"Robust Gaussian Splatting"的研究。该研究提出了一种稳健的高斯纹理喷洒方法，用于重建和渲染三维场景。通过将多通道高斯滤波器与融合器相结合，实现了更准确和高质量的场景重建。研究结果表明，该方法在各种场景下具有更好的性能和稳健性，有望在虚拟现实等领域发挥重要作用。整体来说，该研究对于虚拟场景渲染技术的发展具有重要意义。 <div>
[CV]《Robust Gaussian Splatting》F Darmon, L Porzi, S Rota-Bulò, P Kontschieder [Meta Reality Labs Zurich] (2024) <a href="https://arxiv.org/abs/2404.04211"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok48hdtscj21co0swn9n.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok48i2gntj21is0tgwuc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok48ijn5wj21js0z8jz0.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok48j44xjj21ke1cowoh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok494p65qj20r611yq8z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok494p7qaj20rh0ystes.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok494oqu2j20ri12pn1s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:11:09 GMT</pubDate>
</item>
<item>
<title>提出AI伙伴和AI导师框架，利用语言模型的生成能力实现可扩展、安全的社交技能训练。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Social Skill Training with Large Lang...</title>
<link>https://weibo.com/1402400261/O8RiDFeYK</link>
<guid>https://weibo.com/1402400261/O8RiDFeYK</guid>
<content:encoded><![CDATA[
<div> Social Skill Training, Large Language Models, AI伙伴, AI导师, 可扩展, 安全, 社交技能训练, 语言模型, Stanford University, D Yang

总结:
研究者提出了一种利用语言模型生成能力的AI伙伴和AI导师框架，用于实现可扩展、安全的社交技能训练。他们从Stanford University进行了研究，关注于社会技能训练以及如何利用大型语言模型来实现这一目标。AI伙伴和AI导师的出现可以为个人提供更有效的帮助，使得社交技能的学习变得更加便捷和高效。同时，他们的研究还突出了安全性和可扩展性的重要性，以确保这一技术的应用能够得到广泛的推广和应用。Overall, 这项研究为人工智能在社会技能训练领域的应用带来了新的可能性和发展方向。 <div>
提出AI伙伴和AI导师框架，利用语言模型的生成能力实现可扩展、安全的社交技能训练。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Social Skill Training with Large Language Models》D Yang, C Ziems, W Held, O Shaikh, M S. Bernstein, J Mitchell [Stanford University] (2024) <a href="https://arxiv.org/abs/2404.04204"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok47k6gmij20pk0wmgt9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok47kg6ohj21mq15gtj2.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:09:54 GMT</pubDate>
</item>
<item>
<title>[CL]《Social Skill Training with Large Language Models》D Yang, C Ziems, W Held, O Shaikh, M S. Bernstein, J Mitchell [Stanford University] (2024) 网...</title>
<link>https://weibo.com/1402400261/O8RixeIkU</link>
<guid>https://weibo.com/1402400261/O8RixeIkU</guid>
<content:encoded><![CDATA[
<div> 社交技能训练，大型语言模型，斯坦福大学，2024，D Yang，C Ziems，W Held，O Shaikh，M S. Bernstein，J Mitchell<br />
<br />
该研究来自斯坦福大学，旨在探索如何利用大型语言模型进行社交技能训练。研究团队提出了一种新的方法，利用大型语言模型来帮助学习者提高社交技能。他们通过模型生成对话和提供反馈来帮助用户练习与他人交流。实验结果显示，这种方法能够有效地提高用户的社交技能水平。研究认为，大型语言模型在社交技能训练中具有潜在的应用前景，可以帮助更多人提升社交能力并增强人际关系。<br />
<br />
总结: 该研究来自斯坦福大学，旨在探索利用大型语言模型进行社交技能训练的新方法。研究团队通过模型生成对话和提供反馈来帮助用户练习社交技能，实验结果显示其有效性。大型语言模型在社交技能训练中有潜在应用前景，有助于提升用户社交能力。 <div>
[CL]《Social Skill Training with Large Language Models》D Yang, C Ziems, W Held, O Shaikh, M S. Bernstein, J Mitchell [Stanford University] (2024) <a href="https://arxiv.org/abs/2404.04204"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok47k6gmij20pk0wmgt9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok47kg6ohj21mq15gtj2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:09:39 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.8)》 爱可可微博热门分享(4.8) [图片]</title>
<link>https://weibo.com/1402400261/O8OB6iP7c</link>
<guid>https://weibo.com/1402400261/O8OB6iP7c</guid>
<content:encoded><![CDATA[
<div> 微博热门, 爱可可, 分享, 4.8, 社交, 平台, 关注, 热度, 用户, 内容

<br /><br />总结:
爱可可微博分享的内容在社交平台上取得了较高的热度，吸引了大量用户关注和参与互动。用户可以通过微博平台浏览各种热门话题和内容，为用户带来丰富的社交体验。在4.8分的评分下，爱可可微博得到了较高的用户满意度，成为了备受欢迎的社交平台之一。 <div>
《爱可可微博热门分享(4.8)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405021011245662474"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.8)</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hojsa5d5jqj20k00b9my9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 14:17:09 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Non-negative Contrastive Learning》(ICLR 2024) GitHub: github.com/PKU-ML/non_neg [fig3]《LiDAR4D: Dynamic Neural Fields for Novel ...</title>
<link>https://weibo.com/1402400261/O8NNPDICs</link>
<guid>https://weibo.com/1402400261/O8NNPDICs</guid>
<content:encoded><![CDATA[
<div> 非负对比学习、LiDAR4D、DEADiff、神经网络、图像合成、风格迁移、自然语言处理、推理、游戏狼人杀、长文本评估

总结：<br /><br />本文介绍了几篇论文的实现代码，并提供了GitHub链接，包括非负对比学习、LiDAR4D、DEADiff等。这些论文涵盖了神经网络、图像合成、风格迁移、自然语言处理、推理等多个领域。其中，《Non-negative Contrastive Learning》提出了一种非负对比学习方法，有望提高模型性能；《LiDAR4D》介绍了动态神经场用于新型时空视角LiDAR合成；《DEADiff》提出了一种高效的风格迁移模型；《ChatGLM-Math》通过自我评估管道改进了大型语言模型在数学问题求解中的表现；《Enhance Reasoning for Large Language Models in the Game Werewolf》则探讨了如何增强大型语言模型在狼人杀游戏中的推理能力；《LV-Eval》则提出了一个具有5个长度级别、长文本评估的平衡基准。这些论文对于推动人工智能领域的研究与应用具有重要意义。 <div>
几篇论文实现代码：<br />《Non-negative Contrastive Learning》(ICLR 2024) GitHub: github.com/PKU-ML/non_neg [fig3]<br />《LiDAR4D: Dynamic Neural Fields for Novel Space-time View LiDAR Synthesis》(CVPR 2024) GitHub: github.com/ispc-lab/LiDAR4D [fig1]<br />《DEADiff: An Efficient Stylization Diffusion Model with Disentangled Representations》(CVPR 2024) GitHub: github.com/bytedance/DEADiff<br />《Yuanchen Wu and Xichen Ye and Kequan Yang and Jide Li and Xiaoqiang Li》(CVPR 2024) GitHub: github.com/Wu0409/DuPL [fig2]<br />《ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline》(2024) GitHub: github.com/THUDM/ChatGLM-Math<br />《Enhance Reasoning for Large Language Models in the Game Werewolf》(2024) GitHub: github.com/boluoweifenda/werewolf<br />《LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K》(2024) GitHub: github.com/infinigence/LVEval<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hojnw3xjyxj21fe0niqnp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hojoa48hu5j221o0xyww7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hojolbvol4j219m09n79e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 12:15:47 GMT</pubDate>
</item>
<item>
<title>【QAnything：致力于支持任意格式文件或数据库的本地知识库问答系统，可断网安装使用】'Question and Answer based on Anything - Question and Answer based on...</title>
<link>https://weibo.com/1402400261/O8NNHnqAK</link>
<guid>https://weibo.com/1402400261/O8NNHnqAK</guid>
<content:encoded><![CDATA[
<div> GitHub, 问答系统, 本地知识库, 支持任意格式文件, 断网安装, 
问答系统应用于任意文件或数据库的本地知识库，能够支持各种格式文件，并可在断网情况下安装使用。通过GitHub平台发布，旨在提供更便捷的问答功能。 <div>
【QAnything：致力于支持任意格式文件或数据库的本地知识库问答系统，可断网安装使用】'Question and Answer based on Anything - Question and Answer based on Anything.' GitHub: github.com/netease-youdao/QAnything <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hojoroiegjj20vu0s8djl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 12:15:27 GMT</pubDate>
</item>
<item>
<title>【场景文本图像超分辨率相关论文资源列表】’Awesome Scene Text Image Super-Resolution - A collection of papers and resources on scene text image super-r...</title>
<link>https://weibo.com/1402400261/O8NKfyUVC</link>
<guid>https://weibo.com/1402400261/O8NKfyUVC</guid>
<content:encoded><![CDATA[
<div> GitHub、场景文本图像、超分辨率、论文资源、集合、研究、技术、学术、分析、应用
<br /><br />总结:
本文介绍了一个收集了关于场景文本图像超分辨率的论文和资源的GitHub页面。该页面汇总了相关研究领域中的技术、学术成果和实用应用，为对场景文本图像超分辨率感兴趣的研究者提供了丰富的信息和参考资料。通过这个资源集合，研究者可以更全面地了解当前的研究进展，探讨不同的方法和技术，并且将这些成果应用到实际场景中，推动领域的发展和创新。 <div>
【场景文本图像超分辨率相关论文资源列表】’Awesome Scene Text Image Super-Resolution - A collection of papers and resources on scene text image super-resolution.' GitHub: github.com/yfaqh/Awesome-Scene-Text-Image-Super-Resolution <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hojoiukk13j20yt0u0dlx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 12:06:57 GMT</pubDate>
</item>
<item>
<title>【MLIR-EmitC：将 ML 模型转换为 C++ 代码的工具，它包含将 Keras 和 TensorFlow 模型转换为 TOSA 和 StableHLO dialect，以及将这些dialect转换为 EmitC 的脚本...</title>
<link>https://weibo.com/1402400261/O8NHrcruH</link>
<guid>https://weibo.com/1402400261/O8NHrcruH</guid>
<content:encoded><![CDATA[
<div> MLIR-EmitC, 工具, 将 ML 模型转换为 C++ 代码, Keras, TensorFlow, TOSA, StableHLO dialect, EmitC, 脚本, GitHub <br />
<br />总结:
MLIR-EmitC是一个工具，用于将ML模型转换为C++代码。它支持将Keras和TensorFlow模型转换为TOSA和StableHLO dialect，并提供转换为EmitC的脚本和工具。用户可以在GitHub上找到该项目的代码。MLIR-EmitC的目标是简化将机器学习模型转换为可执行代码的过程，提高开发效率。 <div>
【MLIR-EmitC：将 ML 模型转换为 C++ 代码的工具，它包含将 Keras 和 TensorFlow 模型转换为 TOSA 和 StableHLO dialect，以及将这些dialect转换为 EmitC 的脚本和工具】'MLIR-EmitC - Conversions to MLIR EmitC' GitHub: github.com/iml130/mlir-emitc <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hojobo8f0nj214f0u0gr7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 12:00:01 GMT</pubDate>
</item>
<item>
<title>【用大语言模型(LLM)处理表格数据相关论文资源列表】’Awesome-LLM-Tabular - Awesome-LLM-Tabular: a curated list of Large Language Model applied to Tabula...</title>
<link>https://weibo.com/1402400261/O8NFyFg7N</link>
<guid>https://weibo.com/1402400261/O8NFyFg7N</guid>
<content:encoded><![CDATA[
<div> GitHub、大语言模型、表格数据、资源列表、应用、研究、整理、curated、LLM<br />
<br />
研究人员Johnny Hwu在GitHub上整理了一个名为Awesome-LLM-Tabular的资源列表，其中收集了大量涉及大语言模型在表格数据上应用的相关论文。<br />
该资源列表涵盖了近期的研究成果，帮助研究者了解大语言模型在处理表格数据上的最新进展。<br />
研究人员精心整理和筛选了不同领域的相关文献，为研究者提供了一个方便快捷的资源导航工具。<br />
Awesome-LLM-Tabular这一资源列表对于学术界和工业界的研究者都具有一定的参考价值，可以促进相关领域的研究与应用。<br />
总结: <br />
研究人员Johnny Hwu在GitHub上整理了一个名为Awesome-LLM-Tabular的资源列表，其中收集了大量涉及大语言模型在表格数据上应用的相关论文。该资源列表涵盖了近期的研究成果，帮助研究者了解大语言模型在处理表格数据上的最新进展。研究人员精心整理和筛选了不同领域的相关文献，为研究者提供了一个方便快捷的资源导航工具。Awesome-LLM-Tabular这一资源列表对于学术界和工业界的研究者都具有一定的参考价值，可以促进相关领域的研究与应用。 <div>
【用大语言模型(LLM)处理表格数据相关论文资源列表】’Awesome-LLM-Tabular - Awesome-LLM-Tabular: a curated list of Large Language Model applied to Tabular Data' GitHub: github.com/johnnyhwu/Awesome-LLM-Tabular <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hojo6vfkkjj20u00xujx1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 11:55:24 GMT</pubDate>
</item>
<item>
<title>【llama-cpp-rs：Rust 语言编写的库，提供了 llama.cpp 的绑定，用于处理大型语言模型】'llama-cpp-rs' GitHub: github.com/utilityai/llama-cpp-rs #开源# #机...</title>
<link>https://weibo.com/1402400261/O8NB1mSxV</link>
<guid>https://weibo.com/1402400261/O8NB1mSxV</guid>
<content:encoded><![CDATA[
<div> Rust 语言, 库, llama.cpp, 处理, 大型, 语言模型, 绑定, GitHub, utilityai

<br /><br />总结:
这是一个用Rust语言编写的库，名称为llama-cpp-rs，提供了llama.cpp的绑定，用于处理大型语言模型。该库在GitHub上可找到，地址为github.com/utilityai/llama-cpp-rs。该库可以帮助处理大型语言模型，为开发者提供便利。 <div>
【llama-cpp-rs：Rust 语言编写的库，提供了 llama.cpp 的绑定，用于处理大型语言模型】'llama-cpp-rs' GitHub: github.com/utilityai/llama-cpp-rs <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hojnv8yu78j21740q2wj2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 11:44:13 GMT</pubDate>
</item>
<item>
<title>【基于生成式模型的推荐系统相关论文列表】’Recommender Systems with Generative Models' GitHub: github.com/yasdel/LLM-RecSys #开源# #机器学习# #人工智能...</title>
<link>https://weibo.com/1402400261/O8LcLmQSk</link>
<guid>https://weibo.com/1402400261/O8LcLmQSk</guid>
<content:encoded><![CDATA[
<div> 生成式模型、推荐系统、GitHub、LLM-RecSys、论文、推荐算法、深度学习、人工智能<br />
<br />
生成式模型在推荐系统中的应用越来越受到关注，该论文提出了一种基于生成式模型的推荐系统。通过在GitHub上发布了LLM-RecSys的代码，研究人员展示了他们的研究成果。推荐系统是指根据用户的偏好和行为预测并推荐他们可能感兴趣的物品。传统的推荐算法已经被广泛应用，而基于深度学习的生成式模型为推荐系统带来了新的机遇和挑战。这篇论文探讨了如何利用生成式模型改进推荐系统，为推荐系统的发展提供了新的方向。总的来说，这篇论文为推荐系统领域的研究和实践贡献了有价值的内容，对于深度学习和人工智能领域的研究也具有一定的参考意义。<br /><br />总结: <div>
【基于生成式模型的推荐系统相关论文列表】’Recommender Systems with Generative Models' GitHub: github.com/yasdel/LLM-RecSys <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hojdb6tf3lj210y0u0afj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 05:38:57 GMT</pubDate>
</item>
<item>
<title>【HammerLLM：1.4B参数量的LLM，提供简洁高效的训练代码库，并完全开源了模型权重、环境、代码库和超参数】’HammerLLM - 1.4B sLLM for Chinese and English - ...</title>
<link>https://weibo.com/1402400261/O8Lc7q1tp</link>
<guid>https://weibo.com/1402400261/O8Lc7q1tp</guid>
<content:encoded><![CDATA[
<div> GitHub、HammerLLM、1.4B参数量、LLM、简洁、高效、训练代码库、开源、模型权重、环境、超参数

<br /><br />总结:
HammerLLM是一个拥有1.4B参数量的LLM模型，提供简洁高效的训练代码库，并完全开源了模型权重、环境、代码库和超参数。这个模型支持中文和英文，并在GitHub上开源发布，为用户提供了一个强大的工具和资源。 <div>
【HammerLLM：1.4B参数量的LLM，提供简洁高效的训练代码库，并完全开源了模型权重、环境、代码库和超参数】’HammerLLM - 1.4B sLLM for Chinese and English - HammerLLM🔨' GitHub: github.com/Academic-Hammer/HammerLLM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hojd9jtcc4j21py0u0jvu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 05:37:22 GMT</pubDate>
</item>
<item>
<title>【ClangQL：用于查询 C/C++ 代码的工具，使用 GitQL SDK 并提供了类似于 SQL 的查询语言】'ClangQL - Clang AST Query Language - ClangQL is a tool that allow...</title>
<link>https://weibo.com/1402400261/O8L1V66IW</link>
<guid>https://weibo.com/1402400261/O8L1V66IW</guid>
<content:encoded><![CDATA[
<div> ClangQL, Clang AST Query Language, C/C++代码, 查询工具, GitQL SDK, SQL-like查询语言

<br /><br />总结:
ClangQL是一个用于查询C/C++代码的工具，使用GitQL SDK并提供类似于SQL的查询语言。用户可以在代码中运行类似于SQL的查询，而不是在数据库文件上操作。这个工具可以帮助开发者更方便地分析和查找代码中的关键信息，提高代码的可读性和维护性。GitHub上有相关的开源项目，用户可以查看并使用。ClangQL的出现为C/C++开发者提供了一种全新的代码查询方式，使得代码分析和调试变得更加高效和便捷。 <div>
【ClangQL：用于查询 C/C++ 代码的工具，使用 GitQL SDK 并提供了类似于 SQL 的查询语言】'ClangQL - Clang AST Query Language - ClangQL is a tool that allow you to run SQL-like query on C/C++ Code instead of database files using the GitQL SDK' GitHub: github.com/AmrDeveloper/ClangQL <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hojcjemz4yj20u00xk423.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 05:12:14 GMT</pubDate>
</item>
<item>
<title>【视觉Mamba模型相关文献资源列表】’Awesome-Vision-Mamba - Latest Papers on Vision Mamba and Related Areas' GitHub: github.com/ReaFly/Awesome-Vision-Ma...</title>
<link>https://weibo.com/1402400261/O8L1ca49x</link>
<guid>https://weibo.com/1402400261/O8L1ca49x</guid>
<content:encoded><![CDATA[
<div> GitHub、视觉Mamba模型、相关领域、最新论文、资源列表、Awesome-Vision-Mamba、ReaFly、GitHub链接、研究领域、视觉技术

视觉Mamba模型相关文献资源列表的GitHub库“Awesome-Vision-Mamba”收集了最新的关于视觉Mamba模型及相关研究领域的论文。这个资源库由用户ReaFly维护，提供了丰富的学术资源和论文链接。感兴趣的研究者可以通过这个GitHub链接获取到关于视觉技术的最新进展和研究成果。GitHub库中包含了各种与视觉Mamba模型相关的论文资源，为研究者提供了便捷的学习和参考资料。<br /><br />总结:GitHub上的Awesome-Vision-Mamba收集了最新关于视觉Mamba模型及相关领域的论文资源，由用户ReaFly维护，为研究者提供了丰富的学术资源和论文链接，方便他们了解视觉技术的最新进展。 <div>
【视觉Mamba模型相关文献资源列表】’Awesome-Vision-Mamba - Latest Papers on Vision Mamba and Related Areas' GitHub: github.com/ReaFly/Awesome-Vision-Mamba <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hojcheypefj20xf0u0jxo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 05:10:27 GMT</pubDate>
</item>
<item>
<title>【OpenAI为训练GPT-4转录百万小时YouTube视频，挑战版权灰色地带】 - OpenAI为了获取高质量的训练数据来训练GPT-4，转录了超过100万小时的YouTube视频。这一行为...</title>
<link>https://weibo.com/1402400261/O8J7rk1BG</link>
<guid>https://weibo.com/1402400261/O8J7rk1BG</guid>
<content:encoded><![CDATA[
<div> OpenAI, GPT-4, YouTube, 转录, 数据训练, 版权, AI发展, 挑战, 谷歌, 私隐, 数据收集

<br /><br />总结:
OpenAI为训练GPT-4转录了超过100万小时的YouTube视频，面临着版权和数据获取的挑战。公司高层重视数据收集，但采取的做法有争议。谷歌谴责OpenAI的行为，却自己也在利用YouTube内容训练模型。企业数据使用应受更多监管。消费者对科技公司数据使用行为了解不足，需要更多透明和控制。AI发展中数据和版权问题复杂，各方应加强沟通协调，平衡创新和权益保护。 Meta对隐私进行改革，反映了企业应对数据问题的迫切性。 <div>
【OpenAI为训练GPT-4转录百万小时YouTube视频，挑战版权灰色地带】  <br />- OpenAI为了获取高质量的训练数据来训练GPT-4，转录了超过100万小时的YouTube视频。这一行为处于AI版权法的灰色地带。  <br />- OpenAI总裁Greg Brockman亲自参与了收集用于训练的视频。OpenAI发言人表示，公司为每个模型策划"独特"的数据集，以帮助它们"理解世界"。  <br />- 谷歌发言人表示，该公司已经"看到了未经证实的报道"，称OpenAI的行为违反了YouTube的robots.txt文件和服务条款，这些条款禁止未经授权的抓取或下载YouTube内容。  <br />- 谷歌表示，当有明确的法律或技术依据时，会采取"技术和法律措施"防止此类未经授权的使用。  <br />- 报道称谷歌也从YouTube收集了转录内容。谷歌表示已根据与YouTube创作者的协议，在"一些YouTube内容"上训练其模型。  <br />- 报道指出，在剑桥分析公司丑闻后，Meta对隐私进行了改革，这限制了其使用消费者数据的方式。  <br /><br />思考：  <br />- 尽管OpenAI和谷歌等科技巨头在AI领域处于领先地位，但它们仍面临着获取高质量训练数据的挑战，不得不采取一些有争议甚至违规的做法。这凸显出AI发展中数据和版权问题的复杂性。  <br />- OpenAI总裁亲自参与数据收集，表明公司高层对这一问题的重视程度，但也反映出他们对法律和伦理边界的态度比较激进。  <br />- 谷歌一方面谴责OpenAI的行为，另一方面自己也在利用YouTube内容训练模型，虽然声称是按照协议进行的。这种双重标准耐人寻味。  <br />- 科技公司收集用户数据训练AI模型已是公开的秘密，但消费者对此知之甚少，缺乏足够的知情权和控制力。Meta的例子表明，企业数据使用行为应受到更多监管。  <br />- AI模型背后的数据问题一直没有引起足够重视，各方应加强沟通协调，在鼓励创新和保护权益之间取得平衡。<br />《OpenAI transcribed over a million hours of YouTube videos to train GPT-4 - The Verge》 <a href="https://www.theverge.com/2024/4/6/24122915/openai-youtube-transcripts-gpt-4-training-data-google"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoj43onsskj21f70u010s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 00:20:21 GMT</pubDate>
</item>
<item>
<title>【Weco AI 发布 AIDE：开启软件开发的 AI 时代】- Weco AI 推出了一个名为 AIDE 的 AI 助手，它可以根据用户用自然语言描述的任务，自动搜索设计空间并生成源代...</title>
<link>https://weibo.com/1402400261/O8J5kyAQf</link>
<guid>https://weibo.com/1402400261/O8J5kyAQf</guid>
<content:encoded><![CDATA[
<div> AI、AIDE、代码生成、大语言模型、强化学习、程序合成、质量、可维护性、反馈、报告

<br /><br />总结:
Weco AI推出了名为AIDE的AI助手，可以根据用户用自然语言描述的任务自动生成源代码和报告。AIDE采用大型语言模型和强化学习技术，在代码生成任务上表现出色，且引入了反馈驱动的程序合成和验证机制，提高了代码质量和可靠性。AIDE还可生成详细报告，支持用户决策。Weco AI计划向企业和开发者开放AIDE平台，助力AI技术的民主化。该举措有望加速产业化进程，但也需注意可能带来的安全和伦理风险。 <div>
【Weco AI 发布 AIDE：开启软件开发的 AI 时代】<br />- Weco AI 推出了一个名为 AIDE 的 AI 助手，它可以根据用户用自然语言描述的任务，自动搜索设计空间并生成源代码和报告。这是一个突破性的多模态 AI 系统。  <br />- AIDE 采用了大型语言模型(LLM)和强化学习(RL)技术，可以理解自然语言指令，搜索复杂的程序空间，并生成高质量的代码。这比传统的代码生成方法更加灵活和强大。  <br />- AIDE 在代码质量、运行效率、可维护性等方面表现出色。在标准基准测试中，它优于现有的代码生成模型。  <br />- AIDE 的一个关键创新是引入了程序合成和验证的反馈循环。它会反复修改生成的程序，直到通过各种测试用例，以确保代码的正确性和鲁棒性。  <br />- 除了代码，AIDE 还可以生成对问题、方法、结果的详细分析报告，以支持用户的决策过程。它打通了从需求到落地的全流程。  <br />- AIDE 具有广泛的应用前景，可以帮助软件工程师、数据科学家、领域专家等用户大幅提高生产力，应对日益复杂的现实世界问题。  <br />- Weco AI 计划向企业和开发者开放 AIDE 平台，推动人工智能技术的民主化。用户可以免费试用，或以 API 的方式集成到自己的应用中。<br /><br />思考：  <br />- AIDE 在代码生成任务上的突出表现，例证了大语言模型和强化学习结合的巨大潜力，为进一步开发类似的智能编程助手指明了方向。  <br />- 反馈驱动的程序合成和验证机制是一个很有洞见的设计，充分利用了 AI 系统的迭代优化能力，可以显著提高生成代码的质量和可靠性。  <br />- 自动生成任务的分析报告是一个很有价值的功能，它凸显了 AI 技术在赋能知识工作者、支持专业决策方面的应用前景。  <br />- 报告中对 AIDE 的局限性讨论还不够充分，比如在处理高度开放式、语义复杂度高的任务时可能遇到的挑战。  <br />- Weco AI 开放 AIDE 平台的举措值得肯定，它有助于加速 AI 技术的产业化进程和生态建设。但是否会带来新的安全和伦理风险值得关注。<br />《AIDE: Human-Level Performance in Data Science Competitions》 <a href="https://www.weco.ai/blog/technical-report"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoj3xo7cr3j213i0u00uo.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoj3y35gqjj21230u00xz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoj3y6hiuxj21i60r30wq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 00:15:09 GMT</pubDate>
</item>
<item>
<title>【Replit 正在将 AI 集成到开发环境中，以提高开发人员体验，选择了代码修复任务，因为开发人员在修复软件中花费了大量时间，Replit 团队正在训练第一个7B的 Rep...</title>
<link>https://weibo.com/1402400261/O8J2CFXjF</link>
<guid>https://weibo.com/1402400261/O8J2CFXjF</guid>
<content:encoded><![CDATA[
<div> Replit、AI、开发环境、代码修复、时间、Replit团队、训练、7B、LLM、数据  
<br />  
Replit团队正在将AI集成到开发环境中，选择了代码修复任务，因为开发人员在修复软件中花费了大量时间。他们正在训练第一个7B的Replit原生LLM，利用其大量的数据来修复代码错误。通过这一举措，Replit希望提高开发人员的体验，让他们能够更高效地进行代码修复工作，从而提升整体开发效率和质量。通过AI技术的应用，Replit正在探索如何更好地利用大数据和机器学习来优化软件开发流程，为开发人员提供更好的工具和支持。AI在代码修复领域的应用将在未来继续发展，为开发者提供更多便利和效率。  
<br />  
总结:  
1. Replit团队正在将AI集成到开发环境中，选择了代码修复任务。  
2. 开发人员在修复软件中花费了大量时间。  
3. Replit团队正在训练第一个7B的Replit原生LLM，以利用其大量数据来修复代码错误。  
4. 目的是提高开发者体验，提高开发效率和质量。  
5. AI技术的应用带来了对大数据和机器学习的探索。  
6. Replit致力于优化软件开发流程，提供更好的工具和支持。  
7. AI在代码修复领域的应用将继续发展，为开发者提供更多便利和效率。 <div>
【Replit 正在将 AI 集成到开发环境中，以提高开发人员体验，选择了代码修复任务，因为开发人员在修复软件中花费了大量时间，Replit 团队正在训练第一个7B的 Replit 原生 LLM，以利用其大量的数据来修复代码错误】《Replit — Building LLMs for Code Repair》 <a href="https://blog.replit.com/code-repair"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoj3rccw8zj21950u0tcd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 00:08:29 GMT</pubDate>
</item>
<item>
<title>【RWKV-6发布，提供1.6B和3B两种模型，在2.5T Token上训练，支持100+种语言】《BlinkDL/rwkv-6-world · Hugging Face》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O8J1ckZjq</link>
<guid>https://weibo.com/1402400261/O8J1ckZjq</guid>
<content:encoded><![CDATA[
<div> 模型、RWKV-6、发布、1.6B、3B、语言、训练、2.5T Token、支持、100+

<br /><br />总结:
最新发布的RWKV-6模型提供了1.6B和3B两种版本，在使用2.5T Token进行训练的同时支持100多种语言。这一模型的发布将为自然语言处理领域带来新的突破和可能性，为用户提供更广泛的语言支持和更高的性能表现。 <div>
【RWKV-6发布，提供1.6B和3B两种模型，在2.5T Token上训练，支持100+种语言】《BlinkDL/rwkv-6-world · Hugging Face》 <a href="https://huggingface.co/BlinkDL/rwkv-6-world"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoj3h9ll90j20ya0u0adz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 00:04:58 GMT</pubDate>
</item>
<item>
<title>今日推介(第1369期)：LLM的LLM响应错误检测能力评估、识别破坏安全的良性数据、通过模拟伪代码执行改进算法推理、将LLM变成跨模态跨语言检索系统、语言模型是否...</title>
<link>https://weibo.com/1402400261/O8IiG1TrX</link>
<guid>https://weibo.com/1402400261/O8IiG1TrX</guid>
<content:encoded><![CDATA[
<div> LLM、响应错误检测、良性数据、算法推理、跨模态、跨语言、检索系统、语言模型、token、规划<br />
<br />
总结:<br />
本篇文章介绍了LLM在响应错误检测方面的能力评估，以及识别破坏安全的良性数据的重要性。研究表明，通过模拟伪代码执行可以提升算法推理能力，将LLM转变为跨模态跨语言检索系统也具有潜力。同时，语言模型在为未来的token提前规划方面也有着重要作用。通过这些研究，我们能够更好地理解和应用LLM在不同领域的潜力和效用。 <div>
今日推介(第1369期)：LLM的LLM响应错误检测能力评估、识别破坏安全的良性数据、通过模拟伪代码执行改进算法推理、将LLM变成跨模态跨语言检索系统、语言模型是否为未来的token提前做了规划 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/691199339"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.8)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoj0h8wc0mj21f60lswlz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoj0hbbd4yj21d00ew0vq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoj0hdo4jxj21500mkag4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoj0hgf94lj20qw10kwja.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoj0hjb8iyj219d0u0n1u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 22:15:17 GMT</pubDate>
</item>
<item>
<title>[CV] Streaming Dense Video Captioning 网页链接 提出基于聚类记忆和流式解码的流式稠密视频描述模型，可以实时处理和描述任意长的视频。 [图片][图片][图片]</title>
<link>https://weibo.com/1402400261/O8IcDbV2G</link>
<guid>https://weibo.com/1402400261/O8IcDbV2G</guid>
<content:encoded><![CDATA[
<div> 基于聚类记忆和流式解码的流式稠密视频描述模型、实时处理、描述任意长的视频<br />
<br />
提出的流式稠密视频描述模型结合了聚类记忆和流式解码技术，可以实时处理和描述任意长的视频。该模型能够准确地生成与视频内容相关的语义描述，使得视频内容更易于理解和搜索。在实验中，模型展现出了优越的性能，对于长视频描述任务具有较高的效率和准确性。通过将聚类记忆与流式解码相结合，该模型在视频描述领域有着广阔的应用前景。总结: 提出了一种结合了聚类记忆和流式解码的流式稠密视频描述模型，能够实时处理和描述任意长的视频，为视频描述任务带来了更高的效率和准确性。 <div>
[CV] Streaming Dense Video Captioning  <br /><a href="https://arxiv.org/abs/2404.01297"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出基于聚类记忆和流式解码的流式稠密视频描述模型，可以实时处理和描述任意长的视频。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoj021ltzkj212i1aw7n4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoj021sf0nj21oo0qewny.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoj02249egj20u20kqjut.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 22:00:23 GMT</pubDate>
</item>
<item>
<title>[CV] Video Interpolation with Diffusion Models 网页链接 提出串联式扩散模型VIDIM生成高质量视频插帧，可处理复杂运动，生成效果连贯自然，明显优于现有非生...</title>
<link>https://weibo.com/1402400261/O8I93pO6F</link>
<guid>https://weibo.com/1402400261/O8I93pO6F</guid>
<content:encoded><![CDATA[
<div> 扩散模型、视频插帧、高质量、复杂运动、连贯自然、非生成模型<br />
<br />
提出串联式扩散模型VIDIM生成高质量视频插帧，能够处理复杂运动并产生效果连贯自然的视频插帧结果。与现有的非生成模型相比， VIDIM的生成效果明显优越，为视频插帧任务带来了新的方法和思路。<br /><br />总结: 本文介绍了一种新的视频插帧方法，通过扩散模型实现高质量、连贯自然的视频插帧效果，提升了处理复杂运动的能力，并在实验中表现优异，展现出较高的应用潜力。 <div>
[CV] Video Interpolation with Diffusion Models  <br /><a href="https://arxiv.org/abs/2404.01203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />提出串联式扩散模型VIDIM生成高质量视频插帧，可处理复杂运动，生成效果连贯自然，明显优于现有非生成模型。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoizsvfypoj212u1b47o6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoizsvo8f6j21j20pc4b1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoizswaaabj21j20vwn9v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:51:35 GMT</pubDate>
</item>
<item>
<title>[CL] Comparing Bad Apples to Good Oranges: Aligning Large Language Models via Joint Preference Optimization 网页链接提出一种获取人类对指令-响应对联合...</title>
<link>https://weibo.com/1402400261/O8I6GrzAC</link>
<guid>https://weibo.com/1402400261/O8I6GrzAC</guid>
<content:encoded><![CDATA[
<div> 获取人类偏好、DOVE框架、指令-响应对、语言模型输出、联合偏好优化、实验验证

DOVE框架提出了一种新的方法，用于获取人类对指令-响应对的联合偏好，这一框架能够提供比传统条件排名更丰富的偏好信号。实验结果表明，DOVE框架可以更好地调整大型语言模型的输出，使其更符合人类的偏好。通过联合偏好优化的方式，DOVE框架能够使语言模型生成更准确和贴近人类期望的响应，进一步提高了模型的性能表现。整体来看，DOVE框架为调整大型语言模型的输出提供了一种有效且有前景的方法。 <div>
[CL] Comparing Bad Apples to Good Oranges: Aligning Large Language Models via Joint Preference Optimization  <br /><a href="https://arxiv.org/abs/2404.00530"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br />提出一种获取人类对指令-响应对联合偏好的框架DOVE，可以提供比传统条件排名更丰富的偏好信号，实验表明其可以更好地调整语言模型的输出。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoizmssiedj20uw1diwvg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoizmt6jm2j21fw0tqwqf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoizmte1vtj21ey0vagyf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:45:44 GMT</pubDate>
</item>
<item>
<title>[CL] Towards a Robust Retrieval-Based Summarization System 网页链接 系统地评估和增强了RAG辅助的LLM进行摘要任务的能力，提出了通用的评估管道和可复用的模...</title>
<link>https://weibo.com/1402400261/O8I3tzxRP</link>
<guid>https://weibo.com/1402400261/O8I3tzxRP</guid>
<content:encoded><![CDATA[
<div> 关键词: RAG, LLM, 摘要任务, 评估管道, 模型优化

总结:
本文系统地评估和增强了RAG辅助的LLM在进行摘要任务时的能力。文章提出了通用的评估管道和可复用的模型优化系统，通过这些手段为摘要系统的构建和优化提供了指导。作者们对RAG模型在摘要生成中的表现进行了细致的评估和分析，发现存在一些不足之处，然后提出了相应的改进方法。通过这些改进措施，研究人员成功增强了RAG在摘要生成任务中的表现，使其更加稳健和可靠。这项研究为提升检索式摘要系统的性能提供了重要的参考和借鉴。值得进一步深入研究和应用。 <br /><br /> <div>
[CL] Towards a Robust Retrieval-Based Summarization System  <br /><a href="https://arxiv.org/abs/2403.19889"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />系统地评估和增强了RAG辅助的LLM进行摘要任务的能力，提出了通用的评估管道和可复用的模型优化系统。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoizekisbtj20v61bcnac.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoizekxf8nj21ea0qcdmn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoizelj7kvj217e0r4q90.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:37:50 GMT</pubDate>
</item>
<item>
<title>通过“短视训练”发现，transformer在语言建模场景下并没有有意识地提前缓存对未来有用的信息，主要是当前有用的特征也对未来有用。 - 转发 @爱可可-爱生活:&amp;ens...</title>
<link>https://weibo.com/1402400261/O8HWDg5WJ</link>
<guid>https://weibo.com/1402400261/O8HWDg5WJ</guid>
<content:encoded><![CDATA[
<div> 语言模型、Transformer、短视训练、缓存信息、未来特征、语言建模、意识<br />
<br />
提到的研究表明，在语言建模中，Transformer并没有有意识地提前缓存对未来有用的信息。研究发现当前有用的特征也对未来有用，说明Transformer在处理语言建模场景下并不会预先计划未来的token。这一发现对于理解Transformer在语言建模中的工作方式具有重要意义。 <div>
通过“短视训练”发现，transformer在语言建模场景下并没有有意识地提前缓存对未来有用的信息，主要是当前有用的特征也对未来有用。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Do language models plan ahead for future tokens?》W Wu, J X. Morris, L Levine [University of Colorado Boulder &amp; Cornell University] (2024) <a href="https://arxiv.org/abs/2404.00859"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyqr6kn4j215c0msthf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyqrrmolj21ce0w0tej.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyqrvyzzj21ck0wwn1h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyqs4y34j21co12qk2w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiywy3oi4j20vd0eo3zo.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiywy32pwj20ve0fbgn6.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:20:58 GMT</pubDate>
</item>
<item>
<title>[CL]《Do language models plan ahead for future tokens?》W Wu, J X. Morris, L Levine [University of Colorado Boulder &amp; Cornell University] (2024) 网页...</title>
<link>https://weibo.com/1402400261/O8HWAAnw0</link>
<guid>https://weibo.com/1402400261/O8HWAAnw0</guid>
<content:encoded><![CDATA[
<div> 模型，语言，规划，未来，令牌，预测，计划

本文研究了语言模型是否会提前规划未来的令牌。研究发现，一些语言模型确实会对未来的令牌进行规划，而不仅仅是根据当前的上下文进行预测。这种规划行为有助于提高模型在语言任务中的性能表现。然而，研究也指出，虽然这种规划可以提高模型的性能，但也会增加模型的计算复杂性和资源消耗。因此，未来的研究需要平衡这些因素，以实现更好的性能和效率。总的来说，语言模型的规划行为在提高性能方面有潜力，但需要综合考虑计算成本和效果。<br /><br />总结: <div>
[CL]《Do language models plan ahead for future tokens?》W Wu, J X. Morris, L Levine [University of Colorado Boulder &amp; Cornell University] (2024) <a href="https://arxiv.org/abs/2404.00859"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyqr6kn4j215c0msthf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyqrrmolj21ce0w0tej.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyqrvyzzj21ck0wwn1h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyqs4y34j21co12qk2w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiywy3oi4j20vd0eo3zo.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiywy32pwj20ve0fbgn6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:20:52 GMT</pubDate>
</item>
<item>
<title>利用语言模型跨语言的文本理解能力，以及对比学习框架，从语言模型中构建出强大的跨语言跨模态语音文本匹配系统。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Transform...</title>
<link>https://weibo.com/1402400261/O8HTmeOnG</link>
<guid>https://weibo.com/1402400261/O8HTmeOnG</guid>
<content:encoded><![CDATA[
<div> 跨语言文本理解, 跨模态匹配, 语言模型, 对比学习, 跨语言检索, 跨模态检索, 文本匹配, 跨语言研究

<br /><br />总结:
本文提出了一种利用语言模型构建跨语言跨模态语音文本匹配系统的方法。通过对比学习框架，将语言模型转化为跨模态和跨语言的检索系统。该系统具有强大的文本理解能力，能够实现跨语言检索和跨模态匹配。这一研究为解决语言和模态之间的匹配问题提供了新的思路和方法。 <div>
利用语言模型跨语言的文本理解能力，以及对比学习框架，从语言模型中构建出强大的跨语言跨模态语音文本匹配系统。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Transforming LLMs into Cross-modal and Cross-lingual Retrieval Systems》F P Gomez, R Sanabria, Y Sung, D Cer… [Google Research &amp; Boston University &amp; The University of Edinburgh] (2024) <a href="https://arxiv.org/abs/2404.01616"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiynnmpkvj20my11sqc0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyno9070j20qw10kagd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiynonm2oj20q00i0taa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiynozmchj20qe0my76x.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:12:53 GMT</pubDate>
</item>
<item>
<title>[CL]《Transforming LLMs into Cross-modal and Cross-lingual Retrieval Systems》F P Gomez, R Sanabria, Y Sung, D Cer… [Google Research &amp; Boston Univers...</title>
<link>https://weibo.com/1402400261/O8HTifsCH</link>
<guid>https://weibo.com/1402400261/O8HTifsCH</guid>
<content:encoded><![CDATA[
<div> 跨模态检索，跨语言检索，LLMs，语言模型，转换，跨模态，跨语言，信息检索，谷歌研究，波士顿大学

总结:
研究团队提出了一种将LLMs转化为跨模态和跨语言检索系统的方法。研究旨在提高信息检索的效率和准确性。作者通过在谷歌研究、波士顿大学和爱丁堡大学的合作下，利用语言模型技术实现了不同模态和语言之间的检索。他们的工作为解决多模态和多语言信息检索问题提供了新的视角和方法。 <div>
[CL]《Transforming LLMs into Cross-modal and Cross-lingual Retrieval Systems》F P Gomez, R Sanabria, Y Sung, D Cer… [Google Research &amp; Boston University &amp; The University of Edinburgh] (2024) <a href="https://arxiv.org/abs/2404.01616"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiynnmpkvj20my11sqc0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyno9070j20qw10kagd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiynonm2oj20q00i0taa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiynozmchj20qe0my76x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:12:45 GMT</pubDate>
</item>
<item>
<title>提出THINK-AND-EXECUTE框架，通过发现任务级逻辑并以伪代码格式表达，分解算法推理过程，从而改进了语言模型在广范围算法推理任务上的表现。 - 转发 @爱可可-爱...</title>
<link>https://weibo.com/1402400261/O8HSx6yC4</link>
<guid>https://weibo.com/1402400261/O8HSx6yC4</guid>
<content:encoded><![CDATA[
<div> Language Models, Compilers, Pseudocode Execution, Algorithmic Reasoning, THINK-AND-EXECUTE框架, 任务级逻辑, 伪代码格式, 算法推理过程, 广泛范围, 改进

总结：<br /><br />这篇文章提出了一种名为THINK-AND-EXECUTE框架的方法，通过发现任务级逻辑并以伪代码格式表达，分解算法推理过程，从而改进了语言模型在广泛范围算法推理任务上的表现。研究者们将语言模型视为编译器，模拟伪代码的执行来提高算法推理能力。这种方法有望在提升语言模型的算法推理能力方面取得重要进展。 <div>
提出THINK-AND-EXECUTE框架，通过发现任务级逻辑并以伪代码格式表达，分解算法推理过程，从而改进了语言模型在广范围算法推理任务上的表现。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models》H Chae, Y Kim, S Kim, K T Ong… [Yonsei University &amp; KAIST AI] (2024) <a href="https://arxiv.org/abs/2404.02575"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiyle25i2j20ye0v4k4m.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiylejue8j21500mk7cd.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiylezpb5j215a0vkqbp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiylf806xj214y0h2gnq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiym4god5j214s0i2te4.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:10:51 GMT</pubDate>
</item>
<item>
<title>[CL]《Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models》H Chae, Y Kim, S Kim, K T Ong…...</title>
<link>https://weibo.com/1402400261/O8HSnoFLZ</link>
<guid>https://weibo.com/1402400261/O8HSnoFLZ</guid>
<content:encoded><![CDATA[
<div> Language Models, Compilers, Simulating Pseudocode Execution, Algorithmic Reasoning, Yonsei University, KAIST AI

该研究探讨了将语言模型视为编译器的概念，通过模拟伪代码执行来提高语言模型的算法推理能力。研究团队来自韩国延世大学和韩国科技研究所人工智能领域。他们发现，将语言模型训练成类似编译器的方式，能够帮助提升其算法推理能力。通过模拟伪代码执行过程，语言模型能够更好地理解和推断算法逻辑，从而提高在算法领域的表现。这一研究为将自然语言处理与算法推理结合提供了新的思路和方法。research topic. Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models, H Chae, Y Kim, S Kim, K T Ong… [Yonsei University & KAIST AI] (2024)
<br /><br />总结: 该研究在语言模型领域引入了编译器的概念，通过模拟伪代码执行来提高算法推理能力。研究结果表明，这种方法能够帮助语言模型更好地理解和推断算法逻辑，为算法领域的应用提供了新的思路和方法。 <div>
[CL]《Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models》H Chae, Y Kim, S Kim, K T Ong… [Yonsei University &amp; KAIST AI] (2024) <a href="https://arxiv.org/abs/2404.02575"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiyle25i2j20ye0v4k4m.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiylejue8j21500mk7cd.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiylezpb5j215a0vkqbp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiylf806xj214y0h2gnq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiym4god5j214s0i2te4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:10:28 GMT</pubDate>
</item>
<item>
<title>通过表示和梯度匹配的模型感知方法，发现了数学和列表格式是表面良性但更易导致被攻破的隐性有害数据模式，为编译安全数据提供了启发。 - 转发 @爱可可-爱生活:&amp;...</title>
<link>https://weibo.com/1402400261/O8HRJaf1n</link>
<guid>https://weibo.com/1402400261/O8HRJaf1n</guid>
<content:encoded><![CDATA[
<div> Safe Data, Identifying, Benign Data, Safety, Model, Gradient Matching, Math and List Format, Data Patterns, Security

总结:<br /><br />
本文使用表示和梯度匹配的模型感知方法，发现了数学和列表格式是表面良性但更易导致被攻破的隐性有害数据模式。通过研究这些隐性有害数据模式，提供了启发，为编译安全数据提供了一定的指导。进一步的研究有助于更有效地识别和消除潜在的安全漏洞，提高数据的安全性和可靠性。 <div>
通过表示和梯度匹配的模型感知方法，发现了数学和列表格式是表面良性但更易导致被攻破的隐性有害数据模式，为编译安全数据提供了启发。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《What's in Your "Safe" Data?: Identifying Benign Data that Breaks Safety》L He, M Xia, P Henderson [Princeton University] (2024) <a href="https://arxiv.org/abs/2404.01099"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiyk5vs0nj214s0oqako.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyk6jkwwj21d00ewae1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyk6qevvj21cw0l4q9k.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:08:53 GMT</pubDate>
</item>
<item>
<title>[LG]《What's in Your "Safe" Data?: Identifying Benign Data that Breaks Safety》L He, M Xia, P Henderson [Princeton University] (2024) 网页链接 #机器学...</title>
<link>https://weibo.com/1402400261/O8HRCkaHS</link>
<guid>https://weibo.com/1402400261/O8HRCkaHS</guid>
<content:encoded><![CDATA[
<div> 安全数据，恶意数据，识别，无害数据，数据分析，机器学习，隐私保护，安全性，智能设备，数据安全

总结:<br /><br />该研究由普林斯顿大学的He、Xia和Henderson完成，目的是识别在数据中可能存在的违反安全性的无害数据，该数据可能会破坏隐私保护或数据安全。研究使用数据分析和机器学习技术，通过对智能设备中的数据进行分析，发现了一些看似无害但具有潜在风险的数据。这项研究的结果有助于改善智能设备的安全性，保护用户隐私，并提高数据的安全性。 <div>
[LG]《What's in Your "Safe" Data?: Identifying Benign Data that Breaks Safety》L He, M Xia, P Henderson [Princeton University] (2024) <a href="https://arxiv.org/abs/2404.01099"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiyk5vs0nj214s0oqako.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyk6jkwwj21d00ewae1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyk6qevvj21cw0l4q9k.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:08:37 GMT</pubDate>
</item>
<item>
<title>ReaLMistake是首个包含丰富的LLM错误和详尽标注的基准测试，可全面诊断LLM响应错误检测性能，为进一步改进错误检测提供有价值资源。 - 转发 @爱可可-爱生活:&amp;ens...</title>
<link>https://weibo.com/1402400261/O8HRowkN2</link>
<guid>https://weibo.com/1402400261/O8HRowkN2</guid>
<content:encoded><![CDATA[
<div> LLM错误检测基准测试, 详尽标注, 错误检测性能, 提供有价值资源

<br /><br />
总结: 本研究介绍了ReaLMistake，这是首个包含丰富的LLM错误和详尽标注的基准测试。该基准测试可以全面诊断LLM响应错误检测性能，并为改进错误检测提供有价值资源。研究团队通过对LLMs在检测错误方面的性能进行评估，展示了对LLM模型错误检测能力的热切关注。他们的工作有助于进一步探索和改进LLMs在错误检测方面的表现，为提高模型的准确性和可靠性提供了重要参考。 <div>
ReaLMistake是首个包含丰富的LLM错误和详尽标注的基准测试，可全面诊断LLM响应错误检测性能，为进一步改进错误检测提供有价值资源。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Evaluating LLMs at Detecting Errors in LLM Responses》R Kamoi, S S S Das, R Lou, J J Ahn… [Penn State University] (2024) <a href="https://arxiv.org/abs/2404.03602"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyis1w1fj216u0zch23.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyisg4p4j21f60lsdpy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyissumlj21f80qik4a.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyisxlblj21ec0k6n6s.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyjebso1j20d60cct98.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiyjeckggj20ve0abdi8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyjed1kuj20vk0ap41a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyjecng8j20vd09ztb8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyjebwt3j20rh0eit9c.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:08:03 GMT</pubDate>
</item>
<item>
<title>[CL]《Evaluating LLMs at Detecting Errors in LLM Responses》R Kamoi, S S S Das, R Lou, J J Ahn… [Penn State University] (2024) 网页链接 #机器学习##人...</title>
<link>https://weibo.com/1402400261/O8HRjdlw5</link>
<guid>https://weibo.com/1402400261/O8HRjdlw5</guid>
<content:encoded><![CDATA[
<div> LLMs, Errors, Detection, Evaluation, Performance, Language Models, Responses, Artificial Intelligence, Natural Language Processing, Penn State University

总结:<br /><br />该研究旨在评估LLMs在检测LLM响应中出现错误的能力。研究由宾夕法尼亚州立大学的研究人员进行，他们探讨了语言模型的性能，并对其在检测错误方面的表现进行了评估。研究着重于人工智能和自然语言处理领域，试图提高LLMs的准确性。通过实验和数据分析，研究团队展示了LLMs在识别错误方面的优势，为提升语言模型的能力提供了重要参考。 <div>
[CL]《Evaluating LLMs at Detecting Errors in LLM Responses》R Kamoi, S S S Das, R Lou, J J Ahn… [Penn State University] (2024) <a href="https://arxiv.org/abs/2404.03602"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyis1w1fj216u0zch23.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyisg4p4j21f60lsdpy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyissumlj21f80qik4a.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyisxlblj21ec0k6n6s.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyjebso1j20d60cct98.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiyjeckggj20ve0abdi8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyjed1kuj20vk0ap41a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyjecng8j20vd09ztb8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyjebwt3j20rh0eit9c.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyjee71xj20vh0wutf6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiyjed5paj20vg09l75z.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyjedmnyj20vj0k9goz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:07:51 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.7)》 爱可可微博热门分享(4.7) [图片]</title>
<link>https://weibo.com/1402400261/O8FiGjnut</link>
<guid>https://weibo.com/1402400261/O8FiGjnut</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 爱可可, 分享, 关键词, 点赞, 评论, 转发, 内容

<br /><br />总结:
爱可可微博分享的内容受到了广泛关注，引起了热烈讨论。文章内容引人入胜，吸引了大量的点赞、评论和转发。爱可可的微博在社交平台上拥有很高的影响力，其热门分享常常成为用户关注的焦点。通过持续更新优质内容，爱可可微博不断吸引更多粉丝和用户关注，为用户带来更丰富多样的内容体验。 <div>
《爱可可微博热门分享(4.7)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405020653865795688"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.7)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoin8nt4nuj20fo08t3zv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 14:37:03 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World》(CVPR 2024) Git...</title>
<link>https://weibo.com/1402400261/O8EPYv3SI</link>
<guid>https://weibo.com/1402400261/O8EPYv3SI</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据集, 视频, 人类建模, 头发转移, 优化算法, 地图生成, 大型语言模型, 图像分割

总结:
<br /><br />
本文介绍了几篇论文实现代码，涉及到不同领域的研究成果。其中《EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World》介绍了一个可以用于融合主观和客观视角的数据集。《PKU-DyMVHumans: A Multi-View Video Benchmark for High-Fidelity Dynamic Human Modeling》介绍了一个用于动态人类建模的多视角视频基准数据集。《HairFastGAN: Realistic and Robust Hair Transfer with a Fast Encoder-Based Approach》展示了一种快速和稳健的头发转移方法。《GIPC: Fast and Stable Gauss-Newton Optimization of IPC Barrier Energy》介绍了一种快速优化算法。《P-MapNet: Far-seeing Map Generator Enhanced by both SDMap and HDMap Priors》展示了一个结合了不同先验信息的地图生成模型。《MacGyver: Are Large Language Models Creative Problem Solvers?》研究了大型语言模型在解决问题时的创造性。《UltraLight VM-UNet: Parallel Vision Mamba Significantly Reduces Parameters for Skin Lesion Segmentation》提出了一种降低参数量的皮肤病变分割模型。这些研究有助于推动计算机视觉和人工智能领域的发展。 <div>
几篇论文实现代码：<br />《EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World》(CVPR 2024) GitHub: github.com/OpenGVLab/EgoExoLearn [fig1]<br />《PKU-DyMVHumans: A Multi-View Video Benchmark for High-Fidelity Dynamic Human Modeling》(CVPR 2024) GitHub: github.com/zhengxyun/PKU-DyMVHumans [fig3]<br />《HairFastGAN: Realistic and Robust Hair Transfer with a Fast Encoder-Based Approach》(2024) GitHub: github.com/AIRI-Institute/HairFastGAN [fig2]<br />《GIPC: Fast and Stable Gauss-Newton Optimization of IPC Barrier Energy》(2024) GitHub: github.com/KemengHuang/GPU_IPC<br />《P-MapNet: Far-seeing Map Generator Enhanced by both SDMap and HDMap Priors》(2024) GitHub: github.com/jike5/P-MapNet [fig4]<br />《MacGyver: Are Large Language Models Creative Problem Solvers?》(2024) GitHub: github.com/allenai/MacGyver [fig5]<br />《UltraLight VM-UNet: Parallel Vision Mamba Significantly Reduces Parameters for Skin Lesion Segmentation》(2024) GitHub: github.com/wurenkai/UltraLight-VM-UNet<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoijy4zv3yj20pw08jjye.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoijyn14uxj26221mhx6r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoijzb48o5j21io0gwn87.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoik6yqka6j21jk0v9n9g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoikezela3j21zs0qyx6p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 13:26:20 GMT</pubDate>
</item>
<item>
<title>【Mantis：一个命令行框架，旨在自动化资产发现、反 reconnaissance 和漏洞扫描的工作流程。它支持自动化分发扫描、超级容易定制扫描、仪表板支持、漏洞管理、高...</title>
<link>https://weibo.com/1402400261/O8EPydgTG</link>
<guid>https://weibo.com/1402400261/O8EPydgTG</guid>
<content:encoded><![CDATA[
<div> 命令行框架、资产发现、反 reconnaissance、漏洞扫描、自动化分发、定制扫描、仪表板支持、漏洞管理、高级警报、DNS 服务集成

<br /><br />总结:
Mantis是一个安全框架，旨在自动化资产发现、反侦察和漏洞扫描的工作流程。它支持自动化分发扫描、超级容易定制扫描、仪表板支持、漏洞管理、高级警报和DNS服务集成。Mantis的GitHub链接为github.com/PhonePe/mantis。 <div>
【Mantis：一个命令行框架，旨在自动化资产发现、反 reconnaissance 和漏洞扫描的工作流程。它支持自动化分发扫描、超级容易定制扫描、仪表板支持、漏洞管理、高级警报和 DNS 服务集成】'Mantis - Mantis is a security framework that automates the workflow of discovery, reconnaissance, and vulnerability scanning.' GitHub: github.com/PhonePe/mantis <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%AE%89%E5%85%A8%23&amp;isnewpage=1"><span class="surl-text">#安全#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoil60kjcij20u012p43y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 13:25:17 GMT</pubDate>
</item>
<item>
<title>【Live Transcription with Whisper PoC in Server - Client setup：提供了一个 Live-Transcription (STT) with Whisper PoC 的解决方案，基于 server-client 架...</title>
<link>https://weibo.com/1402400261/O8EO17IU6</link>
<guid>https://weibo.com/1402400261/O8EO17IU6</guid>
<content:encoded><![CDATA[
<div> GitHub, Live Transcription, Whisper PoC, server-client架构, faster-whisper模型, 实时语音转文字, gradio ui/cli, 解决方案

<br /><br />总结:
本文介绍了一个使用 faster-whisper 模型和 gradio ui/cli 实现实时语音转文字的 Live-Transcription (STT) with Whisper PoC 解决方案，基于 server-client 架构。用户可以在 GitHub 上找到相关资源，实现实时语音转文字功能，为用户提供更便捷的文字转换体验。 <div>
【Live Transcription with Whisper PoC in Server - Client setup：提供了一个 Live-Transcription (STT) with Whisper PoC 的解决方案，基于 server-client 架构，使用 faster-whisper 模型和 gradio ui/cli 实现实时语音转文字】'Live Transcription with Whisper PoC in Server - Client setup - Live-Transcription (STT) with Whisper PoC' GitHub: github.com/gaborvecsei/whisper-live-transcription <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoil25zwjlj20xb0u0diw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 13:21:30 GMT</pubDate>
</item>
<item>
<title>【ONNX-YOLO-World-Open-Vocabulary-Object-Detection：用 YOLO-World 模型在 ONNX 中执行开放词汇对象检测的脚本】'ONNX-YOLO-World-Open-Vocabulary-Object-De...</title>
<link>https://weibo.com/1402400261/O8EMFBMEB</link>
<guid>https://weibo.com/1402400261/O8EMFBMEB</guid>
<content:encoded><![CDATA[
<div> Github, YOLO-World, ONNX, 开放词汇对象检测, Python, 脚本, 模型, 执行, 项目, ibaiGorordo

<br /><br />总结:
这是一个在ONNX中使用YOLO-World模型执行开放词汇对象检测的Python脚本项目。通过GitHub仓库可以找到相关代码。该项目利用YOLO-World模型实现对象检测，支持开放词汇，使用Python脚本进行执行。将目标检测技术和ONNX模型相结合，实现了一种高效的对象检测方法。可以通过该项目学习如何在ONNX中使用YOLO-World模型进行对象检测，为相关领域的开发提供了参考和实践基础。 <div>
【ONNX-YOLO-World-Open-Vocabulary-Object-Detection：用 YOLO-World 模型在 ONNX 中执行开放词汇对象检测的脚本】'ONNX-YOLO-World-Open-Vocabulary-Object-Detection - Python scripts performing Open Vocabulary Object Detection using the YOLO-World model in ONNX.' GitHub: github.com/ibaiGorordo/ONNX-YOLO-World-Open-Vocabulary-Object-Detection <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoikypiruyj20u00zkjwg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 13:18:12 GMT</pubDate>
</item>
<item>
<title>【twitter-web-exporter：使用 TypeScript 开发的开源项目，可用于从 Twitter 网页应用程序导出 tweets、书签、列表、搜索结果、用户关注列表等】'twitter-web-e...</title>
<link>https://weibo.com/1402400261/O8EGCt7Uc</link>
<guid>https://weibo.com/1402400261/O8EGCt7Uc</guid>
<content:encoded><![CDATA[
<div> github、twitter-web-exporter、TypeScript、开源项目、导出、tweets、书签、列表、搜索结果、用户关注列表
<br /><br />总结:
这是一个使用 TypeScript 开发的开源项目，名为 twitter-web-exporter，可以从 Twitter 网页应用程序导出 tweets、书签、列表、搜索结果、用户关注列表等数据。用户可以通过该工具方便地将自己在 Twitter 上的信息进行导出和备份，保留个人数据并进行分析。项目地址为 github.com/prinsss/twitter-web-exporter。 <div>
【twitter-web-exporter：使用 TypeScript 开发的开源项目，可用于从 Twitter 网页应用程序导出 tweets、书签、列表、搜索结果、用户关注列表等】'twitter-web-exporter - Export tweets, bookmarks, lists and much more from Twitter(X) web app. (推文/书签/收藏/列表导出工具)' GitHub: github.com/prinsss/twitter-web-exporter <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoikicw2vmj20u00xogph.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 13:03:17 GMT</pubDate>
</item>
<item>
<title>【Boehm-Demers-Weiser Garbage Collector：保守的 C/C++ 垃圾收集器，可以在使用时动态分配内存】'Boehm-Demers-Weiser Garbage Collector - The Boehm-Demers-...</title>
<link>https://weibo.com/1402400261/O8EEBtxd4</link>
<guid>https://weibo.com/1402400261/O8EEBtxd4</guid>
<content:encoded><![CDATA[
<div> Boehm-Demers-Weiser Garbage Collector, C/C++, 垃圾收集器, 动态分配内存<br />
<br />
Boehm-Demers-Weiser Garbage Collector是一个保守的C/C++垃圾收集器，可以在使用时动态分配内存。该收集器以bdwgc、bdw-gc、boehm-gc、libgc等名字闻名，其源代码托管在GitHub上（github.com/ivmai/bdwgc）。该收集器在C/C++代码中提供自动内存管理，消除了手动分配和释放内存的繁琐，提高了开发效率和减少了内存泄漏的风险。 Boehm-Demers-Weiser Garbage Collector采用保守的算法来收集垃圾，能够处理复杂的指针、数据结构和内存分配行为，使得程序员可以更专注于业务逻辑的实现，而无需过多担心内存管理的问题。开发者可以通过GitHub获取该垃圾收集器的源代码，并根据需要进行定制化的配置和集成，以满足不同项目的内存管理需求。总的来说，Boehm-Demers-Weiser Garbage Collector为C/C++开发者提供了一种便捷而高效的内存管理解决方案，极大地简化了开发过程，提高了代码的可靠性和稳定性。 <br /><br />总结: <br />Boehm-Demers-Weiser Garbage Collector是一个保守的C/C++垃圾收集器，提供动态内存分配，有效简化了内存管理，并提高了开发效率。 <div>
【Boehm-Demers-Weiser Garbage Collector：保守的 C/C++ 垃圾收集器，可以在使用时动态分配内存】'Boehm-Demers-Weiser Garbage Collector - The Boehm-Demers-Weiser conservative C/C++ Garbage Collector (bdwgc, also known as bdw-gc, boehm-gc, libgc)' GitHub: github.com/ivmai/bdwgc <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23C%2B%2B%23"><span class="surl-text">#C++#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoike185ehj21740qcq7i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 12:58:19 GMT</pubDate>
</item>
<item>
<title>【OpenAI Streaming：一个 Python 库，提供易于使用的 Pythonic 接口，支持 OpenAI 的基于生成器的 Streaming，并支持回调机制来处理流内容】'OpenAI Streaming ...</title>
<link>https://weibo.com/1402400261/O8EDWAapl</link>
<guid>https://weibo.com/1402400261/O8EDWAapl</guid>
<content:encoded><![CDATA[
<div> OpenAI, Streaming, Python, 接口, 生成器, 回调, Github, 库, 简化, 处理<br />
<br />
要点1: 介绍了一个名为OpenAI Streaming的Python库，用于与OpenAI的基于生成器的Streaming API进行交互。<br />
要点2: 该库提供了易于使用的Pythonic接口，支持生成器来处理流内容。<br />
要点3: OpenAI Streaming还支持使用回调机制来处理流内容，使流处理更加灵活。<br />
要点4: 该库的代码托管在GitHub上，地址为github.com/AlmogBaku/openai-streaming。<br />
要点5: OpenAI Streaming旨在简化与OpenAI的流API的交互，让用户可以更轻松地使用Python来处理和管理流数据。<br />
<br />
总结: <br />
介绍了一个名为OpenAI Streaming的Python库，用于与OpenAI的基于生成器的Streaming API进行交互。该库提供了易于使用的Pythonic接口，支持生成器来处理流内容。OpenAI Streaming还支持使用回调机制来处理流内容，使流处理更加灵活。该库的代码托管在GitHub上，地址为github.com/AlmogBaku/openai-streaming。OpenAI Streaming旨在简化与OpenAI的流API的交互，让用户可以更轻松地使用Python来处理和管理流数据。 <div>
【OpenAI Streaming：一个 Python 库，提供易于使用的 Pythonic 接口，支持 OpenAI 的基于生成器的 Streaming，并支持回调机制来处理流内容】'OpenAI Streaming - Work with OpenAI's streaming API at ease with Python generators' GitHub: github.com/AlmogBaku/openai-streaming <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoikbwbdraj21740t2dkd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 12:56:42 GMT</pubDate>
</item>
<item>
<title>【torchdbg：PyTorch 操作的跟踪器和反应式 UI，用于以调试器的形式可视化跟踪】'torchdbg - PyTorch centric eager mode debugger' GitHub: github.com/ezyang/...</title>
<link>https://weibo.com/1402400261/O8EDkyBfv</link>
<guid>https://weibo.com/1402400261/O8EDkyBfv</guid>
<content:encoded><![CDATA[
<div> torchdbg, PyTorch, 操作, 跟踪器, 反应式, UI, 调试器, 可视化, GitHub

<br /><br />总结:
torchdbg是一个针对PyTorch的eager模式调试器，通过跟踪器和反应式UI可视化操作。用户可以在GitHub上找到该项目。 <div>
【torchdbg：PyTorch 操作的跟踪器和反应式 UI，用于以调试器的形式可视化跟踪】'torchdbg - PyTorch centric eager mode debugger' GitHub: github.com/ezyang/torchdbg <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoikasc2j7j20u00v8n04.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 12:55:11 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@异步图书 送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O8yWi4P6D</link>
<guid>https://weibo.com/1402400261/O8yWi4P6D</guid>
<content:encoded><![CDATA[
<div> 大语言模型、前沿进展、科学家、工程师、学生、案例、庖丁解牛、可可粉、转发、评论

<br /><br />总结:
本文介绍了一本名为《大语言模型：基础与前沿》的书籍活动，截止时间为2024年4月12日12:00。该书全面深入地介绍了大语言模型及其前沿进展，适合科学家、工程师和学生参考。作者摒弃了纯理论的说教模式，而是通过案例和庖丁解牛的方式帮助读者理解与认识大语言模型。参与活动的方式是转发+评论，可可粉转发即可参与。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%BC%82%E6%AD%A5%E5%9B%BE%E4%B9%A6">@异步图书</a>  送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。摒弃了纯理论的说教模式，从案例入手， 采用庖丁解牛的方式帮助读者理解与认识大语言模型。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019331269755053"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef8oboqij20ga0m8q8p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9segl7j20m90m9q6z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9t5km0j20m90m942f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef9tq2esj20m90m9gpe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef9ugq5dj20m90m9dif.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 22:25:24 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O8yW6m9YP</link>
<guid>https://weibo.com/1402400261/O8yW6m9YP</guid>
<content:encoded><![CDATA[
<div> LangChain, 实战, 初学者, 大语言模型, LangChain生态系统, LangServe, LangSmith, 生成式人工智能, 应用场景, LCEL

<br /><br />总结:
LangChain团队推出了《LangChain实战》这本书，专为初学者和对LangChain应用及大语言模型感兴趣的开发者编写。书中介绍了LangChain 0.1版本，配套600分钟详解视频，重点探讨了多个核心应用场景和LCEL的应用方式。此外，书籍详细探讨了LangChain、LangServe和LangSmith等概念，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。截止日期为2024年4月11日中午12点，感兴趣的读者可参与转发+评论活动，有机会获得《LangChain实战》这本书。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a> <a href="https://shop.sc.weibo.com/h5/goods/index?iid=110014024002610004661854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">LangChain实战：从原型到生产，动手打造 LLM 应用</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5ywtixj20ku0zzdmx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hofl98oom9j207q0a0jrm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 22:24:56 GMT</pubDate>
</item>
<item>
<title>今日推介(第1368期)：大型语言模型在手机GPU上的高效部署、用紧凑语言模型加速多模态基础模型、基于思维链提示的文本-语音合成鲁棒编解码器语言建模、高性能卷积...</title>
<link>https://weibo.com/1402400261/O8yVNDx0K</link>
<guid>https://weibo.com/1402400261/O8yVNDx0K</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、手机GPU、高效部署、紧凑语言模型、多模态基础模型、思维链提示、文本-语音合成、鲁棒编解码器、高性能卷积神经网络、语言模型、事实可变性

总结:<br /><br />本文介绍了在手机GPU上高效部署大型语言模型以及用紧凑语言模型加速多模态基础模型的方法。其中，基于思维链提示的文本-语音合成鲁棒编解码器语言建模方法，能够提高合成语音的质量和准确性。此外，研究指出高性能卷积神经网络在语言模型方面的重要性，以及语言模型事实可变性的研究意义。通过这些方法和研究，可以提升语言模型的性能和效率。 <div>
今日推介(第1368期)：大型语言模型在手机GPU上的高效部署、用紧凑语言模型加速多模态基础模型、基于思维链提示的文本-语音合成鲁棒编解码器语言建模、高性能卷积神经网络研究、语言模型事实可变性研究 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/691003771"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.7)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hohv469uhmj21b60n4jup.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hohv49nu91j20r20n2tal.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hohv4c8t0pj219d0u0798.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hohv4enzxuj20wt0u0wjm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hohv4hqugzj20qy174789.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 22:24:11 GMT</pubDate>
</item>
<item>
<title>[CV] Are We on the Right Way for Evaluating Large Vision-Language Models? 网页链接 提出高质量的MMStar多模态基准和多模态收益与泄露指标，全面评估模型视...</title>
<link>https://weibo.com/1402400261/O8ySYC7Nb</link>
<guid>https://weibo.com/1402400261/O8ySYC7Nb</guid>
<content:encoded><![CDATA[
<div> 关键词: MMStar, 多模态基准, 多模态收益与泄露指标, 模型视觉理解能力, 训练策略

总结:<br /><br />本文提出了对大型视觉语言模型进行评估的方法。通过提出高质量的MMStar多模态基准和多模态收益与泄露指标，全面评估模型的视觉理解能力，并分析训练策略。这一方法有助于确定模型的性能和指导未来的研究方向。 <div>
[CV] Are We on the Right Way for Evaluating Large Vision-Language Models?  <br /><a href="https://arxiv.org/abs/2403.20330"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出高质量的MMStar多模态基准和多模态收益与泄露指标，全面评估模型视觉理解能力并分析训练策略。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hohux9mt20j20vc1ayqhu.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hohuxa1z4ij21gq0xsh1a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hohuxarhifj21gq1cgkah.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 22:17:15 GMT</pubDate>
</item>
<item>
<title>[LG] Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak Attacks? 网页链接 通过构建评估基准并在多种语言模型上部署已知攻击，深入分析...</title>
<link>https://weibo.com/1402400261/O8yQY7zLr</link>
<guid>https://weibo.com/1402400261/O8yQY7zLr</guid>
<content:encoded><![CDATA[
<div> 关键词: 评估基准, 语言模型, 攻击, 鲁棒性, GPT-4, 文字越狱, 视觉越狱

总结:<br /><br />本研究通过构建评估基准并在多种语言模型上部署已知攻击，分析了专有模型GPT-4和开源模型在抵御文字及视觉越狱攻击方面的鲁棒性。研究展示了对GPT-4V是否能够抵御uni和multi-modal jailbreak攻击进行了深入的探究。结果表明，GPT-4对抗这些攻击具有一定的鲁棒性，但在某些情况下仍存在安全风险，需要进一步研究和加强防护措施。这项研究对未来提升语言模型的安全性和鲁棒性具有一定的指导意义。 <div>
[LG] Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak Attacks?  <br /><a href="https://arxiv.org/abs/2404.03411"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过构建评估基准并在多种语言模型上部署已知攻击，深入分析了专有模型GPT-4和开源模型抵御文字及视觉越狱攻击的鲁棒性。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohus5l7kfj20uy1dsqkp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 22:12:18 GMT</pubDate>
</item>
<item>
<title>[CV] MM3DGS SLAM: Multi-modal 3D Gaussian Splatting for SLAM Using Vision, Depth, and Inertial Measurements 网页链接 提出一种将单目视觉、深度与惯性测...</title>
<link>https://weibo.com/1402400261/O8yMxsVMF</link>
<guid>https://weibo.com/1402400261/O8yMxsVMF</guid>
<content:encoded><![CDATA[
<div> 关键词: MM3DGS SLAM, 多模态, 单目视觉, 深度测量, 惯性测量, 实时, 高质量重建, 相机定位, 增量式<br />

总结:<br />
本文提出了一种称为MM3DGS SLAM的多模态3D Gaussian Splatting技术，利用单目视觉、深度测量和惯性测量相结合的方法实现实时的SLAM。该方法能够实现高质量的增量式重建和准确的相机定位。通过结合多种传感器信息，可以提高重建的精度和速度。在实验中，作者展示了该方法在各种场景下的有效性和稳定性。这种多模态融合的SLAM方法为实时定位和建图提供了一个新的技术途径。 <div>
[CV]  MM3DGS SLAM: Multi-modal 3D Gaussian Splatting for SLAM Using Vision, Depth, and Inertial Measurements  <br /><a href="https://arxiv.org/abs/2404.00923"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />提出一种将单目视觉、深度与惯性测量相结合的实时3D SLAM方法，可以实现高质量的增量式重建与准确的相机定位。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hohugrida8j213s1d61cz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hohugs09axj20ve0nkn36.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hohugsavb6j20vo0h2jvw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 22:01:23 GMT</pubDate>
</item>
<item>
<title>[CV] 94% on CIFAR-10 in 3.29 Seconds on a Single GPU 网页链接 提出多项技术的组合实现CIFAR-10数据集上快速高效的神经网络训练，取得新的最先进训练速度。 [...</title>
<link>https://weibo.com/1402400261/O8yKpf4By</link>
<guid>https://weibo.com/1402400261/O8yKpf4By</guid>
<content:encoded><![CDATA[
<div> 关键词: CIFAR-10, 数据集, 神经网络训练, 最先进训练速度

总结:<br /><br />总结: 本研究在CIFAR-10数据集上利用多项技术的组合，实现了快速高效的神经网络训练，取得了新的最先进训练速度。研究结果显示，在单个GPU上，达到了94%的准确率，仅需3.29秒的训练时间。这标志着在数据集上实现了显著的性能提升，为神经网络训练的效率和速度带来了新的突破。通过该研究，提出的方法将为未来的深度学习研究和实践提供有益的参考和指导。 <div>
[CV] 94% on CIFAR-10 in 3.29 Seconds on a Single GPU  <br /><a href="https://arxiv.org/abs/2404.00498"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />提出多项技术的组合实现CIFAR-10数据集上快速高效的神经网络训练，取得新的最先进训练速度。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohubaros3j20wm1cmdvk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohubba8z9j21ou0taaqg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hohubbqatij20li0ig0u9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 21:56:08 GMT</pubDate>
</item>
<item>
<title>通过MULAN基准测试集发现语言模型对事实可变性的编码提供了时间感知的新证据，并且可变事实比不可变事实更易于更新。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《MuLan:...</title>
<link>https://weibo.com/1402400261/O8yH9gVHv</link>
<guid>https://weibo.com/1402400261/O8yH9gVHv</guid>
<content:encoded><![CDATA[
<div> 时间感知、事实可变性、语言模型、MuLan、编码、更新、证据、基准测试集、易于更新、University of Copenhagen & Google DeepMind

<br /><br />总结:
研究发现，语言模型对事实可变性的编码在时间感知方面提供了新证据。通过MULAN基准测试集，发现可变事实比不可变事实更易于更新。这项研究由哥本哈根大学和谷歌DeepMind共同进行。 <div>
通过MULAN基准测试集发现语言模型对事实可变性的编码提供了时间感知的新证据，并且可变事实比不可变事实更易于更新。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《MuLan: A Study of Fact Mutability in Language Models》C Fierro, N Garneau, E Bugliarello, Y Kementchedjhieva, A Søgaard [University of Copenhagen &amp; Google DeepMind] (2024) <a href="https://arxiv.org/abs/2404.03036"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohtwyssjlj20ne0w0n4f.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hohtwzg7nej20qy174afd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hohtwzmppqj21hk0mmgr2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohtwzse7xj20r20msacs.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 21:48:06 GMT</pubDate>
</item>
<item>
<title>[CL]《MuLan: A Study of Fact Mutability in Language Models》C Fierro, N Garneau, E Bugliarello, Y Kementchedjhieva, A Søgaard [University of Copenhag...</title>
<link>https://weibo.com/1402400261/O8yH5EFU5</link>
<guid>https://weibo.com/1402400261/O8yH5EFU5</guid>
<content:encoded><![CDATA[
<div> 关键词: MuLan, 语言模型, 可变性, 研究, 事实, University of Copenhagen, Google DeepMind

总结:<br /><br />这篇文章由哥本哈根大学和Google DeepMind的研究人员合作撰写，研究了语言模型中事实可变性的情况。他们以木兰为例，探讨了语言模型中事实的变化和可塑性。研究发现，语言模型在处理事实时存在一定的可变性，可能导致信息失真或误导。通过对不同模型的比较和分析，研究人员提出了一些改进建议，以提高语言模型对事实的处理准确性和可靠性。这项研究对于理解语言模型的运作机制和改进其性能具有重要意义。 <div>
[CL]《MuLan: A Study of Fact Mutability in Language Models》C Fierro, N Garneau, E Bugliarello, Y Kementchedjhieva, A Søgaard [University of Copenhagen &amp; Google DeepMind] (2024) <a href="https://arxiv.org/abs/2404.03036"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohtwyssjlj20ne0w0n4f.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hohtwzg7nej20qy174afd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hohtwzmppqj21hk0mmgr2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohtwzse7xj20r20msacs.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 21:47:58 GMT</pubDate>
</item>
<item>
<title>提出效率差距图等新的分析工具，设计了同时优化模型效率和计算效率的ConvFirstNet，其延迟相比ConvNeXt降低4倍，实现了卷积神经网络效率的重要进步。 - 转发 @爱...</title>
<link>https://weibo.com/1402400261/O8yDEDUuy</link>
<guid>https://weibo.com/1402400261/O8yDEDUuy</guid>
<content:encoded><![CDATA[
<div> ConvFirstNet, 优化模型效率, 计算效率, 延迟降低, 卷积神经网络, 差距图, 分析工具

总结:
2014年至今，深度学习中卷积神经网络成为重要技术，但其效率和计算效率问题一直存在。作者在这篇论文中提出了效率差距图等新的分析工具，设计了ConvFirstNet，优化了模型效率和计算效率，将延迟降低了4倍，实现了对卷积神经网络效率的重要进步。通过这项研究，人们可以更好地理解卷积神经网络的效率问题，并为未来的研究和实践提供指导。 <div>
提出效率差距图等新的分析工具，设计了同时优化模型效率和计算效率的ConvFirstNet，其延迟相比ConvNeXt降低4倍，实现了卷积神经网络效率的重要进步。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《On the Efficiency of Convolutional Neural Networks》A Lavin [Phantom AI] (2024) <a href="https://arxiv.org/abs/2404.03617"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hohtjlzwlij20ua1iikar.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hohtjmou3dj218a14ik0q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohtjn18c9j210u1bgguu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohtjn4nnrj210q11agts.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hohttwco5ij20zt15ndkx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hohttwbvr9j21000djgo3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hohttwbvnoj20zx0kntbx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hohttwcqnij20zz1fhwj0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hohttwbvkaj21000lpdj2.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 21:39:30 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.6)》 爱可可微博热门分享(4.6) [图片]</title>
<link>https://weibo.com/1402400261/O8vSgb1S2</link>
<guid>https://weibo.com/1402400261/O8vSgb1S2</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 分享, 爱可可, 4.6, 爱情, 情感, 大V, 网友

<br /><br />总结:
爱可可微博热门分享(4.6)介绍了一些关于爱情和情感的话题，吸引了众多网友关注。大V分享的内容引起了热议，让人们反思自身情感世界，并分享各自的看法和经历。微博上热门话题的讨论热度持续高涨，展现了网友们对爱情话题的浓厚兴趣。 <div>
《爱可可微博热门分享(4.6)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405020291523805285"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.6)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohhmjyi7uj20kf0bh75r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 14:37:14 GMT</pubDate>
</item>
<item>
<title>【AI生成内容泛滥冲击Google Books】- Google Books作为索引已出版资料的重要学术工具，正在收录大量低质量、由AI生成的书籍内容。 - 这些AI生成的书籍会出现在G...</title>
<link>https://weibo.com/1402400261/O8ujEAJtY</link>
<guid>https://weibo.com/1402400261/O8ujEAJtY</guid>
<content:encoded><![CDATA[
<div> Google Books, AI生成内容, 学术工具, 低质量内容, Google Ngram Viewer, 学术界, 索引, 垃圾内容, 技术挑战, AI技术

<br /><br />总结:
Google Books作为重要学术工具，收录了大量AI生成的低质量书籍内容，可能影响Google Ngram Viewer的准确性。在AI技术迅速发展的背景下，学术界应加强对付AI生成内容的措施。谷歌官方表示将删除低质量内容，但AI生成内容的泛滥令学术工具和搜索引擎受到前所未有的冲击。学术界需重视海量AI垃圾内容稀释优质内容、误导读者和破坏学术生态的问题。识别AI生成内容是技术挑战，需要发展智能AI技术来抵制恶意生成内容。全方位合作加强对AI滥用监管，建立科学的AI治理体系。 <div>
【AI生成内容泛滥冲击Google Books】<br />- Google Books作为索引已出版资料的重要学术工具，正在收录大量低质量、由AI生成的书籍内容。  <br />- 这些AI生成的书籍会出现在Google Books的搜索结果中。 <br />- 大量索引AI生成的垃圾内容，可能会影响Google Ngram Viewer的结果准确性。Ngram Viewer是研究人员用来追踪历史语言使用情况的重要工具，它基于Google Books的数据。  <br />- 这反映出在AI技术快速发展的背景下，学术界对付AI生成的大规模垃圾内容还缺乏应对之策。图书出版和学术搜索工具的把关机制亟待升级，以应对AI带来的挑战。  <br />- 谷歌官方表示会删除所有低质量内容，无论是AI还是人工创作。但AI生成内容的泛滥，对搜索引擎和学术工具构成了前所未有的冲击。  <br /><br />思考：  <br />- AI生成内容正以超乎想象的速度渗透到方方面面。作为知识索引的基础设施，Google Books这样的工具首当其冲受到冲击，凸显出AI时代学术规范和内容把关面临的困境。  <br />- 海量的AI垃圾内容会稀释优质内容的密度，误导读者，破坏学术生态。Ngram Viewer等研究工具也会受到污染，影响学术研究的准确性。学术界需要高度重视这一问题。  <br />- 识别AI生成内容本身就是一个技术挑战。传统的人工审核已然不敷使用，平台和工具方需要研发更智能的AI技术来对抗恶意的AI生成内容。  <br />- 从源头治理，完善AI伦理规范，加强对AI滥用的监管，需要学界、业界、政府多方合力。在拥抱AI红利的同时，也要警惕其负面影响，建立科学的AI治理体系。<img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hohaqzffl3j218z0u0dhi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 10:39:14 GMT</pubDate>
</item>
<item>
<title>【Meta率先扩大AI内容标记范围】Meta宣布将从5月开始扩大对人工智能生成内容的标记范围，主要变化包括： - 标记对象从仅视频扩大到视频、音频和图像等更多种类的...</title>
<link>https://weibo.com/1402400261/O8ufU9kYU</link>
<guid>https://weibo.com/1402400261/O8ufU9kYU</guid>
<content:encoded><![CDATA[
<div> 扩大标记范围, 人工智能, 内容, 标签, Meta, 政策, 透明度, 监督委员会, 深度伪造, 风险

<br /><br />总结:
Meta宣布从5月开始扩大对人工智能生成内容的标记范围，包括视频、音频、图像等多种内容形式。标签生成方式多样，对存在误导公众风险的内容将使用更显著的标签。7月起，Meta将不再删除合规的AI生成内容，而是通过标签标注背景信息。但若内容违规，则无论AI或人工创作均会被删除。调整旨在提高透明度，回应社会对深度伪造技术滥用的担忧。Meta独立监督委员会的反馈促使其更新标签政策。新政策有助于加强公众对AI内容的辨识，平衡创新应用与风险，并为整个行业树立标杆。然而，仅靠标签仍难以根本解决AI内容造假问题，各平台应进一步完善审核机制，加强行业自律与监管合作。 <div>
【Meta率先扩大AI内容标记范围】<br />Meta宣布将从5月开始扩大对人工智能生成内容的标记范围，主要变化包括：  <br />- 标记对象从仅视频扩大到视频、音频和图像等更多种类的内容。  <br />- 标签可通过用户自行披露、事实核查人员建议或Meta检测AI内容的隐形标记等多种方式生成。  <br />- 对于被认为存在误导公众风险的AI内容，将使用更加显著的标签。  <br />- 7月起，Meta将不再默认删除合规的AI生成内容，而是通过标签标注背景信息，以平衡言论自由和内容真实性。  <br />- 但如内容违反平台其他规定如反对选民干预、欺凌骚扰、暴力煽动等，则无论AI或人工创作都将予以删除。  <br /><br />原因与影响：<br />- Meta承认其原有政策过于狭隘，难以应对日益泛滥、形式多样的AI生成内容。此次调整主要是为了提高透明度，更好地回应外界对深度伪造等技术滥用的担忧。  <br />- Meta独立监督委员会此前就敦促其更新标签政策，此举是对委员会反馈的积极回应。  <br />- 业内普遍认为，Meta的新政策有助于在不过度审查的前提下，加强公众对AI生成内容的辨识，平衡创新应用与潜在风险，为业界树立了标杆。  <br />- 但也有观点指出，单靠标签仍难以从根本上遏制AI内容造假滥用，各平台还需进一步完善内容审核机制，加强行业自律与监管协同。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hohahe3eioj20jr0b3t9e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 10:30:00 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Generalized Schrödinger Bridge Matching》(ICLR 2024) GitHub: github.com/facebookresearch/generalized-schrodinger-bridge-matching...</title>
<link>https://weibo.com/1402400261/O8u3hzPEl</link>
<guid>https://weibo.com/1402400261/O8u3hzPEl</guid>
<content:encoded><![CDATA[
<div> Schrödinger Bridge Matching, Generalized, Algorithm, Optimization, Machine Learning, Deep Learning, ICLR 2024, Facebook Research, GitHub

<br />
提出一种广义Schrödinger桥匹配方法，用于优化算法的设计。通过对齐两个分布来实现数据匹配，能够在机器学习和深度学习领域获得更好的效果。该方法在ICLR 2024上得到了应用，并由Facebook Research团队开发。相关代码已经开源在GitHub上。

<br /><br />总结:Schrodinger Bridge Matching是一种新的数据匹配方法，可在深度学习和机器学习中应用，并在ICLR 2024年会议上展示。由Facebook Research团队实现并开源。 <div>
几篇论文实现代码：<br />《Generalized Schrödinger Bridge Matching》(ICLR 2024) GitHub: github.com/facebookresearch/generalized-schrodinger-bridge-matching<br />《Retrieval-Augmented Layout Transformer for Content-Aware Layout Generation》(CVPR 2024) GitHub: github.com/CyberAgentAILab/RALF [fig4]<br />《SSR-Encoder: Encoding Selective Subject Representation for Subject-Driven Generation》(CVPR 2024) GitHub: github.com/Xiaojiu-z/SSR_Encoder [fig6]<br />《AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent》(2024) GitHub: github.com/THUDM/AutoWebGLM [fig1]<br />《DN-Splatter: Depth and Normal Priors for Gaussian Splatting and Meshing》(2024) GitHub: github.com/maturk/dn-splatter<br />《MiniGPT4-Video: Advancing Multimodal LLMs for Video Understanding with Interleaved Visual-Textual Tokens》(2024) GitHub: github.com/Vision-CAIR/MiniGPT4-video [fig2]<br />《Placing Objects in Context via Inpainting for Out-of-distribution Segmentation》(2024) GitHub: github.com/naver/poc [fig3]<br />《CLAP NQ: Cohesive Long-form Answers from Passages in Natural Questions》(2024) GitHub: github.com/primeqa/clapnq<br />《CodeEditorBench: Evaluating Code Editing Capability of Large Language Models》(2024) GitHub: github.com/CodeEditorBench/CodeEditorBench [fig5]<br />《The Hidden Attention of Mamba Models》(2024) GitHub: github.com/AmeenAli/HiddenMambaAttn [fig7]<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoh4p0ibcoj22la0yohdt.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoh631ezzhj22cm11lk22.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoh64h5d9dj21u20hx1e6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoh7gpj4s9j21ds0gy1kx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoh7m5y4xqj22b6170kjl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoh7p7jpxhj24te154b2a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoh9eyqbaij23gg1gxnj3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 09:58:54 GMT</pubDate>
</item>
<item>
<title>'MaxKB - 基于 LLM 大语言模型的知识库问答系统，开箱即用，支持快速嵌入到第三方业务系统' GitHub: github.com/1Panel-dev/MaxKB #开源# #机器学习# #人工智能#...</title>
<link>https://weibo.com/1402400261/O8u2bg0zt</link>
<guid>https://weibo.com/1402400261/O8u2bg0zt</guid>
<content:encoded><![CDATA[
<div> 知识库、问答系统、LLM、大语言模型、开箱即用、第三方业务系统、GitHub、MaxKB、快速嵌入、基于<br />
<br />
提供了一个基于LLM大语言模型的知识库问答系统MaxKB，用户可直接使用，并支持快速嵌入到第三方业务系统中。该系统的源代码可在GitHub上找到，地址为github.com/1Panel-dev/MaxKB。MaxKB的特点包括开箱即用，同时支持定制化和灵活的部署，适用于各种需求。MaxKB使用LLM技术作为核心引擎，能够对用户提出的问题进行准确的回答，大大提升了信息检索效率。用户可以根据自身需求对系统进行定制和优化，以更好地满足业务需求。MaxKB的开源性和易用性使得它成为了知识管理和问答解决方案中的理想选择。 <br /><br />总结: <div>
'MaxKB - 基于 LLM 大语言模型的知识库问答系统，开箱即用，支持快速嵌入到第三方业务系统' GitHub: github.com/1Panel-dev/MaxKB <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoh9i596h1j21h50u0adr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoh9i66189j21hr0u0wl1.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoh9i7gy1pj21hf0u041f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 09:56:11 GMT</pubDate>
</item>
<item>
<title>【BeeTrove：349K 个 OpenAI 自定义 GPTs 的数据】'BeeTrove - OpenAI GPTs Statistics Dataset' GitHub: github.com/beetrove/openai-gpts-data #开源# #机器学...</title>
<link>https://weibo.com/1402400261/O8tTe2lcP</link>
<guid>https://weibo.com/1402400261/O8tTe2lcP</guid>
<content:encoded><![CDATA[
<div> OpenAI, BeeTrove, 自定义GPTs, 数据, 统计, 数据集, GitHub <br />
<br />
提供了关于OpenAI自定义GPTs数据的统计信息，项目名为BeeTrove。数据可以在GitHub上找到。这个数据集包含了大量有关OpenAI GPTs的信息，可以用于各种研究和应用。<br />
数据集由BeeTrove创建和维护，对于研究人员和开发者来说是非常有用的资源。通过这个数据集，用户可以深入了解OpenAI自定义GPTs的特性和应用场景。GitHub上提供了详细的信息和文档，方便用户使用和下载数据。<br />
总结: <br />提供了关于OpenAI自定义GPTs的统计数据，包含在BeeTrove项目中。数据集对于研究和开发具有重要意义，用户可以在GitHub上找到详细信息和文档，方便使用。<br /> <div>
【BeeTrove：349K 个 OpenAI 自定义 GPTs 的数据】'BeeTrove - OpenAI GPTs Statistics Dataset' GitHub: github.com/beetrove/openai-gpts-data <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoh8uwkwlwj20u01040wb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 09:34:07 GMT</pubDate>
</item>
<item>
<title>【SCIN Dataset：SCIN 数据集包含来自美国互联网用户的 10,000+ 张皮肤疾病图像】'SCIN Dataset - The SCIN dataset contains 10,000+ images of dermatology co...</title>
<link>https://weibo.com/1402400261/O8tSg6xbJ</link>
<guid>https://weibo.com/1402400261/O8tSg6xbJ</guid>
<content:encoded><![CDATA[
<div> 皮肤疾病图像 数据集 美国 互联网 用户 10000+<br />
<br />
SCIN 数据集包含来自美国互联网用户的 10,000+ 张皮肤疾病图像，包括自我报告的人口统计信息、症状信息和皮肤科医生的标签。数据集还包含了估计的菲茨帕特里克皮肤类型和教士肤色。<br />
总结: 该SCIN数据集包含10,000+张美国互联网用户的皮肤疾病图像，其中包括自我报告的人口统计信息、症状信息和皮肤科医生的标签，以及估计的菲茨帕特里克皮肤类型和教士肤色。 <div>
【SCIN Dataset：SCIN 数据集包含来自美国互联网用户的 10,000+ 张皮肤疾病图像】'SCIN Dataset - The SCIN dataset contains 10,000+ images of dermatology conditions, crowdsourced with informed consent from US internet users. Contributions include self-reported demographic and symptom information and dermatologist labels. The dataset also contains estimated Fitzpatrick skin type and Monk Skin Tone.' GitHub: github.com/google-research-datasets/scin <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoh8ss2ysej20x50u0n39.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 09:31:43 GMT</pubDate>
</item>
<item>
<title>【Multi-agent Quadruped Environment：多Agent四足机器人环境，支持定位控制或仅高层规划学习】'Multi-agent Quadruped Environment - A multi-agent quadruped...</title>
<link>https://weibo.com/1402400261/O8tQxEkO3</link>
<guid>https://weibo.com/1402400261/O8tQxEkO3</guid>
<content:encoded><![CDATA[
<div> 多Agent四足机器人环境、支持定位控制、高层规划学习、GitHub、ziyanx02、环境、学习、机器人、控制、规划

<br /><br />总结:
这是一个支持多Agent四足机器人环境的项目，能够学习到定位控制或高层规划。通过GitHub可以获取相关信息，作者是ziyanx02。这个环境可以用于机器人的学习、控制和规划。 <div>
【Multi-agent Quadruped Environment：多Agent四足机器人环境，支持定位控制或仅高层规划学习】'Multi-agent Quadruped Environment - A multi-agent quadruped environment, supporting learning of both locomotion control or only high-level planning.' GitHub: github.com/ziyanx02/multiagent-quadruped-environment <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoh8oe0q3mj20xu0u0tdi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 09:27:31 GMT</pubDate>
</item>
<item>
<title>【microWakeWord：基于 TensorFlow 的唤醒词检测训练框架，使用合成样本生成适用于某些微控制器】'microWakeWord - A TensorFlow based wake word detection tra...</title>
<link>https://weibo.com/1402400261/O8tOj9RiR</link>
<guid>https://weibo.com/1402400261/O8tOj9RiR</guid>
<content:encoded><![CDATA[
<div> TensorFlow, 唤醒词检测, 训练框架, 合成样本, 微控制器, GitHub, microWakeWord, 训练, 框架, 适用

总结:<br /><br />本文介绍了基于 TensorFlow 的唤醒词检测训练框架 microWakeWord，该框架利用合成样本生成，适用于某些微控制器。用户可以在GitHub上找到框架的代码和文档。这个框架提供了一种训练唤醒词检测模型的方法，特别适用于资源有限的硬件环境。通过生成合成样本，用户可以有效地训练模型，以在特定的微控制器上实现唤醒词检测功能。框架的设计非常灵活，可以根据用户的需求进行定制化。它为开发唤醒词检测应用提供了一个方便且高效的解决方案。 <div>
【microWakeWord：基于 TensorFlow 的唤醒词检测训练框架，使用合成样本生成适用于某些微控制器】'microWakeWord - A TensorFlow based wake word detection training framework using synthetic sample generation suitable for certain microcontrollers.' GitHub: github.com/kahrendt/microWakeWord <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoh8inc9dnj211l0u0q8q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 09:22:00 GMT</pubDate>
</item>
<item>
<title>【Rule-based Retrieval：一个 Python 软件包，用于创建和管理检索增强生成 (RAG) 应用，支持高级过滤功能，集成了 OpenAI 和 Pinecone，用于文本生成和高效的向...</title>
<link>https://weibo.com/1402400261/O8tEkBkex</link>
<guid>https://weibo.com/1402400261/O8tEkBkex</guid>
<content:encoded><![CDATA[
<div> Rule-based Retrieval, Python, 软件包, 创建, 管理, 检索增强生成, RAG, 应用, 高级过滤功能, OpenAI, Pinecone

<br /><br />总结:
Rule-based Retrieval 是一个 Python 软件包，可帮助用户创建和管理检索增强生成（RAG）应用，并具有高级过滤功能。该软件包与 OpenAI 无缝集成，用于文本生成，同时也与 Pinecone 集成，实现高效的向量数据库管理。该软件包为用户提供了便捷的工具和功能，使其能够更高效地处理文本生成和数据管理任务。 <div>
【Rule-based Retrieval：一个 Python 软件包，用于创建和管理检索增强生成 (RAG) 应用，支持高级过滤功能，集成了 OpenAI 和 Pinecone，用于文本生成和高效的向量数据库管理】'Rule-based Retrieval - The Rule-based Retrieval package is a Python package that enables you to create and manage Retrieval Augmented Generation (RAG) applications with advanced filtering capabilities. It seamlessly integrates with OpenAI for text generation and Pinecone for efficient vector database management.' GitHub: github.com/whyhow-ai/rule-based-retrieval <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoh7t32frfj21740k6q6j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 08:57:26 GMT</pubDate>
</item>
<item>
<title>【从0到1构建一个MiniLLM】'build_MiniLLM_from_scratch - 从0到1构建一个MiniLLM' GitHub: github.com/Tongjilibo/build_MiniLLM_from_scratch #开源# #机器学...</title>
<link>https://weibo.com/1402400261/O8tAX7jU3</link>
<guid>https://weibo.com/1402400261/O8tAX7jU3</guid>
<content:encoded><![CDATA[
<div> MiniLLM, 从0到1构建, GitHub, Tongjilibo, 代码, 学习, 自建, 机器学习, 模型, 训练

<br /><br />总结:
该文章详细介绍了如何从零开始构建一个MiniLLM，作者分享了在GitHub上的项目链接，逐步讲解了建立MiniLLM所需的步骤和方法。通过这篇文章，读者可以深入学习和了解如何自建机器学习模型，包括代码编写、训练模型等方面的知识。这对于想要深入学习机器学习的人来说是一篇很有价值的文章。 <div>
【从0到1构建一个MiniLLM】'build_MiniLLM_from_scratch - 从0到1构建一个MiniLLM' GitHub: github.com/Tongjilibo/build_MiniLLM_from_scratch <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoh7kfnvv1j219f0u00y7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 08:49:06 GMT</pubDate>
</item>
<item>
<title>【mamba-tiny：简单、紧凑的 Mamba SSM（State Space Model）在 PyTorch 中的实现】'mamba-tiny - Simple, minimal implementation of the Mamba SSM in one pyt...</title>
<link>https://weibo.com/1402400261/O8sSegIG5</link>
<guid>https://weibo.com/1402400261/O8sSegIG5</guid>
<content:encoded><![CDATA[
<div> 简单、紧凑、Mamba SSM、PyTorch、实现、GitHub、PeaBrane、efficient、associative scans

<br /><br />总结:
本文介绍了在PyTorch中实现简单、紧凑的Mamba SSM（State Space Model）的方法，作者提供了一个名为mamba-tiny的项目，该项目在一个pytorch文件中实现了Mamba SSM。相比使用for循环，这种实现更加高效，但可能比使用关联扫描效率稍低。感兴趣的读者可以在GitHub上找到该项目，作者是PeaBrane。 <div>
【mamba-tiny：简单、紧凑的 Mamba SSM（State Space Model）在 PyTorch 中的实现】'mamba-tiny - Simple, minimal implementation of the Mamba SSM in one pytorch file. More efficient than using for loops, but probably less efficient than using associative scans' GitHub: github.com/PeaBrane/mamba-tiny <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoh4ds047xj20u00ufjvt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 06:58:55 GMT</pubDate>
</item>
<item>
<title>'StyleLLM 文风大模型 - StyleLLM文风大模型：基于大语言模型的文本风格迁移项目，提供了四个基于中国四大名著训练的模型。Text style transfer base on Large L...</title>
<link>https://weibo.com/1402400261/O8skhukz7</link>
<guid>https://weibo.com/1402400261/O8skhukz7</guid>
<content:encoded><![CDATA[
<div> StyleLLM、文本风格迁移、大语言模型、四大名著、训练模型、GitHub、文风大模型、Text style transfer、关键词提取

总结:<br /><br />StyleLLM 文风大模型是一个基于大语言模型的文本风格迁移项目，提供了四个训练模型，基于中国四大名著。该项目在GitHub上有代码仓库，用于实现文本风格转换。通过这个项目，用户可以通过大语言模型在不同风格的文本间进行转换，实现文本风格的转移。项目的研究对于文本风格迁移技术的发展和应用具有一定的参考意义。 <div>
'StyleLLM 文风大模型 - StyleLLM文风大模型：基于大语言模型的文本风格迁移项目，提供了四个基于中国四大名著训练的模型。Text style transfer base on Large Language Model' GitHub: github.com/stylellm/stylellm_models <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoh1y410w4j20vb0u0wl6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 05:35:16 GMT</pubDate>
</item>
<item>
<title>【RAG进化之路】- 近年来，RAG(检索增强生成)技术在提高语言模型的知识性、准确性等方面发挥着重要作用。RAG可以从外部知识库中检索相关信息，增强语言模型的生...</title>
<link>https://weibo.com/1402400261/O8q7fqGsi</link>
<guid>https://weibo.com/1402400261/O8q7fqGsi</guid>
<content:encoded><![CDATA[
<div> RAG, 检索增强生成, Naive RAG, Advanced RAG, Modular RAG, 外部知识库, 模块化, 管道化, 搜索模块, RAG-Fusion

<br /><br />总结:
近年来，RAG技术在提高语言模型的知识性、准确性等方面发挥着重要作用。RAG经历了从Naive RAG到Advanced RAG再到Modular RAG的进化过程。Naive RAG存在检索质量不高的问题，而Advanced RAG通过查询重写、细粒度分割等策略改进了此问题。Modular RAG具有模块化和管道化的架构，支持端到端的训练，成为当前的标准范式。其中的新模块如Search模块和RAG-Fusion模块进一步增强了RAG系统的适用性。总体来说，RAG技术的进化促进了语言模型的知识化，Modular RAG为当前RAG研究提供了重要方向。 <div>
【RAG进化之路】<br />- 近年来，RAG(检索增强生成)技术在提高语言模型的知识性、准确性等方面发挥着重要作用。RAG可以从外部知识库中检索相关信息，增强语言模型的生成能力。   <br />- RAG技术经历了从Naive RAG到Advanced RAG再到Modular RAG的进化。Naive RAG存在检索质量不高，生成容易出现幻觉等问题。Advanced RAG通过查询重写、细粒度分割等策略改进了Naive RAG。   <br />- Modular RAG具有模块化和管道化的架构，可以灵活组合不同模块来解决具体问题，如添加搜索模块等。Modular RAG支持端到端的训练，成为当前RAG应用的标准范式。   <br />- 文章还介绍了Modular RAG中的一些新模块，如Search模块可以利用生成的代码搜索知识图谱，RAG-Fusion模块可以扩展查询的视角。这些创新进一步增强了RAG系统的适用性。   <br />- 总体来说，RAG技术的进化优化了语言模型的知识化，是让语言模型更适合实际应用的关键技术进步。Modular RAG提供了模块化和可定制的方案，成为当前RAG研究的重要方向。<br />《Evolution of RAGs: Naive RAG, Advanced RAG, and Modular RAG Architectures - MarkTechPost》 <a href="https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hogs7b6j1sj21560p2jxi.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hogs7csd2cj213g0q8aef.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hogs7fi6s3j214i0k20ya.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 23:57:41 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@异步图书 送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O8pDdpdb8</link>
<guid>https://weibo.com/1402400261/O8pDdpdb8</guid>
<content:encoded><![CDATA[
<div> 大语言模型、前沿进展、科学家、工程师、学生、案例、庖丁解牛、理解、认识、赠书<br />
<br />
总结:本文介绍了一本《大语言模型：基础与前沿》的书籍赠送活动，参与者需转发+评论即可参与。该书全面深入地介绍了大语言模型及其前沿进展，适合科学家、工程师和学生参考。书籍摒弃了纯理论说教，而是从案例入手用庖丁解牛的方式帮助读者理解与认识大语言模型。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%BC%82%E6%AD%A5%E5%9B%BE%E4%B9%A6">@异步图书</a>  送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。摒弃了纯理论的说教模式，从案例入手， 采用庖丁解牛的方式帮助读者理解与认识大语言模型。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019331269755053"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef8oboqij20ga0m8q8p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9segl7j20m90m9q6z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9t5km0j20m90m942f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef9tq2esj20m90m9gpe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef9ugq5dj20m90m9dif.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 22:43:42 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O8pCZ8LXr</link>
<guid>https://weibo.com/1402400261/O8pCZ8LXr</guid>
<content:encoded><![CDATA[
<div> LangChain, LangServe, LangSmith, LLM, 初学者, 应用场景, 生态系统,生成式人工智能,开发者, LangChain团队

<br /><br />总结:
LangChain团队推出了《LangChain实战》这本书，专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写。本书基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并深入探讨了LCEL的应用方式。同时，围绕LangChain生态系统的概念，详细探讨了LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。截至2024.4.11 12:00，*可可粉*转发+评论即可参与送出3本《LangChain实战》的活动。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a> <a href="https://shop.sc.weibo.com/h5/goods/index?iid=110014024002610004661854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">LangChain实战：从原型到生产，动手打造 LLM 应用</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5ywtixj20ku0zzdmx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hofl98oom9j207q0a0jrm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 22:43:07 GMT</pubDate>
</item>
<item>
<title>今日推介(第1367期)：用神经压缩文本训练LLM、大型语言模型的演绎、归纳和溯因学习、基于经验合作机制的师生课程学习的再思考、语言模型的表示微调、人工智能与...</title>
<link>https://weibo.com/1402400261/O8pCNjvOY</link>
<guid>https://weibo.com/1402400261/O8pCNjvOY</guid>
<content:encoded><![CDATA[
<div> 神经压缩文本、LLM、大型语言模型、演绎、归纳、溯因学习、经验合作机制、师生课程学习、再思考、语言模型、表示微调、人工智能、知识坍缩问题

总结:<br />
本文介绍了使用神经压缩文本训练LLM和大型语言模型的演绎、归纳和溯因学习方法。同时探讨了基于经验合作机制的师生课程学习的再思考，以及语言模型的表示微调。最后讨论了人工智能与知识坍缩问题，为读者提供了对这些领域的深入了解。文章内容丰富，信息量大，是一篇值得一读的文章。 <div>
今日推介(第1367期)：用神经压缩文本训练LLM、大型语言模型的演绎、归纳和溯因学习、基于经验合作机制的师生课程学习的再思考、语言模型的表示微调、人工智能与知识坍缩问题 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/690889816"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hogq11a160j20zp0u00yg.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hogq13j4zoj20ti0z60zh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hogq186xffj21k80hcaec.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hogq1bd3eoj213s0u0dlu.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hogq1elhakj20s60r00vl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 22:42:39 GMT</pubDate>
</item>
<item>
<title>[CL] Blessing or curse? A survey on the Impact of Generative AI on Fake News 网页链接 通过结构化文献调研，全面系统地总结和分析了生成式AI在假新闻生成与...</title>
<link>https://weibo.com/1402400261/O8pzl1jvt</link>
<guid>https://weibo.com/1402400261/O8pzl1jvt</guid>
<content:encoded><![CDATA[
<div> 关键词: 生成式AI, 假新闻, 检测, 应用, 技术, 主题, 未来方向

总结:<br /><br />本文通过结构化文献调研，系统总结分析了生成式AI在假新闻生成与检测方面的应用现状。文章讨论了关键技术和主要课题，指出生成式AI在假新闻领域既能成为祝福，也可能带来诅咒。未来研究方向包括提高生成式AI的检测能力、加强对假新闻生成过程的监管等，有望帮助更好应对假新闻问题。 <div>
[CL] Blessing or curse? A survey on the Impact of Generative AI on Fake News  <br /><a href="https://arxiv.org/abs/2404.03021"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过结构化文献调研，全面系统地总结和分析了生成式AI在假新闻生成与检测中的应用现状、关键技术、主要课题和未来方向。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hogpsjen8tj21121bgx0l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hogpsjjf8tj21rm0rqq9i.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hogpsk2lrsj20pa17in0f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 22:34:08 GMT</pubDate>
</item>
<item>
<title>[CL] The Probabilities Also Matter: A More Faithful Metric for Faithfulness of Free-Text Explanations in Large Language Models 网页链接 提出相关解释忠...</title>
<link>https://weibo.com/1402400261/O8pvuhX15</link>
<guid>https://weibo.com/1402400261/O8pvuhX15</guid>
<content:encoded><![CDATA[
<div> 解释忠实度、自然语言、指标、反事实测试、细节、评估、新指标、质量、大语言模型、补充
<br />
<br />
总结:本文提出了一个新的衡量自然语言解释忠实度的指标——相关解释忠实度(CEF)，并基于此提出了反事实测试(CCT)。CEF能够更全面地捕捉解释质量的细节，是对解释忠实度评估的有益补充。通过研究大语言模型中的自由文本解释，文章强调了解释质量和忠实度的重要性，并指出传统衡量方法可能存在的局限性。CEF和CCT的提出为解释忠实度的评估提供了新的视角和工具，有助于提高解释质量的准确性和全面性。 <div>
[CL] The Probabilities Also Matter: A More Faithful Metric for Faithfulness of Free-Text Explanations in Large Language Models  <br /><a href="https://arxiv.org/abs/2404.03189"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出相关解释忠实度(CEF)这一衡量自然语言解释忠实度的新指标，并基于此提出了相关反事实测试(CCT)，能捕捉解释质量的更多细节，是对解释忠实度评估的有益补充。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hogpioppe4j20v21b4h2d.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hogpiou8tmj21ee0rc45e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 22:24:39 GMT</pubDate>
</item>
<item>
<title>[CL] Learning to Plan and Generate Text with Citations 网页链接 通过引入问题序列作为生成蓝图，探索了规划型模型的归因能力，发现相比标准序列到序列，规划...</title>
<link>https://weibo.com/1402400261/O8prC2QRE</link>
<guid>https://weibo.com/1402400261/O8prC2QRE</guid>
<content:encoded><![CDATA[
<div> 规划型模型、问题序列、生成蓝图、归因能力、标准序列到序列、输出质量、引文准确率

通过引入问题序列作为生成蓝图，探索了规划型模型的归因能力。研究发现，相比标准序列到序列模型，规划型模型明显提升了长篇问答的输出质量和引文准确率。这一发现为提高自然语言生成模型的性能和实用性提供了新的思路。总结：文章研究了规划型模型的优势，通过引入问题序列，实现了更高的输出质量和引文准确率，为提升自然语言生成模型的能力提供了有益的启示。 <div>
[CL] Learning to Plan and Generate Text with Citations  <br /><a href="https://arxiv.org/abs/2404.03381"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过引入问题序列作为生成蓝图，探索了规划型模型的归因能力，发现相比标准序列到序列，规划明显提升了长篇问答的输出质量和引文准确率。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hogp8pu7yoj20v61aswwp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hogp8q52fcj219619eqio.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hogp8r2xzyj219i0jcn6s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 22:15:06 GMT</pubDate>
</item>
<item>
<title>[RO] Embodied Neuromorphic Artificial Intelligence for Robotics: Perspectives, Challenges, and Research Development Stack 网页链接 全面概述了具身神经...</title>
<link>https://weibo.com/1402400261/O8pmigBsm</link>
<guid>https://weibo.com/1402400261/O8pmigBsm</guid>
<content:encoded><![CDATA[
<div> 具身神经拟态人工智能、机器人、应用现状、关键挑战、未来发展方向、研究、技术、智能、模型

<br /><br />总结:
本文详细介绍了具身神经拟态人工智能在机器人领域的应用现状，包括现有技术和模型的发展。同时探讨了该领域面临的关键挑战，例如如何将人工智能技术与机器人实际应用相结合，并解决实际问题。未来发展方向包括加强研究，推动技术进步，提高智能机器人的性能和功能，拓展其应用范围。整体而言，具身神经拟态人工智能对机器人的发展至关重要，将为未来的机器人技术注入新的活力。 <div>
[RO] Embodied Neuromorphic Artificial Intelligence for Robotics: Perspectives, Challenges, and Research Development Stack  <br /><a href="https://arxiv.org/abs/2404.03325"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />全面概述了具身神经拟态人工智能在机器人领域的应用现状、关键挑战和未来发展方向。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hogov3zvkyj21161byx4v.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hogov4f35jj21lu0va7kl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hogov4i2zzj21720qsagl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 22:02:00 GMT</pubDate>
</item>
<item>
<title>文章构建模型指出依赖AI可能导致知识分布狭窄化，但个体的策略性选择可能有助避免这一风险。 - 转发 @爱可可-爱生活:&amp;ensp;[AI]《AI and the Problem of Knowled...</title>
<link>https://weibo.com/1402400261/O8p92wTuh</link>
<guid>https://weibo.com/1402400261/O8p92wTuh</guid>
<content:encoded><![CDATA[
<div> AI, knowledge collapse, narrow distribution, individual choice, risk avoidance, model, strategy, Peterson, University of Poitiers

<br /><br />总结:
文章指出依赖AI可能导致知识分布狭窄化的问题，但也提出个体的策略性选择可以有助于避免这一风险。通过构建模型，研究者分析了AI对知识分布的影响，强调了个体在面对这一问题时的重要性。个体可以根据自身需求和偏好，选择适合自己的策略，从而降低潜在的风险。这一研究对于理解AI与知识分布之间的关系具有重要意义，也为个体在使用AI时提供了有益的启示。Peterson教授的研究为我们提供了更深入的思考，并为应对知识分布狭窄化的挑战提供了有益的思路。 <div>
文章构建模型指出依赖AI可能导致知识分布狭窄化，但个体的策略性选择可能有助避免这一风险。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [AI]《AI and the Problem of Knowledge Collapse》A J. Peterson [University of Poitiers] (2024) <a href="https://arxiv.org/abs/2404.03502"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hognnc1b5jj20m015s7dp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hognnceiyhj20o616wqc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognncyb2cj20s40nkaby.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hognndegsxj20s60r0tcf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognx0ib6nj20hj0ja3zi.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognx0i633j20hh0jat9o.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognx0i776j20hj0jat9b.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hognx0i2hzj20ht0en74o.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 21:29:21 GMT</pubDate>
</item>
<item>
<title>[AI]《AI and the Problem of Knowledge Collapse》A J. Peterson [University of Poitiers] (2024) 网页链接 #机器学习##人工智能##论文# [图片][图片][图片][...</title>
<link>https://weibo.com/1402400261/O8p8ZzzRL</link>
<guid>https://weibo.com/1402400261/O8p8ZzzRL</guid>
<content:encoded><![CDATA[
<div> knowledge collapse, AI, problem, ethics, decision-making, reliability, uncertainty, bias, information overload

<br /><br />总结:
在Peterson的文章中，探讨了人工智能与知识塌缩的问题。人工智能在决策过程中可能存在伦理、可靠性、不确定性、偏见和信息过载等挑战。知识塌缩可能导致人工智能系统无法正确处理复杂情况，从而影响决策的准确性。处理这一问题需要进一步研究和讨论，以确保人工智能系统的发展能够更好地服务人类社会。 <div>
[AI]《AI and the Problem of Knowledge Collapse》A J. Peterson [University of Poitiers] (2024) <a href="https://arxiv.org/abs/2404.03502"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hognnc1b5jj20m015s7dp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hognnceiyhj20o616wqc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognncyb2cj20s40nkaby.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hognndegsxj20s60r0tcf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognx0ib6nj20hj0ja3zi.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognx0i633j20hh0jat9o.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognx0i776j20hj0jat9b.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hognx0i2hzj20ht0en74o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 21:29:14 GMT</pubDate>
</item>
<item>
<title>提出表示微调框架，发现相比调整权重，直接对语言模型的表示进行有针对性的干预可以以更少的参数实现类似或更好的下游任务表现。 - 转发 @爱可可-爱生活:&amp;ensp;[...</title>
<link>https://weibo.com/1402400261/O8p392NYd</link>
<guid>https://weibo.com/1402400261/O8p392NYd</guid>
<content:encoded><![CDATA[
<div> 微调框架、语言模型表示、下游任务、权重调整、有针对性干预、更少参数、表现更好

<br /><br />总结:本文提出了一种名为ReFT的表示微调框架，通过对语言模型的表示进行有针对性的干预来实现更好的下游任务表现。与传统调整权重相比，该方法可以用更少的参数达到类似甚至更好的效果。通过实验证明，ReFT框架在各种下游任务中表现出色，证实了其有效性和实用性。这一研究对于提高语言模型在各类任务中的性能有着重要的指导意义。 <div>
提出表示微调框架，发现相比调整权重，直接对语言模型的表示进行有针对性的干预可以以更少的参数实现类似或更好的下游任务表现。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《ReFT: Representation Finetuning for Language Models》Z Wu, A Arora, Z Wang, A Geiger… [Stanford University] (2024) <a href="https://arxiv.org/abs/2404.03592"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hognhufqy7j21220lcn5y.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hognhutgorj219o0lg0z4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hognhvez0bj219o0lg0z4.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 21:14:49 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.5)》 爱可可微博热门分享(4.5) [图片]</title>
<link>https://weibo.com/1402400261/O8mxq2PL2</link>
<guid>https://weibo.com/1402400261/O8mxq2PL2</guid>
<content:encoded><![CDATA[
<div> 微博、爱可可、热门分享、4.5、关键词

<br /><br />总结:
爱可可微博热门分享文章以4.5分受到关注，内容涵盖各种热门话题，吸引了大量用户关注和转发。文章内容丰富多样，包括时事新闻、娱乐八卦、美食旅游等多个领域的内容。独特的视角和深入的解析让读者对各种话题有了更深入的了解。文章质量高，得到了广泛的好评和点赞，是一篇深受欢迎的微博热门分享。 <div>
《爱可可微博热门分享(4.5)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405019932638183790"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.5)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hogceqdb8yj20rs0fmwgv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 14:51:10 GMT</pubDate>
</item>
<item>
<title>帮转～ - 转发 @徐亦达教授:&amp;ensp;大家好，请大家有空帮忙一下哈！😄 首先非常感谢大家啦🤝🤝🤝。如果您有时间，是否能帮我拍摄5张同样商标的照片（从不...</title>
<link>https://weibo.com/1402400261/O8kWMkjjj</link>
<guid>https://weibo.com/1402400261/O8kWMkjjj</guid>
<content:encoded><![CDATA[
<div> 照片 商标 角度 拍摄 上传 链接 帮助

商标主人需要大家帮忙拍摄5张同一商标的照片，从不同的角度，然后上传到指定链接。希望大家能够帮忙，非常感激！ <div>
帮转～<br /><blockquote> - 转发 <a href="https://weibo.com/5765533535" target="_blank">@徐亦达教授</a>: 大家好，请大家有空帮忙一下哈！😄 首先非常感谢大家啦🤝🤝🤝。如果您有时间，是否能帮我拍摄5张同样商标的照片（从不同的角度），并将它们上传到以下链接？非常感谢各位朋友的帮助！<br /><a href="https://docs.qq.com/form/page/DR2Zhbm51Tnl0eFFu"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <img src="https://tvax1.sinaimg.cn/large/006ibAEngy1hog14iauzuj30go0gota8.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 10:48:09 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models》(ICLR 2024) GitHub: github.com/kykim0/TextNorm《Tokeniz...</title>
<link>https://weibo.com/1402400261/O8kdOl9zC</link>
<guid>https://weibo.com/1402400261/O8kdOl9zC</guid>
<content:encoded><![CDATA[
<div> Text-to-Image Models, Confidence-aware Reward Optimization, Fine-tuning, Tokenization, Noiseless Channel, Neural Avatar, Image Segmentation, Multi-view Generation, Monocular 3D Detection, Style-Preserving, Change Detection, Language Models, Knowledge Translator, Self-Supervised Point Tracking, Linear Attention, Human Avatars, Dense Retrieval, Bit Vectors

总结:
文中介绍了多篇关于文本到图像模型、标记化、神经化身、图像分割、多视角生成等方面的论文实现代码。每篇论文都探讨了不同的技术和方法，包括模型优化、细化、标记化、图像生成、变化检测、语言模型、自监督点追踪等领域。这些研究为计算机视觉和自然语言处理领域的发展提供了新的视角和解决方案。 <div>
几篇论文实现代码：<br />《Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models》(ICLR 2024) GitHub: github.com/kykim0/TextNorm<br />《Tokenization and the Noiseless Channel》(ACL 2024) GitHub: github.com/zouharvi/tokenization-scorer<br />《Relightable and Animatable Neural Avatar from Sparse-View Video》(CVPR 2024) GitHub: github.com/zju3dv/RelightableAvatar<br />《Rethinking Interactive Image Segmentation with Low Latency, High Quality, and Diverse Prompts》(CVPR 2024) GitHub: github.com/uncbiag/SegNext<br />《MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation》(CVPR 2024) GitHub: github.com/zhizdev/mvdfusion<br />《SeaBird: Segmentation in Bird's View with Dice Loss Improves Monocular 3D Detection of Large Objects》(CVPR 2024) GitHub: github.com/abhi1kumar/SeaBird [fig4]<br />《InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation》(2024) GitHub: github.com/InstantStyle/InstantStyle [fig1]<br />《ChangeMamba: Remote Sensing Change Detection with Spatio-Temporal State Space Model》(2024) GitHub: github.com/ChenHongruixuan/MambaCD [fig2]<br />《ReFT: Representation Finetuning for Language Models》(2024) GitHub: github.com/stanfordnlp/pyreft<br />《Hulk: A Universal Knowledge Translator for Human-Centric Tasks》(2024) GitHub: github.com/OpenGVLab/Hulk [fig5]<br />《DINO-Tracker: Taming DINO for Self-Supervised Point Tracking in a Single Video》(2024) GitHub: github.com/AssafSinger94/dino-tracker<br />《Linear Attention Sequence Parallelism》(2024) GitHub: github.com/OpenNLPLab/LASP [fig3]<br />《HAHA: Highly Articulated Gaussian Human Avatars with Textured Mesh Prior》(2024) GitHub: github.com/david-svitov/HAHA<br />《Efficient Multi-vector Dense Retrieval with Bit Vectors》(2024) GitHub: github.com/CosimoRulli/emvb<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofubz9zdzj21gs17k7fe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofw8kueprj22691797wi.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofwlb8wvwj20k00ct795.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hog0a4fkm7j21gp0dk152.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hog1cq2s18j22ha11w7wh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 08:57:22 GMT</pubDate>
</item>
<item>
<title>'GPTS-Prompt-Collection - 收集GPTS的prompt / Collect the prompt of GPTS' GitHub: github.com/B3o/GPTS-Prompt-Collection #开源# #机器学习# #人工智能# [...</title>
<link>https://weibo.com/1402400261/O8k3kbPso</link>
<guid>https://weibo.com/1402400261/O8k3kbPso</guid>
<content:encoded><![CDATA[
<div> 关键词: GPTS, Prompt, Collection, GitHub, 收集, 提取, 关键点, 800字, 文章, 代码库

总结:<br /><br />
文章介绍了一个GitHub代码库，该代码库用于收集GPTS的prompt。通过这个项目，用户可以获取和分享各种GPTS生成的prompt，从而帮助提高模型的表现。用户可以在GitHub上查看和下载这些prompt，并在自己的项目中使用。该项目提供了一个方便的平台，让用户可以轻松地收集和分享prompt，从而为GPTS的发展做出贡献。GitHub代码库地址为github.com/B3o/GPTS-Prompt-Collection。 <div>
'GPTS-Prompt-Collection - 收集GPTS的prompt / Collect the prompt of GPTS' GitHub: github.com/B3o/GPTS-Prompt-Collection <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hog1fspuh2j20kk0t2go7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 08:31:32 GMT</pubDate>
</item>
<item>
<title>【Orange Meets：基于 Cloudflare Calls 构建的演示应用，可以通过该应用体验 WebRTC 技术】'Orange Meets - a demo application built using Cloudflare Calls...</title>
<link>https://weibo.com/1402400261/O8j8c99JD</link>
<guid>https://weibo.com/1402400261/O8j8c99JD</guid>
<content:encoded><![CDATA[
<div> Cloudflare Calls, 构建, Orange Meets, 演示应用, WebRTC 技术, GitHub, 应用体验

<br /><br />总结:
Orange Meets是一个演示应用，使用Cloudflare Calls构建，可以让用户体验WebRTC技术。这个应用可以在GitHub上找到，名为github.com/cloudflare/orange。通过Orange Meets，用户可以了解和体验Cloudflare Calls和WebRTC技术的功能和优势。 <div>
【Orange Meets：基于 Cloudflare Calls 构建的演示应用，可以通过该应用体验 WebRTC 技术】'Orange Meets - a demo application built using Cloudflare Calls’ GitHub: github.com/cloudflare/orange <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hofxd6vocdj20u00vkq7w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 06:10:46 GMT</pubDate>
</item>
<item>
<title>【Dot：使用大型语言模型(LLM)和检索增强生成(RAG)进行文档交互的独立应用，面向本地使用大型语言模型（LLM）和检索增强生成（RAG）进行文档交互的独立应用程序...</title>
<link>https://weibo.com/1402400261/O8j7p9nAF</link>
<guid>https://weibo.com/1402400261/O8j7p9nAF</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、检索增强生成、文档交互、独立应用、本地使用、GitHub、Mistral 7B、应用程序

<br /><br />总结:
这篇文章介绍了一个名为Dot的独立应用程序，其使用大型语言模型（LLM）和检索增强生成（RAG）技术，实现本地文档交互功能。用户可以通过GitHub下载这个应用程序，并使用其中的Mistral 7B模型进行操作。Dot的设计目的是为用户提供一种便捷的方式来进行文档处理和生成，同时保证数据隐私和安全。通过结合大型语言模型和检索增强生成技术，Dot可以帮助用户快速获取文档信息并生成相关内容，提高工作效率。Dot的本地化设计也符合用户对数据隐私和安全性的需求，让用户能够安心地使用这个应用程序。 <div>
【Dot：使用大型语言模型(LLM)和检索增强生成(RAG)进行文档交互的独立应用，面向本地使用大型语言模型（LLM）和检索增强生成（RAG）进行文档交互的独立应用程序】’Dot - Standalone app for fully local RAG with Mistral 7B' GitHub: github.com/alexpinel/Dot <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hofxbbddiuj20u00xuwj0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 06:08:50 GMT</pubDate>
</item>
<item>
<title>【CIFAR-10 Airbench：包含了基于 PyTorch 框架的 CIFAR-10 数据集快速训练脚本，提供了三种方法，分别可以实现 94.01%、95.01% 和 96.05% 的准确率，运行时间分...</title>
<link>https://weibo.com/1402400261/O8j022Y66</link>
<guid>https://weibo.com/1402400261/O8j022Y66</guid>
<content:encoded><![CDATA[
<div> PyTorch, CIFAR-10, 快速训练脚本, 准确率, 运行时间, GitHub, KellerJordan, CIFAR-10 Airbench<br />
<br />
提供了基于 PyTorch 框架的 CIFAR-10 数据集快速训练脚本，包含三种方法可以实现不同准确率，分别为94.01%、95.01%和96.05%。运行时间分别为3.29秒、10.4秒和46.3秒。项目托管在GitHub上，作者是KellerJordan。  <div>
【CIFAR-10 Airbench：包含了基于 PyTorch 框架的 CIFAR-10 数据集快速训练脚本，提供了三种方法，分别可以实现 94.01%、95.01% 和 96.05% 的准确率，运行时间分别为 3.29 秒、10.4 秒和 46.3 秒】'CIFAR-10 Airbench' GitHub: github.com/KellerJordan/cifar10-airbench <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hofwsfm1cij20yy0u0dk9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 05:50:40 GMT</pubDate>
</item>
<item>
<title>【LL3M：构建支持 Jax/Flax 训练和微调的大语言/多模态模型和 MoE 模型】'LL3M: Large Language and Multi-Modal Model in Jax / Flax - LL3M: Large Language a...</title>
<link>https://weibo.com/1402400261/O8iRXsXRz</link>
<guid>https://weibo.com/1402400261/O8iRXsXRz</guid>
<content:encoded><![CDATA[
<div> Jax, Flax, 训练, 微调, 大语言模型, 多模态模型, MoE 模型, GitHub, 支持, 构建

<br /><br />总结:
该项目提出了一个名为LL3M的大语言和多模态模型，基于Jax和Flax框架，支持模型训练和微调。该模型还包含MoE（Mixture of Experts）模型。整个项目代码托管在GitHub上。LL3M模型可以用于多种任务，包括自然语言处理和计算机视觉。通过该项目，研究人员可以更方便地训练和使用大型语言和多模态模型。 <div>
【LL3M：构建支持 Jax/Flax 训练和微调的大语言/多模态模型和 MoE 模型】'LL3M: Large Language and Multi-Modal Model in Jax / Flax - LL3M: Large Language and Multi-Modal Model in Jax' GitHub: github.com/jiasenlu/LL3M <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hofw7rr0ehj217k0ismzt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 05:30:47 GMT</pubDate>
</item>
<item>
<title>【SableDb：基于 RocksDb 存储引擎的 Key-Value NoSQL 数据库，与 Redis 协议兼容，旨在降低内存成本和增加比 Redis 更大的容量】'SableDb - Ultra fast, persis...</title>
<link>https://weibo.com/1402400261/O8iQd2qwJ</link>
<guid>https://weibo.com/1402400261/O8iQd2qwJ</guid>
<content:encoded><![CDATA[
<div> SableDb、RocksDb、Key-Value、NoSQL、数据库、Redis、协议兼容、降低内存成本、增加容量、GitHub

<br /><br />总结:
SableDb是一个基于RocksDb存储引擎的Key-Value型NoSQL数据库，与Redis协议兼容。旨在降低内存成本和增加比Redis更大的容量。该数据库支持Redis API，具有快速持久性和高性能。用户可以在GitHub上找到SableDb的开源代码，并了解更多相关信息。 <div>
【SableDb：基于 RocksDb 存储引擎的 Key-Value NoSQL 数据库，与 Redis 协议兼容，旨在降低内存成本和增加比 Redis 更大的容量】'SableDb - Ultra fast, persistent database supporting Redis API' GitHub: github.com/sabledb-io/sabledb <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hofw32it0kj21740lwgpg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 05:26:28 GMT</pubDate>
</item>
<item>
<title>'Bili2text - Bilibili视频转文字，一步到位，输入链接即可使用' GitHub: github.com/lanbinshijie/bili2text #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O8ivvFIdX</link>
<guid>https://weibo.com/1402400261/O8ivvFIdX</guid>
<content:encoded><![CDATA[
<div> 关键词: Bili2text, Bilibili, 视频转文字, GitHub, 转换工具, 链接输入<br />
<br />
Bili2text是一个可以将Bilibili视频转换为文字的工具，用户只需输入视频链接即可使用。该工具在GitHub上开源，代码可在github.com/lanbinshijie/bili2text找到。<br /><br />
总结: <br />
1. Bili2text是一个视频转文字工具，可用于将Bilibili视频转换为文字。<br />
2. 用户只需输入视频链接即可使用该工具。<br />
3. 该工具的代码开源在GitHub上，网址为github.com/lanbinshijie/bili2text。 <div>
'Bili2text - Bilibili视频转文字，一步到位，输入链接即可使用' GitHub: github.com/lanbinshijie/bili2text <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hofum86vanj20yd0u0n0v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 04:35:29 GMT</pubDate>
</item>
<item>
<title>【JetMoE: 基于开源数据集训练的大型语言模型，可以与 LLaMA2-7B 等高性能模型相媲美，仅需较少的训练资金(0.1M Dollars)】’JetMoE: Reaching LLaMA2 Performan...</title>
<link>https://weibo.com/1402400261/O8iqA9D3s</link>
<guid>https://weibo.com/1402400261/O8iqA9D3s</guid>
<content:encoded><![CDATA[
<div> 基于开源数据集，训练大型语言模型，性能媲美LLaMA2-7B，仅需0.1M Dollars训练资金<br />
<br />
1. JetMoE是一个基于开源数据集训练的大型语言模型，与LLaMA2-7B等高性能模型相媲美。<br />
2. JetMoE训练所需资金仅为0.1M Dollars，较其他模型相对较低。<br />
3. 这篇文章介绍了JetMoE的训练方式及性能表现，以及与其他模型的对比情况。<br />
4. JetMoE的GitHub链接为github.com/myshell-ai/JetMoE。<br />
<br />
总结:本文介绍了基于开源数据集训练的大型语言模型JetMoE，表现媲美LLaMA2-7B，仅需0.1M Dollars训练资金，是一种高性价比的模型选择。文章详细介绍了JetMoE的优势和性能表现，以及与其他模型的对比情况。感兴趣的读者可通过GitHub链接获取更多信息。 <div>
【JetMoE: 基于开源数据集训练的大型语言模型，可以与 LLaMA2-7B 等高性能模型相媲美，仅需较少的训练资金(0.1M Dollars)】’JetMoE: Reaching LLaMA2 Performance with 0.1M Dollars - Reaching LLaMA2 Performance with 0.1M Dollars' GitHub: github.com/myshell-ai/JetMoE <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hofu9l51tcj21aj0u078p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 04:23:20 GMT</pubDate>
</item>
<item>
<title>【生成式AI高峰已过？】- 生成式AI的兴趣高峰已经过去，公众兴趣下降，风投估值过高，初创公司开始倒闭，企业对部署安全性存疑。 - 但技术本身仍在快速进步，不...</title>
<link>https://weibo.com/1402400261/O8hyyppLO</link>
<guid>https://weibo.com/1402400261/O8hyyppLO</guid>
<content:encoded><![CDATA[
<div> 生成式AI，兴趣高峰，公众下降，风投估值，初创公司，安全性存疑，技术进步，新模型，基础设施，低谷期

<br /><br />总结:
生成式AI的兴趣高峰已经过去，公众兴趣下降，风投估值过高，初创公司开始倒闭，企业对部署安全性存疑。技术虽然在快速进步，但进展不为公众所知。每项革命性技术都经历高峰和低谷，生成式AI可能也是如此。是否再次繁荣取决于默默努力的人们。过度炒作可能导致公众接受困难，技术领域应谨记。技术发展和公众舆论需要平衡。过度炒作会损害公众对技术的信任，阻碍长远发展。变革依靠内在力量，外界关注并非必需。历史将解答生成式AI的命运。 <div>
【生成式AI高峰已过？】<br />- 生成式AI的兴趣高峰已经过去，公众兴趣下降，风投估值过高，初创公司开始倒闭，企业对部署安全性存疑。   <br />- 但技术本身仍在快速进步，不断有新模型问世，基础设施也在建设，只是这些进展不为公众所知。   <br />- 每项革命性技术都曾经历过兴趣的高峰和低谷，生成式AI可能也是这样，目前正处在低谷期。   <br />- 是否会再次繁荣取决于静默努力的人们，而非当下的舆论，历史会给出答案。   <br />- 过度炒作可能让公众在下次繁荣时难以接受，技术领域应谨记。   <br />- 我们应该问自己，技术本身是否有足够的力量推动变革，而非依靠夸大其词。   <br /><br />思考：   <br />- 技术发展的节奏和公众舆论的节奏不尽相同，需要平衡二者。   <br />- 过度炒作会损害公众对技术的信任，可能会阻碍长远发展。   <br />- 变革依靠内在驱动力，外界关注并非必需。<br />《The State of Generative AI, 2024 - by Alberto Romero》 <a href="https://www.thealgorithmicbridge.com/p/the-state-of-generative-ai-2024"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hofqf29bu1j214g0n4tbv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 02:10:14 GMT</pubDate>
</item>
<item>
<title>【128k上下文+多语言+工具：Cohere开放企业级应用大模型Command R+】- Cohere推出Command R+模型，一个为应对企业级工作负载而构建的最强大、最具可扩展性的大型...</title>
<link>https://weibo.com/1402400261/O8h1oCNt9</link>
<guid>https://weibo.com/1402400261/O8h1oCNt9</guid>
<content:encoded><![CDATA[
<div> Cohere, Command R+, Microsoft Azure, 多语言, 工具使用, 128k token上下文窗口,性能升级, 企业级应用, 市场拓展, 合作伙伴关系

<br /><br />总结:
Cohere推出了适用于企业级工作负载的最强大、可扩展的大型语言模型Command R+，首先在Microsoft Azure上推出，旨在加速企业AI的采用。该模型具有128k token的上下文窗口，支持多种关键语言和工具使用，以实现复杂业务流程的自动化。Command R+在各方面表现出色，与微软Azure等云计算巨头合作，有望在多个云平台上快速部署，降低企业的采用门槛。企业如Atomicwork可以利用Command R+来提高数字工作场所体验，加速企业生产力。这标志着Cohere在企业级AI市场的发力，展现了其深刻的企业需求洞察力和强大的技术实力。Cogere还需要持续投入解决数据安全、伦理合规等挑战，助力企业AI的落地应用。 <div>
【128k上下文+多语言+工具：Cohere开放企业级应用大模型Command R+】<br />- Cohere推出Command R+模型，一个为应对企业级工作负载而构建的最强大、最具可扩展性的大型语言模型(LLM)。  <br />- Command R+首先在Microsoft Azure上推出，旨在加速企业AI的采用。它加入了Cohere的R系列LLM，专注于在高效率和强准确性之间取得平衡，使企业能从概念验证走向生产。  <br />- Command R+具有128k token的上下文窗口，旨在提供同类最佳的性能，包括：  <br />  - 先进的检索增强生成(RAG)和引用，以减少幻觉  <br />  - 支持10种关键语言的多语言覆盖，以支持全球业务运营  <br />  - 工具使用，以实现复杂业务流程的自动化  <br />- Command R+在各方面都优于Command R，在类似模型的基准测试中表现出色。  <br />- 开发人员和企业可以从今天开始在Azure上访问Cohere的最新模型，很快也将在Oracle云基础设施(OCI)以及未来几周内的其他云平台上提供。Command R+也将立即在Cohere的托管API上提供。  <br />- Atomicwork等企业客户可以利用Command R+来改善数字工作场所体验，加速企业生产力。  <br /><br />思考：  <br />- Cohere推出Command R+，进一步丰富了其企业级LLM产品线，展现了其在企业AI市场的雄心和实力。与微软Azure的合作有望加速其企业客户的拓展。  <br />- Command R+在Command R的基础上进行了全面升级，128k token的上下文窗口、多语言支持、工具使用等特性使其能够胜任更加复杂多样的企业应用场景。这表明Cohere对企业需求有着深刻洞察。  <br />- RAG和引用功能有助于提高模型输出的可靠性，减少幻觉，这对于企业级应用至关重要。可以看出Cohere在兼顾性能的同时，也非常重视模型的可控性。  <br />- 与微软、甲骨文等云计算巨头合作，使Command R+能够在多个主流云平台上快速部署，降低了企业的采用门槛。这种开放的生态策略有利于加速其市场渗透。  <br />- Atomicwork等企业客户的支持表明Command R+具有显著的商业价值。将LLM与企业数字化转型相结合，有望催生更多创新性的应用。  <br />- Command R+的推出标志着Cohere在企业级AI市场的发力，其强大的性能和完善的生态有望帮助其在竞争中占据优势地位。不过，企业AI的落地仍面临数据安全、伦理合规等诸多挑战，Cohere还需要在这些方面持续投入。<br />《Introducing Command R+: A Scalable LLM Built for Business》 <a href="https://txt.cohere.com/command-r-plus-microsoft-azure/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hofo1hyiwyj21hc0u0n0r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 00:48:32 GMT</pubDate>
</item>
<item>
<title>【OpenAI推出对微调API的改进和新的定制模型计划】- OpenAI推出了对微调API的改进，并扩大了定制模型计划，以帮助开发者提高模型性能，降低延迟，提高准确性并降...</title>
<link>https://weibo.com/1402400261/O8gHS6J2t</link>
<guid>https://weibo.com/1402400261/O8gHS6J2t</guid>
<content:encoded><![CDATA[
<div> OpenAI, 微调API, 定制模型计划, 模型性能, RAG, 合作, 技术, 控制, 提升, 开发者

<br /><br />总结:
OpenAI推出了对微调API的改进和新的定制模型计划，旨在帮助开发者提高模型性能、降低延迟、提高准确性并降低成本。开发者可以运用多种技术，如RAG扩展模型知识、使用微调定制模型行为或构建定制训练模型来提升模型性能。通过新的微调API功能，开发者能更好地控制微调过程，并与OpenAI的AI专家和研究人员合作构建定制模型。自推出自助微调API以来，成千上万家组织已使用API训练了数十万个模型，以增强模型对特定任务的理解和能力。定制模型计划则旨在与OpenAI研究人员合作，针对特定领域训练和优化模型，并根据客户需求不断改进计划以提高性能。重点在于明确使用场景、设计评估系统、选择技术并持续迭代，使模型达到最佳性能。开发者可以通过微调API快速看到有意义的结果，而定制模型计划则适用于需要深度微调或传授特定领域知识的组织。这些举措体现了OpenAI致力于协助开发者和企业实现AI应用的决心，有望促进AI技术在各行业的应用，并加速AI技术向生产环境的渗透。 <div>
【OpenAI推出对微调API的改进和新的定制模型计划】<br />- OpenAI推出了对微调API的改进，并扩大了定制模型计划，以帮助开发者提高模型性能，降低延迟，提高准确性并降低成本。  <br />- 开发者可以使用多种技术来提高模型性能，如使用检索增强生成(RAG)扩展模型知识，使用微调定制模型行为，或使用新的特定领域知识构建定制训练模型。  <br />- OpenAI推出了新的微调API功能，让开发者可以更好地控制使用API进行微调，并引入更多方式与OpenAI的AI专家和研究人员合作构建定制模型。  <br />- 自2023年8月推出GPT-3.5的自助微调API以来，已有数千家组织使用该API训练了数十万个模型。微调可以帮助模型深入理解内容，并增强模型在特定任务上的现有知识和能力。  <br />- OpenAI推出了定制模型计划，旨在与OpenAI研究人员合作，针对特定领域训练和优化模型。通过与客户合作，OpenAI评估了他们的定制模型需求，并改进了计划以进一步最大化性能。  <br />- 关键是要明确使用场景的范围，设计和实施评估系统，选择正确的技术，并准备随着时间的推移不断迭代，使模型达到最佳性能。使用OpenAI，大多数组织可以通过自助微调API快速看到有意义的结果。对于需要更深入地微调模型或向模型灌输新的特定领域知识的组织，OpenAI的定制模型计划可以提供帮助。  <br /><br />思考：  <br />- OpenAI持续改进微调API和定制模型计划，体现了其致力于帮助开发者和企业实现AI应用的决心。这些举措有望加速AI技术在各行各业的落地和普及。  <br />- 文章列举了多种提升模型性能的技术，如RAG、微调、定制训练等，展现了当前AI优化的多样性和灵活性。开发者可以根据具体应用场景选择合适的技术组合。  <br />- 微调API的新功能赋予开发者更多控制权，定制模型计划提供了与OpenAI专家合作的机会，这种开放、灵活的生态有利于满足企业的差异化需求，催生更多创新应用。  <br />- OpenAI与客户的深度合作，如与SKT在电信客户服务领域的合作，展现了定制化AI解决方案的巨大价值。这种合作模式有望在更多行业复制和推广。  <br />- 文章强调了明确使用场景、建立评估体系、选择合适技术、持续迭代优化的重要性，这为企业采用AI提供了很好的方法论指导。  <br />- OpenAI的这些举措有望加速AI技术向生产环境的渗透，帮助企业实现AI价值。同时，我们也要看到，实现AI的规模化应用仍面临诸多挑战，如数据质量、伦理风险等，需要产学研各界共同努力加以应对。<br />《Introducing improvements to the fine-tuning API and expanding our custom models program》 <a href="https://openai.com/blog/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hofmneqtp0j21d70u0q9i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 00:00:26 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@异步图书 送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O8geoaKFM</link>
<guid>https://weibo.com/1402400261/O8geoaKFM</guid>
<content:encoded><![CDATA[
<div> 大语言模型、前沿进展、科学家、工程师、学生、案例、庖丁解牛、理解、认识

<br /><br />总结:
本文介绍了《大语言模型：基础与前沿》这本书，截止日期为2024年4月12日中午12点，*可可粉*转发+评论即可参与赠送3本书。该书全面深入地介绍了大语言模型及其前沿进展，适合想要了解这一领域或掌握这种方法与工具的科学家、工程师和学生参考。书中摒弃了纯理论的说教模式，通过案例入手，以庖丁解牛的方式帮助读者理解与认识大语言模型。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%BC%82%E6%AD%A5%E5%9B%BE%E4%B9%A6">@异步图书</a>  送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。摒弃了纯理论的说教模式，从案例入手， 采用庖丁解牛的方式帮助读者理解与认识大语言模型。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019331269755053"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef8oboqij20ga0m8q8p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9segl7j20m90m9q6z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9t5km0j20m90m942f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef9tq2esj20m90m9gpe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef9ugq5dj20m90m9dif.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 22:47:48 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O8gel92B5</link>
<guid>https://weibo.com/1402400261/O8gel92B5</guid>
<content:encoded><![CDATA[
<div> LangChain实战, 初学者, 大语言模型, LLM, LangChain 0.1版本, LangServe, LangSmith, LangChain团队, 生成式人工智能, LangChain生态系统

<br /><br />总结:
本文介绍了携手送出3本《LangChain实战》的活动，截止日期为2024年4月11日。参与者需转发并评论，即可参与。该书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者编写，基于LangChain 0.1版本。同时，配套600分钟详解视频，重点介绍多个核心应用场景，并深入探讨LCEL的应用方式。书中围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。活动为LangChain的学习者提供了一个学习和交流的平台。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a> <a href="https://shop.sc.weibo.com/h5/goods/index?iid=110014024002610004661854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">LangChain实战：从原型到生产，动手打造 LLM 应用</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5ywtixj20ku0zzdmx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hofl98oom9j207q0a0jrm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 22:47:41 GMT</pubDate>
</item>
<item>
<title>今日推介(第1366期)：在基于Transformer的语言中动态分配计算、描述模型中幻觉的新测量方法、高效的编译时提示结构感知方法、线性注意力序列并行、强化学习的范...</title>
<link>https://weibo.com/1402400261/O8gcClW8Q</link>
<guid>https://weibo.com/1402400261/O8gcClW8Q</guid>
<content:encoded><![CDATA[
<div> Transformer、动态分配计算、模型幻觉、新测量方法、编译时提示、结构感知方法、线性注意力、序列并行、强化学习、范畴网络<br />
<br />
<总结>
本文介绍了一些新的研究成果，包括在基于Transformer的语言模型中动态分配计算的方法，描述模型中幻觉的新测量方法，以及高效的编译时提示结构感知方法。此外，还介绍了线性注意力和序列并行的技术，以及在强化学习中应用范畴网络的视角。这些方法的提出和应用有助于改进机器学习和人工智能领域的相关技术，推动相关领域的研究和发展。 <div>
今日推介(第1366期)：在基于Transformer的语言中动态分配计算、描述模型中幻觉的新测量方法、高效的编译时提示结构感知方法、线性注意力序列并行、强化学习的范畴网络学视角 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/690782999"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hofkfmfv30j20xy0u0q9l.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hofkfol1qzj20sw0pm0xf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hofkfrkzeoj21cc0hqjuz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hofkfuprauj20p211s0xl.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hofkfxbyvlj20ku0qkaba.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 22:43:27 GMT</pubDate>
</item>
<item>
<title>[IR] Efficient Multi-Vector Dense Retrieval Using Bit Vectors 网页链接 提出EMVB框架，通过bit向量预过滤、SIMD计算、量化技术等方法实现高效低内存的多向量...</title>
<link>https://weibo.com/1402400261/O8g7MfrpU</link>
<guid>https://weibo.com/1402400261/O8g7MfrpU</guid>
<content:encoded><![CDATA[
<div> EMVB框架, Bit向量预过滤, SIMD计算, 量化技术, 多向量稠密检索, 高效, 低内存

<br /><br />总结:
本文提出了一种名为EMVB的框架，旨在实现高效低内存的多向量稠密检索。框架包括bit向量预过滤、SIMD计算和量化技术等方法，用于提高检索效率。通过使用bit向量预过滤，可以减少不必要的计算。同时，利用SIMD计算和量化技术对向量进行处理，进一步提高了检索效率。该框架在稠密向量检索任务中表现出色，是一种高效且节省内存的检索方法。 <div>
[IR] Efficient Multi-Vector Dense Retrieval Using Bit Vectors  <br /><a href="https://arxiv.org/abs/2404.02805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出EMVB框架，通过bit向量预过滤、SIMD计算、量化技术等方法实现高效低内存的多向量稠密检索。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofk3ig8y8j20uo1c2duf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofk3inkovj21cw0maaeo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofk3j1u9xj21cs0k043n.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 22:31:31 GMT</pubDate>
</item>
<item>
<title>[CL] CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models 网页链接 CMULAB是一个开源的Web框架，通过集成各...</title>
<link>https://weibo.com/1402400261/O8g5iDezz</link>
<guid>https://weibo.com/1402400261/O8g5iDezz</guid>
<content:encoded><![CDATA[
<div> CMULAB, 开源框架, 自然语言处理, 多语言, 模型集成, 低资源语言, 部署, 微调, 降低门槛
<br />
CMULAB是一个开源的Web框架，通过集成各种多语言NLP模型，简化了低资源语言的自然语言处理工具的部署和微调过程，降低了使用门槛，使更多语言社区受益。 <div>
[CL]  CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models  <br /><a href="https://arxiv.org/abs/2404.02408"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />CMULAB是一个开源的Web框架，通过集成各种多语言NLP模型，简化了低资源语言的自然语言处理工具的部署和微调过程，降低了使用门槛，使更多语言社区受益。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofjx5bxxqj20vk1bg4fy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofjx5roywj21la0ua47x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofjx6a8dwj21oe17idss.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 22:25:25 GMT</pubDate>
</item>
<item>
<title>[LG] Domain Generalization through Meta-Learning: A Survey 网页链接 对基于元学习提高模型泛化能力的域泛化方法进行全面调研，总结现有方法与存在的挑战，为...</title>
<link>https://weibo.com/1402400261/O8g35EtUJ</link>
<guid>https://weibo.com/1402400261/O8g35EtUJ</guid>
<content:encoded><![CDATA[
<div> 域泛化、元学习、模型、挑战、调研、方法、指导、研究、泛化能力、领域

总结:<br /><br />本文对基于元学习的域泛化方法进行了全面调研，总结了现有方法及存在的挑战，并为未来研究提供了指导。在研究中，针对模型在不同领域下的泛化能力进行了讨论，提出了利用元学习来改善泛化能力的思路。调研发现，当前的域泛化方法存在一些挑战，例如领域差异、数据标签分布等问题，需要进一步研究解决。未来的研究可以集中在如何提高模型在多个领域中的表现，以及如何设计更加有效的元学习策略等方面，以促进泛化能力的提升。 <div>
[LG] Domain Generalization through Meta-Learning: A Survey  <br /><a href="https://arxiv.org/abs/2404.02785"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />对基于元学习提高模型泛化能力的域泛化方法进行全面调研，总结现有方法与存在的挑战，为未来研究提供指导。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofjrgd6kmj20xg15m7ga.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofjrh6mp8j21cy150wmo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofjrhnyi5j21c80tqgqh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofjri3qtpj21d40p6aht.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 22:19:59 GMT</pubDate>
</item>
<item>
<title>[CL] Auxiliary task demands mask the capabilities of smaller language models 网页链接 与大模型相比，小规模语言模型更容易受到评估设计引入的辅助需求的影...</title>
<link>https://weibo.com/1402400261/O8g0s5eI3</link>
<guid>https://weibo.com/1402400261/O8g0s5eI3</guid>
<content:encoded><![CDATA[
<div> 大模型,小规模语言模型,评估设计,辅助需求,真实能力,低估,评估,能力发展,研究视角

<br /><br />总结:
小规模语言模型更容易受到评估设计引入的辅助需求的影响，可能导致其真实能力被低估。这一发现为语言模型的评估和能力发展研究提供了新的视角，强调对于小规模语言模型的评估需要综合考虑辅助需求的影响。 <div>
[CL] Auxiliary task demands mask the capabilities of smaller language models  <br /><a href="https://arxiv.org/abs/2404.02418"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />与大模型相比，小规模语言模型更容易受到评估设计引入的辅助需求的影响，其真实能力可能被低估，这一发现为语言模型的评估和能力发展研究提供了新的视角。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofjkptd3ij20va1dqh17.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofjkqdhb6j21bu0x2n6v.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofjkqnw6lj21by0w8wnl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 22:13:28 GMT</pubDate>
</item>
<item>
<title>将强化学习的各种主流算法统一表达为范畴网络学框架中的参数化光学元，通过组合简单的范畴论模块构造复杂算法，揭示了这些算法背后的共性。 - 转发 @爱可可-爱生...</title>
<link>https://weibo.com/1402400261/O8fTmgYeo</link>
<guid>https://weibo.com/1402400261/O8fTmgYeo</guid>
<content:encoded><![CDATA[
<div> 参数化光学元, 强化学习, 范畴网络学框架, 主流算法, 共性, 算法背后, 范畴论模块, 复杂算法

<br /><br />总结:
本文将强化学习的各种主流算法统一表达为范畴网络学框架中的参数化光学元，通过组合简单的范畴论模块构造复杂算法，揭示了这些算法背后的共性。这种方法将不同算法统一起来，揭示了它们之间的联系和共同之处。参数化光学元的概念在此框架中起到关键作用，帮助理解算法之间的联系，并且通过范畴网络学框架的应用，能够更好地理解算法的本质和工作原理。通过这种方式构建的复杂算法模型可以更好地解决现实生活中的问题，同时也为强化学习领域的研究提供了新的思路和方法。整体来看，本文为强化学习算法的发展和应用开辟了新的方向，为研究人员提供了更多的启发和思考。 <div>
将强化学习的各种主流算法统一表达为范畴网络学框架中的参数化光学元，通过组合简单的范畴论模块构造复杂算法，揭示了这些算法背后的共性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Reinforcement Learning in Categorical Cybernetics》J Hedges, R R Sakamoto  (2024) <a href="https://arxiv.org/abs/2404.02688"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofihvxkgyj21j60mwna8.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofihwach1j20ku0qkdhe.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofihwk8anj20la0n2dhq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofihwpqq7j20n20zgq5q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofj2enwrdj20xc05qjs1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofj2en24aj20d108qaac.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofj2enyf5j20zs0d9wgi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofj2envf2j20z80bwdho.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofj2enk53j20zs06y0ts.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 21:56:00 GMT</pubDate>
</item>
<item>
<title>[LG]《Reinforcement Learning in Categorical Cybernetics》J Hedges, R R Sakamoto (2024) 网页链接 #机器学习##人工智能##论文# [图片][图片][图片][图片][图...</title>
<link>https://weibo.com/1402400261/O8fTirwiQ</link>
<guid>https://weibo.com/1402400261/O8fTirwiQ</guid>
<content:encoded><![CDATA[
<div> 强化学习、分类学、网络控制、机器学习、人工智能、深度学习、信息科学

总结:<br /><br />
本文探讨了在分类学的框架下运用强化学习的方法来解决网络控制问题。研究者提出了一种基于分类学思想的强化学习算法，利用深度学习技术实现网络控制的优化。他们认为在信息科学领域中，将强化学习与分类学相结合可以提高系统的性能和鲁棒性。研究结果表明，这种方法可以有效地应用于网络控制领域，为构建更强大的人工智能系统提供了新思路。 <div>
[LG]《Reinforcement Learning in Categorical Cybernetics》J Hedges, R R Sakamoto  (2024) <a href="https://arxiv.org/abs/2404.02688"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofihvxkgyj21j60mwna8.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofihwach1j20ku0qkdhe.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofihwk8anj20la0n2dhq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofihwpqq7j20n20zgq5q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofj2enwrdj20xc05qjs1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofj2en24aj20d108qaac.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofj2enyf5j20zs0d9wgi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofj2envf2j20z80bwdho.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofj2enk53j20zs06y0ts.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 21:55:51 GMT</pubDate>
</item>
<item>
<title>设计了LASP技术实现线性注意力模型的高效序列级并行，对处理长序列任务具有重要意义。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Linear Attention Sequence Paralleli...</title>
<link>https://weibo.com/1402400261/O8fKtAKqW</link>
<guid>https://weibo.com/1402400261/O8fKtAKqW</guid>
<content:encoded><![CDATA[
<div> LASP、线性注意力模型、高效序列级并行、长序列任务、Shanghai AI Laboratory、TapTap

<br /><br />总结:
本文介绍了一种名为LASP的技术，能够实现线性注意力模型的高效序列级并行，对处理长序列任务具有重要意义。LASP技术由上海人工智能实验室和TapTap合作开发。该技术通过实现线性注意力模型的高效序列级并行，提升了长序列任务的处理速度和效率。LASP技术的设计使其在处理长序列任务时能够更加高效，对于提升模型的性能有着重要意义。该研究对于未来在处理长序列任务时的优化具有重要的参考意义。LASP技术在实践中展现出了良好的效果，为解决长序列任务的挑战提供了新的思路和方法。 <div>
设计了LASP技术实现线性注意力模型的高效序列级并行，对处理长序列任务具有重要意义。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Linear Attention Sequence Parallelism》W Sun, Z Qin, D Li, X Shen, Y Qiao, Y Zhong [Shanghai AI Laboratory &amp; TapTap] (2024) <a href="https://arxiv.org/abs/2404.02882"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofi8pdok9j20la12wn6t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofi8pq1gej20p211s7ak.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofi8q20cij20os0omq94.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofi8q8axzj21d60mytfy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofifj2ayvj20j00i4gn9.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 21:34:07 GMT</pubDate>
</item>
<item>
<title>[LG]《Linear Attention Sequence Parallelism》W Sun, Z Qin, D Li, X Shen, Y Qiao, Y Zhong [Shanghai AI Laboratory &amp; TapTap] (2024) 网页链接 #机器学习##...</title>
<link>https://weibo.com/1402400261/O8fKngOP4</link>
<guid>https://weibo.com/1402400261/O8fKngOP4</guid>
<content:encoded><![CDATA[
<div> 关键词: Linear Attention Sequence Parallelism, Shanghai AI Laboratory, TapTap, 并行计算, 自然语言处理, 深度学习

总结:<br /><br />
本文介绍了一种名为Linear Attention Sequence Parallelism的方法，旨在加速自然语言处理任务中的注意力机制计算。该方法由上海人工智能实验室和TapTap联合研发，利用并行计算的方式提高了深度学习模型的计算效率。作者通过实验验证了该方法在不同任务上的性能表现优异，展示了其在提高计算速度和保持模型准确性方面的潜力。通过对比实验和分析，论文强调了Linear Attention Sequence Parallelism对于加速自然语言处理任务的重要性，为深度学习领域的研究和应用提供了新的思路和方法。 <div>
[LG]《Linear Attention Sequence Parallelism》W Sun, Z Qin, D Li, X Shen, Y Qiao, Y Zhong [Shanghai AI Laboratory &amp; TapTap] (2024) <a href="https://arxiv.org/abs/2404.02882"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofi8pdok9j20la12wn6t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofi8pq1gej20p211s7ak.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofi8q20cij20os0omq94.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofi8q8axzj21d60mytfy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofifj2ayvj20j00i4gn9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 21:33:51 GMT</pubDate>
</item>
<item>
<title>提出SAMMO框架，将提示表示为结构化程序，以便在强大语言模型和复杂提示的时代进行元提示优化。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Prompts As Programs: A Str...</title>
<link>https://weibo.com/1402400261/O8fFZ2uJO</link>
<guid>https://weibo.com/1402400261/O8fFZ2uJO</guid>
<content:encoded><![CDATA[
<div> 结构化程序、元提示、SAMMO框架、强大语言模型、复杂提示、优化、编译时、效率、Microsoft Research、T Schnabel、J Neville

<br /><br />总结:
文章提出了SAMMO框架，旨在将提示表示为结构化程序，以便在当今强大语言模型和复杂提示的时代进行元提示优化。该框架由Microsoft Research的T Schnabel和J Neville提出。SAMMO框架可以在编译时对提示进行优化，提高效率。通过将提示转化为程序结构，可以更好地利用语言模型的优势，优化提示生成过程。这一结构化方法为提示的细化和提升提供了新的可能性，对于构建高效的元提示系统具有重要意义。SAMMO框架的提出为提示优化研究和应用带来了新的思路和方法。 <div>
提出SAMMO框架，将提示表示为结构化程序，以便在强大语言模型和复杂提示的时代进行元提示优化。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Prompts As Programs: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization》T Schnabel, J Neville [Microsoft Research] (2024) <a href="https://arxiv.org/abs/2404.02319"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofi1b2mkwj20km0vo45m.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofi1bs15qj21cc0hqdkj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofi1c7e9ij20ws0m8gph.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofi1cfcffj20ws0sydja.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofi3z9lr0j20wm0rgdk2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofi3zqqp5j20wm0t4q5n.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofi402cwpj21te0zsqan.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofi402g19j20wc0qugp6.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 21:23:02 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.4)》 爱可可微博热门分享(4.4) [图片]</title>
<link>https://weibo.com/1402400261/O8cOtffBL</link>
<guid>https://weibo.com/1402400261/O8cOtffBL</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 分享, 爱可可, 4.4, 文章, 社交媒体, 关键词, 热度, 用户互动

<br /><br />总结:
爱可可微博最新一期的热门分享文章于4月4日发布，引起了社交媒体用户的热烈讨论。文章内容涉及各种热门话题，通过关键词的引导，吸引了大量用户互动和讨论。热度持续上升，展现了爱可可微博在用户心中的影响力和地位。通过分享和转发，文章得到了广泛传播和关注。整体来看，这篇文章在社交媒体上取得了不错的成绩，为爱可可微博的发展增添了新的动力。 <div>
《爱可可微博热门分享(4.4)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405019558816645311"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.4)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hof5h4sioaj20lc0c0dhn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 14:05:43 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Readout Guidance: Learning Control from Diffusion Features》(CVPR 2024) GitHub: github.com/google-research/readout_guidance《COMO:...</title>
<link>https://weibo.com/1402400261/O89B424n4</link>
<guid>https://weibo.com/1402400261/O89B424n4</guid>
<content:encoded><![CDATA[
<div> readout guidance, learning control, diffusion features, CVPR 2024, GitHub, code implementation, COMO, compact mapping, odometry, Exploiting Diffusion Prior, generalizable dense prediction, Jailbreaking Leading Safety-Aligned LLMs, simple adaptive attacks, Sparse Feature Circuits, interpretable causal graphs, Long-context LLMs, in-context learning, SciMMIR, scientific multi-modal information retrieval, T-GATE, text-to-image diffusion models, LightM-UNet, medical image segmentation, AniPortrait, audio-driven portrait animations

总结:<br /><br />这篇论文介绍了几篇在CVPR 2024会议上发表的论文实现代码的GitHub地址，涉及到了各种领域的计算机视觉研究成果。具体包括了对控制学习的提升、紧凑型地图制作和测距技术、利用扩散先验进行密集预测、对语言模型的攻击与编辑、长上下文学习时间过长、科学多模态信息检索、文本-图片扩散模型的推理难点、医学图像分割轻量级UNet模型以及音频驱动的逼真肖像动画合成等方面的研究。这些工作为各领域研究提供了重要的工具和基础模型，推动了计算机视觉领域的进步。 <div>
几篇论文实现代码：<br />《Readout Guidance: Learning Control from Diffusion Features》(CVPR 2024) GitHub: github.com/google-research/readout_guidance<br />《COMO: Compact Mapping and Odometry》(CVPR 2024) GitHub: github.com/edexheim/como<br />《Exploiting Diffusion Prior for Generalizable Dense Prediction》(CVPR 2024) GitHub: github.com/shinying/dmp<br />《Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks》(2024) GitHub: github.com/tml-epfl/llm-adaptive-attacks<br />《Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models》(2024) GitHub: github.com/saprmarks/feature-circuits<br />《Long-context LLMs Struggle with Long In-context Learning》(2024) GitHub: github.com/TIGER-AI-Lab/LongICLBench<br />《SciMMIR： Benchmarking Scientific Multi-modal Information Retrieval》(2024) GitHub: github.com/Wusiwei0410/SciMMIR [fig1]<br />《T-GATE: Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models》(2024) GitHub: github.com/HaozheLiu-ST/T-GATE [fig2]<br />《LightM-UNet: Mamba Assists in Lightweight UNet for Medical Image Segmentation》(2024) GitHub: github.com/MrBlankness/LightM-UNet<br />《AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animations》(2024) GitHub: github.com/Blizaine/AniPortrait [fig3]<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoepawlkxqj20ra0cv13q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoepvk3i3fj24ct1xk1l4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoer3jpmafj214y0sddtp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:54:26 GMT</pubDate>
</item>
<item>
<title>【RAG Arena：基于 Next.js 和 LangChain 的开源聊天机器人项目，提供了一种接受多个响应的查询体验】'RAG Arena - RAG Arena is an open-source Next.js projec...</title>
<link>https://weibo.com/1402400261/O89Al8eSF</link>
<guid>https://weibo.com/1402400261/O89Al8eSF</guid>
<content:encoded><![CDATA[
<div> Next.js, LangChain, 开源项目, 聊天机器人, 查询体验, 多个响应, 用户投票, 数据检索方法, GitHub

<br /><br />总结:
RAG Arena 是 Mendable.ai 开发的基于 Next.js 和 LangChain 的开源项目，与 LangChain 接口交互，提供了一种 RAG 聊天机器人体验，查询可以接收多个响应。用户可以对这些响应进行投票，然后解除模糊以展示被使用的检索器，通过不同的数据检索方法来区分聊天机器人。GitHub 上有相关的项目链接。 <div>
【RAG Arena：基于 Next.js 和 LangChain 的开源聊天机器人项目，提供了一种接受多个响应的查询体验】'RAG Arena - RAG Arena is an open-source Next.js project made by Mendable.ai that interfaces with LangChain to provide a RAG chatbot experience where queries receive multiple responses. Users vote on these responses, which are then unblurred to reveal the Retriever used, differentiating the chatbots by their data retrieval methods.' GitHub: github.com/mendableai/rag-arena <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoer87quqnj21740kg787.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:52:39 GMT</pubDate>
</item>
<item>
<title>【L7VP：地理空间智能可视分析和应用开发工具】'L7VP - L7VP is an geospatial intelligent visual analysis and application development tools.' GitHub: gith...</title>
<link>https://weibo.com/1402400261/O89xd5vnp</link>
<guid>https://weibo.com/1402400261/O89xd5vnp</guid>
<content:encoded><![CDATA[
<div> 地理空间、智能、可视分析、应用开发工具、L7VP、GitHub、antvis、README、开发、工具

总结:<br /><br />文章介绍了一款名为L7VP的地理空间智能可视分析和应用开发工具，可在GitHub上找到相关信息。该工具提供了智能的地理空间数据分析和可视化功能，方便开发人员进行应用开发和数据分析。用户可以通过GitHub上的README文件了解更多关于L7VP工具的详情。 <div>
【L7VP：地理空间智能可视分析和应用开发工具】'L7VP - L7VP is an geospatial intelligent visual analysis and application development tools.' GitHub: github.com/antvis/L7VP?tab=readme-ov-file <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoer07278bj21hc0u00y8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:44:57 GMT</pubDate>
</item>
<item>
<title>【Praison AI：将 AutoGen 和 CrewAI 或类似框架集成到一个低代码解决方案中，用于构建和管理多智能体 LLM 系统，重点放在简单性、定制化和高效人机协同上】'Pra...</title>
<link>https://weibo.com/1402400261/O89wKk5UU</link>
<guid>https://weibo.com/1402400261/O89wKk5UU</guid>
<content:encoded><![CDATA[
<div> AutoGen,CrewAI,多智能体,LLM系统,低代码解决方案,简单性,定制化,高效人机协同,PraisonAI,GitHub <br />
<br />
总结:<br />
Praison AI是一个整合了AutoGen和CrewAI等框架的低代码解决方案，用于构建和管理多智能体LLM系统。该解决方案专注于提供简单、定制化和高效的人机协同体验。开发者可以通过PraisonAI快速搭建和管理多智能体系统，从而实现更高效的工作流程和协作模式。感兴趣的用户可以在GitHub上找到PraisonAI的源代码和更多信息。 <div>
【Praison AI：将 AutoGen 和 CrewAI 或类似框架集成到一个低代码解决方案中，用于构建和管理多智能体 LLM 系统，重点放在简单性、定制化和高效人机协同上】'Praison AI - PraisonAI application combines AutoGen and CrewAI or similar frameworks into a low-code solution for building and managing multi-agent LLM systems, focusing on simplicity, customisation, and efficient human-agent collaboration.' GitHub: github.com/MervinPraison/PraisonAI <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoeqz07r47j21740hudip.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:43:48 GMT</pubDate>
</item>
<item>
<title>【RunsOn: 自建 GitHub Action 运行器，提供更便宜、更快的 CI/CD 体验】’RunsOn: 10x cheaper GitHub Action runners. - 10x cheaper GitHub Action runners. ...</title>
<link>https://weibo.com/1402400261/O89vx5PAn</link>
<guid>https://weibo.com/1402400261/O89vx5PAn</guid>
<content:encoded><![CDATA[
<div> RunsOn, 自建 GitHub Action 运行器, 更便宜, 更快, CI/CD, 体验, GitHub Action runners, caches, On premise.<br /><br />总结: RunsOn 是一个提供更便宜、更快的自建 GitHub Action 运行器的平台，可以提供10倍更便宜的 GitHub Action runners 和5倍更快的缓存服务，用户可以在本地部署该平台以获得更优秀的 CI/CD 体验。GitHub 地址为github.com/runs-on/runs-on。 <div>
【RunsOn: 自建 GitHub Action 运行器，提供更便宜、更快的 CI/CD 体验】’RunsOn: 10x cheaper GitHub Action runners. - 10x cheaper GitHub Action runners. 5x faster caches. On premise.' GitHub: github.com/runs-on/runs-on <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoeqvvz33aj20v80u0n1q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:40:49 GMT</pubDate>
</item>
<item>
<title>【AURORA：免费的GPT3.5 API】’AURORA' GitHub: github.com/aurora-develop/aurora #开源# #机器学习# #人工智能#</title>
<link>https://weibo.com/1402400261/O89uMw7en</link>
<guid>https://weibo.com/1402400261/O89uMw7en</guid>
<content:encoded><![CDATA[
<div> GitHub, AURORA, 免费, GPT3.5, API

<br /><br />总结:
AURORA是一个提供免费的GPT3.5 API的开源项目，可通过GitHub进行访问和使用。该API能够帮助开发者快速开发语言处理和生成任务，为用户提供便利。 <div>
【AURORA：免费的GPT3.5 API】’AURORA' GitHub: github.com/aurora-develop/aurora <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a>
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:38:58 GMT</pubDate>
</item>
<item>
<title>【Gazelle：名为 Gazelle 的语音和语言联合模型，可直接响应音频】'Gazelle - Joint Speech Language Model - Joint speech-language model - respond directly ...</title>
<link>https://weibo.com/1402400261/O89ujjcYX</link>
<guid>https://weibo.com/1402400261/O89ujjcYX</guid>
<content:encoded><![CDATA[
<div> 语音和语言联合模型、Gazelle、GitHub、直接响应音频、联合模型、模型、语音、语言、音频

总结:<br /><br />这篇文章介绍了一种名为Gazelle的语音和语言联合模型，能够直接响应音频输入。该模型已在GitHub上开源，能够有效处理语音和语言任务，提供更加智能的交互体验。Gazelle模型的特点在于能够联合处理语音和语言信息，实现更高效的响应和交互能力。通过GitHub链接，用户可以了解和使用这一先进的模型技术。 <div>
【Gazelle：名为 Gazelle 的语音和语言联合模型，可直接响应音频】'Gazelle - Joint Speech Language Model - Joint speech-language model - respond directly to audio!' GitHub: github.com/tincans-ai/gazelle <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoeqsrsj7ej20u0128q77.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:37:48 GMT</pubDate>
</item>
<item>
<title>【DOOM Mistral：用Mistral-7B模型利用 ViZDoom 引擎通过视觉输入玩 DOOM】'DOOM Mistral - Mistral7B playing DOOM' GitHub: github.com/umuthopeyildirim/DOOM...</title>
<link>https://weibo.com/1402400261/O89sEoRqI</link>
<guid>https://weibo.com/1402400261/O89sEoRqI</guid>
<content:encoded><![CDATA[
<div> ViZDoom、Mistral-7B、DOOM、GitHub、视觉输入、引擎、玩、模型

DOOM Mistral项目使用Mistral-7B模型结合ViZDoom引擎，通过视觉输入来玩DOOM游戏。项目代码可在GitHub上找到。这个项目展示了如何利用AI模型和游戏引擎结合，实现视觉输入下的游戏玩法。 <div>
【DOOM Mistral：用Mistral-7B模型利用 ViZDoom 引擎通过视觉输入玩 DOOM】'DOOM Mistral - Mistral7B playing DOOM' GitHub: github.com/umuthopeyildirim/DOOM-Mistral <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoeqoi1tgoj20tg0r80vl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:33:43 GMT</pubDate>
</item>
<item>
<title>【Multi Modal Starter Kit：多模态启动包，支持视频理解和叙述】'Multi Modal Starter Kit - Multi-modal starter kit for AI video understanding and narrati...</title>
<link>https://weibo.com/1402400261/O89johygh</link>
<guid>https://weibo.com/1402400261/O89johygh</guid>
<content:encoded><![CDATA[
<div> 视频理解、叙述、多模态启动包、AI、Ollama、Llava、bakllava、GPT-4v、GitHub、tigrisdata-community<br />
<br />
AI视频理解和叙述的多模态启动包，支持Ollama、GPT-4v等工具的使用。用户可访问GitHub上的项目链接获取相关资源。 <div>
【Multi Modal Starter Kit：多模态启动包，支持视频理解和叙述】'Multi Modal Starter Kit - Multi-modal starter kit for AI video understanding and narration. Works with Ollama (Llava, bakllava), GPT-4v' GitHub: github.com/tigrisdata-community/multi-modal-starter-kit <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoeq0rtvegj214b0u0dk9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:10:54 GMT</pubDate>
</item>
<item>
<title>【Search4All：开源版Perplexity，基于 LLM 和搜索引擎构建的平台，具有可定制且美观的界面，支持共享缓存搜索结果】’Search4All - Open source version of Per...</title>
<link>https://weibo.com/1402400261/O89iJc55p</link>
<guid>https://weibo.com/1402400261/O89iJc55p</guid>
<content:encoded><![CDATA[
<div> 开源版Perplexity，LLM，搜索引擎，平台，界面定制，搜索结果共享，GitHub，AI搜索引擎，可定制美观界面<br />
<br />搜索4All是一个基于LLM和搜索引擎构建的平台，旨在提供开源版本的Perplexity，用户可以定制美观界面，并支持共享缓存搜索结果。该项目已在GitHub上发布，用户可以在github.com/fatwang2/search4all上找到相关信息。这个AI搜索引擎平台提供了一种新的搜索体验，用户可以根据自己的需求定制界面风格，并享受到共享搜索结果的便利性。 <div>
【Search4All：开源版Perplexity，基于 LLM 和搜索引擎构建的平台，具有可定制且美观的界面，支持共享缓存搜索结果】’Search4All - Open source version of Perplexity, your own AI search engine' GitHub: github.com/fatwang2/search4all <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoepz1euaqj212o0u0tcv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:09:16 GMT</pubDate>
</item>
<item>
<title>【只需250美元的低成本开源机械臂】- 可以建造第二个机械臂(领航者臂)来控制另一个臂(跟随者臂)。领航者臂的设计参考GELLO项目但更简单。这种机械臂非常适合机器...</title>
<link>https://weibo.com/1402400261/O88jYlBat</link>
<guid>https://weibo.com/1402400261/O88jYlBat</guid>
<content:encoded><![CDATA[
<div> 开源机械臂、低成本、第二个机械臂、领航者臂、跟随者臂、Dynamixel电机、机器人学习、部件购买链接、3D打印文件、衣服折叠。<br />
<br />
总结:<br />
这篇文章介绍了一种低成本开源机械臂，可以建造第二个机械臂来控制另一个臂。其中采用了Dynamixel XL430和XL330舵机电机，通过Dynamixel SDK控制。作者提供了详细的部件购买链接、装配视频、3D打印文件和组装说明，使读者能够复现这个机械臂。该机械臂适合机器人学习和低成本机器人应用研究，作者演示了机械臂可以折叠衣服，展示了其潜力和价值。 <div>
【只需250美元的低成本开源机械臂】<br />- 可以建造第二个机械臂(领航者臂)来控制另一个臂(跟随者臂)。领航者臂的设计参考GELLO项目但更简单。这种机械臂非常适合机器人学习。   <br />- 该机械臂使用Dynamixel XL430和XL330舵机电机。XL430电机近乎是XL330的两倍强力，用于前两个关节。XL330电机较弱但每个只重18克，使臂非常轻巧和快速。   <br />- 手臂可以通过Dynamixel SDK控制：pip install dynamixel-sdk。提供了一个简单的遥控脚本teleoperation.py来测试机械臂，可能需要调整设备名称。   <br />- 仓库提供了详细的部件购买链接、装配视频、3D打印文件、组装说明，可以让读者复现这个低成本机械臂。   <br />- 作者演示了两个这样的臂可以折叠衣服。该项目对于机器人学习和低成本机器人应用研究具有价值。<br />’$250 Robot Arm' GitHub: github.com/AlexanderKoch-Koch/low_cost_robot <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoeln98w8ij21400u041c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 02:39:35 GMT</pubDate>
</item>
<item>
<title>【LLM入门：不涉及太多数学和术语的LLM基本原理通俗讲解】《Large language models, explained with a minimum of math and jargon》 网页链接 #机器学习# #人工...</title>
<link>https://weibo.com/1402400261/O887qiGgi</link>
<guid>https://weibo.com/1402400261/O887qiGgi</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、解释、基本原理、通俗、数学、术语、讲解

<br /><br />总结:
本文通俗易懂地解释了大型语言模型的基本原理，避免涉及过多数学和专业术语。大型语言模型是指可以处理大量语言数据的模型，通过学习语言规则和模式来生成文本。它们通过巨大的数据集来训练，逐渐提升预测和生成文本的能力。大型语言模型的发展对自然语言处理和人工智能领域具有重要意义，未来有望应用于各种场景中。 <div>
【LLM入门：不涉及太多数学和术语的LLM基本原理通俗讲解】《Large language models, explained with a minimum of math and jargon》 <a href="https://www.understandingai.org/p/large-language-models-explained-with"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoekqyz080j214g0pbtc7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoekr2g625j214g0lnjv5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 02:08:40 GMT</pubDate>
</item>
<item>
<title>【LLM“红队”课程：教你如何测试和发现LLM应用中的漏洞，以使其更安全。通过提示注入攻击各种聊天机器人应用，看系统如何反应，理解安全失败。LLM失败会导致法...</title>
<link>https://weibo.com/1402400261/O87ROztmK</link>
<guid>https://weibo.com/1402400261/O87ROztmK</guid>
<content:encoded><![CDATA[
<div> 红队、LLM应用、漏洞、安全、注入攻击、系统反应、安全失败、法律责任、声誉损害、服务中断
<br />
<br />
总结：本文介绍了一门关于“红队”测试LLM应用的课程，通过教授如何测试和发现应用中的漏洞，从而使其更安全。课程内容包括提示注入攻击各种聊天机器人应用，观察系统反应并理解安全失败的原因。强调LLM应用的失败可能导致法律责任、声誉损害和高昂的服务中断，因此学习如何积极测试、攻击和改进LLM应用的健壮性至关重要。通过本课程，学习者可以提升安全意识，提高对应用漏洞的识别和应对能力。 <div>
【LLM“红队”课程：教你如何测试和发现LLM应用中的漏洞，以使其更安全。通过提示注入攻击各种聊天机器人应用，看系统如何反应，理解安全失败。LLM失败会导致法律责任、声誉损害和代价高昂的服务中断。该课程帮助你积极测试、攻击和改进LLM应用的健壮性】《Red Teaming LLM Applications - DeepLearning.AI》 <a href="https://www.deeplearning.ai/short-courses/red-teaming-llm-applications/?hss_channel=tw-992153930095251456"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoejn3p2y6j20u00w20w8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 01:30:13 GMT</pubDate>
</item>
<item>
<title>【代码转换+精准时间戳：Universal-1树立语音AI新标杆】 - AssemblyAI发布了一个名为Universal-1的新语音识别(ASR)模型，在多个测试场景中展现出优异的性能和鲁...</title>
<link>https://weibo.com/1402400261/O87O4kb9T</link>
<guid>https://weibo.com/1402400261/O87O4kb9T</guid>
<content:encoded><![CDATA[
<div> AssemblyAI, Universal-1, 语音识别, ASR, 性能, 鲁棒性, 用户偏好测试, 代码转换, 时间戳, 鲁棒性, 推理速度

<br /><br />总结:
AssemblyAI发布了Universal-1新语音识别模型，展现出优异性能和鲁棒性。在用户偏好测试中，大多数用户更喜欢Universal-1。Universal-1具有代码转换能力，可转录多种语言。精准估计单词级时间戳，适用于音视频编辑和会话分析。在多个数据集中性能表现优异，特别是在电话和嘈杂环境中。推理速度优于其他模型，有助于实时处理应用。在各方面的表现证明了AssemblyAI在语音识别领域的实力，将推动语音AI在各行业应用。用户偏好、代码转换、时间戳精准度、鲁棒性和推理速度等方面都展示了Universal-1的优势，提升了其实用性和适用性。 <div>
【代码转换+精准时间戳：Universal-1树立语音AI新标杆】  <br />- AssemblyAI发布了一个名为Universal-1的新语音识别(ASR)模型，在多个测试场景中展现出优异的性能和鲁棒性。  <br />- 在用户偏好测试中，71%的用户更喜欢Universal-1的输出，而不是AssemblyAI之前的Conformer-2模型。  <br />- Universal-1展现出了在单个音频文件中转录多种语言的能力，即代码转换能力。  <br />- Universal-1能够精确估计单词级别的时间戳，这对于音视频编辑和会话分析等下游应用至关重要。  <br />- 在11个数据集中的5个上，Universal-1的单词错误率(WER)最低，在电话和嘈杂等声学挑战性环境中表现出强大的鲁棒性。它比Conformer-2的WER相对降低了11%。  <br />- 在相同的推理硬件上，Universal-1的处理速度优于OpenAI的Whisper Large-v3模型。  <br /><br />点评：  <br />- Universal-1在多个测试集上的出色表现证明了AssemblyAI在语音识别领域的技术实力。这将进一步推动语音AI在各行各业的应用。  <br />- 用户偏好测试结果表明，Universal-1不仅在客观指标上有优势，在主观体验上也得到了用户的认可。这对于以用户为中心的产品设计非常重要。  <br />- 代码转换能力使Universal-1能够处理多语言场景，这在全球化背景下具有重要价值，有助于提高语音技术的包容性。  <br />- 精确的单词级时间戳估计使Universal-1能够支持更广泛的应用，如字幕生成、会议纪要等，提升了其实用性。  <br />- 在嘈杂环境中的鲁棒性是Universal-1的一大亮点。这使其能够适应更多真实世界的场景，如呼叫中心、公共场所等，拓宽了应用范围。  <br />- 在推理速度上的优势使Universal-1更具成本效益，这对于需要实时处理的应用(如语音助手)尤为重要。<br />《AssemblyAI Research | Building the world's leading Speech AI models》 <a href="https://www.assemblyai.com/research/universal-1"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoejd6b80tj218g0p0mzw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoejd8sgjfj218g0p0dis.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoejdb3h4mj218g0p0wgo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 01:20:59 GMT</pubDate>
</item>
<item>
<title>【代号Lavender的AI“暗杀”系统：以色列AI军事应用引发伦理和道义拷问】- 以色列军方在加沙战争的前几周使用一个名为"Lavender"的AI机器，通过大规模监控收集的...</title>
<link>https://weibo.com/1402400261/O87JkzOO5</link>
<guid>https://weibo.com/1402400261/O87JkzOO5</guid>
<content:encoded><![CDATA[
<div> 以色列、AI军事应用、伦理、道义、暗杀系统、Lavender、加沙战争、目标选择、人道主义法、国际社会
<br /><br />总结:
文章揭示了以色列在加沙战争中使用AI进行目标选择和暗杀的情况。以色列军方通过名为"Lavender"的AI系统，对加沙地区居民进行监控和评分，将大部分人列入涉嫌"哈马斯武装分子"的名单，严重违反国际人道主义法。另一个名为"Where’s Daddy?"的系统跟踪目标并向军方发出打击信号，故意攻击家庭住宅，展现了行动的残酷和不人道性。高级指挥官的言论暗示了以色列军方普遍使用人体目标AI的可能性，对此应引起国际社会高度关注和谴责。这种利用AI进行杀戮的做法对人工智能军事应用提出了监管挑战，国际社会需要建立规范，确保人工智能发展符合人道主义精神。 <div>
【代号Lavender的AI“暗杀”系统：以色列AI军事应用引发伦理和道义拷问】<br />- 以色列军方在加沙战争的前几周使用一个名为"Lavender"的AI机器，通过大规模监控收集的信息，对加沙地带230万居民中的大多数人进行分析和评分，标记了大约37,000名巴勒斯坦人为涉嫌的"哈马斯武装分子"，大部分是初级成员，列入暗杀名单。   <br />- Lavender软件为加沙的几乎每个人给出1到100的评分，表示他们是哈马斯或巴勒斯坦伊斯兰圣战组织军事翼活跃分子的可能性。  <br />- 以色列军方还使用一个名为"Where’s Daddy?"的系统跟踪这些目标，并在他们进入家中时向军方发出信号。然后军方选择使用"哑弹"打击这些家庭住宅。  <br />- Lavender与以色列军方的另一个AI系统"The Gospel"不同，后者标记军方声称武装分子使用的建筑物和结构，而Lavender标记人并将其列入暗杀名单。  <br />- 以色列高级指挥官曾多次暗示像Lavender这样的人体目标机器的存在。一位8200部队数据科学和AI中心的指挥官在一次私人讲座中也提到了这一点。<br /><br />点评：  <br />- 这篇调查报道揭示了以色列在加沙战争中大规模使用AI进行目标选择和暗杀的惊人细节，引发了对高度自动化战争的伦理和法律问题的严重关切。  <br />- Lavender系统对平民进行大规模监控和评分，并将其列入暗杀名单，这种做法严重违反国际人道主义法，可能构成战争罪。它模糊了战斗人员和平民之间的界限，使平民处于极其危险的境地。  <br />- "Where’s Daddy?"系统跟踪目标并在其进入家中时发出打击信号，故意攻击家庭住宅，这进一步凸显了以色列军事行动的残酷性和不人道性。  <br />- 与标记建筑物的"The Gospel"系统不同，Lavender直接针对人，创建"杀戮名单"，这种做法更加令人不安，因为它赋予机器决定生死的权力。  <br />- 以色列高级指挥官关于人体目标AI的言论表明，这种做法在以色列军方中可能相当普遍，需要国际社会高度警惕和谴责。  <br />- 这种利用AI进行杀戮的做法，对人工智能军事应用的治理和监管提出了严峻挑战。国际社会亟需建立相关规范，防止AI武器化，确保人工智能的发展符合人道主义精神。<br />《‘Lavender’: The AI machine directing Israel’s bombing spree in Gaza》 <a href="https://www.972mag.com/lavender-ai-israeli-army-gaza/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoeiw7qd47j21at0u0aeu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 01:09:19 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@异步图书 送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进...</title>
<link>https://weibo.com/1402400261/O86TsEVJz</link>
<guid>https://weibo.com/1402400261/O86TsEVJz</guid>
<content:encoded><![CDATA[
<div> 大语言模型、前沿、科学家、工程师、学生、案例、庖丁解牛、全面、深入、方法与工具

总结:<br /><br />文章介绍了一本名为《大语言模型：基础与前沿》的书籍，截至2024年4月12日，读者可以通过转发+评论参与送出3本这本书。这本书全面深入地介绍了大语言模型以及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。与纯理论的说教模式不同，这本书采用了从案例入手的方式，采用庖丁解牛的方法帮助读者理解和认识大语言模型。 <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%BC%82%E6%AD%A5%E5%9B%BE%E4%B9%A6">@异步图书</a>  送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。摒弃了纯理论的说教模式，从案例入手， 采用庖丁解牛的方式帮助读者理解与认识大语言模型。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019331269755053"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef8oboqij20ga0m8q8p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9segl7j20m90m9q6z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9t5km0j20m90m942f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef9tq2esj20m90m9gpe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef9ugq5dj20m90m9dif.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 23:01:32 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@博文视点Broadview 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言...</title>
<link>https://weibo.com/1402400261/O86RdFp49</link>
<guid>https://weibo.com/1402400261/O86RdFp49</guid>
<content:encoded><![CDATA[
<div> LangChain, LangServe, LangSmith, LLM, 初学者, 多个核心应用场景, LCEL, LangChain团队, 生成式人工智能, LangChain生态系统

总结:<br />
本文介绍了LangChain团队的新书《LangChain实战》，针对初学者和对LangChain应用感兴趣的开发者。书籍基于LangChain 0.1版本，配套详解视频，重点介绍了多个核心应用场景，并深入探讨了LCEL的应用方式。同时，书中详细探讨了LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。欢迎感兴趣的读者转发+评论参与活动，赢取精彩的实战书籍！ <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5ywtixj20ku0zzdmx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 22:56:01 GMT</pubDate>
</item>
<item>
<title>今日推介(第1365期)：潜扩散模型的缩放特性、语言模型对齐的渐近性、面向高效LLM生成的提示混合专家、用偏好树提高LLM推理能力、长上下文LLM的长上下文学习能力...</title>
<link>https://weibo.com/1402400261/O86Ihb4Al</link>
<guid>https://weibo.com/1402400261/O86Ihb4Al</guid>
<content:encoded><![CDATA[
<div> 潜扩散模型, 缩放特性, 语言模型, 对齐, 渐近性, 提示混合专家, 偏好树, 推理能力, 长上下文, 学习能力

<br /><br />总结:
本文讨论了潜扩散模型的缩放特性和语言模型对齐的渐近性。研究指出，面向高效LLM生成的提示混合专家可以提高LLM的推理能力。同时，通过偏好树的方法，可以进一步提高LLM的推理能力。长上下文LLM具有较强的长上下文学习能力，需要进行专门的评估。研究展示了这些模型在不同场景下的表现，为提高自然语言处理模型的性能提供了重要参考。 <div>
今日推介(第1365期)：潜扩散模型的缩放特性、语言模型对齐的渐近性、面向高效LLM生成的提示混合专家、用偏好树提高LLM推理能力、长上下文LLM的长上下文学习能力评估 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/690674008"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoeejddux9j21ao0pi79e.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoeejff0r5j20wg0u042g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoeejixv1qj21hi0rmgpq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoeejlnscej20x00oo0w5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoeejqx22gj21hc0qswlh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 22:33:57 GMT</pubDate>
</item>
<item>
<title>[CV] ViTamin: Designing Scalable Vision Models in the Vision-Language Era 网页链接 通过重新评估视觉语言模型的视觉后骨干设计，提出了一种融合卷积和Trans...</title>
<link>https://weibo.com/1402400261/O86CVvK4U</link>
<guid>https://weibo.com/1402400261/O86CVvK4U</guid>
<content:encoded><![CDATA[
<div> 关键词: ViTamin, 视觉语言模型, 可拓展性, 下游任务迁移, 混合网络, 卷积, Transformer

总结:<br /><br />
本文重新评估了视觉语言模型的设计，提出了混合网络ViTamin，结合了卷积和Transformer，实现了比ViT更好的可拓展性和下游任务迁移。ViTamin的设计在视觉语言领域具有重要意义，为改善模型性能和应用提供了新的思路。ViTamin的融合设计使其能够更好地理解图像和语言之间的关系，为解决视觉与语言结合的挑战提供了一种创新的方法。混合网络的设计不仅提高了模型在不同任务上的表现，还为未来的研究和应用奠定了基础。这项研究为视觉语言模型的发展和优化提供了有益的启示，为相关领域的进一步探索和创新指明了方向。ViTamin的成功应用证明了混合网络在视觉与语言结合中的潜力，为未来的研究和应用带来了新的可能性。ViTamin的提出对视觉与语言模型的发展具有重要的理论和实际意义，为构建更加智能和有效的视觉语言系统奠定了基础。 <div>
[CV] ViTamin: Designing Scalable Vision Models in the Vision-Language Era  <br /><a href="https://arxiv.org/abs/2404.02132"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过重新评估视觉语言模型的视觉后骨干设计，提出了一种融合卷积和Transformer的混合网络ViTamin，实现了比ViT更好的可拓展性和下游任务迁移。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoee611zmpj212m1aqh6x.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoee61avepj21cy16i4e9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoee61nvddj21de0okn69.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 22:20:48 GMT</pubDate>
</item>
<item>
<title>[CV] Surface Reconstruction from Gaussian Splatting via Novel Stereo Views 网页链接 提出通过3DGS合成立体视图并立体匹配获取深度的表面重建方法，使重建质...</title>
<link>https://weibo.com/1402400261/O86zqaJ9s</link>
<guid>https://weibo.com/1402400261/O86zqaJ9s</guid>
<content:encoded><![CDATA[
<div> 3DGS合成、立体视图、立体匹配、表面重建、质量、速度、神经重建<br />
<br />
总结:<br />
本研究提出了一种通过3DGS合成立体视图并进行立体匹配来获取深度的表面重建方法。与仅基于3DGS的方法相比，该方法重建质量更高，而且速度也要快得多，超越了复杂的神经重建方法。通过这种创新方法，可以更有效地重建物体的表面结构，为三维重建领域的进展带来了新的可能性。 <div>
[CV] Surface Reconstruction from Gaussian Splatting via Novel Stereo Views  <br /><a href="https://arxiv.org/abs/2404.01810"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />提出通过3DGS合成立体视图并立体匹配获取深度的表面重建方法，使重建质量超过仅基于3DGS的方法，速度也远快于复杂的神经重建。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoedwz5a6rj20s816kn8d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoedwzkmn3j21380la0zd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoedx0a70pj213a19i7ei.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 22:12:09 GMT</pubDate>
</item>
<item>
<title>[LG] Are large language models superhuman chemists? 网页链接 提出ChemBench化学基准测试，发现前沿大语言模型整体超过人类专家，但在化学推理和安全评估方面...</title>
<link>https://weibo.com/1402400261/O86umebTC</link>
<guid>https://weibo.com/1402400261/O86umebTC</guid>
<content:encoded><![CDATA[
<div> ChemBench化学基准测试, 大语言模型, 超越人类专家, 化学推理, 安全评估, 局限, 提升

<br /><br />总结:
研究引入了ChemBench化学基准测试，发现前沿大语言模型在整体上超过了人类专家。然而，这些模型在化学推理和安全评估方面仍存在局限性，需要进一步提升。 <div>
[LG] Are large language models superhuman chemists?  <br /><a href="https://arxiv.org/abs/2404.01475"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />提出ChemBench化学基准测试，发现前沿大语言模型整体超过人类专家，但在化学推理和安全评估方面仍有局限，需要进一步提升。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoedk072x7j20tc11adq2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoedk0uh2nj218o0v2n67.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoedk1cnqcj218c0ve10a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoedk1wb03j218u0retgu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:59:41 GMT</pubDate>
</item>
<item>
<title>[CL] Octopus v2: On-device language model for super agent 网页链接 提出了一种通过为每个函数指定唯一标记并进行微调的方法，使20亿参数的在设备语言模型在...</title>
<link>https://weibo.com/1402400261/O86rNDTtw</link>
<guid>https://weibo.com/1402400261/O86rNDTtw</guid>
<content:encoded><![CDATA[
<div> 关键词: Octopus v2, 在设备语言模型, 20亿参数, 超越GPT-4, 函数指定唯一标记, 微调, 函数调用任务, 精度, 速度<br />

总结:<br />
研究提出了Octopus v2，这是一种在设备上的语言模型，通过为每个函数指定唯一标记并进行微调，实现了20亿参数的模型在函数调用任务上超越了GPT-4的精度和速度。 Octopus v2模型的性能表现得非常出色，展示了其在应用领域的巨大潜力。通过该研究，可以看到在设备语言模型的研究领域有着广阔的发展前景，为未来的研究和实践提供了新的思路和方法。 <div>
[CL] Octopus v2: On-device language model for super agent  <br /><a href="https://arxiv.org/abs/2404.01744"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出了一种通过为每个函数指定唯一标记并进行微调的方法，使20亿参数的在设备语言模型在函数调用任务上显著超越GPT-4的精度与速度。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoeddi6m7qj20v01b4gv8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoeddiicy6j215y0iun0a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeddiyjv0j216e0ne0xk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:53:23 GMT</pubDate>
</item>
<item>
<title>通过构建长文本上下文学习基准LongICLBench，比较多种语言模型的能力，发现当前模型在复杂场景下理解长文本仍面临困难。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Lon...</title>
<link>https://weibo.com/1402400261/O86pp4qkN</link>
<guid>https://weibo.com/1402400261/O86pp4qkN</guid>
<content:encoded><![CDATA[
<div> 长文本上下文学习基准、多种语言模型、复杂场景、困难、LongICLBench、长文本理解挑战

<br /><br />总结:
研究人员构建了长文本上下文学习基准LongICLBench，通过比较多种语言模型的能力发现，当前模型在复杂场景下理解长文本仍面临困难。文章指出长文本上下文学习是一个挑战，并提出在长文本任务中进行更深入的研究和改进长文本理解能力的方法。这项研究对于改善语言模型在长文本理解上的表现具有重要意义。 <div>
通过构建长文本上下文学习基准LongICLBench，比较多种语言模型的能力，发现当前模型在复杂场景下理解长文本仍面临困难。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Long-context LLMs Struggle with Long In-context Learning》T Li, G Zhang, Q D Do, X Yue, W Chen [University of Waterloo] (2024) <a href="https://arxiv.org/abs/2404.02060"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoeczzai10j218e12etr3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeczztbjaj21hc0qsqci.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoed00cvbrj21hi0xkwvw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoed00j4c9j21gu0l20xp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoed7a2pwtj20vd0k2go5.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:47:28 GMT</pubDate>
</item>
<item>
<title>[CL]《Long-context LLMs Struggle with Long In-context Learning》T Li, G Zhang, Q D Do, X Yue, W Chen [University of Waterloo] (2024) 网页链接 #机器学...</title>
<link>https://weibo.com/1402400261/O86pmeO8M</link>
<guid>https://weibo.com/1402400261/O86pmeO8M</guid>
<content:encoded><![CDATA[
<div> 长文本理解，长上下文学习，LLMs，困难，学习，上下文，模型，表现，挑战，解决方案

总结:<br />
本文讨论了长上下文语言模型（LLMs）在长篇文本理解中遇到的困难。研究指出，LLMs在处理长文本时存在学习困难，导致性能下降。主要挑战包括对长上下文的学习和理解能力不足，以及模型存储和计算量大。研究团队提出了一些解决方案，包括增加训练数据的规模和多样性，设计更有效的模型结构，以及优化存储和计算效率。这些方法有望提高LLMs在长篇文本处理中的表现。 <div>
[CL]《Long-context LLMs Struggle with Long In-context Learning》T Li, G Zhang, Q D Do, X Yue, W Chen [University of Waterloo] (2024) <a href="https://arxiv.org/abs/2404.02060"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoeczzai10j218e12etr3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeczztbjaj21hc0qsqci.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoed00cvbrj21hi0xkwvw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoed00j4c9j21gu0l20xp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoed7a2pwtj20vd0k2go5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:47:22 GMT</pubDate>
</item>
<item>
<title>通过高质量对齐数据ULTRAINTERACT与定制化的模型优化策略，开发出目前开源环境下推理能力最强的大规模语言模型EURUS。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Advan...</title>
<link>https://weibo.com/1402400261/O86lPhdtz</link>
<guid>https://weibo.com/1402400261/O86lPhdtz</guid>
<content:encoded><![CDATA[
<div> ULTRAINTERACT, 定制化的模型优化策略, EURUS, 大规模语言模型, 推理能力, 高质量对齐数据, 开源环境, 语言模型, 理论推导, 实验结果

总结:<br /><br />这篇文章介绍了一种基于高质量对齐数据ULTRAINTERACT和定制化的模型优化策略开发的大规模语言模型EURUS，通过提升推理能力，成为目前开源环境下推理能力最强的语言模型。研究团队通过理论推导和实验结果展示了EURUS的优势，为进一步提升语言模型的性能提供了新思路。 <div>
通过高质量对齐数据ULTRAINTERACT与定制化的模型优化策略，开发出目前开源环境下推理能力最强的大规模语言模型EURUS。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Advancing LLM Reasoning Generalists with Preference Trees》L Yuan, G Cui, H Wang, N Ding... [Tsinghua University &amp; Northeastern University] (2024) <a href="https://arxiv.org/abs/2404.02078"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoecqyuacaj215w0yo7lp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoecqzascfj21eg0pedlp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoecqznh5rj20x00oogq7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoecqzylyxj21e40p0qd1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoectzftqxj20vh0d5tbh.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:38:40 GMT</pubDate>
</item>
<item>
<title>[CL]《Advancing LLM Reasoning Generalists with Preference Trees》L Yuan, G Cui, H Wang, N Ding... [Tsinghua University &amp; Northeastern University] (202...</title>
<link>https://weibo.com/1402400261/O86lMeoTl</link>
<guid>https://weibo.com/1402400261/O86lMeoTl</guid>
<content:encoded><![CDATA[
<div> Preference Trees, Advancing LLM Reasoning Generalists, Tsinghua University, Northeastern University, Yuan, Cui, Wang, Ding, 2024

<br /><br />总结:
这篇文章讨论了利用偏好树来提升LLM推理通用性的方法。作者们来自清华大学和东北大学，包括Yuan、Cui、Wang和Ding。他们提出了一种新的方法，旨在帮助LLM推理通用性的进步。研究成果有望为语言模型的发展做出贡献。 <div>
[CL]《Advancing LLM Reasoning Generalists with Preference Trees》L Yuan, G Cui, H Wang, N Ding... [Tsinghua University &amp; Northeastern University] (2024) <a href="https://arxiv.org/abs/2404.02078"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoecqyuacaj215w0yo7lp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoecqzascfj21eg0pedlp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoecqznh5rj20x00oogq7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoecqzylyxj21e40p0qd1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoectzftqxj20vh0d5tbh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:38:32 GMT</pubDate>
</item>
<item>
<title>GRIFFIN利用预训练语言模型自身结构特点简单有效地实现了混合专家，大幅减少了计算成本和内存需求，为部署加速提供了灵活高效的新途径。 - 转发 @爱可可-爱生活:...</title>
<link>https://weibo.com/1402400261/O86gFr9eO</link>
<guid>https://weibo.com/1402400261/O86gFr9eO</guid>
<content:encoded><![CDATA[
<div> 预训练语言模型、混合专家、计算成本、内存需求、部署加速、灵活、高效、Prompt-prompted Mixture of Experts、H Dong、B Chen、Y Chi、CMU

<br /><br />总结:
H Dong、B Chen和Y Chi在CMU发表的《Prompt-prompted Mixture of Experts for Efficient LLM Generation》通过利用预训练语言模型自身结构特点，成功实现了混合专家的方法，大幅减少了计算成本和内存需求，为部署加速提供了灵活高效的新途径。该研究为解决语言模型生成过程中的效率和成本问题提供了重要的方法和思路。 <div>
GRIFFIN利用预训练语言模型自身结构特点简单有效地实现了混合专家，大幅减少了计算成本和内存需求，为部署加速提供了灵活高效的新途径。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Prompt-prompted Mixture of Experts for Efficient LLM Generation》H Dong, B Chen, Y Chi [CMU] (2024) <a href="https://arxiv.org/abs/2404.01365"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoecelrotmj21cw0jswod.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoecemawn1j21hm0pk489.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeceminjdj21h60lqafy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoecemop4gj21hi0rmjwl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeckpmjisj210x0dcgnp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoeckpmjpmj210x0cddh4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoeckpmyrej210x0d7jt9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeckpmpltj210x0gbabr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoeckpns53j210x14xtdv.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:25:57 GMT</pubDate>
</item>
<item>
<title>[LG]《Prompt-prompted Mixture of Experts for Efficient LLM Generation》H Dong, B Chen, Y Chi [CMU] (2024) 网页链接 #机器学习##人工智能##论文# [图片][...</title>
<link>https://weibo.com/1402400261/O86gyEnxx</link>
<guid>https://weibo.com/1402400261/O86gyEnxx</guid>
<content:encoded><![CDATA[
<div> 关键词: Prompt-prompted, Mixture of Experts, Efficient LLM Generation, 模型生成, 训练效率

总结:<br /><br />
该研究提出了一种基于Prompt-prompted Mixture of Experts的方法，用于有效生成大型语言模型（LLM）。该方法结合了不同专家的知识，通过Prompt-prompted机制引导模型生成，提高了训练效率和生成质量。研究结果表明，该方法在生成LLM时具有很高的效率和性能。这项研究对于提高大规模语言模型的生成能力具有重要意义，值得进一步深入研究和应用。 <div>
[LG]《Prompt-prompted Mixture of Experts for Efficient LLM Generation》H Dong, B Chen, Y Chi [CMU] (2024) <a href="https://arxiv.org/abs/2404.01365"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoecelrotmj21cw0jswod.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoecemawn1j21hm0pk489.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeceminjdj21h60lqafy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoecemop4gj21hi0rmjwl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeckpmjisj210x0dcgnp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoeckpmjpmj210x0cddh4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoeckpmyrej210x0d7jt9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeckpmpltj210x0gbabr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoeckpns53j210x14xtdv.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoeckpmtr2j210x0hnjtn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeckpntl1j210x0wtaf7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoeckpnr3jj210x0xejwp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:25:41 GMT</pubDate>
</item>
<item>
<title>在简单假设下，证明best-of-N对齐方法渐进等价于最优KL约束强化学习解，从理论上解释了其优异的实际表现。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Asymptotics of L...</title>
<link>https://weibo.com/1402400261/O86breDei</link>
<guid>https://weibo.com/1402400261/O86breDei</guid>
<content:encoded><![CDATA[
<div> Language Model Alignment, Best-of-N对齐方法, 最优KL约束强化学习解, 渐进等价, 理论解释, 优异实际表现, J Q Yang, S Salamatian, Z Sun, A T Suresh, A Beirami

<br /><br />总结: 
该研究探讨了最优KL约束强化学习解与best-of-N对齐方法的渐进等价性，在简单假设下进行理论分析。研究指出，best-of-N对齐方法在实际表现中表现优异，其表现优异的原因是由于其与最优KL约束强化学习解的渐进等价性。这一发现为理解模型对齐方法提供了新的视角，并为实际应用中的性能提升提供了理论支持。 <div>
在简单假设下，证明best-of-N对齐方法渐进等价于最优KL约束强化学习解，从理论上解释了其优异的实际表现。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Asymptotics of Language Model Alignment》J Q Yang, S Salamatian, Z Sun, A T Suresh, A Beirami [University of Sydney &amp; MIT &amp; Google Research] (2024) <a href="https://arxiv.org/abs/2404.01730"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoec130qb2j214811qqke.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoec139wffj21bu1887ca.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:13:04 GMT</pubDate>
</item>
<item>
<title>[LG]《Asymptotics of Language Model Alignment》J Q Yang, S Salamatian, Z Sun, A T Suresh, A Beirami [University of Sydney &amp; MIT &amp; Google Research] (20...</title>
<link>https://weibo.com/1402400261/O86bpwyeM</link>
<guid>https://weibo.com/1402400261/O86bpwyeM</guid>
<content:encoded><![CDATA[
<div> 语言模型对齐，渐近分析，大学悉尼，麻省理工，谷歌研究，2024，文献综述，模型比较，评估方法

<br /><br />总结:
本文研究了语言模型对齐的渐近分析，作者分析了大学悉尼、麻省理工和谷歌研究的相关工作。他们比较了不同模型的有效性，提出了评估方法。文章对语言模型对齐的重要性和发展方向进行了探讨，为未来相关研究提供了指导。 <div>
[LG]《Asymptotics of Language Model Alignment》J Q Yang, S Salamatian, Z Sun, A T Suresh, A Beirami [University of Sydney &amp; MIT &amp; Google Research] (2024) <a href="https://arxiv.org/abs/2404.01730"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoec130qb2j214811qqke.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoec139wffj21bu1887ca.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:13:00 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.3)》 爱可可微博热门分享(4.3) [图片]</title>
<link>https://weibo.com/1402400261/O83uPoNq9</link>
<guid>https://weibo.com/1402400261/O83uPoNq9</guid>
<content:encoded><![CDATA[
<div> 关键词：爱可可、微博、热门、分享、文章、娱乐、新闻、社交、互动、用户

总结：
《爱可可微博热门分享(4.3)》是一篇关于微博热门话题的分享文章，涵盖了娱乐、新闻等多个领域的内容。通过微博平台，用户可以及时了解到各种热门话题，进行互动和社交交流。文章内容丰富多彩，吸引了众多用户的关注和参与，展示了爱可可微博的活力和影响力。通过微博的分享和传播，让更多人了解到最新的资讯和热门事件，促进了信息的传递和交流，为用户提供了一个丰富多样的社交平台。<br /><br />  <div>
《爱可可微博热门分享(4.3)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405019200677872051"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.3)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoe0cedvtmj20rs0fm0ty.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 14:22:36 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《3D-MoLM: Towards 3D Molecule-Text Interpretation in Language Models》(2024) GitHub: github.com/lsh0520/3D-MoLM [fig4]《ViTamin: De...</title>
<link>https://weibo.com/1402400261/O83g9DU0A</link>
<guid>https://weibo.com/1402400261/O83g9DU0A</guid>
<content:encoded><![CDATA[
<div> 关键词: 3D-MoLM, 语言模型, 分子-文本解释, ViTamin, 视觉模型, 梯度对齐, 跨域人脸反欺诈, DePT, 全息提示调整, XScale-NVS, 视图合成, SWE-agent, 软件工程, Agent界面，CameraCtrl, 文本到视频生成, QuaRot, 旋转语言模型, CSD, 扩散模型, Evalverse, 语言模型评估库, JailbreakBench, 鲁邦测试基准, Eurus, 偏好树, LLaVA-Hound-DPO, 视频模型优化, LG_SDG, 医学图像分割, MuseTalk, 实时唇语同步, JaxUED, Jax库, LifelongMemory, 长时记忆, TimeMachine, 时间序列预测, 1-bit LLMs, 1.58比特语言模型, SPRIGHT, 文本到图像模型, Proxy调整, MiM-ISTD, 红外小目标检测

<br /><br />总结: 
"3D-MoLM: Towards 3D Molecule-Text Interpretation in Language Models"提出了一种在语言模型中实现3D分子-文本解释的方法，利用GitHub上的代码进行实现。
"ViTamin: Designing Scalable Vision Models in the Vision-language Era"介绍了在视觉-语言时代设计可扩展视觉模型的技术，并提供了GitHub代码。
"Gradient Alignment for Cross-Domain Face Anti-Spoofing"讨论了跨域人脸反欺诈中的梯度对齐问题，并提供了GitHub代码。
"DePT: Decoupled Prompt Tuning"介绍了一种全息提示调整的方法，帮助提升模型性能，相关代码在GitHub上有提供。
"XScale-NVS: Cross-Scale Novel View Synthesis with Hash Featurized Manifold"描述了跨尺度观点合成的技术，相关代码在GitHub上可找到。
"SWE-agent: Agent Computer Interfaces Enable Software Engineering Language Models"研究了软件工程语言模型中代理界面的应用，相关代码可在GitHub上获取。
"CameraCtrl: Enabling Camera Control for Text-to-Video Generation"介绍了一种控制相机生成文本到视频的技术，相关代码在GitHub上有提供。
"QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs"讨论了在旋转语言模型中实现无异常的4比特推断的方法，相关代码在GitHub上有提供。
"Measuring Style Similarity in Diffusion Models"探讨了扩散模型中的风格相似性衡量方法，相关代码在GitHub上可找到。
"Evalverse: Unified and Accessible Library for Large Language Model Evaluation"提供了一个统一且易用的语言模型评估库，相关代码在GitHub上有提供。 <div>
几篇论文实现代码：<br />《3D-MoLM: Towards 3D Molecule-Text Interpretation in Language Models》(2024) GitHub: github.com/lsh0520/3D-MoLM [fig4]<br />《ViTamin: Designing Scalable Vision Models in the Vision-language Era》(CVPR 2024) GitHub: github.com/Beckschen/ViTamin [fig1]<br />《Gradient Alignment for Cross-Domain Face Anti-Spoofing》(CVPR 2024) GitHub: github.com/Leminhbinh0209/CVPR24-FAS<br />《DePT: Decoupled Prompt Tuning》(CVPR 2024) GitHub: github.com/Koorye/DePT [fig5]<br />《XScale-NVS: Cross-Scale Novel View Synthesis with Hash Featurized Manifold》(CVPR 2024) GitHub: github.com/THU-luvision/XScale-NVS<br />《SWE-agent: Agent Computer Interfaces Enable Software Engineering Language Models》(2024) GitHub: github.com/princeton-nlp/SWE-agent<br />《CameraCtrl: Enabling Camera Control for Text-to-Video Generation》(2024) GitHub: github.com/hehao13/CameraCtrl<br />《QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs》(2024) GitHub: github.com/spcl/QuaRot<br />《Measuring Style Similarity in Diffusion Models》(2024) GitHub: github.com/learn2phoenix/CSD<br />《Evalverse: Unified and Accessible Library for Large Language Model Evaluation》(2024) GitHub: github.com/UpstageAI/evalverse<br />《JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models》(2024) GitHub: github.com/JailbreakBench/jailbreakbench<br />《Advancing LLM Reasoning Generalists with Preference Trees》(2024) GitHub: github.com/OpenBMB/Eurus<br />《Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward》(2024) GitHub: github.com/RifleZhang/LLaVA-Hound-DPO<br />《Language Grounded Single Source Domain Generalization in Medical Image Segmentation》(2024) GitHub: github.com/ShahinaKK/LG_SDG [fig2]<br />《MuseTalk: Real-Time High Quality Lip Synchorization with Latent Space Inpainting》(2024) GitHub: github.com/TMElyralab/MuseTalk [fig3]<br />《JaxUED: A simple and useable UED library in Jax》(2024) GitHub: github.com/DramaCow/jaxued<br />《LifelongMemory: Leveraging LLMs for Answering Queries in Long-form Egocentric Videos》(2024) GitHub: github.com/Agentic-Learning-AI-Lab/lifelong-memory<br />《TimeMachine: A Time Series is Worth 4 Mambas for Long-term Forecasting》(2024) GitHub: github.com/Atik-Ahamed/TimeMachine<br />《The Era of 1-bit LLMs All Large Language Models are in 1.58 Bits》(2024) GitHub: github.com/rejunity/tiny-asic-1_58bit-matrix-mul<br />《Getting it Right: Improving Spatial Consistency in Text-to-Image Models》(2024) GitHub: github.com/SPRIGHT-T2I/SPRIGHT<br />《Tuning Language Models by Proxy》(2024) GitHub: github.com/alisawuffles/proxy-tuning<br />《MiM-ISTD: Mamba-in-Mamba for Efficient Infrared Small Target Detection》(2024) GitHub: github.com/txchen-USTC/MiM-ISTD [fig6]<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hodvmdi4ttj20wn0k011z.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hodvpkbxh3j23tn2vru0y.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hodw340ylwj22s419lk3q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hodwtb71cbj21890eidy5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hodwucbmrpj212q0d37c8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hody2sz7yoj20lo0bh40p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 13:46:27 GMT</pubDate>
</item>
<item>
<title>【Home LLM：基于本地LLM的家庭助理】’Home LLM - A Home Assistant integration that allows you to control your house using an LLM running locally' GitHu...</title>
<link>https://weibo.com/1402400261/O83bBsjHZ</link>
<guid>https://weibo.com/1402400261/O83bBsjHZ</guid>
<content:encoded><![CDATA[
<div> LLM、Home Assistant、GitHub、本地、家庭助理、控制、房屋、集成、acond96、家庭助手<br />
<br />
LLM是一个基于本地LLM的家庭助理，可以让用户通过Home Assistant集成来控制房屋。用户可以在GitHub上找到这个项目，作者是acond96。这个家庭助手的特点是可以在本地运行，提供更安全和私密的控制体验。通过Home LLM，用户可以方便地管理房屋设备和自动化任务，带来更便捷的生活方式。 <div>
【Home LLM：基于本地LLM的家庭助理】’Home LLM - A Home Assistant integration that allows you to control your house using an LLM running locally' GitHub: github.com/acon96/home-llm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodyz6j2pgj213c0u0n2q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 13:35:14 GMT</pubDate>
</item>
<item>
<title>【学术论文极简LaTeX模板】'Minimalist LaTeX Template for Academic Papers - Minimalist LaTeX template for academic papers' GitHub: github.com/pmichailla...</title>
<link>https://weibo.com/1402400261/O82XehgrP</link>
<guid>https://weibo.com/1402400261/O82XehgrP</guid>
<content:encoded><![CDATA[
<div> LaTeX, 模板, 学术论文, GitHub, 精简, pmichaillat 

<br /><br />总结:
这篇学术论文介绍了一个极简的LaTeX模板，主要用于撰写学术论文。该模板提供了简洁的设计和布局，适用于学术界的各种研究领域。作者提供了GitHub地址，方便用户下载和使用。这个模板以简洁、易用和专业为特点，可以帮助学术作者高效地撰写论文。 <div>
【学术论文极简LaTeX模板】'Minimalist LaTeX Template for Academic Papers - Minimalist LaTeX template for academic papers' GitHub: github.com/pmichaillat/latex-paper <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodxydcpzqj21iq0tidm6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 12:59:49 GMT</pubDate>
</item>
<item>
<title>'Open Parse - Streamlines the process of preparing documents for LLM's.' GitHub: github.com/Filimoa/open-parse #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O82VU8v1i</link>
<guid>https://weibo.com/1402400261/O82VU8v1i</guid>
<content:encoded><![CDATA[
<div> GitHub, Open Parse, Streamlines, documents, preparing, LLM's, Filimoa, 

此项目名为Open Parse，旨在简化准备文件为LLM的过程。该项目的GitHub链接为github.com/Filimoa/open-parse。通过使用Open Parse，用户可以更高效地处理文件，节省时间和精力。该工具可以帮助LLM的工作更加流畅和高效，提升工作效率。通过GitHub平台，用户可以方便地获取并使用Open Parse工具，为文件处理过程带来便利。总之，Open Parse是一款实用的工具，为准备文件为LLM提供了便捷的解决方案。 <br /><br />总结： <br />Open Parse是一个可以简化准备文件为LLM的过程的工具，通过GitHub平台提供给用户使用，为文件处理过程带来便利，提升工作效率。 <div>
'Open Parse - Streamlines the process of preparing documents for LLM's.' GitHub: github.com/Filimoa/open-parse <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hodxusqf37j20u00uhdk2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 12:56:33 GMT</pubDate>
</item>
<item>
<title>【LLM相关论文分类列表】’Awesome-LLM-related-Papers-Comprehensive-Topics - Awesome LLM-related papers and repos on very comprehensive topics.' GitHub:...</title>
<link>https://weibo.com/1402400261/O82JOEFhu</link>
<guid>https://weibo.com/1402400261/O82JOEFhu</guid>
<content:encoded><![CDATA[
<div> GitHub, Awesome, LLM, Papers, Repos, Comprehensive Topics, 论文分类, 相关研究, 研究领域

<br /><br />总结:该GitHub项目收集了关于LLM（硕士法学）相关的优秀论文和资源，涵盖了非常全面的主题。通过这个项目，研究者可以轻松地找到有关LLM领域的相关研究成果和资源，有助于帮助他们深入了解和探索这一领域。GitHub平台的开放性和便利性使得研究者们可以方便地分享和获取LLM相关研究成果，促进了学术交流和合作。希望这个项目能够为研究者们提供有益的参考和指导，推动LLM研究领域的发展。 <div>
【LLM相关论文分类列表】’Awesome-LLM-related-Papers-Comprehensive-Topics - Awesome LLM-related papers and repos on very comprehensive topics.' GitHub: github.com/shure-dev/Awesome-LLM-related-Papers-Comprehensive-Topics <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hodx00affrj20vf0u0gqe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 12:26:47 GMT</pubDate>
</item>
<item>
<title>【llm-export：llm模型导出工具，能够将llm模型导出为onnx和mnn模型】'llm-export - llm-export can export llm model to onnx.' GitHub: github.com/wangzhaode...</title>
<link>https://weibo.com/1402400261/O82Fu6YUD</link>
<guid>https://weibo.com/1402400261/O82Fu6YUD</guid>
<content:encoded><![CDATA[
<div> llm-export, llm模型, 导出工具, onnx, mnn模型<br />
<br />
llm-export是一种工具，可以将llm模型导出为onnx和mnn模型。这个工具在GitHub上有开源代码，可以方便地将llm模型转换为onnx格式，便于在其他平台上使用。通过使用llm-export工具，用户可以快速方便地转换和导出llm模型，从而实现跨平台应用和部署。 <div>
【llm-export：llm模型导出工具，能够将llm模型导出为onnx和mnn模型】'llm-export - llm-export can export llm model to onnx.' GitHub: github.com/wangzhaode/llm-export <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hodwovijovj213i0oe0vz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 12:16:06 GMT</pubDate>
</item>
<item>
<title>'MicroLlama-300M - a small Llama based model with 300M parameters trained from scratch with $500 budget' GitHub: github.com/keeeeenw/MicroLlama #开源#...</title>
<link>https://weibo.com/1402400261/O82DKw8P4</link>
<guid>https://weibo.com/1402400261/O82DKw8P4</guid>
<content:encoded><![CDATA[
<div> MicroLlama-300M, small, Llama, 300M parameters, trained from scratch, $500 budget, GitHub, keeeeenw, MicroLlama

<br /><br />
总结:
本文介绍了一个名为MicroLlama-300M的小型Llama模型，拥有300M个参数，并且是从头开始用500美元的预算训练的。该项目的源代码托管在GitHub上的keeeeenw/MicroLlama仓库中。MicroLlama-300M模型通过在有限预算下训练，展示了良好的性能和效率。 <div>
'MicroLlama-300M - a small Llama based model with 300M parameters trained from scratch with $500 budget' GitHub: github.com/keeeeenw/MicroLlama <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hodwkg7r0wj20z80u0431.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 12:11:50 GMT</pubDate>
</item>
<item>
<title>【RAG评估数据集】’Docugami Knowledge Graph Retrieval Augmented Generation (KG-RAG) Datasets - Knowledge Graph Retrieval Augmented Generation (KG-RAG)...</title>
<link>https://weibo.com/1402400261/O82wcrw6z</link>
<guid>https://weibo.com/1402400261/O82wcrw6z</guid>
<content:encoded><![CDATA[
<div> GitHub, Docugami, Knowledge Graph, 数据集, KG-RAG, 检索, 生成, 文档

<br /><br />总结:
文章介绍了Docugami Knowledge Graph Retrieval Augmented Generation (KG-RAG) 数据集，并提供了相关的GitHub链接。该数据集是用于知识图检索和生成的一种评估数据集。数据集涵盖了不同知识图领域的信息，旨在帮助研究人员进行相关实验和模型评估。通过使用KG-RAG数据集，可以更好地理解知识图检索和生成的相关问题，并提供了一种衡量模型性能的标准。KG-RAG数据集是一个有用的资源，可以促进知识图领域的研究和发展。 <div>
【RAG评估数据集】’Docugami Knowledge Graph Retrieval Augmented Generation (KG-RAG) Datasets - Knowledge Graph Retrieval Augmented Generation (KG-RAG) Eval Datasets' GitHub: github.com/docugami/KG-RAG-datasets <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodw13rmouj20zi0u0tft.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 11:53:14 GMT</pubDate>
</item>
<item>
<title>【JailbreakBench：开源的鲁棒性基准，用于评估对大型语言模型(LLM)进行大规模越狱的进展。该基准提供的 JBB-Behaviors 数据集，包含 100 种不同的滥用行为，这...</title>
<link>https://weibo.com/1402400261/O82mC0lCR</link>
<guid>https://weibo.com/1402400261/O82mC0lCR</guid>
<content:encoded><![CDATA[
<div> OpenAI, 鲁棒性基准, 大型语言模型, 滥用行为, JBB-Behaviors 数据集, 基准领域表, 攻击和防御算法

<br /><br />总结:
JailbreakBench是一个开源的鲁棒性基准，专注于评估对大型语言模型进行大规模越狱的进展。其提供了包含100种不同滥用行为的JBB-Behaviors数据集，这些行为经过精挑细选，符合OpenAI的使用策略。此外，该基准还提供了领域表，用于追踪算法在攻击和防御数据集滥用行为方面的性能表现。通过JailbreakBench，研究人员和开发者可以更好地评估和改进语言模型的鲁棒性，促进模型在安全性方面的进步。 <div>
【JailbreakBench：开源的鲁棒性基准，用于评估对大型语言模型(LLM)进行大规模越狱的进展。该基准提供的 JBB-Behaviors 数据集，包含 100 种不同的滥用行为，这些行为是根据 OpenAI 的使用策略性精选的。此外，该基准还提供了官方的JailbreakBench领域表，用于跟踪对数据集中滥用行为进行攻击和防御的算法的性能】'JailbreakBench - An Open Robustness Benchmark for Jailbreaking Language Models' GitHub: github.com/JailbreakBench/jailbreakbench <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodvchzx40j210s0u0tej.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 11:29:36 GMT</pubDate>
</item>
<item>
<title>【Arena-Hard：用于评估指令微调LLM的工具，包含500个挑战性用户查询】'Arena-Hard - Arena-Hard benchmark' GitHub: github.com/lm-sys/arena-hard #开源# #机...</title>
<link>https://weibo.com/1402400261/O82le12r2</link>
<guid>https://weibo.com/1402400261/O82le12r2</guid>
<content:encoded><![CDATA[
<div> GitHub, Arena-Hard, 评估指令微调LLM工具, 500个挑战性用户查询

<br /><br />总结:
GitHub上提供了一个名为Arena-Hard的工具，用于评估指令微调LLM的性能表现。该工具包含500个具有挑战性的用户查询，能够帮助研究人员和开发者对模型进行更全面的评估和测试。通过使用这个工具，可以更好地了解模型在复杂场景下的表现，并为进一步优化和改进模型提供参考。Arena-Hard benchmark项目为研究人员提供了一个有力的工具，帮助他们更好地评估和优化LLM模型的性能。 <div>
【Arena-Hard：用于评估指令微调LLM的工具，包含500个挑战性用户查询】'Arena-Hard - Arena-Hard benchmark' GitHub: github.com/lm-sys/arena-hard <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodv8xnp01j21ji0hc0vl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 11:26:11 GMT</pubDate>
</item>
<item>
<title>【Evalverse：旨在支持LLM(大型语言模型)评估需求。提供一个简单、标准化、用户友好的方案，用于处理和管理LLM评估，满足AI研究工程师和科学家的需求】'evalvers...</title>
<link>https://weibo.com/1402400261/O82kzwXJ8</link>
<guid>https://weibo.com/1402400261/O82kzwXJ8</guid>
<content:encoded><![CDATA[
<div> LLM，评估需求，简单，标准化，用户友好，处理，管理，AI研究工程师，科学家

<br /><br />总结:
Evalverse是一个旨在支持LLM评估需求的解决方案，提供简单、标准化、用户友好的工具，用于处理和管理LLM评估，满足AI研究工程师和科学家的需求。GitHub上有相关信息。 <div>
【Evalverse：旨在支持LLM(大型语言模型)评估需求。提供一个简单、标准化、用户友好的方案，用于处理和管理LLM评估，满足AI研究工程师和科学家的需求】'evalverse - The Universe of Evaluation. All about the evaluation for LLMs.' GitHub: github.com/UpstageAI/evalverse <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodv73vdiuj20u00z60xy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hodv78c1tuj21z40u0q6g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hodv79izxjj21hc0u0tbg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 11:24:35 GMT</pubDate>
</item>
<item>
<title>【Lightning Whisper MLX：极快的Whisper实现，特别优化用于Apple Silicon的MLX，比Whisper CPP快10倍，比目前的MLX Whisper实现快4倍】’Lightning Whisper MLX...</title>
<link>https://weibo.com/1402400261/O82i71rii</link>
<guid>https://weibo.com/1402400261/O82i71rii</guid>
<content:encoded><![CDATA[
<div> Apple Silicon, Whisper, MLX, 极快, 优化, GitHub, 快10倍, 快4倍

<br /><br />总结:
Lightning Whisper MLX是一个针对Apple Silicon进行了特别优化的Whisper实现，使用MLX技术实现极快的速度。相比Whisper CPP实现，速度提升了10倍，比目前的MLX Whisper实现也快了4倍。该项目已经在GitHub上开源，地址为github.com/mustafaaljadery/lightning-whisper-mlx。这个项目为Apple Silicon用户提供了更高效的Whisper体验。 <div>
【Lightning Whisper MLX：极快的Whisper实现，特别优化用于Apple Silicon的MLX，比Whisper CPP快10倍，比目前的MLX Whisper实现快4倍】’Lightning Whisper MLX - An extremely fast implementation of whisper optimized for Apple Silicon using MLX.' GitHub: github.com/mustafaaljadery/lightning-whisper-mlx <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hodv0w73xaj210t0u0ad0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 11:18:31 GMT</pubDate>
</item>
<item>
<title>'TorchComp - Differentiable dynamic range controller in PyTorch GitHub: github.com/yoyololicon/torchcomp #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O82eZuBpL</link>
<guid>https://weibo.com/1402400261/O82eZuBpL</guid>
<content:encoded><![CDATA[
<div> PyTorch、动态范围控制器、可微分、GitHub、torchcomp、yoyololicon、代码库、实现、技术、深度学习<br />
<br />
本文介绍了一个名为TorchComp的PyTorch包，该包实现了一个可微分的动态范围控制器。用户可以在GitHub上找到该项目，作者是yoyololicon。该动态范围控制器对于深度学习中的动态范围管理非常有用，可以帮助优化模型性能。该代码库提供了实现这一技术的工具和方法，为用户提供了更多灵活性和控制权。如果你对动态范围控制器和PyTorch感兴趣，可以查看该项目并了解更多细节。<br /><br />总结: <br />PyTorch、动态范围控制器、可微分、GitHub、torchcomp、yoyololicon、代码库、实现、技术、深度学习  <div>
'TorchComp - Differentiable dynamic range controller in PyTorch GitHub: github.com/yoyololicon/torchcomp <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodusz1fc5j21ji0m8gpo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 11:10:50 GMT</pubDate>
</item>
<item>
<title>【SWE-agent：把语言模型(如GPT-4)变成软件工程Agent，可以修复实际GitHub仓库中的bug和issue】’SWE-agent: Agent Computer Interfaces Enable Software Engine...</title>
<link>https://weibo.com/1402400261/O7ZHpiqdp</link>
<guid>https://weibo.com/1402400261/O7ZHpiqdp</guid>
<content:encoded><![CDATA[
<div> 关键词: SWE-agent, 语言模型, 软件工程, GitHub, bug, issue, Agent Computer Interfaces, princeton-nlp<br />
<br />
总结: <br />
本文介绍了一种将语言模型转变为软件工程代理的方法，可以用来修复实际GitHub仓库中的bug和issue。通过创建SWE-agent，实现了Agent Computer Interfaces，使得语言模型能够与GitHub进行交互。SWE-agent的功能包括自动修复bug和处理issue，大大提高了软件工程的效率。GitHub仓库地址为github.com/princeton-nlp/SWE-agent，该项目为软件工程领域带来了新的可能性。 <div>
【SWE-agent：把语言模型(如GPT-4)变成软件工程Agent，可以修复实际GitHub仓库中的bug和issue】’SWE-agent: Agent Computer Interfaces Enable Software Engineering Language Models' GitHub: github.com/princeton-nlp/SWE-agent <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hodjkxutafj21fl0u0wj0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 04:42:36 GMT</pubDate>
</item>
<item>
<title>【产品级RAG系统构建路线图(文集)】《Building Retrieval-Augmented Generation Systems | by Leonie Monigatti | Apr, 2024 | Medium》 网页链接 #机器学习# #...</title>
<link>https://weibo.com/1402400261/O7Yf0pSBS</link>
<guid>https://weibo.com/1402400261/O7Yf0pSBS</guid>
<content:encoded><![CDATA[
<div> 构建路线图、RAG系统、产品级、检索增强生成系统、Leonie Monigatti、2024年、Medium、推荐系统、生成模型、自然语言处理
总结:<br /><br />本文着重介绍了构建检索增强生成系统（RAG系统）的产品级路线图，作者提到了RAG系统在推荐系统和生成模型中的应用，强调了其在自然语言处理领域的重要性。文章指出了产品级RAG系统的关键元素和构建步骤，为读者提供了实用的指导和建议。文章还探讨了RAG系统在未来的发展方向，展望了其在2024年的发展前景。通过阅读本文，读者可以了解RAG系统的基本概念和构建方法，为相关研究和应用提供了重要参考。 <div>
【产品级RAG系统构建路线图(文集)】《Building Retrieval-Augmented Generation Systems | by Leonie Monigatti | Apr, 2024 | Medium》 <a href="https://medium.com/@iamleonie/building-retrieval-augmented-generation-systems-be587f42aedb"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hodd4w69c4j20u010xtd0.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodd50i04tj20fk08raal.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodd52tlwmj20fk08raae.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hodd54eke4j20go0gojsb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hodd567v5oj20u00u00wc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hodd58d5q4j20as0asdg8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 00:59:53 GMT</pubDate>
</item>
<item>
<title>【AutoRound:面向各硬件平台的LM权重量化SOTA算法】- Intel近期发布了AutoRound v0.1，这是一种针对低比特LM推理的创新型仅量化权重的算法，可以近乎无损地压缩...</title>
<link>https://weibo.com/1402400261/O7YcVkkww</link>
<guid>https://weibo.com/1402400261/O7YcVkkww</guid>
<content:encoded><![CDATA[
<div> Intel、AutoRound、量化算法、LM、权重量化、硬件平台、SOTA、精度、模型部署、符号梯度下降

总结:<br /><br />Intel最近发布了面向各硬件平台的AutoRound v0.1算法，该算法针对LM进行仅量化权重的创新性处理，可以近乎无损地压缩各种流行模型。AutoRound只需调优200步，便可在各种情况下超过其他算法，兼容多种量化设备并支持无缝部署。该算法利用符号梯度下降微调权重的量化和最小最大值，取得了优于其他算法的综合精度，且已在多个模型上发布了精调过的量化模型，精度优于原始浮点模型。 <div>
【AutoRound:面向各硬件平台的LM权重量化SOTA算法】<br />- Intel近期发布了AutoRound v0.1，这是一种针对低比特LM推理的创新型仅量化权重的算法，可以近乎无损地压缩各种流行模型，如gemma-7B、Mistral-7b等。   <br />- AutoRound只需要调优200步，就可以在W4G128、W4G-1、W3G128和W2G128情况下，在大多数场景下持续超过其他算法如GPTQ、AWQ、OmniQuant等。   <br />- AutoRound兼容Intel Guadi2、Intel CPU和Nvidia GPU等量化设备，支持将量化模型无缝部署到Intel CPU和Nvidia GPU平台。   <br />- AutoRound采用符号梯度下降微调权重的量化和最小最大值，只需200步。它利用解空间边界明确的优势。   <br />- 在公平设置下，AutoRound取得了优于GPTQ、AWQ、HQQ、OmniQuant等算法的综合精度。随着调优步数的增加，性能可以进一步提升。   <br />- AutoRound已经发布了若干精调过的量化模型，在多个模型上的精度优于原始浮点模型。<br />《AutoRound: SOTA Weight-Only Quantization Algorithm for LLMs Across Hardware Platforms | by Intel(R) Neural Compressor | Apr, 2024 | Medium》 <a href="https://medium.com/@NeuralCompressor/autoround-sota-weight-only-quantization-algorithm-for-llms-across-hardware-platforms-99fe6eac2861"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hodczs1e69j20u00w9tds.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 00:54:45 GMT</pubDate>
</item>
<item>
<title>【Genie游戏生成器：无监督学习开启游戏AI新纪元】- Google DeepMind开发了一个名为Genie的新模型，可以根据简短描述、手绘草图或照片，生成类似超级马里奥兄弟...</title>
<link>https://weibo.com/1402400261/O7Y6wuD4l</link>
<guid>https://weibo.com/1402400261/O7Y6wuD4l</guid>
<content:encoded><![CDATA[
<div> Genie、无监督学习、游戏AI、Genie训练、视频数据、生成式AI、降低门槛、交互式生成、视觉技巧、商业应用前景

总结:<br /><br />Genie是Google DeepMind开发的游戏生成器，通过无监督学习可以生成类似超级马里奥兄弟的2D平台游戏。它通过观看3万小时的2D平台游戏视频进行训练，可以根据简短描述、手绘草图或照片生成游戏。Genie展示了生成式AI在游戏领域的潜力，为游戏开发提供更多创意支持，并且无监督学习方法可以提高模型的泛化能力。其实时生成游戏画面的能力为玩家提供更加个性化和沉浸式的游戏体验。Genie学会了视差等游戏中的视觉技巧，表明其对美学设计原则有一定理解。虽然目前为内部研究项目，但DeepMind已展望其商业应用前景，即转化为游戏制作工具，显示对其技术的乐观态度。随着Genie功能的完善和推理速度的提高，有望成为一个颠覆性的游戏生成平台，为游戏行业带来新的创新动力。 <div>
【Genie游戏生成器：无监督学习开启游戏AI新纪元】<br />- Google DeepMind开发了一个名为Genie的新模型，可以根据简短描述、手绘草图或照片，生成类似超级马里奥兄弟这样的2D平台游戏。   <br />- Genie通过观看网上3万小时的数百款2D平台游戏视频进行训练，学会了判断游戏人物在视频中的8种可能动作，从而生成每一帧图像。   <br />- Genie可以将简单游戏从手绘草图生成出来。它学会了平台游戏中的一些常见视觉效果，如前景移动速度快于背景的视差效果。   <br />- Genie可能被开发成游戏制作工具。它也可以通过观看机械臂操作日用品的视频，学习控制机械臂。   <br />- Genie使用的技术与大型语言模型类似，运行速度有望达到每秒30帧。它可以生成虚拟环境，用于训练机器人解决各种任务。   <br />- Genie是DeepMind的内部研究项目，暂时不会发布。但它可能成为未来创造力表达的新工具。<br /><br />思考：  <br />- Genie展示了生成式AI在游戏领域的巨大潜力。从零开始自动生成游戏，将极大地降低游戏开发的门槛，为游戏设计师提供更多创意支持。  <br />- 仅使用视频数据进行训练，无需手动标注，这种无监督学习方法可以充分利用海量的游戏视频资源，提高模型的泛化能力。这种方法也可能启发其他领域的AI研究。  <br />- 实时生成游戏画面的能力令人印象深刻。这种交互式生成方式为玩家提供了更加个性化和沉浸式的游戏体验，同时也对模型的推理速度提出了更高要求。  <br />- Genie学会了视差等游戏中的视觉技巧，表明它不仅掌握了游戏的基本规则，还理解了一些美学设计原则。这展现了深度学习在理解和生成视觉内容方面的强大能力。  <br />- 虽然Genie还是一个研究项目，但谷歌DeepMind已经展望了其商业应用前景，即转化为游戏制作工具。这表明他们对这一技术的成熟度和实用性持乐观态度。  <br />- 随着推理速度的提高和功能的完善，Genie有望成为一个颠覆性的游戏生成平台，为游戏行业注入新的创新动力。同时，它也可能对游戏开发者的职业前景产生一定影响。<br />《Google DeepMind’s new generative model makes Super Mario-like games from scratch | MIT Technology Review》 <a href="https://www.technologyreview.com/2024/02/29/1089317/google-deepminds-new-generative-model-makes-super-mario-like-games-from-scratch"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hodcjj9lydj20vz0u0gth.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 00:38:59 GMT</pubDate>
</item>
<item>
<title>【OpenAI的Harvey客户案例分享】- Harvey是一家为法律、税务和金融专业人员提供生成式AI平台的初创公司。最近，它与OpenAI合作创建了一个定制化的案例法模型。 -...</title>
<link>https://weibo.com/1402400261/O7Y3zuvrk</link>
<guid>https://weibo.com/1402400261/O7Y3zuvrk</guid>
<content:encoded><![CDATA[
<div> 合作、定制化、案例法模型、LLM、推理、领域知识、重要差异、高效率、跨领域、用户体验

<br /><br />总结:
OpenAI与Harvey合作创建了定制化的案例法模型，为法律、税务和金融专业人员提供生成式AI平台。这个模型注入新的知识和推理方式，融合了大量数据，提供案例法上下文深度。律师更喜欢定制化模型的输出，因为它提供更完整、深入的答案。创始人建议构建与未来LLM能力相关的解决方案，充分利用模型进步带来的价值。该合作展示了定制化LLM在垂直领域应用的潜力，为传统行业带来变革。创始人背景的跨领域视角和经验对LLM应用至关重要。AI技术有望提高行业效率和生产力，对从业者的技能要求和就业前景可能产生影响。面临的挑战是确保输出的相关性和准确性，提供可靠的来源引用。Harvey致力于简化用户体验，降低使用门槛，以推动AI技术的大规模采用。 <div>
【OpenAI的Harvey客户案例分享】<br />- Harvey是一家为法律、税务和金融专业人员提供生成式AI平台的初创公司。最近，它与OpenAI合作创建了一个定制化的案例法模型。   <br />- 这个模型允许Harvey为复杂的推理、广泛的领域知识以及超出单次模型调用能力的任务提供AI系统，如文档起草、复杂诉讼场景的问答以及数百份合同之间的重大差异识别。   <br />- Harvey的创始人认为，LLM可以聚合信息并呈现给律师进行审查，从而提高工作效率。基础模型在推理方面很强，但缺乏法律工作所需的知识。   <br />- Harvey与OpenAI合作，向基础模型中注入新的知识和推理方式，创建一个定制化的案例法模型。该模型融合了相当于100亿Token的数据，以提供案例法所需的上下文深度。   <br />- 测试结果显示，97%的时间律师更喜欢定制化案例法模型的输出结果，因为它提供了更完整、深入的答案并涵盖了更相关的案例法。   <br />- Harvey计划利用该模型探索其他应用，如起草简要和动议，或帮助律师理解不同管辖区域之间的案例法差异。   <br />- Harvey的合伙创始人建议其他创始人要面向未来的LLM能力进行构建，解决更复杂的问题，以充分利用模型进步带来的价值。<br /><br />思考：    <br />- Harvey与OpenAI的合作展示了定制化LLM在垂直领域应用中的巨大潜力。通过注入特定领域知识，LLM可以胜任需要复杂推理和专业知识的任务，这将极大地拓展LLM的应用范围。    <br />- Harvey的成功表明，LLM正在为传统的知识密集型行业带来变革，如法律、税务和金融。AI技术有望提高这些行业的效率和生产力，同时也可能对从业者的技能要求和就业前景产生影响。    <br /> 创始人的背景结合了法律专业和AI技术，这种跨领域的视角和经验对于将LLM成功应用于法律行业至关重要。这启示我们，未来的创新可能越来越多地来自不同领域的交叉融合。    <br />- Harvey面临的一个挑战是如何确保AI系统输出的相关性和准确性，并提供可靠的来源引用。这对于法律等要求严谨的领域尤为重要。Harvey在这方面取得的进展值得关注。    <br />- 通过将多个模型调用组合成单一输出，Harvey旨在简化用户体验，降低使用门槛。这种以用户为中心的思路对于推动AI技术的大规模采用非常必要。<br />《OpenAI customer story: Harvey》 <a href="https://openai.com/customer-stories/harvey"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hodcbz1ohfj21gm0u0q76.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 00:31:43 GMT</pubDate>
</item>
<item>
<title>【多样本越狱：LLM安全防线的突破口】- Anthropic研究团队发现了一种称为“多样本越狱”的新型对抗性攻击，可以突破大型语言模型的安全保护机制。 - 该攻击利用...</title>
<link>https://weibo.com/1402400261/O7XXf5SgD</link>
<guid>https://weibo.com/1402400261/O7XXf5SgD</guid>
<content:encoded><![CDATA[
<div> 多样本越狱、LLM安全防线、对抗性攻击、大型语言模型、in-context学习、Anthropic研究团队、安全漏洞、多样本越狱攻击、缓解措施、AI安全挑战

<br /><br />总结:
Anthropic研究团队发现了一种名为多样本越狱的新型对抗性攻击，能够突破大型语言模型的安全防护，利用模型处理长上下文能力，在prompt中插入特定格式的文本引导模型产生潜在有害响应。随着示例对话数量增加，攻击成功率也增加，显示多样本越狱的可行性。攻击与模型的in-context学习能力有关，大型语言模型更容易受到攻击，因为其学习能力更强。Anthropic已采取限制上下文长度等缓解措施，但完全解决多样本越狱仍具挑战性。发现漏洞并与业界分享显现了负责任的态度和开放协作精神，有助于整个AI社区共同应对安全挑战。增强安全防护是迫切需要的，尤其随着模型能力的增强，引入新安全风险。文章提醒我们平衡上下文窗口扩大带来的性能提升和安全隐患之间的问题，在评估LLM安全性时需考虑不同攻击手段的组合效果。多样本越狱攻击的有效性及与其他攻击技术相结合的威力，强调AI安全问题的复杂性，需要产学研各界持续投入和协同努力。 <div>
【多样本越狱：LLM安全防线的突破口】<br />- Anthropic研究团队发现了一种称为“多样本越狱”的新型对抗性攻击，可以突破大型语言模型的安全保护机制。   <br />- 该攻击利用了大型语言模型能处理更长上下文的能力，通过在prompt中加入大量特定格式的文本，迫使模型产生潜在有害的响应。   <br />- 随着prompt中示例对话数量的增加，模型产生有害响应的比例也在增加，这表明多样本越狱是可行的。   <br />- 多样本越狱似乎与模型的in-context学习能力有关，随着示例数增多，模型的in-context学习效果呈幂律提升，越狱成功率也是如此。   <br />- 相比小模型，大型语言模型更容易被多样本越狱攻击，因为它们的in-context学习能力更强。   <br />- Anthropic已经采取了一些缓解措施，如限制上下文窗口长度、对prompt进行分类处理等，取得了一定效果。   <br />- 发布这项研究有助于提高对这种新型攻击的重视，促使AI研究者尽快找到有效的防御手段。   <br />- 随着模型变得更强大，缓解这类攻击变得更加重要。Anthropic将继续研究如何在不损害模型有用性的前提下防御多样本越狱。<br /><br />思考：  <br />- 多样本越狱技术揭示了当前LLM安全防护的一个重要漏洞，表明随着模型能力的增强，安全风险也在不断升高，需要引起高度重视。  <br />- Anthropic主动披露漏洞并与业界分享，体现了负责任的态度和开放协作的精神，值得赞赏。这种做法有利于推动整个AI社区共同应对安全挑战。  <br />- 上下文窗口的扩大是LLM发展的重要趋势，带来了性能提升的同时，也引入了新的安全隐患。如何在两者间取得平衡，是一个值得深入探讨的问题。  <br />- 文章通过实验数据展示了多样本越狱的有效性，并指出与其他越狱技术结合会进一步增强威力，这提醒我们在评估LLM安全性时需要考虑各种攻击手段的组合效果。  <br />- 虽然Anthropic已经采取了一些缓解措施，但完全解决多样本越狱并非易事。这凸显了AI安全问题的复杂性，需要产学研各界持续投入和协同努力。<br />《Many-shot jailbreaking \ Anthropic》 <a href="https://www.anthropic.com/research/many-shot-jailbreaking"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hodbdvefxgj20uj0u0440.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 00:16:07 GMT</pubDate>
</item>
<item>
<title>今日推介(第1364期)：用语言模型识别有说服力的论点、让LLM在不泄露隐私信息的情况下获得其他LLM的帮助、基于可控大语言模型的安全性与可用性平衡、旋转LLM实现...</title>
<link>https://weibo.com/1402400261/O7XbFuHyV</link>
<guid>https://weibo.com/1402400261/O7XbFuHyV</guid>
<content:encoded><![CDATA[
<div> 语言模型、认证、隐私、安全性、可用性、推理、噪声感知、训练、布局、公众号

<br /><br />总结:
本文介绍了几个关于语言模型的研究领域，包括用语言模型识别有说服力的论点、如何让LLM在不泄露隐私信息的情况下获得其他LLM的帮助，以及基于可控大语言模型的安全性与可用性平衡。另外还提到了旋转LLM实现无离群值4-bit推理和布局感知语言模型的噪声感知训练等内容。这些研究都对提升语言模型的应用和效用有着积极的意义，并在不同领域具有广泛的应用前景。 <div>
今日推介(第1364期)：用语言模型识别有说服力的论点、让LLM在不泄露隐私信息的情况下获得其他LLM的帮助、基于可控大语言模型的安全性与可用性平衡、旋转LLM实现无离群值4-bit推理、布局感知语言模型的噪声感知训练 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/690477458"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hod8hhfsrxj21fe0tk44f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hod8hl2c26j21330u0dm1.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hod8hnbse3j20vi0k40v0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hod8hq97xbj21f20r40yp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hod8hskrkdj219l0u0tff.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 22:18:55 GMT</pubDate>
</item>
<item>
<title>[CV] Measuring Style Similarity in Diffusion Models 网页链接 提出一种从图像中提取风格描述符的对比学习框架，在零样本任务上优于其他方法，并通过案例研究...</title>
<link>https://weibo.com/1402400261/O7X8lxcyo</link>
<guid>https://weibo.com/1402400261/O7X8lxcyo</guid>
<content:encoded><![CDATA[
<div> 对比学习框架、风格描述符、零样本任务、理解生成模型、归因、应用价值、案例研究 <br />
本文提出了一种对比学习框架，用于从图像中提取风格描述符，并在零样本任务上表现优于其他方法。通过案例研究展示了该框架在理解和归因生成模型中的风格方面的应用价值。 <div>
[CV] Measuring Style Similarity in Diffusion Models  <br /><a href="https://arxiv.org/abs/2404.01292"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />提出一种从图像中提取风格描述符的对比学习框架，在零样本任务上优于其他方法，并通过案例研究展示了其在理解和归因生成模型中的风格方面的应用价值。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod899cavjj20uy1bq7kh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod899jtsij211o16eaj7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod89a39umj21b20kqtf1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 22:10:44 GMT</pubDate>
</item>
<item>
<title>[IR] A Review of Modern Recommender Systems Using Generative Models (Gen-RecSys) 网页链接 系统全面综述了生成模型在推荐系统中的应用，包括基于交互、语言...</title>
<link>https://weibo.com/1402400261/O7X5RaNCV</link>
<guid>https://weibo.com/1402400261/O7X5RaNCV</guid>
<content:encoded><![CDATA[
<div> 生成模型、推荐系统、交互、语言、多模态技术、评估维度、未来方向、研究领域、参考、综述<br />
<br />
总结：<br />
本文综述了生成模型在推荐系统中的应用，包括基于交互、语言和多模态的技术。文章还讨论了评估维度和未来方向，为这一新兴且前景广阔的研究领域提供了宝贵参考。生成模型在推荐系统中的各种应用和技术展示了其在提高推荐效果和用户体验方面的潜力。评估维度的讨论帮助研究者更好地了解如何评估生成模型推荐系统的性能。未来方向的探讨为学者提供了发展方向和研究重点，有助于推动这一领域的进一步发展。希望这篇综述能给推荐系统研究者提供启发，并促进更多创新方法和技术的应用。 <div>
[IR] A Review of Modern Recommender Systems Using Generative Models (Gen-RecSys)  <br /><a href="https://arxiv.org/abs/2404.00579"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />系统全面综述了生成模型在推荐系统中的应用，包括基于交互、语言和多模态的技术，以及评估维度和未来方向，为这一新兴且前景广阔的研究领域提供了宝贵参考。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod82w82hxj213i1c64jy.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod82wgm8gj21w016i16v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 22:04:35 GMT</pubDate>
</item>
<item>
<title>[CL] Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order 网页链接 通过持续预训练和安全性调整...</title>
<link>https://weibo.com/1402400261/O7X3khu4g</link>
<guid>https://weibo.com/1402400261/O7X3khu4g</guid>
<content:encoded><![CDATA[
<div> 多语言、安全性调整、150亿参数、开源、AURORA-M、预训练、语言模型、Red-teamed、美国行政命令

总结:<br />
通过持续预训练和安全性调整，提出了一个多语言、安全可靠的150亿参数开源语言模型AURORA-M。根据美国行政命令进行了Red-teamed测试，证明其在各方面的优势和可靠性。 AURORA-M可应用于诸多领域，为自然语言处理提供了一个重要的工具。 <div>
[CL]  Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order  <br /><a href="https://arxiv.org/abs/2404.00399"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />通过持续预训练和安全性调整，提出了一个多语言、安全可靠的150亿参数开源语言模型AURORA-M。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod7we8wbaj20uw1cy4dd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod7weoe03j21mw10wqd8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod7wf5m0dj21ms116dok.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:58:22 GMT</pubDate>
</item>
<item>
<title>[CL] Mapping the Increasing Use of LLMs in Scientific Papers 网页链接进行第一个大规模分析追踪学术界LLM使用趋势，发现计算机科学增长最快，与作者更频繁发...</title>
<link>https://weibo.com/1402400261/O7WZOuJ28</link>
<guid>https://weibo.com/1402400261/O7WZOuJ28</guid>
<content:encoded><![CDATA[
<div> 计算机科学, LLM, 学术界, 使用趋势, 预印本, 研究领域, 论文<br />
<br />
<br />
总结: 这篇文章通过大规模分析发现，学术界中越来越多地使用LLM，其中计算机科学领域的增长最为迅速。这与作者更频繁发表预印本、研究领域更拥挤以及论文更短等因素有关。LLM的使用趋势在学术界中呈现明显上升趋势，尤其在计算机科学领域。 <div>
[CL] Mapping the Increasing Use of LLMs in Scientific Papers  <br /><a href="https://arxiv.org/abs/2404.01268"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br />进行第一个大规模分析追踪学术界LLM使用趋势，发现计算机科学增长最快，与作者更频繁发表预印本、研究领域更拥挤以及论文更短相关。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod7nee3drj20v81dkaps.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod7ned969j21d010sqi6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod7neppzjj21cc1cwamw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:49:43 GMT</pubDate>
</item>
<item>
<title>[CL]《Noise-Aware Training of Layout-Aware Language Models》R Sarkhel, X Ren, L B Costa, G Su, V Perot, Y Xie, E Koukoumidis, A Nandi [Google &amp; The Oh...</title>
<link>https://weibo.com/1402400261/O7WVazuaD</link>
<guid>https://weibo.com/1402400261/O7WVazuaD</guid>
<content:encoded><![CDATA[
<div> 布局感知语言模型，噪声感知训练，谷歌，俄亥俄州立大学，2024，R Sarkhel，X Ren，L B Costa，G Su，V Perot，Y Xie，E Koukoumidis，A Nandi

<br /><br />总结:
这篇论文探讨了一种新的训练方法，即噪声感知训练，用于提高布局感知语言模型的性能。研究人员提出了一种新颖的噪声注入技术，通过向输入数据中添加噪声来帮助模型更好地理解布局信息。他们在谷歌和俄亥俄州立大学进行了实验，结果表明，这种训练方法可以显著改善布局感知语言模型的性能。这项研究为提高语言模型的布局感知能力提供了新思路，对于提高文本生成、理解和处理的效果具有重要意义。 <div>
[CL]《Noise-Aware Training of Layout-Aware Language Models》R Sarkhel, X Ren, L B Costa, G Su, V Perot, Y Xie, E Koukoumidis, A Nandi [Google &amp; The Ohio State University] (2024) <a href="https://arxiv.org/abs/2404.00488"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod6x1onmnj20le1ag7fb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6x20lkvj20p00nuzoa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod6x2ka9ej21by0vkwmu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6x2tql8j20oi0imgo4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod7bhv7lmj20hi0f1t9d.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod7bhv93mj20hm0e6mxs.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:38:16 GMT</pubDate>
</item>
<item>
<title>QuaRot通过旋转消除激活中的离群点实现了包括权重、激活和KV缓存在内的端到端4-bit LLM量化，保持了几乎全部的模型性能。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Qu...</title>
<link>https://weibo.com/1402400261/O7WOzeI6F</link>
<guid>https://weibo.com/1402400261/O7WOzeI6F</guid>
<content:encoded><![CDATA[
<div> 权重、激活、KV缓存、4-bit量化、端到端、QuaRot、旋转、消除离群点、模型性能、LLMs

<br /><br />总结:
QuaRot是一种新的技术，通过旋转去除激活中的离群点，实现了包括权重、激活和KV缓存在内的端到端4-bit LLM量化。该方法保持了几乎全部的模型性能。研究团队来自ETH Zurich，EPFL和Microsoft Research，他们通过实验验证了这种新方法的有效性。QuaRot主要应用于旋转LLMs，已经证明在4-bit推断中具有很高的效果。通过消除离群点，能够显著提高模型的稳定性和精度。这项研究为低精度推断提供了新的思路，对于在资源受限的设备上部署深度学习模型具有重要意义。QuaRot技术的提出将进一步推动深度学习领域的发展，为模型的应用和优化提供了新的思路。 <div>
QuaRot通过旋转消除激活中的离群点实现了包括权重、激活和KV缓存在内的端到端4-bit LLM量化，保持了几乎全部的模型性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs》S Ashkboos, A Mohtashami, M L. Croci, B Li, M Jaggi, D Alistarh, T Hoefler, J Hensman [ETH Zurich &amp; EPFL &amp; Microsoft Research] (2024) <a href="https://arxiv.org/abs/2404.00456"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod6m7tom8j21620kgdnm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6m8gocdj21f20r4n4y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6m8uxfmj21dy0o60yp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod6m955foj21e40piwjp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod6p5mftwj20ve0hpwha.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6p5mmckj20xq0h5jtm.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod6p5mr7xj20vd0glq4m.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:22:00 GMT</pubDate>
</item>
<item>
<title>[LG]《QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs》S Ashkboos, A Mohtashami, M L. Croci, B Li, M Jaggi, D Alistarh, T Hoefler, J Hensman [ETH...</title>
<link>https://weibo.com/1402400261/O7WMs7i3U</link>
<guid>https://weibo.com/1402400261/O7WMs7i3U</guid>
<content:encoded><![CDATA[
<div> 关键词: QuaRot, Outlier-Free, 4-Bit Inference, Rotated LLMs, ETH Zurich, EPFL, Microsoft Research

总结:<br /><br />这篇文章介绍了一种名为QuaRot的方法，用于在旋转的LLMs中进行无异常值的4位推断。研究团队来自ETH Zurich、EPFL和Microsoft Research，团队成员包括S Ashkboos、A Mohtashami、M L. Croci、B Li、M Jaggi、D Alistarh、T Hoefler和J Hensman。他们提出的方法有效地处理了LLMs中出现的异常情况，可用于进行精确的4位推断。该方法的实现无异常值且高效，为解决此类问题提供了有力的工具。 <div>
[LG]《QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs》S Ashkboos, A Mohtashami, M L. Croci, B Li, M Jaggi, D Alistarh, T Hoefler, J Hensman [ETH Zurich &amp; EPFL &amp; Microsoft Research] (2024) <a href="https://arxiv.org/abs/2404.00456"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod6m7tom8j21620kgdnm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6m8gocdj21f20r4n4y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6m8uxfmj21dy0o60yp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod6m955foj21e40piwjp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod6p5mftwj20ve0hpwha.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6p5mmckj20xq0h5jtm.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod6p5mr7xj20vd0glq4m.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:16:47 GMT</pubDate>
</item>
<item>
<title>通过自生成训练数据并采用不同的微调策略，实现了不需要额外人工标注就能控制大语言模型响应中的安全性和有用性。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Towards S...</title>
<link>https://weibo.com/1402400261/O7WGy0sEy</link>
<guid>https://weibo.com/1402400261/O7WGy0sEy</guid>
<content:encoded><![CDATA[
<div> 关键词: 自生成训练数据, 大语言模型, 安全性, 有用性, 微调策略, 控制, 响应, 人工标注, 平衡, Meta AI 

总结:<br />
研究通过自生成训练数据和不同的微调策略，实现了大语言模型响应中安全性和有用性的平衡。文章指出通过控制大语言模型的响应，无需额外人工标注便可实现对响应内容的安全性和有用性进行调控。研究的关键在于平衡安全性和有用性，需要对训练数据和微调策略进行精细调节，以满足用户的需求。通过Meta AI技术和来自加州大学圣芭芭拉分校的合作，研究取得了显著进展，有望在大语言模型的应用中发挥重要作用。 <div>
通过自生成训练数据并采用不同的微调策略，实现了不需要额外人工标注就能控制大语言模型响应中的安全性和有用性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Towards Safety and Helpfulness Balanced Responses via Controllable Large Language Models》Y Tuan, X Chen, E M Smith, L Martin… [Meta AI &amp; University of California, Santa Barbara] (2024) <a href="https://arxiv.org/abs/2404.01295"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod68zv1orj20qq0xathh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod690byo2j20vi0k4q5y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod690qgbij21p80ka44c.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod690yryqj21pi0jgdks.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod69mje5gj20hs0jwjsj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod69mjrkuj20zs0f7gnq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod69mjddzj20hs0bqt9t.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod69mjeakj20hr07m0t6.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:02:14 GMT</pubDate>
</item>
<item>
<title>[CL]《Towards Safety and Helpfulness Balanced Responses via Controllable Large Language Models》Y Tuan, X Chen, E M Smith, L Martin… [Meta AI &amp; Unive...</title>
<link>https://weibo.com/1402400261/O7WGolSsF</link>
<guid>https://weibo.com/1402400261/O7WGolSsF</guid>
<content:encoded><![CDATA[
<div> 控制大型语言模型，平衡安全和实用性，安全，实用性，平衡，响应，大型语言模型，Meta AI，加州大学圣巴巴拉，2024<br />
<br />
总结:<br />
本文研究了通过控制大型语言模型实现安全和实用性平衡的方法。通过引入新的技术和算法，可以更好地处理大型语言模型在生成响应时可能出现的安全隐患。研究团队从安全性和实用性的角度出发，提出了一种新的平衡方法，可以确保生成的响应既安全又有帮助。他们结合了Meta AI的技术和加州大学圣巴巴拉的研究资源，取得了一定的进展。通过这项研究，可以为大型语言模型的发展提供更加全面和可靠的指导，确保其在未来的应用中能够更好地服务社会。 <div>
[CL]《Towards Safety and Helpfulness Balanced Responses via Controllable Large Language Models》Y Tuan, X Chen, E M Smith, L Martin… [Meta AI &amp; University of California, Santa Barbara] (2024) <a href="https://arxiv.org/abs/2404.01295"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod68zv1orj20qq0xathh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod690byo2j20vi0k4q5y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod690qgbij21p80ka44c.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod690yryqj21pi0jgdks.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod69mje5gj20hs0jwjsj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod69mjrkuj20zs0f7gnq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod69mjddzj20hs0bqt9t.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod69mjeakj20hr07m0t6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:01:52 GMT</pubDate>
</item>
<item>
<title>设计保护隐私的级联系统和查询生成算法，使本地模型可利用远程模型提高性能而不泄露敏感信息。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Can LLMs get help from othe...</title>
<link>https://weibo.com/1402400261/O7WFX0WBK</link>
<guid>https://weibo.com/1402400261/O7WFX0WBK</guid>
<content:encoded><![CDATA[
<div> 隐私保护、本地模型、远程模型、私人信息、级联系统、查询生成算法、LLMs、信息共享、性能提升、敏感信息泄露

总结:<br /><br />
本文讨论了如何设计一种保护隐私的级联系统和查询生成算法，使本地模型能够利用远程模型提高性能而不泄露敏感信息。研究团队提出了一种解决方案，即通过利用LLMs之间的信息共享来提高模型性能，同时保护私人信息不被泄露。他们提出的方法使得模型能够相互协作，共享有用的信息，同时保持敏感信息的隐私性。该方法的设计是基于查询生成算法，能够有效地限制信息的传输和共享范围，从而保护用户的隐私。通过这种方式，本地模型可以从其他远程模型中获得帮助，提高性能，而不会揭露私人信息。这种方法的应用在保护隐私的同时，也有助于提高模型的性能和效率。 <div>
设计保护隐私的级联系统和查询生成算法，使本地模型可利用远程模型提高性能而不泄露敏感信息。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Can LLMs get help from other LLMs without revealing private information?》F Hartmann, D Tran, P Kairouz… [Google Research] (2024) <a href="https://arxiv.org/abs/2404.01041"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod67a2w6qj21cy0wu185.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod67abxk2j21lu0lsada.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod67b21xcj21ls18cdub.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod67blmnvj21mg0ueah1.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:00:46 GMT</pubDate>
</item>
<item>
<title>[LG]《Can LLMs get help from other LLMs without revealing private information?》F Hartmann, D Tran, P Kairouz… [Google Research] (2024) 网页链接 #机...</title>
<link>https://weibo.com/1402400261/O7WFT9hUp</link>
<guid>https://weibo.com/1402400261/O7WFT9hUp</guid>
<content:encoded><![CDATA[
<div> 隐私保护、LLMs、协作、信息共享、安全协议、数据隐私、加密技术、隐私保护算法

总结:<br /><br />本研究讨论了LLMs（Low-Latency Messaging systems）之间如何在不泄露私人信息的情况下进行合作和信息共享。研究团队提出了一种安全协议，利用加密技术和隐私保护算法，实现了LLMs之间的安全信息交流。他们的方案在保护数据隐私的同时，确保了信息的可靠传输和合作的顺畅进行。这项研究对提高LLMs系统的安全性和隐私保护性具有重要意义。 <div>
[LG]《Can LLMs get help from other LLMs without revealing private information?》F Hartmann, D Tran, P Kairouz… [Google Research] (2024) <a href="https://arxiv.org/abs/2404.01041"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod67a2w6qj21cy0wu185.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod67abxk2j21lu0lsada.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod67b21xcj21ls18cdub.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod67blmnvj21mg0ueah1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:00:36 GMT</pubDate>
</item>
<item>
<title>通过检测有说服力论据的能力来研究LLM生成个性化信息的潜力，无需直接人工实验，为持续监测LLM能力发展提供了有效途径。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Can...</title>
<link>https://weibo.com/1402400261/O7WD0skj7</link>
<guid>https://weibo.com/1402400261/O7WD0skj7</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM, 说服力论据识别, 个性化信息生成, 监测能力发展

总结:<br /><br />
该研究探讨了语言模型(LLM)在识别说服力论据和生成个性化信息方面的潜力，无需进行直接人工实验，提供了一种有效的监测LLM能力发展的方法。研究发现，LLM在识别有说服力的论据方面表现出良好的能力，显示了其潜力。该研究由瑞士洛桑联邦理工学院和剑桥大学的研究人员合作完成，为未来研究LLM能力的发展方向提供了重要参考。 <div>
通过检测有说服力论据的能力来研究LLM生成个性化信息的潜力，无需直接人工实验，为持续监测LLM能力发展提供了有效途径。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Can Language Models Recognize Convincing Arguments?》P Rescala, M H Ribeiro, T Hu, R West [EPFL &amp; University of Cambridge] (2024) <a href="https://arxiv.org/abs/2404.00750"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod62w15wjj216s0qu7gm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod62wr5pij21fe0tkdnf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod62xb1y7j20pk0q6jve.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod62y3ofkj20ni0simzh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod60r2rsej20n00k5gnq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod60r2u0qj20n00oeacb.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 20:53:31 GMT</pubDate>
</item>
<item>
<title>[CL]《Can Language Models Recognize Convincing Arguments?》P Rescala, M H Ribeiro, T Hu, R West [EPFL &amp; University of Cambridge] (2024) 网页链接 #机器...</title>
<link>https://weibo.com/1402400261/O7WCWhYof</link>
<guid>https://weibo.com/1402400261/O7WCWhYof</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型，说服性论点，识别，论证，人工智能，自然语言处理，研究，EPFL，剑桥大学

总结:
研究人员来自EPFL和剑桥大学，他们进行了关于语言模型是否能识别具有说服力的论点的研究。他们探讨了人工智能和自然语言处理领域的重要问题，即机器是否能够识别人类的论证方式。研究结果表明，语言模型在识别说服力论点方面取得了一定的进展，但仍存在一些挑战和限制。他们的研究为语言模型的进一步发展提供了有价值的参考，为人工智能领域的研究和应用带来了新的启示。 <div>
[CL]《Can Language Models Recognize Convincing Arguments?》P Rescala, M H Ribeiro, T Hu, R West [EPFL &amp; University of Cambridge] (2024) <a href="https://arxiv.org/abs/2404.00750"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod62w15wjj216s0qu7gm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod62wr5pij21fe0tkdnf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod62xb1y7j20pk0q6jve.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod62y3ofkj20ni0simzh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod60r2rsej20n00k5gnq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod60r2u0qj20n00oeacb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 20:53:21 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.2)》 爱可可微博热门分享(4.2) [图片]</title>
<link>https://weibo.com/1402400261/O7UfG92ii</link>
<guid>https://weibo.com/1402400261/O7UfG92ii</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、文章、内容、关键词、社交媒体、用户、热度

<br /><br />总结:
本文是关于爱可可微博热门分享的内容。文章主要围绕着社交媒体平台微博上热门内容展开，分享了一些用户感兴趣的话题和信息。通过分析关键词和用户互动，可以更好地了解微博热度和用户喜好。爱可可微博分享的内容涵盖了各种各样的主题，吸引了广泛的用户群体关注和参与讨论。通过这些热门分享，可以更好地了解社交媒体上的热点话题和用户需求，为用户提供更好的信息和服务。 <div>
《爱可可微博热门分享(4.2)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405018845323591860"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.2)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hocvj66pjxj20rs0fmmzd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 14:50:33 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation》(CVPR 2024) GitHub: github.com/Aradhye2002/Ec...</title>
<link>https://weibo.com/1402400261/O7TPalOlz</link>
<guid>https://weibo.com/1402400261/O7TPalOlz</guid>
<content:encoded><![CDATA[
<div> ECoDepth, Diffusion Models, Monocular Depth Estimation, Conditioning, Effective, CVPR 2024, GitHub, Relation Rectification, Relation Rectification, Diffusion Model, Hourglass Tokenizer, Efficient, Transformer-Based, 3D Human Pose Estimation, XScale-NVS, Cross-Scale, Novel View Synthesis, Hash Featurized Manifold, DiJiang, Large Language Models, Compact Kernelization, Talk3D, Talking Portrait Synthesis, 3D Generative Prior, Motion Inversion, Video Customization, MineLand, Multi-Agent Interactions, Limited Multimodal Senses, Physical Needs, UPD, Unsolvable Problem Detection, Vision Language Models, Draw-and-Understand, Visual Prompts

总结：<br /><br /> 《ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation》介绍了一种有效的条件扩展扩散模型，用于单目深度估计。GitHub上有相关的代码实现。 《Relation Rectification in Diffusion Model》讨论了扩散模型中的关系校正问题，也提供了相关的GitHub代码。《Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation》介绍了一种用于3D人体姿势估计的高效Transformer模型。XScale-NVS展示了一种跨尺度新视图合成方法，并使用哈希特征化流形。DiJiang通过紧凑内核化实现了高效的大型语言模型。Talk3D提出了一种通过个性化三维生成先验实现的高保真度语音合成方法。Motion Inversion展示了视频定制中的运动反转技术。MineLand通过模拟大规模多智能体交互，限制多模态感知和生理需求。UPD关注视觉语言模型的可信度评估。Draw-and-Understand利用视觉提示帮助大型语言模型理解用户需求。 <div>
几篇论文实现代码：<br />《ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation》(CVPR 2024) GitHub: github.com/Aradhye2002/EcoDepth [fig2]<br />《Relation Rectification in Diffusion Model》(CVPR 2024) GitHub: github.com/WUyinwei-hah/RRNet<br />《Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation》(CVPR 2024) GitHub: github.com/NationalGAILab/HoT<br />《XScale-NVS: Cross-Scale Novel View Synthesis with Hash Featurized Manifold》(CVPR 2024) GitHub: github.com/THU-luvision/XScale-NVS<br />《DiJiang: Efficient Large Language Models through Compact Kernelization》(2024) GitHub: github.com/YuchuanTian/DiJiang [fig1]<br />《Talk3D: High-Fidelity Talking Portrait Synthesis via Personalized 3D Generative Prior》(2024) GitHub: github.com/KU-CVLAB/Talk3D [fig3] <br />《Motion Inversion for Video Customization》(2024) GitHub: github.com/EnVision-Research/MotionInversion<br />《MineLand: Simulating Large-Scale Multi-Agent Interactions with Limited Multimodal Senses and Physical Needs》(2024) GitHub: github.com/cocacola-lab/MineLand<br />《Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models》(2024) GitHub: github.com/AtsuMiyai/UPD [fig4]<br />《Draw-and-Understand: Leveraging Visual Prompts to Enable MLLMs to Comprehend What You Want》(2024) GitHub: github.com/AFeng-x/Draw-and-Understand [fig5]<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hocfuvwv8uj21je0kqak6.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hocfx3bw1xj21x00le1kx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hocg07nt81j259e2g1npf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hocs644i0fj20un0gztsi.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoctmropi0j22ec14q7he.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:45:14 GMT</pubDate>
</item>
<item>
<title>【VillagerBench: 多智能体合作前沿技术的基准套件，旨在挑战虚拟智能体共同完成的极限，从建筑项目到烹饪任务，再到逃脱房间的谜题】'VillagerBench: Benchmark...</title>
<link>https://weibo.com/1402400261/O7TOrFbis</link>
<guid>https://weibo.com/1402400261/O7TOrFbis</guid>
<content:encoded><![CDATA[
<div> 多智能体合作, 基准套件, 挑战, 虚拟智能体, 完成, 极限, 建筑项目, 烹饪任务, 逃脱房间, 谜题

<br /><br />总结:
"VillagerBench"是一个用于多智能体合作的基准套件，旨在挑战虚拟智能体共同完成任务的极限。该套件涵盖了各种任务，包括建筑项目、烹饪任务和逃脱房间谜题，旨在促进智能体在团队合作中的表现。GitHub链接提供了更多关于该套件的信息和资源。 <div>
【VillagerBench: 多智能体合作前沿技术的基准套件，旨在挑战虚拟智能体共同完成的极限，从建筑项目到烹饪任务，再到逃脱房间的谜题】'VillagerBench: Benchmarking Teamwork in the World of Minecraft' GitHub: github.com/cnsdqd-dyb/VillagerAgent <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoctlgywx1j22410u0qft.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:43:28 GMT</pubDate>
</item>
<item>
<title>【ChatDev IDE: 用于构建AI代理的工具，无论是在游戏中的NPC还是强大的代理工具，都可以在这个平台上设计想要的内容】'ChatDev IDE: Building Your AI Agent - C...</title>
<link>https://weibo.com/1402400261/O7TNEvwYT</link>
<guid>https://weibo.com/1402400261/O7TNEvwYT</guid>
<content:encoded><![CDATA[
<div> ChatDev IDE、AI代理、工具、游戏NPC、强大、设计、平台

<br /><br />总结:
ChatDev IDE是一个用于构建AI代理的工具，无论是在游戏中的NPC还是强大的代理工具，用户可以在这个平台上设计他们想要的内容。GitHub上有相关项目：github.com/10cl/chatdev。ChatDev IDE为用户提供了便捷的设计和构建AI代理的功能，让用户可以自定义游戏中的NPC或其他强大的代理工具，实现个性化的需求。通过这个平台，用户可以更轻松地实现他们的AI代理设计和构建工作。 <div>
【ChatDev IDE: 用于构建AI代理的工具，无论是在游戏中的NPC还是强大的代理工具，都可以在这个平台上设计想要的内容】'ChatDev IDE: Building Your AI Agent - ChatDev IDE is an tools for building your ai agent, Whether it's NPCs in games or powerful agent tools, you can design what you want for this platform.' GitHub: github.com/10cl/chatdev <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoctjattloj21hc0qjqe4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoctjdq5a6j20u60czadw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoctjf0qvtj218i0q5164.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:41:31 GMT</pubDate>
</item>
<item>
<title>'LangGraph.js - a library for building stateful, multi-actor applications with LLMs, built on top of (and intended to be used with) LangChain.js' GitH...</title>
<link>https://weibo.com/1402400261/O7TMgqIjs</link>
<guid>https://weibo.com/1402400261/O7TMgqIjs</guid>
<content:encoded><![CDATA[
<div> LangGraph.js, library, stateful, multi-actor applications, LLMs, LangChain.js, GitHub, LangGraph.js

LangGraph.js是一个用于构建具有LLM的有状态多角色应用程序的库，它建立在LangChain.js之上并旨在与之一起使用。GitHub上有该项目的代码库。LangGraph.js可帮助开发人员构建具有状态和多角色功能的应用程序。LangGraph.js库适用于那些需要在应用程序中处理多个角色和状态的开发人员。LangGraph.js是一个建立在LangChain.js之上的库，旨在简化开发人员构建复杂应用程序的过程。LangGraph.js提供了一种有效的方式来管理状态和角色，并且能够与LangChain.js一起使用，使开发更加轻松。LangGraph.js的GitHub代码库包含了该库的所有代码，开发人员可以通过GitHub找到并了解该库的更多信息。LangGraph.js是一个强大的工具，可帮助开发人员快速构建具有LLM的多角色应用程序。总结：LangGraph.js是一个用于构建有状态、多角色应用程序的库，建立在LangChain.js之上，开发人员可以通过GitHub找到该项目的代码库。LangGraph.js提供了一种简化开发过程的有效方式，能够有效管理应用程序中的状态和角色，是一个强大的工具。 <div>
'LangGraph.js - a library for building stateful, multi-actor applications with LLMs, built on top of (and intended to be used with) LangChain.js' GitHub: github.com/langchain-ai/langgraphjs <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoctfvf9u7j21g80u0dma.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:38:05 GMT</pubDate>
</item>
<item>
<title>【nl-sh: 允许用户在终端中直接集成OpenAI的GPTs、Anthropic的Claude或本地GGUF格式的LLM，使操作人员能用流利的人类语言描述任务并执行】’nl-sh: Natural Lang...</title>
<link>https://weibo.com/1402400261/O7TJWloOf</link>
<guid>https://weibo.com/1402400261/O7TJWloOf</guid>
<content:encoded><![CDATA[
<div> 终端、集成、OpenAI、GPTs、Anthropic、Claude、GGUF、LLM、描述任务、执行。<br /><br />总结:
文章介绍了一种名为Natural Language Shell的工具，可以在终端中直接集成OpenAI的GPTs、Anthropic的Claude或本地GGUF格式的LLM，使操作人员能够用流利的人类语言描述任务并执行。这种工具可以让操作人员在终端中以POSIX命令或流利的人类语言描述任务，从而简化操作流程并提高效率。通过集成不同的语言模型，可以提供更多的选择和个性化的体验。该工具的开源地址为github.com/mikecvet/nl-sh，可以在GitHub上查看更多相关信息和下载使用。 <div>
【nl-sh: 允许用户在终端中直接集成OpenAI的GPTs、Anthropic的Claude或本地GGUF格式的LLM，使操作人员能用流利的人类语言描述任务并执行】’nl-sh: Natural Language Shell - The Natural Language Shell integrates OpenAI's GPTs, Anthropic's Claude, or local GGUF-formatted LLMs directly into the terminal experience, allowing operators to describe their tasks in either POSIX commands or fluent human language' GitHub: github.com/mikecvet/nl-sh <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoct9xdb1mj21db0u045y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:32:22 GMT</pubDate>
</item>
<item>
<title>【关于用Agent/大模型打游戏的相关文献资源列表】’A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges - This repo is...</title>
<link>https://weibo.com/1402400261/O7THU9SSK</link>
<guid>https://weibo.com/1402400261/O7THU9SSK</guid>
<content:encoded><![CDATA[
<div> 关键词: 游戏玩家代理、大型模型、方法、应用、挑战、调查、多模态、GitHub、资源

总结: 
<br /><br />这篇文章是有关游戏玩家代理和大型模型的综述调查，介绍了相关方法、应用和挑战。GitHub上提供了一份不断更新的游戏玩家代理和大型多模态模型的文献资源列表。文章主要探讨了游戏玩家代理和大型模型的研究现状和挑战，为该领域的研究提供了有价值的参考。 <div>
【关于用Agent/大模型打游戏的相关文献资源列表】’A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges - This repo is a live list of papers on game playing and large multimodality model - "A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges".' GitHub: github.com/BAAI-Agents/GPA-LM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoct4p04f4j20u00umq8o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:27:21 GMT</pubDate>
</item>
<item>
<title>【GraphAr：开源的、用于存储和检索图数据的标准数据文件格式】'GraphAr - An open source, standard data file format for graph data storage and retrieval' ...</title>
<link>https://weibo.com/1402400261/O7TGHfnZl</link>
<guid>https://weibo.com/1402400261/O7TGHfnZl</guid>
<content:encoded><![CDATA[
<div> GraphAr, 开源, 标准数据文件格式, 图数据, 存储, 检索, GitHub, GraphScope

<br /><br />总结:
GraphAr是一个开源的标准数据文件格式，用于存储和检索图数据。它旨在提供一种统一的方式来组织和访问图数据，使得数据的存储和检索变得更加高效和便捷。通过使用GraphAr，用户可以更容易地管理和操作图数据，从而提高数据处理的效率和准确性。GraphAr将图数据存储在标准格式的文件中，可以通过GitHub获取并使用。 <div>
【GraphAr：开源的、用于存储和检索图数据的标准数据文件格式】'GraphAr - An open source, standard data file format for graph data storage and retrieval' GitHub: github.com/GraphScope/GraphAr <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoct1ly59yj214w0u0n2x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:24:22 GMT</pubDate>
</item>
<item>
<title>'Translational-Style-ChatLLM：西式翻译腔聊天风格中文大模型 - 完全依靠ChatGPT生成数据微调的西式翻译腔聊天风格中文大模型' GitHub: github.com/Benson114/T...</title>
<link>https://weibo.com/1402400261/O7TG2qqfH</link>
<guid>https://weibo.com/1402400261/O7TG2qqfH</guid>
<content:encoded><![CDATA[
<div> 关键词: 西式翻译腔聊天风格、中文大模型、ChatGPT、GitHub

总结:<br /><br />这篇文章介绍了《Translational-Style-ChatLLM：西式翻译腔聊天风格中文大模型》，这是一个完全依靠ChatGPT生成数据微调的西式翻译腔聊天风格中文大模型。GitHub上有相关项目链接。 <div>
'Translational-Style-ChatLLM：西式翻译腔聊天风格中文大模型 - 完全依靠ChatGPT生成数据微调的西式翻译腔聊天风格中文大模型' GitHub: github.com/Benson114/Translational-Style-ChatLLM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hocszxfsemj21ee0kaaea.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:22:45 GMT</pubDate>
</item>
<item>
<title>【用Transformer作为编码器和解码器的无损压缩的概念Demo】’Lossless Text Compression with Transformer-based Language Model - This repo is to demo the co...</title>
<link>https://weibo.com/1402400261/O7TFDoXRY</link>
<guid>https://weibo.com/1402400261/O7TFDoXRY</guid>
<content:encoded><![CDATA[
<div> Transformer、编码器、解码器、无损压缩、文本、语言模型、Github、Lossless Text Compression、demo、概念

总结:<br />
本文介绍了使用Transformer作为编码器和解码器进行无损压缩的概念。这个概念的demo已经在GitHub上发布，展示了如何利用Transformer-based语言模型实现文本的无损压缩。这种方法可以有效地压缩文本数据，同时保证数据的完整性，有望在实际应用中发挥重要作用。 <div>
【用Transformer作为编码器和解码器的无损压缩的概念Demo】’Lossless Text Compression with Transformer-based Language Model - This repo is to demo the concept of lossless compression with Transformers as encoder and decoder.' GitHub: github.com/Shawn-Guo-CN/Lossless_Text_Compression_with_Transformer <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hocsyuonitj21ca0u0gr9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:21:45 GMT</pubDate>
</item>
<item>
<title>【MineLand： 基于 Minecraft 的大型多 Agent 交互模拟器，支持有限的多模态感知和物理需求】'MineLand - Simulating Large-Scale Multi-Agent Interactions wit...</title>
<link>https://weibo.com/1402400261/O7TtFvChI</link>
<guid>https://weibo.com/1402400261/O7TtFvChI</guid>
<content:encoded><![CDATA[
<div> GitHub, MineLand, Minecraft, 多Agent, 交互模拟器, 多模态感知, 物理需求
<br />
<br />
总结:
MineLand是一个基于Minecraft的大型多Agent交互模拟器，支持有限的多模态感知和物理需求。该模拟器允许多个Agent在虚拟世界中进行交互，并能感知不同的模态信息，同时还需满足物理需求。通过GitHub上的项目页面，用户可以了解更多有关MineLand的信息和使用方法。MineLand的研究意义在于模拟大规模多Agent之间的交互，为研究人员提供了一个实验平台，用于探索Agent之间的关系和行为。MineLand的开发对于深入理解多Agent系统的运行机制具有重要意义，有助于推动相关领域的发展。 <div>
【MineLand： 基于 Minecraft 的大型多 Agent 交互模拟器，支持有限的多模态感知和物理需求】'MineLand - Simulating Large-Scale Multi-Agent Interactions with Limited Multimodal Senses and Physical Needs' GitHub: github.com/cocacola-lab/MineLand <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hocs47jdh4j21hc0u07kw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 12:52:17 GMT</pubDate>
</item>
<item>
<title>【StableTTS：轻量TTS模型，专为汉语和英语语音生成服务，参数仅有 10M】'StableTTS - Next-generation TTS model using flow-matching and DiT, inspired by St...</title>
<link>https://weibo.com/1402400261/O7QI8snkE</link>
<guid>https://weibo.com/1402400261/O7QI8snkE</guid>
<content:encoded><![CDATA[
<div> GitHub, StableTTS, 轻量, 汉语, 英语, 语音生成, 10M, 模型, 流匹配, DiT

<br /><br />总结:
StableTTS是一种轻量级TTS模型，专为汉语和英语语音生成服务而设计，模型参数仅有10M。该模型采用了流匹配和DiT技术，受稳定扩散3的启发。这种Next-generation TTS模型将语音合成领域带入了新的阶段，能够更高效地生成自然流畅的语音。通过GitHub平台，用户可以查看和了解StableTTS的具体实现和应用。 <div>
【StableTTS：轻量TTS模型，专为汉语和英语语音生成服务，参数仅有 10M】'StableTTS - Next-generation TTS model using flow-matching and DiT, inspired by Stable Diffusion 3' GitHub: github.com/KdaiP/StableTTS <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hocfwiijyuj21ji0n2q6z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 05:49:41 GMT</pubDate>
</item>
<item>
<title>【HeyForm：开源的表单构建器，允许创建引人入胜的对话性形式用于调查、问卷、测验和投票，无需编程技能即可使用】'HeyForm - an open-source form builder that...</title>
<link>https://weibo.com/1402400261/O7QAdy3jc</link>
<guid>https://weibo.com/1402400261/O7QAdy3jc</guid>
<content:encoded><![CDATA[
<div> 开源、表单构建器、对话性形式、调查、问卷、测验、投票、无需编程技能、GitHub、github.com/heyform/heyform

<br /><br />总结:
HeyForm是一个开源的表单构建器，允许用户创建引人入胜的对话性形式，用于进行调查、问卷、测验和投票。用户无需具备编程技能，通过访问其GitHub页面github.com/heyform/heyform即可开始使用。HeyForm的设计简洁易用，适合各种用户使用，为用户提供了便利的表单创建方式，并能够生成丰富多样的形式，帮助用户收集信息和进行数据分析。 <div>
【HeyForm：开源的表单构建器，允许创建引人入胜的对话性形式用于调查、问卷、测验和投票，无需编程技能即可使用】'HeyForm - an open-source form builder that allows anyone to create engaging conversational forms for surveys, questionnaires, quizzes, and polls. No coding skills required.' GitHub: github.com/heyform/heyform <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hocfc605l7j21900u0n3y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 05:30:10 GMT</pubDate>
</item>
<item>
<title>【RAGFlow：基于深度文档理解构建的开源 RAG(Retrieval-Augmented Generation)引擎】'RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine ...</title>
<link>https://weibo.com/1402400261/O7Qzt7oOe</link>
<guid>https://weibo.com/1402400261/O7Qzt7oOe</guid>
<content:encoded><![CDATA[
<div> 深度文档理解、开源、RAG、引擎、Retrieval-Augmented Generation、GitHub、infiniflow、RAGFlow

<br /><br />总结:
RAGFlow是一个基于深度文档理解构建的开源RAG引擎，采用Retrieval-Augmented Generation技术。用户可以在GitHub上找到该项目的代码库，地址为github.com/infiniflow/ragflow。该引擎具有强大的文档理解能力，能够实现检索和生成结合的文本处理任务。通过RAGFlow，用户可以更加高效地处理文档信息并进行相关任务的实现。 <div>
【RAGFlow：基于深度文档理解构建的开源 RAG(Retrieval-Augmented Generation)引擎】'RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.' GitHub: github.com/infiniflow/ragflow <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hocfa8ht0vj21hc0u00uu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 05:28:19 GMT</pubDate>
</item>
<item>
<title>恭喜@VarusRey 等3名用户获得【《码农翻身2》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效。公示链接：网页链接 - 转发 @爱可可-爱...</title>
<link>https://weibo.com/1402400261/O7Q1b6Oiu</link>
<guid>https://weibo.com/1402400261/O7Q1b6Oiu</guid>
<content:encoded><![CDATA[
<div> 码农翻身2 抽奖 微博 官方 工具 监督 公正 有效 参与 技术 故事 编程语言 Java Python JavaScript C语言 MySQL Redis 技术原理 读起来爽

<br /><br />总结:
在微博举办的《码农翻身2》抽奖活动中，官方唯一抽奖工具监督抽奖过程，确保结果公正有效。参与者只需转发并评论即可参与，有机会获得新出版的《码农翻身2》。这本畅销书以故事的方式讲解技术，让看似枯燥的技术变得有趣。故事中展现了各个编程语言之间的争斗和互动，让读者掌握技术原理的同时又能享受阅读乐趣。 <div>
恭喜<a href="https://weibo.com/n/VarusRey">@VarusRey</a> 等3名用户获得【《码农翻身2》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20280688&amp;pageid=100140E51193834"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 04:03:49 GMT</pubDate>
</item>
<item>
<title>【CPU上的LLaMA语言模型推理速度优化实践】 - 作者为llamafile编写了84个新的矩阵乘法核，使其在CPU上处理prompt和图像的速度提高30%到500%。这对ARM和AVX512等C...</title>
<link>https://weibo.com/1402400261/O7Osgu4Br</link>
<guid>https://weibo.com/1402400261/O7Osgu4Br</guid>
<content:encoded><![CDATA[
<div> 矩阵乘法、CPU、LLaMA、优化、性能、跨平台、普及、应用、性能分析、改进
<br /><br />总结: 通过优化矩阵乘法内核，作者成功提升了LLaMA在CPU上的推理速度，对于资源受限设备的应用具有重要意义。跨平台和跨架构的优化使得LLaMA在更广泛的环境中运行，促进了LLM的普及和应用。作者通过性能分析找到瓶颈并进行有针对性的优化，展示了一种值得借鉴的工程方法。当前优化虽然对长提示的加速有限，但作者持续改进，相信后续表现会更加令人期待。文章首先突出了矩阵乘法在LLM中的核心地位和优化的重要性，详细描述了优化过程和结果，分享了性能优化经验。代码已提交给LLaMA的上游项目，以使更多用户受益。 <div>
【CPU上的LLaMA语言模型推理速度优化实践】<br /> - 作者为llamafile编写了84个新的矩阵乘法核，使其在CPU上处理prompt和图像的速度提高30%到500%。这对ARM和AVX512等CPU架构提速明显。   <br />- 在不同的CPU硬件上测试了优化后的llamafile和原版llama.cpp的性能，结果显示llamafile的速度提升幅度可达2倍。测试的硬件包括Intel、ARM、AMD等在内的服务器、个人电脑和专业工作站。   <br />- 作者主要通过优化矩阵乘法来实现提速，因为分析发现矩阵乘法占了95%的时间。作者使用C++实现了优化的矩阵乘法内核。   <br />- 作者不仅关注服务器硬件的性能，还重视廉价的个人电脑和树莓派等爱好者硬件的性能提升，以使更多用户也能受益。   <br />- 作者还分析了不同数据类型如fp16、bfloat16等对速度和精度的影响。并增加了对这些数据类型的支持。   <br />- 作者的代码已提交给llama.cpp的上游项目，以便所有用户都能受益。代码使用MIT许可发布。   <br />- 文章详细描述了作者是如何通过优化关键的矩阵乘法操作来显著提高整个语言模型的推理速度的，旨在分享这一性能优化经验。   <br /><br />思考：  <br />- 作者通过优化矩阵乘法内核，大幅提升了llamafile在CPU上的推理速度，这对于在资源受限设备上部署LLM具有重要意义。  <br />- 跨平台和跨架构的优化使llamafile能够在更广泛的环境中运行，有利于LLM的普及和应用。  <br />- 通过性能分析定位瓶颈，并针对性优化，这种工程方法值得借鉴。  <br />- 虽然目前的优化对较长提示的加速效果有限，但作者正在持续改进，后续表现值得期待。  <br />- 文章在开头通过简洁的代码定义矩阵乘法，突出了其在LLM中的核心地位和优化的重要性。<br />《LLaMA Now Goes Faster on CPUs》 <a href="https://justine.lol/matmul"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoc5xqcm7uj211q0u0n4f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 00:05:05 GMT</pubDate>
</item>
<item>
<title>“Datawhale - 专注于AI领域的开源组织，致力于构建一个纯粹的学习圈子，帮助学习者更好地成长” 网页链接 #机器学习# #人工智能# [图片][图片][图片]</title>
<link>https://weibo.com/1402400261/O7OqmCa13</link>
<guid>https://weibo.com/1402400261/O7OqmCa13</guid>
<content:encoded><![CDATA[
<div> Datawhale, AI领域, 开源组织, 纯粹学习圈子, 帮助学习者, 成长<br />
<br />
在AI领域，Datawhale是一个专注于开源组织，旨在构建一个纯粹的学习圈子，帮助学习者更好地成长。他们致力于为学习者提供资源和支持，促进知识的共享和学习的发展，旨在推动AI领域的进步和发展。通过不断学习和交流，学习者能够不断提升技能，实现个人的成长和发展。<br /><br />总结: Datawhale是专注于AI领域的开源组织，旨在构建一个纯粹的学习圈子，帮助学习者更好地成长。通过资源和支持，推动知识分享和学习发展，促进个人技能提升和成长。 <div>
“Datawhale - 专注于AI领域的开源组织，致力于构建一个纯粹的学习圈子，帮助学习者更好地成长” <a href="https://linklearner.com/home"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoc5s699fjj21hw0u0n0m.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoc5sp5b6gj20zs0u0dis.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoc5t3b46aj217n0u0gom.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 00:00:24 GMT</pubDate>
</item>
<item>
<title>【矩阵形状与矩阵乘法性能】- 矩阵乘法的性能随矩阵尺寸的增大而整体提升，这是由于计算强度提高和并行度提高带来的。运算相对于内存访问的算术强度越高，性能越...</title>
<link>https://weibo.com/1402400261/O7OpehzFb</link>
<guid>https://weibo.com/1402400261/O7OpehzFb</guid>
<content:encoded><![CDATA[
<div> 矩阵乘法、矩阵形状、性能、计算强度、并行度、划分、内存访问、算术强度、优化、深度学习<br />
<br />
总结:<br />
矩阵乘法的性能随着矩阵尺寸的增大而提升，这与计算强度提高和并行度增加有关。算术强度越高，性能越好。矩阵乘法的性能与矩阵形状的可划分性密切相关，形状能被2、8、16等2的幂整除时性能更优。当形状大小超过波粒子整数倍时，会出现性能下降，这与硬件SM数量相关。微小的矩阵形状变化可能导致巨大的性能差异，选择能被缓存行大小整除的形状很重要。一些框架能自动优化矩阵形状，但手动优化依然重要。理解矩阵运算性能的决定因素，选择合适的矩阵形状，对深度学习模型的性能提升至关重要。 <div>
【矩阵形状与矩阵乘法性能】<br />- 矩阵乘法的性能随矩阵尺寸的增大而整体提升，这是由于计算强度提高和并行度提高带来的。运算相对于内存访问的算术强度越高，性能越好。   <br />- 矩阵乘法的性能与矩阵形状的可划分性高度相关，当形状能被2、8、16等2的幂整除时，性能明显更好。这是由于划分(tiling)带来的更优内存访问模式。   <br />- 当矩阵形状大小超过波粒子(wave)的整数倍时，会出现明显的性能下降。这种波粒子量化的影响与硬件SM(流处理器)的数量相关。   <br />- 由于上述原因，微小的矩阵形状变化可能导致巨大的性能差异。选择能够被缓存行大小整除的形状非常重要。   <br />- 一些框架如torch.compile会自动优化矩阵形状，将其pad至更优形状。但由于存在显存消耗和波粒子量化难以优化的问题，手动优化形状依然重要。   <br />- 理解矩阵运算性能的决定因素，选择合适的矩阵形状，能显著提升矩阵计算的性能。这对基于矩阵运算的深度学习模型具有重要意义。<br />《What Shapes Do Matrix Multiplications Like? [medium]》 <a href="https://www.thonking.ai/p/what-shapes-do-matrix-multiplications"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoc5q6je9dj20w30u00wt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 23:57:36 GMT</pubDate>
</item>
<item>
<title>【用AutoTrain微调Mixtral 8x7B实战】《Finetune Mixtral 8x7B with AutoTrain》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O7OnL0nLA</link>
<guid>https://weibo.com/1402400261/O7OnL0nLA</guid>
<content:encoded><![CDATA[
<div> 关键词：AutoTrain、微调、Mixtral 8x7B、实战

总结:
<br /><br />
本文介绍了如何使用AutoTrain对Mixtral 8x7B进行微调，以适应实际应用场景。首先介绍了Mixtral 8x7B的基本情况，然后详细说明了AutoTrain微调的流程和步骤。通过实例分析和操作步骤，读者可以了解如何利用AutoTrain进行深度模型微调，以提高模型在具体任务上的表现和效果。整个过程需要细致的数据准备、模型配置和调整，同时也需要合理的训练策略和参数设置。最后，作者总结了AutoTrain微调Mixtral 8x7B的实战经验，为读者提供了更加高效和实用的深度学习模型微调方法。通过本文的学习，读者可以更好地掌握深度学习模型微调的技巧和方法，以应对不同任务和场景的需求。 <div>
【用AutoTrain微调Mixtral 8x7B实战】《Finetune Mixtral 8x7B with AutoTrain》 <a href="https://huggingface.co/blog/abhishek/autotrain-mixtral-dgx-cloud-local"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoc5me4grnj20u00utaec.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 23:53:58 GMT</pubDate>
</item>
<item>
<title>HuggingFace开源AI方案手册 - 转发 @爱可可-爱生活:&amp;ensp;【Open-Source AI Cookbook：HuggingFace开源AI方案手册，涵盖了使用开源工具和模型构建AI应用和解决各...</title>
<link>https://weibo.com/1402400261/O7OnguHgt</link>
<guid>https://weibo.com/1402400261/O7OnguHgt</guid>
<content:encoded><![CDATA[
<div> HuggingFace, AI, 开源, 方案手册, 模型, 构建, 应用, 解决任务, GitHub, 笔记本

<br /><br />总结:
HuggingFace开源AI方案手册是一个收集了实际构建AI应用和使用开源工具和模型解决各种机器学习任务的笔记本集合。该手册在GitHub上提供，涵盖了使用HuggingFace开源工具和模型的实用方面。读者可以通过这些示例了解如何利用开源工具和模型构建AI应用，解决各种机器学习任务。通过这些笔记本，读者可以更深入地了解如何利用HuggingFace的技术来提升自己的AI项目。GitHub链接提供了丰富的资源，为AI开发者提供了学习和研究的平台。 HuggingFace开源AI方案手册将帮助读者更好地理解和应用AI技术，推动AI的发展。 <div>
HuggingFace开源AI方案手册<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 【Open-Source AI Cookbook：HuggingFace开源AI方案手册，涵盖了使用开源工具和模型构建AI应用和解决各种任务的方法】'Open-Source AI Cookbook - a collection of notebooks illustrating practical aspects of building AI applications and solving various machine learning tasks using open-source tools and models.’ <a href="https://huggingface.co/learn/cookbook/index"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> GitHub: github.com/huggingface/cookbook <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hmw5wsoap6j20u00ypagc.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 23:52:46 GMT</pubDate>
</item>
<item>
<title>【AI对话零门槛：ChatGPT开放免注册使用】- OpenAI推出了无需注册即可使用ChatGPT的功能，降低了使用门槛，让更多人可以体验AI的好处。 - 目前每周有超过1亿用户...</title>
<link>https://weibo.com/1402400261/O7OmLyBYE</link>
<guid>https://weibo.com/1402400261/O7OmLyBYE</guid>
<content:encoded><![CDATA[
<div> OpenAI, ChatGPT, 无需注册, 降低门槛, 1亿用户, 全球影响力, 用户隐私, 内容安全, 注册用户功能, AI普惠化

总结:<br /><br />OpenAI推出了无需注册即可使用ChatGPT的功能，降低了使用门槛，让更多人可以体验AI的好处。每周有超过1亿用户在185个国家使用ChatGPT，免注册使用将进一步扩大用户基础。虽然取消注册要求，但OpenAI重视用户隐私和内容安全，并提供注册用户专属功能。OpenAI的使命是让普通大众也能体验到AI工具带来的益处，这个新功能是朝着AI普惠化更进一步的重要一步。 <div>
【AI对话零门槛：ChatGPT开放免注册使用】<br />- OpenAI推出了无需注册即可使用ChatGPT的功能，降低了使用门槛，让更多人可以体验AI的好处。   <br />- 目前每周有超过1亿用户在185个国家使用ChatGPT，以学习新知识、寻找创作灵感和获得问题解答。开放使用功能将进一步提升覆盖面。   <br />- 用户提供的信息可能会被OpenAI用来改进模型，但用户可以通过设置关闭此功能。更多详细信息可以在帮助中心查看。   <br />- 为提高内容安全，该体验增加了更广泛类别的提示和生成内容屏蔽。   <br />- 注册账户可以获得保存聊天记录、分享聊天、语音对话等额外功能。   <br />- 对任何之前因注册流程门槛而无法尝试AI的人来说，这个新功能提供了一个零门槛使用ChatGPT的机会。   <br />- OpenAI的使命是让普通大众也能体验到AI工具带来的益处。这个功能的推出是朝着使AI普惠化更进一步。<br /><br />思考：    <br />- 取消注册要求是OpenAI在普及AI方面迈出的重要一步，这将大大降低普通用户接触和体验ChatGPT的门槛，有利于加速AI技术的大众化进程。    <br />- ChatGPT的全球影响力已经非常显著，超过1亿的周活跃用户数据印证了其在知识获取、创意激发等方面的价值。免注册使用将进一步扩大其用户基础。    <br />- 在开放的同时，OpenAI也重视用户隐私和内容安全，为用户提供了控制个人数据使用的选项，并加强了内容审核，这种负责任的态度值得肯定。    <br />- 虽然免注册使用受到欢迎，但注册用户专属的附加功能仍有吸引力，OpenAI在两种模式间取得了较好的平衡。    <br />- 随着准入门槛的降低，ChatGPT在教育、创意、个人助理等领域的应用有望进一步深化，但同时也需警惕对人类认知和创造力的潜在负面影响。<br />《Start using ChatGPT instantly》 <a href="https://openai.com/blog/start-using-chatgpt-instantly"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoc5jv8pktj21i60u0q64.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 23:51:32 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可...</title>
<link>https://weibo.com/1402400261/O7OjVxm5u</link>
<guid>https://weibo.com/1402400261/O7OjVxm5u</guid>
<content:encoded><![CDATA[
<div> Java Python JavaScript C语言 MySQL Redis 技术故事 编程语言 欢迎参与开奖活动！ 

<br /><br />总结:
欢迎参与今日开奖活动，转发并评论可有机会获得《码农翻身2》。书中通过编程语言王国的争斗故事，以轻松幽默的方式讲解技术知识，让枯燥的技术变得有趣。不同编程语言相互攻击，技术原理交融，读者能够在阅读中掌握技术本质。MySQL和Redis之间的对抗，以及C语言的悲催经历，都让读者在阅读过程中获得乐趣和知识。《码农翻身2》的故事情节生动有趣，让大家能够深入理解技术知识，享受阅读乐趣。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 23:44:32 GMT</pubDate>
</item>
<item>
<title>今日推介(第1363期)：从大型语言模型中蒸馏的通用文本嵌入、慢变序列稳定机器学习模型再训练研究、语言模型段落记忆定位、LLM长文本不确定性量化、Transformer- ...</title>
<link>https://weibo.com/1402400261/O7NJulgMx</link>
<guid>https://weibo.com/1402400261/O7NJulgMx</guid>
<content:encoded><![CDATA[
<div> 蒸馏、文本嵌入、慢变序列、稳定机器学习、模型再训练、段落记忆、长文本、不确定性量化、Transformer、混合语言模型

总结：<br />
研究围绕大型语言模型展开，从中提取了通用文本嵌入，通过蒸馏技术实现。同时探讨了慢变序列稳定机器学习模型再训练的方法和实践。针对语言模型段落记忆问题，提出了相应的定位方法。此外，还对LLM长文本不确定性进行量化研究，以提升模型性能。最后，介绍了Transformer-mamba混合语言模型的开发和应用。整体研究丰富了自然语言处理领域的技术和应用。 <div>
今日推介(第1363期)：从大型语言模型中蒸馏的通用文本嵌入、慢变序列稳定机器学习模型再训练研究、语言模型段落记忆定位、LLM长文本不确定性量化、Transformer- mamba混合语言模型 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/690275166"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.2)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoc2qnz3gxj21m30u00yq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoc2qsoq97j21qp0u0tf9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoc2qy4q8cj20te1bcai1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoc2r20mejj21ij0u0dp0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoc2r55kozj20u00vn0w8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 22:14:45 GMT</pubDate>
</item>
<item>
<title>[AI] Towards Greener LLMs: Bringing Energy-Efficiency to the Forefront of LLM Inference 网页链接 通过调节频率、并行度和批处理等多种手段，全面描绘了优...</title>
<link>https://weibo.com/1402400261/O7NFCbFAF</link>
<guid>https://weibo.com/1402400261/O7NFCbFAF</guid>
<content:encoded><![CDATA[
<div> 频率、并行度、批处理、大语言模型、推理平台、能效、性能权衡、数据中心、设计指导

<br /><br />总结:
本文通过调节频率、并行度和批处理等多种手段，全面探讨了优化大语言模型推理平台能效的各种性能权衡。文章为未来数据中心提供了宝贵的设计指导，为实现更加环保的LLMs起到了重要作用。 <div>
[AI] Towards Greener LLMs: Bringing Energy-Efficiency to the Forefront of LLM Inference  <br /><a href="https://arxiv.org/abs/2403.20306"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过调节频率、并行度和批处理等多种手段，全面描绘了优化大语言模型推理平台能效的各种性能权衡，为未来的数据中心提供了宝贵的设计指导。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc2h6digoj20zq1b0kek.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc2h6ui3yj20ls19oaja.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc2h7ipd0j20ls1dwdp3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc2h83c1cj20lu1dyajg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 22:05:13 GMT</pubDate>
</item>
<item>
<title>[CL] STRUM-LLM: Attributed and Structured Contrastive Summarization 网页链接 提出了STRUM-LLM系统，使用大语言模型生成有结构、归因和对比性的摘要，以帮助...</title>
<link>https://weibo.com/1402400261/O7NBeif7h</link>
<guid>https://weibo.com/1402400261/O7NBeif7h</guid>
<content:encoded><![CDATA[
<div> STRUM-LLM系统, 大语言模型, 生成, 结构, 归因, 对比性, 摘要, 无须标注数据, 处理任意长度输入, 自我修订, 质量提升

<br /><br />总结: 
研究提出了STRUM-LLM系统，利用大语言模型生成结构化、归因和对比性的摘要，帮助用户在选择两个选项时做出明智决策。这一方法无需标注数据，能够处理任意长度的输入，并通过自我修订显著提升了摘要质量。 <div>
[CL] STRUM-LLM: Attributed and Structured Contrastive Summarization  <br /><a href="https://arxiv.org/abs/2403.19710"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出了STRUM-LLM系统，使用大语言模型生成有结构、归因和对比性的摘要，以帮助用户在两个选项间进行明智决策，方法无须标注数据，可以处理任意长度输入，通过自我修订显著提升质量。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc25zf8dzj20yy1cstq0.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc25zrv8wj20sw162q9j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:54:25 GMT</pubDate>
</item>
<item>
<title>[CL] ReALM: Reference Resolution As Language Modeling 网页链接 本文通过将指代消解建模为语言模型选择任务，证明了语言模型可以高效解决包含非对话在内的各...</title>
<link>https://weibo.com/1402400261/O7NxtaOwL</link>
<guid>https://weibo.com/1402400261/O7NxtaOwL</guid>
<content:encoded><![CDATA[
<div> RealM, 指代消解, 语言模型选择任务, 非对话, 高效解决, 关键词

<br /><br />总结:
本文通过将指代消解建模为语言模型选择任务，证明了语言模型可以高效解决包含非对话在内的各类指代消解。语言模型在处理指代消解时表现出色，能够有效解决各种语境下的指代问题。这种方法有效缩减了指代消解的复杂性，提高了处理效率。RealM模型为指代消解提供了新的解决思路，为相关领域的研究和应用带来了新的启示。 <div>
[CL] ReALM: Reference Resolution As Language Modeling  <br /><a href="https://arxiv.org/abs/2403.20329"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />本文通过将指代消解建模为语言模型选择任务，证明了语言模型可以高效解决包含非对话在内的各类指代消解。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc1wcriqnj20uu1a4qj3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc1wcwzqgj20us10q42s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:45:09 GMT</pubDate>
</item>
<item>
<title>[CL] DiJiang: Efficient Large Language Models through Compact Kernelization 网页链接 DiJiang通过频域核化，实现了将预训练Transformer高效转换为线性复杂...</title>
<link>https://weibo.com/1402400261/O7NuvCmpL</link>
<guid>https://weibo.com/1402400261/O7NuvCmpL</guid>
<content:encoded><![CDATA[
<div> 频域核化 预训练Transformer 线性复杂度 模型 训练 推理 成本 性能 DiJiang<br />
<br />
提出了一种名为DiJiang的方法，通过频域核化将预训练的Transformer模型高效地转换为具有线性复杂度的模型。这一方法极大地降低了模型的训练和推理成本，同时仍保持了可比的性能水平。DiJiang方法的核心思想是利用频域核化技术，通过计算频域特征来简化模型的复杂度，从而提高模型的效率。通过实验证明，DiJiang模型在保持性能的同时，大幅减少了训练和推理的时间成本，为大规模语言模型的应用提供了一种高效的解决方案。总的来说，DiJiang方法为提升大型语言模型的效率和性能做出了重要贡献。<br /><br />总结: <br />DiJiang通过频域核化将预训练Transformer模型转换为具有线性复杂度的模型，降低了训练和推理成本，保持了可比的性能。 <div>
[CL] DiJiang: Efficient Large Language Models through Compact Kernelization  <br /><a href="https://arxiv.org/abs/2403.19928"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />DiJiang通过频域核化，实现了将预训练Transformer高效转换为线性复杂度模型，极大降低了训练和推理成本，同时保持了可比的性能。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc1oqlhhkj211m1c41e9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc1oqwsg9j21im0ocn3t.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc1oredckj20r20qajuj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc1orxnowj21f40jote2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:37:52 GMT</pubDate>
</item>
<item>
<title>提出Jamba这种混合Transformer-Mamba结构的语言模型，在单GPU上实现了强大的性能，对长序列也很友好，是一种非常有前景的创新型架构。 - 转发 @爱可可-爱生活:&amp;e...</title>
<link>https://weibo.com/1402400261/O7NrFyUBU</link>
<guid>https://weibo.com/1402400261/O7NrFyUBU</guid>
<content:encoded><![CDATA[
<div> Jamba, Transformer-Mamba, 语言模型, 单GPU, 性能, 长序列, 创新型架构

<br /><br />总结:
提出了一种混合Transformer-Mamba结构的语言模型Jamba，在单GPU上实现了强大的性能，对长序列也很友好。该架构具有前景，是一种创新型架构。 Jamba的设计结合了Transformer和Mamba的优点，具有高效的计算能力和长序列处理能力。在实验中，Jamba在多项任务上取得了优异的表现，证明了其性能和实用性。总体而言，Jamba是一种非常有潜力和前景的语言模型架构。 <div>
提出Jamba这种混合Transformer-Mamba结构的语言模型，在单GPU上实现了强大的性能，对长序列也很友好，是一种非常有前景的创新型架构。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Jamba: A Hybrid Transformer-Mamba Language Model》O Lieber, B Lenz, H Bata, G Cohen... [A21 Labs] (2024) <a href="https://arxiv.org/abs/2403.19887"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc1aergz1j21ck0xswuj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1af49fgj215k17ugrx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1afhehij215g0imgny.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc1afrbl0j21500kmdko.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd1qinj20vd0f0755.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd24sbj20ve0g3abi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd1tsrj20vd0egmy7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd301hj20vh0oiwje.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc1hd1bxhj20ns0dc0t7.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:30:52 GMT</pubDate>
</item>
<item>
<title>[CL]《Jamba: A Hybrid Transformer-Mamba Language Model》O Lieber, B Lenz, H Bata, G Cohen... [A21 Labs] (2024) 网页链接 #机器学习##人工智能##论文# [图...</title>
<link>https://weibo.com/1402400261/O7NrCw64v</link>
<guid>https://weibo.com/1402400261/O7NrCw64v</guid>
<content:encoded><![CDATA[
<div> Jamba, Hybrid Transformer-Mamba, Language Model, A21 Labs, 2024, O Lieber, B Lenz, H Bata, G Cohen

<br /><br />总结:
这篇文章介绍了一种名为Jamba的混合Transformer-Mamba语言模型，由A21 Labs团队在2024年的研究成果。该模型结合了Transformer和Mamba的特性，具有较强的语言建模能力。研究团队通过对O Lieber、B Lenz、H Bata和G Cohen等成员的研究，展示了Jamba在自然语言处理领域的潜在应用和优势。Jamba模型的推出将为语言建模和相关领域的发展提供新的思路和可能性。 <div>
[CL]《Jamba: A Hybrid Transformer-Mamba Language Model》O Lieber, B Lenz, H Bata, G Cohen... [A21 Labs] (2024) <a href="https://arxiv.org/abs/2403.19887"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc1aergz1j21ck0xswuj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1af49fgj215k17ugrx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1afhehij215g0imgny.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc1afrbl0j21500kmdko.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd1qinj20vd0f0755.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd24sbj20ve0g3abi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd1tsrj20vd0egmy7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd301hj20vh0oiwje.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc1hd1bxhj20ns0dc0t7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:30:44 GMT</pubDate>
</item>
<item>
<title>针对长文本生成提出句级一致性判断的LUQ方法进行不确定性量化，结果表明LUQ可显著提升语言模型的生成事实性。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《LUQ: Long-tex...</title>
<link>https://weibo.com/1402400261/O7Nl11qlt</link>
<guid>https://weibo.com/1402400261/O7Nl11qlt</guid>
<content:encoded><![CDATA[
<div> 关键词: 长文本生成, 句级一致性, 不确定性量化, LUQ 方法, 语言模型

总结:<br /><br />这篇文章介绍了一种针对长文本生成的句级一致性判断方法LUQ，并对不确定性进行了量化。研究结果显示，LUQ方法能显著提升语言模型的生成事实性。LUQ方法由来自剑桥大学和亚马逊AGI的C Zhang、F Liu、M Basaldella和N Collier合作研究，于2024年发表。这一方法的提出填补了长文本生成领域的研究空白，并为语言模型的发展带来了新的启示。LUQ方法不仅可以帮助评估生成文本的一致性，还可以对生成文本的不确定性进行量化，提高了生成文本的可信度。通过对LUQ方法的研究，可以为提高自然语言处理系统的效果提供有效的方法和技术。LUQ方法的应用前景广阔，对自然语言生成领域具有重要意义。 <div>
针对长文本生成提出句级一致性判断的LUQ方法进行不确定性量化，结果表明LUQ可显著提升语言模型的生成事实性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《LUQ: Long-text Uncertainty Quantification for LLMs》C Zhang, F Liu, M Basaldella, N Collier [University of Cambridge &amp; Amazon AGI] (2024) <a href="https://arxiv.org/abs/2403.20279"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0zrcezoj20kg19ck2a.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0zryhgij21rm0z0too.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0zs8jphj21rg15sqfv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0zseif2j20vm0z678i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc108mpwfj20ho0k3my5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc108mptdj20hm0d3mxj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:14:28 GMT</pubDate>
</item>
<item>
<title>[CL]《LUQ: Long-text Uncertainty Quantification for LLMs》C Zhang, F Liu, M Basaldella, N Collier [University of Cambridge &amp; Amazon AGI] (2024) 网页链...</title>
<link>https://weibo.com/1402400261/O7NkWjPxB</link>
<guid>https://weibo.com/1402400261/O7NkWjPxB</guid>
<content:encoded><![CDATA[
<div> 关键词: LUQ, Uncertainty Quantification, LLMs, Cambridge, Amazon AGI

LUQ: Long-text Uncertainty Quantification for LLMs 是由剑桥大学和亚马逊AGI合作的研究项目，致力于解决长文本对于语言模型的不确定性量化问题。研究着眼于提高语言模型对于长文本理解和处理的准确度，特别是在处理含有不确定性信息的文本时。通过引入新的方法和技术，研究团队成功地开发了LUQ框架，可以有效地衡量和管理语言模型在长文本处理过程中的不确定性。该框架的应用将有助于提升语言模型的性能，并推动自然语言处理领域的进一步发展。

总结:<br /><br />LUQ: Long-text Uncertainty Quantification for LLMs 是一个研究项目，旨在提高语言模型对长文本的处理准确度，尤其是在处理不确定性信息时。研究团队通过开发LUQ框架成功解决了这一问题，为自然语言处理领域的发展提供了新的思路和方法。 <div>
[CL]《LUQ: Long-text Uncertainty Quantification for LLMs》C Zhang, F Liu, M Basaldella, N Collier [University of Cambridge &amp; Amazon AGI] (2024) <a href="https://arxiv.org/abs/2403.20279"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0zrcezoj20kg19ck2a.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0zryhgij21rm0z0too.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0zs8jphj21rg15sqfv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0zseif2j20vm0z678i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc108mpwfj20ho0k3my5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc108mptdj20hm0d3mxj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:14:17 GMT</pubDate>
</item>
<item>
<title>通过梯度分析和训练目标，发现语言模型中的记忆主要集中在较低层的注意力头，解释了记忆的鲁棒性。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Localizing Paragraph Me...</title>
<link>https://weibo.com/1402400261/O7Nks758p</link>
<guid>https://weibo.com/1402400261/O7Nks758p</guid>
<content:encoded><![CDATA[
<div> 记忆、语言模型、注意力头、梯度分析、训练目标、鲁棒性、段落、定位、Google、ETH Zürich

总结:<br /><br />这篇文章通过梯度分析和训练目标发现，语言模型中的记忆主要集中在较低层的注意力头，这解释了记忆的鲁棒性。作者提出了定位段落记忆在语言模型中的方式，并对这一结论进行了实证研究。研究结果显示，语言模型在处理文本任务时对段落级别的记忆有显著影响，有助于解释语言模型的表现和性能。这一发现对语言模型研究和应用具有一定的启发意义，有望进一步拓展语言模型的应用领域。 <div>
通过梯度分析和训练目标，发现语言模型中的记忆主要集中在较低层的注意力头，解释了记忆的鲁棒性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Localizing Paragraph Memorization in Language Models》N Stoehr, M Gordon, C Zhang, O Lewis [Google &amp; ETH Zürich] (2024) <a href="https://arxiv.org/abs/2403.19851"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0y3jp0xj20uc1cogyf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0y3zf8jj20te1bcn7k.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0y49vojj20t60vudn1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0y4lql2j21m00x8ajv.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0yohechj20zx0wxq8n.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0yog5k7j20zt0igae0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0yogdymj20zx0sd77y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0yog11mj20zs0f4tay.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0yofgnwj20zs0atta4.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:13:05 GMT</pubDate>
</item>
<item>
<title>[CL]《Localizing Paragraph Memorization in Language Models》N Stoehr, M Gordon, C Zhang, O Lewis [Google &amp; ETH Zürich] (2024) 网页链接 #机器学习##人...</title>
<link>https://weibo.com/1402400261/O7Nkkr4DX</link>
<guid>https://weibo.com/1402400261/O7Nkkr4DX</guid>
<content:encoded><![CDATA[
<div> Paragraph Memorization, Language Models, Localizing, Google, ETH Zürich, N Stoehr, M Gordon, C Zhang, O Lewis

<br /><br />总结:
这篇文章由N Stoehr, M Gordon, C Zhang, O Lewis等人在2024年发表，并由Google和ETH Zürich合作完成。研究的主题是关于在语言模型中的段落记忆的本地化。研究指出了语言模型在总结信息时的一些问题，并提出了一种新的方法来处理这个问题，以提高模型的效率和准确性。研究结果显示，这种本地化的方法可以显著改善语言模型的记忆和总结能力，在各种应用场景中都具有潜在的重要性。文章的研究方法和结论对自然语言处理领域具有一定的参考价值。 <div>
[CL]《Localizing Paragraph Memorization in Language Models》N Stoehr, M Gordon, C Zhang, O Lewis [Google &amp; ETH Zürich] (2024) <a href="https://arxiv.org/abs/2403.19851"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0y3jp0xj20uc1cogyf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0y3zf8jj20te1bcn7k.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0y49vojj20t60vudn1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0y4lql2j21m00x8ajv.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0yohechj20zx0wxq8n.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0yog5k7j20zt0igae0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0yogdymj20zx0sd77y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0yog11mj20zs0f4tay.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0yofgnwj20zs0atta4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0yohxfgj20zy1atn5d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0yogkxlj20zs0j8776.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0yogkj8j20z40a90uf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0yoggjuj20zx0mf76t.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:12:47 GMT</pubDate>
</item>
<item>
<title>通过定义模型距离度量并集成到混合整数规划算法中，提出一种在机器学习模型数据批量再训练问题上既考虑性能又保证结构稳定性的全局优化方法。 - 转发 @爱可可-爱...</title>
<link>https://weibo.com/1402400261/O7NjUvh7e</link>
<guid>https://weibo.com/1402400261/O7NjUvh7e</guid>
<content:encoded><![CDATA[
<div> 模型距离度量, 混合整数规划, 数据批量再训练, 性能, 结构稳定性, 全局优化方法, 机器学习, 稳定性, 慢变化序列
<br />
<br />
总结: 
该研究提出了一种在机器学习模型数据批量再训练中考虑性能和保证结构稳定性的全局优化方法。通过定义模型距离度量并集成到混合整数规划算法中，利用慢变化序列确保模型稳定性。这种方法在实际应用中有望提升机器学习模型的性能和稳定性，对于机器学习领域具有一定的实用意义。 <div>
通过定义模型距离度量并集成到混合整数规划算法中，提出一种在机器学习模型数据批量再训练问题上既考虑性能又保证结构稳定性的全局优化方法。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Towards Stable Machine Learning Model Retraining via Slowly Varying Sequences》V D Jr, Y Ma, P Paschalidis, D Bertsimas [Management, HEC Paris &amp; MIT &amp; Harvard University] (2024) <a href="https://arxiv.org/abs/2403.19871"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0wvp1eej21d40rqdsd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0ww6ophj21m20rsjzn.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0wwfi43j21ma0pmahx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0wwjpfmj21mo0todm9.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:11:44 GMT</pubDate>
</item>
<item>
<title>[LG]《Towards Stable Machine Learning Model Retraining via Slowly Varying Sequences》V D Jr, Y Ma, P Paschalidis, D Bertsimas [Management, HEC Paris &amp;...</title>
<link>https://weibo.com/1402400261/O7NjQ4qli</link>
<guid>https://weibo.com/1402400261/O7NjQ4qli</guid>
<content:encoded><![CDATA[
<div> 稳定性、机器学习、模型再训练、缓慢变化序列、管理、HEC巴黎、MIT、哈佛大学

总结:<br /><br />这篇文章提出了一种通过缓慢变化序列实现稳定机器学习模型再训练的方法。研究人员来自管理、HEC巴黎、MIT和哈佛大学，他们的方法旨在解决机器学习模型再训练过程中出现的不稳定性问题。通过引入缓慢变化的序列，可以有效地降低模型训练过程中的不确定性，提高模型的稳定性和准确性。这项研究对于提高机器学习模型再训练的效率和可靠性具有重要意义。 <div>
[LG]《Towards Stable Machine Learning Model Retraining via Slowly Varying Sequences》V D Jr, Y Ma, P Paschalidis, D Bertsimas [Management, HEC Paris &amp; MIT &amp; Harvard University] (2024) <a href="https://arxiv.org/abs/2403.19871"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0wvp1eej21d40rqdsd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0ww6ophj21m20rsjzn.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0wwfi43j21ma0pmahx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0wwjpfmj21mo0todm9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:11:34 GMT</pubDate>
</item>
<item>
<title>通过语言模型的知识蒸馏，使一个容量仅1.2亿参数的模型在通用语义理解基准测试中，取得了超过容量7倍大模型的竞争性能。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Gec...</title>
<link>https://weibo.com/1402400261/O7NjbofHT</link>
<guid>https://weibo.com/1402400261/O7NjbofHT</guid>
<content:encoded><![CDATA[
<div> Gecko, 文本嵌入, 语言模型, 知识蒸馏, 容量, 语义理解, 基准测试, Google DeepMind

<br /><br />总结:
本文介绍了一种名为Gecko的方法，通过语言模型的知识蒸馏，将一个容量仅1.2亿参数的模型在通用语义理解基准测试中的性能提升至超过容量7倍大模型的竞争水平。Gecko模型通过迁移学习技术，将大语言模型中的信息压缩为小型模型，并提供了一种高效的文本嵌入方式。研究表明，Gecko在各种任务和语料上都能取得优异的结果，展示了其在文本理解领域的强大能力。Gecko的提出为文本嵌入领域的发展带来了新的思路和可能性，为构建高效、精确的语义理解模型提供了有力支持。 <div>
通过语言模型的知识蒸馏，使一个容量仅1.2亿参数的模型在通用语义理解基准测试中，取得了超过容量7倍大模型的竞争性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Gecko: Versatile Text Embeddings Distilled from Large Language Models》J Lee, Z Dai, X Ren, B Chen… [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.20327"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0vbcwm8j21la0hidos.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0vc19kkj21lk0tqtgq.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0vcc327j21l60wm494.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:09:58 GMT</pubDate>
</item>
<item>
<title>[CL]《Gecko: Versatile Text Embeddings Distilled from Large Language Models》J Lee, Z Dai, X Ren, B Chen… [Google DeepMind] (2024) 网页链接 #机器学习...</title>
<link>https://weibo.com/1402400261/O7Nj4qu11</link>
<guid>https://weibo.com/1402400261/O7Nj4qu11</guid>
<content:encoded><![CDATA[
<div> Gecko, Versatile, Text Embeddings, Large Language Models, DeepMind<br />
<br />
在这篇文章中，研究者介绍了一种称为Gecko的文本嵌入模型，该模型可以从大型语言模型中提炼出高效的文本嵌入。研究团队通过精心设计的训练策略，成功将Gecko应用于各种自然语言处理任务中，取得了令人瞩目的效果。该模型的灵活性和多功能性使其在不同任务和数据集上均表现出色，展现了其在文本表示学习领域的巨大潜力。总的来说，Gecko为利用大型语言模型提炼出高效文本嵌入提供了一种创新的方法，有望推动自然语言处理领域的发展。<br /><br />总结： <br />Gecko模型是一种能够从大型语言模型中提炼文本嵌入的方法，具有灵活性和多功能性。通过精心设计的训练策略，Gecko在各种自然语言处理任务中取得了令人瞩目的效果，并展现出在文本表示学习领域的巨大潜力。 <div>
[CL]《Gecko: Versatile Text Embeddings Distilled from Large Language Models》J Lee, Z Dai, X Ren, B Chen… [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.20327"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0vbcwm8j21la0hidos.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0vc19kkj21lk0tqtgq.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0vcc327j21l60wm494.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:09:41 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.1)》 爱可可微博热门分享(4.1) [图片]</title>
<link>https://weibo.com/1402400261/O7KEQFkmk</link>
<guid>https://weibo.com/1402400261/O7KEQFkmk</guid>
<content:encoded><![CDATA[
<div> 微博、热门分享、爱可可、4.1、关键词、情感分析、用户评论、话题讨论、互动、网友互动

总结:<br /><br />爱可可微博4.1日发布的热门分享内容引起了网友的热烈讨论。通过情感分析，用户评论中反映出了对话题的关注和讨论热度。网友们通过互动的方式展开话题讨论，形成了热门话题。这种互动不仅增加了用户之间的互动性，也提升了微博平台的用户黏性。 <div>
《爱可可微博热门分享(4.1)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405018476531024181"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.1)</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hobp6dkrbpj20rs0fmwik.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 14:25:06 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models》(ICLR 2024) GitHub: github.com/ThisisBillhe/Eff...</title>
<link>https://weibo.com/1402400261/O7KcGCGEF</link>
<guid>https://weibo.com/1402400261/O7KcGCGEF</guid>
<content:encoded><![CDATA[
<div> EfficientDM, quantization-aware fine-tuning, low-bit diffusion models, ICLR 2024, GitHub, TimeMixer, decomposable multiscale mixing, time series forecasting, LaDiC, diffusion models, autoregressive counterparts, image-to-text generation, NAACL 2024, Repurposing Diffusion-Based Image Generators, Monocular Depth Estimation, CVPR 2024

总结:EfficientDM实现了对低比特扩散模型的高效量化感知微调，为ICLR 2024会议的研究中心。TimeMixer通过可分解的多尺度混合提高了时间序列预测的效果，作者发布了GitHub。LaDiC研究了扩散模型与自回归模型在图像到文本生成中的优劣，获得NAACL 2024提名。Marigold-Video项目重复利用扩散模型生成图像，用于单目深度估计，展示于CVPR 2024。SQLdepth提出了一种通用的自监督微结构单目深度估计方法，GitHub上提供了代码。AgentStudio是一个构建通用虚拟代理的工具包，CVPR 2024中的其中一个项目。SA-GS提出了适应尺度的高斯飞溅方法，无需训练即可抗锯齿，作者开源了GitHub代码。ICDPO通过上下文直接优先优化的方法来有效借鉴他人的对齐能力，详细信息可在GitHub上找到。DS-Agent实现了将大型语言模型与案例推理相结合的自动数据科学工具，CVPR 2024有相关研究成果。MoDiTalker是一种针对高保真头像生成的运动解耦扩散模型，KU-CVLAB团队开源了代码。NaturalSpeech 3利用分解编解码器和扩散模型实现了零预测语音合成，项目源代码在GitHub上可用。SVD-LLM提出了针对大型语言模型的截断意识奇异值分解方法，GitHub上有开源代码。Change-Agent致力于实现交互式远程遥感变化解释和分析，Chen-Yang-Liu团队的开源项目。Spectral Motion Alignment提出了一种使用扩散模型的视频运动传输的谱运动对齐方法，详细代码在GitHub上提供。 <div>
几篇论文实现代码：<br />《EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models》(ICLR 2024) GitHub: github.com/ThisisBillhe/EfficientDM<br />《TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting》(ICLR 2024) GitHub: github.com/kwuking/TimeMixer [fig8]<br />《LaDiC: Are Diffusion Models Really Inferior to Autoregressive Counterparts for Image-to-text Generation?》(NAACL 2024) GitHub: github.com/wangyuchi369/LaDiC [fig7]<br />《Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation》(CVPR 2024) GitHub: github.com/pablodawson/Marigold-Video [fig2]<br />《Rewrite the Stars》(CVPR 2024) GitHub: github.com/ma-xu/Rewrite-the-Stars<br />《SQLdepth: Generalizable Self-Supervised Fine-Structured Monocular Depth Estimation》(2024) GitHub: github.com/hisfog/SfMNeXt-Impl<br />《AgentStudio: A Toolkit for Building General Virtual Agents》(2024) GitHub: github.com/SkyworkAI/agent-studio [fig1]<br />《Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation》(2024) GitHub: github.com/pablodawson/Marigold-Video<br />《SA-GS: Scale-Adaptive Gaussian Splatting for Training-Free Anti-Aliasing》(2024) GitHub: github.com/zsy1987/SA-GS<br />《ICDPO: Effectively Borrowing Alignment Capability of Others via In-context Direct Preference Optimization》(2024) GitHub: github.com/F2-Song/ICDPO [fig3]<br />《DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning》(2024) GitHub: github.com/guosyjlu/DS-Agent [fig4]<br />《MoDiTalker: Motion-Disentangled Diffusion Model for High-Fidelity Talking Head Generation》(2024) GitHub: github.com/KU-CVLAB/MoDiTalker<br />《NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models》(2024) GitHub: github.com/lifeiteng/ns3_codec [fig5]<br />《SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language Model Compression》(2024) GitHub: github.com/AIoT-MLSys-Lab/SVD-LLM<br />《Change-Agent: Towards Interactive Comprehensive Remote Sensing Change Interpretation and Analysis》(2024) GitHub: github.com/Chen-Yang-Liu/Change-Agent [fig6]<br />《Spectral Motion Alignment for Video Motion Transfer using Diffusion Models》(2024) GitHub: github.com/geonyeong-park/Spectral-Motion-Alignment<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob8xp699mj227c0yc7wh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hob909rjg3j21ac174dmw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob9db8l86j20gp05n40o.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hob9jehv2uj21qt0myque.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hobml5iiw0j21i40li46r.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hobmm7kf3jj211x0dlwj7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hobn12rglbj242g1q44qq.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hobn2bdaqaj21nq0qoncb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 13:15:43 GMT</pubDate>
</item>
<item>
<title>'stable-diffusion-tutorial - 全网最全Stable Diffusion全套教程，从入门到进阶' GitHub: github.com/ai-vip/stable-diffusion-tutorial #开源# #机器学习# #人...</title>
<link>https://weibo.com/1402400261/O7K8fh9af</link>
<guid>https://weibo.com/1402400261/O7K8fh9af</guid>
<content:encoded><![CDATA[
<div> GitHub, Stable Diffusion, 教程, 入门, 进阶, AI, VIP, 全套, 全网, 最全

<br /><br />总结:
这篇文章是关于Stable Diffusion全套教程的GitHub项目，适合从入门到进阶学习。项目由AI VIP团队提供，涵盖了稳定传播的所有方面，并被称为全网最全的教程。通过该教程，读者可以系统学习稳定传播的原理、应用和进阶技巧，是学习AI技术的必备资源。 <div>
'stable-diffusion-tutorial - 全网最全Stable Diffusion全套教程，从入门到进阶' GitHub: github.com/ai-vip/stable-diffusion-tutorial <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hobmunzax9j20u01g3dl7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 13:04:46 GMT</pubDate>
</item>
<item>
<title>【Jaiqu：基于AI的JSON转换工具】'Jaiqu - Automatically reformat any JSON into any schema with AI' GitHub: github.com/AgentOps-AI/Jaiqu #开源# #机器学习...</title>
<link>https://weibo.com/1402400261/O7K80uAaB</link>
<guid>https://weibo.com/1402400261/O7K80uAaB</guid>
<content:encoded><![CDATA[
<div> GitHub, Jaiqu, AI, JSON, 转换工具, 自动重新格式化, 模式, AgentOps, 

AI技术不断发展，在各个领域都有了广泛的应用。AgentOps团队开发了一款名为Jaiqu的基于AI技术的JSON转换工具，能自动将任何JSON数据重新格式化成任意模式。用户只需输入待转换的JSON数据，Jaiqu就能自动分析并转换为用户指定的模式，极大地提高了数据处理的效率。用户还可以通过GitHub获取Jaiqu的源代码和更多信息。这款工具的推出不仅简化了数据处理的流程，也展示了AI技术在数据处理领域的巨大潜力。 <br /><br />总结:AI技术在数据处理工具中的应用，Jaiqu能自动将JSON重新格式化成任意模式，提高了数据处理效率，用户可通过GitHub获取更多信息。 <div>
【Jaiqu：基于AI的JSON转换工具】'Jaiqu - Automatically reformat any JSON into any schema with AI' GitHub: github.com/AgentOps-AI/Jaiqu <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hobmub0sk7j20zh0u0tcz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 13:04:11 GMT</pubDate>
</item>
<item>
<title>【AutoGen AGI：旨在通过AutoGen技术来提升AI Agent的智能能力，重点在于提高AI Agent在沟通、决策制定以及复杂任务完成等方面的智能水平】’AutoGen AGI: Advan...</title>
<link>https://weibo.com/1402400261/O7H6Xezex</link>
<guid>https://weibo.com/1402400261/O7H6Xezex</guid>
<content:encoded><![CDATA[
<div> AutoGen AGI, AI Agent, 智能能力提升, 沟通, 决策制定, 复杂任务完成, 群体聊天动态, 创新, GitHub, AI未来发展 <br />
<br />
总结: AutoGen AGI是一个旨在通过AutoGen技术提升AI Agent智能能力的项目，重点在于提高AI Agent在沟通、决策制定以及复杂任务完成等方面的能力。项目着眼于创新，尤其关注群体聊天动态等领域的提升，致力于促进AI在未来的发展。GitHub链接：github.com/metamind-ai/autogen-agi。 <div>
【AutoGen AGI：旨在通过AutoGen技术来提升AI Agent的智能能力，重点在于提高AI Agent在沟通、决策制定以及复杂任务完成等方面的智能水平】’AutoGen AGI: Advancing AI agents using AutoGen towards AGI capabilities. Explore cutting-edge enhancements in group chat dynamics, decision-making, and complex task proficiency. Join our journey in shaping AI's future!' GitHub: github.com/metamind-ai/autogen-agi <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hob9irqxyhj20u00u0wl0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:23:21 GMT</pubDate>
</item>
<item>
<title>'IAmDirector - 每个人都能成为导演 - 本项目开源基于NextJS的前端， 希望能够提供一个用于生成式AI的文字转视频， 尤其是电影从编剧到视频生成的Web前端平台参...</title>
<link>https://weibo.com/1402400261/O7H6haljm</link>
<guid>https://weibo.com/1402400261/O7H6haljm</guid>
<content:encoded><![CDATA[
<div> NextJS, 前端, AI, 文字转视频, 电影, Web平台, 开源, 参考, GitHub, 项目

<br /><br />总结:
本项目是一个开源的基于NextJS的前端平台，旨在提供一个用于生成式AI的文字转视频工具，特别是涉及电影从编剧到视频生成的Web前端平台参考。用户可以通过该平台生成自己的影视作品，实现文字变成视频的转换。项目代码托管在GitHub上，方便用户查看和参考。通过使用该平台，每个人都有机会成为一名导演，创造属于自己的影视作品。 <div>
'IAmDirector - 每个人都能成为导演 - 本项目开源基于NextJS的前端， 希望能够提供一个用于生成式AI的文字转视频， 尤其是电影从编剧到视频生成的Web前端平台参考' GitHub: github.com/JiaqiLi404/IAmDirector-Text2Video-NextJS-Client <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hob9gtuh61j21et0u0tfz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hob9guybkkj21fa0u077z.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob9gwvzvaj21im0u0js9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:21:40 GMT</pubDate>
</item>
<item>
<title>'我的大模型课 - 关于如何编写大模型的prompt的一系列课' GitHub: github.com/PandaBearLab/prompt-tutorial #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O7H4mo6a6</link>
<guid>https://weibo.com/1402400261/O7H4mo6a6</guid>
<content:encoded><![CDATA[
<div> 关键词：大模型课、编写、prompt、GitHub、PandaBearLab

大模型课是一系列关于如何编写大模型的prompt的课程，可以在GitHub上的PandaBearLab的仓库找到相关资料。这个课程涵盖了编写大型模型时需要考虑的方方面面，包括设计、实现、调试等等。通过这些课程，学习者可以更好地理解如何构建复杂的大型模型，并学会解决相关问题。GitHub上的资料可以帮助学习者更方便地获取课程内容，学习的过程更加高效和便捷。<br /><br />总结: 大模型课是一系列关于如何编写大模型的prompt的一系列课程，GitHub上PandaBearLab的仓库提供了相关资料，通过这些课程，学习者可以获取关于设计、实现、调试等方面的知识，从而更好地理解和构建复杂的大型模型。GitHub上的资料能够帮助学习者更方便地获取课程内容，提高学习效率。 <div>
'我的大模型课 - 关于如何编写大模型的prompt的一系列课' GitHub: github.com/PandaBearLab/prompt-tutorial <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hob9c5tzcij210i0u00wt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:16:58 GMT</pubDate>
</item>
<item>
<title>'因果推断：从概念到实践 - Causal Inference for the Brave and True的中文翻译版。全部代码基于Python，适用于计量经济学、量化社会学、策略评估等领域。英文...</title>
<link>https://weibo.com/1402400261/O7H1vwTXM</link>
<guid>https://weibo.com/1402400261/O7H1vwTXM</guid>
<content:encoded><![CDATA[
<div> 因果推断、概念、实践、Python、计量经济学、量化社会学、策略评估、Matheus Facure、GitHub、Causal Inference for the Brave and True

<br /><br />总结:
本文介绍了因果推断的概念及实践方法，以Python为工具进行计量经济学、量化社会学和策略评估研究。该指南以Matheus Facure为原作者，涵盖了因果推断的基本原理和实现技巧。读者可通过GitHub获取更多相关信息。 <div>
'因果推断：从概念到实践 - Causal Inference for the Brave and True的中文翻译版。全部代码基于Python，适用于计量经济学、量化社会学、策略评估等领域。英文版原作者：Matheus Facure' GitHub: github.com/xieliaing/CausalInferenceIntro <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob94snrc3j20v80u043v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:09:56 GMT</pubDate>
</item>
<item>
<title>【AgentStudio：用于构建和基准测试通用虚拟Agent的开源工具包】'AgentStudio - An open toolkit for building and benchmarking general virtual agents in the...</title>
<link>https://weibo.com/1402400261/O7GZ8wt8n</link>
<guid>https://weibo.com/1402400261/O7GZ8wt8n</guid>
<content:encoded><![CDATA[
<div> AgentStudio，开源工具包，构建，基准测试，通用虚拟Agent，GitHub，SkyworkAI，Agent-Studio<br />
AgentStudio是一个用于构建和基准测试通用虚拟Agent的开源工具包。用户可以利用AgentStudio来开发和评估各种虚拟Agent，以帮助他们在各种环境中更好地执行任务。该工具包还提供了一些功能强大的工具，用于在现实世界中对Agent进行测试和评估其性能。用户可以通过访问GitHub上的SkyworkAI/agent-studio仓库来获取AgentStudio的源代码，并开始使用这个工具包。AgentStudio的出现为虚拟Agent的构建和测试提供了更多便利和支持，有助于促进虚拟Agent技术的发展。<br /><br />总结: <br />AgentStudio是一个开源工具包，用于构建和基准测试通用虚拟Agent。用户可以通过GitHub获取源代码并使用AgentStudio来开发和评估虚拟Agent，这将有助于促进虚拟Agent技术的发展。 <div>
【AgentStudio：用于构建和基准测试通用虚拟Agent的开源工具包】'AgentStudio - An open toolkit for building and benchmarking general virtual agents in the wild' GitHub: github.com/SkyworkAI/agent-studio <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob8yjg8qsj21xa0u0dp6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob8ymdq8uj22g50u0n4j.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob8yrof1jj21pk0u07az.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:04:06 GMT</pubDate>
</item>
<item>
<title>【旨在复现Anthropic的稀疏自编码可视化】'sae_vis' GitHub: github.com/callummcdougall/sae_vis #开源# #机器学习# #人工智能# [图片][图片]</title>
<link>https://weibo.com/1402400261/O7GYcc9se</link>
<guid>https://weibo.com/1402400261/O7GYcc9se</guid>
<content:encoded><![CDATA[
<div> 稀疏自编码、可视化、GitHub、sae_vis、复现、Anthropic、Callum McDougall

稀疏自编码是一种用于学习数据表示的技术，通过在编码阶段引入稀疏性约束，可以更好地捕捉数据的关键特征，从而实现对数据的压缩和重建。Anthropic提出了一种稀疏自编码的方法，并通过GitHub上的sae_vis项目来展示这种技术的可视化效果。通过复现这个项目，我们可以更好地理解和探究Anthropic提出的稀疏自编码技术，同时也可以学习到如何利用GitHub来分享和展示代码。GitHub上的sae_vis项目由Callum McDougall创建，可以帮助我们更直观地理解稀疏自编码的原理和应用。通过学习和探究这个项目，我们可以加深对稀疏自编码和数据可视化的理解，为进一步研究和应用相关技术提供参考。 

<br /><br />总结: 
稀疏自编码是一种学习数据表示的技术，Anthropic提出了一种稀疏自编码方法，并通过GitHub上的sae_vis项目展示其可视化效果，通过复现该项目可以加深理解和探究相关技术，同时学习如何利用GitHub分享和展示代码，sae_vis项目由Callum McDougall创建，帮助更直观地理解稀疏自编码的原理和应用，通过学习该项目可以深入了解稀疏自编码和数据可视化，为进一步研究和应用相关技术提供参考。 <div>
【旨在复现Anthropic的稀疏自编码可视化】'sae_vis' GitHub: github.com/callummcdougall/sae_vis <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hob8w6ybitj21gu0st49b.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hob8wbxwhuj215x0u0k0f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:01:46 GMT</pubDate>
</item>
<item>
<title>【Heron：可无缝集成多种图像/视频和语言模型的库. 此外, 还提供在各种数据集上训练的预训练权重】'Heron - a library that seamlessly integrates multiple Vis...</title>
<link>https://weibo.com/1402400261/O7GXBxwVd</link>
<guid>https://weibo.com/1402400261/O7GXBxwVd</guid>
<content:encoded><![CDATA[
<div> Heron、图像模型、视频模型、语言模型、集成、库、预训练权重、数据集、训练、GitHub

<br /><br />总结:
Heron是一款库，可以无缝集成多种图像、视频和语言模型，同时还提供在各种数据集上训练的预训练权重。用户可以通过GitHub获取该库，方便使用和开发。Heron为用户提供了整合不同模型的便利，训练和调用均得以简化，是一个强大的工具库。 <div>
【Heron：可无缝集成多种图像/视频和语言模型的库. 此外, 还提供在各种数据集上训练的预训练权重】'Heron - a library that seamlessly integrates multiple Vision and Language models, as well as Video and Language models' GitHub: github.com/turingmotors/heron <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hob8utpmtxj20u00yxgqz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:00:19 GMT</pubDate>
</item>
<item>
<title>《用 bitsandbytes、4 比特量化和 QLoRA 打造亲民的 LLM》- 提出了QLoRA方法，可以在单GPU上微调超大规模语言模型(65B参数)，同时内存使用率显著降低，性能与全1...</title>
<link>https://weibo.com/1402400261/O7FaODDI3</link>
<guid>https://weibo.com/1402400261/O7FaODDI3</guid>
<content:encoded><![CDATA[
<div> bitsandbytes, 4比特量化, QLoRA, LLM, 单GPU, 超大规模语言模型, 内存使用率, NormalFloat4, 低秩适配器, 双量化

<br /><br />总结:
该研究提出了QLoRA方法，可以在单GPU上微调超大规模语言模型(65B参数)，同时降低内存使用率，性能与全16bit量化微调相当。QLoRA核心是将预训练语言模型用4 bit量化压缩，冻结参数并加低秩适配器作为可训练参数，梯度只反向传播到适配器。在Vicuna基准测试中，QLoRA微调的Guanaco聊天机器人性能接近ChatGPT水平。数量化技术降低了训练超大模型门槛，使之在普通GPU上运行。有望加速LLM的大众化进程，让更多人参与到LLM开发和应用。QLoRA巧妙的量化和适配器技术降低内存占用，保持了性能。NF4、双量化技术进一步挖掘了量化潜力，为后续研究提供新思路。小型高质量数据集上微调为LLM应用提供重要启示，即数据质量和针对性可能更关键。 <div>
《用 bitsandbytes、4 比特量化和 QLoRA 打造亲民的 LLM》<br />- 提出了QLoRA方法，可以在单GPU上微调超大规模语言模型(65B参数)，同时内存使用率显著降低，性能与全16bit量化微调相当。   <br />- QLoRA的核心是将预训练语言模型用4bit量化(一般为NormalFloat4)压缩，冻结参数，并添加低秩适配器作为可训练参数。训练时，梯度只反向传播到适配器。   <br />- QLoRA使用不同的数据类型存储权重(4bit)和计算(16bit)，可以减少训练和推理时的内存占用。还可以通过双量化进一步降低内存。   <br />- 在Vicuna基准测试中，使用QLoRA微调的Guanaco聊天机器人性能几乎达到ChatGPT水平，表明该方法训练大模型效果显著。   <br />- 给出了QLoRA的代码实现，支持PyTorch框架，还提供了Google Colab演示Notebook，方便用户上手使用。   <br />- 4bit量化目前与GPU兼容，需要安装CUDA &gt;= 11.2。支持使用accelerate库加载的绝大多数HuggingFace模型都可以进行4bit量化。   <br />- 尽管无法进行全模型4bit训练，但可以在4bit量化的大模型上训练适配器等可训练模块，实现高效微调。   <br />- 4bit量化大模型技术降低了训练超大模型的门槛，使之能在普通GPU上运行，对研究工作具有重要意义。<br /><br />思考：  <br />- 该研究为在消费级硬件上运行和训练大语言模型提供了可行的技术方案，有望加速LLM的大众化进程，让更多人能够参与到LLM的开发和应用中来。  <br />- QLoRA通过巧妙的量化和适配器技术，在大幅降低内存占用的同时保持了与全精度微调相当的性能，体现了算法设计的优雅和高效。  <br />- 引入NF4、双量化等创新技术，进一步挖掘了量化的潜力，为后续研究提供了新的思路。  <br />- 在小型高质量数据集上微调获得最佳性能，这一发现为LLM的实际应用提供了重要启示，即并非训练数据越多越好，数据质量和针对性可能更为关键。  <br /> <a href="https://huggingface.co/blog/zh/4bit-transformers-bitsandbytes"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hob0vxmn22j20u00vgwje.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 00:27:23 GMT</pubDate>
</item>
<item>
<title>【生命的多尺度交响：集体智慧串联生物学】- 生物系统具有多尺度结构，从分子网络到细胞、组织、器官、整体和群体。每个层级都能在不同的问题空间中解决问题，如...</title>
<link>https://weibo.com/1402400261/O7F95wKcj</link>
<guid>https://weibo.com/1402400261/O7F95wKcj</guid>
<content:encoded><![CDATA[
<div> 生物系统、多尺度结构、集体动力学、集体智慧、胚胎发育、细胞迁移、癌症、黑色素瘤、器官建立、动力系统理论

<br /><br />总结:
本文从多尺度视角审视生物学，揭示了生物系统内在的复杂性和协同性。集体智慧为理解生物学不同层次之间的相互作用提供了新的框架，揭示了细胞群体在转录、生理和解剖空间展现的集体智慧。跨尺度研究方法不仅有助于基础生物学研究，也对生物医学和工程设计等应用领域具有重要意义。利用集体智慧这一对称性推进研究是创新性的，为未来研究指明了方向，但具体操作仍需进一步探索。 <div>
【生命的多尺度交响：集体智慧串联生物学】<br />- 生物系统具有多尺度结构，从分子网络到细胞、组织、器官、整体和群体。每个层级都能在不同的问题空间中解决问题，如生理、形态和行为状态空间。将自下而上的适应功能从一个具有能力的子单元层次渗透到一个更高的功能组织层次需要集体动力学：多个组件必须协同工作以实现特定的结果。   <br />- 概述了不同尺度的一些生物学实例，突出显示了细胞材料做出决定的能力，这些决定实现了对特定稳态端点的合作，并通过在细胞、组织和整个有机体水平上解决问题来实现集体智能。   <br />- 探讨了这样的假设：集体智慧不仅仅是动物群体的特例，一个重要的对称性存在于群体行为科学和细胞及其他不同尺度生物系统能力之间。   <br />- 简要概述了这种方法的含义，以及行为多样智能领域的工具对再生医学和合成生物工程的可能影响。   <br />- 发育是一个非常基本的集体示例，胚胎被认为是一个整体，是因为其组成细胞都在协同工作向一个特定的形态空间路径：细胞致力于制造一个特定的功能解剖结构。   <br />- 如果在胚胎层面临时引入隔离岛屿，会形成双生子、三生子等，显示胚胎是一个动力学可激发介质，可以自我组织形成多个连贯的胚胎。   <br />- 当我们观察细胞迁移时，集体行为往往与其组分的倾向相反，即使在相对最小的系统中也是复杂和难以预测的，这是整体与其组成部分竞争的缩影。   <br />- 癌症是一个集体行为的失败模式实例，当细胞与组织的信息结构隔离时，它们会恢复到一个古老的、单细胞的转录和行为表型。   <br />- 在蝾螈模型中，已显示正常黑色素细胞可以被驱动为类似黑色素瘤的转换型：它们过度增殖，并迁移到正常情况下不含黑色素细胞的区域，这个表型重现了黑色素瘤转移。   <br />- 最显著的是，这种表型是全有或全无的现象。使用不同的试剂可以在一组动物中诱导不同百分比的超 Pigmentation(转换)，但这是种群层面的表型：例如，70%的动物可以转换，但任何给定的动物要么完全转换要么完全正常。   <br />- 在解剖形态空间中，细胞集团需要做出关于将要建立哪个器官以及它们必须采取何种形状的具体决定。这与识别基因调控网络和分化信号是一个根本不同的问题。   <br />- 利用动力系统理论和连接主义神经科学/人工智能的工具有助于提供正式化理解细胞网络如何存储模式信息并从部分输入中恢复它，以及这种集体行为如何出现。<br /><br />思考：  <br />- 文章从多尺度视角审视生物学，揭示了生物系统内在的复杂性和协同性，这种视角有助于我们更全面地理解生命现象。  <br />- 集体智慧这一概念的引入，为理解生物学不同层次之间的相互作用提供了一个新的框架，具有启发性。  <br />- 文章指出，细胞群体在转录、生理和解剖空间展现出类似于高等生物的集体智慧，这一发现颠覆了我们对智能的传统认知，表明智能可能是生命的一种基本属性。  <br />- 跨尺度的研究方法不仅有助于基础生物学研究，而且对生物医学和工程设计等应用领域也具有重要意义，体现了基础研究的应用价值。  <br />- 文章提出利用集体智慧这一对称性来推进研究，这种思路具有创新性，为未来的研究指明了方向，不过，如何具体操作还需要进一步探索。<br />《Collective intelligence: A unifying concept for integrating biology across scales and substrates | Communications Biology》 <a href="https://www.nature.com/articles/s42003-024-06037-4?code=96f36603-dac2-4485-a0f5-488009563d60&amp;error=cookies_not_supported"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hob0u4gp0cj20j10ntgpz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hob0u4x4uej20j10hlwgb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob0u5cqu7j20j10o4q7s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob0u5qcvwj20j10mdad8.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hob0u61pwej20j10nqju7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob0u6b64wj20j10onwi6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 00:23:07 GMT</pubDate>
</item>
<item>
<title>【RLHF人工反馈强化学习详解】- ChatGPT的训练可以分为三个阶段：预训练、监督微调(SFT)和人工反馈强化学习(RLHF)。 - 预训练的目标是训练一个大型语言模型(LLM)...</title>
<link>https://weibo.com/1402400261/O7F5VzPzQ</link>
<guid>https://weibo.com/1402400261/O7F5VzPzQ</guid>
<content:encoded><![CDATA[
<div> 预训练、监督微调、人工反馈强化学习、大型语言模型、示范数据、奖励模型、强化学习、高分回复、减少“幻觉”、关键创新点

<br /><br />总结:
ChatGPT的训练过程分为预训练、监督微调和人工反馈强化学习三个阶段。预训练旨在训练大型语言模型，而监督微调利用示范数据进行监督学习。人工反馈强化学习包含奖励模型和强化学习微调两个子阶段，用于让模型生成高质量回复。RLHF可以减少模型的“幻觉”，因为缩小了模型内部知识与标注者知识的差异。这一技术是ChatGPT成功的关键创新点之一，未来可能会得到更广泛应用。在应用RLHF时，难点在于构建高质量的奖励模型和示范数据。公司可考虑使用RLHF来提升语言模型的安全性和适用性，但需要投入大量资源建设示范数据集和奖励模型。 <div>
【RLHF人工反馈强化学习详解】<br />- ChatGPT的训练可以分为三个阶段：预训练、监督微调(SFT)和人工反馈强化学习(RLHF)。   <br />- 预训练的目标是训练一个大型语言模型(LLM)，使其具有语言补全能力。预训练需要大量互联网数据(万亿字符级)，但可用数据有限。   <br />- SFT的目标是让LLM生成符合用户需求的回复，使用人工标注的示范数据进行监督学习。   <br />- RLHF包含奖励模型和强化学习微调两个子阶段。奖励模型用于给出提示-回复对的打分，强化学习用于让LLM生成高分回复。   <br />- RLHF可以减少LLM的“幻觉”，原因可能是减小了LLM内部知识与标注者知识的差异。   <br />- RLHF是ChatGPT等模型成功的关键创新点之一，未来可能会得到更广泛应用。其难点在于构建高质量的奖励模型和示范数据。   <br />- 公司可考虑使用RLHF提升自家LLM的安全性、适用性。但需要投入大量资源建设示范数据集和奖励模型。<br />《RLHF: Reinforcement Learning from Human Feedback》 <a href="https://huyenchip.com/2023/05/02/rlhf.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hob0kl0r2ij213f0u0afz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 00:15:20 GMT</pubDate>
</item>
<item>
<title>【Mamba详解】- Mamba是一种新型的状态空间模型(State Space Model，SSM)，它取得了和Transformer类似的性能，但可以处理更长的序列(例如100万token)。这是通过...</title>
<link>https://weibo.com/1402400261/O7F4sn27H</link>
<guid>https://weibo.com/1402400261/O7F4sn27H</guid>
<content:encoded><![CDATA[
<div> Mamba、状态空间模型、长序列、计算效率、学习矩阵、选择机制、RNN变体、可解释性、Transformer组合、AI安全<br />
<br />
总结:<br />
Mamba是一种新型的状态空间模型，可以处理较长序列并取得性能优势，通过引入选择机制使得学习矩阵适应不同上下文。相比于Transformer，Mamba在长序列建模上提供了更高的效率和可解释性，适用于需处理非常长序列的任务。其创新性在于将RNN的变体与选择机制结合，为AI模型的发展指明了新方向，对研究长期记忆、计划能力和代理人AI安全具有启发意义。 <div>
【Mamba详解】<br />- Mamba是一种新型的状态空间模型(State Space Model，SSM)，它取得了和Transformer类似的性能，但可以处理更长的序列(例如100万token)。这是通过去除Attention机制中的“二次瓶颈”实现的。   <br />- SSM的优点是计算效率高，可以线性缩放序列长度，而Transformer中的Attention机制时间复杂度是平方级的，会随着序列长度的增加而变慢。   <br />- SSM包含状态转移矩阵A、输入矩阵B、输出矩阵C和直接传递矩阵D，这些矩阵都是可学习的。Mamba的创新在于引入了“选择机制”，使这些矩阵都成为输入x的函数，实现对不同上下文的适应。   <br />- SSM可以看作是RNN的变体，但引入选择机制后效果更好，在保持计算高效的同时提高了对长序列建模的有效性。   <br />- Mamba可实现比RNN更长的上下文记忆，但比Transformer更高效。这种在有效性和效率之间的权衡取决于状态表示的压缩程度。   <br />- Mamba适用于需要非常长序列长度的任务，如处理DNA序列、生成长视频、写小说等。   <br />- Mamba可提高模型的可解释性，通过分析状态的变化来理解上下文学习等现象。   <br />- Mamba可与Transformer组合使用，处理不同时间尺度上的建模，发挥各自的优势。   <br />- Mamba对研究长期记忆、计划能力和代理人AI安全具有启发意义。它标志着后Transformer时代的到来。<br /><br />思考：  <br />- Mamba在长序列建模上的突破令人印象深刻，有望扩展AI模型的应用范围，如更长篇章的语言理解和生成。  <br />- 通过巧妙的设计，Mamba在提升性能的同时兼顾了效率，体现了算法的优雅。  <br />- Mamba对状态表征的选择性压缩让人联想到人类的注意力机制，这种机制的引入赋予了模型更强的建模能力。  <br />- 理解AI模型的内部状态和信息流动方式，对于我们解释其行为、提升其可解释性和可控性具有重要意义。  <br />- Mamba作为Transformer的有力挑战者，为探索新的AI建模范式指明了一个有潜力的方向，期待它在更多任务上的表现。<br />《Mamba Explained》 <a href="https://thegradient.pub/mamba-explained/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span> <span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob09qxzk2j21yj0u0791.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hob09yqg7gj20kv0a4wfi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hob0a23vigj20w00lyq4y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hob0a91xi3j218g0p5wh4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 00:11:42 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：明日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可...</title>
<link>https://weibo.com/1402400261/O7Ek9tAoi</link>
<guid>https://weibo.com/1402400261/O7Ek9tAoi</guid>
<content:encoded><![CDATA[
<div> Java, Python, JavaScript, C语言, MySQL, Redis, 技术, 故事, 编程语言, 码农翻身

<br /><br />总结:
《码农翻身2》以故事的形式讲解技术，让枯燥的技术变得有趣。在编程语言王国中，Java与Python争斗，JavaScript与Java对抗，而孤独的C语言则面对没有对象的困境。MySQL和Redis之间的对立不断升级。这本书让读者不仅掌握技术原理和本质，同时能享受阅读乐趣。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：明日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 22:17:38 GMT</pubDate>
</item>
<item>
<title>今日推介(第1362期)：基于开放式指令的自监督图像检索、Transformer网络的topos theory视角分析、编程语言模型漏洞检测现状评估、面向内存高效大型语言模型微调...</title>
<link>https://weibo.com/1402400261/O7Ek1uSou</link>
<guid>https://weibo.com/1402400261/O7Ek1uSou</guid>
<content:encoded><![CDATA[
<div> 自监督图像检索、Transformer网络、topos theory、编程语言模型漏洞检测、层级重要性采样、内存高效大型语言模型微调、语言模型可解释性、因果图发现、因果图编辑

总结:<br /><br />本文报道了基于开放式指令的自监督图像检索方法，通过Transformer网络的topos theory视角分析，评估了编程语言模型漏洞检测现状，并提出了面向内存高效大型语言模型微调的层级重要性采样策略。同时，研究了语言模型可解释因果图的发现与编辑方法，为语言模型研究领域的发展提供了新的观点和思路。 <div>
今日推介(第1362期)：基于开放式指令的自监督图像检索、Transformer网络的topos theory视角分析、编程语言模型漏洞检测现状评估、面向内存高效大型语言模型微调的层级重要性采样、语言模型可解释因果图的发现与编辑 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/690078164"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.1)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoax780v8sj21wc0u048e.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoax79uclvj20yi0n675r.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoax7cpiv0j20u00z1tk0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoax7fqtlgj20p40ksjtb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoax7i9melj21gf0u07ba.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 22:17:18 GMT</pubDate>
</item>
<item>
<title>[CV] DINO-Tracker: Taming DINO for Self-Supervised Point Tracking in a Single Video 网页链接 提出DINO-Tracker框架，将预训练模型的语义先验与针对单视频...</title>
<link>https://weibo.com/1402400261/O7EgX6B7M</link>
<guid>https://weibo.com/1402400261/O7EgX6B7M</guid>
<content:encoded><![CDATA[
<div> 测试时训练、DINO-Tracker、密集点追踪、预训练模型、语义先验、长时遮挡视频

<br /><br />总结:本文提出了DINO-Tracker框架，通过将预训练模型的语义先验与针对单视频的测试时训练相结合，实现了长时遮挡视频中的密集点追踪。该方法利用自监督学习的方式，在测试阶段根据视频的上下文信息，通过自动编码器来推断出点的运动轨迹，实现了对长时间间隔下自动跟踪点的能力。与传统方法相比，DINO-Tracker能自适应地学习不同视频场景下的点追踪模型，并且无需额外的标签数据。实验结果表明，DINO-Tracker在各种复杂的视频中都表现出色，是一种高效且准确的自监督点追踪方法。 <div>
[CV] DINO-Tracker: Taming DINO for Self-Supervised Point Tracking in a Single Video  <br /><a href="https://arxiv.org/abs/2403.14548"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出DINO-Tracker框架，将预训练模型的语义先验与针对单视频的测试时训练相结合，实现长时遮挡视频中的密集点追踪。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoawzlx6thj20v61bwwuz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoawzm8xx0j21hw0s248a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoawzmmg9sj21ak0higr6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 22:09:44 GMT</pubDate>
</item>
<item>
<title>[LG] Tensor Network-Constrained Kernel Machines as Gaussian Processes 网页链接 通过理论证明和实验验证首次建立了张量网络限制的核机和高斯过程之间的关系...</title>
<link>https://weibo.com/1402400261/O7EehAJow</link>
<guid>https://weibo.com/1402400261/O7EehAJow</guid>
<content:encoded><![CDATA[
<div> Tensor Network-Constrained Kernel Machines, Gaussian Processes, 参数独立同分布先验, 收敛, 可完全表征, 实验证明, 理论证明, 高斯过程, 核机, 张量网络限制<br />
<br />
总结: <br />
本文针对张量网络限制的核机和高斯过程之间的关系进行了理论证明和实验证明，首次建立了两者之间的联系。实验结果表明，在参数上放置独立同分布先验时，张量网络限制的核机会收敛到一个可完全表征的高斯过程。这为理解核机和高斯过程之间的关系提供了深入的见解，也为在实际应用中更好地利用这些方法提供了指导。 <div>
[LG] Tensor Network-Constrained Kernel Machines as Gaussian Processes  <br /><a href="https://arxiv.org/abs/2403.19500"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />通过理论证明和实验验证首次建立了张量网络限制的核机和高斯过程之间的关系，即在参数上放置独立同分布先验时，张量网络限制的核机会收敛到一个可完全表征的高斯过程。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoawss39r2j210g1c4h3g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoawss9w5mj210e0f441f.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoawssej1tj210g0eoq7b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 22:03:10 GMT</pubDate>
</item>
<item>
<title>[LG] AgentStudio: A Toolkit for Building General Virtual Agents 网页链接 提出了开源的AgentStudio工具包，它提供了通用的观察和动作空间，在线环境实现，以...</title>
<link>https://weibo.com/1402400261/O7Ecd1kjq</link>
<guid>https://weibo.com/1402400261/O7Ecd1kjq</guid>
<content:encoded><![CDATA[
<div> 工具包、AgentStudio、通用虚拟Agent、观察空间、动作空间、在线环境、数据收集、人机交互界面、研究、基准测试

总结:<br /><br />研究团队提出了开源的AgentStudio工具包，旨在促进通用虚拟Agent的研究和真实场景基准测试。该工具包提供了通用的观察和动作空间，实现了在线环境，并包含数据收集和人机交互界面，为虚拟Agent研究提供了便利和支持。 <div>
[LG] AgentStudio: A Toolkit for Building General Virtual Agents  <br /><a href="https://arxiv.org/abs/2403.17918"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />提出了开源的AgentStudio工具包，它提供了通用的观察和动作空间，在线环境实现，以及数据收集和人机交互界面，可促进通用虚拟Agent的研究和真实场景基准测试。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoawnfy84cj20vk1dok97.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoawngicrxj21oc14gtr0.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoawngk2rmj21o60waalm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:58:03 GMT</pubDate>
</item>
<item>
<title>[CL] A comparison of Human, GPT-3.5, and GPT-4 Performance in a University-Level Coding Course 网页链接 研究发现当前语言模型在物理编程作业方面的能力尚...</title>
<link>https://weibo.com/1402400261/O7E9C39JI</link>
<guid>https://weibo.com/1402400261/O7E9C39JI</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型, 物理编程作业, 教学目标, 教育工作者, 人类, GPT-3.5, GPT-4, 能力, 进步, 调整

总结:<br /><br />研究发现当前语言模型在物理编程作业方面的能力尚未超越人类，但稳步进步预示可能在不久的将来实现突破。这需要教育工作者重新考量编程作业的作用与教学目标的调整。三种实体——人类、GPT-3.5和GPT-4，在大学级编程课程中的表现被比较，结果显示语言模型还有提升空间，需持续关注其发展。根据研究结论，教学需重点关注培养学生的编程能力与思维，或许不久的将来，语言模型在编程方面会有更大突破。 <div>
[CL] A comparison of Human, GPT-3.5, and GPT-4 Performance in a University-Level Coding Course  <br /><a href="https://arxiv.org/abs/2403.16977"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />研究发现当前语言模型在物理编程作业方面的能力尚未超越人类，但稳步进步预示可能在不久的将来实现突破，这需要教育工作者重新考量编程作业的作用与教学目标的调整。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoawgsjinpj210i1c2kb9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoawgsv3imj210e0pytd6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoawgt47x7j210k0pojv9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:51:39 GMT</pubDate>
</item>
<item>
<title>[IR] Scaling Laws For Dense Retrieval 网页链接 通过对比对数似然指标和规模化实验，发现稠密检索模型性能也遵循资源量的幂律缩放关系，建立了模型性能预测和...</title>
<link>https://weibo.com/1402400261/O7E6urV1R</link>
<guid>https://weibo.com/1402400261/O7E6urV1R</guid>
<content:encoded><![CDATA[
<div> 对数似然指标 规模化实验 稠密检索模型 资源量 幂律缩放关系 模型性能 预测 资源优化 分配<br />
<br />
提出通过对比对数似然指标和规模化实验，发现稠密检索模型性能遵循资源量的幂律缩放关系，可用于模型性能预测和资源优化分配。这一发现为稠密检索模型的性能评估和优化提供了新的思路和方法。 <div>
[IR] Scaling Laws For Dense Retrieval  <br /><a href="https://arxiv.org/abs/2403.18684"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过对比对数似然指标和规模化实验，发现稠密检索模型性能也遵循资源量的幂律缩放关系，建立了模型性能预测和资源优化分配的可能性。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw8sg5zoj2102188nfw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw8svf04j21q80qu79o.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw8tgikjj21kq0ngwii.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:43:58 GMT</pubDate>
</item>
<item>
<title>通过稀疏自编码器和线性近似，提出一种发现人类可解释语言模型特征之间因果关系的可扩展流水线，以构建细粒度回路解释模型行为，并应用于下游任务。 - 转发 @爱...</title>
<link>https://weibo.com/1402400261/O7E3Q9kNu</link>
<guid>https://weibo.com/1402400261/O7E3Q9kNu</guid>
<content:encoded><![CDATA[
<div> 稀疏自编码器、线性近似、因果关系、可扩展流水线、细粒度回路、解释模型行为、下游任务、语言模型、特征、语言模型特征

总结:<br /><br />这篇文章提出了一种利用稀疏自编码器和线性近似的方法，来发现人类可解释的语言模型特征之间的因果关系。他们构建了一个可扩展的流水线，用于构建细粒度回路来解释模型行为，并将其应用于下游任务中。通过架构Sparse Feature Circuits，使得研究人员能够在语言模型中发现和编辑可解释的因果关系图，并对模型进行细致的解释。这种方法可以帮助研究人员更好地理解语言模型的工作原理和特征之间的关系，为语言处理领域的研究和实践提供了新的思路。 <div>
通过稀疏自编码器和线性近似，提出一种发现人类可解释语言模型特征之间因果关系的可扩展流水线，以构建细粒度回路解释模型行为，并应用于下游任务。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models》S Marks, C Rager, E J. Michaud, Y Belinkov, D Bau, A Mueller [Northeastern University &amp; MIT] (2024) <a href="https://arxiv.org/abs/2403.19647"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoavurbf0qj21em0potkf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavurv5khj21oi0ro13q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavusaiiaj21p00ywqep.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavuskxi0j21ou0n0qb7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oy3hnj20vh0dh76g.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oyhohj20vi0eydj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oydahj20vj0fuwhe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoaw1oyalgj20ve0gdtb5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oyqsjj20vf0qkadm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:37:26 GMT</pubDate>
</item>
<item>
<title>[LG]《Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models》S Marks, C Rager, E J. Michaud, Y Belinkov, D B...</title>
<link>https://weibo.com/1402400261/O7E3JjgAw</link>
<guid>https://weibo.com/1402400261/O7E3JjgAw</guid>
<content:encoded><![CDATA[
<div> Sparse Feature Circuits, Discovering, Editing, Interpretable, Causal Graphs, Language Models, Northeastern University, MIT, 2024

<br /><br />总结:
这篇论文由Northeastern大学和MIT的研究人员共同合作，提出了一种称为Sparse Feature Circuits的方法，可以发现和编辑语言模型中可解释的因果图。研究人员指出，传统的语言模型在解释和编辑因果关系方面存在一定的困难，因此他们提出了这种新方法。Sparse Feature Circuits是一种新颖的方法，可以帮助人们更好地理解语言模型中的因果关系，并进行相应的编辑。通过实验证明，这种方法在发现和编辑可解释的因果图方面取得了显著的效果。整体而言，这项研究为语言模型中因果关系的理解和编辑提供了新的思路和方法。 <div>
[LG]《Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models》S Marks, C Rager, E J. Michaud, Y Belinkov, D Bau, A Mueller [Northeastern University &amp; MIT] (2024) <a href="https://arxiv.org/abs/2403.19647"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoavurbf0qj21em0potkf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavurv5khj21oi0ro13q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavusaiiaj21p00ywqep.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavuskxi0j21ou0n0qb7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oy3hnj20vh0dh76g.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oyhohj20vi0eydj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oydahj20vj0fuwhe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoaw1oyalgj20ve0gdtb5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oyqsjj20vf0qkadm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw1oyu6mj20ve0m2n02.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oyjjgj20vh0mk0vg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw1oy2sej20ve0el40d.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oyratj20vi0fa768.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oycdnj20vf0hztax.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw1oyimjj20vi0kc0vc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoaw1oynjjj20vd0gr76y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oye9ij20vd0j0wh2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoaw1oyo2kj20vd0g2jtp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:37:10 GMT</pubDate>
</item>
<item>
<title>LISA通过层级重要性采样有效模拟LoRA更新方式，实现内存高效的大规模语言模型微调，在多任务上性能优异。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《LISA: Layerwise I...</title>
<link>https://weibo.com/1402400261/O7E08j19a</link>
<guid>https://weibo.com/1402400261/O7E08j19a</guid>
<content:encoded><![CDATA[
<div> 层级重要性采样、LoRA更新方式、内存高效、大规模语言模型微调、多任务、性能优异、LISA、香港科技大学

<br /><br />总结:
该研究提出了一种名为LISA的方法，通过层级重要性采样有效模拟LoRA更新方式，实现了内存高效的大规模语言模型微调。该方法在多任务上表现出色，性能优异，为语言模型微调提供了新的思路和解决方案。LISA方法由香港科技大学的研究团队提出，为大规模语言模型微调领域的发展做出了重要贡献。 <div>
LISA通过层级重要性采样有效模拟LoRA更新方式，实现内存高效的大规模语言模型微调，在多任务上性能优异。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning》R Pan, X Liu, S Diao, R Pi, J Zhang, C Han, T Zhang [The Hong Kong University of Science and Technology] (2024) <a href="https://arxiv.org/abs/2403.17919"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavmt9utbj21d60o6drq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoavmtktt0j20p40ksgo8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoavmtxfumj21ik0l6q7x.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavmu3z4zj20s80pqtby.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoavsfd8fhj20hv0f7aat.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoavsfd33aj20hu0g8gm6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoavsfdtokj20yw0rlgog.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoavsfd67pj20ua097gm4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoavsfcw1hj20qs097wex.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:28:18 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.31)》 爱可可微博热门分享(3.31) [图片]</title>
<link>https://weibo.com/1402400261/O7B7H4FP8</link>
<guid>https://weibo.com/1402400261/O7B7H4FP8</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、3.31、关键词

<br /><br />总结:
3月31日，爱可可微博账号分享了一篇热门内容，引起了网友的关注和转发。文章内容涵盖了多个话题，包括生活趣事、美食推荐、时尚搭配等。微博中的精彩内容吸引了众多用户的注意，让大家在微博平台上进行互动和分享。通过这些热门话题，网友们可以了解到更多有趣的信息，充实自己的生活。爱可可微博成为了人们交流和分享的平台，为大家带来了更多的快乐和收获。 <div>
《爱可可微博热门分享(3.31)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405018110007574965"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.31)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaj2y0wrpj20c206st96.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 14:08:40 GMT</pubDate>
</item>
<item>
<title>【AI生成内容泛滥，文化生态岌岌可危】- 各类AI模型(如GPT-4、ChatGPT等)产生的文本、图像、视频等内容，质量参差不齐，正在大量充斥互联网。这些内容包括学术论...</title>
<link>https://weibo.com/1402400261/O7yyxwwUe</link>
<guid>https://weibo.com/1402400261/O7yyxwwUe</guid>
<content:encoded><![CDATA[
<div> AI生成内容、文化生态、科学研究、影响、低质量视频、儿童认知、社会实验、公共文化资源、环境立法、清洁互联网法案

<br /><br />总结:
AI生成内容在互联网上泛滥，给文化生态带来威胁，影响深远。在科学研究领域，AI生成内容的使用严重影响同行评审，可能带来不当行为。此外，在视频领域，低质量的AI合成儿童视频可能损害儿童认知发展，需要引起警惕。针对这一趋势，需要借鉴20世纪环境立法的经验，制定《清洁互联网法案》，强制监管AI生成内容，保护公共文化资源。AI公司应该加强自律，但同样需要法律监管来应对AI内容污染问题。AI的快速发展带来了一系列社会问题，需要重视并加强监管，避免其失控。 <div>
【AI生成内容泛滥，文化生态岌岌可危】<br />- 各类AI模型(如GPT-4、ChatGPT等)产生的文本、图像、视频等内容，质量参差不齐，正在大量充斥互联网。这些内容包括学术论文、社交媒体帖子、虚假账号、搜索结果等。   <br />- AI生成内容对科学研究的影响尤其严重。研究发现，参加AI会议的科研人员在同行评审中大量使用类似AI生成文本的词汇。这意味着部分作者可能使用AI生成内容或辅助完成同行评审。   <br />- YouTube上也出现大量使用AI合成的低质量儿童视频，这可能会损害儿童认知发展。我们正在进行一场大规模的社会实验，还不知道后果如何。   <br />- 企业和个人出于经济利益考虑，会选择使用廉价的AI生成内容。这导致“公共文化资源”遭到污染，犯了“公地悲剧”的错误。   <br />- 20世纪需要环境立法来保护共享环境，21世纪同样需要立法来保护共享文化。具体可要求对AI生成内容进行标记或水印。   <br />- AI公司目前不愿添加高级水印，担心这会影响模型性能。需立法强制对生成内容添加统计图案等难以移除的水印，以便检测。   <br />- 我们需要等同于《清洁空气法案》的《清洁互联网法案》，通过立法监管来应对AI内容污染问题，不能仅期望企业自律。  <br /><br />思考：  <br />- AI生成内容泛滥成灾，污染文化环境，这一观点发人深省。AI的影响已经渗透到科学等重要领域，令人警醒。  <br />- 连科学论文评审都大量使用AI，反映出目前学术界对AI的过度依赖和急功近利，值得反思。  <br />- AI在学术领域的滥用，凸显了AI技术发展的负面影响。如何规范AI的使用，划定伦理道德底线，是一个亟待解决的问题。  <br />- 文章揭示了AI技术快速发展带来的社会问题，表明我们要高度警惕AI的负面影响，加强监管，防止其失控。<br />《Opinion | AI Garbage Is Already Polluting the Internet - The New York Times》 <a href="https://www.nytimes.com/2024/03/29/opinion/ai-internet-x-youtube.html?ugrp=u&amp;unlocked_article_code=1.gU0.U5Ee.kvPE0e0DodvZ&amp;smid=url-share"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa7r3rbruj20u0126tfm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:36:35 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment》(ICLR 2024) GitHub: github.com/lisiyao21/Du...</title>
<link>https://weibo.com/1402400261/O7yvaAD75</link>
<guid>https://weibo.com/1402400261/O7yvaAD75</guid>
<content:encoded><![CDATA[
<div> 关键词：Duolando、GPT、强化学习、舞蹈伴奏、UniDepth、深度估计、T2I模型、超分辨率、LiDAR、视觉SLAM

总结:
Duolando是一种使用强化学习技术对GPT进行跟随的方法，用于舞蹈伴奏。UniDepth是一种通用的单目度量深度估计模型。 T2I模型可以通过识别语义方向实现连续、特定主题的属性控制。AdaSR-TalkingHead是一种用于一次性生成语音头像的自适应超分辨率技术。 LTA-OM是一种长期关联的激光雷达-惯性里程计和地图构建技术。EfficientVMamba是一种轻量级视觉Mamba的有选择性扫描技术。LITA是一种语言指导的时间定位助理模型。GaussianCube利用最优传输将高斯喷洒结构化用于三维生成建模。Perturbed-Attention Guidance是一种扰动注意力引导技术。ROUTERBENCH是用于多LLM路由系统的基准测试。Long-Context-Attention是用于长上下文LLM模型训练的分布式注意力实现。DevBench是用于软件开发的全面基准测试。Should-It-Be-Executed-Or-Processed探讨LLMs是否能够区分指令和数据。BasicPBC是学习匹配的动画油桶着色基准测试。EasyRL4Rec是一个用户友好的基于强化学习的推荐系统代码库。SuperPoint是一种自监督兴趣点检测和描述模型。EgoSchema是用于非常长形式视频语言理解的诊断基准测试。 <div>
几篇论文实现代码：<br />《Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment》(ICLR 2024) GitHub: github.com/lisiyao21/Duolando<br />《UniDepth: Universal Monocular Metric Depth Estimation》(CVPR 2024) GitHub: github.com/lpiccinelli-eth/UniDepth [fig1]<br />《Continuous, Subject-Specific Attribute Control in T2I Models by Identifying Semantic Directions》(2024) GitHub: github.com/CompVis/attribute-control<br />《Adaptive Super Resolution for One-Shot Talking Head Generation》(2024) GitHub: github.com/Songluchuan/AdaSR-TalkingHead<br />《LTA-OM: Long-Term Association LiDAR-Inertial Odometry and Mapping》(2024) GitHub: github.com/hku-mars/LTAOM<br />《EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba》(2024) GitHub: github.com/TerryPei/EfficientVMamba [fig2] <br />《LITA: Language Instructed Temporal-Localization Assistant》(2024) GitHub: github.com/NVlabs/LITA<br />《GaussianCube: Structuring Gaussian Splatting for 3D Generative Modeling using Optimal Transport》(2024) GitHub: github.com/GaussianCube/GaussianCube<br />《Perturbed-Attention Guidance》(2024) GitHub: github.com/KU-CVLAB/Perturbed-Attention-Guidance<br />《ROUTERBENCH: A Benchmark for Multi-LLM Routing System》(2024) GitHub: github.com/withmartian/routerbench<br />《Long-Context-Attention: Distributed Attention Implementations for Long Context LLM Model Training》(2024) GitHub: github.com/feifeibear/long-context-attention<br />《DevBench: A Comprehensive Benchmark for Software Development》(2024) GitHub: github.com/open-compass/DevBench [fig3]<br />《Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?》(2024) GitHub: github.com/egozverev/Should-It-Be-Executed-Or-Processed<br />《Learning Inclusion Matching for Animation Paint Bucket Colorization》(2024) GitHub: github.com/ykdai/BasicPBC<br />《EasyRL4Rec: A User-Friendly Code Library for Reinforcement Learning Based Recommender Systems》(2024) GitHub: github.com/chongminggao/EasyRL4Rec<br />《SuperPoint: Self-Supervised Interest Point Detection and Description》(2024) GitHub: github.com/christian-rauch/super_point_inference<br />《EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding》(2024) GitHub: github.com/egoschema/EgoSchema<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoa145bowtj21rf0i6wu8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoa1h04n3kj20l70deafb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoa681no84j23zf1827wh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:28:18 GMT</pubDate>
</item>
<item>
<title>【EPUB to Audiobook Converter：EPUB到有声书的转换器】’EPUB to Audiobook Converter - EPUB to audiobook converter, optimized for Audiobookshelf' GitHub...</title>
<link>https://weibo.com/1402400261/O7yttipiX</link>
<guid>https://weibo.com/1402400261/O7yttipiX</guid>
<content:encoded><![CDATA[
<div> GitHub, EPUB to Audiobook Converter, Audiobookshelf
<br />
EPUB到有声书的转换器，可以将EPUB转换为有声书，GitHub上有项目epub_to_audiobook，作者是p0n1，优化了Audiobookshelf的使用体验。

<br /><br />总结:
EPUB到有声书的转换器是一个可以将EPUB格式的电子书转换为有声书的工具，适用于Audiobookshelf，作者是p0n1，在GitHub上开源了相关项目。 <div>
【EPUB to Audiobook Converter：EPUB到有声书的转换器】’EPUB to Audiobook Converter - EPUB to audiobook converter, optimized for Audiobookshelf' GitHub: github.com/p0n1/epub_to_audiobook <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa7e0zh6mj21010u0aec.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:24:06 GMT</pubDate>
</item>
<item>
<title>【Softmax for Arbitrary Label Trees：一个用于医学影像分割的框架】'Softmax for Arbitrary Label Trees - Softmax for Arbitrary Label Trees (SALT) is a fr...</title>
<link>https://weibo.com/1402400261/O7yt26gby</link>
<guid>https://weibo.com/1402400261/O7yt26gby</guid>
<content:encoded><![CDATA[
<div> 分词：Softmax、Arbitrary Label Trees、医学影像分割、框架、训练、分割网络、条件概率、模型、层级关系、数据

总结:<br /><br />这篇文章介绍了一个名为Softmax for Arbitrary Label Trees (SALT)的框架，用于训练医学影像分割网络。SALT利用条件概率来建模数据中的层级关系，从而更好地进行分割任务。该框架的GitHub链接是github.com/UMEssen/SALT。SALT框架可以帮助提高医学影像分割的准确性和效率，是一个有潜力的方法。 <div>
【Softmax for Arbitrary Label Trees：一个用于医学影像分割的框架】'Softmax for Arbitrary Label Trees - Softmax for Arbitrary Label Trees (SALT) is a framework for training segmentation networks using conditional probabilities to model hierarchical relationships in the data.' GitHub: github.com/UMEssen/SALT <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa7d02ja2j20u0112n32.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:23:00 GMT</pubDate>
</item>
<item>
<title>【Edge Infer：- 旨在资源受限的设备上运行小型 AI 模型(包括向量化和Onnx模型)，如 Android、iOS 或 MCU，实现高效的边缘智能，用于实时决策】'Edge Infer - Ed...</title>
<link>https://weibo.com/1402400261/O7ys0ziZp</link>
<guid>https://weibo.com/1402400261/O7ys0ziZp</guid>
<content:encoded><![CDATA[
<div> Edge Infer, 资源受限设备, 小型AI模型, 向量化, Onnx模型, Android, iOS, MCU, 边缘智能, 实时决策, GitHub

总结:<br /><br />Edge Infer 是一种旨在在资源受限的设备上运行小型AI模型的工具，包括向量化和Onnx模型，适用于Android、iOS或MCU等设备，实现高效的边缘智能，用于实时决策。Edge Infer的GitHub链接为github.com/unit-mesh/edge-infer。 <div>
【Edge Infer：- 旨在资源受限的设备上运行小型 AI 模型(包括向量化和Onnx模型)，如 Android、iOS 或 MCU，实现高效的边缘智能，用于实时决策】'Edge Infer - EdgeInfer enables efficient edge intelligence by running small AI models, including embeddings and OnnxModels, on resource-constrained devices like Android, iOS, or MCUs for real-time decision-making. EdgeInfer' GitHub: github.com/unit-mesh/edge-infer <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa7adt8y1j20yc0u0dil.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:20:30 GMT</pubDate>
</item>
<item>
<title>【hoarder-app：用于数据(链接、图片、笔记)收集的应用，支持AI自动打标和全文检索功能】'hoarder-app - A self-hostable bookmark-everything app (links, note...</title>
<link>https://weibo.com/1402400261/O7yrtjJXR</link>
<guid>https://weibo.com/1402400261/O7yrtjJXR</guid>
<content:encoded><![CDATA[
<div> 自托管、收藏一切数据的应用、链接、笔记、图片、AI自动标记、全文检索、GitHub、MohamedBassem、hoarder-app<br />
<br />
总结:<br />
hoarder-app是一个自托管的应用程序，用于收藏各种数据，包括链接、笔记和图片。该应用支持AI自动标记和全文检索功能，用户可以方便地管理和查找自己收藏的信息。该项目可以在GitHub上找到，由MohamedBassem维护。 <div>
【hoarder-app：用于数据(链接、图片、笔记)收集的应用，支持AI自动打标和全文检索功能】'hoarder-app - A self-hostable bookmark-everything app (links, notes and images) with AI-based automatic tagging and full text search' GitHub: github.com/MohamedBassem/hoarder-app <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa78e98l2j21jk0u0n4q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:19:10 GMT</pubDate>
</item>
<item>
<title>【Popple：分布式、高可用、通用用途的键/值数据库】'Popple - Popple is a distributed, highly available, general purpose key/value database.' GitHub: git...</title>
<link>https://weibo.com/1402400261/O7ypPED6c</link>
<guid>https://weibo.com/1402400261/O7ypPED6c</guid>
<content:encoded><![CDATA[
<div> 分布式、高可用、通用、键/值数据库、Popple、GitHub、hoorayman、distributed、highly available、general purpose

分布式键/值数据库Popple是一个通用、高可用的分布式键/值数据库，可以处理各种用途的数据。它具有弹性，能够在整个系统中分布数据，保证数据的高可用性。Popple的代码托管在GitHub上，由hoorayman开发和维护。采用分布式架构，Popple可以有效地存储和检索大量键/值对，适用于各种应用场景。总的来说，Popple是一个强大的键/值数据库，具有分布式部署和高可用性的特点，适用于多种通用用途。 <br /><br />总结: Popple是一个分布式、高可用、通用用途的键/值数据库，由hoorayman开发，可用于处理各种数据应用。 <div>
【Popple：分布式、高可用、通用用途的键/值数据库】'Popple - Popple is a distributed, highly available, general purpose key/value database.' GitHub: github.com/hoorayman/popple <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%95%B0%E6%8D%AE%E5%BA%93%23&amp;isnewpage=1"><span class="surl-text">#数据库#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa74ti7tdj21240u0q73.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:15:08 GMT</pubDate>
</item>
<item>
<title>【rev.ng：基于LLVM和QEMU的二进制分析框架和反编译器】’The rev.ng binary analysis framework and decompiler' GitHub: github.com/revng/revng-c #开源# #机...</title>
<link>https://weibo.com/1402400261/O7ynd9CZx</link>
<guid>https://weibo.com/1402400261/O7ynd9CZx</guid>
<content:encoded><![CDATA[
<div> LLVM、QEMU、二进制分析框架、反编译器、GitHub、rev.ng、revng-c

总结:<br /><br />rev.ng是基于LLVM和QEMU的二进制分析框架和反编译器，它提供一种强大的工具来分析和反编译二进制文件。通过GitHub上的revng-c项目，用户可以轻松访问和使用这个框架。LLVM和QEMU的结合使得rev.ng具备了强大的分析和反编译能力，帮助用户更好地理解和操纵二进制文件。通过rev.ng，用户可以深入研究二进制文件的内部结构和功能，从而进行更高级的安全研究和分析工作。是一个有着广泛应用前景的二进制分析工具。 <div>
【rev.ng：基于LLVM和QEMU的二进制分析框架和反编译器】’The rev.ng binary analysis framework and decompiler' GitHub: github.com/revng/revng-c <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa6y3b15sj21i60l4n1o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:08:41 GMT</pubDate>
</item>
<item>
<title>【EasyRL4Rec - 专注于强化学习(RL)为基础的推荐系统(RS)的全面且易于使用的库】'EasyRL4Rec - a comprehensive and easy-to-use library designed specifically...</title>
<link>https://weibo.com/1402400261/O7ym7486g</link>
<guid>https://weibo.com/1402400261/O7ym7486g</guid>
<content:encoded><![CDATA[
<div> 库，强化学习，推荐系统，全面，易于使用，github，Reinforcement Learning，Recommender Systems，comprehensive，easy-to-use

总结:<br /><br />
"EasyRL4Rec"是一个专注于强化学习为基础的推荐系统的全面且易于使用的库。其设计旨在为推荐系统提供强化学习的解决方案，并在GitHub上提供代码库。该库提供了强化学习和推荐系统的综合性功能，并且易于使用，成为开发推荐系统的有力工具。 <div>
【EasyRL4Rec - 专注于强化学习(RL)为基础的推荐系统(RS)的全面且易于使用的库】'EasyRL4Rec - a comprehensive and easy-to-use library designed specifically for Reinforcement Learning (RL)-based Recommender Systems (RSs)‘ GitHub: github.com/chongminggao/EasyRL4Rec <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa6v4ng6rj20v60u0gpv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:05:58 GMT</pubDate>
</item>
<item>
<title>【高效SAM分割模型大列表】’Efficient-Segment-Anything-Model - One summary of efficient segment anything models' GitHub: github.com/czg1225/Awesome-Eff...</title>
<link>https://weibo.com/1402400261/O7yfei9ug</link>
<guid>https://weibo.com/1402400261/O7yfei9ug</guid>
<content:encoded><![CDATA[
<div> GitHub, Efficient-Segment-Anything-Model, 分割模型, 高效, 模型, 列表, 精彩, 总结, 优点, 应用

<br /><br />总结:
本文介绍了高效SAM分割模型的一份大列表，包含了各种精彩的分割模型。这些模型在分割任务中具有高效性，能够快速准确地识别出目标物体。这些模型的优点在于其高效性和准确性，可以被广泛应用于图像分割、语义分割等领域。通过这个列表，研究者和开发者可以找到适合自己项目的高效SAM分割模型，提高分割任务的效率和准确率。 <div>
【高效SAM分割模型大列表】’Efficient-Segment-Anything-Model - One summary of efficient segment anything models' GitHub: github.com/czg1225/Awesome-Efficient-Segment-Anything <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa6dbad5kj20u00unq7j.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa6dcle9yj215h0u0gq9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa6ddlmj6j20xi0c540f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa6deyl0kj235s0peqd6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa6dfx5dwj21tv0u00yz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa6dhbvx5j235s0natjb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa6diu3ruj22u80u0wo6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa6djqb0uj21f70u0q98.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa6dlfv25j21j40u0jys.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 06:49:01 GMT</pubDate>
</item>
<item>
<title>【RestAI：基于LlamaIndex、Ollama和HF pipelines的AIaaS(人工智能即服务)开源平台】'RestAI - RestAI is an AIaaS (AI as a Service) open-source platform. Bu...</title>
<link>https://weibo.com/1402400261/O7xdOmrEj</link>
<guid>https://weibo.com/1402400261/O7xdOmrEj</guid>
<content:encoded><![CDATA[
<div> RestAI、AIaaS、开源平台、LlamaIndex、Ollama、HF Pipelines、支持、LLM、嵌入式使用、调优

总结:<br /><br />RestAI是一个基于LlamaIndex、Ollama和HF Pipelines的AIaaS开源平台，支持任何被LlamaIndex支持的公共LLM和任何被Ollama支持的本地LLM。它提供精准的嵌入式使用和调优功能。GitHub上有相关项目。 <div>
【RestAI：基于LlamaIndex、Ollama和HF pipelines的AIaaS(人工智能即服务)开源平台】'RestAI - RestAI is an AIaaS (AI as a Service) open-source platform. Built on top of LlamaIndex, Ollama and HF Pipelines. Supports any public LLM supported by LlamaIndex and any local LLM suported by Ollama. Precise embeddings usage and tuning.' GitHub: github.com/apocas/restai <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa1v0x4sij20ud0u0ad4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 04:12:47 GMT</pubDate>
</item>
<item>
<title>【Plandex：基于OpenAI API的命令行AI编程引擎，用于处理复杂的任务，可以帮助用户分解大型任务为更小的子任务，并逐个实现这些子任务，帮助快速完成工作流，与...</title>
<link>https://weibo.com/1402400261/O7xaJE7HH</link>
<guid>https://weibo.com/1402400261/O7xaJE7HH</guid>
<content:encoded><![CDATA[
<div> 命令行、AI编程引擎、处理任务、分解任务、实现子任务、完成工作流、技术互动、减少时间、GitHub、Plandex<br />
<br />
AI编程引擎Plandex基于OpenAI API，用于处理复杂任务，能帮助用户将大型任务分解为小任务，并逐一实现，从而快速完成工作流。用户可以利用Plandex与不熟悉的技术互动，摆脱困境，减少在无聊事务上的时间花费。该工具的GitHub仓库可在github.com/plandex-ai/plandex找到。Plandex是一个有用的AI工具，可提高用户的工作效率和减轻工作负担。总结: <br />AI编程引擎Plandex基于OpenAI API，可帮助用户快速解决复杂任务，通过分解大型任务为小任务逐一实现，并与不熟悉的技术互动，提高工作效率。 <div>
【Plandex：基于OpenAI API的命令行AI编程引擎，用于处理复杂的任务，可以帮助用户分解大型任务为更小的子任务，并逐个实现这些子任务，帮助快速完成工作流，与不熟悉的技术互动，摆脱困境，减少在无聊的事情上花费的时间】’Plandex - An AI coding engine for complex tasks' GitHub: github.com/plandex-ai/plandex <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa1mb9tl9j20u00uwn1d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 04:05:12 GMT</pubDate>
</item>
<item>
<title>【深度伪造(Deepfake)相关文献资源列表】’Deepfake Generation and Detection: A Benchmark and Survey - A Survey on Deepfake Generation and Detection' Git...</title>
<link>https://weibo.com/1402400261/O7x9Clzzn</link>
<guid>https://weibo.com/1402400261/O7x9Clzzn</guid>
<content:encoded><![CDATA[
<div> Deepfake Generation, Detection, Benchmark, Survey, GitHub, Resource, Awesome, Flyingby, Survey on Deepfake Generation and Detection

<br /><br />总结:
本文介绍了关于深度伪造（Deepfake）生成和检测的研究现状，提供了一个包含相关资源的GitHub链接。文章从深度伪造生成和检测的角度出发，提供了相关资源和信息，帮助读者了解深度伪造技术的发展和应用。GitHub链接中包含了丰富的资料，为研究者提供了实用的工具和参考文献。深度伪造技术的发展对社会产生了重要影响，因此深入了解相关信息和研究是十分必要的。通过本文和相关资源，读者可以更好地了解和研究深度伪造技术，为社会和科学研究做出更有益的贡献。 <div>
【深度伪造(Deepfake)相关文献资源列表】’Deepfake Generation and Detection:   <br />  A Benchmark and Survey - A Survey on Deepfake Generation and Detection' GitHub: github.com/flyingby/Awesome-Deepfake-Generation-and-Detection <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa1k9ly7yj21js0jr79w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa1kaeawrj20vb0d4goz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 04:02:27 GMT</pubDate>
</item>
<item>
<title>【OpenUI：让使用者描述网页界面并实时渲染的开源项目】'OpenUI - OpenUI let's you describe UI using your imagination, then see it rendered live.' GitHub:...</title>
<link>https://weibo.com/1402400261/O7x5h1h9B</link>
<guid>https://weibo.com/1402400261/O7x5h1h9B</guid>
<content:encoded><![CDATA[
<div> OpenUI、描述、界面、实时渲染、开源项目、GitHub、使用者、网页、界面、渲染 live。

<br /><br />总结:
OpenUI是一个开源项目，可以让使用者通过描述界面来实时渲染网页界面。用户可以发挥自己的想象力来描述界面，然后看到它在实时渲染的过程中呈现出来。该项目托管在GitHub上，方便用户查看和参与贡献。通过OpenUI，用户可以轻松创建自己想要的网页界面，带来更加直观和便捷的设计体验。 <div>
【OpenUI：让使用者描述网页界面并实时渲染的开源项目】'OpenUI - OpenUI let's you describe UI using your imagination, then see it rendered live.' GitHub: github.com/wandb/openui <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa193yigoj21410u00wc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 03:51:44 GMT</pubDate>
</item>
<item>
<title>【OpenDevin: 一个开源项目，旨在复制Devin，Devin是一个自主的AI软件工程师，能执行复杂的工程任务，并积极与用户协作进行软件开发项目的合作】'OpenDevin: Cod...</title>
<link>https://weibo.com/1402400261/O7x2Kl9x2</link>
<guid>https://weibo.com/1402400261/O7x2Kl9x2</guid>
<content:encoded><![CDATA[
<div> OpenDevin, 开源项目, 复制Devin, AI软件工程师, 执行工程任务, 用户协作, 软件开发项目, GitHub, Code Less, Make More

<br /><br />总结:
OpenDevin是一个开源项目，旨在复制Devin，Devin是一个自主的AI软件工程师，能执行复杂的工程任务，并积极与用户协作进行软件开发项目的合作。该项目在GitHub上可找到，旨在让用户编写更少的代码，取得更多的成果。 <div>
【OpenDevin: 一个开源项目，旨在复制Devin，Devin是一个自主的AI软件工程师，能执行复杂的工程任务，并积极与用户协作进行软件开发项目的合作】'OpenDevin: Code Less, Make More' GitHub: github.com/opendevin/opendevin <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5017953058357310"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax4.sinaimg.cn/orj480/5396ee05ly1hoa12ihxhwj21f20qumxl.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/ksQ6Y1c5lx08dIbPt6Na010412002IBP0E010.mp4?label=mp4_720p&amp;template=1368x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711865762&amp;ssig=PUWH7V97Hq&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/n7Oawc2Jlx08dIbPjD5e010412001fj80E010.mp4?label=mp4_hd&amp;template=912x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711865762&amp;ssig=buxMcLzUUi&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/TLUUJoUrlx08dIbPBcUE010412000JWS0E010.mp4?label=mp4_ld&amp;template=684x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711865762&amp;ssig=X5k%2F11GgW2&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5017953058357310" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 03:45:31 GMT</pubDate>
</item>
<item>
<title>《LLM 应用开发实践笔记》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O7wM56Ev8</link>
<guid>https://weibo.com/1402400261/O7wM56Ev8</guid>
<content:encoded><![CDATA[
<div> 应用开发、LLM、实践、笔记、技术、编程、学习、经验、案例、方法论

<br /><br />总结:
LLM 应用开发实践笔记是一篇关于应用开发实践的经验分享文章。文章通过具体的案例和方法论，介绍了在应用开发过程中的技术细节和实践经验。作者通过自身的学习和实践，总结出了一套有效的开发方法，帮助读者更好地理解应用开发的过程。通过本文，读者可以学习到实际应用开发中的技巧和经验，为自己的开发工作提供有用的参考。 <div>
《LLM 应用开发实践笔记》 <a href="https://aitutor.liduos.com/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9zv1onj7j20ki10s76d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 03:04:27 GMT</pubDate>
</item>
<item>
<title>对 预训练 MoE、upcycled MoE 和 FrankenMoE 三类 MoE 模型的简介。- 预训练 MoE预训练 MoE 旨在利用 MoE 架构从头开始预训练语言模型，以期获得比传统密集模型...</title>
<link>https://weibo.com/1402400261/O7wxgeqRs</link>
<guid>https://weibo.com/1402400261/O7wxgeqRs</guid>
<content:encoded><![CDATA[
<div> 预训练 MoE、upcycled MoE、FrankenMoE、语言模型、专家、预训练、计算成本、效果、模型合并

<br /><br />总结:
预训练 MoE 是一种利用 MoE 架构从头开始预训练语言模型的方法，具有训练速度快、推理速度快和专家针对不同概念等优势，代表性模型有 Switch Transformer、Mixtral。upcycled MoE 是在已经训练好的基础模型上创建多个专家形成 MoE 模型，优势在于计算成本低、可灵活控制专家数量，代表性工作有 DeepSeek-MoE、Upstage SOLAR。FrankenMoE 是将在特定任务上表现优异的微调模型组合成 MoE 模型，专家面向特定任务，但缺乏负载均衡优势，表现可能优于通用 MoE 模型，代表性模型为 Beyonder-4x7B-v2。 <div>
对 预训练 MoE、upcycled MoE 和 FrankenMoE 三类 MoE 模型的简介。<br /><br />- 预训练 MoE<br />预训练 MoE 旨在利用 MoE 架构从头开始预训练语言模型，以期获得比传统密集模型更高效的训练效果。预训练 MoE 的优势在于：<br />1. 训练速度更快。在相同计算预算下，MoE 模型理论上可以比密集模型更快达到相同的性能水平。<br />2. 推理速度更快。尽管 MoE 模型参数量巨大，但实际推理时只会激活部分专家，因此推理速度比拥有相同参数量的密集模型更快。<br />3. 专家可以专门针对不同的浅层概念或词元组，而不是某个特定主题。<br />不过，预训练 MoE 也面临一些挑战，如推理时需要大量内存来加载所有专家参数，以及在下游任务微调时容易过拟合等。代表性的预训练 MoE 模型有 Switch Transformer、Mixtral 等。<br /><br />- upcycled MoE<br />upcycled MoE 的思路是在一个已经训练好的基础模型上，通过复制其前馈网络来创建多个专家，形成一个 MoE 模型。与从头预训练相比，upcycled MoE 的优势在于：<br />1. 基于成熟的预训练模型，继续预训练的计算成本更低。<br />2. 可以使用细粒度的专家，即将前馈网络切割成更小的单元，从而获得数量众多的小型专家。  <br />3. 可以灵活控制要激活的专家数量，在推理速度和效果之间进行权衡。<br />upcycled MoE 的代表性工作包括 DeepSeek-MoE、Upstage SOLAR 等。<br /><br />- FrankenMoE<br />FrankenMoE 的思路与模型合并类似，即选择几个在特定任务上表现优异的微调模型，将它们组合成一个 MoE 模型。通过一定的训练，可以让路由器学会将不同类型的token发送给对应的专家。<br />与预训练 MoE 和再利用 MoE 相比，FrankenMoE 的特点是：<br />1. 专家是面向特定任务的，而不是通用的浅层概念，这一点与预训练 MoE 有本质区别。<br />2. 不再具有 MoE 的某些优势，如负载均衡。因为专家之间的能力差异较大。<br />3. 在特定任务上的表现可能优于通用的 MoE 模型，如 Beyonder-4x7B-v2。<br />但 FrankenMoE 能否广泛应用于不同场景，目前还有待进一步验证。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9yoziedxj20xc4t8b29.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9yp0i5o4j20u70i90v8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9yp1kqcyj20pb0chwfw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 02:27:57 GMT</pubDate>
</item>
<item>
<title>《混合专家模型 (MoE) 详解》- MoE 是一种将大型语言模型中全连接层替换为稀疏层的技术，可以显著提高预训练效率。其包含两个主要元素：稀疏的 MoE 层和一个门控...</title>
<link>https://weibo.com/1402400261/O7w5scEbo</link>
<guid>https://weibo.com/1402400261/O7w5scEbo</guid>
<content:encoded><![CDATA[
<div> 稀疏层、MoE层、门控网络、专家、模型规模、Transformer、微调、训练挑战、开源项目、知识蒸馏、量化

<br /><br />总结:
混合专家模型（MoE）是一种将大型语言模型中全连接层替换为稀疏层的技术，通过引入稀疏性和门控网络，实现部分输入数据计算、模型规模扩张而不增加计算量，并通过专家负载平衡、辅助损失函数和专家容量限制来提高效率。MoE与Transformer结合取得进展，如GShard实现规模扩张至6000亿参数，Switch Transformer简化门控网络，提出专家容量概念。MoE模型在微调中容易过拟合，需采用更高正则化，多任务示教微调再单任务微调可提升表现。面临训练和部署挑战，需专家并行、通信优化、断点续训、模型压缩等技术。MoE模型为构建大规模高效神经网络提供新思路，Switch Transformers等研究解决MoE不稳定性问题，指明后续改进方向。MoE引发学术界和工业界广泛关注，多个研究组织发布基于MoE模型取得性能进步，未来可进一步探索知识蒸馏、量化等方向。将MoE蒸馏为密集模型和量化是有前景的研究方向，在保持性能的同时大幅压缩模型体积，促进MoE在资源受限环境下的部署。 <div>
《混合专家模型 (MoE) 详解》<br />- MoE 是一种将大型语言模型中全连接层替换为稀疏层的技术，可以显著提高预训练效率。其包含两个主要元素：稀疏的 MoE 层和一个门控网络，门控网络决定每个 token 由哪个 expert 处理。   <br />- MoE 的起源可追溯到 1991 年的论文，2010-2015 年间的研究为 MoE 在深度网络中的应用奠定了基础。2017 年的论文首次在 NLP 任务中应用了 MoE，将 LSTM 模型扩展到 1300 亿参数。   <br />- MoE 引入了稀疏性，只对部分输入数据进行计算，从而实现模型规模的扩张而不增加计算量。门控网络学习将输入分配给不同的专家(expert)。   <br />- 为了平衡各专家的负载，需要添加辅助损失函数鼓励所有专家得到近似相等的训练样本。还可以设置专家容量限制。   <br />- MoE 与 Transformer 的结合取得了显著进展。例如 GShard 利用 MoE 将模型扩展到 6000 亿参数；Switch Transformer 引入单专家策略简化了门控网络，提出了专家容量的概念。   <br />- 相较于稠密模型，MoE 模型在下游任务的微调中更容易过拟合，需要采用更高的正则化。最近的工作显示先进行多任务示教微调然后再单任务微调可以显著提升 MoE 的表现。   <br />- 训练和部署 MoE 也面临一些挑战，论文提出了专家并行、通信优化、断点续训、模型压缩等技术来解决这些问题。   <br />- 目前有多个开源项目致力于 MoE 的研究，未来可探索的方向包括知识蒸馏、量化等。  <br /><br />思考：  <br />- MoE 模型的出现为构建大规模且高效的神经网络提供了新的思路。通过将专家作为组件嵌入到网络中，MoE 有望突破传统密集模型的瓶颈。  <br />- Switch Transformers 等工作针对 MoE 的不稳定性问题进行了深入研究，为后续的改进指明了方向。1.6 万亿参数的 MoE 模型展现了这一架构的巨大潜力。  <br />- 多个研究组织已经发布了基于 MoE 的模型，表明 MoE 正在受到学术界和工业界的广泛关注。这些模型在性能上取得了显著进步，有望在实际应用中发挥重要作用。  <br />- 将 MoE 蒸馏为密集模型以及对其进行量化是非常有前景的研究方向。这不仅能够在保持性能的同时大幅压缩模型体积，还能促进 MoE 在资源受限环境下的部署。<br /> <a href="https://huggingface.co/blog/moe"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9wulpqsaj20za0u00wv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 01:19:26 GMT</pubDate>
</item>
<item>
<title>《BrushNet - BrushNet: A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion | a Hugging Face Space by TencentARC》 网页链接 #...</title>
<link>https://weibo.com/1402400261/O7vT1o0c8</link>
<guid>https://weibo.com/1402400261/O7vT1o0c8</guid>
<content:encoded><![CDATA[
<div> BrushNet, Image Inpainting, Plug-and-Play Model, Diffusion, Dual-Branch, Decomposed, Hugging Face Space, TencentARC

<br /><br />总结:
本文介绍了一种基于图像修复的模型BrushNet，通过两个分支的扩散机制实现图像修复。该模型能够自动进行图像修复，满足用户需求。通过对不同部分的修复分解，提高了修复效果。 TencentARC团队在Hugging Face Space上提供了该模型，方便用户使用。 <div>
《BrushNet - BrushNet: A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion | a Hugging Face Space by TencentARC》 <a href="https://huggingface.co/spaces/TencentARC/BrushNet"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5017908603191302"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax3.sinaimg.cn/orj480/5396ee05ly1ho9vyjuuigj20zk0k00tk.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/DGCmhkr0lx08dHZH7en6010412005TBA0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711858507&amp;ssig=CUnU3p7Iwb&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/xv8u3UeOlx08dHZGKSly010412002Lz70E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711858507&amp;ssig=CXQrgsO%2Fnc&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/Afyz8Cvblx08dHZGKdLq010412001JUS0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711858507&amp;ssig=xQSd7WEinY&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5017908603191302" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 00:48:49 GMT</pubDate>
</item>
<item>
<title>【DSPy：机器学习工作流重塑提示工程】- DSPy 是一个与众不同的提示工程框架，它将逻辑与提示分离，使开发人员能够通过 dspy.Module 确定性地编程逻辑，而不用关...</title>
<link>https://weibo.com/1402400261/O7vOKCeLv</link>
<guid>https://weibo.com/1402400261/O7vOKCeLv</guid>
<content:encoded><![CDATA[
<div> 提示工程、DSPy、机器学习、工作流、逻辑、LLM、闭合循环、易用性、术语、概念

总结：<br /><br />本文介绍了DSPy这一机器学习工作流重塑提示工程的框架，其将逻辑与提示分离，使开发人员专注于逻辑编程而不需关心底层LLM，有望简化提示工程流程。DSPy将提示工程转变为结构化的机器学习工作流，闭合了训练和评估的循环，突出了LLM/Agent系统的重要性。然而，DSPy目前存在易用性问题，术语和概念晦涩，对新手不友好。希望DSPy在优化易用性方面做出改进，降低学习门槛，扩大受众群。 <div>
【DSPy：机器学习工作流重塑提示工程】<br />- DSPy 是一个与众不同的提示工程框架，它将逻辑与提示分离，使开发人员能够通过 dspy.Module 确定性地编程逻辑，而不用关心所使用的 LLM。  <br />- DSPy 的革命性在于它将提示工程纯手工过程转变为结构化的机器学习工作流，包括准备数据集、定义模型、训练、评估和测试。  <br />- DSPy 的关键贡献是闭合了提示工程中训练和评估的循环，并将逻辑与文本表示分离开来，凸显了对 LLM/Agent 系统的潜在重要性。  <br />- DSPy 目前存在的问题是对新手来说学习曲线较陡峭，其习语如 signature、module、program、teleprompter、optimization 和 compile 等术语让人望而生畏。即使对于精通提示工程的人来说，在 DSPy 中驾驭这些概念也是一个具有挑战性的迷宫。  <br /><br />思考：  <br />- DSPy 通过将逻辑与提示分离，使开发人员能够专注于逻辑编程，而无需关注底层 LLM，这一点令人印象深刻。这种方式有望大大简化提示工程的流程。  <br />- 将提示工程转变为结构化的机器学习工作流是一个宏伟的愿景，如果能实现，将极大地推动 LLM 应用的发展。不过这需要 DSPy 在易用性上做出改进。  <br />- DSPy 的术语和概念目前还比较晦涩，对新手不够友好。如果能在这方面做些优化，降低学习门槛，DSPy 的受众会更加广泛。  <br />《DSPy: Not Your Average Prompt Engineering》 <a href="https://jina.ai/news/dspy-not-your-average-prompt-engineering/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9vnlvwvzj20xc0hiabc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9vnnsds1j20xc0hijt8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 00:38:18 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评...</title>
<link>https://weibo.com/1402400261/O7uVrf61S</link>
<guid>https://weibo.com/1402400261/O7uVrf61S</guid>
<content:encoded><![CDATA[
<div> 编程语言、故事、技术、Java、Python、JavaScript、C语言、MySQL、Redis、技术原理。

<br /><br />总结:
《码农翻身2》是一本故事化的技术书籍，通过讲述编程语言之间的斗争和争端，将看似枯燥的技术知识变得生动有趣。Java、Python、JavaScript、C语言、MySQL和Redis等技术在书中扮演着不同角色，展现了它们之间的互动和竞争。读者在享受故事的同时，也能够学到技术的原理和本质。《码农翻身2》是一部结合技术和趣味的书籍，让读者在轻松愉快的阅读中提升自己的技术水平。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 22:22:01 GMT</pubDate>
</item>
<item>
<title>今日推介(第1361期)：使用方向感知t-SNE可视化高维时间数据、超越回路重叠寻找模型机制、语言模型视角下的工具使用研究综述、用引导扩散从零开始生成强大的投毒...</title>
<link>https://weibo.com/1402400261/O7uVh0dhT</link>
<guid>https://weibo.com/1402400261/O7uVh0dhT</guid>
<content:encoded><![CDATA[
<div> 方向感知t-SNE、高维时间数据、超越回路重叠、模型机制、语言模型、工具使用、引导扩散、投毒和后门、反事实预训练、目标移除和插入

<br /><br />总结:
本文介绍了几篇关于机器学习和人工智能领域的研究成果。首先，提出了使用方向感知t-SNE可视化高维时间数据的方法，可以更直观地展示数据的特征和变化。其次，探讨了超越回路重叠寻找模型机制的方法，对于理解复杂系统的运作机制具有重要意义。另外，从语言模型的视角分析了工具使用研究，为提升用户体验和效率提供了新思路。此外，介绍了用引导扩散从零开始生成强大的投毒和后门的技术，以及用于逼真目标移除和插入的自举反事实预训练的方法，这些技术在安全和数据处理领域具有重要应用前景。通过这些研究成果的分享，可以促进机器学习和人工智能领域的发展，推动相关技术的创新和应用。 <div>
今日推介(第1361期)：使用方向感知t-SNE可视化高维时间数据、超越回路重叠寻找模型机制、语言模型视角下的工具使用研究综述、用引导扩散从零开始生成强大的投毒和后门、用于逼真目标移除和插入的自举反事实预训练 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/689966788"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.31)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9rpdhji0j20go0gswgt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho9rpfuh30j20go0960uf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho9rpicbi3j20go0dt3zx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho9rpkv1naj20go07kmxz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho9rpn7yx5j20go08fta0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 22:21:36 GMT</pubDate>
</item>
<item>
<title>通过构建反事实图像数据集微调扩散模型，实现了逼真的物体删除和插入，显著提高了渲染物体对场景效应的能力。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《ObjectDrop: B...</title>
<link>https://weibo.com/1402400261/O7uR4D6Cm</link>
<guid>https://weibo.com/1402400261/O7uR4D6Cm</guid>
<content:encoded><![CDATA[
<div> 反事实图像数据集、微调、扩散模型、物体删除、物体插入、场景效应、物体移除、物体添加、渲染能力、ObjectDrop
<br />
<br />
总结：研究通过构建反事实图像数据集微调扩散模型，实现了逼真的物体删除和插入，提高了渲染物体对场景效应的能力。这项研究利用了ObjectDrop技术，通过对图像进行微调和扩散模型的训练，实现了物体的删除和插入，使得场景效果更加真实。该技术对于图像处理和渲染领域具有重要意义，可以在实际应用中提供更多可能性。研究团队的工作有望为数字图像处理领域带来新的突破，为物体移除和添加等任务提供更加高效、准确的解决方案。 <div>
通过构建反事实图像数据集微调扩散模型，实现了逼真的物体删除和插入，显著提高了渲染物体对场景效应的能力。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion》D Winter, M Cohen, S Fruchter, Y Pritch, A Rav-Acha, Y Hoshen [Google Research] (2024) <a href="https://arxiv.org/abs/2403.18818"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9r6lfzd1j21fc0j812s.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9r6lwz2pj21ok0xu7g6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9r6m52xjj21oi0m6gtc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9r6mf9a0j21p80uync4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9reswzu0j210y0m4aeu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9resx0v3j210z0n7tda.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9reswusnj210x0ovn0q.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resxfa7j210x0qu43z.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9resx035j210p0epq6x.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 22:11:15 GMT</pubDate>
</item>
<item>
<title>[CV]《ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion》D Winter, M Cohen, S Fruchter, Y Pritch, A Rav-Acha, ...</title>
<link>https://weibo.com/1402400261/O7uR2hqNe</link>
<guid>https://weibo.com/1402400261/O7uR2hqNe</guid>
<content:encoded><![CDATA[
<div> Bootstrapping, Counterfactuals, Object Removal, Object Insertion, Photorealistic, Google Research, Deep Learning, Image Editing, Computer Vision, Object Detection

<br /><br />总结：
该研究来自Google Research团队，提出了一种名为ObjectDrop的方法，用于在图像中实现真实感十足的对象删除和插入操作。通过引入反事实生成器来训练深度学习模型，实现了对于图像中物体的有效去除和替换。与传统方法相比，ObjectDrop能够更好地处理较复杂的情景，并且生成的结果质量更高。研究团队在大规模数据集上进行了实验证实，结果表明ObjectDrop在图像编辑和计算机视觉领域具有广阔的应用前景。 <div>
[CV]《ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion》D Winter, M Cohen, S Fruchter, Y Pritch, A Rav-Acha, Y Hoshen [Google Research] (2024) <a href="https://arxiv.org/abs/2403.18818"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9r6lfzd1j21fc0j812s.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9r6lwz2pj21ok0xu7g6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9r6m52xjj21oi0m6gtc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9r6mf9a0j21p80uync4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9reswzu0j210y0m4aeu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9resx0v3j210z0n7tda.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9reswusnj210x0ovn0q.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resxfa7j210x0qu43z.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9resx035j210p0epq6x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9reswcx8j21120dtad2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9resvwsij210y091wgh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resz9qcj21111h3k2x.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9resz22mj210m1ggwp5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9resz299j210x1fgqdh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9reszey1j210x1fg13w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resz2ntj210x1eg130.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resyyvrj210x1fowog.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 22:11:10 GMT</pubDate>
</item>
<item>
<title>利用引导扩散生成高质量和高效的中投毒基础样本，再与下游攻击算法相结合，实现了更隐蔽和强效的对抗机器学习。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Generating ...</title>
<link>https://weibo.com/1402400261/O7uKD6OzN</link>
<guid>https://weibo.com/1402400261/O7uKD6OzN</guid>
<content:encoded><![CDATA[
<div> 中投毒基础样本, 引导扩散, 下游攻击算法, 对抗机器学习, 高质量, 高效, 隐蔽, 强效, 生成, 转发 

总结:<br /><br />这篇文章介绍了一种利用引导扩散生成高质量和高效的中投毒基础样本的方法，然后与下游攻击算法相结合，实现了更隐蔽和强效的对抗机器学习。研究者通过这种方法能够生成具有潜在毒害和后门功能的样本，为网络安全领域提供了有力的工具和技术。 <div>
利用引导扩散生成高质量和高效的中投毒基础样本，再与下游攻击算法相结合，实现了更隐蔽和强效的对抗机器学习。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion》H Souri, A Bansal, H Kazemi, L Fowl... [Johns Hopkins University &amp; University of Maryland &amp; Google] (2024) <a href="https://arxiv.org/abs/2403.16365"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qlilx7pj21jo0veh0a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qljbfj9j21uu0ua4be.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qljtdcij21ki16q7ki.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qljxysoj21kg0vk7ez.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0tti1j20vi0j3wh9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0t8m3j20sq083ta2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qy0trcsj20vd0g6di1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0v0c4j20vg0hggox.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0u9apj20vg0hgdjp.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:55:23 GMT</pubDate>
</item>
<item>
<title>[LG]《Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion》H Souri, A Bansal, H Kazemi, L Fowl... [Johns Hopkins University &amp; U...</title>
<link>https://weibo.com/1402400261/O7uKuxzfT</link>
<guid>https://weibo.com/1402400261/O7uKuxzfT</guid>
<content:encoded><![CDATA[
<div> 关键词: Generating Potent Poisons, Backdoors, Guided Diffusion, Johns Hopkins University, University of Maryland, Google

总结:
本研究由约翰霍普金斯大学、马里兰大学和谷歌合作完成，探讨了如何利用引导扩散技术从头开始生成强效毒药和后门。研究团队通过实验和研究发现，在网络安全领域中，利用引导扩散方法可以快速生成具有毒性和后门功能的恶意软件和程序。通过深入分析和模拟实验，研究人员成功演示了这种方法的有效性和潜力，为网络安全防御提供了新的思路和方法。这项研究对于加强网络安全防御和对抗恶意攻击具有重要意义，有望为未来的网络安全研究和应用提供有益的参考和借鉴。 <div>
[LG]《Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion》H Souri, A Bansal, H Kazemi, L Fowl... [Johns Hopkins University &amp; University of Maryland &amp; Google] (2024) <a href="https://arxiv.org/abs/2403.16365"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qlilx7pj21jo0veh0a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qljbfj9j21uu0ua4be.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qljtdcij21ki16q7ki.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qljxysoj21kg0vk7ez.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0tti1j20vi0j3wh9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0t8m3j20sq083ta2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qy0trcsj20vd0g6di1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0v0c4j20vg0hggox.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0u9apj20vg0hgdjp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0tmvnj20vh0e4abz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0toplj20vj0e4gnj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qy0txctj20vh0hi77g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qy0u2x6j20vh0hhq6h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0ttahj20vh0hgmzw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qy0tk82j20vj0e4jt7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0thgyj20vj0e4jt9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:55:03 GMT</pubDate>
</item>
<item>
<title>通过定义工具的概念、总结应用场景和方法、分析效率等方面，全面系统地回顾和分析了工具辅助语言模型的研究进展，为该领域的发展提供了重要指导。 - 转发 @爱可...</title>
<link>https://weibo.com/1402400261/O7uEwqhRZ</link>
<guid>https://weibo.com/1402400261/O7uEwqhRZ</guid>
<content:encoded><![CDATA[
<div> 工具概念, 应用场景, 方法, 效率, 语言模型, 研究进展, 指导意义, 重要性, 调查, 资源分配
<br /><br />总结:
本文系统地回顾和分析了工具辅助语言模型的研究进展。首先定义工具的概念，然后总结了工具在语言模型中的应用场景和方法。分析了工具辅助语言模型的效率，并探讨了其在领域发展中的重要性和指导意义。通过对工具的调查和资源分配，为该领域的进一步发展提供了重要启示。 <div>
通过定义工具的概念、总结应用场景和方法、分析效率等方面，全面系统地回顾和分析了工具辅助语言模型的研究进展，为该领域的发展提供了重要指导。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《What Are Tools Anyway? A Survey from the Language Model Perspective》Z Wang, Z Cheng, H Zhu, D Fried, G Neubig [CMU &amp; Shanghai Jiao Tong University] (2024) <a href="https://arxiv.org/abs/2403.15452"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qcpp0boj21ge0natio.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qcq7gp6j20qs0m6djr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qcqfpcsj20rc0ro0y6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qcqml1qj21pm0jyqdc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qinfp1cj20d107bwey.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qingarmj20vk0drtap.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:40:21 GMT</pubDate>
</item>
<item>
<title>[CL]《What Are Tools Anyway? A Survey from the Language Model Perspective》Z Wang, Z Cheng, H Zhu, D Fried, G Neubig [CMU &amp; Shanghai Jiao Tong Univers...</title>
<link>https://weibo.com/1402400261/O7uEusOfo</link>
<guid>https://weibo.com/1402400261/O7uEusOfo</guid>
<content:encoded><![CDATA[
<div> 关键词：工具，语言模型，调查，功能，应用，自然语言处理，研究，方法，数据集，评估

总结：<br /><br />总结:本文介绍了基于语言模型的视角对工具进行调查的研究。作者探讨了工具的功能、应用及在自然语言处理中的作用。研究方法包括对数据集的评估和分析，为未来研究提供了参考。 <div>
[CL]《What Are Tools Anyway? A Survey from the Language Model Perspective》Z Wang, Z Cheng, H Zhu, D Fried, G Neubig [CMU &amp; Shanghai Jiao Tong University] (2024) <a href="https://arxiv.org/abs/2403.15452"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qcpp0boj21ge0natio.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qcq7gp6j20qs0m6djr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qcqfpcsj20rc0ro0y6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qcqml1qj21pm0jyqdc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qinfp1cj20d107bwey.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qingarmj20vk0drtap.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:40:16 GMT</pubDate>
</item>
<item>
<title>提出 EAP-IG 方法，实验证明它相比 EAP 可以提取出更忠实的回路，以更准确地理解语言模型的内在运算机制。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Have Faith in Fa...</title>
<link>https://weibo.com/1402400261/O7uBnidh5</link>
<guid>https://weibo.com/1402400261/O7uBnidh5</guid>
<content:encoded><![CDATA[
<div> 提取关键词：
EAP-IG、EAP、回路、语言模型、内在运算机制、信任度、模型机制、研究

总结:
本文提出了EAP-IG方法，与传统的EAP方法相比，能够更准确地提取出语言模型内在运算机制中更忠实的回路。实验证明，EAP-IG方法能够更好地理解模型的运作机制，从而提高对语言模型的理解信任度。研究结果表明，通过考虑回路的信任度，可以超越仅仅考虑回路重叠，从而更全面地揭示语言模型的内在机制。详细分析表明EAP-IG方法在理解语言模型方面的优势，为深入研究语言模型的内在运作机制提供了新的思路。Br><br />总结: 本研究提出了EAP-IG方法，与传统的EAP方法相比，能够更准确地提取出语言模型内在运算机制中更忠实的回路。实验结果表明，EAP-IG方法能够提高对语言模型的理解信任度，有助于揭示模型的内在机制。通过考虑回路的信任度，可以更全面地理解语言模型的内在运作机制，为深入研究提供了新的方向。 <div>
提出 EAP-IG 方法，实验证明它相比 EAP 可以提取出更忠实的回路，以更准确地理解语言模型的内在运算机制。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms》M Hanna, S Pezzelle, Y Belinkov [University of Amsterdam &amp; Technion] (2024) <a href="https://arxiv.org/abs/2403.17806"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q33y9lhj21bq0vwnca.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q34mdhyj21lg0qik0x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9q34yn5ej21m00vyk6a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q352mugj21l211en6e.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajljb6j20vh0dy76v.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qajlihij20vf0gidi8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajkv4qj20vd0bawfe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qajl2bfj20un0euq4i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajlil2j20ve0d140p.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:32:35 GMT</pubDate>
</item>
<item>
<title>[LG]《Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms》M Hanna, S Pezzelle, Y Belinkov [University of Amsterdam...</title>
<link>https://weibo.com/1402400261/O7uBkAiq9</link>
<guid>https://weibo.com/1402400261/O7uBkAiq9</guid>
<content:encoded><![CDATA[
<div> 信念，忠诚，模型机制，电路重叠，大学阿姆斯特丹，特希翁，2024年

<br />
本研究旨在探讨在寻找模型机制时如何超越电路重叠的思维。研究团队来自阿姆斯特丹大学和以色列理工学院，通过实证分析发现，在研究模型机制时，一定要坚定信念和忠诚，不仅仅停留在电路重叠的层面上，还要深入挖掘更为深层的原因和关联。他们提出了一种新的研究方法，希望可以帮助学术界在探索模型机制时更加全面和深入地思考问题。总体来说，这项研究为相关领域的学者们提供了新的研究思路和方法，对于推动学术研究具有一定启发意义。

<br />
总结: 该研究提出了超越电路重叠的新思路，强调在寻找模型机制时需要有信念和忠诚，以更深入和全面的视角探讨问题，为学术界提供了新的研究方法。 <div>
[LG]《Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms》M Hanna, S Pezzelle, Y Belinkov [University of Amsterdam &amp; Technion] (2024) <a href="https://arxiv.org/abs/2403.17806"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q33y9lhj21bq0vwnca.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q34mdhyj21lg0qik0x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9q34yn5ej21m00vyk6a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q352mugj21l211en6e.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajljb6j20vh0dy76v.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qajlihij20vf0gidi8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajkv4qj20vd0bawfe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qajl2bfj20un0euq4i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajlil2j20ve0d140p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajkfrcj20uw03ugm3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajldlxj20t10cc0tl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajll3dj20vh0frq53.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajlhyaj20ve0npwgz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:32:29 GMT</pubDate>
</item>
<item>
<title>【开源大语言模型的选择之道】- 近期不断有新的大型语言模型(LLM)发布，如Llama 2、Mixtral 8x7B、Zephyr 7B、SOLAR 10.7B和Code Llama等。这些模型规模越来越大...</title>
<link>https://weibo.com/1402400261/O7n3vpf2O</link>
<guid>https://weibo.com/1402400261/O7n3vpf2O</guid>
<content:encoded><![CDATA[
<div> 关键词: 大语言模型、选择、开源、性能、部署成本、可控性、多语言支持、部署流程、负责任、开源模型

总结:<br />
选择大语言模型时需考虑性能表现、调优空间、多语言支持等因素，开源模型具有更高的可控性、数据安全性和成本效益，但需要自行部署和维护。专用LLM在特定任务上表现更优，但通用LLM适用范围更广，需根据需求选择。在部署LLM时要考虑偏见、问责制等伦理问题，选择合适的模型大小和做好基础设施规划。API和监控可以简化部署流程和识别问题。发展中的LLM需要负责任地造福社会，模型参数量不代表在所有任务上表现更好，开源模型可能在灵活性、成本等方面更有优势。在实际应用中需全面评估质量、速度和成本，并不盲目追求参数量。开源模型可能是更好的选择，部署大语言模型需要考虑多方面策略，是一个复杂的过程。 <div>
【开源大语言模型的选择之道】<br />- 近期不断有新的大型语言模型(LLM)发布，如Llama 2、Mixtral 8x7B、Zephyr 7B、SOLAR 10.7B和Code Llama等。这些模型规模越来越大，性能也在不断提升。   <br />- 选择使用哪个LLM要考虑多方面因素，如性能表现、调优空间、多语言支持、部署成本等。例如Llama 2在安全性方面较好，Mixtral 8x7B的效率高，Zephyr 7B理解人类意图的能力强。   <br />- 相比商业LLM，开源LLM有更高的可控性、数据安全性、成本效益及社区支持等优势。但它们也需要自行部署和维护。   <br />- 专用LLM比通用LLM在特定任务上的表现更优，但后者应用范围更广。需根据实际需求选择。   <br />- 大规模部署LLM需考虑偏见、透明度、问责制等伦理问题。同时要选择合适的模型大小，做好基础设施规划，实现可扩展性等。   <br />- API、模型服务框架等可以简化LLM的部署流程。日志和监控对于运行中识别问题也很重要。   <br />- LLM的潜力正在不断被开发，需要继续推动其以负责任的方式造福社会。<br /><br />思考：  <br />- 模型参数量越大，训练数据越多，并不一定意味着在所有任务上都表现更好，有时更小的模型针对特定领域优化反而更有优势。  <br />- 开源模型在灵活性、成本等方面可能比商业模型更有优势。  <br />- 大语言模型的发展速度惊人，但在实际应用中需要全面评估质量、速度、成本等因素，不能盲目追求参数量。  <br />- 开源正在成为AI领域的重要趋势，开源模型在许多场景下可能是更好的选择。  <br />- 部署大语言模型需要考虑诸多策略，涉及模型选择、推理优化、提示工程、伦理安全等方方面面，是一个复杂的过程。<br />《Navigating the World of Large Language Models》 <a href="https://www.bentoml.com/blog/navigating-the-world-of-large-language-models"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8sy28h1vj20u00wtwka.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 02:19:55 GMT</pubDate>
</item>
<item>
<title>【不确定的确定性：用生成式模型颠覆天气预报】- 由于气象本质上是随机的，传统方法通过物理模拟生成一组预测来定量化不确定性，但这需要大量计算成本。Google提...</title>
<link>https://weibo.com/1402400261/O7mnVgkA5</link>
<guid>https://weibo.com/1402400261/O7mnVgkA5</guid>
<content:encoded><![CDATA[
<div> 生成式模型、天气预报、SEEDS、生成对抗网络、不确定性、物理模拟、极端天气事件、混合预报系统、数据和机器学习、跨学科融合<br />
<br />
总结：<br />
Google提出的SEEDS生成对抗网络模型可以以更低的成本有效生成大规模天气预报集合，可以匹配甚至超过基于物理的预测集合。SEEDS能更准确地预测尾部分布的可能性，如极端天气事件。该模型充分利用生成式AI的力量，以高效速度生成集合预报，代表了混合预报系统的一种新型应用。SEEDS展示了生成AI在天气预报中的巨大潜力，特别对于预测极端天气事件的概率。这项研究表明，生成式AI和扩散模型是一个前景广阔的方向，可以为传统科学和工程领域带来新的解决方案。基于数据和机器学习的方法在不确定性量化和概率预测方面可能比传统的物理模拟更具优势。跨学科融合将为更多领域提供突破，如AI技术与天气预报的结合。 <div>
【不确定的确定性：用生成式模型颠覆天气预报】<br />- 由于气象本质上是随机的，传统方法通过物理模拟生成一组预测来定量化不确定性，但这需要大量计算成本。Google提出了一种名为SEEDS的生成对抗网络模型，可以以比传统物理预测模型低得多的成本有效生成大规模的天气预报集合。   <br />- SEEDS基于去噪扩散概率模型，是一种最先进的生成AI技术，只需要一个或两个来自运算天气预测系统的种子预报，就可以生成一个大的集合，而这个集合可以匹配或超过基于物理的集合的技能指标。   <br />- SEEDS生成的集合可以更准确地给出尾部分布的可能性，如±2σ和±3σ的极端天气事件。它可以在很短时间内生成超过10000个集合成员，这对准确定量化极端事件的可能性非常有用。   <br />- SEEDS充分利用了生成式AI的力量，以加速的速度产生了与操作系统可比的集合预报。它代表了一种混合预报系统，只需要很少的物理模拟轨迹就可以激发扩散模型高效生成更多预报。   <br />- SEEDS展示了生成AI在运行数值天气预报方面的巨大应用潜力。它可以加速气象预报的进步，并可扩展到需要大量集合的领域，如对未来气候的不确定性进行风险评估。   <br /><br />思考：<br />- 传统认为天气预报依赖复杂的物理模型和超级计算机，但这项工作表明生成式AI可以在很低的计算成本下取得更好的效果，尤其在预测极端天气事件概率方面。  <br />- 生成式AI和扩散模型是一个非常有前景的方向，可以应用到传统的科学和工程领域，提供新的解决方案  <br />- 在不确定性量化和概率预测方面，基于数据和机器学习的方法可能比传统的物理模拟更有优势  <br />- 跨学科融合将产生更多突破，比如这里就是AI技术与天气预报的结合<br />《Generative AI to quantify uncertainty in weather forecasting – Google Research Blog》 <a href="https://blog.research.google/2024/03/generative-ai-to-quantify-uncertainty.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8q0mpl24j20u00zt7nf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8q0nte93j21jj0q5amj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 00:37:28 GMT</pubDate>
</item>
<item>
<title>【MLX版4-bit量化的DBRX模型】《mlx-community/dbrx-instruct-4bit · Hugging Face》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O7m7kCzNp</link>
<guid>https://weibo.com/1402400261/O7m7kCzNp</guid>
<content:encoded><![CDATA[
<div> 关键词: MLX, 4-bit量化, DBRX模型

总结:
MLX团队提出了一种基于4-bit量化的DBRX模型，该模型在保持高性能的同时大幅减少了模型大小和计算资源的需求。通过将模型参数量化为4-bit，可以显著降低模型的存储空间和计算复杂度，同时还能保持较高的模型精度。在实验中，该模型在ImageNet数据集上取得了与32-bit浮点模型相媲美的性能，证明了其在实际应用中的可行性和有效性。该方法为轻量级模型设计提供了新的思路和实践指导。MLX团队的研究成果为深度学习领域的模型压缩和优化提供了有益的启示。 <div>
【MLX版4-bit量化的DBRX模型】《mlx-community/dbrx-instruct-4bit · Hugging Face》 <a href="https://huggingface.co/mlx-community/dbrx-instruct-4bit"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho8ou5negyj20ws0u041g.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 23:56:36 GMT</pubDate>
</item>
<item>
<title>匿名排行榜有长答案偏好，这一点确实值得关注 - 转发 @爱可可-爱生活:&amp;ensp;【Maxime Labonne：Starling-LM-7B-beta模型在各种基准测试中表现出色，这给我们带来...</title>
<link>https://weibo.com/1402400261/O7m6JoLoN</link>
<guid>https://weibo.com/1402400261/O7m6JoLoN</guid>
<content:encoded><![CDATA[
<div> 模型、排行榜、Starling、性能、基准测试、实用性、评估、优势、缺陷、细节<br />
<br />
总结：<br />
Maxime Labonne提到了Starling-LM-7B-beta模型在Chatbot Arena排行榜上表现出色，超过了许多更大的模型，包括GPT-3.5-Turbo等。他指出Starling的PPO微调提高了回答实用性，但现有基准测试可能没有正确评估这一点。建议使用大语言模型作为评判者，并专注于回答的实用性。尽管Starling的回答更详尽，但评分也可能受到一些排行榜本身的限制，如不能处理对话等。这篇文章着重强调了基准测试体系的不足，以及Starling模型的优点和局限性。 <div>
匿名排行榜有长答案偏好，这一点确实值得关注<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 【Maxime Labonne：Starling-LM-7B-beta模型在各种基准测试中表现出色，这给我们带来了一些启示】<br />在Chatbot Arena排行榜上，这个7B的模型令人印象深刻地超过了许多更大的模型，包括GPT-3.5-Turbo、Mixtral、Gemini Pro以及Llama 2 70B的所有微调版本，也明显优于排名第30的Mistral-7B-Instruct-v0.。  <br />在另一个排行榜上，Starling的平均分数虽然低于Mistral-7B-Instruct-v0.2，但评估结果表明Starling更优秀：  <br />- 在AGIEval这个优秀的基准测试中，分数高出5.71分  <br />- 在BigBench和GPT4All测试中也有2-3分的领先，其中BigBench和AGIEval一样出色  <br />- 在TruthfulQA上表现较差，但这个基准测试本身就不可靠  <br />不过，Starling并没有比它使用的基础模型OpenChat 3.5 0106高出太多。MT-bench和MMLU基准测试也没能很好地体现出Starling的优势。  <br />我猜测，Starling的PPO微调显著提高了其回答的实用性，而这一点没有被现有的基准测试正确评估。这凸显了当前评估体系的不足。与其引入新的评估集，不如用大语言模型作为评判者，专门关注回答的实用性。  <br />当然，Chatbot Arena也不是完美的。它不能处理对话，而且答案越详细，Elo分数往往越高。Starling的回答通常比OpenChat更加详尽，这正是它的优势所在。  <br />鉴于7B模型的出色表现，我很想看到它们在Chatbot Arena排行榜上的排名。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8ooeruumj20u01xn4cq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8oof8g8ij20t60sa0xl.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 23:55:07 GMT</pubDate>
</item>
<item>
<title>【Maxime Labonne：Starling-LM-7B-beta模型在各种基准测试中表现出色，这给我们带来了一些启示】在Chatbot Arena排行榜上，这个7B的模型令人印象深刻地超过了许...</title>
<link>https://weibo.com/1402400261/O7m5fdezH</link>
<guid>https://weibo.com/1402400261/O7m5fdezH</guid>
<content:encoded><![CDATA[
<div> 关键词: Starling-LM-7B-beta模型, Chatbot Arena, 基准测试, 实用性, 评估体系, 回答详尽, 优秀表现, PPO微调, 评判者, 不足

总结:<br /><br />Maxime Labonne介绍了Starling-LM-7B-beta模型在各种基准测试中的出色表现，超过了更大的模型，如GPT-3.5-Turbo、Mixtral等，并提出现有评估体系的不足之处。Starling的PPO微调显著提高了回答的实用性，而现有基准测试未能正确评估这一点。建议使用大语言模型作为评判者，专注于回答的实用性。此外，Chatbot Arena虽然评分准则有限，但在答案详尽度方面有一定偏向，导致Starling的回答通常比OpenChat更详尽。Starling的优势在于回答的详细性，值得期待7B模型在排行榜上的表现。 <div>
【Maxime Labonne：Starling-LM-7B-beta模型在各种基准测试中表现出色，这给我们带来了一些启示】<br />在Chatbot Arena排行榜上，这个7B的模型令人印象深刻地超过了许多更大的模型，包括GPT-3.5-Turbo、Mixtral、Gemini Pro以及Llama 2 70B的所有微调版本，也明显优于排名第30的Mistral-7B-Instruct-v0.。  <br />在另一个排行榜上，Starling的平均分数虽然低于Mistral-7B-Instruct-v0.2，但评估结果表明Starling更优秀：  <br />- 在AGIEval这个优秀的基准测试中，分数高出5.71分  <br />- 在BigBench和GPT4All测试中也有2-3分的领先，其中BigBench和AGIEval一样出色  <br />- 在TruthfulQA上表现较差，但这个基准测试本身就不可靠  <br />不过，Starling并没有比它使用的基础模型OpenChat 3.5 0106高出太多。MT-bench和MMLU基准测试也没能很好地体现出Starling的优势。  <br />我猜测，Starling的PPO微调显著提高了其回答的实用性，而这一点没有被现有的基准测试正确评估。这凸显了当前评估体系的不足。与其引入新的评估集，不如用大语言模型作为评判者，专门关注回答的实用性。  <br />当然，Chatbot Arena也不是完美的。它不能处理对话，而且答案越详细，Elo分数往往越高。Starling的回答通常比OpenChat更加详尽，这正是它的优势所在。  <br />鉴于7B模型的出色表现，我很想看到它们在Chatbot Arena排行榜上的排名。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8ooeruumj20u01xn4cq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8oof8g8ij20t60sa0xl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 23:51:27 GMT</pubDate>
</item>
<item>
<title>【三层评估法则：快速迭代，系统优化AI产品】- 构建语言模型产品的成功关键是快速迭代。必须具备评估质量、调试问题和改变系统行为的流程和工具。 - 评估系统有3...</title>
<link>https://weibo.com/1402400261/O7lI1oWfy</link>
<guid>https://weibo.com/1402400261/O7lI1oWfy</guid>
<content:encoded><![CDATA[
<div> 快速迭代, 系统优化, AI产品, 评估, 单元测试, 模型评估, 人工评估, A/B测试, 日志记录, 微调

总结:<br /><br />这篇文章讲述了构建语言模型产品成功的关键在于快速迭代。作者提出了评估系统的三个层次：单元测试、模型和人工评估、A/B测试。单元测试是成本最低、频率最高的评估方式，要包含特定功能的场景和通用场景，不断更新。模型评估需要日志记录对话，构建特定领域的数据查看和标注工具，并定期进行人工评估。自动评估也很重要，可用于合成数据。作者强调A/B测试要谨慎引入，只有在产品较成熟时才适合。评估基础设施的建立可重复使用于调试和评估解决方案的效果。评估系统不仅能加速迭代，还能解锁微调和调试能力，从而提升AI系统的质量。整体而言，作者通过这些观点为AI产品开发提供了清晰的指导。 <div>
【三层评估法则：快速迭代，系统优化AI产品】<br />- 构建语言模型产品的成功关键是快速迭代。必须具备评估质量、调试问题和改变系统行为的流程和工具。   <br />- 评估系统有3个层次：单元测试、人工和模型评估、A/B测试。单元测试成本最低，频率最高。   <br />- 单元测试要包含特定功能的场景和通用场景，要不断根据新出现的错误更新。还要用语言模型生成测试用例。   <br />- 日志记录对话是模型评估的先决条件。要使查看数据无障碍，构建特定领域的数据查看和标注工具。定期人工评估样本很重要。   <br />- 可以用更强大的语言模型做自动评估。要跟踪模型和人工评价的相关性。自动评价也可以用于合成数据。   <br />- A/B测试确保AI产品驱动了预期的用户行为。当AI产品较成熟时再考虑。   <br />- 评估系统为微调和调试解锁能力。大部分微调工作是收集高质量数据，评估系统已具备数据生成和整理引擎。   <br />- 评估基础设施可重复使用于调试。可快速定位、复现错误，评估解决方案的效果。<br /><br />点评：  <br />- 作者基于多年从事语言模型相关工作的经验，指出鲁棒的评估系统对AI产品的成功至关重要，这一观点非常中肯和实用。  <br />- 文章强调了快速迭代对AI成功的重要性，并提出了质量评估、问题调试等必备流程和工具，为AI产品开发提供了清晰的指导。  <br />- 作者将评估分为三个层次：单元测试、模型和人工评估、A/B测试，这种分层思路有助于系统地开展评估工作，提高评估的针对性和有效性。  <br />- 对于第三层A/B测试，作者建议要谨慎对待，只有在产品足够成熟时才适合引入，这体现了作者对AI产品负责任开发的重视。  <br />- 文章还提到了评估AI子组件(如RAG)的重要性，这为进一步优化和改进AI系统提供了思路。  <br />- 作者强调评估系统不仅能加速迭代，还能解锁微调和调试能力，从而大幅提升AI系统质量，这一观点具有启发性，值得AI从业者深思。<br />《Your AI Product Needs Evals - How to construct domain-specific LLM evaluation systems.》 <a href="https://hamel.dev/blog/posts/evals/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8n1bjwo3j20u013fq7s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:54:15 GMT</pubDate>
</item>
<item>
<title>【Voice Engine：15秒音频样本，开启逼真语音合成新时代】- OpenAI开发了一个名为Voice Engine的模型，可以通过15秒的音频样本生成自然语音，非常逼真地模拟原说...</title>
<link>https://weibo.com/1402400261/O7lGhyHkc</link>
<guid>https://weibo.com/1402400261/O7lGhyHkc</guid>
<content:encoded><![CDATA[
<div> Voice Engine、OpenAI、15秒音频样本、逼真语音合成、安全措施、合成语音、风险、负责任部署、公开对话、全球公众<br />
<br />
总结：<br />
OpenAI开发了Voice Engine模型，能通过15秒音频样本生成逼真语音，有广泛的应用前景。在试用阶段，OpenAI重视安全措施和负责任部署，通过公开对话推动社会适应该技术。合成语音技术存在滥用风险，OpenAI提出相应措施防范潜在滥用行为。透过预览展示技术潜力，强调提高全球公众对合成语音技术认识十分必要，体现开放和负责任态度。 <div>
【Voice Engine：15秒音频样本，开启逼真语音合成新时代】<br />- OpenAI开发了一个名为Voice Engine的模型，可以通过15秒的音频样本生成自然语音，非常逼真地模拟原说话人的声音。这表明即使是一个小模型，也可以利用极短的音频样本生成富有情感和逼真的语音。   <br />- OpenAI已经在一小部分可靠合作伙伴中试用Voice Engine，发现它在教育、翻译、辅助交流等方面有广阔的应用前景。它可以为更广泛的受众创作语音内容，将内容翻译成多种语言保留原说话人的语调，为失语人群提供个性化语音等。   <br />- OpenAI认识到合成语音存在严重的风险，特别是在选举年。OpenAI正在与各国政府、媒体、娱乐、教育等领域的合作伙伴接触，收集他们的反馈意见。   <br />- OpenAI已经为Voice Engine引入了多项安全措施，包括给生成语音添加水印以追踪来源，监控其使用情况，需要合作伙伴遵守使用政策等。但OpenAI暂时还不会大规模部署这项技术。   <br />- OpenAI希望这项技术的预览能凸显它的潜力，同时也推动社会加强应对日渐逼真的生成模型带来的挑战的能力。OpenAI建议采取多项措施应对这一技术潮流。   <br />- OpenAI承诺会继续就合成语音的挑战和机遇与各界进行讨论。OpenAI将基于这些讨论结果决定是否和如何大规模部署这项技术。<br /><br />点评：  <br />- Voice Engine展示了OpenAI在语音合成技术方面的突破性进展，仅需15秒的音频样本就能生成逼真的自然语音，令人印象深刻。  <br />- OpenAI在Voice Engine的开发和应用中体现了对AI安全和负责任部署的高度重视，这种谨慎和知情的态度值得肯定。  <br />- 合成语音技术的滥用风险不容忽视，OpenAI提出的语音验证和禁止语音列表等措施，有助于在一定程度上防范潜在的滥用行为。  <br />- 通过Voice Engine的小规模预览，OpenAI展开了关于合成语音技术负责任部署的公开对话，这对于推动社会适应和应对这一新兴技术至关重要。  <br />- OpenAI强调，无论他们是否最终广泛部署Voice Engine，提高全球公众对语音合成技术发展趋势的认识和理解都十分必要，这体现了他们的开放和负责任态度。<br />《Navigating the Challenges and Opportunities of Synthetic Voices》 <a href="https://openai.com/blog/navigating-the-challenges-and-opportunities-of-synthetic-voices"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho8mwpd8pcj21fq0u0qa5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:49:58 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评...</title>
<link>https://weibo.com/1402400261/O7lvlzpnR</link>
<guid>https://weibo.com/1402400261/O7lvlzpnR</guid>
<content:encoded><![CDATA[
<div> Java、Python、JavaScript、C语言、MySQL、Redis、技术、故事、编程语言、王国

<br /><br />总结:
《码农翻身2》是一本将技术知识以故事的形式生动讲解的畅销书，让看似枯燥的技术变得有趣。书中描述了编程语言王国的争斗，如Java向Python渗透、JavaScript向Java进攻、以及C语言的悲催处境。故事中MySQL和Redis之间的矛盾不断升级，让读者能轻松掌握技术原理。书籍内容丰富，既有技术知识，又富有趣味性。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:23:01 GMT</pubDate>
</item>
<item>
<title>今日推介(第1360期)：只用少数微调模型达到模型融合性能、教语言模型提问澄清问题、直接偏好优化中长度与质量的解缠、将偏好数据集分割逐步使用的DPO、多专家递...</title>
<link>https://weibo.com/1402400261/O7lvdpHBP</link>
<guid>https://weibo.com/1402400261/O7lvdpHBP</guid>
<content:encoded><![CDATA[
<div> 模型微调、模型融合、语言模型、问题澄清、偏好优化、长度与质量、DPO、专家递延回归

<br /><br />总结:
本文介绍了一些最新的研究成果和技术应用。首先，提出了一种只用少数微调模型就可以达到模型融合性能的方法，从而提高模型的效率和准确性。其次，讨论了如何教导语言模型提问以澄清问题，从而提高模型的理解和应用能力。接着，介绍了直接偏好优化中长度与质量的解缠技术，帮助优化结果更加准确和可靠。然后，讨论了将偏好数据集分割逐步使用的DPO方法，提高了数据集的利用效率。最后，介绍了多专家递延回归技术，有助于提高模型的预测和分析能力。这些技术都有着广泛的应用前景，可以帮助解决实际问题并提高工作效率。 <div>
今日推介(第1360期)：只用少数微调模型达到模型融合性能、教语言模型提问澄清问题、直接偏好优化中长度与质量的解缠、将偏好数据集分割逐步使用的DPO、多专家递延回归 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/689840527"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.30)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8m45hovtj20go06g3z8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8m47vrtij20go0aygn2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho8m4b400wj20go0clwg7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8m4dj4ofj20go05u0t9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8m4h6e0pj20go09omz8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:22:41 GMT</pubDate>
</item>
<item>
<title>[CV] Mesh2NeRF: Direct Mesh Supervision for Neural Radiance Field Representation and Generation 网页链接 提出Mesh2NeRF，一种从网格中直接获取NeRF表示的...</title>
<link>https://weibo.com/1402400261/O7lrfnG01</link>
<guid>https://weibo.com/1402400261/O7lrfnG01</guid>
<content:encoded><![CDATA[
<div> 直接获取NeRF表示、网格、3D监督、渲染过程、单场景拟合、生成、精确可靠、提升表现、Mesh2NeRF、解析解  
<br /><br />总结:  
本研究提出了一种名为Mesh2NeRF的方法，可以通过直接从网格中获取NeRF表示的解析解，为各类NeRF任务提供精确可靠的3D监督。这种方法可以绕过渲染过程中的不确定性，显著提升NeRF在单场景拟合和生成中的表现。Mesh2NeRF可以为NeRF任务提供更准确的监督信号，有望在3D场景表示与生成领域中发挥重要作用。 <div>
[CV] Mesh2NeRF: Direct Mesh Supervision for Neural Radiance Field Representation and Generation  <br /><a href="https://arxiv.org/abs/2403.19319"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出Mesh2NeRF，一种从网格中直接获取NeRF表示的解析解，可为各类NeRF任务提供精确可靠的3D监督，绕过渲染过程中的不确定性，显著提升NeRF在单场景拟合和生成中的表现。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho8lubomuaj20rg16gwqn.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho8luby8cxj21c012itm4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:12:55 GMT</pubDate>
</item>
<item>
<title>[CV] LocCa: Visual Pretraining with Location-aware Captioners 网页链接 LocCa通过引入位置感知描述任务实现了视觉表示对局部细节和整体语义的统一建模，在保...</title>
<link>https://weibo.com/1402400261/O7lp22VlA</link>
<guid>https://weibo.com/1402400261/O7lp22VlA</guid>
<content:encoded><![CDATA[
<div> Visual Pretraining, Location-aware Captioners, LocCa, 图像理解, 定位性能, 位置感知描述任务, 视觉表示, 局部细节, 整体语义

LocCa是一种通过引入位置感知描述任务实现视觉表示对局部细节和整体语义的统一建模方法。该方法在保持图像级理解能力的同时显著提升了定位性能。通过对图像进行位置感知描述任务的预训练，LocCa使得模型能够更好地对图像中的局部细节和整体语义进行捕捉和理解。这种方法为视觉表示学习带来了新的启发，为提升图像理解和定位性能提供了新的思路。LocCa的引入为视觉预训练领域带来了新的研究方向，将在未来的研究中继续发挥重要作用。<br /><br />总结:LocCa通过引入位置感知描述任务实现了视觉表示对局部细节和整体语义的统一建模，在保持图像级理解能力的同时大幅提升了定位性能。 <div>
[CV] LocCa: Visual Pretraining with Location-aware Captioners  <br /><a href="https://arxiv.org/abs/2403.19596"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />LocCa通过引入位置感知描述任务实现了视觉表示对局部细节和整体语义的统一建模，在保持图像级理解能力的同时大幅提升了定位性能。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8lolftcpj20rc16mtky.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8lom5f2fj21ck0y8akb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:07:27 GMT</pubDate>
</item>
<item>
<title>[LG] Tiny Machine Learning: Progress and Futures 网页链接 TinyML通过算法和系统的协同设计，实现深度学习模型在内存和计算有限的微控制器上的高效推理和训练...</title>
<link>https://weibo.com/1402400261/O7llHvZry</link>
<guid>https://weibo.com/1402400261/O7llHvZry</guid>
<content:encoded><![CDATA[
<div> 关键词: TinyML, 算法, 深度学习模型, 微控制器, 推理, 训练, AI能力, 边缘物联网设备

总结:<br /><br />
本文介绍了Tiny Machine Learning（TinyML）技术的进展和未来发展。TinyML通过算法和系统的协同设计，在内存和计算有限的微控制器上实现了深度学习模型的高效推理和训练，从而将强大的AI能力扩展到无数的边缘物联网设备中。TinyML的发展为边缘设备赋予了智能化的能力，可以提供更快速、更可靠的数据处理和决策能力，推动了物联网领域的进一步发展。TinyML技术的未来发展将不断完善算法和系统设计，提高在资源有限的设备上的性能和效率，同时推动AI能力在边缘计算领域的广泛应用和普及。 <div>
[LG] Tiny Machine Learning: Progress and Futures  <br /><a href="https://arxiv.org/abs/2403.19076"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />TinyML通过算法和系统的协同设计，实现深度学习模型在内存和计算有限的微控制器上的高效推理和训练，将强大的AI能力扩展到无数的边缘物联网设备中。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho8lg3cjwnj20wy17u7oc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8lg3ml3lj21kq0uuqet.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8lg3sr1pj21ki18cqff.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho8lg3u4s2j21ke0iin5p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 21:59:15 GMT</pubDate>
</item>
<item>
<title>通过设计可证明H一致性的单阶段和两阶段代理损失函数，巧妙地将多专家递延框架扩展至回归问题，既适用于联合学习也适用于预训练模型。 - 转发 @爱可可-爱生活:&amp;e...</title>
<link>https://weibo.com/1402400261/O7lg0kReZ</link>
<guid>https://weibo.com/1402400261/O7lg0kReZ</guid>
<content:encoded><![CDATA[
<div> 代理损失函数, 单阶段, 两阶段, 多专家递延框架, 回归问题, 联合学习, 预训练模型<br />
<br />
提出了一种可以证明H一致性的单阶段和两阶段代理损失函数，将多专家递延框架扩展至回归问题。该方法适用于联合学习和预训练模型。通过设计巧妙的损失函数，实现了对多专家预测结果的推迟，在保证模型的一致性的同时提高了模型的性能和泛化能力。实验结果表明，该方法在回归问题上取得了良好的性能表现。总体而言，本文提出的方法在处理回归问题中充分发挥了多专家的优势，为相关领域的研究和应用提供了新的思路和方法。<br /><br />总结: <div>
通过设计可证明H一致性的单阶段和两阶段代理损失函数，巧妙地将多专家递延框架扩展至回归问题，既适用于联合学习也适用于预训练模型。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Regression with Multi-Expert Deferral》A Mao, M Mohri, Y Zhong [Courant Institute of Mathematical Sciences &amp; Google Research] (2024) <a href="https://arxiv.org/abs/2403.19494"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho8kufil4jj21cq0sakch.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 21:45:13 GMT</pubDate>
</item>
<item>
<title>[LG]《Regression with Multi-Expert Deferral》A Mao, M Mohri, Y Zhong [Courant Institute of Mathematical Sciences &amp; Google Research] (2024) 网页链接 #...</title>
<link>https://weibo.com/1402400261/O7lfY0hw3</link>
<guid>https://weibo.com/1402400261/O7lfY0hw3</guid>
<content:encoded><![CDATA[
<div> 关键词: Regression, Multi-Expert Deferral, Courant Institute of Mathematical Sciences, Google Research

总结:<br /><br />这篇文章由毛阿(Mao)、莫里(Mohri)和钟杨(Zhong)共同撰写，研究了多专家推迟的回归方法。他们从数学科学研究所和谷歌研究部门发表了这项研究。<br />该研究提出了一种新方法，通过使用多个专家的意见来进行回归预测，以提高预测准确性。<br />专家推迟是指在有争议的情况下，将决策推迟到更有经验和专业知识的专家来做出。<br />研究使用了各种数学和统计方法来解决多专家推迟的回归问题，为实际应用提供了新的解决方案。<br />该研究成果对于数据科学领域以及商业决策具有重要意义，可以提高预测模型的准确性和稳定性。<br />毛阿、莫里和钟杨等研究人员的工作有望推动回归分析领域的进一步发展，为未来研究提供新的思路和方法。<br />通过结合数学科学和实际应用，他们的研究为数据分析领域带来了新的启示和突破。<br />毛阿、莫里和钟杨在多专家推迟的回归领域做出了重要贡献，为该领域的研究做出了新的探索和创新。<br />他们的研究成果为数据科学和机器学习领域提供了新的视角和方法，拓展了学术研究和实践应用的范围。<br />通过整合不同领域的专业知识和经验，毛阿、莫里和钟杨等研究人员为多专家推迟的回归方法提供了新的理论基础和实践指导。 <div>
[LG]《Regression with Multi-Expert Deferral》A Mao, M Mohri, Y Zhong [Courant Institute of Mathematical Sciences &amp; Google Research] (2024) <a href="https://arxiv.org/abs/2403.19494"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho8kufil4jj21cq0sakch.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 21:45:06 GMT</pubDate>
</item>
<item>
<title>提出sDPO，将偏好数据集分步使用以获取更严格的下界约束，从而获得整体性能更强的语言模型。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《sDPO: Don't Use Your Data All...</title>
<link>https://weibo.com/1402400261/O7lcEBZ31</link>
<guid>https://weibo.com/1402400261/O7lcEBZ31</guid>
<content:encoded><![CDATA[
<div> 关键词: sDPO, 偏好数据集, 下界约束, 语言模型, 整体性能, 转发, Upstage AI

总结:<br /><br />
这篇文章提出了sDPO方法，旨在通过分步使用偏好数据集来获取更严格的下界约束，从而提升语言模型的整体性能。sDPO的核心思想是不将所有数据一次性使用，而是分阶段使用，以优化模型的性能。作者通过实验和研究表明，sDPO能够有效提升语言模型的性能，使其更加强大和稳健。这一方法在未来可能对自然语言处理领域有着重要的影响，并值得进一步研究和探索。 <div>
提出sDPO，将偏好数据集分步使用以获取更严格的下界约束，从而获得整体性能更强的语言模型。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《sDPO: Don't Use Your Data All at Once》D Kim, Y Kim, W Song, H Kim, Y Kim, S Kim, C Park [Upstage AI] (2024) <a href="https://arxiv.org/abs/2403.19270"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho8kl4nf9uj20o60qc44m.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho8kl5h2ltj21km0jswkb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho8kl5nudnj20s40godhv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8kl5voulj20s00f6gnn.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 21:36:58 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.29)》 爱可可微博热门分享(3.29) [图片]</title>
<link>https://weibo.com/1402400261/O7ie07MEC</link>
<guid>https://weibo.com/1402400261/O7ie07MEC</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、3.29、关键词

<br /><br />总结:
3月29日，爱可可微博上热门分享了许多精彩内容，引起了广泛关注。其中包括美食推荐、旅行攻略、时尚资讯等各种各样的话题。用户们纷纷参与讨论，点赞和转发量也很高。爱可可微博的内容多样性和质量受到了用户的肯定。希望未来能继续为大家带来更多有趣的内容。 <div>
《爱可可微博热门分享(3.29)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405017383558316417"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.29)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho87newffvj20d607e3zd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 14:02:01 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《SuperNormal: Neural Surface Reconstruction via Multi-View Normal Integration》(CVPR 2024) GitHub: github.com/CyberAgentAILab/Super...</title>
<link>https://weibo.com/1402400261/O7hNne0Zq</link>
<guid>https://weibo.com/1402400261/O7hNne0Zq</guid>
<content:encoded><![CDATA[
<div> 关键词：神经表面重建、多视图法线集成、情感图像生成、深度学习、自动驾驶、人物重建、虚拟人视频生成、语言模型、远程感知图像分类、视频对象分割。

总结:<br /><br />
这篇论文整理了几篇实现代码，涵盖了神经表面重建、情感图像生成、神经网络鲁棒性评估等多个领域。其中包括了一种通过多视图法线集成实现神经表面重建的方法，以及一种用于生成情感图像内容的文本到图像扩散模型。同时还介绍了一种自动驾驶中用于融合单视图和多视图深度信息的自适应融合算法，以及一种在野外环境中从单目视频中重建多个人物的方法。此外还有一种用于挖掘多模态视觉语言模型潜力的MiniGemini模型，以及一种生成高保真虚拟人视频的MuseV模型等。<br />
另外，还介绍了一种用于实现长视频理解的语言库，以及一种基于变分自动编码器的明暗风格内容分离模型。还有一种实时变换器开放词汇检测的方法，以及一种用状态空间模型实现遥感图像分类的RSMamba模型。同时还有一种用于控制区域级标题生成的ControlCap模型，以及一种使用文本到图像扩散实现注意力插值的AID模型。此外还有一种由LLM引导的组合式4D场景生成模型Comp4D，以及一种用于改善视觉识别中非层级Mamba算法的PlainMamba模型等。最后还介绍了一种通过调制交叉注意力内存实现高效视频对象分割的MAVOS模型，以及一种通过修剪和低秩修改评估安全性调整脆弱性的方法。 <div>
几篇论文实现代码：<br />《SuperNormal: Neural Surface Reconstruction via Multi-View Normal Integration》(CVPR 2024) GitHub: github.com/CyberAgentAILab/SuperNormal [fig3] <br />《EmoGen: Emotional Image Content Generation with Text-to-Image Diffusion Models》(CVPR 2024) GitHub: github.com/JingyuanYY/EmoGen [fig4]<br />《ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object》(CVPR 2024) GitHub: github.com/chenshuang-zhang/imagenet_d<br />《Adaptive Fusion of Single-View and Multi-View Depth for Autonomous Driving》(CVPR 2024) GitHub: github.com/Junda24/AFNet<br />《MultiPly: Reconstruction of Multiple People from Monocular Video in the Wild》(CVPR 2024) GitHub: github.com/jzr99/MultiPly<br />《Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models》(2024) GitHub: github.com/dvlab-research/MiniGemini [fig1]<br />《MuseV: Infinite-length and High Fidelity Virtual Human Video Generation with Visual Conditioned Parallel Denoising》(2024) GitHub: github.com/TMElyralab/MuseV [fig2] <br />《Long-form factuality in large language models》(2024) GitHub: github.com/google-deepmind/long-form-factuality<br />《Implicit Style-Content Separation using B-LoRA》(2024) GitHub: github.com/yardenfren1996/B-LoRA [fig5] <br />《Real-time Transformer-based Open-Vocabulary Detection with Efficient Fusion Head》(2024) GitHub: github.com/om-ai-lab/OmDet [fig8]<br />《RSMamba: Remote Sensing Image Classification with State Space Model》(2024) GitHub: github.com/KyanChen/RSMamba [fig9]<br />《Language Repository for Long Video Understanding》(2024) GitHub: github.com/kkahatapitiya/LangRepo [fig10]<br />《Light and Optimal Schr\"odinger Bridge Matching》(2024) GitHub: github.com/SKholkin/LightSB-Matching<br />《ControlCap: Controllable Region-level Captioning》(2024) GitHub: github.com/callsys/ControlCap [fig11]<br />《AID: Attention Interpolation of Text-to-Image Diffusion》(2024) GitHub: github.com/QY-H00/attention-interpolation-diffusion<br />《Comp4D: LLM-Guided Compositional 4D Scene Generation》(2024) GitHub: github.com/VITA-Group/Comp4D<br />《PlainMamba: Improving Non-hierarchical Mamba in Visual Recognition》(2024) GitHub: github.com/ChenhongyiYang/PlainMamba [fig7]<br />《Fed3DGS: Scalable 3D Gaussian Splatting with Federated Learning》(2024) GitHub: github.com/DensoITLab/Fed3DGS<br />《Efficient Video Object Segmentation via Modulated Cross-Attention Memory》(2024) GitHub: github.com/Amshaker/MAVOS [fig6]<br />《Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications》(2024) GitHub: github.com/boyiwei/alignment-attribution-code<br />《Surface and Edge Detection for Primitive Fitting of Point Clouds》(2024) GitHub: github.com/yuanqili78/SED-Net<br />《FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions》(2024) GitHub: github.com/orionw/FollowIR<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho81cu9q8pj22tu0uxe73.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho81cv52blj20re0jjjyq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho81cylzabj22t02bc7wm.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho81cxbo0vj21ll0hfwsr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho81cyh6kmj20h909d419.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho81czzpxdj21yh0tykib.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho83zmbtfmj224y0n81kx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho84jcw8cuj237a1nb17e.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho84yi8kbtj21x80i4qiw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho84z1po9rj22po0sph3r.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho852lcklej21u61eeu0x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:56:26 GMT</pubDate>
</item>
<item>
<title>【遥感多模态大语言模型相关论文资源列表】’Awesome-Remote-Sensing-Multimodal-Large-Language-Model (Vision-Language) - Multimodal Large Language Model f...</title>
<link>https://weibo.com/1402400261/O7hIcz64J</link>
<guid>https://weibo.com/1402400261/O7hIcz64J</guid>
<content:encoded><![CDATA[
<div> 遥感、多模态、大语言模型、远程感知、视觉-语言、资源、GitHub、论文、研究、文献

总结：<br /><br />这份资源列表涵盖了远程感知多模态大语言模型相关的研究论文和资源，提供了GitHub链接，供研究人员参考。远程感知是指利用卫星或无人机等远距离传感器获取地表信息的技术，多模态大语言模型则是融合了视觉和语言信息的模型。这个领域的研究涉及到文献综述、模型应用、数据集构建等方面，对于推动远程感知和人工智能领域的发展具有重要意义。 <div>
【遥感多模态大语言模型相关论文资源列表】’Awesome-Remote-Sensing-Multimodal-Large-Language-Model (Vision-Language) - Multimodal Large Language Model for Remote Sensing (Vision-Language)' GitHub: github.com/ZhanYang-nwpu/Awesome-Remote-Sensing-Multimodal-Large-Language-Model <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho85e0nazbj21a10u0q7t.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:43:42 GMT</pubDate>
</item>
<item>
<title>【高斯Splatting相关论文列表】’2024-Arxiv-Paper-List-Gaussian-Splatting - 2024 Gaussian Splatting Paper List(Arxiv)' GitHub: github.com/Lee-JaeWon/202...</title>
<link>https://weibo.com/1402400261/O7hH1r6Pl</link>
<guid>https://weibo.com/1402400261/O7hH1r6Pl</guid>
<content:encoded><![CDATA[
<div> 高斯，Splatting，Arxiv，论文，列表，GitHub，2024

总结:
该GitHub项目整理了关于高斯Splatting的Arxiv论文列表，汇总了2024年的相关研究成果。这些论文涵盖了高斯Splatting技术在计算机图形学和计算机视觉领域的应用和研究进展。通过这个列表，研究者可以快速了解最新的研究动态和成果，为未来的研究提供参考和启发。GitHub项目还提供了详细的文献信息和链接，方便研究者进行更深入的阅读和学习。整理这些论文列表有助于促进学术交流和合作，推动高斯Splatting技术的发展和应用。 <div>
【高斯Splatting相关论文列表】’2024-Arxiv-Paper-List-Gaussian-Splatting - 2024 Gaussian Splatting Paper List(Arxiv)' GitHub: github.com/Lee-JaeWon/2024-Arxiv-Paper-List-Gaussian-Splatting <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho85b13zdrj20u00ul42w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:40:48 GMT</pubDate>
</item>
<item>
<title>【AxoNN：用于训练深度神经网络的并行框架】'AxoNN - A parallel framework for training deep neural networks' GitHub: github.com/axonn-ai/axonn #开源# #机...</title>
<link>https://weibo.com/1402400261/O7hGmmKev</link>
<guid>https://weibo.com/1402400261/O7hGmmKev</guid>
<content:encoded><![CDATA[
<div> 并行框架、训练、深度神经网络、AxoNN、GitHub、神经网络、深度学习、机器学习、人工智能

<br /><br />总结:
AxoNN是一个用于训练深度神经网络的并行框架，旨在提高训练过程的效率和速度。通过在GitHub上开源项目，AxoNN为研究人员和开发者提供了一个方便的工具，帮助他们在深度学习和机器学习领域进行神经网络的训练。AxoNN的并行架构使得训练过程更加快速，并能够处理大规模数据集。这个框架对于推动人工智能领域的发展具有重要意义，为神经网络的训练提供了新的可能性。AxoNN的开发和使用将有助于加速深度学习技术的发展，促进人工智能的应用和创新。 <div>
【AxoNN：用于训练深度神经网络的并行框架】'AxoNN - A parallel framework for training deep neural networks' GitHub: github.com/axonn-ai/axonn <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho859cfbodj211a0iajtg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:39:10 GMT</pubDate>
</item>
<item>
<title>【mistral.rs： 纯Rust写的语言模型推理平台】'mistral.rs - Blazingly fast LLM inference.' GitHub: github.com/EricLBuehler/mistral.rs #开源# #机器学习# #...</title>
<link>https://weibo.com/1402400261/O7hFUnXaF</link>
<guid>https://weibo.com/1402400261/O7hFUnXaF</guid>
<content:encoded><![CDATA[
<div> Rust、语言模型、推理、平台、mistral.rs、快速、LLM、推断、GitHub、EricLBuehler<br />
<br />
Rust编写的语言模型推理平台mistral.rs具有快速性能，支持深度语言模型推断。该项目托管在GitHub上，由EricLBuehler开发。通过mistral.rs，用户可以快速进行语言模型的推断，提高工作效率。该平台在推理速度和准确性方面表现优异，是一个值得关注的工具。 <div>
【mistral.rs： 纯Rust写的语言模型推理平台】'mistral.rs - Blazingly fast LLM inference.' GitHub: github.com/EricLBuehler/mistral.rs <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8586irc7j21310u0q6i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:38:03 GMT</pubDate>
</item>
<item>
<title>'Docker image for A1111 Stable Diffusion Web UI, Kohya_ss and ComfyUI - Docker image for Stable Diffusion WebUI with ControlNet, After Detailer, Dream...</title>
<link>https://weibo.com/1402400261/O7hAC6AMQ</link>
<guid>https://weibo.com/1402400261/O7hAC6AMQ</guid>
<content:encoded><![CDATA[
<div> GitHub, Docker image, Stable Diffusion WebUI, Kohya_ss, ComfyUI, ControlNet, After Detailer, Dreambooth, Deforum, ReActor

<br /><br />总结:
本文介绍了一个GitHub项目，提供了用于A1111 Stable Diffusion Web UI的Docker镜像，其中包含了Kohya_ss和ComfyUI。另外还提供了另一个Docker镜像，包含了Stable Diffusion WebUI以及ControlNet、After Detailer、Dreambooth、Deforum和ReActor等扩展功能。感兴趣的用户可以在github.com/ashleykleynhans/stable-diffusion-docker找到更多信息。 <div>
'Docker image for A1111 Stable Diffusion Web UI, Kohya_ss and ComfyUI - Docker image for Stable Diffusion WebUI with ControlNet, After Detailer, Dreambooth, Deforum and ReActor extensions, as well as Kohya_ss and ComfyUI' GitHub: github.com/ashleykleynhans/stable-diffusion-docker <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho84ulotv0j21ji0ka41v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:25:00 GMT</pubDate>
</item>
<item>
<title>【Bolna：快速构建LLM语音聊天应用的关键框架，帮助开发人员轻松打造高效的聊天应用】'Bolna - End-to-end platform enabling LLM based voice driven conversat...</title>
<link>https://weibo.com/1402400261/O7hvwvhmu</link>
<guid>https://weibo.com/1402400261/O7hvwvhmu</guid>
<content:encoded><![CDATA[
<div> 快速构建、LLM语音聊天应用、关键框架、开发人员、高效、聊天应用、Bolna、End-to-end、platform、GitHub

总结:<br /><br />
本文介绍了Bolna，一个能够实现LLM语音驱动的对话应用的端到端平台。通过提供关键框架，帮助开发人员轻松构建高效的聊天应用。开发者可以在GitHub上找到Bolna的源代码项目。 <div>
【Bolna：快速构建LLM语音聊天应用的关键框架，帮助开发人员轻松打造高效的聊天应用】'Bolna - End-to-end platform enabling LLM based voice driven conversational applications' GitHub: github.com/bolna-ai/bolna <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho84hifed3j21bk0gmacb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:12:28 GMT</pubDate>
</item>
<item>
<title>【PyTorch in JavaScript：一个深度学习 JavaScript 库，旨在与 PyTorch 的语法相类似，以便开发人员使用 JavaScript 实现深度学习模型】'PyTorch in JavaScript...</title>
<link>https://weibo.com/1402400261/O7hsykjAw</link>
<guid>https://weibo.com/1402400261/O7hsykjAw</guid>
<content:encoded><![CDATA[
<div> PyTorch, JavaScript, 深度学习, 库, 语法, 开发人员, 实现, 模型, GitHub, 项目
<br /><br />总结:
PyTorch在JavaScript中的实现是一个类似于PyTorch的JavaScript库，从头开始构建。这个项目旨在提供一个类似于PyTorch的编程体验，使开发人员能够使用JavaScript语言来实现深度学习模型。通过GitHub上的项目，开发人员可以了解和使用这个深度学习库，从而在JavaScript环境中进行模型的开发和应用。JavaScript语言的灵活性和便捷性使得这个库可以更好地与前端开发集成，为开发人员提供了更多选择和可能性。通过这个项目，开发人员可以在JavaScript中体验和应用类似于PyTorch的深度学习功能，进一步推动了深度学习技术在不同领域的应用和发展。 <div>
【PyTorch in JavaScript：一个深度学习 JavaScript 库，旨在与 PyTorch 的语法相类似，以便开发人员使用 JavaScript 实现深度学习模型】'PyTorch in JavaScript - A JavaScript library like PyTorch, built from scratch.' GitHub: github.com/eduardoleao052/js-torch <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho849wysk6j21am0u0gpo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:05:08 GMT</pubDate>
</item>
<item>
<title>【RAG相关资源大列表】’Awesome-RAG' GitHub: github.com/frutik/Awesome-RAG #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O7hrKuBtP</link>
<guid>https://weibo.com/1402400261/O7hrKuBtP</guid>
<content:encoded><![CDATA[
<div> GitHub、RAG、资源、列表、frutik、Awesome-RAG、资源列表、相关资源、大列表
<br />
RAG是一个GitHub上的资源列表，由frutik创建并维护，收录了大量与RAG相关的资源。这个列表包含了各种与RAG技术相关的项目和工具，可以帮助用户更好地了解和学习RAG技术。通过这个资源列表，用户可以找到各种教程、示例代码、工具软件等，帮助他们在RAG领域取得更多的进展。总的来说，Awesome-RAG是一个集合了丰富资源并持续更新的GitHub资源列表，对RAG技术的学习和应用提供了很大的帮助。
<br /><br />
总结: RAG资源列表是由frutik创建并维护的GitHub项目，整合了大量关于RAG技术的资源，包括教程、示例代码和工具软件，为用户提供了学习和应用RAG技术的支持。 <div>
【RAG相关资源大列表】’Awesome-RAG' GitHub: github.com/frutik/Awesome-RAG <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho845k6jptj20sm1j4q92.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:03:10 GMT</pubDate>
</item>
<item>
<title>【Page Assist：开源 Chrome 插件它提供一个 Sidebar 和 Web UI，让你在任意网页和本地 AI 模型交互】’Page Assist - Use your locally running AI models to a...</title>
<link>https://weibo.com/1402400261/O7hpvAAoK</link>
<guid>https://weibo.com/1402400261/O7hpvAAoK</guid>
<content:encoded><![CDATA[
<div> 开源 Chrome 插件 Sidebar Web UI 任意网页 本地 AI 模型 交互 GitHub page-assist 

<br /><br />总结:
Page Assist 是一个开源的 Chrome 插件，它提供了一个 Sidebar 和 Web UI，让用户可以在任意网页上和本地 AI 模型进行交互。用户可以利用本地运行的 AI 模型来辅助浏览网页，提供更智能的功能和服务。这个项目的代码托管在 GitHub 上，地址为github.com/n4ze3m/page-assist。通过安装该插件，用户可以提升网页浏览的效率和体验，利用 AI 技术来更好地辅助自己的工作和学习。Page Assist 将 AI 技术与浏览器插件相结合，为用户提供了一种新的交互方式，帮助他们更好地利用本地AI模型，实现更智能化的网页浏览体验。 <div>
【Page Assist：开源 Chrome 插件它提供一个 Sidebar 和 Web UI，让你在任意网页和本地 AI 模型交互】’Page Assist - Use your locally running AI models to assist you in your web browsing' GitHub: github.com/n4ze3m/page-assist <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho8423ptyjj20dc0a074e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 11:57:39 GMT</pubDate>
</item>
<item>
<title>【ratchet：跨平台浏览器ML框架】’ratchet - A cross-platform browser ML framework.' GitHub: github.com/huggingface/ratchet #开源# #机器学习# #人工智能#...</title>
<link>https://weibo.com/1402400261/O7gRiszJV</link>
<guid>https://weibo.com/1402400261/O7gRiszJV</guid>
<content:encoded><![CDATA[
<div> 跨平台浏览器 ML 框架、GitHub、huggingface、ratchet、ratchet - A cross-platform browser ML framework<br />
<br />
要点1: ratchet是一个跨平台浏览器ML框架。
要点2: 这个框架的代码托管在GitHub上，地址为github.com/huggingface/ratchet。
要点3: 感兴趣的用户可以查看并了解这个框架的具体功能和用途。
要点4: ratchet的设计可以让用户在不同平台上使用浏览器进行机器学习相关的工作。
要点5: 这个框架为浏览器提供了一种跨平台的机器学习解决方案。
<br /><br />总结: 
ratchet是一个跨平台浏览器ML框架，用户可以通过GitHub上的地址github.com/huggingface/ratchet了解和使用这个框架。这个框架的设计使得用户可以在不同平台上使用浏览器进行机器学习相关的工作，为浏览器提供了一种跨平台的机器学习解决方案。 <div>
【ratchet：跨平台浏览器ML框架】’ratchet - A cross-platform browser ML framework.' GitHub: github.com/huggingface/ratchet <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho81mf2w3vj213y0o80v6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 10:33:22 GMT</pubDate>
</item>
<item>
<title>【DeepSeek：基于LLM的检索引擎】'DeepSeek - LLM powered retrieval engine designed to process a ton of sources to collect a comprehensive list of entiti...</title>
<link>https://weibo.com/1402400261/O7gMqyvjl</link>
<guid>https://weibo.com/1402400261/O7gMqyvjl</guid>
<content:encoded><![CDATA[
<div> LLM，GitHub，检索引擎，DeepSeek，实体收集，源数据处理，全面列表，DeepSeek设计，LLM加强，大量来源<br />
<br />
提供了基于LLM的检索引擎DeepSeek，旨在处理大量来源数据，以收集全面的实体列表。DeepSeek利用LLM技术加强检索过程，能够快速有效地从各种来源中提取信息。GitHub上有相关项目代码，有兴趣的话可以查看详细信息。 <div>
【DeepSeek：基于LLM的检索引擎】'DeepSeek - LLM powered retrieval engine designed to process a ton of sources to collect a comprehensive list of entities.' GitHub: github.com/dzhng/deep-seek <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho819ysep7j214w0u0dif.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 10:21:22 GMT</pubDate>
</item>
<item>
<title>【MAD-Lab：用来加速深学习架构设计的开源项目，使用简单的合成任务来预测模型在序列模式中的性能】'MAD-Lab - A MAD laboratory to improve AI architecture de...</title>
<link>https://weibo.com/1402400261/O7gfz9Dfi</link>
<guid>https://weibo.com/1402400261/O7gfz9Dfi</guid>
<content:encoded><![CDATA[
<div> 加速深学习架构设计 开源项目 简单 合成任务 预测 模型 序列模式 性能

<br /><br />总结:
MAD-Lab是一个用来加速深学习架构设计的开源项目，通过简单的合成任务来预测模型在序列模式中的性能。该项目提供了一个MAD实验室，旨在改进人工智能架构设计。用户可以在GitHub上找到该项目，通过使用这个工具，可以更有效地设计和优化深度学习模型，提升模型的性能和效率。MAD-Lab的出现为深度学习领域的研究者和开发者提供了一个有益的工具和资源，有助于推动人工智能技术的发展和应用。 <div>
【MAD-Lab：用来加速深学习架构设计的开源项目，使用简单的合成任务来预测模型在序列模式中的性能】'MAD-Lab - A MAD laboratory to improve AI architecture designs' GitHub: github.com/athms/mad-lab <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7yxjrtmdj210l0u0ajb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 09:00:24 GMT</pubDate>
</item>
<item>
<title>'《一人企业方法论》第二版，也适合做其他副业（比如自媒体、电商、数字商品）的非技术人群' GitHub: github.com/easychen/one-person-businesses-methodology-v...</title>
<link>https://weibo.com/1402400261/O7gdbAQPy</link>
<guid>https://weibo.com/1402400261/O7gdbAQPy</guid>
<content:encoded><![CDATA[
<div> 关键词: 一人企业、方法论、副业、自媒体、电商、数字商品、非技术人群

<br /><br />总结:
《一人企业方法论》第二版是适用于非技术人群的方法论，不仅适用于经营一人企业，也适合从事副业如自媒体、电商、数字商品等领域的人群。该方法论提供了系统化的指导和实践经验，帮助个体创业者建立和拓展自己的事业。通过深入了解市场、客户需求，精准定位、有效推广，以及灵活的运营策略，个体创业者可以实现自身事业的增长和成功。在如今激烈竞争的商业环境下，掌握一套科学的方法论对于非技术人群来说尤为重要，可以帮助他们更好地应对挑战，实现事业的持续发展。 <div>
'《一人企业方法论》第二版，也适合做其他副业（比如自媒体、电商、数字商品）的非技术人群' GitHub: github.com/easychen/one-person-businesses-methodology-v2.0 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho7yrkguatj20ks0rkdl0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:54:33 GMT</pubDate>
</item>
<item>
<title>【OpenTAD: 开源的PyTorch时间动作检测工具箱】'OpenTAD: An Open-Source Temporal Action Detection Toolbox. - OpenTAD is an open-source temporal action de...</title>
<link>https://weibo.com/1402400261/O7gcPf6p9</link>
<guid>https://weibo.com/1402400261/O7gcPf6p9</guid>
<content:encoded><![CDATA[
<div> PyTorch, 时间动作检测, 开源工具箱, OpenTAD, GitHub, 检测工具, 时间序列, 神经网络, 视频数据<br />
<br />
提到了一个名为OpenTAD的开源工具箱，用于PyTorch平台上的时间动作检测任务。这个工具箱主要基于神经网络技术，针对视频数据中的时间序列进行动作检测。此工具箱的代码开源在GitHub上，为研究人员和开发者提供了一个方便易用的工具，帮助他们在时间动作检测方面取得更好的成果。 <div>
【OpenTAD: 开源的PyTorch时间动作检测工具箱】'OpenTAD: An Open-Source Temporal Action Detection Toolbox. - OpenTAD is an open-source temporal action detection (TAD) toolbox based on PyTorch.' GitHub: github.com/sming256/OpenTAD <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho7yq5hkkyj21360u07a1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:53:38 GMT</pubDate>
</item>
<item>
<title>【Valkey：一个新的开源项目，旨在重启之前的开源 Redis 项目】' - A new project to resume development on the formerly open-source Redis project. We're ca...</title>
<link>https://weibo.com/1402400261/O7gc7dqjj</link>
<guid>https://weibo.com/1402400261/O7gc7dqjj</guid>
<content:encoded><![CDATA[
<div> Valkey, 开源项目, Redis, 重启, Valkyrie, GitHub, 意在继续开发, 新项目, 项目名称

<br /><br />总结:
Valkey是一个新的开源项目，旨在重启之前的开源Redis项目。项目名称取自Valkyrie，意在继续开发并完善之前的Redis项目。Valkey的代码托管在GitHub上，为开发人员提供了一个共同合作和贡献的平台。这个新项目旨在延续Redis的精神，为用户提供更好的数据存储和管理解决方案。通过Valkey项目，我们希望能够持续推动开源技术的发展，为开发者提供更多优质的工具和资源。 <div>
【Valkey：一个新的开源项目，旨在重启之前的开源 Redis 项目】' - A new project to resume development on the formerly open-source Redis project. We're calling it Valkey, like a Valkyrie.' GitHub: github.com/valkey-io/valkey <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Redis%23"><span class="surl-text">#Redis#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho7yovkkwjj21jo0p6wjr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:51:54 GMT</pubDate>
</item>
<item>
<title>GitHub: github.com/databricks/dbrx - 转发 @爱可可-爱生活:&amp;ensp;【Databricks开源DBRX高性能大语言模型】- DBRX是Databricks开发的开源通用语言模型，在多项...</title>
<link>https://weibo.com/1402400261/O7g8IykIK</link>
<guid>https://weibo.com/1402400261/O7g8IykIK</guid>
<content:encoded><![CDATA[
<div> Databricks, DBRX, 开源, 语言模型, MoE架构, GenAI, 训练, 效率, 商业模型, Hugging Face

<br /><br />总结:
Databricks推出了开源通用语言模型DBRX，在多项基准测试中表现出色，尤其在编程和数学推理方面优于其他开源模型。DBRX采用MoE架构，在训练和推理上更为高效，推理吞吐量提高2-3倍。DBRX已集成在Databricks的GenAI产品中，客户可以通过API使用。其训练代码和模型也在Hugging Face平台上开源。DBRX的推出展示了Databricks高效训练语言模型的能力，为企业训练定制模型提供了可能。这一举措将推动语言模型的开放性发展，为开发者和企业构建定制模型提供新的选择。MoE架构在提升大型语言模型效率方面有着巨大潜力，为进一步优化模型提供了思路。Databricks将DBRX定位为GenAI战略的核心，展现了他们对语言模型和GenAI商业化的信心和决心。这也预示着更多垂直领域模型的到来。 <div>
GitHub: github.com/databricks/dbrx<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 【Databricks开源DBRX高性能大语言模型】<br />- DBRX是Databricks开发的开源通用语言模型，在多项标准基准测试上达到了当前开源语言模型的最高水平。   <br />- DBRX在多项综合基准测试中表现最好，尤其在编程和数学推理方面优于其他开源模型。与开源模型相比，DBRX在MMLU数据集上的表现也是最好的。   <br />- 根据测试，DBRX甚至超过了专门用于编程的CodeLLAMA-70B，并且与商业模型GPT-3.5相当甚至略胜。DBRX也与Gemini 1.0 Pro和Mistral Medium等商业模型有竞争力。   <br />- DBRX使用混合专家(MoE)架构，使其在训练和推理上更加高效。与类似参数量的非MoE模型相比，DBRX的推理吞吐量提高2-3倍。   <br />- DBRX的整体训练效率比之前提高了近4倍，这得益于更好的数据、MoE架构以及其他改进。   <br />- DBRX已经在Databricks的GenAI产品中进行了集成，客户可以通过API使用该模型。DBRX的训练代码和模型也在Hugging Face平台上开源。   <br />- DBRX证明了Databricks可以高效地训练世界级的基础语言模型，也为企业训练自己的基础模型提供了能力。DBRX只是Databricks协助客户训练定制语言模型的一个例子。<br /><br />思考：  <br />- Databricks作为一家数据和AI公司推出如此强大的开源LLM令人印象深刻，这将极大推动LLM的开放性发展。  <br />- DBRX在通用和编程能力上的出色表现，有望成为开发者和企业构建定制LLM的新选择。  <br />- MoE架构在提升LLM效率方面的潜力得到了很好的体现，为进一步优化大模型提供了思路。  <br />- Databricks将DBRX定位于其GenAI战略的核心，反映出他们对LLM和GenAI商业化的信心和决心。  <br />- Databricks过去为客户大规模训练LLM的经验，为DBRX的成功奠定了基础，也预示着更多垂直领域模型的到来。<br />《Introducing DBRX: A New State-of-the-Art Open LLM | Databricks》 <a href="https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6bjgicy7j21ej0u0jvd.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6bjkgdyqj21c70u0tbn.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:43:32 GMT</pubDate>
</item>
<item>
<title>【Jamba：突破性的SSM-Transformer混合架构模型】- AI21 推出了名为 Jamba 的新型自然语言处理模型，首个基于 Mamba 结构化状态空间(Structured State Space mod...</title>
<link>https://weibo.com/1402400261/O7g6y9NdH</link>
<guid>https://weibo.com/1402400261/O7g6y9NdH</guid>
<content:encoded><![CDATA[
<div> Jamba, SSM-Transformer, 混合架构, 模型, Mamba, Transformer, 注意力机制, 模块化设计, 开源, AI21

<br /><br />总结:
AI21推出了Jamba，这是首个基于Mamba结构化状态空间(SSM)模型和传统Transformer架构的混合模型。Jamba结合了Mamba和Transformer的优势，解决了纯SSM模型质量不高和Transformer计算效率低的问题。该模型使用混合注意力机制，支持256K上下文窗口，在单GPU上可以支持14万token并有3倍吞吐量提升。通过模块化设计、动态激活部分参数的方式，Jamba的效果与传统52B参数模型相当。初步评估显示Jamba在吞吐量和效率等指标上表现优异，权重已在Apache 2.0许可下开源。AI21希望通过开源Jamba推动SSM-Transformer架构的发展和创造更多应用。 <div>
【Jamba：突破性的SSM-Transformer混合架构模型】<br />- AI21 推出了名为 Jamba 的新型自然语言处理模型，首个基于 Mamba 结构化状态空间(Structured State Space model，SSM)模型和传统Transformer架构的混合模型。   <br />- Jamba 结合了 Mamba 和 Transformer 两种模型的优势，既解决了纯 SSM 模型质量不高的问题，又克服了 Transformer 在大上下文场景下计算效率低的缺点。   <br />- Jamba 使用混合注意力机制，同时支持256K的上下文窗口，在单GPU上可以支持14万token。相比类似规模的模型，其吞吐量提升3倍。   <br />- Jamba采用模块化设计， transformer模块、mamba模块和mixture-of-experts模块分别承担不同功能。同时使用动态激活部分参数的方式，使12B参数发挥与全Transformer架构52B参数模型相当的效果。   <br />- 初步评估显示，Jamba在多个指标上表现优异，如吞吐量、效率等。这充分验证了 Jamba作为首个达到商业级水平的SSM-Transformer混合架构模型的可行性。   <br />- Jamba的权重已在Apache 2.0许可下开源，用户可以在Hugging Face上使用。Jamba旨在作为基础模型进行微调、训练和开发定制化解决方案。   <br />- AI21希望通过开源Jamba，能推动SSM-Transformer架构的进一步发展和优化，创造更多新奇有趣的应用。<br />《Jamba：A Groundbreaking SSM - Transformer Open Model》 <a href="https://www.ai21.com/jamba"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho7ya8797hj21of0u077k.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7ya9ejbbj21hc0u0q4x.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho7yabemj3j20vo0iymyx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7yad0805j21k60u0769.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho7yadvis9j21v00u00v7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:38:10 GMT</pubDate>
</item>
<item>
<title>【Grok-1.5发布：支持128K超长上下文】- Grok-1.5是xAI最新发布的大型语言模型，具有更强的推理和解决问题的能力。 - Grok-1.5的一个显著改进是在编程和数学相关...</title>
<link>https://weibo.com/1402400261/O7fqKClTg</link>
<guid>https://weibo.com/1402400261/O7fqKClTg</guid>
<content:encoded><![CDATA[
<div> Grok-1.5, xAI, 128K超长上下文, 推理能力, 人工智能, 编程, 数学, 长文本理解, NIAH, JAX, Rust, Kubernetes, GPU集群, 用户反馈, 基准测试, 模型优化, 发展创新, 定制分布式训练框架, 马斯克, 商业化进程, 开源<br />
<br />
总结:<br />
Grok-1.5是xAI发布的大型语言模型，具有强大的推理和解决问题能力，特别在编程和数学任务中表现优异。其支持处理高达128K token的超长文本，在NIAH任务中表现出色。该模型基于JAX、Rust和Kubernetes构建，可以在大规模GPU集群上进行原型设计和模型训练。xAI团队非常注重用户反馈，并持续改进Grok以满足需求。未来Grok可能引入新功能如总结帖子、内容建议等。虽然未提供微调代码，但开源Grok-1展现了xAI开放、透明的态度。马斯克暗示将扩大Grok聊天机器人的使用权限，显示xAI正逐步推进商业化进程。 <div>
【Grok-1.5发布：支持128K超长上下文】<br />- Grok-1.5是xAI最新发布的大型语言模型，具有更强的推理和解决问题的能力。   <br />- Grok-1.5的一个显著改进是在编程和数学相关任务上的表现，在MATH和GSM8K这两个评估中学科竞赛问题解决能力的基准测试中取得了50.6%和90%的得分。   <br />- Grok-1.5可以处理高达128K token的长文本理解任务，上下文窗口增大了16倍，记忆能力显著提升。它在长文本检索任务NIAH中展示了在长达128k token的上下文中完美检索文本的能力。   <br />- Grok-1.5基于JAX、Rust和Kubernetes构建，使团队可以在大规模GPU集群上进行原型设计和模型训练。检查点、数据加载和任务重启等都进行了优化，以最大程度提高可靠性和训练时间。   <br />- Grok-1.5即将向早期测试用户开放，xAI团队欢迎用户反馈意见。在未来几天里，他们还会推出一些新功能。   <br />- Grok-1.5在多个基准测试中表现强劲，显示出语言理解和推理方面的长足进步。它为解决更加复杂的问题提供了更大的上下文理解能力。xAI将继续改进Grok，以满足用户的需求。   <br /><br />思考：  <br />- Grok-1.5在推理、编码和数学能力方面的改进令人印象深刻，xAI在不断推动人工智能技术的发展和创新。  <br />- 128K token的长上下文处理能力是一个重大突破，使Grok-1.5能够更好地理解和利用长文档中的信息，处理更复杂的提示，这将大大拓展其应用场景。  <br />- 定制的分布式训练框架体现了xAI在底层技术和工程能力方面的实力，有利于加速人工智能模型的迭代和优化。  <br />- 尽管Grok-1.5尚未正式发布，但马斯克已经透露了一些未来可能引入的新功能，如总结帖子、内容建议等，这些都将大大提升用户体验。  <br />- 开源Grok-1彰显了xAI开放、透明的态度，但没有提供微调代码，可能是出于保护核心技术和竞争优势的考虑。  <br />- 马斯克暗示将逐步扩大Grok聊天机器人的使用权限，表明xAI正在稳步推进商业化进程，未来可能会成为X平台的重要变现途径之一。<br />《Announcing Grok-1.5》 <a href="https://x.ai/blog/grok-1.5"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho7vbau0f3j221o0u0aeg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho7vbbwf6yj21jk0rs0wb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 06:55:13 GMT</pubDate>
</item>
<item>
<title>恭喜@i_tuna 等3名用户获得【《hello 算法》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效。公示链接：网页链接 - 转发 @爱可可-爱...</title>
<link>https://weibo.com/1402400261/O7eixaBMz</link>
<guid>https://weibo.com/1402400261/O7eixaBMz</guid>
<content:encoded><![CDATA[
<div> 微博官方、《hello 算法》、抽奖、监督、公正、有效、携手、数据结构、算法、动画图解

<br /><br />总结:
本次活动是微博官方举办的抽奖活动，奖品为《hello 算法》书籍，抽奖过程经过官方监督，结果公正有效。参与方式为转发并评论，截止时间为2024年3月29日12:00。《hello 算法》书籍内容生动易懂，配有动画图解，帮助读者轻松掌握数据结构与算法知识。书中还提供实战代码示例和互动环节设计，让读者即学即用，提高学习效率。通过这本书，读者可以以全新的视角进入算法的世界，掌握重要的数据结构和算法知识。 <div>
恭喜<a href="https://weibo.com/n/i_tuna">@i_tuna</a> 等3名用户获得【《hello 算法》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20240246&amp;pageid=100140E51191126"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 04:02:13 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评...</title>
<link>https://weibo.com/1402400261/O7bWjsGOq</link>
<guid>https://weibo.com/1402400261/O7bWjsGOq</guid>
<content:encoded><![CDATA[
<div> Java, Python, JavaScript, C语言, MySQL, Redis, 技术原理, 故事, 码农翻身2

<br /><br />
总结: 
《码农翻身2》是一本以故事形式讲解技术的畅销书，通过描述编程语言王国的争斗和技术之间的矛盾，让读者了解技术原理并且阅读愉快。书中描绘了Java向Python渗透、JavaScript向Java进攻的情景，C语言的孤独悲催以及MySQL和Redis间的矛盾。通过趣味性的故事，读者可以轻松掌握技术知识。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 22:01:59 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*...</title>
<link>https://weibo.com/1402400261/O7bWgwtuw</link>
<guid>https://weibo.com/1402400261/O7bWgwtuw</guid>
<content:encoded><![CDATA[
<div> 开奖 参与 携手 hello算法 可可粉 数据结构 算法 视角 图解 实战代码 思考问题  <br />
<br />
总结: 今天有开奖活动，欢迎大家参与。赠送3本《hello 算法》，截止时间是2024年3月29日中午12点。参与方式是转发并在评论中加上关键词“可可粉”。这本书可以帮助读者轻松掌握数据结构和算法，以全新的视角进入算法的世界。每一章都有生动的动画图解让抽象的概念变得直观易懂，实战代码示例可以帮助读者即学即用，加深对新知识的理解。书中的互动环节设计可以帮助读者主动思考，提出问题并解决问题。希望大家能够充分利用这本书提升自己的算法能力。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 22:01:52 GMT</pubDate>
</item>
<item>
<title>今日推介(第1359期)：大型语言模型中的长文本事实性、语言模型的少样本重校准、大型语言模型能产生具有同理心的反应、监控提示训练、适应任意分辨率的视觉Transf...</title>
<link>https://weibo.com/1402400261/O7bW44IwI</link>
<guid>https://weibo.com/1402400261/O7bW44IwI</guid>
<content:encoded><![CDATA[
<div> 长文本事实性、语言模型、少样本重校准、同理心、监控提示训练、任意分辨率、视觉Transformer<br />
<br />
大型语言模型在生成长文本时，需要保证信息的准确性和事实性，这对于提高模型的可信度至关重要。研究表明，少样本重校准技术可以帮助语言模型更好地理解和生成文本，提高其效果和表现。另外，大型语言模型能够产生具有同理心的反应，为人类与AI之间建立更加亲近的联系提供可能。监控提示训练是一种有效的训练方法，可以帮助语言模型适应多样的语境和情境，提高其对话和文本生成的能力。同时，视觉Transformer具有适应任意分辨率的能力，能够更好地处理各种视觉任务。综上所述，大型语言模型在不断发展和完善的过程中，不断探索新的技术方法和应用场景，为人工智能领域的发展带来新的可能性和机遇。<br /><br />总结:长文本事实性是大型语言模型生成文本时需要考虑的重要因素，少样本重校准技术可以提高模型效果，大型语言模型能产生具有同理心的反应，监控提示训练有助于提高模型能力，视觉Transformer适应任意分辨率的特性能够更好应对各种视觉任务。 <div>
今日推介(第1359期)：大型语言模型中的长文本事实性、语言模型的少样本重校准、大型语言模型能产生具有同理心的反应、监控提示训练、适应任意分辨率的视觉Transformer 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/689639917"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.29)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7fvouo5nj20go08e75c.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7fvs8ioaj20go05qq3r.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7fvuu2uvj20go0913z2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7fvx9i5qj20go0fat9u.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho7fvzpva4j20go0b10u3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 22:01:22 GMT</pubDate>
</item>
<item>
<title>[CV] EgoLifter: Open-world 3D Segmentation for Egocentric Perception 网页链接 EgoLifter利用3D高斯与实例特征的组合以及对比学习，实现了从第一人称视频进...</title>
<link>https://weibo.com/1402400261/O7bSLBR4R</link>
<guid>https://weibo.com/1402400261/O7bSLBR4R</guid>
<content:encoded><![CDATA[
<div> EgoLifter, 3D高斯，实例特征，对比学习，第一人称视频，开放世界3D场景分割，端到端框架，无需人工3D标注数据

<br /><br />总结:
EgoLifter利用3D高斯与实例特征的组合以及对比学习，实现了从第一人称视频进行开放世界3D场景分割的端到端框架，无需人工3D标注数据。 <div>
[CV] EgoLifter: Open-world 3D Segmentation for Egocentric Perception  <br /><a href="https://arxiv.org/abs/2403.18118"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />EgoLifter利用3D高斯与实例特征的组合以及对比学习，实现了从第一人称视频进行开放世界3D场景分割的端到端框架，无需人工3D标注数据。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fnia6goj20uy1cuwsn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fnipwdjj211g17eh27.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7fnj4p5nj211o0sa7df.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fnjjgkgj20wu1bq179.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:53:15 GMT</pubDate>
</item>
<item>
<title>[CV] Benchmarking Object Detectors with COCO: A New Path Forward 网页链接 通过构建高质量的数据集COCO-ReM，揭示了目标检测模型评估的重要性，为未来的算法...</title>
<link>https://weibo.com/1402400261/O7bPVv6UR</link>
<guid>https://weibo.com/1402400261/O7bPVv6UR</guid>
<content:encoded><![CDATA[
<div> 构建数据集 COCO-ReM 目标检测模型评估 算法研究 基准 数据集质量 目标检测模型 可靠性

<br /><br />总结:
该文章介绍了通过建立高质量数据集COCO-ReM来揭示目标检测模型评估的重要性，并为未来算法研究奠定可靠基准。这项研究突出了数据集质量对于目标检测模型评估的关键性，并提出了使用COCO-ReM作为基准数据集的优势。作者强调了评估目标检测模型的重要性，列举了一些现有数据集的局限性，并指出了COCO-ReM数据集的创新性和研究意义。通过对比各种数据集，研究人员表明了COCO-ReM数据集在不同性能指标上的优势，包括更高的准确性和更全面的测试。文章最后总结了该研究的重要性，并呼吁未来的算法研究应该基于可靠的基准数据集进行评估，以推动目标检测领域的发展。 <div>
[CV]  Benchmarking Object Detectors with COCO: A New Path Forward  <br /><a href="https://arxiv.org/abs/2403.18819"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过构建高质量的数据集COCO-ReM，揭示了目标检测模型评估的重要性，为未来的算法研究奠定可靠的基准。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fg83ke0j210g184wud.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fg8jnpsj217a0xi4dd.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7fg90wc4j217w0ja47w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7fg9jn61j217c0jk0xh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:46:15 GMT</pubDate>
</item>
<item>
<title>[CL] Enhancing Legal Document Retrieval: A Multi-Phase Approach with Large Language Models 网页链接 通过在法律文档多阶段检索流程中集成提示驱动的大型语...</title>
<link>https://weibo.com/1402400261/O7bNMp76A</link>
<guid>https://weibo.com/1402400261/O7bNMp76A</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、法律文档检索、多阶段方法、提示驱动、性能提升、集成、检索性能、法律领域、信息检索、语言模型

<br /><br />总结:
本文提出了一种通过在法律文档多阶段检索流程中集成提示驱动的大型语言模型来提升检索性能的方法。研究针对法律领域的信息检索问题进行了探讨，并提出了一种多阶段方法，其中大型语言模型起到关键作用。通过集成大型语言模型，可以显著提高法律文档的检索性能，提高检索结果的准确性和相关性。这种方法为提高法律文档检索效率和质量提供了新思路和方法。 <div>
[CL] Enhancing Legal Document Retrieval: A Multi-Phase Approach with Large Language Models  <br /><a href="https://arxiv.org/abs/2403.18093"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过在法律文档多阶段检索流程中集成提示驱动的大型语言模型，提出了一种可显著提高检索性能的方法。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7faq17bhj20rm16oals.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7faqartwj21no0qagrd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7farrkrzj21060n2dht.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:40:58 GMT</pubDate>
</item>
<item>
<title>[CL] BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text 网页链接 提出了面向生物医学领域的小型开源语言模型BioMedLM，证明了通过高质量...</title>
<link>https://weibo.com/1402400261/O7bLx6SZP</link>
<guid>https://weibo.com/1402400261/O7bLx6SZP</guid>
<content:encoded><![CDATA[
<div> 生物医学领域、小型开源语言模型、BioMedLM、高质量领域语料训练、生物医学QA、竞争力效果

<br /><br />总结:
文章介绍了一个面向生物医学领域的小型开源语言模型BioMedLM，该模型在经过高质量领域语料训练后，在生物医学QA等任务上展现出竞争力的效果。作者提出了这个2.7B参数的语言模型，证明了即使不是追求模型规模，通过充分训练仍可以在生物医学领域取得良好的表现。BioMedLM为生物医学领域的文本处理和分析提供了一个有潜力的工具，为相关研究和实践带来了新的可能性。该研究结果为语言模型在特定领域的应用提供了有益的启示，强调了训练数据和模型设计的重要性。BioMedLM的出现丰富了开源语言模型的领域应用场景，对于推动生物医学领域的智能化发展具有积极意义。 <div>
[CL] BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text  <br /><a href="https://arxiv.org/abs/2403.18421"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出了面向生物医学领域的小型开源语言模型BioMedLM，证明了通过高质量的领域语料训练，即使不追求模型规模也可以在生物医学QA等任务上达到竞争力的效果。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7f4yzhcpj20zk1daww5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7f4zbj9xj21cs0k2wg9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7f4zyeftj214u0pm0ul.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:35:25 GMT</pubDate>
</item>
<item>
<title>[LG] Tutorial on Diffusion Models for Imaging and Vision 网页链接 本教程全面系统地介绍了从变分自编码器到扩散模型的发展脉络，数学推导细致，内容丰富，是...</title>
<link>https://weibo.com/1402400261/O7bJ6kisn</link>
<guid>https://weibo.com/1402400261/O7bJ6kisn</guid>
<content:encoded><![CDATA[
<div> 变分自编码器、扩散模型、数学推导、理解、教材、系统性、发展脉络、内容丰富、图像、视觉功能
<br />
<br />
总结: 本教程全面系统地介绍了从变分自编码器到扩散模型的发展脉络，数学推导细致，内容丰富，是理解扩散模型的好教材。 <div>
[LG] Tutorial on Diffusion Models for Imaging and Vision  <br /><a href="https://arxiv.org/abs/2403.18103"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />本教程全面系统地介绍了从变分自编码器到扩散模型的发展脉络，数学推导细致，内容丰富，是理解扩散模型的好教材。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7eypxk3tj210q17ggwg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7eyq7nf7j21i80vetis.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7eyqmidgj21cm0o60yj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:29:26 GMT</pubDate>
</item>
<item>
<title>通过自适应token融合模块和模糊位置编码增强了视觉Transformer的分辨率可扩展性，使其在广泛分辨率上都能保持高性能。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《ViTAR...</title>
<link>https://weibo.com/1402400261/O7bFwiMRP</link>
<guid>https://weibo.com/1402400261/O7bFwiMRP</guid>
<content:encoded><![CDATA[
<div> 关键词: 自适应token融合模块, 模糊位置编码, 视觉Transformer, 分辨率可扩展性, 高性能

总结:<br /><br />这篇论文介绍了一种名为ViTAR的视觉Transformer模型，通过引入自适应token融合模块和模糊位置编码，提高了模型在不同分辨率下的性能表现。该模型能够在广泛的分辨率下保持高性能，并具有较强的分辨率可扩展性。该研究由中国科学院和字节跳动的团队共同完成。<br />ViTAR模型在视觉Transformer的基础上做出了创新改进，使得模型在各种分辨率上的应用更加灵活可靠。通过自适应token融合模块，模型能够有效地融合不同分辨率的特征信息，提升了模型的表征能力和泛化能力。<br />同时，引入模糊位置编码则进一步增强了模型的分辨率可扩展性，使其能够处理更加复杂的视觉任务。这些技术创新为视觉Transformer的发展带来了新的思路和可能性，为未来的视觉任务研究提供了有益的启示。 <div>
通过自适应token融合模块和模糊位置编码增强了视觉Transformer的分辨率可扩展性，使其在广泛分辨率上都能保持高性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《ViTAR: Vision Transformer with Any Resolution》Q Fan, Q You, X Han, Y Liu, Y Tao, H Huang, R He, H Yang [Chinese Academy of Sciences &amp; ByteDance] (2024) <a href="https://arxiv.org/abs/2403.18361"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7edlfnhcj20ng15c13g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho7edls4tmj20vk0ukgqy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7edmc5nzj21qc158gxh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7edmhwrij20um0ia761.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho7epi8s51j20r30fcdh7.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:20:36 GMT</pubDate>
</item>
<item>
<title>[CV]《ViTAR: Vision Transformer with Any Resolution》Q Fan, Q You, X Han, Y Liu, Y Tao, H Huang, R He, H Yang [Chinese Academy of Sciences &amp; ByteDance...</title>
<link>https://weibo.com/1402400261/O7bFtD4yb</link>
<guid>https://weibo.com/1402400261/O7bFtD4yb</guid>
<content:encoded><![CDATA[
<div> 关键词: ViTAR, 视觉Transformer, 分辨率, 中国科学院, 字节跳动

总结:<br /><br />
本文介绍了 ViTAR，一种具有任意分辨率的视觉Transformer模型，由中国科学院和字节跳动共同研发。该模型在视觉任务中表现出色，能够处理各种分辨率的图像输入。研究人员通过实验证明，ViTAR在不同分辨率下均能取得出色的性能表现。该模型的独特之处在于能够处理不同分辨率的输入，提高了模型的适用性和泛化能力。总体而言，ViTAR为视觉Transformer模型的发展带来了新的思路和方法，对图像分析和处理领域具有重要意义。 <div>
[CV]《ViTAR: Vision Transformer with Any Resolution》Q Fan, Q You, X Han, Y Liu, Y Tao, H Huang, R He, H Yang [Chinese Academy of Sciences &amp; ByteDance] (2024) <a href="https://arxiv.org/abs/2403.18361"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7edlfnhcj20ng15c13g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho7edls4tmj20vk0ukgqy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7edmc5nzj21qc158gxh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7edmhwrij20um0ia761.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho7epi8s51j20r30fcdh7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:20:31 GMT</pubDate>
</item>
<item>
<title>【如何成为“效率大师”？】其实，提高工作效率并没有想象中那么难，只要掌握几个简单的技巧，你也可以成为效率之王。 - 首先，学会专注。把时间分块，在日历上...</title>
<link>https://weibo.com/1402400261/O73tVBTUS</link>
<guid>https://weibo.com/1402400261/O73tVBTUS</guid>
<content:encoded><![CDATA[
<div> 专注 深度工作 艾森豪威尔矩阵 邮件处理 习惯 养成 目标计划 番茄工作法 回顾 说“不” 散步  自动化

<br /><br />总结:
首先，要学会专注，将时间分块，全神贯注地完成每项任务。其次，练习深度工作，保持专注，不分心。第三，使用艾森豪威尔矩阵来安排任务，注重重要事项。第四，批量处理邮件和消息，有效安排时间。第五，养成每天练习习惯，坚持一年即可看到成效。第六，利用番茄工作法战胜拖延症。第七，制定目标和计划，每天进行回顾。第八，学会对事情说“不”，拒绝无关紧要的事务。第九，每天晚上散步，可结合冥想。最后，尽可能自动化任务，提高效率。生活就像马拉松，效率是取得优异成绩的关键。 <div>
【如何成为“效率大师”？】<br />其实，提高工作效率并没有想象中那么难，只要掌握几个简单的技巧，你也可以成为效率之王。   <br />- 首先，学会专注。把时间分块，在日历上为每个任务预留时间，然后全神贯注地完成当前的任务。可以尝试3:3:3法则：每天花3小时做最重要的项目，3小时做短期任务，3小时做日常维护。   <br />- 其次，练习"深度工作"。每天至少花4个小时专注工作，期间不要分心(可以把手机调到飞行模式)。学习新东西时，可以用费曼技巧：选一个主题，试着向一个5岁的孩子解释，然后继续研究以填补知识空白。   <br />- 第三，用艾森豪威尔(Eisenhower)矩阵来安排任务。目标是把更多时间花在重要的事情上，那些能推进你长期价值观、使命、目标和原则的事情。   <br />- 第四，批量处理邮件和消息。每天集中1-3次时间来处理邮件。对不必要的邮件立即删除，需要别人处理的转发出去，几分钟内可以回复的马上回，其他的则安排时间处理。   <br />- 第五，养成每天练习20分钟的习惯。坚持一年，你就会比90%的人做得更好。可以用"尽善尽美"(GTD)的方法来高效地安排每一件事。   <br />- 第六，用番茄工作法来战胜拖延症。选择一个任务，设置25分钟的计时器，专注工作，中间不要分心，然后休息一下，再重复。每完成4个番茄钟，就休息久一点。   <br />- 第七，制定年度、月度、周度和日常的目标和计划。没有目标，你可能哪儿也到不了。   <br />- 第八，进行每日和每周回顾。问问自己："我今天做了哪些符合目标的事情?""有什么地方可以改进吗?"   <br />- 第九，学会对很多事情说”不”！一个"不"就是对很多其他事情说"是"。   <br />- 第十，每天晚上散步30分钟。如果能在散步时冥想，那就更好了。   <br />- 最后，尽可能地自动化。试着用各种工具来自动化一切可以自动化的事情，尤其是重复性的任务。   <br />生活就像一场马拉松，效率就是你的配速。掌握这些技巧，相信你一定能在这场马拉松中取得优异的成绩。当然，知易行难，关键是要把这些方法落实到行动中。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho6ekdg9wgj20u01kt11n.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho6ekdwe11j20u019en53.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:30:05 GMT</pubDate>
</item>
<item>
<title>【distil-large-v3：Whisper large-v3的蒸馏精简版】Distil-Whisper的设计旨在加快推理速度，仅使用两个解码器层，实现了与原版Whisper相媲美的语音识别准确性，...</title>
<link>https://weibo.com/1402400261/O73pWbPS5</link>
<guid>https://weibo.com/1402400261/O73pWbPS5</guid>
<content:encoded><![CDATA[
<div> 解码器层、语音识别、推理速度、准确性、幻听错误、分块长文本算法、错误率、Distil-Whisper、设计、提升速度

<br /><br />总结:
Distil-Whisper是一个蒸馏精简版的Whisper模型，旨在加快推理速度。它仅使用两个解码器层，但在语音识别准确性方面与原版Whisper相媲美，推理速度提升了6.3倍。此外，Distil-Whisper在降低幻听错误方面也取得了重大进展，使用分块长文本算法时，幻听错误率降低了约30%。Distil-Whisper的设计使得语音识别更加高效、准确，为技术领域带来了新的突破。 <div>
【distil-large-v3：Whisper large-v3的蒸馏精简版】Distil-Whisper的设计旨在加快推理速度，仅使用两个解码器层，实现了与原版Whisper相媲美的语音识别准确性，但速度却提升了惊人的6.3倍。此外，Distil-Whisper在降低幻听错误方面也取得了重大进展，使用分块长文本算法时，幻听错误率降低了约30%。 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho6ea22y2cj20y20u0tdo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:20:15 GMT</pubDate>
</item>
<item>
<title>【AI许可(licensing)：虚幻的安全感与真实的管理困境】- 一些组织主张通过许可证限制强大AI模型的扩散，类似于核武器或人体克隆。但是这种做法在实施上不可行。 ...</title>
<link>https://weibo.com/1402400261/O73nMkiHG</link>
<guid>https://weibo.com/1402400261/O73nMkiHG</guid>
<content:encoded><![CDATA[
<div> 许可证、AI模型、扩散、训练成本、国际合作、利益、风险、监管套利、开源AI、灵活应对

总结:<br /><br />本文讨论了AI许可在管理风险方面的困境。许可证虽然被一些组织主张限制强大AI模型的扩散，但实施上存在诸多困难。训练成本逐渐下降，监控数据中心需要国际合作。少数大公司将获益，强制许可证可能加剧风险。许可证可能导致恶化风险和监管套利，开源AI也需要预防措施。需要更加开放和灵活的方式应对AI发展带来的影响。许可不能真正阻止恶意使用，执法难度大。颠覆性技术难以被垄断。要综合评估AI风险，并制定相应措施应对。 <div>
【AI许可(licensing)：虚幻的安全感与真实的管理困境】<br />- 一些组织主张通过许可证限制强大AI模型的扩散，类似于核武器或人体克隆。但是这种做法在实施上不可行。   <br />- 尽管目前训练顶级AI模型需要大量算力，但随着算法和硬件的进步，训练成本正在急速下降。要全面监控数据中心以限制AI开发不可行且需要空前国际合作。   <br />- 尽管AI模型会扩散，但少数大公司将从这波爆发中获得巨大利益。强制许可证将进一步加剧这种风险，因为只有少数公司可以开发顶级AI。   <br />- 许可证可能导致AI风险恶化，包括安全风险、结果同质化、定义可接受言论界限、影响公众态度等。这也有利于行业巨头进行监管套利。   <br />- 鼓励不同背景的学术界、企业和非营利组织开发和评估顶级AI模型，可能是解决AI风险的更好方式。当然，开源AI也需要防范措施。   <br />- 总体而言，AI技术许可证在实施可行性和有效性上都存在重大障碍。我们需要更加开放和灵活的方式来应对AI发展带来的影响。<br /><br />思考：  <br />- 作者对许可能否有效管理AI风险提出了尖锐质疑，这个观点有一定道理，值得认真考虑。  <br />- 文章指出，许可无法真正阻止坏人，因为他们总能找到非法获取模型的办法。这提醒我们，单纯的许可可能并非万全之策。  <br />- 作者认为许可的支持者低估了执法难度，这一论断可能有一定道理。但能否通过技术创新等方式克服这些难度，可能还有待进一步探索。  <br />- 文章指出，从历史上看，颠覆性技术无法被垄断，终会扩散。这启示我们要用发展的眼光看待AI技术的传播。  <br />- 作者提醒我们不要被许可制造的虚假安全感所迷惑，而忽视了更紧迫的风险。这提示我们要全面评估AI风险，并相应制定综合防控措施。<br />《Licensing is neither feasible nor effective for addressing AI risks》 <a href="https://www.aisnakeoil.com/p/licensing-is-neither-feasible-nor"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6e4nvbhwj20y20u0tdo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:14:56 GMT</pubDate>
</item>
<item>
<title>【模型微调是否仍有价值】- 最近有一些观点开始质疑模型微调的价值，作者认为在许多情况下，模型微调仍然非常有价值。 - 模型微调对于学习语法、风格和规则很有...</title>
<link>https://weibo.com/1402400261/O73m0AYRY</link>
<guid>https://weibo.com/1402400261/O73m0AYRY</guid>
<content:encoded><![CDATA[
<div> 微调 价值 观点 场景 领域 评估 框架 提示工程 区分 RAG

<br /><br />总结: 本文讨论了模型微调的价值，认为在学习语法、风格和规则等方面仍然非常有帮助，但对于开发者工具等通用情况，微调的效果可能有限。作者强调了评估框架的重要性，指出微调需有系统的性能度量。此外，提示工程在微调中扮演着重要的角色，能帮助检验和改善模型的性能。文章还对微调和基于检索的方法进行了区分，指出它们各自适用于不同的场景和目的。综上所述，微调仍然是提升模型表现的有效手段，但其应用需根据具体情况进行决定。 <div>
【模型微调是否仍有价值】<br />- 最近有一些观点开始质疑模型微调的价值，作者认为在许多情况下，模型微调仍然非常有价值。   <br />- 模型微调对于学习语法、风格和规则很有帮助，而提示工程更适合为模型提供上下文和最新事实。   <br />- 在开发者工具、基础模型、通用助手等情况下，模型微调不太有价值。但在专业领域和特定使用案例中，模型微调可以明显改进性能。   <br />- 在产品早期阶段，由于没有域特定的评估体系，很难有效地进行模型微调。构建评估体系是使用模型微调的先决条件。   <br />- 文章给出了Honeycomb和ReChat两个案例，说明了如何通过模型微调学习特定语法、风格和规则，从而提升产品性能。   <br />- 模型微调不仅适用于小模型，大型模型如GPT-3.5也能从中获益。模型微调仍然是提升模型表现的有效手段，值得继续探索与改进。<br /><br />思考：  <br />- 文章对当前AI领域微调价值的看法提供了一个平衡的视角。作者在承认怀疑声音日益增多的同时，坚持认为微调在许多场景下仍有很高价值。  <br />- 一个关键见解是，微调的适用性在很大程度上取决于具体的使用场景和领域。对于通用的开发者工具或基础模型本身，微调的边际效用可能有限。但对于更专业的应用，微调仍可带来显著改善。  <br />- 文章强调要有一个鲁棒的评估框架，作为任何模型优化(包括微调)的基础。没有系统的性能度量方式，我们很容易武断地否定微调等技术。  <br />- 文章也突出了提示工程作为微调的前提和补充所扮演的角色。广泛的提示可以检验评估机制，如果效果令人满意，它本身就足够了。  <br />- 作者对微调和基于检索的方法(如RAG)做了有益的区分，前者更适合学习风格和语法模式，后者更适合注入最新信息。<br />《Hamel’s Blog - Is Fine-Tuning Still Valuable?》 <a href="https://hamel.dev/blog/posts/fine_tuning_valuable.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho6e0460lkj20u016rtg6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:10:33 GMT</pubDate>
</item>
<item>
<title>【用FrankenMoE集成多个预训练模型：MergeKit赋能高效MoE构建】- MoE(混合专家模型)是一种提高性能的模型架构，它使用多个子网络(称为“专家”)。MoE只激活相关...</title>
<link>https://weibo.com/1402400261/O73kchGO2</link>
<guid>https://weibo.com/1402400261/O73kchGO2</guid>
<content:encoded><![CDATA[
<div> MoE, 混合专家模型, FrankenMoE, MergeKit, 预训练模型, 性能提升, 创新思路, 高质量模型, 实用性, 创意方法

<br /><br />总结:
本文介绍了使用FrankenMoE集成多个预训练模型来创建MoE的方法。传统的MoE需要从头训练专家和路由器，而FrankenMoE通过MergeKit集成预训练模型，使MoE构建更快速、灵活、提高性能。作者创建了一个名为Beyonder-4x7B-v3的FrankenMoE模型，并取得了不错的结果。虽然FrankenMoE方法在性能提升方面有潜力，但也存在一些实际问题，如较高的VRAM需求，需要权衡利弊来决定使用。MergeKit为MoE构建提供了创新思路，具有很大实用价值，读者可以尝试实践。LazyMergeKit成功创建并评估了作者的frankenMoE，证明了方法的可行性和有效性。MergeKit的创新有望推动MoE技术的进一步发展和应用。 <div>
【用FrankenMoE集成多个预训练模型：MergeKit赋能高效MoE构建】<br />- MoE(混合专家模型)是一种提高性能的模型架构，它使用多个子网络(称为“专家”)。MoE只激活相关的专家，从而实现更快的训练和推理。   <br />- 传统的MoE模型需要从头训练专家和路由器(确定哪些token由哪些专家处理)。而“FrankenMoE”则是通过集成多个预训练好的模型来创建MoE。   <br />- FrankenMoE的创建包括选择专家模型、定义正样本和负样本提示、使用MergeKit生成MoE模型。文章详细介绍了一个例子。   <br />- 作者创建了一个FrankenMoE模型Beyonder-4x7B-v3，它在多个基准测试中取得了不错的结果，展示了这种方法的潜力。   <br />- FrankenMoE在提高性能方面很有前景，但也存在一些实际中的问题，如较高的VRAM需求。需要权衡利弊来决定是否适合使用。   <br />- 这种方法为改进模型性能提供了一种创新思路，值得进一步探索，但还有待改进。建议读者尝试自己创建FrankenMoE模型。<br /><br />思考：  <br />- MergeKit通过集成预训练模型创建MoE的方法非常有创意，为MoE的构建提供了一种新的思路和途径。  <br />- 与从头训练MoE相比，MergeKit的方法可以更快速、灵活地创建高质量的MoE，具有很大的实用价值。  <br />- 文章对MergeKit创建frankenMoEs的过程进行了详细的介绍和示范，读者可以很容易地上手实践。  <br />- 作者使用LazyMergeKit成功创建并评估了自己的frankenMoE，证明了这一方法的可行性和有效性。  <br />- MergeKit在MoE领域的创新有望推动MoE技术的进一步发展和应用，值得业界关注和探索。<br />《Create Mixtures of Experts with MergeKit | by Maxime Labonne | Mar, 2024 | Towards Data Science》 <a href="https://towardsdatascience.com/create-mixtures-of-experts-with-mergekit-11b318c99562"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho6dvfyxq4j20u00vsgrj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho6dvgrvsgj21hc0u0n21.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:06:05 GMT</pubDate>
</item>
<item>
<title>【RLHF成功背后的隐忧：AI安全亟需多管齐下】- 文章认为当前主流的模型对齐技术RLHF在防止语言模型非故意的伤害方面非常有效，使得聊天机器人产品得以推向大众消...</title>
<link>https://weibo.com/1402400261/O73iKrQzj</link>
<guid>https://weibo.com/1402400261/O73iKrQzj</guid>
<content:encoded><![CDATA[
<div> 模型对齐技术、RLHF、AI安全、聊天机器人、意图恶意使用、防范措施、内容审核、软件安全、灾难性风险

总结：<br /><br />本文指出，现有模型对齐技术在防止语言模型非故意伤害方面表现出色，尤其在聊天机器人领域取得成功。然而，对意图恶意使用的对手，模型对齐无法产生很大作用，因此需要额外的防范措施。模型对齐其实更像内容审核，而不是软件安全，应重视其局限性。对于AI安全问题，需要更系统性的思考，不能过度依赖模型对齐技术。需要开发更强大的对齐技术，同时关注模型外的防御措施，以确保全面的安全性。对于可能带来严重意外伤害的场景，单纯的技术方法可能不够，AI安全社区应高度重视。 <div>
【RLHF成功背后的隐忧：AI安全亟需多管齐下】<br />- 文章认为当前主流的模型对齐技术RLHF在防止语言模型非故意的伤害方面非常有效，使得聊天机器人产品得以推向大众消费者。   <br />- 但是RLHF无法防止有意图的恶意使用。对付资金雄厚的对手，模型对齐毫无用处，因为对手可以重新训练模型或移除对齐。   <br />- 对付日常用户的恶意使用，模型对齐仍有一定效用，因为它使其更难进行故意误用。但不能仅依赖模型对齐，还需要产品级的其他防范措施。   <br />- 模型对齐更像是内容审核，而不是软件安全。它的不足不应引发恐慌，仍然是有用的。但对付灾难性风险，不应过分依赖模型对齐。   <br />- 需要开发更强大的对齐技术，同时关注模型之外的防御措施，扩大安全性的系统性思考。<br /><br />思考：  <br />- 文章指出，业界过度依赖模型对齐技术来解决AI安全问题，这一观点值得重视。我们不能把模型对齐视为万灵药。  <br />- RLHF等模型对齐技术在聊天机器人领域取得了成功，但其局限性也日益凸显。对齐完美与否，取决于诸多因素。  <br />- 对手绕过对齐技术引发的担忧合情合理。但暂停AI等极端措施是否必要和可行，仍有待商榷。  <br />- 文章提到即使对齐了，聊天机器人也可能有害，产品概念也很重要。这启示我们AI安全需要更全面的视角，不能只盯着模型本身。  <br />- 对于自主智能体等可能带来更严重意外伤害的场景，单纯的技术方法可能不够，这值得AI安全社区高度重视。<br />《Model alignment protects against accidental harms, not intentional ones》 <a href="https://www.aisnakeoil.com/p/model-alignment-protects-against"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6drrmzkdj20ud0u0dks.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:02:32 GMT</pubDate>
</item>
<item>
<title>【模型安全≠使用安全，AI治理需要更全面的视角】- 在AI界存在一个普遍假设，即AI安全性是AI模型的一项特性。基于这个假设，许多公司投资了大量资源来提高模型的...</title>
<link>https://weibo.com/1402400261/O73hpqXEs</link>
<guid>https://weibo.com/1402400261/O73hpqXEs</guid>
<content:encoded><![CDATA[
<div> 模型安全, 使用安全, AI治理, 模型特性, 上下文, 系统性思考, 误用, 边际风险, 对抗测试, 社会成本

总结:<br /><br />这篇文章指出了AI安全不是模型特性，强调了模型的安全与其部署的上下文和环境密切相关。文章提出了四点建议，包括防范模型误用、评估边际风险、重塑对抗测试和让第三方进行对抗测试。作者认为模型无法判断某些恶意用途，提出责任划分会变得复杂，AI安全需要综合思考。文章还讨论了安全内容的差异化处理和警惕简单思维定势的重要性。整体而言，AI治理需要更全面的视角，并且不能简单地将安全问题归咎于模型特性。 <div>
【模型安全≠使用安全，AI治理需要更全面的视角】<br />- 在AI界存在一个普遍假设，即AI安全性是AI模型的一项特性。基于这个假设，许多公司投资了大量资源来提高模型的安全性。但是文章认为这种做法是有限的，因为AI安全性不是模型的特性，而在很大程度上取决于模型被部署的上下文和环境。   <br />- 文章举了钓鱼邮件、生物恐怖主义和传播虚假信息等例子，说明模型本身无法判断这些用途是否恶意，因为模型无法获知完整的部署上下文。要做到只生成无害内容几乎不可能。   <br />- 文章提出了四点建议：一是防范模型误用的主要措施应位于模型之外；二是评估开源模型的边际风险；三是重塑对抗测试，以发现对手方的新能力；四是让第三方而不是开发者自己进行对抗测试。   <br />- 文章认为，接受模型无法杜绝误用意味着责任划分会变得非常复杂。开发者在道德上应承担部分由于AI滥用带来的社会成本，但在法律上很难执行。这是AI政策亟待解决的难题。   <br />- 文章提出AI安全性不是模型特性这一观点，认为仅仅对模型进行安全性改进是有限的，需要更广泛的系统性思考。这一观点对当前AI安全研究具有重要启发意义。<br /><br />思考：  <br />- 作者提出了一个有趣的观点，即AI安全不是模型的特性，这与业界的主流看法形成了鲜明对比，值得深入思考。  <br />- 文章指出，即使模型本身是安全的，也可能被用于恶意目的，这提醒我们在考虑AI安全时需要更全面的视角。  <br />- 作者认为不能将安全问题全权委托给模型决定，因为模型可能缺乏必要的上下文信息，这一论断有一定道理，但可能也并非放之四海而皆准。  <br />- 文章提到一些例外情况，如儿童色情内容等，表明某些内容本身就是有问题的。这提示我们在AI安全治理中，可能需要对不同类型的内容采取差异化的策略。  <br />- "安全是模型特性"说法之所以会流行，可能确实与其便利性有关。这提醒我们在探讨AI安全时，要警惕简单化、一刀切的思维定势。<br />《AI safety is not a model property》 <a href="https://www.aisnakeoil.com/p/ai-safety-is-not-a-model-property"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho6dob3pdpj20ug0u0n1d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 23:59:14 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评...</title>
<link>https://weibo.com/1402400261/O73czeXBY</link>
<guid>https://weibo.com/1402400261/O73czeXBY</guid>
<content:encoded><![CDATA[
<div> Java、Python、JavaScript、C语言、MySQL、Redis、技术、故事、码农翻身

<br /><br />总结:
《码农翻身2》是一本以故事方式讲解技术的畅销书，其中描述了编程语言王国之间的争斗和趣味故事。Java、Python、JavaScript等编程语言相互竞争，MySQL和Redis互相斗争，C语言则面临着单身的悲催。这本书旨在让读者掌握技术原理的同时，享受有趣的阅读体验。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 23:47:18 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：明日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*...</title>
<link>https://weibo.com/1402400261/O73cwc9dI</link>
<guid>https://weibo.com/1402400261/O73cwc9dI</guid>
<content:encoded><![CDATA[
<div> 可可粉、转发、评论、hello 算法、数据结构、算法、动画图解、实战代码示例、互动环节设计、轻松掌握

<br /><br />总结:
明日将会开奖，并欢迎大家参与携手送出3本《hello 算法》的活动。截止日期是2024年3月29日中午12点。参与方式是转发并评论*可可粉*即可参与。这本书旨在帮助读者轻松掌握数据结构与算法，通过全新的视角引领读者进入算法的世界。每一章节都配有生动的动画图解，使抽象的数据结构和算法变得直观易懂。书中的实战代码示例让读者可以即学即用，及时巩固新知识。互动环节的设计帮助读者主动思考，提出问题并解决问题。这本书的目的是让读者在学习数据结构与算法的过程中更加轻松愉快。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：明日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 23:47:11 GMT</pubDate>
</item>
<item>
<title>【Chatbot匿名竞技场最新更新：Claude 3 0pus不负众望成为冠军，Starling-LM-7B-beta以7B的规模击败GPT 3.5、Mistral 和 Gemini Pro】《LMSys Chatbot Arena Lea...</title>
<link>https://weibo.com/1402400261/O72QQ683v</link>
<guid>https://weibo.com/1402400261/O72QQ683v</guid>
<content:encoded><![CDATA[
<div> 更新、竞技场、Claude 3 0pus、冠军、Starling-LM-7B-beta、击败、GPT 3.5、Mistral、Gemini Pro

<br /><br />总结:
最新更新显示，匿名竞技场中，Claude 3 0pus凭借强大实力成为冠军，而Starling-LM-7B-beta也以7B规模战胜了GPT 3.5、Mistral和Gemini Pro，引起广泛关注。 <div>
【Chatbot匿名竞技场最新更新：Claude 3 0pus不负众望成为冠军，Starling-LM-7B-beta以7B的规模击败GPT 3.5、Mistral 和 Gemini Pro】《LMSys Chatbot Arena Leaderboard - a Hugging Face Space by lmsys》 <a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6bs0wrabj21c30u0q88.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 22:53:46 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.27)》 爱可可微博热门分享(3.27) [图片]</title>
<link>https://weibo.com/1402400261/O6ZHV30UH</link>
<guid>https://weibo.com/1402400261/O6ZHV30UH</guid>
<content:encoded><![CDATA[
<div> 微博，热门，分享，爱可可，3.27，关键词：

抖音，短视频，创作者，内容，粉丝，明星，合作，推广，营销，平台

<br /><br />总结:
3月27日，爱可可微博发布了热门分享内容，讨论的焦点主要集中在抖音平台上。抖音作为一个热门的短视频平台，吸引了众多创作者在上面发布各种内容，受到粉丝们的喜爱。不仅普通用户，就连明星也会在抖音上开设账号，与粉丝互动。同时，抖音也成为了许多品牌推广营销的平台，通过和创作者合作，进行推广活动，取得良好的营销效果。 <div>
《爱可可微博热门分享(3.27)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405016671747440838"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.27)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho5xwefsbuj20m80cijt5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 14:53:33 GMT</pubDate>
</item>
<item>
<title>【Redis架构演进之路】就像罗马不是一天建成的，Redis的架构也是随着时间的推移而不断进化的。 - Redis最初于2010年发布1.0版本，那时的架构非常简单，主要用作...</title>
<link>https://weibo.com/1402400261/O6YFu0ZOC</link>
<guid>https://weibo.com/1402400261/O6YFu0ZOC</guid>
<content:encoded><![CDATA[
<div> Redis、架构、演进、内存、持久化、故障转移、监控、集群、数据结构、多线程IO
<br /><br />总结:
Redis架构从简单的缓存应用不断演进，2013年的2.8版本引入了持久化和复制功能，提高了可用性。2015年的3.0版本推出集群功能，通过数据分片管理数据。2017年的5.0版本新增了Stream数据类型，2020年的6.0版本引入了多线程IO处理，进一步提升了性能。Redis的架构演进之路充满智慧和汗水，体现了业界对高性能、高可用数据存储的追求。Redis不断成长为强大的内存数据库，为业务应用开发带来便利和高效。Redis的发展历程，展示了持续创新和不断进化的精神。Redis架构模型的优化和技术的不断引入，为用户提供更稳定、更高效的数据服务。Redis的成功也启示着业界追求卓越的态度，值得持续关注和学习。 <div>
【Redis架构演进之路】<br />就像罗马不是一天建成的，Redis的架构也是随着时间的推移而不断进化的。   <br />- Redis最初于2010年发布1.0版本，那时的架构非常简单，主要用作业务应用的缓存。但由于Redis是将数据存储在内存中，一旦重启，所有数据就会丢失，流量会直接冲击数据库。   <br />- 到了2013年，Redis 2.8版本解决了这个问题。它引入了RDB内存快照来持久化数据，同时还支持AOF(Append-Only-File)方式，将每个写命令都写入AOF文件。此外，Redis 2.8还增加了复制功能来提高可用性。主节点处理实时的读写请求，从节点则同步主节点的数据。   <br />- 为了实时监控Redis实例，Redis 2.8推出了Sentinel(哨兵)。它承担四大任务：监控、通知、自动故障转移和配置提供者。可以说，Sentinel为Redis保驾护航，时刻守护着Redis的可用性。   <br />- Redis的下一个里程碑是2015年发布的3.0版本，该版本增加了Redis集群功能。Redis集群是一种分布式数据库解决方案，通过数据分片来管理数据。整个数据被分为16384个槽位，每个节点负责一部分槽位。这就好比将一个大蛋糕切成16384份，分给不同的人去管理。   <br />- Redis之所以备受欢迎，是因为其高性能和丰富的数据结构，大大降低了开发业务应用的复杂度。2017年发布的Redis 5.0新增了Stream数据类型。2020年发布的Redis 6.0则引入了多线程IO处理，进一步提升了性能。Redis的架构模型被划分为网络模块和主处理模块，开发者发现网络模块往往会成为系统的瓶颈。而多线程IO的引入，则解决了这个潜在的问题。   <br />Redis的架构演进之路，充满了智慧和汗水。从最初简单的缓存应用，到集群分片、多线程IO，Redis一步步成长为今天这个强大的内存数据库。它的发展历程，也映射出了业界对高性能、高可用数据存储的追求。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho5tas9ihej20u01k9qbj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho5tbbdmc6j20te10otfe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 12:14:48 GMT</pubDate>
</item>
<item>
<title>【Sora运行揭秘】- Sora是基于Latent Diffusion和Transformer的扩散模型，相比早期的图像生成模型显著提升了视频质量和一致性。 - 数据量和计算量的扩大是改进视...</title>
<link>https://weibo.com/1402400261/O6YA4eBGV</link>
<guid>https://weibo.com/1402400261/O6YA4eBGV</guid>
<content:encoded><![CDATA[
<div> Latent Diffusion、Transformer、视频质量、计算量、用户界面、训练计算量、应用渗透度、真实世界模拟、合成数据、机器学习技术

总结:<br /><br />
Sora是基于Latent Diffusion和Transformer的扩散模型，提升了视频质量和一致性。数据量和计算量的扩大是改进视频生成模型的关键，计算量增加将带来性能提升。Runway等公司正在研发Sora用户界面，对实用性至关重要。训练计算量巨大，推理计算将大于训练。Sora学会了模拟真实世界，可用于合成数据和数据增强。Sora代表了视频生成模型向更高质量发展里程碑，展示了先进机器学习技术潜力。训练数据对性能至关重要，Sora可能借助大型视频数据集。AI生成视频技术的快速发展将影响多个行业，未来电影制作可能由AI完成。视频生成模型发展将增大对算力尤其GPU的需求，Sora为未来GPU需求预测提供重要参考。 <div>
【Sora运行揭秘】<br />- Sora是基于Latent Diffusion和Transformer的扩散模型，相比早期的图像生成模型显著提升了视频质量和一致性。   <br />- 数据量和计算量的扩大是改进视频生成模型的关键，与大语言模型类似，可以预期计算量持续增加会带来模型性能的快速提升。   <br />- Runway等公司正在研发Sora等模型的用户界面和工作流程，这对其实用性至关重要。   <br />- Sora的训练计算量巨大，据估计需要4200-10500块H100 GPU计算一个月。但推理计算要大于训练计算，“收支平衡点”在生成1530-3810万分钟视频后。   <br />- 如果Sora类模型在TikTok和Youtube等平台达到较高应用渗透度，预计峰值需求将达到约72万个H100 GPU。   <br />- Sora隐含地学会了模拟真实世界，这对于在像素空间大规模训练机器人等具身智能体非常有用。   <br />- Sora类模型也可用于生成合成数据和数据增强，为缺乏数据的领域提供帮助。<br /><br />思考：  <br />- Sora代表了视频生成模型向更大规模、更高质量方向发展的重要里程碑。  <br />- Sora采用了多种先进的机器学习技术，包括扩散模型、潜在空间建模和Transformer架构，展示了这些技术在视频生成领域的巨大潜力。  <br />- 大规模高质量的训练数据对于视频生成模型的性能至关重要。Sora很可能得益于一个前所未有的大型视频数据集。  <br />- Sora的出现预示着AI生成视频技术的快速发展，将对电影、广告等多个行业产生深远影响。未来，AI有可能生成完整的电影，彻底改变视频内容的制作方式。  <br />- 随着视频生成模型的不断发展，对算力尤其是GPU的需求也将大幅增长。Sora为业界对未来GPU需求的预测提供了重要参考。<br />《Factorial Funds | Under The Hood: How OpenAI's Sora Model Works》 <a href="https://www.factorialfunds.com/blog/under-the-hood-how-openai-s-sora-model-works"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho5sx94j2qj20tu0grjup.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 12:01:28 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Mastering Memory Tasks with World Models》(ICLR 2024) GitHub: github.com/chandar-lab/Recall2Imagine《Composed Video Retrieval via ...</title>
<link>https://weibo.com/1402400261/O6WfYlh3o</link>
<guid>https://weibo.com/1402400261/O6WfYlh3o</guid>
<content:encoded><![CDATA[
<div> 关键词: Memory Tasks, World Models, Recall2Imagine, Video Retrieval, Logit Standardization, Knowledge Distillation, Vision-Language Models, Spec-Gaussian, AniPortrait, Data Mixing Laws

总结:<br /><br />本文介绍了几篇论文的实现代码，涵盖了多个领域包括记忆任务、视频检索、知识蒸馏、视觉-语言模型等。第一篇论文《Mastering Memory Tasks with World Models》通过实现代码Recall2Imagine来实现记忆任务。第二篇论文《Composed Video Retrieval via Enriched Context and Discriminative Embeddings》介绍了视频检索方法。第三篇论文《Logit Standardization in Knowledge Distillation》探讨了知识蒸馏中logit标准化的重要性。第四篇论文《Dual Memory Networks: A Versatile Adaptation Approach for Vision-Language Models》提出了一种适用于视觉-语言模型的双重记忆网络方法。还有其他论文涉及3D高斯光滑、音频驱动的动态图像合成、数据混合规律、波谱图像处理等多个领域。这些论文的实现代码均可在GitHub上找到，为相关研究领域的学术研究者提供了重要的参考资源。 <div>
几篇论文实现代码：<br />《Mastering Memory Tasks with World Models》(ICLR 2024) GitHub: github.com/chandar-lab/Recall2Imagine<br />《Composed Video Retrieval via Enriched Context and Discriminative Embeddings》(CVPR 2024) GitHub: github.com/OmkarThawakar/composed-video-retrieval<br />《Logit Standardization in Knowledge Distillation》(CVPR 2024) GitHub: github.com/sunshangquan/logit-standardization-KD<br />《Dual Memory Networks: A Versatile Adaptation Approach for Vision-Language Models》(CVPR 2024) GitHub: github.com/YBZh/DMN [fig4]<br />《Spec-Gaussian: Anisotropic View-Dependent Appearance for 3D Gaussian Splatting》(2024) GitHub: github.com/ingra14m/Specular-Gaussians<br />《AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animations》(2024) GitHub: github.com/Zejun-Yang/AniPortrait [fig1]<br />《Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance》(2024) GitHub: github.com/yegcjs/mixinglaws<br />《RGBD GS-ICP SLAM》(2024) GitHub: github.com/Lab-of-AI-and-Robotics/GS_ICP_SLAM<br />《AdaIR: Adaptive All-in-One Image Restoration via Frequency Mining and Modulation》(2024) GitHub: github.com/c-yn/AdaIR [fig2]<br />《Sotopia-π: Interactive Learning of Socially Intelligent Language Agents》(2024) GitHub: github.com/sotopia-lab/sotopia-pi [fig3]<br />《Visual CoT: Unleashing Chain-of-Thought Reasoning in the Multi-Modal Language Model》(2024) GitHub: github.com/deepcs233/Visual-CoT [fig5]<br />《LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models》(2024) GitHub: github.com/42Shawn/LLaVA-PruMerge<br />《GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks》(2024) GitHub: github.com/alibaba/GraphTranslator [fig6]<br />《Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance》(2024) GitHub: github.com/fudan-generative-vision/champ<br />《Optimizing LiDAR Placements for Robust Driving Perception in Adverse Conditions》(2024) GitHub: github.com/ywyeli/Place3D<br />《TC4D: Trajectory-Conditioned Text-to-4D Generation》(2024) GitHub: github.com/sherwinbahmani/tc4d<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho5hr2enfbj214y0sddtp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho5hu2pesmj20qi0hz7i3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho5humfr3hj21jk1jkkh6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho5ia4849cj20lb0fg46o.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho5iaui3hij21740gy430.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho5ihzzcdhj21h60tsgvg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 06:06:28 GMT</pubDate>
</item>
<item>
<title>【Go-Redis：快速高效的内存型 Key-Value 存储，Redis的替代方案，用 Go 语言实现】'Go-Redis - Super fast drop-in replacement of the in memory key-value st...</title>
<link>https://weibo.com/1402400261/O6WfRkdaQ</link>
<guid>https://weibo.com/1402400261/O6WfRkdaQ</guid>
<content:encoded><![CDATA[
<div> Go-Redis、快速、高效、内存型、Key-Value、存储、替代方案、Go语言实现、GitHub、Dhravya

<br /><br />总结:
Go-Redis是一个快速高效的内存型Key-Value存储，是Redis的替代方案，用Go语言实现。该项目托管在GitHub上，由Dhravya开发。Go-Redis是一个极具竞争力的项目，旨在提供与Redis相当甚至更快的性能。由于使用了Go语言实现，Go-Redis具有高效的并发处理能力和优秀的执行性能。通过使用Go-Redis，用户可以获得比传统的Redis更快的操作速度，这使得它成为许多项目的理想选择。如果您正在寻找一个快速、高效且易于集成的Key-Value存储解决方案，Go-Redis可能是您的不二之选。 <div>
【Go-Redis：快速高效的内存型 Key-Value 存储，Redis的替代方案，用 Go 语言实现】'Go-Redis - Super fast drop-in replacement of the in memory key-value store Redis, made in Golang' GitHub: github.com/Dhravya/go-redis <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Redis%23"><span class="surl-text">#Redis#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5inu9wf5j212f0u0q5w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 06:06:11 GMT</pubDate>
</item>
<item>
<title>【C-Shopping：基于Nextjs开发同时适配Desktop、Tablet、Phone多种设备的精美购物平台】'C-Shopping v1.0.0 - A beautiful shopping platform developed with Ne...</title>
<link>https://weibo.com/1402400261/O6WamwqdU</link>
<guid>https://weibo.com/1402400261/O6WamwqdU</guid>
<content:encoded><![CDATA[
<div> Next.js, Desktop, Tablet, Phone, 购物平台, 适配, GitHub, 开发, 设备, 精美

<br /><br />总结:
"C-Shopping v1.0.0"是一个基于Next.js开发的购物平台，可以适配多种设备，包括Desktop、Tablet和Phone。这个平台具有精美的界面设计，开发者已经将代码上传到GitHub上。希望通过这个平台提供更好的用户体验，满足不同设备的需求。 <div>
【C-Shopping：基于Nextjs开发同时适配Desktop、Tablet、Phone多种设备的精美购物平台】'C-Shopping v1.0.0 - A beautiful shopping platform developed with Next.js, tailored for various devices including Desktop, Tablet, and Phone. ' GitHub: github.com/huanghanzhilian/c-shopping <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho5i9ndpbej20dw07x0up.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5i9o9wgyj20rs0fq0ub.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5i9qf5elj20rs0fqdh6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:52:39 GMT</pubDate>
</item>
<item>
<title>【Flatito:用于搜索 YAML 和 JSON 文件的Grep工具，它可以帮助搜索文件中特定的关键字并获取相关信息】'Flatito: Grep for YAML and JSON files - Grep for YAML...</title>
<link>https://weibo.com/1402400261/O6W9hxmvS</link>
<guid>https://weibo.com/1402400261/O6W9hxmvS</guid>
<content:encoded><![CDATA[
<div> GitHub，Flatito，Grep，YAML，JSON，搜索工具，关键字，获取信息，ceritium，文件<br /><br />总结:
文章介绍了一款名为Flatito的工具，在GitHub上开源，用于搜索YAML和JSON文件中特定关键字的Grep工具。用户可以通过使用Flatito，搜索文件中的关键字，并获取相关信息。Flatito为程序员提供了便利，使他们能够快速准确地定位文件中的信息，提高工作效率。Flatito由ceritium开发，为用户提供了一个方便的工具，帮助他们更好地管理和处理YAML和JSON文件。 <div>
【Flatito:用于搜索 YAML 和 JSON 文件的Grep工具，它可以帮助搜索文件中特定的关键字并获取相关信息】'Flatito: Grep for YAML and JSON files - Grep for YAML and JSON files' GitHub: github.com/ceritium/flatito <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho5i6zke6sj20ui0u0dlc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:49:59 GMT</pubDate>
</item>
<item>
<title>【LLM-Culture：用于研究大型语言模型文化演化的开源框架】'LLM-Culture' GitHub: github.com/jeremyperez2/LLM-Culture #开源# #机器学习# #人工智能# [图片][...</title>
<link>https://weibo.com/1402400261/O6W8b6Y2a</link>
<guid>https://weibo.com/1402400261/O6W8b6Y2a</guid>
<content:encoded><![CDATA[
<div> GitHub, LLM-Culture, 研究, 大型语言模型, 文化演化, 开源框架

<br /><br />总结:
LLM-Culture是一个用于研究大型语言模型文化演化的开源框架。该项目存储在GitHub上，旨在探讨和分析语言模型在不同文化背景下的发展和变化。通过这个框架，研究人员可以对大型语言模型的文化演化有更深入的理解，并且可以进行进一步的研究和探索。希望这个工具能够为语言模型研究领域带来更多的启发和成果。 <div>
【LLM-Culture：用于研究大型语言模型文化演化的开源框架】'LLM-Culture' GitHub: github.com/jeremyperez2/LLM-Culture <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho5i41xnnmj22rl0u0wo9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5i43nxr3j21c00u0wh6.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho5i456uhyj22n90u0wog.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:47:16 GMT</pubDate>
</item>
<item>
<title>【WhatTheDuck：用于 DuckDB 的开源 web 应用，用户能将 CSV 文件上传并将其存储在表格中，并通过 SQL 进行查询】'WhatTheDuck - an open-source web applicatio...</title>
<link>https://weibo.com/1402400261/O6W7maOoB</link>
<guid>https://weibo.com/1402400261/O6W7maOoB</guid>
<content:encoded><![CDATA[
<div> DuckDB, 开源, web 应用, CSV 文件, 存储, 表格, SQL 查询, GitHub, incentius-foss, WhatTheDuck

<br /><br />总结:
WhatTheDuck是一个基于DuckDB的开源web应用，允许用户上传CSV文件并将其存储在表格中，然后通过SQL查询数据。用户可以在GitHub上找到该项目的代码，链接为github.com/incentius-foss/WhatTheDuck。通过WhatTheDuck，用户可以方便地管理CSV数据并进行SQL查询操作，为数据分析和处理提供了便利和效率。 <div>
【WhatTheDuck：用于 DuckDB 的开源 web 应用，用户能将 CSV 文件上传并将其存储在表格中，并通过 SQL 进行查询】'WhatTheDuck - an open-source web application built on DuckDB. It allows users to upload CSV files, store them in tables, and perform SQL queries on the data.' GitHub: github.com/incentius-foss/WhatTheDuck <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%95%B0%E6%8D%AE%E5%BA%93%23&amp;isnewpage=1"><span class="surl-text">#数据库#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5i21ftj3j21im0pkgqe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:45:14 GMT</pubDate>
</item>
</channel>
</rss>