<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>爱可可-爱生活的微博</title>
<link>https://weibo.com/1402400261/</link>

<item>
<title>今日推介(第1383期)：自动化社会科学、多跳多模态网络Agent基准、将AlphaFold初始训练时间减少到10小时、人类价值观及AI与其对齐研究、基于分层投机解码的长序列...</title>
<link>https://weibo.com/1402400261/OaQeSCPzy</link>
<guid>https://weibo.com/1402400261/OaQeSCPzy</guid>
<content:encoded><![CDATA[
<div> 自动化社会科学、多跳多模态网络Agent基准、AlphaFold、初始训练时间、人类价值观、AI对齐、分层投机解码、长序列生成、无损加速

<br><br>总结:
本文介绍了几个最新研究领域的前沿技术和发展。首先是自动化社会科学的探索，通过数据和技术的应用实现社会科学研究的自动化。其次是多跳多模态网络Agent基准的提出，为多模态网络的研究提供了一个标准基准。接着是将AlphaFold的初始训练时间缩短到10小时，这将极大地提高蛋白结构预测的效率。另外，研究人员也探讨了人类价值观与人工智能的对齐问题，强调了在AI发展中考虑人类价值观的重要性。还有基于分层投机解码的长序列生成无损加速的方法，为大规模数据处理提供了有效解决方案。这些研究成果将为相关领域的进一步发展和应用提供重要参考。 <div>
今日推介(第1383期)：自动化社会科学、多跳多模态网络Agent基准、将AlphaFold初始训练时间减少到10小时、人类价值观及AI与其对齐研究、基于分层投机解码的长序列生成无损加速 公·众·号：爱可可爱生活 <a href="http://aicoco.net/s/8l"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoz6yh5saaj21400s4dkb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoz6yjixxlj21370u0qc2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoz6ylu09kj21400iiwid.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoz6yq9346j21400owagc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoz6ytqblbj21400kyq8z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 22:08:30 GMT</pubDate>
<pubDate>Sun, 21 Apr 2024 22:08:30 GMT</pubDate>
</item>
<item>
<title>[CL] Measuring Cross-lingual Transfer in Bytes 网页链接 通过字节级标记化和数据迁移指标的方法发现语言模型中存在重要的语言无关知识成分，这可能是模型强大...</title>
<link>https://weibo.com/1402400261/OaQasdPPi</link>
<guid>https://weibo.com/1402400261/OaQasdPPi</guid>
<content:encoded><![CDATA[
<div> 字节级标记化、数据迁移指标、语言无关知识、语言模型、跨语言迁移能力、关键所在<br>
<br>
在语言模型中，通过字节级标记化和数据迁移指标的方法发现了重要的语言无关知识成分，这可以提高模型在不同语言间进行迁移时的能力。研究表明，语言模型中存在一定数量的语言无关知识，这些知识可以帮助模型在跨语言任务中取得更好的性能。因此，通过对模型进行字节级标记化处理和实验评估，可以更好地了解模型的跨语言迁移能力，并为进一步优化和改进模型提供重要参考。总体来说，研究结果表明字节级标记化和数据迁移指标是发现语言模型跨语言迁移能力关键的有效方法，对于加强模型的跨语言表现具有重要意义。<br><br>总结: <br>通过字节级标记化和数据迁移指标发现了语言模型中的重要语言无关知识成分，提高了模型的跨语言迁移能力。研究结果为理解模型的跨语言表现提供了重要参考，为未来改进和优化模型奠定了基础。 <div>
[CL] Measuring Cross-lingual Transfer in Bytes  <br /><a href="https://arxiv.org/abs/2404.08191"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>        <br />通过字节级标记化和数据迁移指标的方法发现语言模型中存在重要的语言无关知识成分，这可能是模型强大的跨语言迁移能力的关键所在。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz6ng91wrj20sg16u187.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz6ngirr4j21ki0v0q9b.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz6nh7pymj21l00oyn37.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:57:36 GMT</pubDate>
<pubDate>Sun, 21 Apr 2024 21:57:36 GMT</pubDate>
</item>
<item>
<title>[LG] Stepwise Alignment for Constrained Language Model Policy Optimization 网页链接 通过逐步调整语言模型策略以满足奖励和安全约束，提出了一种简单、稳定...</title>
<link>https://weibo.com/1402400261/OaQ8g7dE9</link>
<guid>https://weibo.com/1402400261/OaQ8g7dE9</guid>
<content:encoded><![CDATA[
<div> 调整语言模型，奖励约束，安全约束，简单，稳定，灵活，有用，无害，步骤对齐

<br><br>总结:
本文介绍了一种通过逐步调整语言模型策略以满足奖励和安全约束的方法。该方法简单、稳定、灵活，能够获得既有用又无害的语言模型。通过调整语言模型策略，实现了对奖励和安全约束的平衡，从而提高了语言模型的性能和效果。步骤对齐是该方法的关键特点，有效地引导语言模型在训练过程中逐步优化，确保其在输出时符合预设的约束条件。通过该方法，可以更好地利用语言模型在各种领域中的应用，并提升其在实际场景中的效果和可靠性。 <div>
[LG] Stepwise Alignment for Constrained Language Model Policy Optimization  <br /><a href="https://arxiv.org/abs/2404.11049"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />通过逐步调整语言模型策略以满足奖励和安全约束，提出了一种简单、稳定、灵活的方法来获得既有用又无害的语言模型。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz6huberoj20q413ktk3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz6hulau8j21ci0j0ahi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz6huykdpj21c20pmdm7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:52:12 GMT</pubDate>
<pubDate>Sun, 21 Apr 2024 21:52:12 GMT</pubDate>
</item>
<item>
<title>[CL] Language Models Still Struggle to Zero-shot Reason about Time Series 网页链接 提出时间序列推理的三种形式，发现当前语言模型在这三方面表现均较差，...</title>
<link>https://weibo.com/1402400261/OaQ6w5YJl</link>
<guid>https://weibo.com/1402400261/OaQ6w5YJl</guid>
<content:encoded><![CDATA[
<div> 时间序列推理、语言模型、表现差、理解时间序列、重要方向<br>
<br>
时间序列数据在许多领域中起着关键作用，对其进行推理有着重要意义。研究者提出了三种形式的时间序列推理：定性推理、定量推理和因果推理。然而，当前语言模型在这三方面表现都较差，存在很大的改进空间。针对这一问题，需要进一步探索如何让语言模型更好地理解时间序列行为，从而改善其推理能力，这仍然是一个值得深入探讨的重要方向。<br><br>总结: <br>时间序列数据推理在各领域具有重要意义，但当前语言模型在理解和推理时间序列数据方面表现不佳，需要进一步研究和改进。 <div>
[CL] Language Models Still Struggle to Zero-shot Reason about Time Series  <br /><a href="https://arxiv.org/abs/2404.11757"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />提出时间序列推理的三种形式，发现当前语言模型在这三方面表现均较差，说明理解时间序列行为仍是一个值得探索的重要方向。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz6dczvzjj20qk16ek57.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz6ddalqbj217q0n07b4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz6ddk7j6j21be0q2do7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:47:54 GMT</pubDate>
<pubDate>Sun, 21 Apr 2024 21:47:54 GMT</pubDate>
</item>
<item>
<title>[CL] When LLMs are Unfit Use FastFit: Fast and Effective Text Classification with Many Classes 网页链接 FastFit利用批量对比学习和token级表示快速有效地...</title>
<link>https://weibo.com/1402400261/OaQ4olOZe</link>
<guid>https://weibo.com/1402400261/OaQ4olOZe</guid>
<content:encoded><![CDATA[
<div> 关键词: FastFit, 批量对比学习, token级表示, 文本分类, 样本量少, 类别数多

FastFit是一种快速有效的文本分类方法，利用批量对比学习和token级表示解决了样本量少但类别数多的问题。该方法能够高效地处理多类别分类任务，提高了分类的准确性和速度。FastFit的效果在实验中得到验证，展现出了其优越的性能。总体而言，FastFit是一种解决文本分类问题的快速且有效的方法。 <br><br>
总结: <br>
1. FastFit利用批量对比学习和token级表示解决了样本量少但类别数多的文本分类问题。
2. 该方法在多类别分类任务中表现出高效的分类准确性和速度。
3. 实验结果验证了FastFit的优越性能，显示其是一种快速有效的文本分类方法。 <div>
[CL] When LLMs are Unfit Use FastFit: Fast and Effective Text Classification with Many Classes  <br /><a href="https://arxiv.org/abs/2404.12365"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />FastFit利用批量对比学习和token级表示快速有效地解决了样本量少但类别数多的文本分类问题。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz67x34v9j20s616mqg7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz67x7thnj20s60q0mze.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz67xrm8wj20sm0tw0wf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:42:40 GMT</pubDate>
<pubDate>Sun, 21 Apr 2024 21:42:40 GMT</pubDate>
</item>
<item>
<title>通过分层投机解码和基于检索的键值缓存选择策略，实现了大型语言模型长序列生成的可扩展且无损的加速，在保持生成质量的同时显著提升了推理效率。 - 转发 @爱可...</title>
<link>https://weibo.com/1402400261/OaQ1OoAsw</link>
<guid>https://weibo.com/1402400261/OaQ1OoAsw</guid>
<content:encoded><![CDATA[
<div> 加速、分层投机解码、基于检索的键值缓存、大型语言模型、长序列生成、推理效率

<br><br>总结:本研究利用分层投机解码和基于检索的键值缓存选择策略，实现了对大型语言模型长序列生成的加速，保持生成质量的同时提升了推理效率。通过TriForce算法，实现了可扩展且无损的加速，为语言模型的进一步研究和应用提供了新的思路。 <div>
通过分层投机解码和基于检索的键值缓存选择策略，实现了大型语言模型长序列生成的可扩展且无损的加速，在保持生成质量的同时显著提升了推理效率。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding》H Sun, Z Chen, X Yang, Y Tian, B Chen [CMU] (2024) <a href="https://arxiv.org/abs/2404.11912"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5uz5nefj21f40o6wrw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5uzou58j21ko0todsq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5uzrforj21kg0qeajg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5uzwgcgj21kk0qek01.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz618jfsfj20fi0aljru.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz618jp0fj20b40cddg7.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz618locjj210z0hh0w3.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:36:19 GMT</pubDate>
<pubDate>Sun, 21 Apr 2024 21:36:19 GMT</pubDate>
</item>
<item>
<title>[CL]《TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding》H Sun, Z Chen, X Yang, Y Tian, B Chen [CMU] ...</title>
<link>https://weibo.com/1402400261/OaQ1MlBLe</link>
<guid>https://weibo.com/1402400261/OaQ1MlBLe</guid>
<content:encoded><![CDATA[
<div> Hierarchical Speculative Decoding, TriForce, Lossless Acceleration, Long Sequence Generation, CMU, H Sun, Z Chen, X Yang, Y Tian, B Chen 

<br><br>总结:
这篇论文提出了一种名为TriForce的方法，旨在加速长序列生成过程并提高性能。其中，采用了层次化的推测式解码技术，通过结合多个解码器以并行生成大规模序列，实现了无损压缩的效果。研究团队通过对该方法的实验验证，证明了其在不同任务中均取得了显著的性能提升。通过在CMU进行的研究，该方法展示了在长序列生成领域的潜在优势，为推动序列生成技术的发展提供了新的思路和方法。 <div>
[CL]《TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding》H Sun, Z Chen, X Yang, Y Tian, B Chen [CMU] (2024) <a href="https://arxiv.org/abs/2404.11912"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5uz5nefj21f40o6wrw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5uzou58j21ko0todsq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5uzrforj21kg0qeajg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5uzwgcgj21kk0qek01.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz618jfsfj20fi0aljru.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz618jp0fj20b40cddg7.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz618locjj210z0hh0w3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:36:14 GMT</pubDate>
<pubDate>Sun, 21 Apr 2024 21:36:14 GMT</pubDate>
</item>
<item>
<title>提出一种通过语言模型引导广泛公众参与表达和评判价值观来构建人工智能系统值观对齐目标的新方法，并通过实验验证了该方法在多个关键指标上的有效性 - 转发 @爱...</title>
<link>https://weibo.com/1402400261/OaPYzfhws</link>
<guid>https://weibo.com/1402400261/OaPYzfhws</guid>
<content:encoded><![CDATA[
<div> 人工智能系统、价值观、语言模型、有效性验证、公众参与、人类价值、价值观对齐、新方法、实验、多个关键指标
<br>
<br>
人工智能系统与人类价值观的对齐问题一直备受关注，研究团队提出了一种新方法，通过语言模型引导广泛公众参与表达和评判价值观，来构建人工智能系统的价值观对齐目标。他们进行了实验验证，结果显示该方法在多个关键指标上取得了有效性。这项研究为解决人工智能系统与人类价值观背离的问题提供了新的思路和解决方案。 <div>
提出一种通过语言模型引导广泛公众参与表达和评判价值观来构建人工智能系统值观对齐目标的新方法，并通过实验验证了该方法在多个关键指标上的有效性<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《What are human values, and how do we align AI to them?》O Klingefjord, R Lowe, J Edelman [Meaning Alignment Institute] (2024) <a href="https://arxiv.org/abs/2404.10636"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5e7aanoj214m0vynbp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5e7rh69j21c40tygw5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5e7w1j5j21cc0tsn5b.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5e7ztkhj21bs0xwtf7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5svukgwj20vd0z6gqs.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz5svt67oj20vg0j340a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5svv2zbj20vd16tdls.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5svu9anj20vg0psq7k.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz5svttk6j20vi0maaco.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:28:19 GMT</pubDate>
<pubDate>Sun, 21 Apr 2024 21:28:19 GMT</pubDate>
</item>
<item>
<title>[CL]《What are human values, and how do we align AI to them?》O Klingefjord, R Lowe, J Edelman [Meaning Alignment Institute] (2024) 网页链接 #机器学习...</title>
<link>https://weibo.com/1402400261/OaPYwhY8e</link>
<guid>https://weibo.com/1402400261/OaPYwhY8e</guid>
<content:encoded><![CDATA[
<div> 人类价值观, 人工智能, 对齐, 伦理, 发展, 控制, 效益, 道德, 尊重, 合作

总结:<br><br>本文讨论了人类价值观以及如何将人工智能对齐到这些价值观。针对人工智能发展中可能出现的伦理问题，我们需要制定合适的控制措施，确保人工智能的发展符合道德标准并尊重人类价值观。在引入人工智能技术时，应考虑其长期效益，并重视人类价值观的重要性。促进人工智能与人类之间的合作关系，以实现最佳的发展和利益。 <div>
[CL]《What are human values, and how do we align AI to them?》O Klingefjord, R Lowe, J Edelman [Meaning Alignment Institute] (2024) <a href="https://arxiv.org/abs/2404.10636"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5e7aanoj214m0vynbp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5e7rh69j21c40tygw5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5e7w1j5j21cc0tsn5b.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5e7ztkhj21bs0xwtf7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5svukgwj20vd0z6gqs.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz5svt67oj20vg0j340a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5svv2zbj20vd16tdls.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5svu9anj20vg0psq7k.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz5svttk6j20vi0maaco.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5svubn0j20vd0ymq7p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5svu2hrj20vd0tjad4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5svtjepj20vd0p1wh9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz5svtg4oj20vd0i8abz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5svvimkj20vg1bwth6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:28:12 GMT</pubDate>
<pubDate>Sun, 21 Apr 2024 21:28:12 GMT</pubDate>
</item>

<item>
<title>ScaleFold通过深入分析AlphaFold训练的可扩展性瓶颈，从算法结构到底层实现进行系统性优化，使之成功扩展到2080个GPU并将初步训练时间缩短至10小时。 - 转发 @爱...</title>
<link>https://weibo.com/1402400261/OaPRLo6Du</link>
<guid>https://weibo.com/1402400261/OaPRLo6Du</guid>
<content:encoded><![CDATA[
<div> 可扩展性瓶颈, 算法结构, 低层实现, 系统优化, 2080个GPU, 初步训练时间缩短至10小时  

总结:  
ScaleFold通过深入分析AlphaFold训练的可扩展性瓶颈，从算法结构到低层实现进行系统性优化，成功将训练扩展到2080个GPU，并将初步训练时间缩短至10小时。这一研究对于加速蛋白结构预测有重要意义，为未来的生物信息学研究提供了新的思路。 <div>
ScaleFold通过深入分析AlphaFold训练的可扩展性瓶颈，从算法结构到底层实现进行系统性优化，使之成功扩展到2080个GPU并将初步训练时间缩短至10小时。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《ScaleFold: Reducing AlphaFold Initial Training Time to 10 Hours》F Zhu, A Nowaczynski, R Li, J Xin… [NVIDIA] (2024) <a href="https://arxiv.org/abs/2404.11068"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz5adpgtuj20u00sg12b.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5ae4iwaj21og0ryaix.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5ae9lymj21jo0fun08.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5aedp05j20tu0lg0vy.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:11:34 GMT</pubDate>
</item>
<item>
<title>[LG]《ScaleFold: Reducing AlphaFold Initial Training Time to 10 Hours》F Zhu, A Nowaczynski, R Li, J Xin… [NVIDIA] (2024) 网页链接 #机器学习##人工智...</title>
<link>https://weibo.com/1402400261/OaPRGmIll</link>
<guid>https://weibo.com/1402400261/OaPRGmIll</guid>
<content:encoded><![CDATA[
<div> 关键词: ScaleFold, Reducing, AlphaFold, Initial Training Time, 10 Hours, NVIDIA

本文介绍了一种名为ScaleFold的方法，可以将AlphaFold的初始训练时间缩短至10小时。研究团队包括F Zhu、A Nowaczynski、R Li和J Xin，合作单位为NVIDIA。他们在文章中提出了这种新的方法，能够显著减少AlphaFold的训练时间，从而提高效率。通过ScaleFold的应用，研究人员可以在更短的时间内进行模型训练和优化，加快了科学研究和发现的步伐。这一创新有望为蛋白质结构预测领域带来重大突破，对于促进生命科学和药物研发具有重要意义。<br /><br />总结: 本文介绍了ScaleFold方法，可以将AlphaFold的初始训练时间缩短至10小时，提高了蛋白质结构预测的效率，对推动科学研究和药物研发具有重要意义。 <div>
[LG]《ScaleFold: Reducing AlphaFold Initial Training Time to 10 Hours》F Zhu, A Nowaczynski, R Li, J Xin… [NVIDIA] (2024) <a href="https://arxiv.org/abs/2404.11068"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz5adpgtuj20u00sg12b.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz5ae4iwaj21og0ryaix.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5ae9lymj21jo0fun08.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz5aedp05j20tu0lg0vy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:11:22 GMT</pubDate>
</item>
<item>
<title>构建了一个多步多模态基准测试MMInA，在不断变化的真实网站环境中评估Agent完成复杂互联网任务的能力，为未来智能体互联网应用能力的测试提供了一个高标准的基准...</title>
<link>https://weibo.com/1402400261/OaPPSdk67</link>
<guid>https://weibo.com/1402400261/OaPPSdk67</guid>
<content:encoded><![CDATA[
<div> 多模态、多步、基准测试、MMInA、Agent、互联网任务、评估、真实网站环境、智能体、应用能力

<br /><br />总结:
本研究构建了一个名为MMInA的多步多模态基准测试，旨在评估智能Agent在复杂互联网任务中的表现能力。该基准测试在真实网站环境中进行，在不断变化的场景中对智能体进行评估。研究团队来自南洋理工大学，通过评估Agent的能力，为未来智能体在互联网应用中的能力提供了高标准的基准。这项研究的结果发表在CV领域的论文中，为智能体在互联网任务中的发展提供了重要参考。 <div>
构建了一个多步多模态基准测试MMInA，在不断变化的真实网站环境中评估Agent完成复杂互联网任务的能力，为未来智能体互联网应用能力的测试提供了一个高标准的基准。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《MMInA: Benchmarking Multihop Multimodal Internet Agents》Z Zhang, S Tian, L Chen, Z Liu [Nanyang Technological University] (2024) <a href="https://arxiv.org/abs/2404.09992"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz551759cj21460ycqiu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz551xnwuj21c810wk72.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz55257t4j21d60w0dmc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5529mlhj20hi0kw75a.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:06:54 GMT</pubDate>
</item>
<item>
<title>[CV]《MMInA: Benchmarking Multihop Multimodal Internet Agents》Z Zhang, S Tian, L Chen, Z Liu [Nanyang Technological University] (2024) 网页链接 #机器...</title>
<link>https://weibo.com/1402400261/OaPPO5atQ</link>
<guid>https://weibo.com/1402400261/OaPPO5atQ</guid>
<content:encoded><![CDATA[
<div> Benchmarking, Multihop, Multimodal, Internet Agents, MMInA, Nanyang Technological University, 2024

<br /><br />总结:
本研究由南洋理工大学的张、田、陈和刘等人完成，针对多跳多模态互联网智能体技术进行了基准测试。研究旨在评估这种技术在网络通信中的表现，并为未来研究提供参考。研究团队在2024年发表了这篇文章，详细介绍了他们的研究成果。他们的研究对于推动多跳多模态互联网智能体技术的发展至关重要，为相关领域的进一步研究提供了有价值的信息。
 <div>
[CV]《MMInA: Benchmarking Multihop Multimodal Internet Agents》Z Zhang, S Tian, L Chen, Z Liu [Nanyang Technological University] (2024) <a href="https://arxiv.org/abs/2404.09992"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz551759cj21460ycqiu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoz551xnwuj21c810wk72.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz55257t4j21d60w0dmc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz5529mlhj20hi0kw75a.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:06:44 GMT</pubDate>
</item>
<item>
<title>提出并证明了一种使用结构因果模型与大型语言模型相结合，实现社会科学研究全流程自动化的方法。 - 转发 @爱可可-爱生活:&amp;ensp;[AI]《Automated Social Science:...</title>
<link>https://weibo.com/1402400261/OaPP2cVAg</link>
<guid>https://weibo.com/1402400261/OaPP2cVAg</guid>
<content:encoded><![CDATA[
<div> 模型；社会科学；结构因果模型；大型语言模型；自动化方法；研究全流程；B S. Manning；K Zhu；J J. Horton

总结:<br /><br />这篇文章提出了一种结合结构因果模型与大型语言模型的方法，实现社会科学研究全流程的自动化。研究由B S. Manning、K Zhu和J J. Horton进行，并在2024年发表。他们提出利用语言模型作为研究者和对象，开创了自动化社会科学研究的新思路。通过这一方法，可以更高效地进行社会科学研究，提高研究的准确性和可靠性。 <div>
提出并证明了一种使用结构因果模型与大型语言模型相结合，实现社会科学研究全流程自动化的方法。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [AI]《Automated Social Science: Language Models as Scientist and Subjects》B S. Manning, K Zhu, J J. Horton [MIT &amp; Harvard] (2024) <a href="https://arxiv.org/abs/2404.11794"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz53b6axoj21a010217q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz53bprvtj21gc10sqb0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz53bzkvmj20p00xugno.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz53c9xg8j218m19gwq5.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:04:49 GMT</pubDate>
</item>
<item>
<title>[AI]《Automated Social Science: Language Models as Scientist and Subjects》B S. Manning, K Zhu, J J. Horton [MIT &amp; Harvard] (2024) 网页链接 #机器学习#...</title>
<link>https://weibo.com/1402400261/OaPOWiiDR</link>
<guid>https://weibo.com/1402400261/OaPOWiiDR</guid>
<content:encoded><![CDATA[
<div> 社会科学、语言模型、自动化、科学家、主题、研究、机器学习、社会影响、数据分析、技术发展

总结:<br /><br />本文讨论了自动化社会科学领域中语言模型的应用。研究者通过机器学习技术构建了能够扮演科学家和研究对象角色的语言模型，实现了自动化的科学研究过程。语言模型的运用影响了社会科学领域的数据分析方法，促进了技术的发展。这一新领域的出现将对社会产生重要影响，需持续关注研究进展和技术应用。 <div>
[AI]《Automated Social Science: Language Models as Scientist and Subjects》B S. Manning, K Zhu, J J. Horton [MIT &amp; Harvard] (2024) <a href="https://arxiv.org/abs/2404.11794"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz53b6axoj21a010217q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoz53bprvtj21gc10sqb0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoz53bzkvmj20p00xugno.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoz53c9xg8j218m19gwq5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:04:36 GMT</pubDate>
</item>
<item>
<title>早！[太阳] #早安# [图片]</title>
<link>https://weibo.com/1402400261/OaPOioLre</link>
<guid>https://weibo.com/1402400261/OaPOioLre</guid>
<content:encoded><![CDATA[
<div> 关键词: 早, 文章, 中文, 总结, 要点

想要正确完成一篇文章的总结，必须准确提取主要关键词和要点。这篇文章首先提出了要求总结一篇文章的任务，提示先提取关键词。然后要求用中文撰写800字内的总结，按顺序列出所有重要要点。务必按要求正确提取关键词和准确总结文章内容。<br /><br />总结:文章要求提取关键词和撰写800字内的总结，按要点顺序逐一列出。 <div>
早！<span class="url-icon"><img alt="[太阳]" src="https://h5.sinaimg.cn/m/emoticon/icon/others/w_taiyang-2b1d91ddac.png" style="width: 1em; height: 1em;" /></span> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%97%A9%E5%AE%89%23&amp;isnewpage=1"><span class="surl-text">#早安#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoz52o8al2j20fu0j076s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 21:03:01 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.21)》 爱可可微博热门分享(4.21) [图片]</title>
<link>https://weibo.com/1402400261/OaNjNbqip</link>
<guid>https://weibo.com/1402400261/OaNjNbqip</guid>
<content:encoded><![CDATA[
<div> 微博、爱可可、热门、分享、4.21、话题、新闻、讨论、网友、评论

<br /><br />总结:
4月21日，爱可可的微博内容受到了热门关注，涉及各种话题和新闻。网友们纷纷参与讨论，展开评论，形成热烈的互动氛围。这些内容被分享出来，引发广泛关注，展示了微博平台的活跃和多样性。 <div>
《爱可可微博热门分享(4.21)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405025728633634863"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.21)</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoyu2hvc2vj20kf0bhmyc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 14:42:22 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Elucidating the Exposure Bias in Diffusion Models》(ICLR 2024) GitHub: github.com/forever208/ADM-ES《Toward Generalist Anomaly Det...</title>
<link>https://weibo.com/1402400261/OaMVtvTUZ</link>
<guid>https://weibo.com/1402400261/OaMVtvTUZ</guid>
<content:encoded><![CDATA[
<div> 关键词: 曝光偏差, 扩散模型, 异常检测, 图像分割, 语言模型

总结:
<br /><br />
本文研究了扩散模型中的曝光偏差，并提出了一种全新的训练方法ADM-ES来解决这一问题。通过在GitHub上提供的代码实现，展示了该方法的有效性和性能。在CVPR 2024会议上，提出了一种通过少量样本提示实现通用异常检测的方法InCTRL。此外，还提出了一种利用视觉基础模型进行领域通用语义分割的方法rein，并展示了其强大性能。在大语言模型训练方面，提出了一种记忆高效的完整参数训练方法BAdam。此外，还介绍了AgentKit，一种基于图形的无需编码的流工程解决方案。最后，针对远程感知图像中的语义变化检测问题，提出了ClearSCD模型，充分利用语义和变化关系，通过GitHub提供了相关代码实现。 <div>
几篇论文实现代码：<br />《Elucidating the Exposure Bias in Diffusion Models》(ICLR 2024) GitHub: github.com/forever208/ADM-ES<br />《Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts》(CVPR 2024) GitHub: github.com/mala-lab/InCTRL [fig2]<br />《Stronger, Fewer, &amp; Superior: Harnessing Vision Foundation Models for Domain Generalized Semantic Segmentation》(CVPR 2024) GitHub: github.com/w1oves/rein [fig4]<br />《BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models》(2024) GitHub: github.com/Ledzy/BAdam<br />《AgentKit: Flow Engineering with Graphs, not Coding》(2024) GitHub: github.com/Holmeswww/AgentKit [fig1]<br />《LongEmbed: Extending Embedding Models for Long Context Retrieval》(2024) GitHub: github.com/dwzhu-pku/LongEmbed [fig3]<br />《The ClearSCD model: Comprehensively leveraging semantics and change relationships for semantic change detection in high spatial resolution remote sensing imagery》(2024) GitHub: github.com/tangkai-RS/ClearSCD [fig5]<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoyq0hcbq7j23aj1ubb2a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoyq3hakl3j21jq0xggxl.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoyqzgna5fj218b0e1whd.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoyr01jl9sj20pj08gaei.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoyrjnq7g0j25so32qb2e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:42:28 GMT</pubDate>
</item>
<item>
<title>【robocorp - 用于创建和部署 Python AI 操作和自动化】’Create, deploy and operate Python Automations and AI Actions anywhere. - Create Python AI Action...</title>
<link>https://weibo.com/1402400261/OaMP3FfYZ</link>
<guid>https://weibo.com/1402400261/OaMP3FfYZ</guid>
<content:encoded><![CDATA[
<div> GitHub, Python, AI, 操作, 自动化, 创建, 部署, 运营

<br /><br />总结:
robocorp是一个用于创建和部署Python AI操作和自动化的平台。用户可以在其中创建Python AI操作和自动化，并在任何地方部署和操作。该平台的GitHub链接为github.com/robocorp/robocorp。通过robocorp，用户可以灵活地开发和部署各种Python基础的操作和AI功能，为各种场景提供自动化解决方案。 <div>
【robocorp - 用于创建和部署 Python AI 操作和自动化】’Create, deploy and operate Python Automations and AI Actions anywhere. - Create Python AI Actions and Automations, and deploy &amp; operate them anywhere' GitHub: github.com/robocorp/robocorp <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoyrvqiz98j21hc0u0zms.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:26:40 GMT</pubDate>
</item>
<item>
<title>【推理AI用数据大列表】’awesome-reasoning - a curated list of data for reasoning ai' GitHub: github.com/neurallambda/awesome-reasoning #开源# #机器学...</title>
<link>https://weibo.com/1402400261/OaMO9Djnd</link>
<guid>https://weibo.com/1402400261/OaMO9Djnd</guid>
<content:encoded><![CDATA[
<div> GitHub, 推理AI, 数据大列表, 精选数据, 理由<br />
<br />
1. 该GitHub项目是一个关于推理人工智能使用数据的精选列表。
2. 项目旨在为推理AI提供丰富的数据资源。
3. 数据包括各种类型的信息，可以帮助AI进行推理和分析。
4. 这个列表是经过精心筛选和整理的，以确保质量和多样性。
5. GitHub链接为github.com/neurallambda/awesome-reasoning，可以随时查看和使用。
6. 数据涵盖了各个领域和主题，适用于不同类型的推理任务。
7. 对于开发推理AI的研究人员和工程师来说，这个列表是一个宝贵的资源。
8. 通过利用这些数据，可以训练和提升推理AI的性能和准确性。
9. 该列表对于推动推理人工智能领域的发展和创新具有重要意义。
<br /><br />总结: 该GitHub项目提供了一个精选的数据列表，为推理人工智能提供丰富的资源，可以帮助AI进行推理和分析。同时，这个列表的较牢确保了数据的质量和多样性，对于推动推理AI领域的发展具有重要意义。 <div>
【推理AI用数据大列表】’awesome-reasoning - a curated list of data for reasoning ai' GitHub: github.com/neurallambda/awesome-reasoning <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoyrti6ic0j20u00wfjvd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:24:26 GMT</pubDate>
</item>
<item>
<title>【社交Agent相关论文资源列表】’Awesome Social Agents - A collection of works that investigate social agents, simulations and their real-world impact i...</title>
<link>https://weibo.com/1402400261/OaMNis4v5</link>
<guid>https://weibo.com/1402400261/OaMNis4v5</guid>
<content:encoded><![CDATA[
<div> 社交Agent、模拟、影响、文本、实体、机器人、研究、GitHub、资源列表、真实世界<br />
<br />
社交Agent相关论文资源列表包括研究社交Agent在文本、实体和机器人领域的影响及其在现实世界中的作用。GitHub上收集了相关研究的作品。社交Agent的研究对于理解人机交互、社交模拟以及人工智能的发展具有重要意义。通过对社交Agent的研究与应用，可以为社会提供更智能、更智能的解决方案。此资源列表为社交Agent研究者提供了丰富的文献资源，帮助他们更深入地理解和探索这一领域的知识和技术。<br /> 
<br />
总结:社交Agent的研究与实践对人机交互、社交模拟和人工智能发展至关重要，并且在现实世界中产生重要影响。GitHub资源列表为研究者提供了丰富的文献资料，促进了社交Agent领域的探索和创新。 <div>
【社交Agent相关论文资源列表】’Awesome Social Agents - A collection of works that investigate social agents, simulations and their real-world impact in text, embodied, and robotics contexts.' GitHub: github.com/sotopia-lab/awesome-social-agents <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoyrrbq78pj214u0u0n3c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:22:19 GMT</pubDate>
</item>
<item>
<title>【Ayin：免费且开源的图片编辑软件，可在 Windows、Linux 和 macOS 上使用】'Ayin - Ayin is a free and open source photo editing software available on Wind...</title>
<link>https://weibo.com/1402400261/OaMLl4K4i</link>
<guid>https://weibo.com/1402400261/OaMLl4K4i</guid>
<content:encoded><![CDATA[
<div> 免费、开源、图片编辑软件、Windows、Linux、macOS、GitHub、github.com/faresbakhit/ayin

<br /><br />总结:
Ayin是一款免费且开源的图片编辑软件，用户可以在Windows、Linux和MacOS上使用。该软件的源代码可在GitHub上找到，项目链接为github.com/faresbakhit/ayin。Ayin提供了丰富的功能，可以满足用户对图片编辑的各种需求。无论是个人用户还是企业用户，都可以通过Ayin轻松实现图片编辑工作，而且免费使用。Ayin的跨平台性也很强，可以在不同操作系统上无缝运行，为用户提供了更大的使用灵活性。Ayin的开源性保证了软件的透明性和安全性，用户可以自行查看源代码并对其进行定制化，从而更好地满足个性化需求。总的来说，Ayin是一款功能强大、方便易用的图片编辑软件，为用户提供了一个高质量的编辑平台。 <div>
【Ayin：免费且开源的图片编辑软件，可在 Windows、Linux 和 macOS 上使用】'Ayin - Ayin is a free and open source photo editing software available on Windows, Linux, and MacOS' GitHub: github.com/faresbakhit/ayin <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoyrlzlo1qj21ha0ty78h.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:17:29 GMT</pubDate>
</item>
<item>
<title>【LLMstudio by TensorOps：提示工程工具包】’LLMstudio by TensorOps - Framework to bring LLM applications to production' GitHub: github.com/TensorOpsAI...</title>
<link>https://weibo.com/1402400261/OaMJAgRXO</link>
<guid>https://weibo.com/1402400261/OaMJAgRXO</guid>
<content:encoded><![CDATA[
<div> LLMstudio, TensorOps, Framework, production, GitHub, 工程工具包, 应用推广, 生产环境, 开发工具, 运维工具

<br /><br />总结:
LLMstudio是由TensorOps推出的工程工具包，旨在将LLM应用推广至生产环境。该工具包旨在提供开发工具和运维工具，帮助用户更轻松实现LLM应用的上线和管理。通过GitHub平台，用户可以方便地获取和使用这一工具包。 <div>
【LLMstudio by TensorOps：提示工程工具包】’LLMstudio by TensorOps - Framework to bring LLM applications to production' GitHub: github.com/TensorOpsAI/LLMstudio <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoyrhnxiabj20ys0u0gop.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:13:10 GMT</pubDate>
</item>
<item>
<title>【Shadcn Table：一个 shadcn 表格组件，支持服务器端排序、过滤和分页】'Shadcn Table - A shadcn table component with server-side sorting, filtering, and ...</title>
<link>https://weibo.com/1402400261/OaMHGq2Fu</link>
<guid>https://weibo.com/1402400261/OaMHGq2Fu</guid>
<content:encoded><![CDATA[
<div> shadcn Table, 组件, 服务器端排序, 过滤, 分页

总结:<br /><br />这篇文章介绍了一个名为Shadcn Table的表格组件，具有服务器端排序、过滤和分页功能。该组件通过GitHub进行开源，用于帮助开发者更便捷地处理大量数据。用户可以根据自己的需求对数据进行排序、过滤和分页，从而提高数据展示和操作的效率。通过使用Shadcn Table组件，开发者可以轻松地实现对数据的动态处理，提升用户体验和数据管理效率。 <div>
【Shadcn Table：一个 shadcn 表格组件，支持服务器端排序、过滤和分页】'Shadcn Table - A shadcn table component with server-side sorting, filtering, and pagination.' GitHub: github.com/sadmann7/shadcn-table <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoyrcvt1e0j213r0l7q8e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:08:29 GMT</pubDate>
</item>
<item>
<title>【Frappe HR：开源的 HR 和薪酬管理软件项目，提供了一个完整的 HRMS 解决方案，包括员工管理、入职、请假、薪酬、税务等多个模块】'Frappe HR - Open Source HR...</title>
<link>https://weibo.com/1402400261/OaMGg7gIb</link>
<guid>https://weibo.com/1402400261/OaMGg7gIb</guid>
<content:encoded><![CDATA[
<div> 开源、HR、薪酬管理软件、项目、HRMS、员工管理、入职、请假、税务、模块
<br /><br />总结:
Frappe HR是一个开源的HR和薪酬管理软件项目，提供了完整的HRMS解决方案。该软件包括员工管理、入职、请假、薪酬、税务等多个模块，为企业提供了全面的人力资源管理和支付相关功能。通过GitHub平台，用户可以轻松访问并使用这一功能强大的解决方案，帮助企业实现高效的人力资源管理和薪酬处理。Frappe HR的开源特性使得用户可以根据自身需求进行定制和升级，实现更加个性化的管理和支付流程。对于需要全面的HRMS解决方案的企业来说，Frappe HR是一个值得考虑的选择。 <div>
【Frappe HR：开源的 HR 和薪酬管理软件项目，提供了一个完整的 HRMS 解决方案，包括员工管理、入职、请假、薪酬、税务等多个模块】'Frappe HR - Open Source HR and Payroll Software' GitHub: github.com/frappe/hrms <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoyr953dl9j21390u0q5z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:04:58 GMT</pubDate>
</item>
<item>
<title>【GPT-Subtrans：用 LLM 翻译 SRT 字幕】'GPT-Subtrans - Open Source project using LLMs to translate SRT subtitles' GitHub: github.com/machinewrapped/gpt...</title>
<link>https://weibo.com/1402400261/OaMF2hlt0</link>
<guid>https://weibo.com/1402400261/OaMF2hlt0</guid>
<content:encoded><![CDATA[
<div> github、GPT-Subtrans、LLMs、SRT、字幕、翻译、开源项目

<br /><br />总结:
介绍了一个名为GPT-Subtrans的开源项目，利用LLMs来翻译SRT字幕。该项目的GitHub链接为github.com/machinewrapped/gpt-subtrans。通过这个项目，用户可以方便地利用先进的语言模型来翻译字幕文件，提高翻译效率和准确性。 <div>
【GPT-Subtrans：用 LLM 翻译 SRT 字幕】'GPT-Subtrans - Open Source project using LLMs to translate SRT subtitles' GitHub: github.com/machinewrapped/gpt-subtrans <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoyr3ajf6ij21i00iodjb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 13:01:58 GMT</pubDate>
</item>
<item>
<title>【llama3-Chinese-chat：首个llama3 中文版) ，供学习交流演示】'llama3-Chinese-chat - Llama3 中文版' GitHub: github.com/CrazyBoyM/llama3-Chinese-chat #开...</title>
<link>https://weibo.com/1402400261/OaMCfgJ79</link>
<guid>https://weibo.com/1402400261/OaMCfgJ79</guid>
<content:encoded><![CDATA[
<div> 关键词: llama3, 中文版, 学习, 交流, 演示, GitHub, CrazyBoyM, 开发

llama3 中文版是一个供学习交流演示的项目，由 GitHub 上的用户CrazyBoyM 开发。这个项目为用户提供了一个中文版的llama3，使得更多人可以通过这个工具来学习和交流。用户可以在GitHub 上找到这个项目的源代码和文档，方便学习和参与讨论。 llamas3 中文版的发布为中文用户提供了更好的使用体验和学习资源，使得交流和学习更加便利。总结： <br /><br /> <div>
【llama3-Chinese-chat：首个llama3 中文版) ，供学习交流演示】'llama3-Chinese-chat - Llama3 中文版' GitHub: github.com/CrazyBoyM/llama3-Chinese-chat <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoyqyzyuxsj21f60u0gr4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 12:55:05 GMT</pubDate>
</item>
<item>
<title>【Anything：一个 Mac 应用，用 AI 自动化任何事，类似于 Zapier，但专注于 AI】'Anything [Alpha Pre Release] - Mac app for automating anything with AI' Gi...</title>
<link>https://weibo.com/1402400261/OaMBIAlpJ</link>
<guid>https://weibo.com/1402400261/OaMBIAlpJ</guid>
<content:encoded><![CDATA[
<div> GitHub, tryanything-ai, anything, Mac 应用, AI, 自动化, Zapier, 专注, Pre Release

<br /><br />总结:
这是一个名为Anything的Mac应用，专注于利用人工智能来自动化任何事情，类似于Zapier。该应用目前处于Alpha预发布阶段，用户可以前往GitHub上的tryanything-ai/anything仓库了解更多信息。应用使用AI技术，旨在帮助用户更智能地完成各种任务和流程。 <div>
【Anything：一个 Mac 应用，用 AI 自动化任何事，类似于 Zapier，但专注于 AI】'Anything [Alpha Pre Release] - Mac app for automating anything with AI' GitHub: github.com/tryanything-ai/anything <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoyqwm836rj21400mqtbe.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoyqwpgminj213q0mqtbb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 12:53:47 GMT</pubDate>
</item>
<item>
<title>’Dynamic Tp - 基于配置中心的轻量级动态线程池，内置监控告警功能，集成常用中间件线程池管理，可通过SPI自定义扩展实现' GitHub: github.com/dromara/dynamic...</title>
<link>https://weibo.com/1402400261/OaMAZvwYN</link>
<guid>https://weibo.com/1402400261/OaMAZvwYN</guid>
<content:encoded><![CDATA[
<div> dynamic tp, 配置中心, 轻量级, 动态线程池, 监控告警, 中间件线程池管理, SPI, 自定义扩展

总结:
Dynamic Tp是一个基于配置中心的轻量级动态线程池，具有内置监控告警功能和集成常用中间件线程池管理的特点。通过SPI可以实现自定义扩展，为线程池管理提供更多灵活性和定制化选择。Github链接为github.com/dromara/dynamic-tp。 <div>
’Dynamic Tp - 基于配置中心的轻量级动态线程池，内置监控告警功能，集成常用中间件线程池管理，可通过SPI自定义扩展实现' GitHub: github.com/dromara/dynamic-tp <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoyqvbek72j212q0u0jvw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoyqvlh7qgj214t0sd7a8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoyqvryolkj21tg0u0gqj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 12:52:00 GMT</pubDate>
</item>
<item>
<title>【SeekStorm：开源的 Rust 实现的全文搜索库和多租户搜索服务器，具有高性能和实时搜索功能】'SeekStorm - sub-millisecond full-text search library &amp; multi-t...</title>
<link>https://weibo.com/1402400261/OaMpKw1ld</link>
<guid>https://weibo.com/1402400261/OaMpKw1ld</guid>
<content:encoded><![CDATA[
<div> Rust, 全文搜索库, 多租户搜索服务器, 高性能, 实时搜索, 开源

<br /><br />总结:
SeekStorm是一个开源的 Rust 实现的全文搜索库和多租户搜索服务器，具有高性能和实时搜索功能。该库能够实现毫秒级的全文搜索，支持多租户环境下对搜索功能的管理和使用。通过在Rust语言中实现，SeekStorm具有高性能的特点，并且能够提供实时搜索的能力，可用于构建各种需要高效搜索功能的应用程序。SeekStorm的GitHub地址为github.com/SeekStorm/SeekStorm，欢迎查看和下载使用。 <div>
【SeekStorm：开源的 Rust 实现的全文搜索库和多租户搜索服务器，具有高性能和实时搜索功能】'SeekStorm - sub-millisecond full-text search library &amp; multi-tenancy server in Rust' GitHub: github.com/SeekStorm/SeekStorm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%90%9C%E7%B4%A2%23"><span class="surl-text">#搜索#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoyq2ytdrjj20vz0u0gpe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 12:24:18 GMT</pubDate>
</item>
<item>
<title>【NanoLLM：专门为 LLM 提供优化本地推理的平台，提供了 HuggingFace 风格的 API，用于量化、视觉 / 语言模型、多模态Agent、语音、矢量数据库和 RAG】'NanoLLM ...</title>
<link>https://weibo.com/1402400261/OaMpkrqNR</link>
<guid>https://weibo.com/1402400261/OaMpkrqNR</guid>
<content:encoded><![CDATA[
<div> 优化本地推理, LLM, HuggingFace, API,量化,视觉模型,语言模型,多模态Agent,语音,矢量数据库, RAG<br />
<br />总结: NanoLLM是专门为LLM提供优化本地推理的平台，具有类似HuggingFace的API，可用于量化、视觉/语言模型、多模态Agent、语音、矢量数据库和RAG。NanoLLM在GitHub上有代码库。 <div>
【NanoLLM：专门为 LLM 提供优化本地推理的平台，提供了 HuggingFace 风格的 API，用于量化、视觉 / 语言模型、多模态Agent、语音、矢量数据库和 RAG】'NanoLLM - Optimized local inference for LLMs with HuggingFace-like APIs for quantization, vision/language models, multimodal agents, speech, vector DB, and RAG.' GitHub: github.com/dusty-nv/NanoLLM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoyq1g0bcbj21700pc788.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 12:23:16 GMT</pubDate>
</item>
<item>
<title>【fastfit：提供快速准确少样本分类方法的Python库，特别适用于具有许多语义上相似类别的情况】'fastfit - a method, and a Python package design to provide f...</title>
<link>https://weibo.com/1402400261/OaMovkgeD</link>
<guid>https://weibo.com/1402400261/OaMovkgeD</guid>
<content:encoded><![CDATA[
<div> 快速准确少样本分类方法 Python库 语义相似类别<br />
<br />
要点1: 该Python库名为fastfit，旨在提供快速准确的少样本分类方法。<br />
要点2: 特别适用于具有许多语义上相似类别的情况。<br />
要点3: fastfit是一个方法和一个Python包，旨在提供快速准确的少样本分类。<br />
要点4: 适用于那些有许多语义相似类别的场景。<br />
要点5: GitHub链接为github.com/IBM/fastfit。<br />
<br />
总结: 该Python库fastfit旨在提供快速准确的少样本分类方法，特别适用于具有许多语义上相似类别的情况，适合那些需要进行高效分类的场景。GitHub链接为github.com/IBM/fastfit。 <div>
【fastfit：提供快速准确少样本分类方法的Python库，特别适用于具有许多语义上相似类别的情况】'fastfit - a method, and a Python package design to provide fast and accurate few-shot classification, especially for scenarios with many semantically similar classes' GitHub: github.com/IBM/fastfit <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoypypcpnej215z0u0q8p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 12:21:14 GMT</pubDate>
</item>
<item>
<title>编码游戏是学习编程的最佳方式——从CSS、Python、JavaScript到区块链。十个最佳在线通过游戏学编程网站推荐： #编程#1. CryptoZombiesCryptoZombies 是一所互动...</title>
<link>https://weibo.com/1402400261/OaHADFtSr</link>
<guid>https://weibo.com/1402400261/OaHADFtSr</guid>
<content:encoded><![CDATA[
<div> CryptoZombies, SQL Murder Mystery, SQL Police, Flexbox Froggy, Screeps, CodinGame, CodeCombat, Checkio, Codewars, Elevator Saga

总结:<br /><br />本文介绍了十个在线通过游戏学习编程的网站，涵盖了各种编程语言和技术，如区块链、SQL、CSS、JavaScript等。这些网站通过互动的游戏方式来教授编程知识，使学习过程更加有趣和有效。每个网站都有不同的特点和重点，适合不同程度和背景的学习者使用。通过这些网站，学习者可以通过实践和挑战提升他们的编程能力，并在竞争中学习和成长。这些网站为学习者提供了丰富的资源和机会，让他们在编程领域不断进步和提升技能。 <div>
编码游戏是学习编程的最佳方式——从CSS、Python、JavaScript到区块链。十个最佳在线通过游戏学编程网站推荐： <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%BC%96%E7%A8%8B%23&amp;isnewpage=1"><span class="surl-text">#编程#</span></a><br /><br />1. CryptoZombies<br />CryptoZombies 是一所互动学校，教您有关区块链的所有技术知识。<br />cryptozombies.io<br /><br />2. The SQL Murder Mystery<br />2. SQL 谋杀之谜<br />在破案时学习 SQL 概念和命令。<br />mystery.knightlab.com<br /><br />3. 通过警察局游戏学习 SQL<br />SQL Police 是一款在线游戏，您可以在其中使用SQL解决犯罪问题。<br />sqlpd.com<br /><br />4. Flexbox Froggy<br />一个学习CSS flexbox的游戏。<br />Flexbox 是 CSS 中的一个重要概念，因此本游戏将以非常简单的方式教您 Flexbox。<br />flexboxfroggy.com<br /><br />5. Screeps<br />这是一款面向程序员的开源游戏，其核心机制是编程。<br />你通过编写 JavaScript 来控制你的殖民地。<br />screeps.com<br /><br />6. CodinGame<br />这个基于游戏的学习网站改变了学生学习编码的方式。<br />本网站提供超过 25 种编程语言，包括 JavaScript、Ruby 和 PHP。<br />codingame.com/start<br /><br />7. CodeCombat<br />CodeCombat 以非常简单的方式设计，旨在帮助学生在玩和编写代码的同时接受学习。<br />codecombat.com<br /><br />8. Checkio<br />通过此游戏网站学习 Python 和 Typescript。<br />checkio.org<br /><br />9. Codewars<br />在Code Wars中，你可以通过与他人竞争来练习，以提高你的能力。<br />它们提供了多种语言，包括 Python、JavaScript 等。<br />codewars.com<br /><br />10. Elevator Saga<br />Elevator Saga 通过 100+ 挑战测试您的 JavaScript 知识。<br />play.elevatorsaga.com<br /><br />via: hasantoxr<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoy4s2of3wj20xc0m8wkt.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoy4rdjg78j21za1d8npd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy4rz4p1rj22281gaqv5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 21 Apr 2024 00:07:24 GMT</pubDate>
</item>
<item>
<title>【Elon Musk 称赞 Meta 的 Llama 3 AI，引起业界广泛关注】- 伊隆·马斯克最近评价Meta的开源语言模型Llama 3“不错”，这让Llama 3突然受到广泛关注。 - Llama ...</title>
<link>https://weibo.com/1402400261/OaHnanztp</link>
<guid>https://weibo.com/1402400261/OaHnanztp</guid>
<content:encoded><![CDATA[
<div> Meta、Llama 3、Elon Musk、赞扬、开源、70亿参数、性能领先、多语言支持、负责任开发、自然语言处理

总结:<br /><br />伊隆·马斯克最近称赞Meta推出的开源语言模型Llama 3，该模型是Meta推出的第三代开源大模型，参数量达到70亿，在多项基准测试中展现出领先的性能。Meta声称Llama 3在关键能力上有明显提升，是同规模参数下最优秀的开源模型，并计划继续扩展其多语言和多模态支持。Meta采用了负责任的方法开发Llama 3，并提供各种资源帮助用户进行负责任的使用。Llama 3可广泛应用于自然语言处理领域，包括语音识别、对话系统、文本生成等。 Llama 3面临的主要竞争对手是Anthropic的Claude系列模型，马斯克的正面评价有助于提升开发者对Llama 3的关注和采用。 <div>
【Elon Musk 称赞 Meta 的 Llama 3 AI，引起业界广泛关注】<br />- 伊隆·马斯克最近评价Meta的开源语言模型Llama 3“不错”，这让Llama 3突然受到广泛关注。   <br />- Llama 3是Meta继Llama和Llama 2之后推出的第三代开源大模型，参数量达到70亿，在多项业界基准测试上展现出领先的性能。   <br />- Meta声称Llama 3在推理、编码等关键能力上有明显提升，是同规模参数下最优秀的开源模型。Meta计划继续扩展Llama 3的多语言和多模态支持。   <br />- Meta采用了负责任的方法开发Llama 3，提供了各种资源帮助用户进行负责任的使用，包括Llama Guard 2、Code Shield和CyberSec Eval 2等信任与安全工具。   <br />- Llama 3可广泛应用于自然语言处理领域，包括语音识别、对话系统、文本生成等。马斯克的正面评价有助于提升开发者对Llama 3的关注和采用。   <br />- Llama 3面临的主要竞争对手是Anthropic的Claude系列模型，两者都在不断进步。Llama 3的开源特性为研究人员提供了充分理解和迭代模型的机会。<br />《Elon Musk's 'not bad' review thrusts Meta's Llama 3 AI into spotlight | VentureBeat》 <a href="https://venturebeat.com/ai/elon-musks-not-bad-review-thrusts-metas-llama-3-ai-into-spotlight/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoy3rxlli9j20y70u0gs9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 23:34:12 GMT</pubDate>
</item>
<item>
<title>【Qwen1.5 110B模型聊天Demo】《Qwen1.5 110B Chat Demo - a Hugging Face Space by Qwen》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/OaHlh55eT</link>
<guid>https://weibo.com/1402400261/OaHlh55eT</guid>
<content:encoded><![CDATA[
<div> 关键词: Qwen1.5 110B模型, 聊天Demo, Hugging Face Space

总结:<br /><br />本文介绍了Qwen1.5 110B模型聊天Demo，通过Hugging Face Space提供的功能，用户可以进行对话交流。这个模型具有智能聊天的能力，能够与用户进行自然语言交互。用户可以体验到人工智能技术在对话系统中的应用，并感受到模型的智能性和便利性。同时，Hugging Face Space提供了一个交流的空间，让用户可以更加便捷地与模型互动，提出问题、寻求帮助或者进行娱乐性的对话。整体来说，Qwen1.5 110B模型聊天Demo为用户提供了一个新颖有趣的对话体验。 <div>
【Qwen1.5 110B模型聊天Demo】《Qwen1.5 110B Chat Demo - a Hugging Face Space by Qwen》 <a href="https://huggingface.co/spaces/Qwen/Qwen1.5-110B-Chat-demo"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoy3osryuvj21990u0te1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 23:29:32 GMT</pubDate>
</item>
<item>
<title>今日推介(第1382期)：基于潜扩散的长音乐生成、通过想象、搜索与批评实现LLM的自我提升、语言失衡可促进跨语言泛化、语言模型能解决奥林匹克编程问题吗、情感分...</title>
<link>https://weibo.com/1402400261/OaH8VrIV4</link>
<guid>https://weibo.com/1402400261/OaH8VrIV4</guid>
<content:encoded><![CDATA[
<div> 潜扩散、长音乐生成、自我提升、语言失衡、跨语言泛化、语言模型、奥林匹克编程问题、情感分析、因果机制研究

<br /><br />总结:
最近的研究表明，基于潜扩散的长音乐生成具有很大的潜力。通过想象、搜索与批评，可以实现LLM的自我提升，帮助人们提高语言能力。此外，语言失衡也可能促进跨语言泛化，让人们更容易学会多种语言。关于语言模型能否解决奥林匹克编程问题的讨论仍在进行中。最后，情感分析的因果机制研究为我们提供了更深入的理解。通过这些研究，我们可以更好地利用语言模型和情感分析技术，提升生活质量。 <div>
今日推介(第1382期)：基于潜扩散的长音乐生成、通过想象、搜索与批评实现LLM的自我提升、语言失衡可促进跨语言泛化、语言模型能解决奥林匹克编程问题吗、情感分析的因果机制研究 公·众·号：爱可可爱生活 <a href="http://aicoco.net/s/8j"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoy2sv3a75j20qk0mqmzs.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoy2sy684oj21400i1go4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoy2t0r2hwj21200i4acw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoy2t3gejjj21400lz43a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoy2t62wf0j21400naq9v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 22:59:07 GMT</pubDate>
</item>
<item>
<title>[CL] The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey 网页链接 调研了AI Agent在复杂任务推理、规划...</title>
<link>https://weibo.com/1402400261/OaH0f4HGE</link>
<guid>https://weibo.com/1402400261/OaH0f4HGE</guid>
<content:encoded><![CDATA[
<div> Agent, AI, 推理, 规划, 工具调用, 架构, 调研, 进展, 系统, 关键考量

<br /><br />总结:
本文调研了AI Agent在复杂任务推理、规划和工具调用方面的最新进展，重点关注了Agent系统的架构设计和关键考量。研究指出，有效的Agent系统需要具备强大的推理和规划能力，并能够有效地调用各种工具来完成任务。在构建Agent系统时，需要考虑任务复杂性、系统性能、通信协议等方面的因素。研究结果为构建高效的Agent系统提供了重要的参考。 <div>
[CL] The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey  <br /><a href="https://arxiv.org/abs/2404.11584"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />调研了AI Agent在复杂任务推理、规划和工具调用方面的最新进展，提出了构建高效Agent系统的关键考量。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoy26w6561j20um14kwqa.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoy26wdw77j21h00wiagb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy26x1qn6j219y1dcqhq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 22:37:43 GMT</pubDate>
</item>
<item>
<title>[AS] A Large-Scale Evaluation of Speech Foundation Models 网页链接 SUPERB通过面向多任务的标准化评估，系统验证了语音基础模型的有效性，并通过开放平台推...</title>
<link>https://weibo.com/1402400261/OaGXIgSXZ</link>
<guid>https://weibo.com/1402400261/OaGXIgSXZ</guid>
<content:encoded><![CDATA[
<div> 标准化评估 多任务 语音基础模型 有效性 开放平台 统一发展

总结:<br /><br />本研究通过面向多任务的标准化评估，验证了语音基础模型的有效性。同时，通过开放平台推动了该领域的统一发展。该研究为语音领域的研究和发展提供了重要的参考和借鉴。 <div>
[AS] A Large-Scale Evaluation of Speech Foundation Models  <br /><a href="https://arxiv.org/abs/2404.09385"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />SUPERB通过面向多任务的标准化评估，系统验证了语音基础模型的有效性，并通过开放平台推动了该领域的统一发展。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy20ctl48j20xe188nfo.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoy20djvevj213o1bcdxa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy20e50csj20r414ijwx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 22:31:30 GMT</pubDate>
</item>
<item>
<title>[CL] ALERT: A Comprehensive Benchmark for Assessing Large Language Models' Safety through Red Teaming 网页链接 提出一个大规模红队测试基准ALERT来评估语...</title>
<link>https://weibo.com/1402400261/OaGUF2lgz</link>
<guid>https://weibo.com/1402400261/OaGUF2lgz</guid>
<content:encoded><![CDATA[
<div> 基准测试, 语言模型, 安全性, 红队, 漏洞, 主流模型, 评估, 部署, 语境

总结:<br /><br />这篇文章提出了一个名为ALERT的大规模红队测试基准，旨在评估语言模型的安全性。研究发现，主流模型在特定类别仍存在漏洞，因此呼吁在部署时需要根据语境进行安全性评估。该基准测试有助于发现模型的潜在安全风险，为提高语言模型的安全性提供了重要的参考依据。 <div>
[CL] ALERT: A Comprehensive Benchmark for Assessing Large Language Models' Safety through Red Teaming  <br /><a href="https://arxiv.org/abs/2404.08676"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出一个大规模红队测试基准ALERT来评估语言模型的安全性，发现主流模型在特定类别仍存在漏洞，呼吁在部署时需要根据语境进行安全性评估。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoy1skxneij20qw16mqgi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy1sl6vuxj21ce0rc10u.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoy1slsqwmj21c60sajx9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 22:23:58 GMT</pubDate>
</item>
<item>
<title>[CL] Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models 网页链接 Reka研发的Core、Flash和Edge是一系列多模态语言模型，在语言和...</title>
<link>https://weibo.com/1402400261/OaGQw4hUJ</link>
<guid>https://weibo.com/1402400261/OaGQw4hUJ</guid>
<content:encoded><![CDATA[
<div> 关键词: Reka, Core, Flash, Edge, 多模态语言模型, 强大性能, GPT-4

Reka研发的Core、Flash和Edge是一系列多模态语言模型，展现出超越同类模型的强大性能，尤其是Core模型接近GPT-4水平。这些模型在语言和视觉任务上表现出色，为未来的技术发展提供了巨大的潜力。通过结合语言和视觉信息，这些模型可以更准确地理解和处理复杂的任务。Reka公司的Core、Flash和Edge模型将成为未来计算机科学领域的重要突破，为人工智能领域带来新的发展机遇。总结:Reka公司开发了一系列多模态语言模型，其中Core模型在性能上接近GPT-4，展现了强大的潜力，将对计算机科学和人工智能领域带来重大影响。 <div>
[CL] Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models  <br /><a href="https://arxiv.org/abs/2404.12387"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />Reka研发的Core、Flash和Edge是一系列多模态语言模型，在语言和视觉任务上展现出超越同等计算类别模型的强大性能，特别是最大的Core模型已接近GPT-4等领先模型的水平。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy1hy2du8j210e1ckdqb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy1hylxjzj218211m0vc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoy1hz8xboj21ia0l6n1c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 22:13:46 GMT</pubDate>
</item>
<item>
<title>通过归纳文本与情感的因果机制，指导构建对齐的因果提示以改进语言模型在情感分析任务上的表现。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《On the Causal Nature of S...</title>
<link>https://weibo.com/1402400261/OaGNisVlw</link>
<guid>https://weibo.com/1402400261/OaGNisVlw</guid>
<content:encoded><![CDATA[
<div> 因果机制, 情感分析, 对齐, 语言模型, 提示, 表现, 文本, 情感, 归纳, 改进

总结:<br /><br />本文提出了通过归纳文本与情感的因果机制来指导构建对齐的因果提示，以改进语言模型在情感分析任务上的表现。文章重点探讨了情感分析的因果性质，提出了一种新的方法来实现对文本和情感之间因果关系的建模。通过对文本和情感之间的因果机制进行分析，可以指导语言模型在情感分析任务上取得更好的效果。作者通过实验验证了提出的方法的有效性，并指出这种方法可以有助于改进情感分析中因果关系的理解和建模。<br /> <div>
通过归纳文本与情感的因果机制，指导构建对齐的因果提示以改进语言模型在情感分析任务上的表现。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《On the Causal Nature of Sentiment Analysis》Z Lyu, Z Jin, F Gonzalez, R Mihalcea, B Schoelkopf, M Sachan [University of Hong Kong &amp; ETH Zürich] (2024) <a href="https://arxiv.org/abs/2404.11055"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoy141354yj20o812swnu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoy141l615j21kq0x07ig.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoy141mu60j20s40jgmz7.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 22:05:50 GMT</pubDate>
</item>
<item>
<title>[CL]《On the Causal Nature of Sentiment Analysis》Z Lyu, Z Jin, F Gonzalez, R Mihalcea, B Schoelkopf, M Sachan [University of Hong Kong &amp; ETH Zürich]...</title>
<link>https://weibo.com/1402400261/OaGNh2Gs5</link>
<guid>https://weibo.com/1402400261/OaGNh2Gs5</guid>
<content:encoded><![CDATA[
<div> 关键词: 情感分析, 因果关系, 自然语言处理, 数据集, 模型训练

总结:<br /><br />总结: 本文讨论了情感分析的因果性质。研究者借助自然语言处理技术和机器学习方法，探讨了在情感分析中因果关系的重要性。通过使用不同数据集进行模型训练，研究者发现了因果关系对情感分析的影响，并提出了一些新的观点和方法来改善模型的准确性和效率。这些研究结果对情感分析领域的发展具有重要意义。 <div>
[CL]《On the Causal Nature of Sentiment Analysis》Z Lyu, Z Jin, F Gonzalez, R Mihalcea, B Schoelkopf, M Sachan [University of Hong Kong &amp; ETH Zürich] (2024) <a href="https://arxiv.org/abs/2404.11055"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoy141354yj20o812swnu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoy141l615j21kq0x07ig.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoy141mu60j20s40jgmz7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 22:05:46 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and Benchmark》(CVPR 2024) GitHub: github.com/facebookresearch/real-a...</title>
<link>https://weibo.com/1402400261/OaC2fz3IW</link>
<guid>https://weibo.com/1402400261/OaC2fz3IW</guid>
<content:encoded><![CDATA[
<div> 关键词：音频-视觉数据集，房间声学，单视角对象重建，多视角遮挡监督，文本图像转换，身份保留，频率感知扩散合声器，车辆轨迹预测，事实核查，语音带宽扩展

总结:<br /><br />《Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and Benchmark》提出了一个音频-视觉数据集，用于房间声学研究，并提供了评估基准。<br />《MOHO: Learning Single-view Hand-held Object Reconstruction with Multi-view Occlusion-Aware Supervision》介绍了一种学习单视角手持对象重建的方法，具备多视角遮挡监督。<br />《Customizing Text-to-Image Diffusion with Camera Viewpoint Control》探讨了通过自定义相机视角控制来改善文本到图像转换的方法。<br />《FlashFace: Human Image Personalization with High-fidelity Identity Preservation》展示了一种人像个性化处理方法，保持高保真度身份信息。<br />《FreGrad: Lightweight and fast frequency-aware diffusion vocoder》介绍了一种轻量级且快速的频率感知扩散合声器。<br />《Decomposing and Editing Predictions by Modeling Model Computation》通过建模模型计算来分解和编辑预测结果。<br />《Self-playing Adversarial Language Game Enhances LLM Reasoning》探讨了自我对抗语言游戏如何增强大型语言模型的推理能力。<br />《BLINK: Multimodal Large Language Models Can See but Not Perceive》展示了多模态大型语言模型的能力，并指出其无法感知信息。<br />《A Unified Framework for Scalable Vehicle Trajectory Prediction》提出了一个可扩展的车辆轨迹预测统一框架。<br />《MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents》介绍了一种在基础文件上高效检查大型语言模型事实的方法。<br />《Towards High-Quality and Efficient Speech Bandwidth Extension with Parallel Amplitude and Phase Prediction》展示了一种高质量、高效率的语音带宽扩展方法。<br />《AbsGS: Recovering Fine Details for 3D Gaussian Splatting》提出了一种用于3D高斯喷涂的细节恢复方法。<br />《Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs》描述了如何通过在图上推理来增强大型语言模型。<br />《TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding》介绍了一种通过分层推测解码实现长序列生成的无损加速方法。 <div>
几篇论文实现代码：<br />《Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and Benchmark》(CVPR 2024) GitHub: github.com/facebookresearch/real-acoustic-fields<br />《MOHO: Learning Single-view Hand-held Object Reconstruction with Multi-view Occlusion-Aware Supervision》(CVPR 2024) GitHub: github.com/ZhangCYG/MOHO<br />《Customizing Text-to-Image Diffusion with Camera Viewpoint Control》(2024) GitHub: github.com/customdiffusion360/custom-diffusion360 [fig1]<br />《FlashFace: Human Image Personalization with High-fidelity Identity Preservation》(2024) GitHub: github.com/ali-vilab/FlashFace<br />《Position Paper: Learning with 3D rotations, a hitchhiker’s guide to SO(3)》(2024) GitHub: github.com/martius-lab/hitchhiking-rotations<br />《FreGrad: Lightweight and fast frequency-aware diffusion vocoder》(2024) GitHub: github.com/signofthefour/fregrad<br />《Decomposing and Editing Predictions by Modeling Model Computation》(2024) GitHub: github.com/MadryLab/modelcomponents [fig2]<br />《Self-playing Adversarial Language Game Enhances LLM Reasoning》(2024) GitHub: github.com/Linear95/SPAG<br />《BLINK: Multimodal Large Language Models Can See but Not Perceive》(2024) GitHub: github.com/zeyofu/BLINK_Benchmark [fig3]<br />《A Unified Framework for Scalable Vehicle Trajectory Prediction》(2024) GitHub: github.com/vita-epfl/UniTraj [fig4]<br />《MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents》(2024) GitHub: github.com/Liyan06/MiniCheck<br />《Towards High-Quality and Efficient Speech Bandwidth Extension with Parallel Amplitude and Phase Prediction》(2024) GitHub: github.com/yxlu-0102/AP-BWE<br />《AbsGS: Recovering Fine Details for 3D Gaussian Splatting》(2024) GitHub: github.com/ingra14m/floater-free-gaussian-splatting<br />《Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs》(2024) GitHub: github.com/PeterGriffinJin/Graph-CoT [fig5] <br />《TriForce: Lossless Acceleration of Long Sequence<br />Generation with Hierarchical Speculative Decoding》(2024) GitHub: github.com/Infini-AI-Lab/TriForce<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoxckkex4lj23131diaqu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoxeejw5idj21wu1867h7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoxefof2d3j21w115gx6p.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoxet0bufnj21pz0obtq5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoxf0cpj4hj21ue0yuap9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:58:57 GMT</pubDate>
</item>
<item>
<title>【BeyondLLM：用于实验、评估和部署基于检索增强生成 (RAG) 的系统的工具包，支持各种大语言模型 (LLM)，旨在减少 LLM 幻觉风险并提高可靠性】'BeyondLLM - Buil...</title>
<link>https://weibo.com/1402400261/OaC28Bhro</link>
<guid>https://weibo.com/1402400261/OaC28Bhro</guid>
<content:encoded><![CDATA[
<div> GitHub, 工具包, 检索增强生成, 语言模型, 减少风险, 提高可靠性, 实验, 评估, 部署  

总结:<br /><br />文章介绍了名为BeyondLLM的工具包，旨在帮助用户构建、评估和部署基于检索增强生成（RAG）的系统，支持各种大语言模型（LLM）。该工具包的目标是减少LLM产生的幻觉风险并提高系统的可靠性。用户可以利用该工具包进行实验、评估和观察LLM应用的表现，并确保系统在不同环境下的稳定性和可靠性。GitHub链接为github.com/aiplanethub/beyondllm。 <div>
【BeyondLLM：用于实验、评估和部署基于检索增强生成 (RAG) 的系统的工具包，支持各种大语言模型 (LLM)，旨在减少 LLM 幻觉风险并提高可靠性】'BeyondLLM - Build, evaluate and observe LLM apps' GitHub: github.com/aiplanethub/beyondllm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoxg94f63qj20u00ybaec.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:58:40 GMT</pubDate>
</item>
<item>
<title>【SAE Lens：在语言模型上训练稀疏自编码器】'SAE Lens - Training Sparse Autoencoders on Language Models' GitHub: github.com/jbloomAus/SAELens #开源# #机...</title>
<link>https://weibo.com/1402400261/OaBYXglHQ</link>
<guid>https://weibo.com/1402400261/OaBYXglHQ</guid>
<content:encoded><![CDATA[
<div> 稀疏自编码器、语言模型、训练、GitHub、SAELens

<br /><br />总结:
本文介绍了在语言模型上训练稀疏自编码器的方法，作者提供了在GitHub上的开源代码SAELens。稀疏自编码器是一种无监督学习的模型，通过学习数据的稀疏表示来降低维度。在语言模型上训练稀疏自编码器可以帮助提取文本数据中的特征，并用于各种自然语言处理任务。通过使用SAELens，研究人员可以方便地训练和测试稀疏自编码器，这对于语言模型和深度学习领域的研究具有重要意义。 <div>
【SAE Lens：在语言模型上训练稀疏自编码器】'SAE Lens - Training Sparse Autoencoders on Language Models' GitHub: github.com/jbloomAus/SAELens <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoxg0m3a8mj20u010644w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:50:49 GMT</pubDate>
</item>
<item>
<title>【A Web Component for Math Input：为网页提供易于使用的数学公式输入界面的强大 Web 组件】'A Web Component for Math Input - A web component for easy math...</title>
<link>https://weibo.com/1402400261/OaBYufwEK</link>
<guid>https://weibo.com/1402400261/OaBYufwEK</guid>
<content:encoded><![CDATA[
<div> Web Component, Math Input, 网页, 数学公式, 输入界面, GitHub, 强大, 组件, 简单, 使用

<br /><br />总结:
本文介绍了一个名为"A Web Component for Math Input"的Web组件，旨在为网页提供方便易用的数学公式输入界面。该组件可以在GitHub上找到，提供了强大的功能，让用户可以轻松输入数学公式。通过这个组件，用户可以快速在网页中添加数学公式，提高了数学输入的效率和便利性。 <div>
【A Web Component for Math Input：为网页提供易于使用的数学公式输入界面的强大 Web 组件】'A Web Component for Math Input - A web component for easy math input' GitHub: github.com/arnog/mathlive <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoxfzqu3vvj20x20u0jv2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:49:40 GMT</pubDate>
</item>
<item>
<title>【CIANNA：专门为天体物理学家设计的深度学习框架，用于天体数据分析，并提供了高级 Python 接口】'CIANNA - Convolutional Interactive Artificial Neural Netw...</title>
<link>https://weibo.com/1402400261/OaBY1AIPW</link>
<guid>https://weibo.com/1402400261/OaBY1AIPW</guid>
<content:encoded><![CDATA[
<div> 天体物理学家、深度学习框架、CIANNA、天体数据分析、高级 Python 接口、GitHub、Convolutional Interactive Artificial Neural Networks、Astrophysicists、GitHub仓库

<br /><br />总结:
CIANNA是专门为天体物理学家设计的深度学习框架，用于天体数据分析。它提供了高级 Python 接口，方便用户使用。CIANNA的全称为Convolutional Interactive Artificial Neural Networks，为天体物理学家提供了一个便捷的工具进行数据处理和分析。用户可以在GitHub上找到CIANNA的开源代码仓库，方便下载和使用。 <div>
【CIANNA：专门为天体物理学家设计的深度学习框架，用于天体数据分析，并提供了高级 Python 接口】'CIANNA - Convolutional Interactive Artificial Neural Networks by/for Astrophysicists' GitHub: github.com/Deyht/CIANNA <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoxfylkspsj20u00x0grb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:48:32 GMT</pubDate>
</item>
<item>
<title>【python-barcode：创建标准条形码的简单 Python 库】'python-barcode - Create standard barcodes with Python. No external dependencies. 100% Organic Pytho...</title>
<link>https://weibo.com/1402400261/OaBXCyavy</link>
<guid>https://weibo.com/1402400261/OaBXCyavy</guid>
<content:encoded><![CDATA[
<div> GitHub, python-barcode, 标准条形码, Python, 无外部依赖, 100% 纯 Python

python-barcode 是一个简单的 Python 库，用于创建标准的条形码，不需要外部依赖，完全由 Python 编写。可以通过 GitHub 获取项目源代码。此库是为了方便用户在 Python 中生成标准的条形码。与其他库不同的是，python-barcode 是一个纯 Python 库，不依赖于任何其他第三方库。用户可以直接使用这个库来生成不同类型的条形码，比如 EAN13、UPCA、CODE128 等等。这个库的设计是非常简洁和易于使用的，用户只需导入库并调用相应的方法即可生成所需的条形码。总的来说，python-barcode 是一个方便、易用且没有额外依赖的 Python 条形码生成库。<br /><br />总结: 该库是一个简单的 Python 库，用于创建标准的条形码，不需要外部依赖，完全由 Python 编写。用户可以直接使用这个库来生成不同类型的条形码，设计简洁易用。 <div>
【python-barcode：创建标准条形码的简单 Python 库】'python-barcode - Create standard barcodes with Python. No external dependencies. 100% Organic Python.' GitHub: github.com/WhyNotHugo/python-barcode <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoxfx05yfnj21h80lkacy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:47:32 GMT</pubDate>
</item>
<item>
<title>【Live2D Virtual Human for Chatting based on Unity：寄语Unity的开源聊天虚拟人项目】'Live2D Virtual Human for Chatting based on Unity - Live2D Virtual ...</title>
<link>https://weibo.com/1402400261/OaBMw0bqn</link>
<guid>https://weibo.com/1402400261/OaBMw0bqn</guid>
<content:encoded><![CDATA[
<div> Live2D、Unity、开源项目、虚拟人、聊天、GitHub、Navi Studio、项目、技术、实现

总结:<br /><br />这是一个基于Unity的开源项目，旨在创建一个能够进行实时对话的Live2D虚拟人。项目已经在GitHub上发布，由Navi Studio开发。通过使用技术实现，用户可以与虚拟人进行交流和互动，为Unity开发者提供了一个有趣的项目。 <div>
【Live2D Virtual Human for Chatting based on Unity：寄语Unity的开源聊天虚拟人项目】'Live2D Virtual Human for Chatting based on Unity - Live2D Virtual Human for Chatting based on Unity' GitHub: github.com/Navi-Studio/Virtual-Human-for-Chatting?tab=readme-ov-file <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoxf3jdpeqj215s0nm0wt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:20:10 GMT</pubDate>
</item>
<item>
<title>【json-repair：提供了一个名为 json-repair 的工具，用于修复从语言模型(LLM)产生的 JSON 格式异常】'Repair JSON！Solution for JSON Anomalies from LLMs.' G...</title>
<link>https://weibo.com/1402400261/OaBLxcg7u</link>
<guid>https://weibo.com/1402400261/OaBLxcg7u</guid>
<content:encoded><![CDATA[
<div> 修复工具、JSON异常、语言模型、LLM、GitHub、解决方案、RealAlexandreAI、修复JSON格式异常
<br />
提供了一个名为 json-repair 的工具，用于修复从语言模型(LLM)产生的 JSON 格式异常。你可以在 GitHub 上找到这个工具，地址是 github.com/RealAlexandreAI/json-repair。该工具能够解决从LLMs产生的JSON异常，是一个修复JSON格式异常的解决方案。 <div>
【json-repair：提供了一个名为 json-repair 的工具，用于修复从语言模型(LLM)产生的 JSON 格式异常】'Repair JSON！Solution for JSON Anomalies from LLMs.' GitHub: github.com/RealAlexandreAI/json-repair <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoxf2dlge9j20u010eafa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 09:17:45 GMT</pubDate>
</item>
<item>
<title>【The largest Awesome List of CLI/TUI programs：最大的精选 CLI/TUI 应用清单，并以 CSV 文件的形式组织了源数据】'The largest Awesome List of CLI/TUI pro...</title>
<link>https://weibo.com/1402400261/OaBDrrpN6</link>
<guid>https://weibo.com/1402400261/OaBDrrpN6</guid>
<content:encoded><![CDATA[
<div> GitHub, CLI/TUI 应用清单, CSV 文件, 源数据, 组织, 最大的<br />
<br />总结:
本文介绍了 GitHub 上最大的 CLI/TUI 应用清单，其中包括了以 CSV 文件形式组织的源数据。这个清单中涵盖了大量的 CLI/TUI 应用程序，为用户提供了便利的选择。CLI/TUI 应用程序在命令行或文本用户界面上执行操作，可帮助用户提高工作效率。通过这个清单，用户能够更方便地找到并使用各种 CLI/TUI 应用程序，让他们的工作更加高效和便捷。GitHub 上的这个 Awesome List 为用户提供了一个全面而精选的资源，帮助他们更好地利用 CLI/TUI 技术。 <div>
【The largest Awesome List of CLI/TUI programs：最大的精选 CLI/TUI 应用清单，并以 CSV 文件的形式组织了源数据】'The largest Awesome List of CLI/TUI programs - The largest Awesome Curated list of CLI/TUI applications with source data organized into CSV files' GitHub: github.com/toolleeo/cli-apps <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23CLI%23"><span class="surl-text">#CLI#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoxeht1hsej20u01307bh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 08:57:49 GMT</pubDate>
</item>
<item>
<title>【Form Extractor Prototype：使用 Claude 3 LLM 模型的工具，可以从表单图像中提取结构，并将其转换为符合 GOV.UK 表单模式的 JSON 结构，然后生成多页面的 Web...</title>
<link>https://weibo.com/1402400261/OaBBCyFlS</link>
<guid>https://weibo.com/1402400261/OaBBCyFlS</guid>
<content:encoded><![CDATA[
<div> GitHub, Form Extractor Prototype, Claude 3 LLM 模型, 表单图像, 结构提取, GOV.UK 表单模式, JSON 结构, 多页面 Web 表单

<br /><br />总结:
这篇文章介绍了一个名为'Form Extractor Prototype'的工具，使用了Claude 3 LLM模型，可以从表单图像中提取结构，并转换为符合GOV.UK表单模式的JSON结构。然后，该工具可以生成多页面的Web表单。这个工具的开源代码可以在GitHub上找到。 <div>
【Form Extractor Prototype：使用 Claude 3 LLM 模型的工具，可以从表单图像中提取结构，并将其转换为符合 GOV.UK 表单模式的 JSON 结构，然后生成多页面的 Web 表单】'Form Extractor Prototype' GitHub: github.com/timpaul/form-extractor-prototype <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoxed5196tj216a0o077r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 08:53:20 GMT</pubDate>
</item>
<item>
<title>【NeRF-Based-SLAM-Incredible-Insights：旨在提供对各种基于 NeRF(神经辐射场)的 Slam(同时定位和建图)算法的全面见解】'NeRF-Based-SLAM-Incredible-Insights'...</title>
<link>https://weibo.com/1402400261/OaAdMq4FU</link>
<guid>https://weibo.com/1402400261/OaAdMq4FU</guid>
<content:encoded><![CDATA[
<div> NeRF, Slam, 神经辐射场, 定位, 建图, 算法, 全面见解, GitHub, Incredible Insights

<br /><br />总结:
本文旨在提供对各种基于 NeRF(神经辐射场)的 Slam(同时定位和建图)算法的全面见解。NeRF 是一种用于重建三维场景的方法，结合 Slam 可以实现准确的定位和建图。通过 GitHub 项目 'NeRF-Based-SLAM-Incredible-Insights'，我们可以深入了解这些算法的原理、应用和不同方面的技术细节。通过研究这些内容，我们可以获得关于 NeRF-Based Slam 算法的令人难以置信的洞察力。 <div>
【NeRF-Based-SLAM-Incredible-Insights：旨在提供对各种基于 NeRF(神经辐射场)的 Slam(同时定位和建图)算法的全面见解】'NeRF-Based-SLAM-Incredible-Insights' GitHub: github.com/electech6/NeRF-Based-SLAM-Incredible-Insights?tab=readme-ov-file <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hox88etlaej21740se0xv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 05:21:51 GMT</pubDate>
</item>
<item>
<title>LLM匿名竞技场的最新结果显示，在English赛道 Llama-3-70b-Instruct 已经超过 Claude 3 Opus，仅次于 GPT-4 #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/Oaz9ih5C7</link>
<guid>https://weibo.com/1402400261/Oaz9ih5C7</guid>
<content:encoded><![CDATA[
<div> LLM, 匿名竞技场, English赛道, Llama-3-70b-Instruct, Claude 3 Opus, GPT-4

总结:<br /><br />LLM匿名竞技场的最新结果显示，在English赛道，Llama-3-70b-Instruct已经超越了Claude 3 Opus，仅次于GPT-4。这表明Llama-3-70b-Instruct在竞技场中取得了相对较高的成绩，在与GPT-4的比较中显示出潜力和竞争力。整体上，LLM匿名竞技场的结果显示了Llama-3-70b-Instruct在语言模型竞技中的优异表现，尤其在英语赛道上的表现让人印象深刻。 <div>
LLM匿名竞技场的最新结果显示，在English赛道 Llama-3-70b-Instruct 已经超过 Claude 3 Opus，仅次于 GPT-4 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hox3h8l6exj213s0u0q6s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 02:38:03 GMT</pubDate>
</item>
<item>
<title>【Penzai：基于 JAX 的神经网络研究工具包，用于构建、编辑和可视化神经网络，可轻松查看模型内部结构，允许在任意地方注入自定义逻辑】'Penzai - A JAX researc...</title>
<link>https://weibo.com/1402400261/Oaz0M09Ku</link>
<guid>https://weibo.com/1402400261/Oaz0M09Ku</guid>
<content:encoded><![CDATA[
<div> JAX, 神经网络, Penzai, 工具包, 构建, 编辑, 可视化, 内部结构, 自定义逻辑

总结:<br /><br />
Penzai是基于JAX的神经网络研究工具包，能够用于构建、编辑和可视化神经网络。该工具包可以轻松查看模型的内部结构，同时允许在任意地方注入自定义逻辑。帮助研究人员更加方便地探索神经网络模型，提高研究效率。GitHub上有Penazi的开源代码，有兴趣的人可以去查看。 <div>
【Penzai：基于 JAX 的神经网络研究工具包，用于构建、编辑和可视化神经网络，可轻松查看模型内部结构，允许在任意地方注入自定义逻辑】'Penzai - A JAX research toolkit for building, editing, and visualizing neural networks.' GitHub: github.com/google-deepmind/penzai <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5025178598703171"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a><br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/5396ee05ly1hox2wosemcj20oy0k0wh3.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/sQZgTkjMlx08edZz9w5G0104120055cZ0E010.mp4?label=mp4_720p&amp;template=898x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713584543&amp;ssig=YDnz52zEjL&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/zAC4BK15lx08edZyUd9m010412002vLD0E010.mp4?label=mp4_hd&amp;template=596x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713584543&amp;ssig=Hbdwn75tZD&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/BY7hT4E0lx08edZyOAFi010412001vFF0E010.mp4?label=mp4_ld&amp;template=448x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713584543&amp;ssig=BzajPp1l3d&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5025178598703171" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 02:17:03 GMT</pubDate>
</item>
<item>
<title>【LLM API价格比较表】《Compare LLM API Pricing Instantly - Quickly Find the Perfect Large Language Models (LLM) API for Your Budget! Use Our Free Tool...</title>
<link>https://weibo.com/1402400261/OayOl2GT7</link>
<guid>https://weibo.com/1402400261/OayOl2GT7</guid>
<content:encoded><![CDATA[
<div> 关键词：LLM API，价格比较，快速找到适合预算的API提供商

总结:<br /><br />本文介绍了比较LLM API价格的工具，可以帮助用户快速找到适合预算的API提供商。用户可以通过免费工具即时查看顶级提供商的最新价格。这有助于用户更好地选择合适的大型语言模型API，并控制成本。 <div>
【LLM API价格比较表】《Compare LLM API Pricing Instantly - Quickly Find the Perfect Large Language Models (LLM) API for Your Budget! Use Our Free Tool for Instant Access to the Latest Prices from Top Providers》 <a href="https://llmpricecheck.com/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hox207p18pj217i0u041x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 20 Apr 2024 01:46:25 GMT</pubDate>
</item>
<item>
<title>【用 ORPO 将 Llama 3 的性能提升到新高度】- ORPO(Odds Ratio Preference Optimization)是一种新的微调技术，可以将传统的监督微调和偏好对齐阶段合并为一个过...</title>
<link>https://weibo.com/1402400261/OaxUVi5hh</link>
<guid>https://weibo.com/1402400261/OaxUVi5hh</guid>
<content:encoded><![CDATA[
<div> ORPO, Llama 3, 性能提升, 新高度, 监督微调, 偏好对齐, 计算资源, 训练时间, 语言建模, 比值项

<br /><br />总结:
ORPO是一种新的微调技术，可以将监督微调和偏好对齐合并为一个过程，通过修改语言建模目标，强化被选择的响应，从而将Llama 3的性能提升到新高度。文章使用ORPOTrainer在Llama 3 8B模型上进行微调，尽管样本量有限，但在Nous基准测试中表现良好。ORPO展现了作为新微调范式的潜力，重要的是在更大规模的偏好数据集上进行充分训练。当前开源社区活跃，开源模型与专有模型差距缩小，微调是关键。 <div>
【用 ORPO 将 Llama 3 的性能提升到新高度】<br />- ORPO(Odds Ratio Preference Optimization)是一种新的微调技术，可以将传统的监督微调和偏好对齐阶段合并为一个过程，从而减少计算资源和训练时间。   <br />- ORPO通过修改语言建模目标，将负对数似然损失与比值(OR)项相结合，以弱化被拒绝的响应并强化被选择的响应，让模型同时学习目标任务和人类偏好。   <br />- 文章使用TRL库中的ORPOTrainer在Llama 3 8B模型上进行ORPO微调，数据集包含DPO偏好对，共1000个样本。   <br />- 尽管由于样本量少仅训练了1个epoch，但微调后的模型在Nous的基准测试中表现良好，所有指标上均优于Llama 3原模型。   <br />- ORPO展现了作为新的微调范式的潜力，未来在更大规模的偏好数据集上进行充分训练将产生更好的效果。选择高质量的数据集也非常重要。   <br />- 当前是开源社区的活跃时期，正在发布越来越多高质量的开源模型，开源模型与专有模型的差距正在缩小，微调是获得最佳性能的关键。<br />《Fine-tune Llama 3 with ORPO》 <a href="https://huggingface.co/blog/mlabonne/orpo-llama-3"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8howy0qq6enj20u00xyq83.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 23:29:53 GMT</pubDate>
</item>
<item>
<title>今日推介(第1381期)：语言模型实际上是个Q函数、3D旋转学习指南、单目视频的一致网格重建、视觉基础模型语义分割基准测试方案探索、用微调和迭代推理增强特定领...</title>
<link>https://weibo.com/1402400261/OaxvlyGXB</link>
<guid>https://weibo.com/1402400261/OaxvlyGXB</guid>
<content:encoded><![CDATA[
<div> 语言模型、Q函数、3D旋转、学习、单目视频、一致网格重建、视觉基础模型、语义分割、基准测试方案、微调、迭代推理、领域问答<br />
<br />
语言模型实际上是一个Q函数，通过3D旋转学习指南，实现单目视频的一致网格重建。同时，探索视觉基础模型语义分割的基准测试方案，研究用微调和迭代推理增强特定领域问答的方法。这些内容在公众号"爱可可爱生活"中得以详细阐述，为读者提供了丰富的学习资源和研究思路。 <div>
今日推介(第1381期)：语言模型实际上是个Q函数、3D旋转学习指南、单目视频的一致网格重建、视觉基础模型语义分割基准测试方案探索、用微调和迭代推理增强特定领域问答的比较研究 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/693516407"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8howw8ziy3uj21400d9tcz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8howw924g2wj20t60madiy.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8howw95n2pej21230u0gth.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8howw98e2iuj20ts0vsgpf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8howw9axgf2j20uw0u00v8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 22:26:53 GMT</pubDate>
</item>
<item>
<title>[LG] Deconstructing Human-AI Collaboration: Agency, Interaction, and Adaptation 网页链接 通过代理、交互和适应三个关键方面提出人机协作设计空间模型，为...</title>
<link>https://weibo.com/1402400261/Oaxrssys1</link>
<guid>https://weibo.com/1402400261/Oaxrssys1</guid>
<content:encoded><![CDATA[
<div> 代理、交互、适应、人机协作、设计空间模型、理解、评估、协作系统、有效工具

<br /><br />总结:
本文提出了人机协作设计空间模型，通过代理、交互和适应三个关键方面来理解、设计和评估人机协作系统。该模型为研究人机协作提供了有效工具，帮助人们更好地理解和优化人工智能与人类之间的合作关系。通过对代理、交互和适应三个方面的深入分析，可以有效提高人机协作系统的效能和用户体验。 <div>
[LG] Deconstructing Human-AI Collaboration: Agency, Interaction, and Adaptation  <br /><a href="https://arxiv.org/abs/2404.12056"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过代理、交互和适应三个关键方面提出人机协作设计空间模型，为理解、设计和评估此类协作系统提供了有效工具。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howvzcr871j20x216y15l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howvzczerhj21l80p6wn2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howvzdee75j21ko0my7ej.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 22:17:19 GMT</pubDate>
</item>
<item>
<title>[CL] Exploring the landscape of large language models: Foundations, techniques, and challenges 网页链接 本文全面概述了大型语言模型的发展现状、关键技术...</title>
<link>https://weibo.com/1402400261/OaxoHm6eo</link>
<guid>https://weibo.com/1402400261/OaxoHm6eo</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、发展现状、关键技术、应用前景、理论分析、实际问题、研究人员、从业者、指南

总结:<br /><br />本文全面概述了大型语言模型的发展现状，重点介绍了关键技术和应用前景。通过理论分析和关注实际问题，为研究人员和从业者提供了很好的指南。文章涵盖了大型语言模型的基础知识，探讨了其在各个领域的应用及挑战。同时，也提出了未来研究方向，为读者开拓了思路。整体而言，这篇文章对大型语言模型的全貌有了全面的展示，对于深入了解和应用该技术具有重要意义。 <div>
[CL] Exploring the landscape of large language models: Foundations, techniques, and challenges  <br /><a href="https://arxiv.org/abs/2404.11973"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>        <br />本文全面概述了大型语言模型的发展现状、关键技术和应用前景，既有理论分析，也关注实际问题，为研究人员和从业者提供了很好的指南。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howvs9lsdxj20q2150tc7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1howvs9ymd5j218g1d6nad.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howvsaik9zj214m19s49b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 22:10:31 GMT</pubDate>
</item>
<item>
<title>[CL] Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment 网页链接 通过跨语言奖励模型迁移实现无需目标语言偏好数据即可对齐语...</title>
<link>https://weibo.com/1402400261/OaxjOkucv</link>
<guid>https://weibo.com/1402400261/OaxjOkucv</guid>
<content:encoded><![CDATA[
<div> 跨语言、奖励模型迁移、无需目标语言偏好数据、对齐语言模型、实证结果、有效性、实用性<br />
<br />
提出了一种通过跨语言奖励模型迁移实现无需目标语言偏好数据即可对齐语言模型的方法，并提供了一系列实证结果证明了该方法的有效性和实用性。该方法可以帮助实现跨语言对齐，提供了一种有效的无监督或弱监督学习的思路。研究表明，通过将奖励机制在不同语言间进行迁移，可以有效地传递模型知识和对齐模型特性。这种方法不仅适用于文本领域，也可以拓展到其他领域，为跨语言模型迁移和对齐提供了新的思路和方法。该研究为促进不同语言之间的信息交流和知识共享提供了重要的理论和方法支持，具有一定的实际应用意义。<br /><br />总结: <br />提出了一种跨语言奖励模型迁移的方法，无需目标语言偏好数据即可完成语言模型对齐，实证结果证明了该方法的有效性和实用性，为跨语言模型迁移和对齐提供了新的思路和方法。 <div>
[CL] Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment  <br /><a href="https://arxiv.org/abs/2404.12318"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过跨语言奖励模型迁移实现无需目标语言偏好数据即可对齐语言模型，并提供了一系列实证结果证明了该方法的有效性和实用性。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howvfqcsowj20sg16mgy4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howvfqmcp0j20ni190gsf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howvfr9qyfj21bg17aguq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 21:58:28 GMT</pubDate>
</item>
<item>
<title>[IR] Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing 网页链接 通过后处理相关性预测与排序偏好，成功将L...</title>
<link>https://weibo.com/1402400261/Oaxhfeihj</link>
<guid>https://weibo.com/1402400261/Oaxhfeihj</guid>
<content:encoded><![CDATA[
<div> 大语言模型、后处理、相关性预测、排序、LLM、公共数据集、整合、打分、排名能力、良好平衡

在这篇论文中，研究人员通过后处理方法成功地整合了大型语言模型（LLM）的打分和排名能力，实现了在多个公共数据集上排序与相关性指标的良好平衡。他们提出了一种方法，通过对LLM输出的打分和排名结果进行后处理来提高性能。通过在不同任务和数据集上的实验，研究人员证明了这种方法的有效性，说明后处理可以帮助提高LLM的排序和相关性预测能力。这项研究对于改进大语言模型在各种自然语言处理任务中的表现具有重要意义，为进一步研究提供了新的思路。

<br /><br />总结: 本研究通过后处理方法整合了大型语言模型的打分和排名能力，实现了在多个公共数据集上排序与相关性指标的良好平衡。他们的方法在不同任务和数据集上的实验表明有效性，对改进自然语言处理任务中的表现具有重要意义，为未来研究提供了新方向。 <div>
[IR] Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing  <br /><a href="https://arxiv.org/abs/2404.11791"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />通过后处理相关性预测与排序偏好，成功将LLM的打分与排名能力进行整合，在多个公共数据集上取得了排序与相关性指标的良好平衡。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howv9680z3j20wg1c4kaj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1howv96cn7dj21h20lugri.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howv96ot9fj20qk14adln.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 21:52:09 GMT</pubDate>
</item>
<item>
<title>通过定制化的嵌入模型、生成模型以及OODA循环推理，大幅提高了基于检索增强生成的金融QA系统在FinanceBench数据集上的性能，为构建高质量、高鲁棒性的QA系统提供...</title>
<link>https://weibo.com/1402400261/Oaxh64KoM</link>
<guid>https://weibo.com/1402400261/Oaxh64KoM</guid>
<content:encoded><![CDATA[
<div> 金融QA系统、检索增强生成、嵌入模型、生成模型、OODA循环推理、FinanceBench数据集、性能提升、高质量、高鲁棒性、指导<br />
<br />
<br />
总结: 通过定制化的嵌入模型、生成模型以及OODA循环推理，大幅提高了基于检索增强生成的金融QA系统在FinanceBench数据集上的性能。这项研究为构建高质量、高鲁棒性的QA系统提供了宝贵指导，为金融领域提供了有益的研究成果。 <div>
通过定制化的嵌入模型、生成模型以及OODA循环推理，大幅提高了基于检索增强生成的金融QA系统在FinanceBench数据集上的性能，为构建高质量、高鲁棒性的QA系统提供了宝贵指导。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Enhancing Q&amp;A with Domain-Specific Fine-Tuning and Iterative Reasoning: A Comparative Study》Z Nguyen, A Annunziata, V Luong, S Dinh... [Aitomatic, Inc &amp; IBM Research] (2024) <a href="https://arxiv.org/abs/2404.11792"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuvz20w3j21fa0j8qca.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuvzauhuj212u0wa77s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howuvzo7zpj218u17kn27.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 21:51:47 GMT</pubDate>
</item>
<item>
<title>[CL]《Enhancing Q&amp;A with Domain-Specific Fine-Tuning and Iterative Reasoning: A Comparative Study》Z Nguyen, A Annunziata, V Luong, S Dinh... [Aitomat...</title>
<link>https://weibo.com/1402400261/Oaxh1ryzv</link>
<guid>https://weibo.com/1402400261/Oaxh1ryzv</guid>
<content:encoded><![CDATA[
<div> 领域特定微调，迭代推理，自动化公司，IBM研究，问答系统

<br /><br />总结:
研究对比了领域特定微调和迭代推理对问答系统性能的影响。研究由Aitomatic公司和IBM Research共同进行。首先介绍了问答系统的背景和重要性，随后阐述了领域特定微调和迭代推理的工作原理和优势。研究结果显示，在特定领域微调和迭代推理相结合的情况下，问答系统的性能有显著提升。这些发现对于优化问答系统的设计和应用具有重要意义。 <div>
[CL]《Enhancing Q&amp;A with Domain-Specific Fine-Tuning and Iterative Reasoning: A Comparative Study》Z Nguyen, A Annunziata, V Luong, S Dinh... [Aitomatic, Inc &amp; IBM Research] (2024) <a href="https://arxiv.org/abs/2404.11792"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuvz20w3j21fa0j8qca.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuvzauhuj212u0wa77s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howuvzo7zpj218u17kn27.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 21:51:36 GMT</pubDate>
</item>
<item>
<title>通过对各种基准测试设置的影响分析，推荐了一个平衡代表性与效率的视觉基础模型(VFM)语义分割评测方案，并基于此得出了多个有价值的模型选择及设计建议。 - 转发...</title>
<link>https://weibo.com/1402400261/Oaxb0xXmO</link>
<guid>https://weibo.com/1402400261/Oaxb0xXmO</guid>
<content:encoded><![CDATA[
<div> 基准测试、影响分析、视觉基础模型、语义分割、评测方案、模型选择、设计建议、效率、代表性、多个关键词

<br /><br />总结:
研究通过对各种基准测试设置的影响分析，提出了一个平衡代表性与效率的视觉基础模型(VFM)语义分割评测方案。该评测方案为模型选择和设计提供了有价值的建议，可以帮助研究人员更好地评估和改进语义分割模型的性能。通过本文的工作，可以更好地理解在语义分割任务中不同基准测试设置对模型性能评估的影响，并且能够为研究人员提供指导，以找到平衡代表性与效率的最佳模型选择和设计方案。 <div>
通过对各种基准测试设置的影响分析，推荐了一个平衡代表性与效率的视觉基础模型(VFM)语义分割评测方案，并基于此得出了多个有价值的模型选择及设计建议。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《How to Benchmark Vision Foundation Models for Semantic Segmentation?》T Kerssies, D d Geus, G Dubbelman [Eindhoven University of Technology] (2024) <a href="https://arxiv.org/abs/2404.12172"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howuhnhg2jj20tu19g17l.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuho5wn0j20ts0vsdka.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuhoazb3j20ta0t6ade.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuhodswij20ty0tk427.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1howut0pbmyj20j00imjsn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howut0pezwj20j10im3zr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howut0p8vtj20j00imaba.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howut0pbd6j20j00htab4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howut0p3mlj20j10hsmy6.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 21:36:47 GMT</pubDate>
</item>
<item>
<title>[CV]《How to Benchmark Vision Foundation Models for Semantic Segmentation?》T Kerssies, D d Geus, G Dubbelman [Eindhoven University of Technology] (20...</title>
<link>https://weibo.com/1402400261/OaxaWpNT8</link>
<guid>https://weibo.com/1402400261/OaxaWpNT8</guid>
<content:encoded><![CDATA[
<div> 关键词：Benchmark, Vision Foundation Models, Semantic Segmentation, Eindhoven University of Technology<br />
<br />
总结: 本文作者来自Eindhoven University of Technology，提出了如何为语义分割的视觉基础模型进行基准测试的方法。他们通过研究深度学习模型，在语义分割任务中的表现，在实验中对比不同模型的性能。作者使用了一些先进的基准测试方法，以确保结果的准确性和可靠性。他们的研究结果有助于指导语义分割模型的发展和优化，为进一步研究提供了重要参考。 <div>
[CV]《How to Benchmark Vision Foundation Models for Semantic Segmentation?》T Kerssies, D d Geus, G Dubbelman [Eindhoven University of Technology] (2024) <a href="https://arxiv.org/abs/2404.12172"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howuhnhg2jj20tu19g17l.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuho5wn0j20ts0vsdka.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuhoazb3j20ta0t6ade.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howuhodswij20ty0tk427.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1howut0pbmyj20j00imjsn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howut0pezwj20j10im3zr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howut0p8vtj20j00imaba.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howut0pbd6j20j00htab4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howut0p3mlj20j10hsmy6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howut0pf6ij20j00jh75n.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 21:36:37 GMT</pubDate>
</item>
<item>
<title>提出通过 Marching Cubes 算法从关联高斯点云重建质量高且具跨帧对应关系的动态网格。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《Dynamic Gaussians Mesh: Consistent ...</title>
<link>https://weibo.com/1402400261/Oax4K9MNa</link>
<guid>https://weibo.com/1402400261/Oax4K9MNa</guid>
<content:encoded><![CDATA[
<div> 高斯点云，Marching Cubes算法，动态网格，质量重建，跨帧对应关系，单眼视频，一致性网格重建，加州大学圣地亚哥，刘伊，苏华，王欣

总结：<br /><br />本文提出了一种名为动态高斯网格的方法，旨在通过单眼视频实现一致的网格重建。通过利用高斯点云和Marching Cubes算法，实现了高质量的网格重建，同时具备跨帧对应关系。研究团队来自加州大学圣地亚哥，作者包括刘伊、苏华和王欣。通过该方法，可以实现动态物体的精确重建，并且在单眼视频情况下也能取得理想的效果。 <div>
提出通过 Marching Cubes 算法从关联高斯点云重建质量高且具跨帧对应关系的动态网格。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular Videos》I Liu, H Su, X Wang [University of California, San Diego] (2024) <a href="https://arxiv.org/abs/2404.12379"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howub5bwhsj20zw0t1drm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howub5zgouj20gs0iytbf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howub69cfoj216c0rygt4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howub6i7n8j216c0rygt4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howucwogrzj20rk17hdka.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howucwodfvj20rk16pwhz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1howucwnt24j20rj0jdtbe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howucwopssj20rk16nq6n.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howucwp5xaj20rk17ntcs.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 21:21:20 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.19)》 爱可可微博热门分享(4.19) [图片]</title>
<link>https://weibo.com/1402400261/Oauk4ninj</link>
<guid>https://weibo.com/1402400261/Oauk4ninj</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、4.19、话题、讨论、用户、社交平台、关注者

<br /><br />总结:
本文讨论了在社交平台上热门的话题和分享内容，主要围绕爱可可微博上4.19日的讨论展开。用户们积极参与讨论和分享，吸引了大量关注者的关注。微博作为一个社交平台，扮演着连接用户和内容的重要角色，为用户提供了一个互动交流的平台。整体来看，用户们对这个话题表现出了浓厚的兴趣和参与度。 <div>
《爱可可微博热门分享(4.19)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405024998443319789"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.19)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1howi7i3z0zj20rs0fmaei.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 14:20:52 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Learning to Produce Semi-dense Correspondences for Visual Localization》(CVPR 2024) GitHub: github.com/TruongKhang/DeViLoc《Closel...</title>
<link>https://weibo.com/1402400261/Oaufxs1ea</link>
<guid>https://weibo.com/1402400261/Oaufxs1ea</guid>
<content:encoded><![CDATA[
<div> Learning, Semi-dense Correspondences, Visual Localization, Deep Learning, Computer Vision, 地标识别<br />
<br />
要点1: 该论文提出了一种学习产生半密集对应关系用于视觉定位的方法，通过深度学习技术实现。<br />
要点2: 该方法在地标识别和视觉定位方面取得了较好的效果，提高了准确性和鲁棒性。<br />
要点3: 通过GitHub链接可以获取论文实现代码，方便其他研究者进行复现和进一步研究。<br />

总结: 本篇论文介绍了一种利用深度学习技术学习半密集对应关系以实现视觉定位的方法。该方法在地标识别和视觉定位方面表现出色，提高了准确性和鲁棒性。通过提供GitHub链接，使得其他研究者可以获取论文实现代码，促进了进一步的研究和应用。 <div>
几篇论文实现代码：<br />《Learning to Produce Semi-dense Correspondences for Visual Localization》(CVPR 2024) GitHub: github.com/TruongKhang/DeViLoc<br />《Closely Interactive Human Reconstruction with Proxemics and Physics-Guided Adaption》(CVPR 2024) GitHub: github.com/boycehbz/HumanInteraction [fig1]<br />《Contrastive Mean-Shift Learning for Generalized Category Discovery》(CVPR 2024) GitHub: github.com/sua-choi/CMS [fig3]<br />《Can Language Models Solve Olympiad Programming?》(2024) GitHub: github.com/princeton-nlp/USACO<br />《Neural Speech Decoding》(2024) GitHub: github.com/flinkerlab/neural_speech_decoding [fig2]<br />《Actions Speak Louder than Words Trillion-Parameter Sequential Transducers for Generative Recommendations》(2024) GitHub: github.com/facebookresearch/generative-recommenders<br />《Dynamic Typography: Bringing Text to Life via Video Diffusion Prior》(2024) GitHub: github.com/zliucz/animate-your-word<br />《RoadBEV: Road Surface Reconstruction in Bird’s Eye View》(2024) GitHub: github.com/ztsrxh/RoadBEV [fig4]<br />《GISTEmbed: Guided In-sample Selection of Training Negatives for Text Embedding Fine-tuning》(2024) GitHub: github.com/avsolatorio/GISTEmbed [fig5] <br />《TF-CLIP: Learning Text-Free CLIP for Video-Based Person Re-identification》(2024) GitHub: github.com/AsuradaYuci/TF-CLIP [fig6]<br />《Learning to design protein-protein interactions with enhanced generalization》(2024) GitHub: github.com/anton-bushuiev/PPIRef<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howgyj3nr8j24ou1q71jj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howgyjjvgxj22vq130as1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1howh6kwq9aj234o11ox09.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1howh7ep8e6j21e00dh7dv.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howhemwstrj21mc1uob29.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1howhga2rzej219m0qdwz7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 14:09:42 GMT</pubDate>
</item>
<item>
<title>【Academic paper URL to Obsidian Note：Obsidian 插件，用于自动从 arXiv.org、acl anthology 和 semantic scholar 创建笔记】'Academic paper URL to Obsidia...</title>
<link>https://weibo.com/1402400261/Oau9bE0WO</link>
<guid>https://weibo.com/1402400261/Oau9bE0WO</guid>
<content:encoded><![CDATA[
<div> arXiv.org, acl anthology, semantic scholar, Obsidian 插件, 自动创建笔记, 学术论文

插件名称为"Academic paper URL to Obsidian Note"，可以从arXiv.org、acl anthology和semantic scholar自动创建笔记。用户只需提供学术论文的URL链接，插件即可帮助用户生成相应的笔记。这个工具为研究人员提供了方便快捷的方法来整理和管理自己感兴趣的学术论文信息，节省了他们的时间和精力。值得注意的是，插件的开发者为GitHub上的chauff。通过安装这个插件，研究人员可以更加高效地利用这些在线学术资源，将有助于他们的学术研究工作。<br /><br />总结: 本插件为Obsidian提供了一个便捷的方式，可以从arXiv.org、acl anthology和semantic scholar自动创建笔记，为研究人员提供了一个整理和管理学术论文信息的高效工具。 <div>
【Academic paper URL to Obsidian Note：Obsidian 插件，用于自动从 arXiv.org、acl anthology 和 semantic scholar 创建笔记】'Academic paper URL to Obsidian Note - Obsidian plugin to automatically create a note from arXiv.org, acl anthology and semantic scholar.' GitHub: github.com/chauff/paper-note-filler <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Obsidian%23"><span class="surl-text">#Obsidian#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8howhfrcz23j21bc0u0gux.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 13:54:04 GMT</pubDate>
</item>
<item>
<title>【多模态大语言模型(MLLM)幻觉相关论文资源列表】’Awesome Hallucination Papers in MLLMs - Papers about Hallucination in Multi-Modal Large Language Model...</title>
<link>https://weibo.com/1402400261/Oau8pBStj</link>
<guid>https://weibo.com/1402400261/Oau8pBStj</guid>
<content:encoded><![CDATA[
<div> GitHub、多模态大语言模型、幻觉、论文、资源、列表、研究、深度学习、人工智能、自然语言处理

总结:<br />
本GitHub资源分享了关于多模态大语言模型（MLLMs）中幻觉方面的论文，涵盖了深度学习、人工智能和自然语言处理等研究领域。可以在该资源中找到与MLLMs幻觉相关的最新论文，帮助研究者了解其在不同视觉和语言模态之间生成幻觉的机制和应用。GitHub链接提供了丰富的文献资源，有助于学术界和工业界关注和探讨MLLMs中幻觉产生的现象和挑战。 <div>
【多模态大语言模型(MLLM)幻觉相关论文资源列表】’Awesome Hallucination Papers in MLLMs - Papers about Hallucination in Multi-Modal Large Language Models (MLLMs)' GitHub: github.com/shikiw/Awesome-MLLM-Hallucination <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8howhdeyb79j20y20u042k.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 13:52:09 GMT</pubDate>
</item>
<item>
<title>【LibContinual：基于 PyTorch 的开源持续学习工具箱】'LibContinual - A Framework of Continual Learning' GitHub: github.com/RL-VIG/LibContinual #开源# #...</title>
<link>https://weibo.com/1402400261/Oau6hxUQx</link>
<guid>https://weibo.com/1402400261/Oau6hxUQx</guid>
<content:encoded><![CDATA[
<div> GitHub, LibContinual, PyTorch, 开源, 持续学习, 工具箱, 框架, Continual Learning <br />
<br />
提供了一个基于PyTorch的开源持续学习工具箱LibContinual，旨在帮助研究人员和开发者进行持续学习任务。该工具箱提供了一个框架，可以在不断接收新信息的情况下进行持续学习，有助于模型的不断进化和优化。LibContinual还提供了丰富的功能和工具，方便用户进行持续学习任务的实验和研究。使用LibContinual可以更加高效地进行持续学习任务的开发和实施，为持续学习领域的研究和应用提供了重要的工具支持。整体来说，LibContinual是一个功能强大且易于使用的持续学习工具箱，为研究人员和开发者提供了便利和支持。 <br />
<br />总结: <br />提供了一个基于PyTorch的开源持续学习工具箱LibContinual，框架可以进行持续学习，有助于模型不断进化；提供了丰富的功能和工具，方便进行持续学习任务的实验和研究；高效进行持续学习任务的开发和实施，为持续学习领域提供了重要支持。 <div>
【LibContinual：基于 PyTorch 的开源持续学习工具箱】'LibContinual - A Framework of Continual Learning' GitHub: github.com/RL-VIG/LibContinual <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8howh86zdgpj20u00u3tcr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 13:46:54 GMT</pubDate>
</item>
<item>
<title>【hf-chat：使用 huggingface/chat-ui 和 huggingface/candle 创建的适用于 macOS 和 iOS 的本地高效的聊天应用程序】'hf-chat' GitHub: github.com/Narsil/hf-c...</title>
<link>https://weibo.com/1402400261/Oau4NwirE</link>
<guid>https://weibo.com/1402400261/Oau4NwirE</guid>
<content:encoded><![CDATA[
<div> GitHub, hf-chat, huggingface, chat-ui, candle, macOS, iOS, 本地, 高效, 聊天应用程序
<br /><br />总结:
文章介绍了一款本地高效的聊天应用程序'hf-chat'，使用了huggingface/chat-ui和huggingface/candle创建，适用于macOS和iOS系统。该应用程序的GitHub地址为github.com/Narsil/hf-chat。通过结合huggingface/chat-ui和huggingface/candle技术，实现了具有高效性能的聊天功能，满足了用户在macOS和iOS系统下的聊天需求。 <div>
【hf-chat：使用 huggingface/chat-ui 和 huggingface/candle 创建的适用于 macOS 和 iOS 的本地高效的聊天应用程序】'hf-chat' GitHub: github.com/Narsil/hf-chat <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8howh4g43zjj20u012z0xa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 13:43:15 GMT</pubDate>
</item>
<item>
<title>【深度神经网络剪枝相关论文资源列表】’awesome-pruning' GitHub: github.com/hrcheng1066/awesome-pruning #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/Oau46tkM3</link>
<guid>https://weibo.com/1402400261/Oau46tkM3</guid>
<content:encoded><![CDATA[
<div> GitHub, 深度神经网络, 剪枝, 资源列表, 论文<br />
<br />
提到了一个名为'awesome-pruning'的GitHub仓库，其中收集了与深度神经网络剪枝相关的资源列表。这个资源库包含了大量剪枝相关的论文，可以帮助研究人员更好地了解和探索这个领域。深度神经网络剪枝是一种通过减少模型中的冗余参数来提高模型效率和加速推理过程的技术。研究这个领域的论文可以指导剪枝算法的设计和优化。这些论文提出了各种剪枝方法和策略，可以根据需求选择适合的剪枝技术来优化模型。深度神经网络的剪枝是提高模型性能和效率的重要手段，研究人员可以通过这个资源库获取最新的剪枝论文和技术，从而推动这个领域的发展。<br /><br />总结: <br />这个GitHub资源库收集了与深度神经网络剪枝相关的论文，可以帮助研究人员了解剪枝技术的发展和应用。剪枝是提高模型性能和效率的重要方法，研究人员可以根据需求选择合适的剪枝技术来优化模型。这些论文提出了各种剪枝方法和策略，可以指导剪枝算法的设计和优化。通过研究这些论文，可以更好地了解剪枝技术的原理和实践，为深度学习领域的发展提供指导和启发。 <div>
【深度神经网络剪枝相关论文资源列表】’awesome-pruning' GitHub: github.com/hrcheng1066/awesome-pruning <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8howh2owhacj20n40bkjtd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 13:41:32 GMT</pubDate>
</item>
<item>
<title>【chatstream for Shiny for Python：一个 Shiny for Python 模块，用于构建 AI 聊天应用程序】'chatstream for Shiny for Python - Example Shiny for Python a...</title>
<link>https://weibo.com/1402400261/Oau3p7H6a</link>
<guid>https://weibo.com/1402400261/Oau3p7H6a</guid>
<content:encoded><![CDATA[
<div> chatstream, Shiny for Python, AI, 聊天应用程序, 模块, OpenAI API, GitHub, wch, Example

<br /><br />总结:
Shiny for Python 是一个用于构建 AI 聊天应用程序的模块，chatstream for Shiny for Python 则是一个示例应用，可以与 OpenAI API 进行交互。这个项目托管在 GitHub 上，由用户 wch 开发和维护。通过该模块，用户可以快速搭建基于 Python 的 AI 聊天应用程序，并利用 OpenAI API 的强大功能实现更丰富的对话交互体验。 <div>
【chatstream for Shiny for Python：一个 Shiny for Python 模块，用于构建 AI 聊天应用程序】'chatstream for Shiny for Python - Example Shiny for Python app which talks to the OpenAI API' GitHub: github.com/wch/chatstream <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8howh0wmpb5j21740oyq7v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 13:39:48 GMT</pubDate>
</item>
<item>
<title>【ARAGOG：旨在探索和比较各种基于检索增强生成(RAG)技术，用于评估人工智能研究论文数据集的输出，包括模块化代码，以便于实验和重用，包含用于评估的问答对、A...</title>
<link>https://weibo.com/1402400261/Oar5dcyBs</link>
<guid>https://weibo.com/1402400261/Oar5dcyBs</guid>
<content:encoded><![CDATA[
<div> 代码、RAG、人工智能、实验、数据集、评估、问答对、AI ArXiv 论文集合、资源文件、Jupyter 笔记本

<br /><br />总结:
ARAGOG是一个旨在探索和比较各种基于检索增强生成(RAG)技术的项目，用于评估人工智能研究论文数据集的输出。该项目包含了模块化的代码，使实验和重用变得更加容易。其中包括用于评估的问答对、AI ArXiv 论文集合、资源文件(如提示模板和配置文件)、主要脚本(用于定义和执行实验)、Jupyter 笔记本(用于分析最终实验结果)、辅助函数和用于设置向量数据库的脚本。通过ARAGOG，研究人员可以快速地对不同的RAG技术进行比较和分析，从而为人工智能领域的研究提供更多参考和借鉴。 <div>
【ARAGOG：旨在探索和比较各种基于检索增强生成(RAG)技术，用于评估人工智能研究论文数据集的输出，包括模块化代码，以便于实验和重用，包含用于评估的问答对、AI ArXiv 论文集合、资源文件(如提示模板和配置文件)、主要脚本(用于定义和执行实验)、Jupyter 笔记本(用于分析最终实验结果)、辅助函数和用于设置向量数据库的脚本。 4】’ARAGOG- Advanced RAG Output Grading. Exploring and comparing various Retrieval-Augmented Generation (RAG) techniques on AI research papers dataset. Includes modular code for easy experimentation and reusability.' GitHub: github.com/predlico/ARAGOG <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8how3wpwz14j20u00z2dlk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 06:06:01 GMT</pubDate>
</item>
<item>
<title>【MLC-MiniCPM：基于 MLC-LLM 开发，将 MiniCPM 和 MiniCPM-V 在 Android 手机端上运行】'MLC-MiniCPM - MiniCPM on Android platform.' GitHub: github.com/Ope...</title>
<link>https://weibo.com/1402400261/Oar2grQdj</link>
<guid>https://weibo.com/1402400261/Oar2grQdj</guid>
<content:encoded><![CDATA[
<div> MiniCPM, MiniCPM-V, Android手机端, MLC-LLM, GitHub, 开发
<br />
MLC-MiniCPM是基于MLC-LLM开发的，可以在Android手机端上运行MiniCPM和MiniCPM-V。该项目在GitHub上有开源代码。
<br /><br />总结:
MLC-MiniCPM是一个运行在Android手机上的项目，基于MLC-LLM开发，可以实现MiniCPM和MiniCPM-V的功能。用户可以在GitHub上查看该项目的开源代码。 <div>
【MLC-MiniCPM：基于 MLC-LLM 开发，将 MiniCPM 和 MiniCPM-V 在 Android 手机端上运行】'MLC-MiniCPM - MiniCPM on Android platform.' GitHub: github.com/OpenBMB/mlc-MiniCPM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8how3p08oy5j209o0lgq35.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 05:58:46 GMT</pubDate>
</item>
<item>
<title>【SoccerNet Game State Challenge：SoccerNet 游戏状态开发工具包是一个帮助开始使用数据和建议任务的工具包。它建立在 TrackLab 上，一个用于多目标跟踪的研究...</title>
<link>https://weibo.com/1402400261/OaqQyzdGs</link>
<guid>https://weibo.com/1402400261/OaqQyzdGs</guid>
<content:encoded><![CDATA[
<div> SoccerNet, Game State, 数据, 建议任务, TrackLab, 多目标跟踪, 计算机视觉, 运动分析, 识别任务, 位置定位

<br /><br />总结:
SoccerNet 游戏状态开发工具包是一个建立在TrackLab上的工具包，用于帮助开始使用数据和建议任务。它专注于游戏状态识别任务，这是一项新的高级计算机视觉任务，旨在识别和定位所有运动员在球场上的位置。这个挑战还有一个公开的GitHub仓库，用于支持SoccerNet Game State Challenge。 <div>
【SoccerNet Game State Challenge：SoccerNet 游戏状态开发工具包是一个帮助开始使用数据和建议任务的工具包。它建立在 TrackLab 上，一个用于多目标跟踪的研究框架。游戏状态识别任务是一项新的高级计算机视觉任务，专门用于运动分析。它旨在识别和定位所有运动员（球员、裁判等）在球场上的位置，基于原始输入视频】'SoccerNet Game State Challenge - Public repository for the SoccerNet Game State Challenge' GitHub: github.com/SoccerNet/sn-gamestate <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8how2v3fsctj20m80ci40w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8how2v5uo9mj22c60u0tgg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 05:29:55 GMT</pubDate>
</item>
<item>
<title>【llm：Andrjey Karpathy最小化LLM代码的Mojo移植版】’llm - port of Andrjey Karpathy's llm.c to Mojo' GitHub: github.com/dorjeduck/llm.mojo #开源# #机器...</title>
<link>https://weibo.com/1402400261/OaqNe0jCI</link>
<guid>https://weibo.com/1402400261/OaqNe0jCI</guid>
<content:encoded><![CDATA[
<div> llm, Andrjey Karpathy, 移植, Mojo, GitHub, dorjeduck, 代码, 最小化, 版本, llm.c
<br /><br />
总结: 本文介绍了将Andrjey Karpathy的llm.c代码移植到Mojo的版本，作者在GitHub上发布了名为llm.mojo的项目。这个项目是对原始代码的最小化版本，旨在将代码移植到Mojo平台上。读者可以在GitHub上找到该项目并了解更多详细信息。 <div>
【llm：Andrjey Karpathy最小化LLM代码的Mojo移植版】’llm - port of Andrjey Karpathy's llm.c to Mojo' GitHub: github.com/dorjeduck/llm.mojo <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8how2mm0152j21ji0qmwjk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 05:21:41 GMT</pubDate>
</item>
<item>
<title>【深度立体匹配(Deep Stereo Matching）相关论文资源列表】’Awesome-Deep-Stereo-Matching - A curated list of awesome Deep Stereo Matching resources' GitH...</title>
<link>https://weibo.com/1402400261/OaqMQDpHJ</link>
<guid>https://weibo.com/1402400261/OaqMQDpHJ</guid>
<content:encoded><![CDATA[
<div> 深度立体匹配, 资源列表, 论文, GitHub, 资源, 深度学习, 立体视觉, 深度信息, 深度图像, 深度特征

<br />
在GitHub上有一份资源列表，包含了有关深度立体匹配的论文和资源，涵盖了深度学习在立体视觉中的应用。这份列表整理了各种文献和研究成果，供研究者和开发者参考，帮助他们在深度立体匹配领域取得更好的效果。通过学习这些资源，可以更好地理解立体信息的提取和匹配过程，提高立体图像处理的准确性和效率。深度学习技术在立体匹配中的应用，可以为计算机视觉和机器人领域带来更多新的可能性。总之，这份资源列表对于深度立体匹配研究者和实践者来说是一个很有价值的工具。 

<br /><br />总结:深度立体匹配的资源列表在GitHub上提供了相关论文和资源，为研究者和开发者提供了学习和参考资料，促进了深度学习在立体视觉领域的发展。 <div>
【深度立体匹配(Deep Stereo Matching）相关论文资源列表】’Awesome-Deep-Stereo-Matching - A curated list of awesome Deep Stereo Matching resources' GitHub: github.com/fabiotosi92/Awesome-Deep-Stereo-Matching <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8how2lnrtqpj21jk0qawlm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 05:20:47 GMT</pubDate>
</item>
<item>
<title>【Prompt Fuzzer：用于强化 GenAI 应用的开源工具，旨在帮助开发人员检测和防御针对其应用的 LLM 攻击，包括一个 Playground 聊天界面，用于帮助用户迭代地提高...</title>
<link>https://weibo.com/1402400261/OaqM44g2U</link>
<guid>https://weibo.com/1402400261/OaqM44g2U</guid>
<content:encoded><![CDATA[
<div> GenAI、开源工具、Prompt Fuzzer、LLM 攻击、Playground、聊天界面、系统提示的安全性、LLM 提供商、动态攻击模拟、安全测试<br />
<br />
总结:<br />
"Prompt Fuzzer"是一个开源工具，用于强化GenAI应用的安全性，帮助开发人员检测和防御针对应用的LLM攻击。该工具包括一个Playground聊天界面，用户可以通过迭代提高系统提示的安全性。支持20种不同的LLM提供商和20种动态LLM攻击模拟，包括Jailbreak、Prompt Injection和System Prompt Extraction。用户可以使用这个工具来测试和加固他们的系统提示，确保其应用程序安全可靠。 <div>
【Prompt Fuzzer：用于强化 GenAI 应用的开源工具，旨在帮助开发人员检测和防御针对其应用的 LLM 攻击，包括一个 Playground 聊天界面，用于帮助用户迭代地提高其系统提示的安全性，支持 20 种不同的 LLM 提供商和 20 种动态 LLM 攻击模拟，例如 Jailbreak、Prompt Injection 和 System Prompt Extraction】'Prompt Fuzzer - Make your GenAI Apps Safe &amp; Secure Test &amp; harden your system prompt' GitHub: github.com/prompt-security/ps-fuzz <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8how2jmu2l6j20z70u0n0h.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 05:18:51 GMT</pubDate>
</item>
<item>
<title>【非官方的 ComfyUI 魔法变装实现】'unofficial implementation of Comfyui magic clothing' GitHub: github.com/frankchieng/ComfyUI_MagicClothing #开源# #机...</title>
<link>https://weibo.com/1402400261/OaqFA13o4</link>
<guid>https://weibo.com/1402400261/OaqFA13o4</guid>
<content:encoded><![CDATA[
<div> GitHub, ComfyUI, 魔法变装, 非官方实现, 服装改变, 项目, 模仿实现, 可穿戴技术

总结:<br /><br />文章介绍了一个非官方的 ComfyUI 魔法变装实现项目，通过 GitHub 上的项目链接可以找到该项目的详细信息。该项目模仿了 ComfyUI 魔法变装的功能，实现了服装的变换和改变。这个项目展示了可穿戴技术的潜力，为用户提供了一种新颖的穿戴体验。 <div>
【非官方的 ComfyUI 魔法变装实现】'unofficial implementation of Comfyui magic clothing' GitHub: github.com/frankchieng/ComfyUI_MagicClothing <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8how2314cb9j21ce0lyjv9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 05:02:52 GMT</pubDate>
</item>
<item>
<title>GitHub：github.com/meta-llama/llama3 - 转发 @爱可可-爱生活:&amp;ensp;【Meta发布Llama 3，新一代开源大型语言模型】- Meta发布了第三代开源大模型Meta Llama 3，...</title>
<link>https://weibo.com/1402400261/OaqEtw0k5</link>
<guid>https://weibo.com/1402400261/OaqEtw0k5</guid>
<content:encoded><![CDATA[
<div> Meta、Llama 3、开源、语言模型、性能、安全可控、多语言、长上下文、多模态输入、部署
<br /><br />总结:
Meta发布了第三代开源大模型Llama 3，包括8B和70B参数两种规模的预训练语言模型，在多项基准测试中都表现出领先的性能，特别在推理和编码方面有明显改进。为了提高对话用例表现，Meta开发了指令微调技术，并确保模型的安全可控，提供了多种信任与安全工具。Llama 3将在各大云平台部署，支持多语言、长上下文和多模态输入。同时，Meta正在开发超过400B参数的Llama 3模型，未来会开源发布，并已将Meta AI助手集成了Llama 3，用户可以在不同的Meta产品上使用体验。Meta还开发了torchtune等辅助开发Llama 3的开源工具。 <div>
GitHub：github.com/meta-llama/llama3<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 【Meta发布Llama 3，新一代开源大型语言模型】<br />- Meta发布了第三代开源大模型Meta Llama 3，包括8B和70B参数两种规模的预训练语言模型。这是目前同规模参数下开源领域的最优模型。   <br />- Llama 3在多项业界基准测试上展现出领先的性能，尤其是在推理和编码等方面有明显改进。Meta通过预训练数据量的扩大、模型并行和管道并行等方式实现了模型训练的大规模化。   <br />- 为了让Llama 3对话用例的表现更优，Meta开发了指令微调技术，结合监督微调、拒绝抽样、近端策略优化等方法。提示质量和偏好排序对模型性能有很大影响。   <br />- Meta采用系统层面的方法确保Llama 3的安全可控，不仅微调了模型，还提供了 Llama Guard 2、Code Shield 和 CyberSec Eval 2等信任与安全工具。   <br />- Llama 3将在各大云平台部署，支持多语言、长上下文和多模态输入。Meta还开发了torchtune等辅助开发Llama 3的开源工具。   <br />- Meta正在开发超过400B参数的Llama 3模型，未来会开源发布。Meta AI助手已经集成了Llama 3，用户可以在不同的Meta产品上使用体验。<br />《Introducing Meta Llama 3: The most capable openly available LLM to date》 <a href="https://ai.meta.com/blog/meta-llama-3/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hovr9gq146j21e00u0tav.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hovr9idh2bj21hc0u0q65.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hovr9ketfcj21bt0u041d.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hovr9oe9jvj218g0hqq4t.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 19 Apr 2024 05:00:09 GMT</pubDate>
</item>
<item>
<title>【YouTube多语言数据集，包含 YouTube 上的视频信息和相关元数据，总共包含 400k 条记录，字段包括视频标题、链接、描述、发布日期、许可证、原始语言和转录语言...</title>
<link>https://weibo.com/1402400261/OaoBdxMrE</link>
<guid>https://weibo.com/1402400261/OaoBdxMrE</guid>
<content:encoded><![CDATA[
<div> 数据集、YouTube、视频信息、元数据、400k条记录、字段、视频标题、链接、描述、发布日期、许可证、原始语言、转录语言

总结:<br />
该数据集是关于YouTube上的视频信息和相关元数据的，总共包含400k条记录。每条记录包括视频标题、链接、描述、发布日期、许可证、原始语言和转录语言等字段。数据集涵盖广泛的主题和内容，对研究和分析YouTube平台上的视频具有重要意义。数据集的规模庞大，提供了丰富的信息资源，有助于深入了解YouTube视频的特点和趋势。该数据集对于语言处理、数据挖掘和机器学习等领域的研究具有重要的参考价值。数据集的开放共享也为学术研究和商业应用提供了便利，为相关领域的研究工作提供了重要支持。 <div>
【YouTube多语言数据集，包含 YouTube 上的视频信息和相关元数据，总共包含 400k 条记录，字段包括视频标题、链接、描述、发布日期、许可证、原始语言和转录语言等】《PleIAs/YouTube-Commons · Datasets at Hugging Face》 <a href="https://huggingface.co/datasets/PleIAs/YouTube-Commons"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hovsy07p36j21f40u07b3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 23:46:38 GMT</pubDate>
</item>
<item>
<title>【Meta发布Llama 3，新一代开源大型语言模型】- Meta发布了第三代开源大模型Meta Llama 3，包括8B和70B参数两种规模的预训练语言模型。这是目前同规模参数下开源...</title>
<link>https://weibo.com/1402400261/OaodKvpuJ</link>
<guid>https://weibo.com/1402400261/OaodKvpuJ</guid>
<content:encoded><![CDATA[
<div> 关键词: Meta, Llama 3, 开源, 大型语言模型, 性能, 安全, 部署, 辅助工具, 400B参数, Meta AI助手

总结:<br /><br />
Meta发布了第三代开源大模型Llama 3，包括8B和70B参数两种规模的预训练语言模型。该模型在多项业界基准测试上表现出领先性能，特别在推理和编码方面有明显改进。为了优化对话用例表现，Meta开发了指令微调技术。为保证安全可控，Meta采用系统层面方法，提供信任与安全工具。Llama 3将在各大云平台部署，支持多语言、长上下文和多模态输入。Meta还开发了辅助工具torchtune。未来Meta将发布400B参数的Llama 3模型，并已在Meta AI助手中集成Llama 3，用户可在不同产品上使用体验。 <div>
【Meta发布Llama 3，新一代开源大型语言模型】<br />- Meta发布了第三代开源大模型Meta Llama 3，包括8B和70B参数两种规模的预训练语言模型。这是目前同规模参数下开源领域的最优模型。   <br />- Llama 3在多项业界基准测试上展现出领先的性能，尤其是在推理和编码等方面有明显改进。Meta通过预训练数据量的扩大、模型并行和管道并行等方式实现了模型训练的大规模化。   <br />- 为了让Llama 3对话用例的表现更优，Meta开发了指令微调技术，结合监督微调、拒绝抽样、近端策略优化等方法。提示质量和偏好排序对模型性能有很大影响。   <br />- Meta采用系统层面的方法确保Llama 3的安全可控，不仅微调了模型，还提供了 Llama Guard 2、Code Shield 和 CyberSec Eval 2等信任与安全工具。   <br />- Llama 3将在各大云平台部署，支持多语言、长上下文和多模态输入。Meta还开发了torchtune等辅助开发Llama 3的开源工具。   <br />- Meta正在开发超过400B参数的Llama 3模型，未来会开源发布。Meta AI助手已经集成了Llama 3，用户可以在不同的Meta产品上使用体验。<br />《Introducing Meta Llama 3: The most capable openly available LLM to date》 <a href="https://ai.meta.com/blog/meta-llama-3/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hovr9gq146j21e00u0tav.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hovr9idh2bj21hc0u0q65.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hovr9ketfcj21bt0u041d.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hovr9oe9jvj218g0hqq4t.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 22:48:49 GMT</pubDate>
</item>
<item>
<title>【开放语言模型对齐】《Aligning open language models - Google Slides》Nathan Lambert 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/Oao9Ftpmw</link>
<guid>https://weibo.com/1402400261/Oao9Ftpmw</guid>
<content:encoded><![CDATA[
<div> 关键词：开放语言模型、对齐、Google Slides、Nathan Lambert

总结:<br /><br />本文介绍了如何通过对齐开放语言模型来提高其性能和效率。首先，作者介绍了开放语言模型的重要性和应用场景。接着，讨论了如何利用Google Slides平台进行开放语言模型的对齐工作。文章还提到了Nathan Lambert在这一领域的研究和贡献。通过对齐开放语言模型，可以更好地理解和应用这些模型，提高其性能和准确性。通过这篇文章，读者可以更深入地了解开放语言模型对齐的重要性和方法。 <div>
【开放语言模型对齐】《Aligning open language models - Google Slides》Nathan Lambert <a href="https://docs.google.com/presentation/d/1quMyI4BAx4rvcDfk8jjv063bmHg4RxZd9mhQloXpMn0/edit"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hovqz9hzngj21hd0u0jzg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 22:38:45 GMT</pubDate>
</item>
<item>
<title>今日推介(第1380期)：语多样本上下文学习、通过位置信息操纵提升大型语言模型、用更少截断改进语言建模、分子图上GNN的可扩展性研究、面向相机运动模糊的高斯Spl...</title>
<link>https://weibo.com/1402400261/Oao1n80W3</link>
<guid>https://weibo.com/1402400261/Oao1n80W3</guid>
<content:encoded><![CDATA[
<div> 语多样本上下文学习、位置信息操纵、大型语言模型、少截断改进、分子图上GNN可扩展性研究、面向相机运动模糊的高斯Splatting

总结:<br /><br />本文介绍了几个关于语言建模和图神经网络的研究进展。首先，提出了语多样本上下文学习和通过位置信息操纵来提升大型语言模型的方法，以改进语言建模的效果。其次，研究了如何通过更少的截断来改进语言建模的性能，以减少信息丢失。然后，探讨了在分子图上应用图神经网络的可扩展性，并对面向相机运动模糊的高斯Splatting技术进行了探讨。这些研究对于提高语言建模和图神经网络的效果有着重要的意义。 <div>
今日推介(第1380期)：语多样本上下文学习、通过位置信息操纵提升大型语言模型、用更少截断改进语言建模、分子图上GNN的可扩展性研究、面向相机运动模糊的高斯Splatting 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/693301537"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hovqdp5pzuj21j80rc10i.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hovqdtv4emj20qi0ucwi6.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hovqdx1q56j21nd0u07b2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hovqdzdhwyj20te0tgtdd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hovqe35lmpj21660oejw9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 22:18:19 GMT</pubDate>
</item>
<item>
<title>[CL] Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions 网页链接 通过审视社交智能的概念内涵和研究进展，提出Social-AI...</title>
<link>https://weibo.com/1402400261/OanXMemuh</link>
<guid>https://weibo.com/1402400261/OanXMemuh</guid>
<content:encoded><![CDATA[
<div> 挑战, 社交智能, AI代理, 技术, 社交构造, 互动信号, 多重视角, 智能体适应性, 方法, 开放问题

总结:<br />
本文探讨了社交智能在AI代理中的重要性，提出了面临的4大技术挑战：社交构造的模糊性、细微互动信号、多重视角和智能体适应性。针对这些挑战，文章提出了一些应对方法，并指出了一些仍待解决的开放问题。通过这些讨论，可以为Social-AI研究提供重要的指导和启发。 <div>
[CL] Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions  <br /><a href="https://arxiv.org/abs/2404.11023"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过审视社交智能的概念内涵和研究进展，提出Social-AI研究面临的4大核心技术挑战，包括社交构造的模糊性、细微互动信号、多重视角、智能体适应性，并给出应对这些挑战的方法与开放问题，对指导Social-AI研究具有重要启发作用。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovq4v7d09j20vy1ckngq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovq4vfqquj217619u4ai.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovq4w42hpj20ua0sutdn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 22:09:28 GMT</pubDate>
</item>
<item>
<title>[IR] A Survey on Retrieval-Augmented Text Generation for Large Language Models 网页链接 通过预处理、检索、后处理和生成四个阶段全面梳理检索增强型文本生...</title>
<link>https://weibo.com/1402400261/OanTvAiNt</link>
<guid>https://weibo.com/1402400261/OanTvAiNt</guid>
<content:encoded><![CDATA[
<div> 技术框架、方法进展、应用潜力、预处理、检索、后处理、生成、检索增强型文本生成、RAG

<br /><br />总结:
本文对检索增强型文本生成（RAG）进行了综合调查，从预处理、检索、后处理和生成四个阶段全面分析了RAG的技术框架、方法进展和应用潜力。首先介绍了RAG的基本概念及其研究背景，然后详细探讨了RAG在不同阶段的技术应用和改进，包括预处理阶段的数据准备和文本清洗，检索阶段的信息获取和匹配，生成阶段的文本生成能力和模型优化等。文章指出RAG在自然语言处理领域具有广阔的应用前景，能够提高文本生成的质量和效率，为读者深入了解RAG的内涵提供了详尽的参考资料。 <div>
[IR] A Survey on Retrieval-Augmented Text Generation for Large Language Models  <br /><a href="https://arxiv.org/abs/2404.10981"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过预处理、检索、后处理和生成四个阶段全面梳理检索增强型文本生成(RAG)的技术框架、方法进展与应用潜力，为读者理解 RAG 的内涵提供了清晰直观的途径。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovptxdy6aj20w41cak9j.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovptxmkrqj21b00n8aeg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovptyfzdcj21q60watot.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 21:58:57 GMT</pubDate>
</item>
<item>
<title>[CL] Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent 网页链接 Octopus v3提出了文本、图像和功能令牌的结合框架，在亚十亿参数...</title>
<link>https://weibo.com/1402400261/OanQxm3l0</link>
<guid>https://weibo.com/1402400261/OanQxm3l0</guid>
<content:encoded><![CDATA[
<div> 提取关键词: Octopus v3, 文本, 图像, 功能令牌, 多模态建模, 边缘部署, 亚十亿参数量

总结:<br /><br />总结: Octopus v3提出了文本、图像和功能令牌的结合框架，实现了多模态建模和边缘部署的有效结合。该模型在亚十亿参数量下进行了设计和实施，展现了在实际设备上运行的能力。通过结合不同类型的输入数据，Octopus v3能够更好地理解和处理复杂的信息，实现更高效的AI任务处理。同时，边缘部署也提高了模型的响应速度和隐私保护性，使得该多模态AI Agent在各种环境中都能够得到有效应用和部署。Octopus v3的提出为多模态AI技术的发展提供了重要的思路和参考。 <div>
[CL] Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent  <br /><a href="https://arxiv.org/abs/2404.11459"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />Octopus v3提出了文本、图像和功能令牌的结合框架，在亚十亿参数量下实现了多模态建模和边缘部署的有效结合。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovpmbqamlj20uu1aw4a2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovpmbyahuj21600xwdoi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovpmcelrxj216q0u8dk6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 21:51:38 GMT</pubDate>
</item>
<item>
<title>[LG] Variational Bayesian Last Layers 网页链接 提出变分贝叶斯最后层(VBLL)方法，以极小的计算开销显著改进了神经网络的不确定度建模和泛化能力。 [图片][图...</title>
<link>https://weibo.com/1402400261/OanNwjhGR</link>
<guid>https://weibo.com/1402400261/OanNwjhGR</guid>
<content:encoded><![CDATA[
<div> 变分贝叶斯；最后层；神经网络；不确定度建模；泛化能力；VBLL方法；计算开销；改进；极小；提出
<br />
<br />
总结: 本文提出了一种新方法，称为变分贝叶斯最后层（VBLL），可以显著改进神经网络的不确定度建模和泛化能力。通过极小的计算开销，VBLL方法在提高模型表现的同时，也可以有效地提高模型的不确定度估计能力。VBLL方法对于提高神经网络的性能和可靠性具有重要意义。 <div>
[LG] Variational Bayesian Last Layers  <br /><a href="https://arxiv.org/abs/2404.11599"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出变分贝叶斯最后层(VBLL)方法，以极小的计算开销显著改进了神经网络的不确定度建模和泛化能力。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovpelk329j20vu1cy7le.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovpelras0j21980oktfg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovpem2pxej219q0iwq7g.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 21:44:12 GMT</pubDate>
</item>
<item>
<title>提出DeblurGS框架，通过联合优化相机运动轨迹和基于3D高斯Splatting的清晰场景表示，实现了从含模糊多视图中重建细致逼真3D场景的目标，对处理实际应用中存在的...</title>
<link>https://weibo.com/1402400261/OanKPenH4</link>
<guid>https://weibo.com/1402400261/OanKPenH4</guid>
<content:encoded><![CDATA[
<div> DeblurGS, 相机运动轨迹, 3D高斯Splatting, 清晰场景表示, 多视图重建, 模糊效果, 实际应用, 重要意义, 高质量重建, 高效性能

<br /><br />总结:
DeblurGS框架提出了一种通过联合优化相机运动轨迹和基于3D高斯Splatting的清晰场景表示的方法。该方法旨在重建细致逼真的3D场景，处理含模糊多视图中存在的各类模糊效果。该框架结合了高质量重建和高效性能，对实际应用具有重要意义。通过对相机运动轨迹和3D场景表示的优化，DeblurGS实现了有效的模糊去除，为多视图重建提供了新的思路。通过使用3D高斯Splatting技术，使得重建的场景更加细致逼真。该研究为解决实际应用中的模糊效果问题提供了有力的工具和方法。 <div>
提出DeblurGS框架，通过联合优化相机运动轨迹和基于3D高斯Splatting的清晰场景表示，实现了从含模糊多视图中重建细致逼真3D场景的目标，对处理实际应用中存在的各类模糊效果具有重要意义。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《DeblurGS: Gaussian Splatting for Camera Motion Blur》J Oh, J Chung, D Lee, K M Lee [Seoul National University] (2024) <a href="https://arxiv.org/abs/2404.11358"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovp0hblwkj20zo0pck1m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovp0hpdj4j215g0p0aht.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovp0hwk7ij21660oeagj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovp0i1z1jj216o0u0qc6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovp7l7cqpj20rl0eegnq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovp7l76bfj20rl0e20ue.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovp7l850gj20rh0u2jw3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovp7l7ohyj20rl0iatbz.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 21:37:33 GMT</pubDate>
</item>
<item>
<title>[CV]《DeblurGS: Gaussian Splatting for Camera Motion Blur》J Oh, J Chung, D Lee, K M Lee [Seoul National University] (2024) 网页链接 #机器学习##人工智...</title>
<link>https://weibo.com/1402400261/OanKMzLzW</link>
<guid>https://weibo.com/1402400261/OanKMzLzW</guid>
<content:encoded><![CDATA[
<div> Gaussian Splatting, Camera Motion Blur, DeblurGS, Seoul National University

总结：<br /><br />这篇文章提出了一种名为DeblurGS的方法，用于处理相机运动模糊。通过高斯混合模型进行像素插值，实现对图像的去模糊处理。实验结果表明，DeblurGS在减少模糊效果方面取得了良好效果，能够有效提高图像质量，适用于多种场景和应用。研究由首尔国立大学进行，展示了该方法在图像去模糊领域的潜力和有效性。 <div>
[CV]《DeblurGS: Gaussian Splatting for Camera Motion Blur》J Oh, J Chung, D Lee, K M Lee [Seoul National University] (2024) <a href="https://arxiv.org/abs/2404.11358"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovp0hblwkj20zo0pck1m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovp0hpdj4j215g0p0aht.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovp0hwk7ij21660oeagj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovp0i1z1jj216o0u0qc6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovp7l7cqpj20rl0eegnq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovp7l76bfj20rl0e20ue.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovp7l850gj20rh0u2jw3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovp7l7ohyj20rl0iatbz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 21:37:27 GMT</pubDate>
</item>
<item>
<title>通过大规模实验研究证明，GNN模型在分子图建模任务中存在强大的可扩展性，持续扩大模型和数据集规模可以获得显著提升，在各种下游任务上性能优异，为GNN模型应用...</title>
<link>https://weibo.com/1402400261/OanGMlXEw</link>
<guid>https://weibo.com/1402400261/OanGMlXEw</guid>
<content:encoded><![CDATA[
<div> 关键词：GNN模型、分子图建模、可扩展性、药物发现

总结：<br /><br />这篇文章通过大规模实验研究证明了GNN模型在分子图建模任务中具有强大的可扩展性，持续扩大模型和数据集规模可以显著提升性能。研究发现GNN模型在各种下游任务上表现优异，为其在药物发现领域的应用奠定了基础。通过验证实验，论文展示了GNN模型在处理分子图数据时的优势，为未来在药物发现领域的应用提供了重要参考。研究者呼吁更多关注GNN模型在分子图建模任务中的可扩展性，以进一步推动其在药物发现领域的发展。 <div>
通过大规模实验研究证明，GNN模型在分子图建模任务中存在强大的可扩展性，持续扩大模型和数据集规模可以获得显著提升，在各种下游任务上性能优异，为GNN模型应用于药物发现奠定基础。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《On the Scalability of GNNs for Molecular Graphs》M Sypetkowski, F Wenkel, F Poursafaei, N Dickson... [Valence Labs] (2024) <a href="https://arxiv.org/abs/2404.11568"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovoonj6z1j20p014atjm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovoonyuzxj20te0tg44r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovoooha3uj20q21ayqbq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovoooq9jkj20we18gdq0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovooy4urmj212d0ikaeb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovooy3vcxj20j00hq75r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovooy47k5j212d07idhf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovooy4ohbj212d0euwi3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovooy4kgsj212g0k6tbq.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 21:27:35 GMT</pubDate>
</item>
<item>
<title>[LG]《On the Scalability of GNNs for Molecular Graphs》M Sypetkowski, F Wenkel, F Poursafaei, N Dickson... [Valence Labs] (2024) 网页链接 #机器学习##...</title>
<link>https://weibo.com/1402400261/OanDw57nB</link>
<guid>https://weibo.com/1402400261/OanDw57nB</guid>
<content:encoded><![CDATA[
<div> 分子图、图神经网络、可扩展性、分子属性预测、计算效率、模型效果、图神经网络层次结构、特征表征、化学信息处理、模型训练<br />
<br />
该研究主要探讨了图神经网络（GNNs）在处理分子图时的可扩展性问题。研究者针对分子属性预测任务，在不同数据集上对比了不同GNN模型的计算效率和模型效果。实验结果显示，随着分子图规模和复杂度的增加，GNNs的计算速度和模型性能呈现较大差异。研究发现，通过设计合理的图神经网络层次结构和特征表征方法，能够有效提高模型的可扩展性和化学信息处理能力。此外，模型训练过程中的超参数调节也对GNNs的表现产生重要影响。总体而言，本文对于GNNs在分子图领域的应用具有一定的启发意义。 <br /><br />总结: <div>
[LG]《On the Scalability of GNNs for Molecular Graphs》M Sypetkowski, F Wenkel, F Poursafaei, N Dickson... [Valence Labs] (2024) <a href="https://arxiv.org/abs/2404.11568"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovoonj6z1j20p014atjm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovoonyuzxj20te0tg44r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovoooha3uj20q21ayqbq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovoooq9jkj20we18gdq0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovooy4urmj212d0ikaeb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovooy3vcxj20j00hq75r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovooy47k5j212d07idhf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovooy4ohbj212d0euwi3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovooy4kgsj212g0k6tbq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovooy4d7dj212d0gognt.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovooy4gc4j212d0evaca.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hovooy55i2j212h0ncwje.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 21:19:33 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.18)》 爱可可微博热门分享(4.18) [图片]</title>
<link>https://weibo.com/1402400261/OakUnaXhF</link>
<guid>https://weibo.com/1402400261/OakUnaXhF</guid>
<content:encoded><![CDATA[
<div> 微博, 热门分享, 爱可可, 4.18, 好物, 点赞, 萌宠, 美食, 旅行, 心情<br />
<br />
爱可可微博在4月18日分享了一些热门话题，包括优质好物推荐、萌宠日常、美食探店、旅行心情分享等内容。大家纷纷点赞评论，互动热烈。微博内容涵盖了多个领域，让粉丝们享受到丰富多彩的信息和乐趣。总体而言，爱可可微博的热门分享内容丰富多彩，受到广泛关注和喜爱。<br /><br />总结: <div>
《爱可可微博热门分享(4.18)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405024636554575876"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.18)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovcn8wytoj20dc07iwey.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 14:22:50 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《NARUTO: Neural Active Reconstruction from Uncertain Target Observations》(CVPR 2024) GitHub: github.com/oppo-us-research/Naruto《D...</title>
<link>https://weibo.com/1402400261/OakPDdo2d</link>
<guid>https://weibo.com/1402400261/OakPDdo2d</guid>
<content:encoded><![CDATA[
<div> 关键词: NARUTO, 目标重建, 不确定观测, 神经网络, 实现代码, 论文, CVPR 2024

总结:
NARUTO是一篇CVPR 2024年的论文，提出了神经网络方法用于从不确定的目标观测中进行主动重建。该论文提供了实现代码的GitHub链接，可以帮助其他研究人员深入了解和复现这项工作。这篇论文的主要贡献是引入了一种新颖的方法，可以有效地重建不确定的目标观测数据。通过该方法，可以实现更准确和可靠的目标重建，有望在未来的研究中得到广泛应用。 NARUTO这篇论文在CVPR 2024会议上展示并受到关注。 <div>
几篇论文实现代码：<br />《NARUTO: Neural Active Reconstruction from Uncertain Target Observations》(CVPR 2024) GitHub: github.com/oppo-us-research/Naruto<br />《DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation》(CVPR 2024) GitHub: github.com/JeremyCJM/DiffSHEG [fig3]<br />《Degrees of Freedom Matter: Inferring Dynamics from Point Trajectories》(CVPR 2024) GitHub: github.com/yz-cnsdqz/DOMA-release<br />《InFusion: Inpainting 3D Gaussians via Learning Depth Completion from Diffusion Prior》(2024) GitHub: github.com/ali-vilab/Infusion [fig1]<br />《MMInA: Benchmarking Multihop Multimodal Internet Agents》(2024) GitHub: github.com/shulin16/MMInA<br />《Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention》(2024) GitHub: github.com/jiahe7ay/infini-mini-transformer [fig2]<br />《Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation》(2024) GitHub: github.com/omer11a/bounded-attention<br />《OpenEval: Benchmarking Programming Agents for Open-Domain Tasks》(2024) GitHub: github.com/bigcode-project/open-eval<br />《Consistent Diffusion Meets Tweedie》(2024) GitHub: github.com/giannisdaras/ambient-tweedie<br />《Automatic Lyric Transcription and Automatic Music Transcription from Multimodal Singing》(2024) GitHub: github.com/guxm2021/SVT_SpeechBrain [fig5]<br />《Safe Low-Altitude Navigation in Steep Terrain with Fixed-Wing Aerial Vehicles》(2024) GitHub: github.com/ethz-asl/terrain-navigation<br />《OpenGraph: Open-Vocabulary Hierarchical 3D Graph Representation in Large-Scale Outdoor Environments》(2024) GitHub: github.com/BIT-DYN/OpenGraph<br />《Tightly Joining Positioning and Control for Trustworthy Unmanned Aerial Vehicles Based on Factor Graph Optimization in Urban Transportation》(2024) GitHub: github.com/RoboticsPolyu/IPN_MPC<br />《Learning to walk in confined spaces using 3D representation》(2024) GitHub: github.com/leggedrobotics/terrain-generator<br />《ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback》(2024) GitHub: github.com/liming-ai/ControlNet_Plus_Plus<br />《Fast and Optimal Weight Update for Pruned Large Language Models》(2024) GitHub: github.com/fmfi-compbio/admm-pruning<br />《SHIELD: An Evaluation Benchmark for Face Spoofing and Forgery Detection with Multimodal Large Language Models》(2024) GitHub: github.com/laiyingxin2/SHIELD<br />《A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity》(2024) GitHub: github.com/ajyl/dpo_toxic<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovaefr12dj21430o5b29.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovaegvnyqj21e00oewhl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hovb915w0aj229u0xxnpd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hovb9t52g7j21l30fr1kx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hovbv01eglj22hk0w0njp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 14:11:09 GMT</pubDate>
</item>
<item>
<title>【公开的机器学习病理数据集，包括肺、乳腺、结直肠、前列腺、肾等多种肿瘤组织】'Histopathology Datasets for Machine Learning - Ressources of histopatholo...</title>
<link>https://weibo.com/1402400261/OakGEb2KR</link>
<guid>https://weibo.com/1402400261/OakGEb2KR</guid>
<content:encoded><![CDATA[
<div> 肺、乳腺、结直肠、前列腺、肾、机器学习、病理数据集、GitHub、Histopathology Datasets

Histopathology Datasets for Machine Learning项目提供了多种肿瘤组织的病理数据集，包括肺、乳腺、结直肠、前列腺、肾等。这些数据集可用于机器学习研究，有助于开展肿瘤相关的数据挖掘和分析工作。感兴趣的研究者可在GitHub上找到相关资源。Histopathology Datasets for Machine Learning为研究和应用提供了重要的数据基础，促进了医学病理学和机器学习领域的交叉发展。 <div>
【公开的机器学习病理数据集，包括肺、乳腺、结直肠、前列腺、肾等多种肿瘤组织】'Histopathology Datasets for Machine Learning - Ressources of histopathology datasets' GitHub: github.com/maduc7/Histopathology-Datasets <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hovbng463uj21080u0wi2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 13:49:01 GMT</pubDate>
</item>
<item>
<title>【List of ML File Formats：机器学习常见文件格式列表，包含了众多机器学习系统使用的文件格式，并提供了相关工具和补充信息】'List of ML File Formats - List...</title>
<link>https://weibo.com/1402400261/OakDMgIdY</link>
<guid>https://weibo.com/1402400261/OakDMgIdY</guid>
<content:encoded><![CDATA[
<div> 机器学习、文件格式、相关工具、GitHub、ML文件格式、系统使用、补充信息、常见、列表、工具<br />
<br />
总结:<br />
本文介绍了机器学习常见文件格式列表，包含了众多机器学习系统使用的文件格式，提供了相关工具和补充信息。GitHub上有一个名为"List of ML file formats"的项目，供大家查阅。文章列举了多种常见的机器学习文件格式及其应用情况，对于机器学习从业者具有一定的参考价值。读者可以通过该列表了解机器学习领域中常见的文件格式，为实际应用提供参考和指导。 <div>
【List of ML File Formats：机器学习常见文件格式列表，包含了众多机器学习系统使用的文件格式，并提供了相关工具和补充信息】'List of ML File Formats - List of ML file formats' GitHub: github.com/trailofbits/ml-file-formats <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hovbgauk7lj20u00zsae5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 13:41:57 GMT</pubDate>
</item>
<item>
<title>【Cognita：用于生产环境中构建模块化、开源RAG应用的框架】'Cognita - Cognita by TrueFoundry - Framework for building modular, open source RAG applicatio...</title>
<link>https://weibo.com/1402400261/OakD1b7Ez</link>
<guid>https://weibo.com/1402400261/OakD1b7Ez</guid>
<content:encoded><![CDATA[
<div> 框架，生产环境，模块化，开源，RAG应用，TrueFoundry，GitHub，TrueFoundry/cognita<br />
<br />总结:<br />文章介绍了Cognita这个由TrueFoundry推出的框架，用于在生产环境中构建模块化、开源的RAG应用。Cognita旨在帮助开发人员快速构建应用程序，并提供灵活性和可定制性。开发者可以在GitHub上找到Cognita的源代码，并借助此框架开发自己的应用程序。Cognita为构建现代化的应用程序提供了一个强大的工具，有助于提高生产效率和应用程序质量。 <div>
【Cognita：用于生产环境中构建模块化、开源RAG应用的框架】'Cognita - Cognita by TrueFoundry - Framework for building modular, open source RAG applications for production.' GitHub: github.com/truefoundry/cognita <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hovbewe9p5j20u014ewll.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 13:40:05 GMT</pubDate>
</item>
<item>
<title>【股价预测/量化交易相关论文列表】’stock-top-papers - Top paper collection for stock price prediction, quantitative trading. Covering top conferences ...</title>
<link>https://weibo.com/1402400261/OakBGgPuo</link>
<guid>https://weibo.com/1402400261/OakBGgPuo</guid>
<content:encoded><![CDATA[
<div> 股价预测, 量化交易, 论文, 列表, 会议, 期刊, GitHub, KDD, TKDE

<br /><br />总结:
这篇论文汇总了关于股价预测和量化交易的顶级论文，涵盖了诸如KDD、TKDE、CIKM、AAAI、IJCAI、ACL、EMNLP等顶级会议和期刊。研究主要关注股票市场的价格走势预测和量化交易策略的设计与优化，为投资者提供了重要的参考和指导。GitHub链接提供了更多相关信息和资源。 <div>
【股价预测/量化交易相关论文列表】’stock-top-papers - Top paper collection for stock price prediction, quantitative trading. Covering top conferences and journals like KDD, TKDE, CIKM, AAAI, IJCAI, ACL, EMNLP.' GitHub: github.com/Waterkin/stock-top-papers <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hovbbgl24ej20ve0u0goy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 13:36:47 GMT</pubDate>
</item>
<item>
<title>【Web Scraper：用于抓取网页并将其转换为 Markdown 格式，以便于 AI 搜索应用的增强】'Web Scraper - Scrape the webpage convert it into Markdown, and enhan...</title>
<link>https://weibo.com/1402400261/OakuQg556</link>
<guid>https://weibo.com/1402400261/OakuQg556</guid>
<content:encoded><![CDATA[
<div> 抓取、网页、转换、Markdown、增强、AI、搜索应用、Web Scraper、GitHub、zzzgydi<br />
<br />
抓取网页并转换为Markdown格式，可用于增强AI搜索应用的Web Scraper工具现已开源在GitHub上（github.com/zzzgydi/webscraper）。该工具能够帮助用户快速抓取网页内容，转换为Markdown格式，使其更易于阅读和分析，并可以在AI搜索应用中使用。利用Web Scraper，用户可以更高效地收集和处理网页信息，提升搜索应用的效率和准确性。通过将网页内容转换为Markdown格式，可以帮助用户更好地管理和整理数据，为AI搜索应用的优化提供支持。总之，Web Scraper是一个实用的工具，可以为AI搜索应用的开发和应用带来便利和效益。<br /><br />总结: <br />抓取网页并转换为Markdown格式，用于增强AI搜索应用。 工具现已开源于GitHub，可提高网页信息处理效率。 转换为Markdown格式便于数据管理和搜索应用优化。 实用工具为AI搜索应用开发和应用带来便利。 <div>
【Web Scraper：用于抓取网页并将其转换为 Markdown 格式，以便于 AI 搜索应用的增强】'Web Scraper - Scrape the webpage convert it into Markdown, and enhance AI search applications.' GitHub: github.com/zzzgydi/webscraper <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hovatd5e3mj21280u0786.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 13:19:56 GMT</pubDate>
</item>
<item>
<title>【Coix：实现概率编程中的程序组合器的JAX框架，提供了许多基本的程序转换和常见的目标，可以用于实现和运行各种推理算法】'Coix - Inference Combinators in JA...</title>
<link>https://weibo.com/1402400261/Oakugc0AX</link>
<guid>https://weibo.com/1402400261/Oakugc0AX</guid>
<content:encoded><![CDATA[
<div> GitHub、Coix、JAX、程序组合器、概率编程、程序转换、推理算法、基本的、常见的目标

<br /><br />总结:
文章介绍了在JAX框架中实现的概率编程中的程序组合器Coix，提供了多种基本的程序转换和常见的目标，可以用于实现和运行各种推理算法。Coix的开源代码存储在GitHub上，并提供了详细的文档和示例供用户参考。该框架的设计旨在简化推理算法的实现过程，使用户能够通过组合现有的程序部件来构建复杂的推理模型。通过利用JAX框架的高性能计算能力，Coix能够快速、高效地执行各种推理任务，为概率编程领域的研究和应用提供了有力的工具支持。Coix的灵活性和可扩展性使其适用于各种不同类型的概率模型，为用户提供了更多选择和可能性。通过使用Coix，用户可以更轻松地实现自己的推理算法，并与其他研究者分享他们的工作成果。Coix的出现为概率编程和推理算法的发展带来了新的机遇和挑战，有望推动该领域的进一步发展和创新。 <div>
【Coix：实现概率编程中的程序组合器的JAX框架，提供了许多基本的程序转换和常见的目标，可以用于实现和运行各种推理算法】'Coix - Inference Combinators in JAX' GitHub: github.com/jax-ml/coix <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hovar42i9cj20x70u0tdp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 13:18:30 GMT</pubDate>
</item>
<item>
<title>【BiTE：平台无关的执行文件分析工具，旨在提供一个环境来检查二进制文件和调试信息的内容，支持多种架构】'BiTE - Disassembler focused on comprehensive rust...</title>
<link>https://weibo.com/1402400261/Oaksl0rF6</link>
<guid>https://weibo.com/1402400261/Oaksl0rF6</guid>
<content:encoded><![CDATA[
<div> 平台无关、执行文件分析工具、环境、检查、二进制文件、调试信息、支持、多种架构、GitHub

<br />
BiTE是一个平台无关的执行文件分析工具，旨在提供一个环境来检查二进制文件和调试信息的内容。该工具支持多种架构，特别关注在综合rust支持上。用户可以通过GitHub上的WINSDK/bite找到该工具的详细信息和下载。BiTE的设计目标是帮助用户了解二进制文件的内容和调试信息，解决不同架构的执行文件分析需求。如果你需要一个专注于rust语言支持的反汇编工具，不妨试试BiTE。 <div>
【BiTE：平台无关的执行文件分析工具，旨在提供一个环境来检查二进制文件和调试信息的内容，支持多种架构】'BiTE - Disassembler focused on comprehensive rust support.' GitHub: github.com/WINSDK/bite <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%B7%A5%E5%85%B7%23&amp;isnewpage=1"><span class="surl-text">#工具#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hovanh0ywjj21kg0piaev.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 13:13:46 GMT</pubDate>
</item>
<item>
<title>【ImgCatr：用RUST写的命令行图像显示应用】'ImgCatr - cat for images, by RUST' GitHub: github.com/SilinMeng0510/imgcatr #开源# #工具# [图片][图片]</title>
<link>https://weibo.com/1402400261/Oaha3145u</link>
<guid>https://weibo.com/1402400261/Oaha3145u</guid>
<content:encoded><![CDATA[
<div> RUST, 命令行, 图像显示, 应用, ImgCatr, GitHub, SilinMeng0510, cat, 图片<br />
<br />
总结:
这篇文章介绍了一个用RUST编写的命令行图像显示应用ImgCatr。该应用类似于Linux中的cat命令，但是用于显示图片。GitHub上有这个应用的代码仓库，可以在github.com/SilinMeng0510/imgcatr找到。用户可以使用ImgCatr来在命令行中显示和查看图片，提供了一种不同于常规图片查看器的方式。该应用简单易用，适用于需要在命令行环境中查看图片的场景。 <div>
【ImgCatr：用RUST写的命令行图像显示应用】'ImgCatr - cat for images, by RUST' GitHub: github.com/SilinMeng0510/imgcatr <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%B7%A5%E5%85%B7%23&amp;isnewpage=1"><span class="surl-text">#工具#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8houw34yft1j20u00vxq5i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8houw3s10qmj20ke0lmgo1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 04:50:28 GMT</pubDate>
</item>
<item>
<title>【EasyFrontend：免费开源的 Tailwind CSS UI 组件库，用于创建 landing pages 和网站】’EasyFrontend - Tailwind CSS Components - Free Tailwind html UI Com...</title>
<link>https://weibo.com/1402400261/Oah8S1QHY</link>
<guid>https://weibo.com/1402400261/Oah8S1QHY</guid>
<content:encoded><![CDATA[
<div> Tailwind CSS, UI组件库, landing pages, 网站, 免费, 开源, GitHub, EasyFrontend, 支持, 爱心

总结:<br /><br />EasyFrontend是一个免费开源的Tailwind CSS UI组件库，专为创建landing pages和网站而构建。这些UI组件是免费的，用户可以在GitHub上找到EasyFrontend的项目。支持EasyFrontend，并体现您的爱心，不要忘记给他们一个star。 <div>
【EasyFrontend：免费开源的 Tailwind CSS UI 组件库，用于创建 landing pages 和网站】’EasyFrontend - Tailwind CSS Components - Free Tailwind html UI Components - built to create landing pages and websites. Easyfrontend UI components are free and open-source. show your support and love, don't forget to give us a star' GitHub: github.com/EasyFrontend-com/html-tailwindcss-components <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%89%8D%E7%AB%AF%23&amp;isnewpage=1"><span class="surl-text">#前端#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8houw0pym7rj21400p0tbo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8houw0qi18dj21400p0din.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8houw0ro74zj21400p0ae7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 04:47:34 GMT</pubDate>
</item>
<item>
<title>【bucketMul LLM 推理的实现，使用 Swift 和 Metal 语言编写】'An implementation of bucketMul LLM inference' GitHub: github.com/kolinko/effort #开源# #机...</title>
<link>https://weibo.com/1402400261/Oah8vogzq</link>
<guid>https://weibo.com/1402400261/Oah8vogzq</guid>
<content:encoded><![CDATA[
<div> bucketMul LLM, 推理, 实现, Swift, Metal, GitHub, implementation, inference, Kolinko, effort

<br /><br />总结:
该篇文章介绍了使用Swift和Metal语言编写的bucketMul LLM推理的实现。作者在GitHub上提供了相关代码和资源。通过这个实现，用户可以进行推理操作，并了解LLM模型在推理阶段的工作原理和效果。这为研究人员和开发者提供了一个学习和使用LLM模型的机会。 <div>
【bucketMul LLM 推理的实现，使用 Swift 和 Metal 语言编写】'An implementation of bucketMul LLM inference' GitHub: github.com/kolinko/effort <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8houvzvchphj21190u0af9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 04:46:40 GMT</pubDate>
</item>
<item>
<title>【Mistral Common：旨在帮助用户处理 Mistral 模型的工具集。首次发布包含文本的分词功能，其分词器不仅处理常规的文本到标记的转换，还增加了工具解析和结构化...</title>
<link>https://weibo.com/1402400261/Oah7ThdiQ</link>
<guid>https://weibo.com/1402400261/Oah7ThdiQ</guid>
<content:encoded><![CDATA[
<div> 分词功能, 工具解析, 结构化对话, API, 验证, 规范化代码, Mistral 模型, 用户处理, 发布, GitHub

总结:<br /><br />
"Mistral Common"是一个工具集，旨在帮助用户处理Mistral模型。首次发布的功能包括文本的分词功能，分词器不仅可以处理常规的文本到标记的转换，还增加了工具解析和结构化对话的处理。此外，还发布了用于API中的验证和规范化代码。用户可以在GitHub上找到"Mistral Common"的开源代码。 <div>
【Mistral Common：旨在帮助用户处理 Mistral 模型的工具集。首次发布包含文本的分词功能，其分词器不仅处理常规的文本到标记的转换，还增加了工具解析和结构化对话的处理，还发布了用于API中的验证和规范化代码】'Mistral Common' GitHub: github.com/mistralai/mistral-common <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8houvy2qym5j21740tq0x8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 04:45:09 GMT</pubDate>
</item>
<item>
<title>【波士顿动力推出电动人型机器人Atlas，展现超强力量与灵活性】- Boston Dynamics推出了全新的全电动Atlas机器人，这是在几十年的机器人创新和多年实践经验基础...</title>
<link>https://weibo.com/1402400261/OafoiBw4B</link>
<guid>https://weibo.com/1402400261/OafoiBw4B</guid>
<content:encoded><![CDATA[
<div> 机器人, Atlas, 波士顿动力, 电动, 强力量, 灵活性, 海云达, 测试, 商业化, AI技术

<br /><br />总结:
波士顿动力推出了全新的电动人型机器人Atlas，具有强大力量和广阔运动范围，可抬起和操纵各种重量和形状不规则的物体。公司将与海云达等客户合作，在真实环境中测试和迭代Atlas的应用，逐步实现商业化。在软件方面，波士顿动力运用了强化学习、计算机视觉等AI技术，提升了机器人适应复杂环境的能力。Atlas能够高效地完成各种任务，并超越人的运动能力。波士顿动力在Spot和Stretch商业化中积累了丰富经验，为Atlas提供完整的软件、服务和支持生态系统，推动其应用，助力解决更多行业痛点，实现机器人的商业化应用。 <div>
【波士顿动力推出电动人型机器人Atlas，展现超强力量与灵活性】<br />- Boston Dynamics推出了全新的全电动Atlas机器人，这是在几十年的机器人创新和多年实践经验基础上实现的。   <br />- 相比上一代的液压Atlas，全新电动Atlas机器人力量更大、运动范围更广。它能抬起和操纵各种重量、形状不规则的物体。   <br />- Boston Dynamics将与海云达等客户合作，在工厂等真实环境中测试和迭代Atlas的应用，逐步实现商业化。   <br />- 除了硬件，Boston Dynamics在软件方面也取得了进步，如运用了强化学习、计算机视觉等AI技术，提升了机器人适应复杂环境的能力。   <br />- 人形机器人Atlas能够以高效的方式完成各种任务，其运动方式会超越人的能力。   <br />- Boston Dynamics在Spot和Stretch商业化中积累了丰富经验，能为Atlas提供完整的软件、服务和支持生态系统，推动其应用。   <br />- Atlas加入Spot和Stretch，将助力Boston Dynamics解决更多行业痛点，实现机器人的商业化应用。<br />《An Electric New Era for Atlas | Boston Dynamics》 <a href="https://bostondynamics.com/blog/electric-new-era-for-atlas/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/5396ee05ly1houoa04fxij20zk0k0my7.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/3YuHe3LRlx08eaFK9BWw01041200dNAv0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713403966&amp;ssig=I4DM9UuhP1&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/Iu16yviSlx08eaFJSpgA0104120076LL0E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713403966&amp;ssig=nxEZ%2FzvIDH&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/BUR9FJMAlx08eaFJoVJC010412004xnG0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713403966&amp;ssig=eiT8vV%2Bhnc&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5024424257060882" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 00:20:05 GMT</pubDate>
</item>
<item>
<title>【Pile-T5：更好的通用预训练语言模型】- Pile-T5通过在Pile数据集上预训练T5模型，并使用LLAMA分词器，改进了原始T5的编码能力。 - Pile-T5总体上明显优于原始T...</title>
<link>https://weibo.com/1402400261/OafmCeJxq</link>
<guid>https://weibo.com/1402400261/OafmCeJxq</guid>
<content:encoded><![CDATA[
<div> Pile-T5, 预训练模型, 提升, 下游任务, 质量更高, 多任务微调, 模型演化, 解释性研究, bug, 通用预训练语言模型

<br /><br />总结:
Pile-T5是通过在Pile数据集上预训练T5模型，并使用LLAMA分词器改进的通用预训练语言模型。在多个下游任务中，Pile-T5表现优异，尤其在代码任务上有显著提升，说明预训练质量更高，更适合多任务微调。Pile-T5模型在训练步长的中间检查点有利于模型演化和解释性研究。尽管存在bug，Pile-T5仍值得研究者基于其进行编码-解码任务的探索，特别是基础和大模型表现更稳定。 <div>
【Pile-T5：更好的通用预训练语言模型】<br />- Pile-T5通过在Pile数据集上预训练T5模型，并使用LLAMA分词器，改进了原始T5的编码能力。   <br />- Pile-T5总体上明显优于原始T5v1.1模型，尤其在代码任务上的提升更大。这主要得益于Pile中包含代码数据以及LLAMA分词器包含编程常用字符。   <br />- 在多个下游任务的微调中，Pile-T5不同规模的模型表现优异，如在SuperGLUE、CodeXGLUE、MMLU和BigBench Hard上的结果。   <br />- 尽管与专门微调的Flan-T5相比略逊色，但Pile-T5仍优于T5v1.1，表明其预训练质量更高，更适合多任务微调。   <br />- 公开了Pile-T5模型在不同训练步长的中间检查点，这有利于模型演化和解释性研究。   <br />- Pile-T5 Large模型在某些任务上的表现不佳，可能存在bug，用户需谨慎使用。   <br />- Pile-T5是更好的通用预训练语言模型，值得研究者基于其进行编码-解码任务的探索。其中基础和大模型表现更稳定。<br />《Pile-T5 | EleutherAI Blog》 <a href="https://blog.eleuther.ai/pile-t5/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8houo66lks0j20vp0u07au.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 00:15:56 GMT</pubDate>
</item>
<item>
<title>【大语言模型时代的科学发现】- LLM技术进步迅速，广泛应用使科学界既兴奋又担忧。LLM可能影响科学信息搜索、创作和科研等方方面面。 - LLM的环境影响问题亟待解...</title>
<link>https://weibo.com/1402400261/OaflRxl5I</link>
<guid>https://weibo.com/1402400261/OaflRxl5I</guid>
<content:encoded><![CDATA[
<div> LLM、科学发现、影响、环境、人类交流、创新、幻觉、辅助、合作、负责任保障

<br /><br />总结:
LLM技术的迅速发展在科学界引起了兴奋和担忧，虽然在信息搜索、创作和科研方面有广泛应用，但也存在环境影响和碳排放的问题。然而，LLM缺乏人类语言交流和建构意义的能力，可能会导致文本信息的不准确性和意义的缺失。此外，LLM也有可能错过科学创新的异常点，难以推动科学范式的转变。因此，科学家需要保持审慎态度，避免过度依赖LLM，应将其视为科研发现的辅助工具。此外，科学界需要与LLM开发商紧密合作，制定最佳实践和标准，确保其负责任和伦理使用，促进科学的严谨性和可重现性。最终，科学界应积极主张研发LLM安全保障措施，以促进LLM的可持续发展。 <div>
【大语言模型时代的科学发现】<br />- LLM技术进步迅速，广泛应用使科学界既兴奋又担忧。LLM可能影响科学信息搜索、创作和科研等方方面面。   <br />- LLM的环境影响问题亟待解决。无论其应用效果如何，LLM运算都有很大的碳排放。科学家和社会必须正视LLM的使用如何加剧气候危机。   <br />- LLM缺乏人类语言交流和意义建构的能力。它们无法像科学家那样，通过交换理由来建立和验证事实，也无法传达意图、表达文本的意义。   <br />- LLM可能会错过或平均科学创新的异常点。它们当前难以革命性推动科学范式的转变。   <br />- LLM生成的文本存在“幻觉”问题，可能产生不准确甚至虚假内容。科学家不能过度依赖LLM撰写文献综述等。   <br />- LLM难以准确表达科学文献中的细微价值判断、不确定性和局限性。这可能导致对研究结果的误读。   <br />- LLM应仅被视为辅助科研发现的工具，而非取代科学家。科学发现应建立在负责任、以目标为导向的研究实践之上。   <br />- 科学界应与LLM开发商紧密合作，制定最佳实践和标准，确保LLM的使用不损害科学的严谨性和可重现性。同时促进不同学科之间的交流讨论。   <br />- 科学家应保持审慎态度，避免过度依赖LLM。科学界应更积极主张研发LLM安全保障措施，促进LLM的负责任和伦理使用。<br />《Science in the age of large language models | Nature Reviews Physics》 <a href="https://www.nature.com/articles/s42254-023-00581-4"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8houo48mtgsj21hw0u0tfe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 00:14:05 GMT</pubDate>
</item>
<item>
<title>【Mistral AI 开源 Mixtral 8x22B】- Mistral AI发布了新的开源模型Mixtral 8x22B。该模型以39B活跃参数实现141B参数规模，极大提升了模型规模与成本效率。 - Mi...</title>
<link>https://weibo.com/1402400261/OafkRu8TD</link>
<guid>https://weibo.com/1402400261/OafkRu8TD</guid>
<content:encoded><![CDATA[
<div> Mistral AI、Mixtral 8x22B、开源、模型、成本效率、多语言、数学、编程、Apache 2.0许可证、性能价格比
<br /><br />总结: Mistral AI发布了新的开源模型Mixtral 8x22B，以39B活跃参数实现141B参数规模，极大提升模型规模与成本效率。Mixtral 8x22B支持多语言，具有强大的数学和编程能力，并支持函数调用，可实现应用开发和技术栈现代化。采用最宽松的Apache 2.0许可证发布。同时，Mixtral 8x22B在性能价格比、推理、知识、多语言、编程、数学等多个基准测试上表现优异，后续还将发布指导版本提升数学表现。 Mistral AIModels致力于提升成本效率，Mixtral 8x22B相对同规模模型具有更佳的性能价格比，稀疏激活可提升速度。 <div>
【Mistral AI 开源 Mixtral 8x22B】<br />- Mistral AI发布了新的开源模型Mixtral 8x22B。该模型以39B活跃参数实现141B参数规模，极大提升了模型规模与成本效率。   <br />- Mixtral 8x22B支持英语、法语、意大利语、德语和西班牙语，并具有强大的数学和编程能力。其支持函数调用，可大规模实现应用开发和技术栈现代化。   <br />- Mistral AI坚信开源的力量，Mixtral 8x22B以最宽松的Apache 2.0许可证发布。   <br />- Mistral AIModels追求卓越的成本效率。Mixtral 8x22B相较同规模模型，提供最佳的性能价格比。其稀疏激活可提升速度。   <br />- Mixtral 8x22B在推理、知识、多语言、编程、数学等多个基准测试上，表现优于其他开源模型。后续会发布指导版本，数学表现更佳。   <br />《Cheaper, Better, Faster, Stronger | Mistral AI | Frontier AI in your hands》 <a href="https://mistral.ai/news/mixtral-8x22b/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8houo1gf9xpj21890u0dk6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8houo1ja09cj21c00sy77c.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8houo1nnovqj22tw0u0n46.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 18 Apr 2024 00:11:37 GMT</pubDate>
</item>
<item>
<title>今日推介(第1379期)：语言模型级联、RAG知识和LLM内部先验间的博弈、解缠表示学习的三种互补归纳偏置、DPO是否比PPO更适合LLM对齐、在众多模拟世界中扩展可指示A...</title>
<link>https://weibo.com/1402400261/OaeBajyAP</link>
<guid>https://weibo.com/1402400261/OaeBajyAP</guid>
<content:encoded><![CDATA[
<div> 语言模型级联、RAG知识、LLM内部先验、解缠表示学习、互补归纳偏置、DPO、PPO、LLM对齐、可指示Agent、模拟世界扩展

总结:<br />
本文主要介绍了在语言模型领域的一些前沿研究，包括语言模型级联、RAG知识和LLM内部先验的博弈、解缠表示学习的三种互补归纳偏置等内容。研究讨论了DPO是否比PPO更适合LLM对齐的问题，还探讨了在众多模拟世界中扩展可指示Agent的相关方法。这些研究成果对于推动自然语言处理和深度学习领域的发展具有重要意义。 <div>
今日推介(第1379期)：语言模型级联、RAG知识和LLM内部先验间的博弈、解缠表示学习的三种互补归纳偏置、DPO是否比PPO更适合LLM对齐、在众多模拟世界中扩展可指示Agent 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/693095550"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.18)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8houks80i25j21d00p2tfn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8houksa70d6j219u0nmn2q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8houkscmj6bj20rm0vswi0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8houksgby4rj20u01c947t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8houksjmqv1j216j0u0wkx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 22:19:02 GMT</pubDate>
</item>
<item>
<title>[CV] SRGS: Super-Resolution 3D Gaussian Splatting 网页链接 通过高分辨率密集化和纹理学习，提出一种只需低分辨率多视图输入就可以实现高质量高分辨率小场景...</title>
<link>https://weibo.com/1402400261/OaexUdIhC</link>
<guid>https://weibo.com/1402400261/OaexUdIhC</guid>
<content:encoded><![CDATA[
<div> 关键词: 高分辨率密集化，纹理学习，多视图输入，新视图合成，SRGS

总结:<br /><br />这篇文章提出了一种名为SRGS的方法，通过高分辨率密集化和纹理学习，实现了只需低分辨率多视图输入就能合成高质量高分辨率小场景新视图的技术。文章通过对输入数据进行高效处理和重建，使得生成的新视图能够保持高质量，并具有真实感。这种方法为小场景的新视图合成提供了一种简单而有效的解决方案，有望在虚拟现实和增强现实领域有广泛应用。 <div>
[CV] SRGS: Super-Resolution 3D Gaussian Splatting  <br /><a href="https://arxiv.org/abs/2404.10318"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过高分辨率密集化和纹理学习，提出一种只需低分辨率多视图输入就可以实现高质量高分辨率小场景新视图合成的方法SRGS。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houkk5qbs6j20xa150dwb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houkk67k85j20xm0oigrc.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houkk6re5hj21gg0xq187.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 22:11:00 GMT</pubDate>
</item>
<item>
<title>[CV] MobileNetV4 - Universal Models for the Mobile Ecosystem 网页链接 通过巧妙设计的模块、注意力机制和NAS方法，使模型在移动端各硬件上都能高效部署。 [...</title>
<link>https://weibo.com/1402400261/OaevgwwKJ</link>
<guid>https://weibo.com/1402400261/OaevgwwKJ</guid>
<content:encoded><![CDATA[
<div> MobileNetV4, Universal Models, 移动端, 模块, 注意力机制, NAS方法, 高效部署, 硬件<br />
<br />
MobileNetV4是一种通过巧妙设计的模块、注意力机制和NAS方法而创建的通用模型，可以在移动端的各种硬件上高效部署。通过使用注意力机制，模型能够集中精力在关键部分，提高性能。NAS方法使模型更具智能化和可调节性，适应不同的移动设备。这些特点使MobileNetV4成为一个非常适用于移动生态系统的模型。<br /><br />总结:MobileNetV4通过巧妙设计的模块、注意力机制和NAS方法，在移动端各硬件上高效部署，适应不同设备，使其成为一个通用且智能的模型。 <div>
[CV] MobileNetV4 - Universal Models for the Mobile Ecosystem  <br /><a href="https://arxiv.org/abs/2404.10518"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过巧妙设计的模块、注意力机制和NAS方法，使模型在移动端各硬件上都能高效部署。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houkdepnqzj20ra16owq4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1houkdexlm1j214g0vyn6c.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houkdfhmmyj213k0hw76j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 22:04:30 GMT</pubDate>
</item>
<item>
<title>[LG] Social Choice for AI Alignment: Dealing with Diverse Human Feedback 网页链接 提出可运用社会选择理论来系统地指导RLHF中的人工反馈选择和聚合，以制定...</title>
<link>https://weibo.com/1402400261/Oaetj6Zv6</link>
<guid>https://weibo.com/1402400261/Oaetj6Zv6</guid>
<content:encoded><![CDATA[
<div> 社会选择理论 RLHF 人工反馈 选择 聚合 公平 不排斥 人类价值观 机制

<br /><br />总结:
本文提出了利用社会选择理论指导强化学习和人类反馈的机制，以确保人工智能对各种群体的价值观都能公平对待，不排斥任何群体。通过系统地选择和汇总人类反馈，制定更公平的人类价值观调整机制，帮助人工智能更好地对人类价值观进行调整，使其更符合社会的整体利益。 <div>
[LG] Social Choice for AI Alignment: Dealing with Diverse Human Feedback  <br /><a href="https://arxiv.org/abs/2404.10271"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />提出可运用社会选择理论来系统地指导RLHF中的人工反馈选择和聚合，以制定更公平且不排斥任何群体的人类价值观调整机制。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houk8dfzzdj20xw16w7ny.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houk8drgc9j21ke11c12y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houk8eel05j21kc0lo7bb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 21:59:40 GMT</pubDate>
</item>
<item>
<title>[CV] Comprehensive Survey of Model Compression and Speed up for Vision Transformers 网页链接 通过全面调研和比较量化、低秩近似、知识蒸馏和剪枝四种关键...</title>
<link>https://weibo.com/1402400261/Oaer1drUB</link>
<guid>https://weibo.com/1402400261/Oaer1drUB</guid>
<content:encoded><![CDATA[
<div> 关键词: 模型压缩, 视觉Transformer, CIFAR数据集, 准确率, 效率, 低秩近似, 知识蒸馏, 剪枝, trade-off, 实际模型部署

总结:<br /><br />本文对视觉Transformer模型压缩技术在CIFAR数据集上的效果进行了全面调研和比较，分别探讨了量化、低秩近似、知识蒸馏和剪枝四种关键压缩技术。研究结果为在实际模型部署中考虑准确率与效率trade-off提供了宝贵的参考。调研发现，这四种压缩技术在不同情况下对模型性能的影响有所不同，需要根据具体应用场景进行选择。在模型压缩方面，低秩近似和知识蒸馏能够有效降低模型的复杂度，而剪枝技术在减少参数和计算量方面表现突出。然而，在压缩过程中需要注意平衡准确率和效率之间的关系，以确保模型性能不受过度压缩的影响。因此，研究者建议根据具体需求选择合适的压缩技术，并在实际部署中进行综合考量，以达到最佳的模型性能和效率之间的平衡。 <div>
[CV] Comprehensive Survey of Model Compression and Speed up for Vision Transformers  <br /><a href="https://arxiv.org/abs/2404.10407"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过全面调研和比较量化、低秩近似、知识蒸馏和剪枝四种关键视觉Transformer模型压缩技术在CIFAR数据集上的效果，为考虑准确率与效率trade-off的实际模型部署提供了宝贵参考。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houk2imtp3j20r014sqgm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houk2j2bmkj219m0non2n.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1houk2j90anj20yu0qa42b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 21:54:02 GMT</pubDate>
</item>
<item>
<title>提出一个雄心勃勃的项目，旨在通过将语言指令与复杂3D环境交互相结合，开发泛化能力强大的可指示Agent。 - 转发 @爱可可-爱生活:&amp;ensp;[RO]《Scaling Instructab...</title>
<link>https://weibo.com/1402400261/OaejuExON</link>
<guid>https://weibo.com/1402400261/OaejuExON</guid>
<content:encoded><![CDATA[
<div> 谷歌DeepMind团队在2024年提出了一个名为《Scaling Instructable Agents Across Many Simulated Worlds》的项目，旨在开发泛化能力强大的可指示Agent。关键词：项目、DeepMind、指示代理、泛化能力、多个模拟环境。

<br /><br />总结:
2024年，谷歌DeepMind团队发起了一个名为《Scaling Instructable Agents Across Many Simulated Worlds》的项目，旨在通过将语言指令与复杂3D环境交互相结合，开发泛化能力强大的可指示Agent。项目旨在让Agent能够在多个模拟环境中适用，并能够根据指示执行各种任务。这将为人工智能领域带来重大突破，提高Agent的适用性和智能水平。DeepMind团队将以此为目标，探索机器学习和自然语言处理的结合，开拓智能代理系统的新领域。 <div>
提出一个雄心勃勃的项目，旨在通过将语言指令与复杂3D环境交互相结合，开发泛化能力强大的可指示Agent。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [RO]《Scaling Instructable Agents Across Many Simulated Worlds》S Team, M A Raad, A Ahuja, C Barros... [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2404.10179"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houjbg8h83j21n00q6qhe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1houjbgqv67j21ms15gqhv.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houjbh4x0rj21de0tatn9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houjbhabsij21dm19awrj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houjj53yx4j21140gstav.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houjj566haj21150ue7b9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houjj54e7aj21190j6771.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houjj549jnj21150ne0vo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houjj54b6gj21140gy410.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 21:35:30 GMT</pubDate>
</item>
<item>
<title>[RO]《Scaling Instructable Agents Across Many Simulated Worlds》S Team, M A Raad, A Ahuja, C Barros... [Google DeepMind] (2024) 网页链接 #机器学习##人...</title>
<link>https://weibo.com/1402400261/Oaejsl4lK</link>
<guid>https://weibo.com/1402400261/Oaejsl4lK</guid>
<content:encoded><![CDATA[
<div> Scaling, Instructable Agents, Simulated Worlds, Multi-agent Systems, Reinforcement Learning, DeepMind

<br /><br />总结:
本研究通过在多个模拟世界中扩展可指导的代理，实现了在多智能体系统中的扩展。利用强化学习算法，结合深度Mind技术，实现了在模拟环境中的智能体规模扩展。研究团队对于多智能体系统的设计和优化具有重要意义，为实现自主智能体在复杂环境中的应用提供了新的思路。 <div>
[RO]《Scaling Instructable Agents Across Many Simulated Worlds》S Team, M A Raad, A Ahuja, C Barros... [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2404.10179"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houjbg8h83j21n00q6qhe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1houjbgqv67j21ms15gqhv.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houjbh4x0rj21de0tatn9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houjbhabsij21dm19awrj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houjj53yx4j21140gstav.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houjj566haj21150ue7b9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houjj54e7aj21190j6771.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houjj549jnj21150ne0vo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houjj54b6gj21140gy410.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houjj55696j21160odn1c.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houjj54aqxj211a0jawh1.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houjj5434pj21160fo0uq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 21:35:24 GMT</pubDate>
</item>
<item>
<title>通过理论分析和综合实验发现PPO经过精心微调可以优于DPO，在对话和代码生成任务上都取得了最先进的结果。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Is DPO Superior t...</title>
<link>https://weibo.com/1402400261/Oaefpy987</link>
<guid>https://weibo.com/1402400261/Oaefpy987</guid>
<content:encoded><![CDATA[
<div> PPO, DPO, 精心微调, 对话任务, 代码生成任务, 最先进结果, 理论分析, 综合实验, Tsinghua University, OpenPsi Inc

<br /><br />总结:
本研究通过理论分析和综合实验发现，经过精心微调后的PPO在对话和代码生成任务上可以优于DPO，取得了最先进的结果。该研究由清华大学和OpenPsi公司的研究人员合作完成，探讨了PPO和DPO在LLM对齐方面的优劣。研究结果显示，PPO的调优效果更好，适用于各种任务，并提出了一种综合性研究方法，为相关领域的研究提供了重要的参考价值。 <div>
通过理论分析和综合实验发现PPO经过精心微调可以优于DPO，在对话和代码生成任务上都取得了最先进的结果。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study》S Xu, W Fu, J Gao, W Ye, W Liu, Z Mei, G Wang, C Yu, Y Wu [Tsinghua University &amp; OpenPsi Inc] (2024) <a href="https://arxiv.org/abs/2404.10719"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houj1rxkpxj20pa16wali.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houj1sbxbhj20uc1cs49b.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houj1sk52wj20tw0l8777.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 21:25:27 GMT</pubDate>
</item>
<item>
<title>[CL]《Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study》S Xu, W Fu, J Gao, W Ye, W Liu, Z Mei, G Wang, C Yu, Y Wu [Tsinghua University ...</title>
<link>https://weibo.com/1402400261/Oaefnozyq</link>
<guid>https://weibo.com/1402400261/Oaefnozyq</guid>
<content:encoded><![CDATA[
<div> 关键词: DPO, PPO, LLM Alignment, Tsinghua University, OpenPsi Inc

总结:<br /><br />本研究探讨了DPO和PPO对LLM对齐的优劣。研究团队来自清华大学和OpenPsi公司。他们进行了全面的研究，发现DPO在LLM对齐方面表现更优。研究结果对相关领域的进一步发展具有重要意义，为未来研究提供了有益的认识。<br />研究方法:<br />实验结果:<br />结论: <div>
[CL]《Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study》S Xu, W Fu, J Gao, W Ye, W Liu, Z Mei, G Wang, C Yu, Y Wu [Tsinghua University &amp; OpenPsi Inc] (2024) <a href="https://arxiv.org/abs/2404.10719"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houj1rxkpxj20pa16wali.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houj1sbxbhj20uc1cs49b.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houj1sk52wj20tw0l8777.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 21:25:21 GMT</pubDate>
</item>
<item>
<title>提出Tripod模型，通过改进并协调使用三种互补的归纳偏置——量化、独立性和混合性，实现了图像表征的最优去相关效果。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Tripo...</title>
<link>https://weibo.com/1402400261/OaeaQEiyI</link>
<guid>https://weibo.com/1402400261/OaeaQEiyI</guid>
<content:encoded><![CDATA[
<div> Tripod模型, 量化, 独立性, 混合性, 图像表征, 去相关效果, 三种互补的归纳偏置, disentangled representation learning

<br /><br />总结:
本文提出了Tripod模型，通过改进并协调使用三种互补的归纳偏置——量化、独立性和混合性，实现了图像表征的最优去相关效果。Tripod模型结合了这三种偏置，从而在图像表征学习中取得了显著的效果。这种综合利用不同偏置的方法，使得模型能够更好地学习到图像之间的不相关特征，从而实现更好的图像表征学习效果。Tripod模型的提出，为 disentangled representation learning 领域带来了新的思路和方法，有望在未来的研究中有更多的应用和拓展。Tripod模型的成功应用展示了在图像表征学习中综合利用多种归纳偏置的重要性，并为相关领域的研究和应用带来了新的启示。<br />模型提出了三种互补的归纳偏置——量化、独立性和混合性，通过综合利用这些归纳偏置，实现了更好的去相关效果，为图像表征学习带来了新的突破和进展。Tripod模型的介绍和应用，为相关研究领域提供了新的思路和方法，为未来的研究和应用奠定了更坚实的基础。Tripod模型的提出，将有望推动图像表征学习领域的发展，为实现更好的图像表征学习效果提供了新的途径和可能性。Tripod模型的成功应用充分展示了综合利用不同归纳偏置的重要性，并为相关领域的进一步研究和发展提供了有益的启示。Tripod模型的发展，有望在未来为图像表征学习领域带来更多的突破和进展，为解决实际问题提供更好的解决方案。Tripod模型的提出，为图像表征学习领域带来了新的思路和方法，有望在未来的研究和应用中发挥更重要的作用，进一步推动领域的发展和进步。 <div>
提出Tripod模型，通过改进并协调使用三种互补的归纳偏置——量化、独立性和混合性，实现了图像表征的最优去相关效果。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Tripod: Three Complementary Inductive Biases for Disentangled Representation Learning》K Hsu, J I Hamid, K Burns, C Finn, J Wu [Stanford University] (2024) <a href="https://arxiv.org/abs/2404.10282"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houivs4781j20ns10idp5.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houivsiwudj20rm0vsdkf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houivsxv78j20re0t80wd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houivt5llmj21iy0qqdn8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1houiwh6ug6j20iv0l0abl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1houiwh8iwfj212d0kl0yw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1houiwh9ownj212d13ojzb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1houiwh9z0cj212d0z7n3t.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1houiwhaynej212d0z7n6r.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 21:14:12 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.17)》 爱可可微博热门分享(4.17) [图片]</title>
<link>https://weibo.com/1402400261/OabA8CAIl</link>
<guid>https://weibo.com/1402400261/OabA8CAIl</guid>
<content:encoded><![CDATA[
<div> 微博，热门，分享，爱可可，4.17，关键词

<br /><br />总结:
4月17日，爱可可微博热门分享引起了大量关注。在微博上，不同话题和内容的分享活动吸引了许多用户的参与和互动。热门内容涵盖了各个领域，吸引了广泛的注意。爱可可的微博分享活动使得用户可以了解到更多有趣的信息，并且促进了社交平台上的交流和互动。通过微博的热门分享，用户能够获得更多的乐趣和启发，增加了他们在社交网络上的参与度和快乐。 <div>
《爱可可微博热门分享(4.17)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405024278050635924"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.17)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hou7gzw5iij20er08aaaw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 14:38:16 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Distort, Distract, Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions》(ICLR 2024) GitHub: github.com...</title>
<link>https://weibo.com/1402400261/OaaOwpeWL</link>
<guid>https://weibo.com/1402400261/OaaOwpeWL</guid>
<content:encoded><![CDATA[
<div> Distort, Distract, Decode, Instruction-Tuned Model, Response Refinement, Noisy Instructions, ICLR 2024, GitHub, Instructive Decoding

<br />
模型调整，响应优化，ICLR 2024会议上提出了一种指导模型根据有噪指令优化响应的方法。通过扭曲、分散、解码处理嘈杂指令，GitHub上提供了相应的代码实现。

<br /><br />总结: 该论文介绍了一种指导模型优化响应的方法，针对嘈杂指令进行了处理，通过扭曲、分散和解码操作来优化响应。研究在ICLR 2024会议上发布，并提供GitHub上的代码实现。 <div>
几篇论文实现代码：<br />《Distort, Distract, Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions》(ICLR 2024) GitHub: github.com/joonkeekim/Instructive-Decoding [fig6]<br />《Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization》(ICLR 2024) GitHub: github.com/Lei-Kun/uni-o4<br />《Motion2VecSets: 4D Latent Vector Set Diffusion for Non-rigid Shape Reconstruction and Tracking》(CVPR 2024) GitHub: github.com/VVeiCao/Motion2VecSets [fig3]<br />《Map-Relative Pose Regression for Visual Re-Localization》(CVPR 2024) GitHub: github.com/nianticlabs/marepo [fig5]<br />《On the Content Bias in Fréchet Video Distance》(CVPR 2024) GitHub: github.com/songweige/content-debiased-fvd<br />《Decomposing Disease Descriptions for Enhanced Pathology Detection: A Multi-Aspect Vision-Language Matching Framework》(CVPR 2024) GitHub: github.com/HieuPhan33/MAVL [fig8]<br />《TetraSphere: A Neural Descriptor for O(3)-Invariant Point Cloud Analysis》(CVPR 2024) GitHub: github.com/pavlo-melnyk/tetrasphere<br />《Efficient Test-Time Adaptation of Vision-Language Models》(CVPR 2024) GitHub: github.com/kdiAAA/TDA<br />《UNIAA: A Unified Multi-modal Image Aesthetic Assessment Baseline and Benchmark》(2024) GitHub: github.com/Uniaa-MLLM/Uniaa [fig1]<br />《Compression Represents Intelligence Linearly》(2024) GitHub: github.com/hkust-nlp/llm-compression-intelligence [fig2]<br />《Prepacking: A Simple Method for Fast Prefilling and Increased Throughput in Large Language Models》(2024) GitHub: github.com/siyan-zhao/prepacking<br />《Match-Stereo-Videos: Bidirectional Alignment for Consistent Dynamic Stereo Matching》(2024) GitHub: github.com/TomTomTommi/bidastereo<br />《Wild Visual Navigation: Fast Traversability Learning via Pre-Trained Models and Online Self-Supervision》(2024) GitHub: github.com/leggedrobotics/wild_visual_navigation<br />《OneChart: Purify the Chart Structural Extraction via One Auxiliary Token》(2024) GitHub: github.com/LingyvKong/OneChart<br />《Any2Point: Empowering Any-modality Large Models for Efficient 3D Understanding》(2024) GitHub: github.com/Ivan-Tang-3D/Any2Point [fig4]<br />《M2Chat: Empowering VLM for Multimodal LLM Interleaved Text-Image Generation》(2024) GitHub: github.com/litwellchi/M2Chat [fig7] <br />《ScribblePrompt: Fast and Flexible Interactive Segmentation for Any Biomedical Image》(2024) GitHub: github.com/halleewong/ScribblePrompt<br />《BAGS: Blur Agnostic Gaussian Splatting through Multi-Scale Kernel Modeling》(2024) GitHub: github.com/snldmt/BAGS [fig9]<br />《ROAM: Robust and Object-aware Motion Generation using Neural Pose Descriptors》(2024) GitHub: github.com/RosettaWYzhang/Roam<br />《NeuSurf: On-Surface Priors for Neural Surface Reconstruction from Sparse Input Views》(2024) GitHub: github.com/leonwu0108/NeuSurf<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotpwu5glhj22we1aykjm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotpzosmbgj21a60niwpr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotq804fbcj234o1ggwxu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotqmjf1woj21840j8423.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotqinkqhfj23ie17kb29.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotqmyfbabj218a0iiwsz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hou1wp26q3j22p714gkjl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hou3kurmn1j255h1wd7vd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hou3nj2g33j252n2dib29.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 12:40:57 GMT</pubDate>
</item>
<item>
<title>【ATAC：命令行简单API客户端(类似postman)】'ATAC - A simple API client (postman like) in your terminal' GitHub: github.com/Julien-cpsn/ATAC #开源# #API...</title>
<link>https://weibo.com/1402400261/OaaNT43xs</link>
<guid>https://weibo.com/1402400261/OaaNT43xs</guid>
<content:encoded><![CDATA[
<div> GitHub, ATAC, 命令行, API, 客户端, postman, 简单, Julien-cpsn

<br /><br />总结:
ATAC是一个简单的命令行API客户端，类似于postman，方便用户在终端中进行API调用和测试。该工具的GitHub地址是github.com/Julien-cpsn/ATAC。用户可以通过ATAC在命令行中直接发送HTTP请求，并查看返回结果，实现API的快速测试和调试。ATAC提供了类似postman的功能，帮助用户更高效地与API进行交互，是一个方便实用的工具。 <div>
【ATAC：命令行简单API客户端(类似postman)】'ATAC - A simple API client (postman like) in your terminal' GitHub: github.com/Julien-cpsn/ATAC <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23API%23"><span class="surl-text">#API#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hou40srbmwj215n0u0jvq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 12:39:23 GMT</pubDate>
</item>
<item>
<title>【AudioCraft：用于深度学习音频生成研究的PyTorch库】’AudioCraft - Audiocraft is a library for audio processing and generation with deep learning. It f...</title>
<link>https://weibo.com/1402400261/OaaLwmiwW</link>
<guid>https://weibo.com/1402400261/OaaLwmiwW</guid>
<content:encoded><![CDATA[
<div> PyTorch, 深度学习, 音频生成, AudioCraft, EnCodec, MusicGen, 压缩器, 音频处理, 音乐生成, GitHub

<br /><br />总结:
AudioCraft是一个用于音频处理和生成的PyTorch库，其中包含了最先进的EnCodec音频压缩器/标记器以及MusicGen，一个具有文本和旋律条件的简单可控音乐生成LM。通过这个库，研究人员可以利用深度学习来进行音频生成研究，为音乐和音频领域的人工智能研究提供了有力的工具。GitHub上有相关代码和更多信息可供查阅。 <div>
【AudioCraft：用于深度学习音频生成研究的PyTorch库】’AudioCraft - Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning.' GitHub: github.com/nateraw/audiocraft <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hou3vd4p4tj211t0u079h.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 12:33:33 GMT</pubDate>
</item>
<item>
<title>【LLM可解释性/机制理解相关论文列表】’awesome papers for understanding LLM mechanism - awesome papers in LLM interpretability' GitHub: github.com/zepi...</title>
<link>https://weibo.com/1402400261/OaaHbBcEe</link>
<guid>https://weibo.com/1402400261/OaaHbBcEe</guid>
<content:encoded><![CDATA[
<div> GitHub, LLM, 解释性, 机制理解, 论文, 列表, 理解, 机制, awesome, 作者

<br /><br />总结:
这个GitHub仓库收集了一些关于LLM（Large Language Model）可解释性和机制理解相关的优秀论文。这些论文帮助读者更好地理解LLM的工作机制和解释方式，对于研究人员和学习者来说是非常有价值的资源。通过阅读这些论文，可以深入了解LLM在自然语言处理领域的应用，以及其在模型理解和解释方面的进展。如果你对LLM的工作原理和解释机制感兴趣，不妨查阅这个GitHub仓库，里面收录的论文可能会给你带来启发和新的见解。 <div>
【LLM可解释性/机制理解相关论文列表】’awesome papers for understanding LLM mechanism - awesome papers in LLM interpretability' GitHub: github.com/zepingyu0512/awesome-llm-understanding-mechanism <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hou3k9gmr9j20yz0u0tds.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 12:22:53 GMT</pubDate>
</item>
<item>
<title>【Sitcom Simulator：利用多种人工智能技术生成幽默短视频，结合了 AI 生成的脚本、角色的语音合成、以及视觉艺术生成，最后通过视频编辑软件将这些元素组合成影...</title>
<link>https://weibo.com/1402400261/OaaAfocYT</link>
<guid>https://weibo.com/1402400261/OaaAfocYT</guid>
<content:encoded><![CDATA[
<div> ChatGPT, Stable Diffusion, FakeYou, FreePD, 视频生成, 人工智能, 幽默短视频, GitHub<br />
<br />
AI技术结合制作的Sitcom Simulator利用ChatGPT、Stable Diffusion、FakeYou和FreePD等多种人工智能技术生成幽默短视频。通过AI生成脚本、角色语音合成和视觉艺术生成，最后通过视频编辑软件将这些元素组合成影片。GitHub上有该项目代码的存储库。Sitcom Simulator是一种结合多种AI技术制作视频的工具。 <div>
【Sitcom Simulator：利用多种人工智能技术生成幽默短视频，结合了 AI 生成的脚本、角色的语音合成、以及视觉艺术生成，最后通过视频编辑软件将这些元素组合成影片】’Sitcom Simulator - A tool that combines ChatGPT, Stable Diffusion, FakeYou, and FreePD to create AI-generated videos.' GitHub: github.com/joshmoody24/sitcom-simulator <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hou32beg8zj209m0h4myr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hou32cfjo2j209r0h5abc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hou32diklvj209q0h4409.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 12:05:47 GMT</pubDate>
</item>
<item>
<title>【深度学习表格检测与结构识别相关论文与资源列表】’Deep learning for table detection and structure recognition: A survey' GitHub: github.com/abdoelsaye...</title>
<link>https://weibo.com/1402400261/OaazHx0W8</link>
<guid>https://weibo.com/1402400261/OaazHx0W8</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度学习, 表格检测, 结构识别, 调研, GitHub, 论文, 资源, 检测技术, 文本提取, 表格解析

深度学习在表格检测和结构识别领域的应用取得了显著进展。该调研论文综述了相关工作，并提供了GitHub资源链接。论文涵盖了表格检测技术、表格结构识别、文本提取等内容。围绕着深度学习方法，研究者们通过实验和案例研究展示了各种技术的应用效果。GitHub资源提供了更多相关论文和实现代码，为研究者们提供了更多的参考和学习资料。

<br /><br />总结: 
1. 调研论文总结了深度学习在表格检测与结构识别领域的最新进展。
2. 论文提供了GitHub资源链接，包含了相关论文和实现代码，为研究者提供了更多参考资料。
3. 论文涵盖了表格检测技术、表格结构识别、文本提取等内容。
4. 研究者们通过实验和案例研究展示了深度学习方法在表格检测与结构识别中的应用效果。 <div>
【深度学习表格检测与结构识别相关论文与资源列表】’Deep learning for table detection and structure recognition: A survey' GitHub: github.com/abdoelsayed2016/Table-Detection-Structure-Recognition <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hou30wo2paj20u00u979z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 12:04:27 GMT</pubDate>
</item>
<item>
<title>【GPT-AI-Code-Interpreter：基于云运行时的 Python &amp; JavaScript SDK，用于构建自定义代码解释器。它支持 LLM（如 OpenAI、Cohere 和 Anthropic）生成的代码块...</title>
<link>https://weibo.com/1402400261/Oaaum8q2G</link>
<guid>https://weibo.com/1402400261/Oaaum8q2G</guid>
<content:encoded><![CDATA[
<div> Python, JavaScript, SDK, 构建, 自定义, 代码解释器, LLM, 代码块, 状态共享, 图表输出

<br /><br />总结:
本文介绍了基于云运行时的 Python 和 JavaScript SDK，用于构建自定义代码解释器。该 SDK 支持 LLM 生成的代码块之间的状态共享，允许用户逐步执行代码，并支持图表输出等功能。GitHub 上有相关项目的代码仓库。 <div>
【GPT-AI-Code-Interpreter：基于云运行时的 Python &amp; JavaScript SDK，用于构建自定义代码解释器。它支持 LLM（如 OpenAI、Cohere 和 Anthropic）生成的代码块之间的状态共享，允许用户逐步执行代码，并支持图表输出等功能】'Code Interpreter SDK - Python &amp; JS SDK for building custom code interpreters. Built with E2B - Cloud Runtime for AI Agents.' GitHub: github.com/e2b-dev/code-interpreter <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hou2n9u58pj20u010a0xi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 11:51:16 GMT</pubDate>
</item>
<item>
<title>'AIChat Web - 在ChatGPT-Next-Web的基础上，增加注册登录，额度限制，邀请，敏感词，支付，基于docker一键部署。提供后台管理系统，可配置标题、欢迎词、额度不...</title>
<link>https://weibo.com/1402400261/Oa7OrujpC</link>
<guid>https://weibo.com/1402400261/Oa7OrujpC</guid>
<content:encoded><![CDATA[
<div> 注册登录、额度限制、邀请、敏感词、支付、docker一键部署、后台管理系统、配置标题、欢迎词、公告<br /><br />总结: 该项目是在ChatGPT-Next-Web基础上进行了扩展，增加了注册登录功能、额度限制、邀请制度、敏感词过滤、支付功能，并基于docker实现了一键部署。此外，项目提供了后台管理系统，允许管理员配置网站的标题、欢迎词、额度不足提醒和公告信息，为用户提供了更多的个性化设置和管理权限。 <div>
'AIChat Web - 在ChatGPT-Next-Web的基础上，增加注册登录，额度限制，邀请，敏感词，支付，基于docker一键部署。提供后台管理系统，可配置标题、欢迎词、额度不足提醒、公告' GitHub: github.com/Nanjiren01/AIChatWeb <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hotqtx93zyj21o00u077g.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hotqtztannj21hj0u0gnn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 05:02:30 GMT</pubDate>
</item>
<item>
<title>【DeepBI：AI原生的数据分析平台，DeepBI充分利用大语言模型的能力来探索、查询、可视化和共享来自任何数据源的数据，用户可以使用DeepBI洞察数据并做出数据驱动...</title>
<link>https://weibo.com/1402400261/Oa7NxA4Us</link>
<guid>https://weibo.com/1402400261/Oa7NxA4Us</guid>
<content:encoded><![CDATA[
<div> 数据分析平台, AI, 大语言模型, 探索, 查询, 可视化, 共享, 数据源, 数据驱动决策, GitHub<br />
<br />
总结:<br />
DeepBI是一款基于大语言模型的数据分析平台，利用AI驱动的无限思考重新定义了商业智能。用户可以通过DeepBI来探索、查询、可视化和共享来自任何数据源的数据，从而做出数据驱动的决策。感兴趣的用户可以在GitHub上找到DeepBI的代码库。 <div>
【DeepBI：AI原生的数据分析平台，DeepBI充分利用大语言模型的能力来探索、查询、可视化和共享来自任何数据源的数据，用户可以使用DeepBI洞察数据并做出数据驱动的决策】'DeepBI - LLM based data scientist, AI native data application. AI-driven infinite thinking redefines BI.' GitHub: github.com/DeepInsight-AI/DeepBI <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hotqrpo49kj20xa0u00vb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 05:00:18 GMT</pubDate>
</item>
<item>
<title>【Mamba相关文献资源列表】’Awesome Mamba - A Comprehensive Survey of Mamba in Deep Learning' GitHub: github.com/xmindflow/Awesome_Mamba #开源# #机器学...</title>
<link>https://weibo.com/1402400261/Oa7MMmMdL</link>
<guid>https://weibo.com/1402400261/Oa7MMmMdL</guid>
<content:encoded><![CDATA[
<div> 关键词：Mamba、深度学习、综述、GitHub、资源、调查、全面、神经网络、模型、技术

Mamba是一个关于深度学习中Mamba的综合调查，GitHub上有相关资源。这份综述详细介绍了Mamba在神经网络模型和技术方面的应用。有兴趣研究Mamba的人可以在这个GitHub上找到更多信息。总的来说，这篇综述涵盖了Mamba在深度学习领域的全面内容，对研究者和开发者有着一定的参考价值。<br /><br />总结: Mamba综述了深度学习中Mamba的应用，包括神经网络模型和技术，对该领域有兴趣的人可以在GitHub上找到更多相关资源。 <div>
【Mamba相关文献资源列表】’Awesome Mamba - A Comprehensive Survey of Mamba in Deep Learning' GitHub: github.com/xmindflow/Awesome_Mamba <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hotqpilrqqj20zf0u0dkz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:58:25 GMT</pubDate>
</item>
<item>
<title>【posteriors：基于 PyTorch 的通用不确定性量化库】'posteriors - Uncertainty quantification with PyTorch' GitHub: github.com/normal-computing/posteriors...</title>
<link>https://weibo.com/1402400261/Oa7I8Aktr</link>
<guid>https://weibo.com/1402400261/Oa7I8Aktr</guid>
<content:encoded><![CDATA[
<div> PyTorch、不确定性量化、库、posteriors、GitHub、基于、通用、Uncertainty quantification、normal-computing、不确定性量化。<br />
<br />
基于PyTorch开发的通用不确定性量化库posteriors在GitHub上开源，旨在帮助用户通过PyTorch实现不确定性量化。这个库提供了丰富的功能，可以帮助用户更好地理解和量化模型的不确定性，以及提供模型预测的置信度。用户可以借助posteriors库探索不确定性的来源，并在模型训练和评估过程中应用这些信息。通过posteriors库，用户可以轻松地实现不确定性量化方法，例如贝叶斯神经网络和蒙特卡洛Dropout。posteriors库的开源使得更多研究者和开发者能够利用其中的工具和函数来提高他们模型的性能和鲁棒性，进一步推动不确定性量化领域的发展。总之，posteriors库为基于PyTorch的不确定性量化提供了一个便捷、高效的解决方案，有望帮助用户在机器学习和深度学习领域取得更好的效果。 <br /><br />总结: 该基于PyTorch的通用不确定性量化库 posteriors 在GitHub上提供了丰富的功能和工具，帮助用户实现不确定性量化、理解模型的不确定性并提高模型性能。 <div>
【posteriors：基于 PyTorch 的通用不确定性量化库】'posteriors - Uncertainty quantification with PyTorch' GitHub: github.com/normal-computing/posteriors <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hotqdw8qoxj212f0u0dke.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:46:59 GMT</pubDate>
</item>
<item>
<title>【GWalkR:R中的交互式探索性数据分析（EDA）工具】'GWalkR: Your One-Stop R Package for Exploratory Data Analysis with Visualization - Turn your data fram...</title>
<link>https://weibo.com/1402400261/Oa7HlmfIP</link>
<guid>https://weibo.com/1402400261/Oa7HlmfIP</guid>
<content:encoded><![CDATA[
<div> 交互式，探索性数据分析，EDA，工具，R，数据框，可视化，界面，GitHub，GWalkR<br />
<br />
总结：<br />
本文介绍了GWalkR，一个R包，用于交互式探索性数据分析（EDA），提供类似Tableau的拖放式用户界面，可将数据框转换为可视化界面。用户可以使用该工具在R中轻松构建可视化图表，实现数据分析更为直观和高效。GitHub链接为github.com/Kanaries/GWalkR。 <div>
【GWalkR:R中的交互式探索性数据分析（EDA）工具】'GWalkR: Your One-Stop R Package for Exploratory Data Analysis with Visualization - Turn your data frame into a tableau style drag and drop UI interface to build visualization in R.' GitHub: github.com/Kanaries/GWalkR <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hotqbtva9vj21bw0u0436.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hotqbv0m8ij212w0obqh0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:45:02 GMT</pubDate>
</item>
<item>
<title>【AI文档理解相关文献资源列表】’Awesome-Document-Understanding - Document Artifical Intelligence' GitHub: github.com/harrytea/Awesome-Document-Underst...</title>
<link>https://weibo.com/1402400261/Oa7Fzi2RK</link>
<guid>https://weibo.com/1402400261/Oa7Fzi2RK</guid>
<content:encoded><![CDATA[
<div> 关键词：GitHub、文档理解、人工智能、资源、Awesome-Document-Understanding

总结：<br /><br />这篇文章介绍了一个名为"Awesome-Document-Understanding - Document Artificial Intelligence"的GitHub项目，该项目旨在提供关于文档理解和人工智能方面的相关资源。GitHub链接为github.com/harrytea/Awesome-Document-Understanding。该项目可能包括各种文档理解技术、人工智能算法以及其他相关资源的链接和信息。对于对文档理解和人工智能感兴趣的人来说，这个项目可能是一个很好的参考和学习资源。<br /> <div>
【AI文档理解相关文献资源列表】’Awesome-Document-Understanding - Document Artifical Intelligence' GitHub: github.com/harrytea/Awesome-Document-Understanding <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hotq7b3j71j20x70u0wki.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:40:39 GMT</pubDate>
</item>
<item>
<title>【利用深度学习进行定理证明相关论文资源累表列表】’Deep Learning for Theorem Proving (DL4TP) - A Survey on Deep Learning for Theorem Proving' GitHub: g...</title>
<link>https://weibo.com/1402400261/Oa7FgEUsH</link>
<guid>https://weibo.com/1402400261/Oa7FgEUsH</guid>
<content:encoded><![CDATA[
<div> Deep Learning, Theorem Proving, Survey, Resource, GitHub, Artificial Intelligence, Machine Learning, Neural Networks, Automation, Logic<br />
<br />总结:<br />
这篇论文调研了深度学习在定理证明中的应用，提供了相关资源和GitHub链接。文章介绍了深度学习在定理证明中的作用，讨论了人工智能、机器学习和神经网络等技术在自动化推理领域的重要性。研究者对深度学习在定理证明中的发展和应用进行了综述，为进一步研究提供了重要参考。 <div>
【利用深度学习进行定理证明相关论文资源累表列表】’Deep Learning for Theorem Proving (DL4TP) - A Survey on Deep Learning for Theorem Proving' GitHub: github.com/zhaoyu-li/DL4TP <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hotq6j4oxsj211z0u0te9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:39:55 GMT</pubDate>
</item>
<item>
<title>【LLM Experiments：与 OpenAI 语言模型 GPT 进行交互的Demo项目】’LLM Experiments - I play with my best friend GPT' GitHub: github.com/ggoonnzzaallo/llm...</title>
<link>https://weibo.com/1402400261/Oa7EPtSaC</link>
<guid>https://weibo.com/1402400261/Oa7EPtSaC</guid>
<content:encoded><![CDATA[
<div> GitHub、LLM Experiments、OpenAI、语言模型、GPT、交互、Demo项目、玩耍、项目、最佳朋友
<br />
该项目是一个与OpenAI语言模型GPT进行交互的Demo项目，通过GitHub进行发布。项目名称为LLM Experiments，主要内容是作者和GPT模型互动，就像与最好的朋友一样玩耍。项目展示了作者与GPT模型的对话和交流过程，探索了语言模型在不同场景下的应用。项目的灵感来源于对人工智能技术的兴趣和探索，展示了如何与先进的自然语言处理模型进行有趣的互动。通过这个项目，作者展示了人与人工智能之间的交互可能性，以及语言模型在日常生活中的潜在应用。整个项目与GPT模型之间的互动充满趣味和创意，展示了人工智能技术的潜力和可能性。通过这个Demo项目，作者展示了对人工智能技术的理解和应用，同时也探索了人工智能与人类之间的关系和合作。总体而言，该项目展示了作者与GPT模型之间的创造性互动，为人工智能技术的发展和创新提供了新的思路和灵感。
<br /><br />总结: 该项目是一个与OpenAI语言模型GPT进行交互的Demo项目，通过GitHub进行发布。项目展示了作者与GPT模型的对话和交流过程，探索了语言模型在不同场景下的应用。展示了人与人工智能之间的交互可能性，以及语言模型在日常生活中的潜在应用。整个项目与GPT模型之间的互动充满趣味和创意，展示了人工智能技术的潜力和可能性。 <div>
【LLM Experiments：与 OpenAI 语言模型 GPT 进行交互的Demo项目】’LLM Experiments - I play with my best friend GPT' GitHub: github.com/ggoonnzzaallo/llm_experiments <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hotq56s2qdj20u013fdn7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:38:50 GMT</pubDate>
</item>
<item>
<title>【Firecrawl：将网站内容转换为适合LLM的Markdown格式文本的工具】'Firecrawl - Turn entire websites into LLM-ready markdown' GitHub: github.com/mendableai...</title>
<link>https://weibo.com/1402400261/Oa7DlzX7X</link>
<guid>https://weibo.com/1402400261/Oa7DlzX7X</guid>
<content:encoded><![CDATA[
<div> 工具、Firecrawl、网站内容、转换、LLM、Markdown格式、GitHub、mendableai

<br /><br />总结:
Firecrawl是一个工具，可以将网站的内容转换为适合LLM（Large Language Models）的Markdown格式文本。用户可以通过GitHub上的mendableai/firecrawl找到该工具。通过Firecrawl，用户可以将整个网站的内容快速转换为LLM所能识别的Markdown格式，便于进一步处理和分析。Firecrawl的使用简单高效，为用户提供了一个方便的工具来整理和处理网站内容。 <div>
【Firecrawl：将网站内容转换为适合LLM的Markdown格式文本的工具】'Firecrawl - Turn entire websites into LLM-ready markdown' GitHub: github.com/mendableai/firecrawl <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hotq1lp0ahj21740smtds.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:35:11 GMT</pubDate>
</item>
<item>
<title>【CodeQwen1.5：基于人工智能的代码生成工具，可以根据自然语言描述生成完整的代码，该工具利用了Qwen大语言模型，可以提供高质量、准确的代码生成结果】'CodeQw...</title>
<link>https://weibo.com/1402400261/Oa7C4xjT8</link>
<guid>https://weibo.com/1402400261/Oa7C4xjT8</guid>
<content:encoded><![CDATA[
<div> 人工智能、代码生成工具、Qwen大语言模型、高质量、准确、代码生成结果、Alibaba Cloud

<br /><br />总结:
CodeQwen1.5是一款基于人工智能的代码生成工具，利用了Qwen大语言模型，能够根据自然语言描述生成完整的代码。该工具提供高质量、准确的代码生成结果，是由阿里云的Qwen团队开发的具有先进技术的工具。GitHub上有该工具的代码存储库，用户可以查看并使用。 <div>
【CodeQwen1.5：基于人工智能的代码生成工具，可以根据自然语言描述生成完整的代码，该工具利用了Qwen大语言模型，可以提供高质量、准确的代码生成结果】'CodeQwen1.5 - the code version of Qwen, the large language model series developed by Qwen team, Alibaba Cloud.' GitHub: github.com/QwenLM/CodeQwen1.5 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hotpy9sxkuj20yz0u00wd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 04:32:03 GMT</pubDate>
</item>
<item>
<title>【MIT新书《计算机视觉基础》，一本关于计算机视觉基础的教材，该教材结合了计算机视觉的经典方法和深度学习的最新进展，并从全面的角度介绍了计算机视觉的基础...</title>
<link>https://weibo.com/1402400261/Oa5M68zO3</link>
<guid>https://weibo.com/1402400261/Oa5M68zO3</guid>
<content:encoded><![CDATA[
<div> 计算机视觉基础 深度学习 经典方法 基础问题 人类感知 关系

<br /><br />总结:
《计算机视觉基础》是一本结合了计算机视觉的经典方法和深度学习最新进展的教材。该教材从全面的角度介绍了计算机视觉的基础问题，并探讨了计算机视觉与人类感知的关系。在学习计算机视觉的过程中，深度学习技术的应用成为了一个重要方向。通过本书的学习，读者能够了解到计算机视觉在实际应用中的原理和方法，以及如何将计算机视觉技术与深度学习相结合，从而更好地理解和应用这一领域的知识。《计算机视觉基础》为读者提供了一个系统化、全面的学习计算机视觉基础知识的平台，帮助他们更加深入地了解这一领域的理论和实践。 <div>
【MIT新书《计算机视觉基础》，一本关于计算机视觉基础的教材，该教材结合了计算机视觉的经典方法和深度学习的最新进展，并从全面的角度介绍了计算机视觉的基础问题和其与人类感知的关系】《Foundations of Computer Vision》 <a href="https://mitpress.mit.edu/9780262048972/foundations-of-computer-vision/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hothts9z1tj20gk0iln00.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 23:51:15 GMT</pubDate>
</item>
<item>
<title>【免费书《大语言模型》，为读者提供关于大语言模型技术的全面了解，从基础原理、关键技术到应用前景。它介绍了大模型技术的整体框架和路线图，并提供了下载链接...</title>
<link>https://weibo.com/1402400261/Oa5KC99ej</link>
<guid>https://weibo.com/1402400261/Oa5KC99ej</guid>
<content:encoded><![CDATA[
<div> 大语言模型、技术、基础原理、关键技术、应用前景、整体框架、路线图、下载链接、配套资源

大语言模型是一本免费的书籍，提供了关于大语言模型技术的全面了解。书中介绍了大模型技术的整体框架和路线图，包括基础原理、关键技术以及应用前景。读者可以从中了解到大语言模型的基本原理和关键技术，同时获取相关的下载链接和配套资源。这本书为对大语言模型技术感兴趣的读者提供了丰富的知识和资源，帮助他们更好地理解和应用这一前沿技术。<br /><br />总结: 大语言模型提供了关于大模型技术的详细介绍，包括基础原理、关键技术和应用前景，读者可通过下载链接获取更多资源。 <div>
【免费书《大语言模型》，为读者提供关于大语言模型技术的全面了解，从基础原理、关键技术到应用前景。它介绍了大模型技术的整体框架和路线图，并提供了下载链接和配套资源】《大语言模型 | LLMBook-zh》 <a href="https://llmbook-zh.github.io/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hothpwd0kaj20u01c5wl2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hothphj1wej20s30bygp0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 23:47:34 GMT</pubDate>
</item>
<item>
<title>《AI类知识文档全网合集 - 飞书云文档》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/Oa5Jz6sti</link>
<guid>https://weibo.com/1402400261/Oa5Jz6sti</guid>
<content:encoded><![CDATA[
<div> 关键词: AI, 知识文档, 全网, 合集, 飞书, 云文档

总结: 
AI类知识文档全网合集是一份收集了各种与人工智能相关的文档的合集，在飞书云文档中可获取。这份合集包含了各种有关AI的知识和信息，为研究人员、开发者和学习者提供了丰富的资源和参考资料。通过飞书云文档，用户可以方便地浏览和获取这些文档，从而提升对人工智能的理解和运用能力。AI技术的发展日新月异，掌握最新的知识和资讯对于从事相关领域的人员至关重要。飞书云文档为用户提供了一个方便快捷的获取AI类知识文档的平台，帮助他们更加高效地学习和研究人工智能技术。AI类知识文档全网合集的推出，将为AI领域的学习和发展提供更多便利，促进人工智能技术的创新和应用。<br /><br />总结: <div>
《AI类知识文档全网合集 - 飞书云文档》 <a href="https://uqtg4okxsd.feishu.cn/wiki/MoB0w5Zd2ie2IckGg7WccMRRnrg"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hothnowlqsj21at0u0tdw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 23:45:00 GMT</pubDate>
</item>
<item>
<title>【torchtune：用 PyTorch 轻松微调大语言模型】 - PyTorch发布了torchtune库的alpha版本，用于轻松微调大型语言模型。该库遵循PyTorch的设计原则，提供了组件化...</title>
<link>https://weibo.com/1402400261/Oa5IUgoKb</link>
<guid>https://weibo.com/1402400261/Oa5IUgoKb</guid>
<content:encoded><![CDATA[
<div> PyTorch, torchtune, 大语言模型, 微调, 组件化, 模块化,易扩展性, 开源生态系统, Hugging Face Hub, PyTorch FSDP

总结：<br /><br />PyTorch发布了torchtune库的alpha版本，用于轻松微调大型语言模型。该库遵循PyTorch的设计原则，提供了组件化和模块化的构建块，以及易于扩展的微调示例，以在各种消费级和专业GPU上微调流行的大型语言模型。torchtune支持完整的微调工作流程，包括数据集和模型检查点的下载和准备、可组合的构建块进行训练自定义、训练过程的日志和指标记录、模型量化、在知名基准上的模型评估以及本地推理。torchtune致力于易扩展性，让微调大众化，并与开源生态系统的互操作性。未来还将增加更多模型、特征和微调技术。torchtune与Hugging Face Hub、PyTorch FSDP、Weights & Biases、EleutherAI的评估工具、ExecuTorch和torchao等开源生态系统的组件深度集成，为用户提供灵活性和控制力。 <div>
【torchtune：用 PyTorch 轻松微调大语言模型】<br /> - PyTorch发布了torchtune库的alpha版本，用于轻松微调大型语言模型。该库遵循PyTorch的设计原则，提供了组件化和模块化的构建块，以及易于扩展的微调示例，以在各种消费级和专业GPU上微调流行的大型语言模型。   <br />- torchtune支持从头到尾的完整微调工作流程，包括数据集和模型检查点的下载和准备、可组合的构建块进行训练自定义、训练过程的日志和指标记录、模型量化、在知名基准上的模型评估以及本地推理。   <br />- torchtune致力于易扩展性、让微调大众化、与开源生态系统的互操作性。未来几周将持续为库增加更多模型、特征和微调技术。   <br />- torchtune与Hugging Face Hub、PyTorch FSDP、Weights &amp; Biases、EleutherAI的评估工具、ExecuTorch和torchao等开源生态系统的组件深度集成，为用户提供灵活性和控制力。<br />《torchtune: Easily fine-tune LLMs using PyTorch | PyTorch》 <a href="https://pytorch.org/blog/torchtune-fine-tune-llms"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hothm0tmfej214a0u0adk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 23:43:23 GMT</pubDate>
</item>
<item>
<title>今日推介(第1378期)：具有无限上下文长度的高效LLM预训练和推理、大型语言模型可以自动实现特征工程以进行少样本表格学习、反馈注意力是工作记忆、偏好噪声对生...</title>
<link>https://weibo.com/1402400261/Oa5a0hxA0</link>
<guid>https://weibo.com/1402400261/Oa5a0hxA0</guid>
<content:encoded><![CDATA[
<div> 预训练、推理、特征工程、少样本表格学习、工作记忆、偏好噪声、生成式语言模型、对齐性能、状态幻觉

<br /><br />总结:
本文介绍了具有无限上下文长度的高效LLM预训练和推理的方法，以及大型语言模型可以自动实现特征工程来进行少样本表格学习的技术。研究表明，反馈注意力在工作记忆中起到重要作用。此外，偏好噪声对生成式语言模型的对齐性能有影响。最后，讨论了状态-空间模型中状态幻觉的问题。这些研究结果对提升语言模型的效率和性能具有重要指导意义。 <div>
今日推介(第1378期)：具有无限上下文长度的高效LLM预训练和推理、大型语言模型可以自动实现特征工程以进行少样本表格学习、反馈注意力是工作记忆、偏好噪声对生成式语言模型对齐性能的影响、状态-空间模型的状态幻觉 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/692889182"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.17)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hotf47b02lj219o0qwaec.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hotf49o2isj22bl0u0jzw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hotf4cc4bxj21jk0p8qa3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hotf4f73pej21a00jk40m.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hotf4ib6y8j20tu12uahn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 22:17:23 GMT</pubDate>
</item>
<item>
<title>[LG] Foundational Challenges in Assuring Alignment and Safety of Large Language Models 网页链接 本文系统地总结了确保大语言模型安全性和对齐性的18大基础...</title>
<link>https://weibo.com/1402400261/Oa55Cy133</link>
<guid>https://weibo.com/1402400261/Oa55Cy133</guid>
<content:encoded><![CDATA[
<div> 挑战、安全性、对齐性、大语言模型、路线图、研究、基础性、清晰、确保、系统地

总结:<br /><br />文章系统地总结了确保大语言模型安全性和对齐性的18大基础性挑战，为后续研究提供了清晰的路线图。 <div>
[LG] Foundational Challenges in Assuring Alignment and Safety of Large Language Models  <br /><a href="https://arxiv.org/abs/2404.09932"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />本文系统地总结了确保大语言模型安全性和对齐性的18大基础性挑战，为后续研究提供了清晰的路线图。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotet9yrp1j210y1d8n80.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotetactpyj20zy1d6tnl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotetat0gbj210c1d4k8f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotetau6f6j210g1dcncu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 22:06:36 GMT</pubDate>
</item>
<item>
<title>[CL] Large Language Models are as persuasive as humans, but why? About the cognitive effort and moral-emotional language of LLM arguments 网页链接 发...</title>
<link>https://weibo.com/1402400261/Oa52EjLan</link>
<guid>https://weibo.com/1402400261/Oa52EjLan</guid>
<content:encoded><![CDATA[
<div> 认知加工难度, 道德语言, LLM, 说服力, 人类, 差异, 线索, 情感语言, 论点

<br /><br />总结:
LLM与人类在说服力上存在差异，这部分原因可能在于认知加工难度和道德语言的运用。LLM的论点在道德语言和情感语言上的表达可能是其说服力的关键之一，而这也为研究LLM的说服力提供了一些线索。虽然在某些方面LLM可能和人类一样具有说服力，但认知加工难度和道德语言的使用会导致它们在说服力上出现一些差异。通过深入研究LLM的道德语言运用和情感语言表达，或许可以更好地理解其说服力的机制。 <div>
[CL] Large Language Models are as persuasive as humans, but why? About the cognitive effort and moral-emotional language of LLM arguments  <br /><a href="https://arxiv.org/abs/2404.09329"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>        <br />发现LLM论点相较人类论点在认知加工难度和道德语言运用上存在差异，为解析LLM的说服力提供了线索。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotelnjv88j216g18q168.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotelo1nzvj21kw0vu79l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotelogyrnj21bg19244e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:59:17 GMT</pubDate>
</item>
<item>
<title>[CV] Map-Relative Pose Regression for Visual Re-Localization 网页链接 该方法将场景特定的几何表示与场景无关的姿态回归相结合，在保持端到端高效的同时实现...</title>
<link>https://weibo.com/1402400261/Oa4Zjke8v</link>
<guid>https://weibo.com/1402400261/Oa4Zjke8v</guid>
<content:encoded><![CDATA[
<div> 重定位、场景特定、几何表示、姿态回归、端到端、高效、高精度、视觉重定位、重要进展
<br />
<br />
总结: 本文提出了一种将场景特定的几何表示与场景无关的姿态回归相结合的方法，实现了高精度的视觉重定位。这种方法在保持端到端高效的同时，取得了重要的进展，对姿态回归领域具有重要意义。 <div>
[CV] Map-Relative Pose Regression for Visual Re-Localization  <br /><a href="https://arxiv.org/abs/2404.09884"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />该方法将场景特定的几何表示与场景无关的姿态回归相结合，在保持端到端高效的同时实现了高精度的视觉重定位，是姿态回归领域的重要进展。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoted2fx86j20wo13sdv7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoted2g0rlj21no0jowkp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoted38d5tj20ue0ywn24.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:51:03 GMT</pubDate>
</item>
<item>
<title>[CL] Is Next Token Prediction Sufficient for GPT? Exploration on Code Logic Comprehension 网页链接 通过新的预训练任务增强了语言模型区分逻辑等价代码的...</title>
<link>https://weibo.com/1402400261/Oa4X1xhCP</link>
<guid>https://weibo.com/1402400261/Oa4X1xhCP</guid>
<content:encoded><![CDATA[
<div> 预训练任务、语言模型、代码逻辑、等价代码、LLM、关键词集合、逻辑理解、代码理解

总结:<br /><br />文章通过探讨新的预训练任务增强了语言模型在区分逻辑等价代码方面的能力，证明当前LLM仍将代码视为无序关键词集合而非真正理解其背后的逻辑。通过研究可以得出，对于GPT来说，仅仅进行下一个标记的预测可能并不足以实现对代码逻辑的完全理解。文章呼吁加强对语言模型在代码逻辑理解方面的研究，以提高其应用的准确性和可靠性。 <div>
[CL] Is Next Token Prediction Sufficient for GPT? Exploration on Code Logic Comprehension  <br /><a href="https://arxiv.org/abs/2404.08885"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />通过新的预训练任务增强了语言模型区分逻辑等价代码的能力，证明当前LLM仍将代码视为无序关键词集合而非真正理解其背后的逻辑。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hote78otucj20s616uwut.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hote78rpjyj21h80yok14.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hote79fcsmj20qe0s6n1p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:45:25 GMT</pubDate>
</item>
<item>
<title>[CL] Compression Represents Intelligence Linearly 网页链接 大型语言模型压缩外部语料的效率与其在知识理解、编程和数学推理方面的表现几乎呈线性相关，压缩...</title>
<link>https://weibo.com/1402400261/Oa4TApUVY</link>
<guid>https://weibo.com/1402400261/Oa4TApUVY</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、压缩、外部语料、效率、知识理解、编程、数学推理、线性相关、测试集泄露、智能评价指标 <br />
<br />
总结: 本文指出，大型语言模型在压缩外部语料方面的效率与其在知识理解、编程和数学推理方面的表现几乎呈线性相关。压缩效率可以作为一个既避免测试集泄露又与模型智能高度相关的评价指标。 <div>
[CL] Compression Represents Intelligence Linearly  <br /><a href="https://arxiv.org/abs/2404.09937"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />大型语言模型压缩外部语料的效率与其在知识理解、编程和数学推理方面的表现几乎呈线性相关，压缩效率可以作为一个避免测试集泄露且与模型智能高度相关的评价指标。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdyeg0o7j20qc16mdrg.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdyeoig5j21bs0pgdn2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdyfenn5j21bi0oqaha.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:36:56 GMT</pubDate>
</item>
<item>
<title>利用回路复杂度理论证明了SSM在状态跟踪问题上与Transformer有相似的固有表达能力局限，表明SSM难以处理需要顺序计算的状态跟踪任务。 - 转发 @爱可可-爱生活:&amp;e...</title>
<link>https://weibo.com/1402400261/Oa4QidNBy</link>
<guid>https://weibo.com/1402400261/Oa4QidNBy</guid>
<content:encoded><![CDATA[
<div> 状态跟踪问题, SSM, Transformer, 回路复杂度理论, 表达能力局限<br />
<br />
总结:<br />
文章利用回路复杂度理论证明了SSM在状态跟踪问题上与Transformer具有相似的固有表达能力局限。作者指出，SSM难以处理需要顺序计算的状态跟踪任务。他们认为，SSM模型在处理复杂的状态跟踪问题时存在局限性，需要进一步改进。文章的研究对于深入理解SSM在状态跟踪问题中的表现有着重要的意义。 <div>
利用回路复杂度理论证明了SSM在状态跟踪问题上与Transformer有相似的固有表达能力局限，表明SSM难以处理需要顺序计算的状态跟踪任务。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《The Illusion of State in State-Space Models》W Merrill, J Petty, A Sabharwal [New York University] (2024) <a href="https://arxiv.org/abs/2404.08819"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdjlg2npj20p018u4am.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdjm922bj20tu12u48k.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdjmimbij20tg0lu431.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdjmpz89j21mm0qowky.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:28:49 GMT</pubDate>
</item>
<item>
<title>[LG]《The Illusion of State in State-Space Models》W Merrill, J Petty, A Sabharwal [New York University] (2024) 网页链接 #机器学习##人工智能##论文# [...</title>
<link>https://weibo.com/1402400261/Oa4QfBnP7</link>
<guid>https://weibo.com/1402400261/Oa4QfBnP7</guid>
<content:encoded><![CDATA[
<div> state-space models, illusion, state, New York University, analysis, methodology, implications, measurements, research, findings

总结:<br /><br />本文由纽约大学的W Merrill, J Petty和A Sabharwal撰写，探讨了状态空间模型中的状态错觉现象。研究通过分析方法论和测量方法，揭示了状态空间模型中状态的虚幻性质。研究结果对测量和研究方法产生了重要影响，强调了状态空间模型中存在的一些潜在误导。通过深入研究，文章呈现了对状态空间模型的新理解，为相关领域的研究提供了有价值的参考。 <div>
[LG]《The Illusion of State in State-Space Models》W Merrill, J Petty, A Sabharwal [New York University] (2024) <a href="https://arxiv.org/abs/2404.08819"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdjlg2npj20p018u4am.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdjm922bj20tu12u48k.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdjmimbij20tg0lu431.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdjmpz89j21mm0qowky.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:28:44 GMT</pubDate>
</item>
<item>
<title>提出一个注入可控噪声的框架，系统地研究了不同类型和程度的偏好噪声如何影响生成式语言模型(GLM)对齐效果以及置信度滤波在降噪方面的作用，为更好地理解和处理...</title>
<link>https://weibo.com/1402400261/Oa4KSCq0X</link>
<guid>https://weibo.com/1402400261/Oa4KSCq0X</guid>
<content:encoded><![CDATA[
<div> GLM, 偏好噪声, 对齐效果, 置信度滤波, 框架, 研究, 影响, 指导, 理解, 处理

总结:<br /><br />
这篇文章提出了一个注入可控噪声的框架，系统地研究了不同类型和程度的偏好噪声如何影响生成式语言模型对齐效果以及置信度滤波在降噪方面的作用。研究结果为更好地理解和处理偏好噪声提供了指导。文章内容包括：框架提出和设计，不同类型偏好噪声的影响研究，对齐效果分析，置信度滤波的降噪作用探讨等。研究结论表明，注入偏好噪声对于生成式语言模型的对齐效果有明显影响，同时置信度滤波能有效降噪，有助于提高模型的稳定性和准确性。这些研究结果对于深入理解和解决偏好噪声问题具有一定的启发意义。 <div>
提出一个注入可控噪声的框架，系统地研究了不同类型和程度的偏好噪声如何影响生成式语言模型(GLM)对齐效果以及置信度滤波在降噪方面的作用，为更好地理解和处理偏好噪声提供了指导。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Impact of Preference Noise on the Alignment Performance of Generative Language Models》Y Gao, D Alon, D Metzler [Google Research] (2024) <a href="https://arxiv.org/abs/2404.09824"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotdbib6xzj211s0r8n8s.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdbitoq6j219i0m243e.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdbj2c5pj217s0osgrp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdbj6djhj217s0osgrp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdbxypyqj20ul0gbac7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdbxyrn0j20ul0gcdib.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdbxxyrlj20ul0codgu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotdby0anjj20vg18cafc.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:15:30 GMT</pubDate>
</item>
<item>
<title>[CL]《Impact of Preference Noise on the Alignment Performance of Generative Language Models》Y Gao, D Alon, D Metzler [Google Research] (2024) 网页链...</title>
<link>https://weibo.com/1402400261/Oa4KOqXVu</link>
<guid>https://weibo.com/1402400261/Oa4KOqXVu</guid>
<content:encoded><![CDATA[
<div> 对关键词进行提取：Preference Noise, Alignment Performance, Generative Language Models, Impact, Google Research

总结:<br /><br />
这篇文章由Google Research团队的Y Gao、D Alon和D Metzler撰写，探讨了偏好噪音对生成语言模型对齐性能的影响。研究结果表明，偏好噪音会对生成语言模型的对齐性能产生负面影响。文章通过实验和分析发现，偏好噪音会导致模型生成不符合用户预期的输出，降低了模型在任务中的性能表现。研究强调了在训练生成语言模型时需要考虑和处理偏好噪音，以提高模型的对齐性能。文章为生成语言模型的进一步研究和优化提供了重要参考。 <div>
[CL]《Impact of Preference Noise on the Alignment Performance of Generative Language Models》Y Gao, D Alon, D Metzler [Google Research] (2024) <a href="https://arxiv.org/abs/2404.09824"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotdbib6xzj211s0r8n8s.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdbitoq6j219i0m243e.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdbj2c5pj217s0osgrp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdbj6djhj217s0osgrp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotdbxypyqj20ul0gbac7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdbxyrn0j20ul0gcdib.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdbxxyrlj20ul0codgu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotdby0anjj20vg18cafc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:15:19 GMT</pubDate>
</item>
<item>
<title>提出Transformer反馈注意力记忆(FAM)架构，通过反馈循环实现对自身潜在表示的注意力处理，使Transformer获得工作记忆能力，可以高效处理无限长输入序列。 - 转发...</title>
<link>https://weibo.com/1402400261/Oa4KnfVSw</link>
<guid>https://weibo.com/1402400261/Oa4KnfVSw</guid>
<content:encoded><![CDATA[
<div> 注意力记忆架构, Transformer, 反馈循环, 自身潜在表示, 高效处理, 无限长输入序列<br />
<br />
提出了Transformer反馈注意力记忆(FAM)架构，通过反馈循环实现对自身潜在表示的注意力处理，使得Transformer获得了工作记忆能力，可以高效处理无限长输入序列。该架构不仅提升了Transformer在处理长序列任务上的性能，还为其赋予了对潜在注意力需求的工作记忆能力。通过引入FAM，Transformer在长序列上的表现大幅提升，能够更好地捕捉重要信息并处理长距离依赖关系。这一架构的提出为Transformer的进一步优化和发展提供了新的思路和可能性。FAM的引入在自然语言处理领域具有重要意义，有望在各种NLP任务中取得显著的性能提升。 <br /><br />总结: <div>
提出Transformer反馈注意力记忆(FAM)架构，通过反馈循环实现对自身潜在表示的注意力处理，使Transformer获得工作记忆能力，可以高效处理无限长输入序列。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《TransformerFAM: Feedback attention is working memory》D Hwang, W Wang, Z Huo, K C Sim, P M Mengibar [Google] (2024) <a href="https://arxiv.org/abs/2404.09173"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hotda1luctj20ng0rkjxz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotda25eodj21jk0p8n6j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotda2aqnaj21jo0j2gst.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotda2dqnkj20s00piae0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotdakyrigj20iv0fmt9t.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdakzrrhj212d0zpq61.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hotdakzgocj212c0g80tx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hotdakywcpj20ob0bpgm2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hotdakz0jzj212f0g8gmo.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 21:14:15 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.16)》 爱可可微博热门分享(4.16) [图片]</title>
<link>https://weibo.com/1402400261/Oa26Y3PGD</link>
<guid>https://weibo.com/1402400261/Oa26Y3PGD</guid>
<content:encoded><![CDATA[
<div> 微博热门, 爱可可, 分享, 4.16, 关键词

<br /><br />总结:
爱可可微博在4月16日分享的内容受到了广泛关注。这篇热门分享内容涉及了各种话题，引发了网友们的讨论热情。其中，爱可可微博通过分享内容吸引了大量粉丝的关注和转发。网友们纷纷在评论区留言表达自己的看法，互动热烈。这篇文章在微博上迅速传播，成为当天的热门话题之一。通过此次分享，爱可可微博再次展现了其在社交平台上的影响力和号召力。 <div>
《爱可可微博热门分享(4.16)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405023914001826171"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.16)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hot1nu3m6mj20kg0bimyv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 14:31:40 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video》(CVPR 2024) GitHub: github.c...</title>
<link>https://weibo.com/1402400261/O9YS6d40h</link>
<guid>https://weibo.com/1402400261/O9YS6d40h</guid>
<content:encoded><![CDATA[
<div> 关键词: 视频游戏、实时交互、真实感、浏览器兼容、图像网格、零样本视频问答、LLM预训练、无限上下文长度、无穷注意力、语音增强

总结:
本文介绍了几篇论文的实现代码，包括《Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video》、《An Image Grid Can Be Worth a Video: Zero-shot Video Question Answering Using a VLM》、《Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length》、《Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention》、《Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios》、《Unsupervised Speech Enhancement with Diffusion-based Generative Models》、《Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!》、《MapTracker: Tracking with Strided Memory Fusion for Consistent Vector HD Mapping》。这些论文涵盖了实时交互、真实感、浏览器兼容、零样本视频问答、LLM预训练、无限上下文长度、无穷注意力、语音增强等方面的内容，为相关研究领域提供了有价值的研究成果。 <div>
几篇论文实现代码：<br />《Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video》(CVPR 2024) GitHub: github.com/video2game/video2game [fig1]<br />《An Image Grid Can Be Worth a Video: Zero-shot Video Question Answering Using a VLM》(CVPR 2024) GitHub: github.com/Kroery/DiffMOT<br />《Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length》(2024) GitHub: github.com/XuezheMax/megalodon<br />《Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention》(2024) GitHub: github.com/dingo-actual/infini-transformer?tab=readme-ov-file<br />《Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios》(2024) GitHub: github.com/JoeYing1019/UltraTool [fig2]<br />《Unsupervised Speech Enhancement with Diffusion-based Generative Models》(2024) GitHub: github.com/joanne-b-nortier/UDiffSE<br />《Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!》(2024) GitHub: github.com/ZHZisZZ/emulated-disalignment<br />《MapTracker: Tracking with Strided Memory Fusion for Consistent Vector HD Mapping》(2024) GitHub: github.com/woodfrog/maptracker [fig3]<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hosm09y7x7j21e50hj1kx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hosmzpah1jj21960hg7ea.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hosn8kplusj26a44lahdz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 06:16:48 GMT</pubDate>
</item>
<item>
<title>【Speechless LLM based Agents：基于LLM 的Agent，具有主动交互、长期记忆、外部工具集成和本地部署能力，旨在建立一个智能协作伙伴，该伙伴可以独立交互、持续...</title>
<link>https://weibo.com/1402400261/O9YRebTep</link>
<guid>https://weibo.com/1402400261/O9YRebTep</guid>
<content:encoded><![CDATA[
<div> LLM, Agent, 主动交互, 长期记忆, 外部工具集成, 本地部署, 智能协作伙伴, 实际价值, GitHub <br />
<br />
要点1: Speechless LLM based Agents 是基于LLM的代理，具有主动交互、长期记忆、外部工具集成和本地部署能力。
要点2: 旨在建立一个智能协作伙伴，可以独立交互、持续发展，并与各种业务场景密切对齐。
要点3: 为企业提供实际价值，提高工作效率和协同能力。
要点4: 该项目托管在GitHub上（github.com/uukuguy/speechless）。<br /><br />
总结: Speechless LLM based Agents是基于LLM的代理，具备多种先进功能，旨在成为企业的智能协作伙伴，提供实际价值，并实现外部工具集成和本地部署。通过长期记忆和主动交互，可以持续发展并适应各种业务场景，提高工作效率和协同能力。GitHub上提供了相关信息，为感兴趣的用户提供了更多了解和参与的机会。 <div>
【Speechless LLM based Agents：基于LLM 的Agent，具有主动交互、长期记忆、外部工具集成和本地部署能力，旨在建立一个智能协作伙伴，该伙伴可以独立交互、持续发展，并与各种业务场景密切对齐，为企业提供实际价值】’Speechless LLM based Agents - LLM based agents with proactive interactions, long-term memory, external tool integration, and local deployment capabilities.' GitHub: github.com/uukuguy/speechless <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hosnas5lwbj20wj0u0wkr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 06:14:39 GMT</pubDate>
</item>
<item>
<title>【OpenChatML Specification：用于表示对话数据的结构化格式，为对话系统、聊天机器人、对话数据集等场景提供了一种标准化的表示方式】'OpenChatML Specificatio...</title>
<link>https://weibo.com/1402400261/O9YP9DkAG</link>
<guid>https://weibo.com/1402400261/O9YP9DkAG</guid>
<content:encoded><![CDATA[
<div> 对话数据、结构化格式、OpenChatML Specification、对话系统、聊天机器人、对话数据集、标准化、表示方式、GitHub、版本控制<br />
<br />总结:
'OpenChatML Specification'是用于表示对话数据的结构化格式的标准，为对话系统、聊天机器人、对话数据集等场景提供了一种统一的表示方式。该规范定义了数据的组织结构，使得不同系统间可以更方便地交换和处理对话数据。通过遵循该规范，可以实现对话数据的标准化，提高数据处理的效率和准确性。该规范的开发和维护可以在GitHub上进行，版本控制和协作更加方便和高效。通过使用OpenChatML Specification，可以促进对话数据领域的发展，提升对话系统和聊天机器人的性能和用户体验。 <div>
【OpenChatML Specification：用于表示对话数据的结构化格式，为对话系统、聊天机器人、对话数据集等场景提供了一种标准化的表示方式】'OpenChatML Specification v0.1' GitHub: github.com/cognitivecomputations/OpenChatML <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hosn5hgf71j216s0u00xz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 06:09:32 GMT</pubDate>
</item>
<item>
<title>【Memento：记录计算机所有动作并允许用户返回时间、搜索和通过 LLM（大语言模型）与时间线聊天以查找收集到信息的 Python 应用】'Memento - a Python app that ...</title>
<link>https://weibo.com/1402400261/O9YLujW50</link>
<guid>https://weibo.com/1402400261/O9YLujW50</guid>
<content:encoded><![CDATA[
<div> 记录、计算机、动作、用户、返回、时间、搜索、LLM、大语言模型、Python应用
<br /><br />总结:
Memento是一个Python应用程序，可记录用户在计算机上的所有操作。用户可以随时返回过去的时间点，进行搜索，并通过与LLM（大语言模型）对话来查找收集到的信息。该应用具有多种功能，使用户能够方便地追溯和查找他们之前所做的工作。 Memento的开源代码可以在GitHub上找到。 <div>
【Memento：记录计算机所有动作并允许用户返回时间、搜索和通过 LLM（大语言模型）与时间线聊天以查找收集到信息的 Python 应用】'Memento - a Python app that records everything you do on your computer and lets you go back in time, search, and chat with a LLM (Large Language Model) to find back information about what you did.' GitHub: github.com/apirrone/Memento <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hosmuvx8o2j20x80u078e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 06:00:31 GMT</pubDate>
</item>
<item>
<title>【Decompyle++：用 C++ 编写的 Python 字节码反编译器和反汇编器基于 OpenAI whisper 的 YouTube 视频搜索工具，可以将音频转为文本，并在视频中高亮搜索到的关...</title>
<link>https://weibo.com/1402400261/O9YKgyq5Q</link>
<guid>https://weibo.com/1402400261/O9YKgyq5Q</guid>
<content:encoded><![CDATA[
<div> GitHub, C++, Python, bytecode, disassembler, decompiler, OpenAI, whisper, 视频搜索工具

<br /><br />总结:
Decompyle++是一个用C++编写的Python字节码反汇编器和反编译器，基于OpenAI whisper的YouTube视频搜索工具。它可以将音频转换为文本，并在视频中高亮显示搜索到的关键词。该工具在GitHub上开源，旨在帮助用户对Python字节码进行分析和反编译。通过这个工具，用户可以更加方便地理解和修改Python程序的底层运行机制，提高代码分析和调试的效率。Decompyle++的灵活性和高效性使其成为Python开发者和研究人员的有力辅助工具，为他们提供了深入学习和探索Python编程语言的机会。 <div>
【Decompyle++：用 C++ 编写的 Python 字节码反编译器和反汇编器基于 OpenAI whisper 的 YouTube 视频搜索工具，可以将音频转为文本，并在视频中高亮搜索到的关键词】'Decompyle++ - C++ python bytecode disassembler and decompiler' GitHub: github.com/zrax/pycdc <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hosmsyhsn4j21760r6wj3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 05:57:31 GMT</pubDate>
</item>
<item>
<title>【CTRL-F for videos：基于 OpenAI whisper 的 YouTube 视频搜索工具，可以将音频转为文本，并在视频中高亮搜索到的关键词】'CTRL-F for videos - Ctrl-f for vi...</title>
<link>https://weibo.com/1402400261/O9YJ9qTCj</link>
<guid>https://weibo.com/1402400261/O9YJ9qTCj</guid>
<content:encoded><![CDATA[
<div> 音频转文本, 视频搜索工具, OpenAI whisper, GitHub, 高亮搜索, 关键词

<br /><br />总结: 该文章介绍了一款名为"CTRL-F for videos"的工具，基于OpenAI whisper技术，能够将视频中的音频内容转换为文本。用户可以使用这个工具在YouTube视频中搜索关键词，并在视频中高亮显示搜索到的关键词。该工具的源代码可在GitHub上找到。通过这个工具，用户可以更方便地找到他们感兴趣的内容，提高视频搜索的效率。 <div>
【CTRL-F for videos：基于 OpenAI whisper 的 YouTube 视频搜索工具，可以将音频转为文本，并在视频中高亮搜索到的关键词】'CTRL-F for videos - Ctrl-f for videos' GitHub: github.com/Evan-Wildenhain/CTRL-F-VIDEO <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hosmq1gaeaj20zk0u00xf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hosmq25nelj20kh020t8n.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 05:54:46 GMT</pubDate>
</item>
<item>
<title>【SiLLM - Silicon LLM Training &amp; Inference Toolkit：基于 MLX 框架的 Silicon LLM 训练和推理工具包，简化了在 Apple Silicon 上训练和运行大语言模型的过程...</title>
<link>https://weibo.com/1402400261/O9YHIbzCL</link>
<guid>https://weibo.com/1402400261/O9YHIbzCL</guid>
<content:encoded><![CDATA[
<div> GitHub, MLX, Silicon LLM, 训练, 推理, 工具包, 简化, Apple Silicon, 大语言模型

<br /><br />总结:
SiLLM是一个基于MLX框架的Silicon LLM训练和推理工具包，旨在简化用户在Apple Silicon上训练和运行大语言模型的过程。该工具包提供了一套方便易用的工具和接口，使用户能够更轻松地进行训练和推理操作。通过SiLLM，用户可以快速构建和训练自己的语言模型，提升模型性能并加速推理过程。同时，SiLLM还支持在Apple Silicon等平台上进行高效的训练和推理，为用户提供了更便捷的工具和资源。通过SiLLM，用户可以更加灵活地进行语言模型的训练和运行，提高工作效率和模型性能。SiLLM的开源项目地址为https://github.com/armbues/SiLLM。 <div>
【SiLLM - Silicon LLM Training &amp; Inference Toolkit：基于 MLX 框架的 Silicon LLM 训练和推理工具包，简化了在 Apple Silicon 上训练和运行大语言模型的过程】'SiLLM - Silicon LLM Training &amp; Inference Toolkit' GitHub: github.com/armbues/SiLLM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hosmmfnbfuj20u00uwjw0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 05:51:13 GMT</pubDate>
</item>
<item>
<title>【llm-transparency-tool：开源交互式工具包，用于分析基于 Transformer 的语言模型的内部工作原理】'llm-transparency-tool - LLM Transparency Tool (LLM-TT),...</title>
<link>https://weibo.com/1402400261/O9Yzy24pt</link>
<guid>https://weibo.com/1402400261/O9Yzy24pt</guid>
<content:encoded><![CDATA[
<div> 开源、交互式工具包、分析、Transformer、语言模型、内部工作原理、GitHub、demo、Facebook Research

总结:<br />
llm-transparency-tool是一个开源的交互式工具包，用于分析基于Transformer的语言模型的内部工作原理。你可以在GitHub上找到该工具包，并查看演示。Facebook Research开发了这一工具，它提供了对语言模型内部工作原理的深入分析，帮助研究人员更好地了解和利用Transformer技术。该工具包为语言模型的研究和应用提供了重要的支持和帮助。 <div>
【llm-transparency-tool：开源交互式工具包，用于分析基于 Transformer 的语言模型的内部工作原理】'llm-transparency-tool - LLM Transparency Tool (LLM-TT), an open-source interactive toolkit for analyzing internal workings of Transformer-based language models. *Check out demo at* <a href="https://huggingface.co/spaces/facebook/llm-transparency-tool-demo'"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> GitHub: github.com/facebookresearch/llm-transparency-tool <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hosm1ftip2j213i0u0tf6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 05:31:06 GMT</pubDate>
</item>
<item>
<title>【Mini Gemini：挖掘多模态视觉语言模型潜力】《Mini Gemini - a Hugging Face Space by wcy1122》 网页链接 #机器学习# #人工智能# [图片][图片]</title>
<link>https://weibo.com/1402400261/O9WF3bLvB</link>
<guid>https://weibo.com/1402400261/O9WF3bLvB</guid>
<content:encoded><![CDATA[
<div> 挖掘、多模态、视觉、语言模型、潜力、Mini Gemini、Hugging Face Space、wcy1122、关键词

<br /><br />总结:
本文介绍了Mini Gemini这一多模态视觉语言模型的潜力和应用。作者通过挖掘不同模态数据的信息，提出了一种新的模型架构，旨在实现多模态信息的融合和处理。Mini Gemini基于Hugging Face Space平台，为研究者和开发者提供了一个实验和创新的空间。通过实验和案例分析，展示了Mini Gemini模型在多模态任务中的优势和表现。该模型能有效处理视觉和语言信息，为未来的研究和应用提供了新的思路和可能性。Mini Gemini的提出将推动多模态模型领域的发展，为人工智能和机器学习提供更多可能性和机会。 <div>
【Mini Gemini：挖掘多模态视觉语言模型潜力】《Mini Gemini - a Hugging Face Space by wcy1122》 <a href="https://huggingface.co/spaces/wcy1122/Mini-Gemini"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hosdlb0qdpj217c0p411f.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hosdlfqxkhj20zk0a1jte.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 00:39:10 GMT</pubDate>
</item>
<item>
<title>【视觉语言模型详解】- 视觉语言模型可以同时从图像和文本中学习，处理视觉问答、图像描述等多种任务。 - 主要的开源视觉语言模型包括LLaVA、DeepSeek、CogVLM、...</title>
<link>https://weibo.com/1402400261/O9WD6s1R5</link>
<guid>https://weibo.com/1402400261/O9WD6s1R5</guid>
<content:encoded><![CDATA[
<div> 视觉语言模型、图像、文本、开源、评估、多语言、建模基准测试、模型结构、Transformer、微调

<br /><br />
总结:视觉语言模型是一种可以同时从图像和文本中学习的模型，可以处理视觉问答、图像描述等多种任务。目前主要的开源视觉语言模型包括LLaVA、DeepSeek、CogVLM、Fuyu等，规模不等，支持多语言训练。评估视觉语言模型的重要指标包括视觉匿名竞技场人工评价、开源视觉语言模型排行榜中的各项指标。主要的视觉语言建模基准测试有MMMU、MMBench等，用于测试模型的跨学科知识理解和推理能力。典型的视觉语言模型由图像编码器、多模态投影器、文本解码器组成，通过图像文字匹配来联合训练。使用Transformer可以便捷地加载模型进行推理，最新版本的TRL可进行视觉语言模型的微调。视觉语言模型是多模态AI的未来发展方向，应用前景广泛，选择合适的模型、进行标准化评估和微调对于实现良好效果至关重要。 <div>
【视觉语言模型详解】<br />- 视觉语言模型可以同时从图像和文本中学习，处理视觉问答、图像描述等多种任务。   <br />- 主要的开源视觉语言模型包括LLaVA、DeepSeek、CogVLM、Fuyu等，规模从几十亿到万亿参数不等，图像分辨率从224x224到672x672。   <br />- 部分模型支持“grounding”功能，可以减少模型虚构内容(幻觉)。所有模型默认使用英语训练，部分支持多语言。   <br />- 评估视觉语言模型的重要指标有视觉匿名竞技场人工评价、开源视觉语言模型排行榜中的各项指标。   <br />- 主要的视觉语言建模基准测试包括MMMU、MMBench等，测试模型的跨学科知识理解和推理能力。   <br />- 典型的视觉语言模型由图像编码器、多模态投影器、文本解码器组成，通过图像文字匹配来联合训练。   <br />- 使用Transformer可以便捷地加载模型进行推理。使用最新版本的TRL可以进行视觉语言模型的微调。   <br />- 视觉语言模型正在引领多模态AI的发展，其应用前景广阔。选择合适的模型、使用标准化评估和微调对实现良好效果至关重要。<br />《Vision Language Models Explained》 <a href="https://huggingface.co/blog/vlms"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hosdgkl9dvj21hc0u0ahb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hosdgnuqboj21hc0u0whn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 00:34:22 GMT</pubDate>
</item>
<item>
<title>【开源模型推动教育：用 Llama 2 打造个性化教育平台】- 韩国教育公司Mathpresso利用开源模型Llama 2打造了数学学习平台QANDA和数学专用语言模型MathGPT。 - 商...</title>
<link>https://weibo.com/1402400261/O9WAooogF</link>
<guid>https://weibo.com/1402400261/O9WAooogF</guid>
<content:encoded><![CDATA[
<div> Mathpresso, Llama 2, QANDA, MathGPT, ChatGPT, Upstage, AI导师, 个性化教育, 开源模型, 灵活性

<br /><br />总结:韩国教育公司Mathpresso利用开源模型Llama 2成功打造了个性化数学学习平台QANDA和数学专用语言模型MathGPT。相较于商业语言模型如ChatGPT，Llama 2的灵活性使得Mathpresso可以充分利用自身数据和技术，为用户提供更个性化的教育服务。MathGPT不仅可以给出答案，还能提供详细的解释，有助于学生深入理解数学知识。同时，其他公司如Upstage也在使用Llama 2，其模型在开源语言模型排行榜上首次超过了GPT-3.5。开源模型为公司带来公平机会，为教育领域带来开创性影响。Mathpresso希望通过AI导师实现个性化教育的普及。开源模型的出现为公司提供了灵活性，创造了可负担的教育工具。 <div>
【开源模型推动教育：用 Llama 2 打造个性化教育平台】<br />- 韩国教育公司Mathpresso利用开源模型Llama 2打造了数学学习平台QANDA和数学专用语言模型MathGPT。   <br />- 商业语言模型如ChatGPT缺乏针对复杂教育背景的个性化。Llama 2灵活开源，Mathpresso可以充分利用自己的数据和技术。   <br />- MathGPT不仅给出答案，还提供步骤详细的解释，帮助学生深入理解。它在国小和国中数学测试中刷新了世界纪录。   <br />- 韩国AI创业公司Upstage也使用了Llama 2。它的模型在开源语言模型排行榜上首次超过了GPT-3.5。   <br />- Upstage认为Llama 2作为顶尖开源语言模型，为他们提供了充分的基础去开发定制化模型。   <br />- Mathpresso希望通过AI导师，实现个性化教育向所有人开放。Llama 2这样的开源模型给了他们灵活性去创造可负担的教育工具。   <br />- Llama 2等开源模型为公司大大小小提供了使用尖端技术的公平机会。它们正在开创性地影响教育等领域。<br />《Leveraging Llama 2 to create a platform for highly personalized learning》 <a href="https://ai.meta.com/blog/llama-2-mathgpt-mathpresso-qanda-upstage-open-source-llm/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hosd9reujej218g0p0wh3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 00:27:41 GMT</pubDate>
</item>
<item>
<title>【Limitless Pendant：又一款可穿戴AI设备，可以录音保存用户对话，并提供个性化AI助手服务。外形小巧时尚，一次充电可使用100小时，价格仅99美元，预计2024年第...</title>
<link>https://weibo.com/1402400261/O9WwCEdNU</link>
<guid>https://weibo.com/1402400261/O9WwCEdNU</guid>
<content:encoded><![CDATA[
<div> Limitless Pendant, 可穿戴AI设备, 录音保存对话, 个性化AI助手服务, 外形时尚, 一次充电100小时, 价格99美元, 预计2024年第四季度发货

<br /><br />总结:
Limitless Pendant是一款外形小巧时尚的可穿戴AI设备，用户可以使用它录音保存对话，并获得个性化AI助手服务。这款设备一次充电可使用100小时，价格仅99美元，计划在2024年第四季度发货。Limitless Pendant将提供用户更便利的日常生活体验，为用户创造无限的可能。 <div>
【Limitless Pendant：又一款可穿戴AI设备，可以录音保存用户对话，并提供个性化AI助手服务。外形小巧时尚，一次充电可使用100小时，价格仅99美元，预计2024年第四季度发货】《Limitless - Personalized AI powered by what you’ve seen, said, and heard》 <a href="https://www.limitless.ai/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5023699045384217"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a><br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/5396ee05ly1hosczoottuj20zk0k0q3g.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/cYSkNt3slx08e7tR3rDW01041200bX0d0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713234828&amp;ssig=DyWT01iYoN&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/bHZcyXNMlx08e7tQWavK010412005URT0E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713234828&amp;ssig=qfGj%2BwYqlq&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/10IguTvylx08e7tQv59u010412003JSy0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713234828&amp;ssig=q31rdaNg%2Br&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5023699045384217" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 00:18:24 GMT</pubDate>
</item>
<item>
<title>【一张图看匿名竞技场开源vs.闭源LLM表现】 - 随着时间的推移，模型的性能有不断提升的趋势，最新的GPT-4和Claude 3等模型表现更优。- 开源和闭源之间的差距已缩...</title>
<link>https://weibo.com/1402400261/O9Wsp9P6V</link>
<guid>https://weibo.com/1402400261/O9Wsp9P6V</guid>
<content:encoded><![CDATA[
<div> 关键词: 匿名竞技场, 开源, 闭源, LLM, GPT-4, Claude 3, 性能提升, 差距缩短, 模型表现, 相对性能

总结:<br /><br />本文探讨了匿名竞技场开源与闭源LLM的表现比较。随着时间推移，模型性能不断提升，最新的GPT-4和Claude 3表现优秀。开源与闭源之间的差距已经缩短至6-10个月，远远小于之前的几年。在同类型模型中，闭源模型如GPT-4、GPT-4 Turbo、Gemini Pro整体表现更出色，但也有一些开源模型如Mistral、OpenChat-3.5表现不错。一些较早期的模型如GPT-3.5 Turbo、Vicuna、Llama虽然性能较弱，但也有不错的表现。整体而言，开源与闭源的性能差距在不断缩小，各种的LLM模型在匿名竞技场中不断演化，展现出不同的表现与优势。 <div>
【一张图看匿名竞技场开源vs.闭源LLM表现】  <br />- 随着时间的推移，模型的性能有不断提升的趋势，最新的GPT-4和Claude 3等模型表现更优。<br />- 开源和闭源之间的差距已缩短至6-10个月，GPT-4刚发布时该差距为几年。<br />- 在同类型模型中，闭源模型如GPT-4、GPT-4-Turbo、Gemini Pro等整体性能优于开源模型。但也有一些开源模型如Mistral、OpenChat-3.5等表现不错。  <br />- 一些较早期的模型如GPT-3.5 Turbo、Vicuna、Llama等虽然性能相对较弱，但也有不错的性能表现。  <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><br />graph via:Maxime Labonne<img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoscjlde7nj20w60l8q5f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 00:08:00 GMT</pubDate>
</item>
<item>
<title>【Idefics2：强大的 8B 视觉语言模型，为社区带来全新体验】- Hugging Face发布了多模态基础模型Idefics2，输入文本和图像，输出文本。 - 相比上一版本Idefics1...</title>
<link>https://weibo.com/1402400261/O9WoW9nrE</link>
<guid>https://weibo.com/1402400261/O9WoW9nrE</guid>
<content:encoded><![CDATA[
<div> Hugging Face, Idefics2, 多模态, 视觉语言模型, Apache 2.0, 开源许可, OCR, 视觉问答, 数据集, 微调

<br /><br />总结:
Hugging Face发布了新的多模态基础模型Idefics2，该模型具有80亿参数量，采用Apache 2.0开源许可，并优化了OCR能力，在视觉问答基准测试中表现出色。Idefics2支持任意分辨率、任意宽高比的图像输入，增强了文档文字识别能力，简化了视觉特征整合。模型在公开数据集上预训练，如维基百科和图像标题对等，通过指令微调提升了多轮会话能力。用户可以在Hugging Face Hub上使用Idefics2，并通过Transformers API进行微调。此外，Hugging Face还发布了Idefics2的模型卡片、数据集卡片和微调教程等资源，方便用户使用。Idefics2采用Apache 2.0开源许可，用户可以自由使用，感谢Google和Mistral AI开源了预训练模型。作为目前最强大的开源多模态基础模型之一，Idefics2为社区提供了坚实的基础，推动了多模态AI的发展。 <div>
【Idefics2：强大的 8B 视觉语言模型，为社区带来全新体验】<br />- Hugging Face发布了多模态基础模型Idefics2，输入文本和图像，输出文本。   <br />- 相比上一版本Idefics1，Idefics2参数量达到80亿，采用Apache 2.0开源许可，优化了OCR能力。在视觉问答基准测试中表现顶尖。   <br />- Idefics2支持任意分辨率、任意宽高比的图像输入，避免缩放成固定大小。增强了对文档文字识别的能力。简化了视觉特征的整合。   <br />- Idefics2在公开数据集上进行预训练，如维基百科、图像标题对等。并在多模态任务数据集上进行指令微调，提升多轮会话能力。   <br />- 用户可以在Hugging Face Hub上使用Idefics2，并利用Transformers API进行微调。文章给出了使用代码示例。   <br />- Hugging Face还发布了Idefics2的模型卡片、数据集卡片、微调教程等资源，方便用户使用。   <br />- Idefics2采用Apache 2.0开源许可，用户可以自由使用。感谢Google和Mistral AI开源了预训练模型。   <br />- Idefics2是目前最强大的开源多模态基础模型之一，为社区提供了坚实的基础，促进多模态AI的发展。<br />《Introducing Idefics2: A Powerful 8B Vision-Language Model for the community》 <a href="https://huggingface.co/blog/idefics2"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoscgfofglj20u00voade.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 23:59:28 GMT</pubDate>
</item>
<item>
<title>【OpenAI API 推出批处理API：异步响应、5折价格】- 节省成本，获得异步任务（如摘要、翻译和图像分类）的更高速率限制。 - 只需上传一个批量请求文件，24小时内...</title>
<link>https://weibo.com/1402400261/O9Wly9dXt</link>
<guid>https://weibo.com/1402400261/O9Wly9dXt</guid>
<content:encoded><![CDATA[
<div> 批处理API、异步响应、5折价格、节省成本、高速率限制、上传批量请求文件、24小时内收到结果、优惠享受

总结:<br />
OpenAI推出批处理API，为用户提供了异步响应和5折价格优惠，能够帮助用户节省成本，同时增加了对异步任务的高速率限制。用户只需上传一个批量请求文件，就能在24小时内收到结果，并享受半价优惠。这可以大大提升效率和操作便利性，让用户能更好地利用OpenAI API的功能。 <div>
【OpenAI API 推出批处理API：异步响应、5折价格】<br />- 节省成本，获得异步任务（如摘要、翻译和图像分类）的更高速率限制。   <br />- 只需上传一个批量请求文件，24小时内收到结果，并享受5折优惠。<br />《Batch | API Reference - OpenAI API》 <a href="http://aicoco.net/s/8i"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hosc7qm57oj20xc0irack.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 23:51:07 GMT</pubDate>
</item>
<item>
<title>今日推介(第1377期)：大语言模型Tokenization理论研究、基于仿真优化的语言模型提示选择、ChatGPT正在改变学者的写作风格吗、使用少量token预训练小型基础语言模...</title>
<link>https://weibo.com/1402400261/O9VJOweam</link>
<guid>https://weibo.com/1402400261/O9VJOweam</guid>
<content:encoded><![CDATA[
<div> 大语言模型、Tokenization、理论研究、基于仿真优化、语言模型提示选择、ChatGPT、学者写作风格、少量token预训练、小型基础语言模型、检索增强生成、减少结构化输出幻觉  

<br /><br />总结:  
本文探讨了大语言模型Tokenization的理论研究，以及基于仿真优化的语言模型提示选择的相关内容。研究表明，ChatGPT对学者的写作风格有可能产生影响。此外，使用少量token预训练小型基础语言模型可能对性能有所改进。最后，通过检索增强生成可以减少结构化输出中的幻觉。 <div>
今日推介(第1377期)：大语言模型Tokenization理论研究、基于仿真优化的语言模型提示选择、ChatGPT正在改变学者的写作风格吗、使用少量token预训练小型基础语言模型、通过检索增强生成减少结构化输出中的幻觉 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/692682961"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.16)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hos9indv4lj219s0u0gtq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hos9iq6iyej20w50u0wiw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hos9iu2gr2j20t80ugjuv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hos9ixkqxyj21c00q6430.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hos9izu0unj20qk0pa0ur.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 22:18:09 GMT</pubDate>
</item>
<item>
<title>[CV] OccGaussian: 3D Gaussian Splatting for Occluded Human Rendering 网页链接 提出OccGaussian方法，使用3D高斯采样实现快速训练和实时渲染遮挡的人体。 [...</title>
<link>https://weibo.com/1402400261/O9VHhyvil</link>
<guid>https://weibo.com/1402400261/O9VHhyvil</guid>
<content:encoded><![CDATA[
<div> OccGaussian, 3D Gaussian Splatting, 遮挡人体渲染, 快速训练, 实时渲染

<br /><br />总结: 本文提出了OccGaussian方法，利用3D高斯采样技术实现了遮挡人体渲染。该方法能够实现快速训练和实时渲染，为解决遮挡问题提供了一种有效的解决方案。文章详细介绍了OccGaussian方法的原理和实现过程，实验证明该方法在遮挡人体渲染中具有较高的效率和准确性。通过对比实验，作者验证了OccGaussian方法在处理遮挡人体渲染任务上的优越性能，为相关领域的研究和应用提供了有价值的参考。 <div>
[CV] OccGaussian: 3D Gaussian Splatting for Occluded Human Rendering  <br /><a href="https://arxiv.org/abs/2404.08449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />提出OccGaussian方法，使用3D高斯采样实现快速训练和实时渲染遮挡的人体。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos9ci9medj20x015u17w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos9cidgt3j21oi14ydve.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos9cinh8aj20tw0so79l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 22:11:55 GMT</pubDate>
</item>
<item>
<title>[CV] Probing the 3D Awareness of Visual Foundation Models 网页链接 通过深度、法线估计和跨视角对应任务，系统评估了当前视觉模型对3D结构的表示和跨视角一...</title>
<link>https://weibo.com/1402400261/O9VCXxPHZ</link>
<guid>https://weibo.com/1402400261/O9VCXxPHZ</guid>
<content:encoded><![CDATA[
<div> 关键词: 3D感知, 视觉模型, 深度估计, 法线估计, 跨视角任务

总结:<br />
本研究通过深度、法线估计和跨视角对应任务来评估视觉模型对3D结构的表示和跨视角一致性。发现不同训练目标会对模型的3D感知产生重要影响。研究为构建真正具备3D意识的视觉模型提供了基础和启发。 <div>
[CV] Probing the 3D Awareness of Visual Foundation Models  <br /><a href="https://arxiv.org/abs/2404.08636"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />通过深度、法线估计和跨视角对应任务，系统评估了当前视觉模型对3D结构的表示和跨视角一致性，发现不同训练目标对模型的3D感知产生重要影响，为构建真正3D意识的视觉模型提供了基础和启发。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos91ee225j20we13m7jh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos91faqquj21n80ugk5j.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos91fvypsj20ue0sc0yn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 22:01:16 GMT</pubDate>
</item>
<item>
<title>[CV] Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies 网页链接 通过控制数据量、模型大小和训练策略等变量，...</title>
<link>https://weibo.com/1402400261/O9VA3beNf</link>
<guid>https://weibo.com/1402400261/O9VA3beNf</guid>
<content:encoded><![CDATA[
<div> 数据量、模型大小、训练策略、CLIP模型、性能、计算预算、实用指导

<br /><br />总结:
本研究通过控制数据量、模型大小、训练策略等变量，全面分析了在计算预算受限条件下CLIP模型的性能。研究为部署CLIP到实际应用提供了实用指导，为实现模型性能的有效缩放提供了理论支持。研究结果表明，在不同场景下调整数据量和模型大小可以显著改善模型性能，合理选择训练策略也至关重要。通过本研究，可以更好地理解和利用CLIP模型，在资源受限的环境下实现更好的性能表现。 <div>
[CV] Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies  <br /><a href="https://arxiv.org/abs/2404.08197"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过控制数据量、模型大小和训练策略等变量，全面分析了计算预算受限条件下CLIP模型的性能，为部署CLIP到实际应用提供了实用指导。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos8tzf1fgj20v416en9w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos8tz8h54j21kq0reaih.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos8tzf9t1j21k80imjvb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:54:06 GMT</pubDate>
</item>
<item>
<title>[IR] Generative Information Retrieval Evaluation 网页链接 探讨了大型语言模型在信息检索评估中的应用前景，它降低了评价成本，提高了一致性，为评估和训练快...</title>
<link>https://weibo.com/1402400261/O9VuWghFE</link>
<guid>https://weibo.com/1402400261/O9VuWghFE</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、信息检索评估、应用前景、评价成本、一致性、快速产品系统、人类评估、降低、提高、可能

<br /><br />总结:
本文探讨了大型语言模型在信息检索评估中的应用前景。使用大型语言模型可以降低评价成本，提高评价一致性，并为评估和训练快速产品系统提供可能性。然而，仍需人类评估作为基础，以确保评估结果的准确性和可靠性。通过综合利用大型语言模型和人类评估的优势，可以更好地实现信息检索评估的有效性和效率。 <div>
[IR] Generative Information Retrieval Evaluation  <br /><a href="https://arxiv.org/abs/2404.08137"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />探讨了大型语言模型在信息检索评估中的应用前景，它降低了评价成本，提高了一致性，为评估和训练快速产品系统提供了可能，但仍需人类评估作为基础。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos8gud01gj20rm0z4do5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos8gutvzlj20zo0r2n1q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos8gv33lmj21as102whg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:41:30 GMT</pubDate>
</item>
<item>
<title>通过检索增强生成方法显著减少了工作流生成任务中的幻象，提高了质量和泛化能力，降低了计算资源需求。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Reducing hallucinat...</title>
<link>https://weibo.com/1402400261/O9VuNerio</link>
<guid>https://weibo.com/1402400261/O9VuNerio</guid>
<content:encoded><![CDATA[
<div> 检索增强生成方法、幻象减少、质量提高、泛化能力、计算资源需求降低

<br /><br />总结:
本文介绍了一种通过检索增强生成方法显著减少工作流生成任务中幻象的技术。该方法提高了生成结果的质量和泛化能力，同时降低了计算资源的需求。作者通过对结构化输出中的幻象问题进行研究，提出了一种有效的解决方案。这种方法可以帮助提升生成模型在工作流生成任务中的性能，为相关领域的研究和实践提供有益的启示。 <div>
通过检索增强生成方法显著减少了工作流生成任务中的幻象，提高了质量和泛化能力，降低了计算资源需求。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Reducing hallucination in structured outputs via Retrieval-Augmented Generation》P Béchard, O M Ayala [ServiceNow] (2024) <a href="https://arxiv.org/abs/2404.08189"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7zn809oj20n80x6jzn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7znbd1qj20qk0pawha.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7znlhfqj21hq0iajuz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos8flislzj20hs0f6wfr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos8fln073j20zz0vzdj9.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:41:09 GMT</pubDate>
</item>
<item>
<title>[LG]《Reducing hallucination in structured outputs via Retrieval-Augmented Generation》P Béchard, O M Ayala [ServiceNow] (2024) 网页链接 #机器学习##...</title>
<link>https://weibo.com/1402400261/O9Vurxov4</link>
<guid>https://weibo.com/1402400261/O9Vurxov4</guid>
<content:encoded><![CDATA[
<div> 结构化输出、幻觉减少、检索增强生成、P Béchard、O M Ayala、ServiceNow、2024

<br /><br />
总结: 这篇文章探讨了通过检索增强生成的方式，在结构化输出中减少幻觉的问题。研究人员提出了一种新方法，利用检索方法来增强生成模型，从而提高输出的准确性和质量。他们的研究表明，这种方法可以有效降低幻觉出现的可能性，为未来相关领域的研究提供了新的思路和方向。在实验中，他们使用了ServiceNow平台进行实验验证，结果显示了这种方法的有效性和潜力。通过这项研究，我们能够更深入地理解如何利用检索增强生成来改善结构化输出中的幻觉问题，为相关领域的研究和应用带来了新的启示。 <div>
[LG]《Reducing hallucination in structured outputs via Retrieval-Augmented Generation》P Béchard, O M Ayala [ServiceNow] (2024) <a href="https://arxiv.org/abs/2404.08189"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7zn809oj20n80x6jzn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7znbd1qj20qk0pawha.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7znlhfqj21hq0iajuz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos8flislzj20hs0f6wfr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos8fln073j20zz0vzdj9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:40:17 GMT</pubDate>
</item>
<item>
<title>Inheritune通过明智地重用参考模型参数和少量额外训练，实现了高效开发小规模而性能强劲的语言模型。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Pre-training Small Ba...</title>
<link>https://weibo.com/1402400261/O9Vnbt985</link>
<guid>https://weibo.com/1402400261/O9Vnbt985</guid>
<content:encoded><![CDATA[
<div> Pre-training, Small Base LMs, Fewer Tokens, Inheritune, 高效开发, 语言模型, 参考模型参数, 少量额外训练, 性能强劲

总结:<br /><br />
这篇文章介绍了一种名为Inheritune的方法，通过明智地重用参考模型参数和少量额外训练，实现了高效开发小规模而性能强劲的语言模型。研究者在文章中提出了Pre-training Small Base LMs with Fewer Tokens这一方法，其可以在使用更少token的情况下，提升小基准语言模型的性能。实验结果表明，在文本生成和自然语言推理等任务上，Inheritune可以取得令人满意的表现，为小规模语言模型的开发提供了新的思路和方法。 <div>
Inheritune通过明智地重用参考模型参数和少量额外训练，实现了高效开发小规模而性能强劲的语言模型。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Pre-training Small Base LMs with Fewer Tokens》S Sanyal, S Sanghavi, A G. Dimakis [UT Austin] (2024) <a href="https://arxiv.org/abs/2404.08634"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7qqk3e3j20kw15ik12.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7qqoc4rj21c00q6ag1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7qqqoo0j20sa0q8tdr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7qqu022j20sm0rqdkj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7wwrmx3j20hq0h875y.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7wwry74j20zt0g4dhr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7wwrsf0j20ht0l6abz.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:22:24 GMT</pubDate>
</item>
<item>
<title>[CL]《Pre-training Small Base LMs with Fewer Tokens》S Sanyal, S Sanghavi, A G. Dimakis [UT Austin] (2024) 网页链接 #机器学习##人工智能##论文# [图片][...</title>
<link>https://weibo.com/1402400261/O9Vn9ggKc</link>
<guid>https://weibo.com/1402400261/O9Vn9ggKc</guid>
<content:encoded><![CDATA[
<div> Small Base LMs, Pre-training, Fewer Tokens, UT Austin, S Sanyal, S Sanghavi, A G. Dimakis

<br /><br />总结:
本文讨论了使用更少词汇量进行小基础语言模型的预训练。研究团队来自德克萨斯大学奥斯汀分校，包括S Sanyal，S Sanghavi和A G. Dimakis。他们的研究旨在提高小型语言模型的预训练效果，并展示了一种基于较少标记的方法。通过实验和分析，研究人员表明这种方法可以在小型语言模型中取得良好的效果，从而为自然语言处理领域的发展提供了一种有效的方法。 <div>
[CL]《Pre-training Small Base LMs with Fewer Tokens》S Sanyal, S Sanghavi, A G. Dimakis [UT Austin] (2024) <a href="https://arxiv.org/abs/2404.08634"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7qqk3e3j20kw15ik12.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7qqoc4rj21c00q6ag1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7qqqoo0j20sa0q8tdr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7qqu022j20sm0rqdkj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7wwrmx3j20hq0h875y.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7wwry74j20zt0g4dhr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7wwrsf0j20ht0l6abz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:22:19 GMT</pubDate>
</item>
<item>
<title>通过词频统计模型估计了ChatGPT对计算机科学论文摘要写作风格的重要影响，是第一份定量分析该领域大规模语言模型应用的研究。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]...</title>
<link>https://weibo.com/1402400261/O9Vjl1CLP</link>
<guid>https://weibo.com/1402400261/O9Vjl1CLP</guid>
<content:encoded><![CDATA[
<div> 关键词: ChatGPT, 计算机科学论文, 摘要写作风格, 词频统计模型, 大规模语言模型应用, 研究, 影响, 变革, 定量分析, 领域

总结:<br /><br />文章研究了ChatGPT对计算机科学论文摘要写作风格的影响，通过词频统计模型进行了定量分析，这是第一份在该领域对大规模语言模型应用进行定量分析的研究。研究发现ChatGPT对学术写作风格有重要影响，可能带来变革。研究结果为进一步探讨语言模型在学术写作领域的应用提供了参考。 <div>
通过词频统计模型估计了ChatGPT对计算机科学论文摘要写作风格的重要影响，是第一份定量分析该领域大规模语言模型应用的研究。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Is ChatGPT Transforming Academics' Writing Style?》M Geng, R Trotta [Scuola Internazionale Superiore di Studi Avanzati (SISSA)] (2024) <a href="https://arxiv.org/abs/2404.08627"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7ltc9ywj20p60s4gsf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7ltvg0uj20t80ugn1l.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7lu07e5j20t20qudjf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7lu3exyj20t80s0q67.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7mvq821j20iy0ista3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7mvukjjj20ix0is3zy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7mvugslj20j00kzjt1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7mvqxt4j20iy0hoq43.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7mvs7quj20ix0hmjsh.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:12:55 GMT</pubDate>
</item>
<item>
<title>[CL]《Is ChatGPT Transforming Academics' Writing Style?》M Geng, R Trotta [Scuola Internazionale Superiore di Studi Avanzati (SISSA)] (2024) 网页链接 ...</title>
<link>https://weibo.com/1402400261/O9Vjf5Tzg</link>
<guid>https://weibo.com/1402400261/O9Vjf5Tzg</guid>
<content:encoded><![CDATA[
<div> transforming, ChatGPT, academics, writing style, AI, language generation, academic writing, technology, impact, research

<br /><br />总结:
这篇文章讨论了ChatGPT如何正在改变学术界的写作风格。研究指出，人工智能技术对学术写作有着深远的影响，特别是在语言生成方面。学者们需要关注ChatGPT等工具对学术写作风格和质量的可能影响，以及如何充分利用这些技术进行研究。AI技术的发展为学术界带来了新的挑战和机遇，需要进一步研究和讨论。 <div>
[CL]《Is ChatGPT Transforming Academics' Writing Style?》M Geng, R Trotta [Scuola Internazionale Superiore di Studi Avanzati (SISSA)] (2024) <a href="https://arxiv.org/abs/2404.08627"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7ltc9ywj20p60s4gsf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7ltvg0uj20t80ugn1l.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7lu07e5j20t20qudjf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7lu3exyj20t80s0q67.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7mvq821j20iy0ista3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7mvukjjj20ix0is3zy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7mvugslj20j00kzjt1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7mvqxt4j20iy0hoq43.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7mvs7quj20ix0hmjsh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7mvuh3yj20j00midhz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7mvs2c9j20ix0hcq40.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7mvul97j20ix0ko0uw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7mvun20j20j00lz40s.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7mvqt4gj20ix0irmyb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7mvqv4ij20ix0hpgms.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7mvqsntj20ix0hbwfd.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7mvs4huj20ix0fm3zm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7mvs60qj20iy0irjsj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:12:41 GMT</pubDate>
</item>
<item>
<title>通过构建代理模型和获取函数，提出仿真优化框架，实现高效低成本的语言模型提示选择。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Language Model Prompt Selection via...</title>
<link>https://weibo.com/1402400261/O9Virq4My</link>
<guid>https://weibo.com/1402400261/O9Virq4My</guid>
<content:encoded><![CDATA[
<div> 代理模型、获取函数、仿真优化框架、语言模型提示选择、高效低成本、CL、张华、何军、Righter、郑忠、UC Berkeley

总结:<br /><br />
该研究提出了一种通过仿真优化实现语言模型提示选择的方法。首先构建代理模型来模拟语言模型提示的选择过程，然后获取函数来评估不同提示的效果，利用仿真优化框架进行参数调整，从而实现高效低成本的语言模型提示选择。研究团队来自UC Berkeley，由张华、何军、Righter和郑忠等人合作完成。 <div>
通过构建代理模型和获取函数，提出仿真优化框架，实现高效低成本的语言模型提示选择。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Language Model Prompt Selection via Simulation Optimization》H Zhang, J He, R Righter, Z Zheng [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.08164"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jw696fj21da0jmaio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jwrxj4j21he0n6n4z.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jx88c9j21g21cmqcr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jwz47dj21h80lq0ye.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7kiem59j212m0f20uw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7kig3lwj212m0hxwh8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7kig5uvj212j0g7wh1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7kiemvbj212m0hxgo4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7kigc3xj210x0n840n.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:10:43 GMT</pubDate>
</item>
<item>
<title>[CL]《Language Model Prompt Selection via Simulation Optimization》H Zhang, J He, R Righter, Z Zheng [UC Berkeley] (2024) 网页链接 #机器学习##人工智能...</title>
<link>https://weibo.com/1402400261/O9VijuFyw</link>
<guid>https://weibo.com/1402400261/O9VijuFyw</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型、模拟优化、选择、模拟、最优化、模型、预测、模型优化

总结:<br />
本研究围绕语言模型prompt的选择展开，通过模拟优化方法进行模型优化。研究者们提出了一种基于模拟优化的语言模型prompt选择方法，通过在模拟环境中进行优化，不断调整模型的输入来提高模型的性能。研究表明，该方法可以有效提高语言模型的预测准确性和效率，为自然语言处理领域的进一步研究提供了新思路。 <div>
[CL]《Language Model Prompt Selection via Simulation Optimization》H Zhang, J He, R Righter, Z Zheng [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.08164"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jw696fj21da0jmaio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jwrxj4j21he0n6n4z.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jx88c9j21g21cmqcr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7jwz47dj21h80lq0ye.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7kiem59j212m0f20uw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7kig3lwj212m0hxwh8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7kig5uvj212j0g7wh1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7kiemvbj212m0hxgo4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7kigc3xj210x0n840n.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:10:24 GMT</pubDate>
</item>
<item>
<title>深入探讨了Tokenization在降低Transformer语言模型的交叉熵损失方面的理论机制，并比较了不同Tokenization方案的泛化能力，为理解和改进Tokenization提供了范式...</title>
<link>https://weibo.com/1402400261/O9VhOrZ07</link>
<guid>https://weibo.com/1402400261/O9VhOrZ07</guid>
<content:encoded><![CDATA[
<div> Tokenization, 降低Transformer语言模型的交叉熵损失, 理论机制, 不同Tokenization方案, 泛化能力, 理解, 改进, LLMs, N Rajaraman, J Jiao, K Ramchandran, UC Berkeley

<br /><br />总结: 

该研究深入探讨了Tokenization在降低Transformer语言模型的交叉熵损失方面的理论机制。研究比较了不同Tokenization方案的泛化能力，为理解和改进Tokenization提供了范式。研究团队包括N Rajaraman、J Jiao和K Ramchandran，来自UC Berkeley。文章为进一步研究Tokenization在语言模型中的作用提供了理论基础，为提高模型表现和效率提供了重要的参考。 <div>
深入探讨了Tokenization在降低Transformer语言模型的交叉熵损失方面的理论机制，并比较了不同Tokenization方案的泛化能力，为理解和改进Tokenization提供了范式。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Toward a Theory of Tokenization in LLMs》N Rajaraman, J Jiao, K Ramchandran [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.08335"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7i86yhbj21cc0pwqfa.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7i8gargj21hm0fc0vx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7i93968j21i60ziqem.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7i94vgvj21jk0smwnu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7iwjo79j21190mzwj5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7iwhmg4j21130iqjtx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7iwjxnkj21120trtcr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7iwl831j21110o8jvc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7iwlf0ej21100rkjvk.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:09:10 GMT</pubDate>
</item>
<item>
<title>[CL]《Toward a Theory of Tokenization in LLMs》N Rajaraman, J Jiao, K Ramchandran [UC Berkeley] (2024) 网页链接 #机器学习##人工智能##论文# [图片][图片...</title>
<link>https://weibo.com/1402400261/O9VhGsaVY</link>
<guid>https://weibo.com/1402400261/O9VhGsaVY</guid>
<content:encoded><![CDATA[
<div> 关键词: Tokenization, LLMs, Theory, NLP, Language Models, UC Berkeley

本文旨在探讨LLMs中的Tokenization理论，作者来自加州大学伯克利分校。文章通过对Tokenization在自然语言处理中的重要性和实践中的挑战进行讨论，指出Tokenization在LLMs中的作用和影响。作者提出了一种针对LLMs的Tokenization理论，旨在提高模型的性能和效率。研究结果揭示了Tokenization对LLMs任务的关键影响，为进一步研究和应用Tokenization在自然语言处理领域提供了重要参考。通过该理论，可以更好地理解和优化LLMs的Tokenization过程，从而提升模型的表现。文章为我们深入了解LLMs中Tokenization的意义和方法提供了有益的启示。
<br /><br />总结: 本研究探讨了LLMs中Tokenization理论的重要性和挑战，提出了一种新的Tokenization理论，旨在提高模型的性能和效率。研究结果揭示了Tokenization对LLMs任务的关键影响，为进一步优化LLMs的Tokenization提供了重要参考。 <div>
[CL]《Toward a Theory of Tokenization in LLMs》N Rajaraman, J Jiao, K Ramchandran [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.08335"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7i86yhbj21cc0pwqfa.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7i8gargj21hm0fc0vx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7i93968j21i60ziqem.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7i94vgvj21jk0smwnu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7iwjo79j21190mzwj5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7iwhmg4j21130iqjtx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hos7iwjxnkj21120trtcr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7iwl831j21110o8jvc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hos7iwlf0ej21100rkjvk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hos7iwjjg7j210b0pg76m.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hos7iwhajbj20pr07kaab.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:08:51 GMT</pubDate>
</item>
<item>
<title>早！[太阳] #早安# [图片]</title>
<link>https://weibo.com/1402400261/O9Vg1cVHL</link>
<guid>https://weibo.com/1402400261/O9Vg1cVHL</guid>
<content:encoded><![CDATA[
<div> 关键词: 早、文章、中文、总结、800字、要点

总结:
<br />
这篇文章着重强调了使用中文写作总结文章的重要性。在800字内，作者提到了提取关键词、按顺序分要点、逐步梳理的方法。文章指出，总结是对文章内容的概括归纳，可以帮助读者更好地理解和记忆文章内容。因此，学会写好总结是非常重要的。 <div>
早！<span class="url-icon"><img alt="[太阳]" src="https://h5.sinaimg.cn/m/emoticon/icon/others/w_taiyang-2b1d91ddac.png" style="width: 1em; height: 1em;" /></span> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%97%A9%E5%AE%89%23&amp;isnewpage=1"><span class="surl-text">#早安#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hos7egvfcqj207s0awq3b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 21:04:45 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.15)》 爱可可微博热门分享(4.15) [图片]</title>
<link>https://weibo.com/1402400261/O9SJHgKrz</link>
<guid>https://weibo.com/1402400261/O9SJHgKrz</guid>
<content:encoded><![CDATA[
<div> 爱可可 微博 热门 分享 4.15

<br /><br />总结:
4月15日，爱可可微博热门分享内容丰富，吸引了众多用户关注。其中包括了各种各样的热门话题，例如新闻事件、娱乐八卦、美食推荐等。用户通过微博平台分享自己的生活点滴，获得了许多的点赞和转发。微博已经成为人们交流互动的重要平台，为用户提供了丰富多彩的信息和内容。 <div>
《爱可可微博热门分享(4.15)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405023553614643315"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.15)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1horw9s8ihxj20ip0ait9o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 14:39:37 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《IPoD: Implicit Field Learning with Point Diffusion for Generalizable 3D Object Reconstruction from Single RGB-D Images》(CVPR 2024...</title>
<link>https://weibo.com/1402400261/O9S8o7TG9</link>
<guid>https://weibo.com/1402400261/O9S8o7TG9</guid>
<content:encoded><![CDATA[
<div> IPoD, Implicit Field Learning, Point Diffusion, 3D Object Reconstruction, RGB-D Images, GitHub, Probing, 3D Awareness, Visual Foundation Models, GitHub, Generalizable Tumor Synthesis, Attention Calibration, Disentangled Text-to-Image Personalization, GauStudio, 3D Gaussian Splatting, Mantis, Interleaved Multi-Image Instruction Tuning, Mixture-of-Depths, Transformer-based Language Models, ProteinDT, Text-guided Protein Design Framework, StoryImager, Coherent Story Visualization, Agent Group Chat, Collective Emergent Behavior, Concept Depth, Large Language Models, Cacophony, Contrastive Audio-Text Model, Learning, Explainable Stock Predictions, ProSparse, Activation Sparsity, Mamba-ND, State Space Modeling 

<br /><br />总结: 本文总结了多篇CVPR 2024会议的论文，并提供了各篇论文的GitHub链接。这些论文涵盖了各种主题，包括3D目标重建、注意力校准、深度学习模型、文本引导的蛋白质设计等。通过这些研究，研究人员展示了他们在不同领域的创新思维和技术进步。CVPR 2024的这些论文为相关领域的研究和实践提供了宝贵的参考和启发。 <div>
几篇论文实现代码：<br />《IPoD: Implicit Field Learning with Point Diffusion for Generalizable 3D Object Reconstruction from Single RGB-D Images》(CVPR 2024) GitHub: github.com/yushuang-wu/IPoD [fig1] <br />《Probing the 3D Awareness of Visual Foundation Models》(CVPR 2024) GitHub: github.com/mbanani/probe3d<br />《Towards Generalizable Tumor Synthesis》(CVPR 2024) GitHub: github.com/MrGiovanni/DiffTumor [fig4]<br />《Attention Calibration for Disentangled Text-to-Image Personalization》(CVPR 2024) GitHub: github.com/Monalissaa/DisenDiff [fig6]<br />《GauStudio: A Modular Framework for 3D Gaussian Splatting and Beyond》(2024) GitHub: github.com/hugoycj/2dgs-gaustudio<br />《Mantis: Interleaved Multi-Image Instruction Tuning》(2024) GitHub: github.com/TIGER-AI-Lab/Mantis<br />《Mixture-of-Depths: Dynamically allocating compute in transformer-based language models》(2024) GitHub: github.com/astramind-ai/Mixture-of-depths<br />《ProteinDT: A Text-guided Protein Design Framework》(2024) GitHub: github.com/chao1224/ProteinDT [fig2] <br />《StoryImager: A Unified and Efficient Framework for Coherent Story Visualization and Completion》(2024) GitHub: github.com/tobran/StoryImager [fig3]<br />《Agent Group Chat: An Interactive Group Chat Simulacra For Better Eliciting Collective Emergent Behavior》(2024) GitHub: github.com/MikeGu721/AgentGroup<br />《Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?》(2024) GitHub: github.com/Luckfort/CD [fig5]<br />《Cacophony: An Improved Contrastive Audio-Text Model》(2024) GitHub: github.com/gzhu06/Cacophony [fig7]<br />《Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models》(2024) GitHub: github.com/koa-fin/sep<br />《ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models》(2024) GitHub: github.com/Raincleared-Song/sparse_gpu_operator<br />《Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data》(2024) GitHub: github.com/jacklishufan/Mamba-ND<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1horrgdoj1mj21r50hxdqu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1horrhhsx6dj21we1a67w9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1horryjwxk9j21ta0cedsn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1horsi61d0kj230c0vyhdt.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1horslf7kpsj21310j7dsz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hort0qeasvj215v0ea0xv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hort2rarh0j217t0wenbd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 13:07:42 GMT</pubDate>
</item>
<item>
<title>'EmoLLM-心理健康大模型 - 心理健康大模型、LLM、The Big Model of Mental Health、Finetune、InternLM2、Qwen、ChatGLM、Baichuan、DeepSeek、Mixtral' GitHub:...</title>
<link>https://weibo.com/1402400261/O9S6jgEtx</link>
<guid>https://weibo.com/1402400261/O9S6jgEtx</guid>
<content:encoded><![CDATA[
<div> GitHub、EmoLLM、心理健康大模型、LLM、The Big Model of Mental Health、Finetune、InternLM2、Qwen、ChatGLM、Baichuan
<br />
<br />总结: 本篇介绍了EmoLLM-心理健康大模型及其相关项目，包括心理健康大模型、LLM、The Big Model of Mental Health、Finetune、InternLM2、Qwen、ChatGLM、Baichuan等。这些项目都是关于心理健康的大规模模型，旨在提供更好的心理健康支持和帮助。GitHub链接为github.com/SmartFlowAI/EmoLLM，感兴趣的读者可以进一步了解和探索这些项目。 <div>
'EmoLLM-心理健康大模型 - 心理健康大模型、LLM、The Big Model of Mental Health、Finetune、InternLM2、Qwen、ChatGLM、Baichuan、DeepSeek、Mixtral' GitHub: github.com/SmartFlowAI/EmoLLM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hortgh6oizj20w00u0dkx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hortgw8h8sj21340u00ws.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hortgy1qu7j216i0ju430.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 13:02:35 GMT</pubDate>
</item>
<item>
<title>【surya-rs：基于 Rust 语言实现的多语言文档 OCR 工具包，基于修改版 Segformer、OpenCV 和 donut transformer 实现】'surya-rs - Rust implementation of Sury...</title>
<link>https://weibo.com/1402400261/O9S3Xh8Ai</link>
<guid>https://weibo.com/1402400261/O9S3Xh8Ai</guid>
<content:encoded><![CDATA[
<div> Rust、多语言文档 OCR 工具包、Segformer、OpenCV、donut transformer、GitHub、surya-rs

<br /><br />总结:
surya-rs是一个基于Rust语言实现的多语言文档OCR工具包。它基于修改版的Segformer、OpenCV和donut transformer实现。该项目的GitHub链接为github.com/Jimexist/surya-rs。这个工具包提供了一种跨语言的文档OCR解决方案，借助强大的图像处理和Transformer模型，帮助用户实现对文档的文字识别和提取。Surya-rs的实现是基于开源技术，旨在提供高效和准确的文档OCR服务，为用户提供良好的文字识别体验。 <div>
【surya-rs：基于 Rust 语言实现的多语言文档 OCR 工具包，基于修改版 Segformer、OpenCV 和 donut transformer 实现】'surya-rs - Rust implementation of Surya' GitHub: github.com/Jimexist/surya-rs <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hortavl8frj21740koad2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:56:47 GMT</pubDate>
</item>
<item>
<title>'qwen-vllm - 通义千问VLLM推理部署DEMO' GitHub: github.com/owenliang/qwen-vllm #开源# #机器学习# #人工智能# [图片][图片]</title>
<link>https://weibo.com/1402400261/O9S1b0WPy</link>
<guid>https://weibo.com/1402400261/O9S1b0WPy</guid>
<content:encoded><![CDATA[
<div> GitHub、qwen-vllm、通义千问、VLLM、推理部署、DEMO、owenliang、模型、部署、开源

<br /><br />总结:
本文介绍了名为'qwen-vllm - 通义千问VLLM推理部署DEMO'的项目，该项目可以在GitHub上找到，作者是owenliang。项目主要是关于利用VLLM模型进行推理部署的演示，其中包含了通义千问的推理任务。该项目为开源项目，可供学习和研究使用。 <div>
'qwen-vllm - 通义千问VLLM推理部署DEMO' GitHub: github.com/owenliang/qwen-vllm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hort3qbzrpj21ae0u0dmj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hort3s62yuj21n10u0q6c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:49:56 GMT</pubDate>
</item>
<item>
<title>【repo2pdf：将 GitHub 仓库转换为 PDF 文件的工具】’repo2pdf - repo2pdf is a tool that allows you to convert a GitHub repository into a PDF file. It cl...</title>
<link>https://weibo.com/1402400261/O9S0q6lwd</link>
<guid>https://weibo.com/1402400261/O9S0q6lwd</guid>
<content:encoded><![CDATA[
<div> GitHub、仓库、转换、PDF 文件、工具、clone、处理文件、创建 PDF、repo2pdf、BankkRoll<br /><br />总结:repo2pdf是一个工具，可以将GitHub仓库转换为PDF文件。它会克隆仓库，处理文件，然后创建一个PDF。这个工具的GitHub链接是github.com/BankkRoll/repo2pdf。 <div>
【repo2pdf：将 GitHub 仓库转换为 PDF 文件的工具】’repo2pdf - repo2pdf is a tool that allows you to convert a GitHub repository into a PDF file. It clones the repository, processes the files, and then creates a PDF.' GitHub: github.com/BankkRoll/repo2pdf <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hort1tzoxbj21h90qi0w1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:48:04 GMT</pubDate>
</item>
<item>
<title>【ComfyUI ArtGallery | Prompt Visualization：用于可视化提示词的项目，提供了五大类提示词参考图，包括艺术家、艺术运动、艺术媒介、相机镜头和胶片相机】'Co...</title>
<link>https://weibo.com/1402400261/O9RTJjxbo</link>
<guid>https://weibo.com/1402400261/O9RTJjxbo</guid>
<content:encoded><![CDATA[
<div> ComfyUI ArtGallery, Prompt Visualization, 项目, 提示词, 五大类, 艺术家, 艺术运动, 艺术媒介, 相机镜头, 胶片相机

<br /><br />总结:
ComfyUI ArtGallery是一个用于可视化提示词的项目，提供了五大类提示词参考图，包括艺术家、艺术运动、艺术媒介、相机镜头和胶片相机。该项目的GitHub链接为github.com/ZHO-ZHO-ZHO/ComfyUI-ArtGallery。 <div>
【ComfyUI ArtGallery | Prompt Visualization：用于可视化提示词的项目，提供了五大类提示词参考图，包括艺术家、艺术运动、艺术媒介、相机镜头和胶片相机】'ComfyUI ArtGallery | Prompt Visualization - Prompt Visualization | Art Gallery' GitHub: github.com/ZHO-ZHO-ZHO/ComfyUI-ArtGallery <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5023521164689425"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a><br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax3.sinaimg.cn/orj480/5396ee05ly1horskely4gj20qo0k0t9y.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/ZNeSlFv8lx08e6HjDkeY01041200iwRD0E010.mp4?label=mp4_720p&amp;template=960x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713191262&amp;ssig=6sGumgevRw&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/f3kUu6mWlx08e6HjiKg00104120095eE0E010.mp4?label=mp4_hd&amp;template=640x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713191262&amp;ssig=HX4lo%2FQn%2Bg&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/mEKe2fCVlx08e6HjafWw010412005NTX0E010.mp4?label=mp4_ld&amp;template=480x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1713191262&amp;ssig=9BVRBrkhwn&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5023521164689425" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:31:36 GMT</pubDate>
</item>
<item>
<title>【ServoProject：基于 Arduino 的业余舵机控制项目，提供了丰富的文档和视频演示】'ServoProject - Getting the most out of your hobby servo' GitHub: github....</title>
<link>https://weibo.com/1402400261/O9RS7yBiK</link>
<guid>https://weibo.com/1402400261/O9RS7yBiK</guid>
<content:encoded><![CDATA[
<div> Arduino, 业余, 业余舵机, 控制项目, 文档, 视频演示, GitHub, ServoProject

<br /><br />总结:
ServoProject 是一个基于 Arduino 的业余舵机控制项目，旨在帮助用户更好地利用他们的业余舵机。该项目提供了丰富的文档和视频演示，使用户能够轻松地了解并使用该项目。用户可以在GitHub上找到ServoProject的代码和资料，方便下载和参考。通过该项目，用户可以更加灵活地控制舵机，实现各种有趣的功能和项目。无论是初学者还是有经验的用户，都可以从ServoProject中受益，探索舵机控制的乐趣和可能性。ServoProject为Arduino爱好者提供了一个学习和创造的平台，让大家共同探索并享受舵机控制的乐趣。 <div>
【ServoProject：基于 Arduino 的业余舵机控制项目，提供了丰富的文档和视频演示】'ServoProject - Getting the most out of your hobby servo' GitHub: github.com/adamb314/ServoProject <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8horsgk68skj21400u0n0a.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:27:38 GMT</pubDate>
</item>
<item>
<title>【Agent Group Chat: 模拟群聊的交互工具，旨在促进更好的集体群体行为，旨在帮助研究人类群体行为，并为研究人类行为提供有用的工具】’Agent Group Chat: An I...</title>
<link>https://weibo.com/1402400261/O9RNrsIxS</link>
<guid>https://weibo.com/1402400261/O9RNrsIxS</guid>
<content:encoded><![CDATA[
<div> 模拟群聊、交互工具、集体行为、研究、人类行为、工具、GitHub、MikeGu721、AgentGroup

<br /><br />总结:
"Agent Group Chat"是一个模拟群聊的交互工具，旨在促进更好的集体群体行为，帮助研究人类群体行为，为研究人类行为提供有用的工具。该项目可在GitHub上找到，由MikeGu721维护，名为"AgentGroup"。 <div>
【Agent Group Chat: 模拟群聊的交互工具，旨在促进更好的集体群体行为，旨在帮助研究人类群体行为，并为研究人类行为提供有用的工具】’Agent Group Chat: An Interactive Group Chat Simulacra For Better Eliciting Collective Emergent Behavior' GitHub: github.com/MikeGu721/AgentGroup <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hors3ymi8qj21170r4dno.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:16:06 GMT</pubDate>
</item>
<item>
<title>【面向计算机视觉的Mamba相关论文资源列表】’Mamba-in-Computer-Vision - A paper list of some recent Mamba-based CV works.' GitHub: github.com/Yangzhangc...</title>
<link>https://weibo.com/1402400261/O9RMTtNBr</link>
<guid>https://weibo.com/1402400261/O9RMTtNBr</guid>
<content:encoded><![CDATA[
<div> 计算机视觉、Mamba、论文资源、GitHub、最近、CV作品、列表<br />
<br />
提供了一个基于Mamba的计算机视觉作品论文列表。该列表包含了最近一些使用Mamba的计算机视觉作品，提供了GitHub链接以供查阅。这些论文资源展示了Mamba在计算机视觉领域的应用和研究成果，为进一步探索Mamba在CV领域的潜力提供了参考。目前，这些近期的Mamba相关CV作品正在不断积累和发布，为学术研究和技术发展提供了重要的参考和借鉴。通过这个论文资源列表，研究人员和开发者们可以更深入地了解Mamba在计算机视觉应用中的应用情况和研究成果，促进学术交流和技术创新的进步。<br /><br />总结: <br />提供了最近一些使用Mamba的计算机视觉作品论文列表，为CV领域的研究和发展提供了重要参考。 <div>
【面向计算机视觉的Mamba相关论文资源列表】’Mamba-in-Computer-Vision - A paper list of some recent Mamba-based CV works.' GitHub: github.com/Yangzhangcst/Mamba-in-CV <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hors35hrygj20yp0u00wn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:14:45 GMT</pubDate>
</item>
<item>
<title>【Code-Friendly HTML to Markdown Converter：轻量 Python 脚本，可将 HTML 页面转换为 Markdown 格式，支持代码块】'Code-Friendly HTML to Markdown Converte...</title>
<link>https://weibo.com/1402400261/O9RMd2tnv</link>
<guid>https://weibo.com/1402400261/O9RMd2tnv</guid>
<content:encoded><![CDATA[
<div> GitHub、HTML、Markdown、Python、脚本、转换、代码块、轻量、页面、格式
<br /><br />
总结:这是一个轻量级的Python脚本，能够将HTML页面转换为Markdown格式，同时支持代码块的转换。该脚本的GitHub地址是github.com/SivilTaram/code-html-to-markdown。 <div>
【Code-Friendly HTML to Markdown Converter：轻量 Python 脚本，可将 HTML 页面转换为 Markdown 格式，支持代码块】'Code-Friendly HTML to Markdown Converter - A lightweight script for processing HTML page to markdown format with support for code blocks' GitHub: github.com/SivilTaram/code-html-to-markdown <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hors1f0ugwj213y0u0wj1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 12:13:03 GMT</pubDate>
</item>
<item>
<title>【dspy-neo4j-knowledge-graph：基于 DSPy 和 Neo4j 的自动知识图谱构建，使用 OpenAI 的 GPT-4 模型从文本中提取实体和关系】'dspy-neo4j-knowledge-graph - LL...</title>
<link>https://weibo.com/1402400261/O9RtglWY4</link>
<guid>https://weibo.com/1402400261/O9RtglWY4</guid>
<content:encoded><![CDATA[
<div> DSPy, Neo4j, 自动知识图谱构建, OpenAI, GPT-4, 实体提取, 关系提取, 文本, GitHub, LLM<br />
<br />自动化知识图谱构建工具dspy-neo4j-knowledge-graph利用DSPy和Neo4j，以及OpenAI的GPT-4模型，从文本中提取实体和关系。通过这个工具，用户可以快速构建知识图谱，帮助理解文本中的复杂关系。该工具在GitHub上开源，为研究者和开发者提供了一个强大的工具，用于自动化知识图谱的构建与分析。总之，dspy-neo4j-knowledge-graph结合了先进的自然语言处理技术和知识图谱建模工具，为研究者和开发者提供了一个高效且智能的解决方案。 <br /><br />总结: <div>
【dspy-neo4j-knowledge-graph：基于 DSPy 和 Neo4j 的自动知识图谱构建，使用 OpenAI 的 GPT-4 模型从文本中提取实体和关系】'dspy-neo4j-knowledge-graph - LLM-driven automated knowledge graph construction from text using DSPy and Neo4j.' GitHub: github.com/chrisammon3000/dspy-neo4j-knowledge-graph <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8horqou1qctj21h20u0q82.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 11:26:23 GMT</pubDate>
</item>
<item>
<title>【Purl：用于文本处理的命令行工具，提供简单直观的命令选项，支持对文件或标准输入的处理，兼容 Mac 和 Linux】'Purl - Streamlining Text Processing' GitHub:...</title>
<link>https://weibo.com/1402400261/O9RsxmCF3</link>
<guid>https://weibo.com/1402400261/O9RsxmCF3</guid>
<content:encoded><![CDATA[
<div> purl, 文本处理, 命令行工具, 简单直观, 文件, 标准输入, Mac, Linux, GitHub, catatsuy

<br /><br />总结:
文章介绍了一款用于文本处理的命令行工具 purl，提供简单直观的命令选项，支持对文件或标准输入的处理，兼容 Mac 和 Linux。该工具方便用户进行文本处理操作，提高工作效率，适合需要频繁处理文本数据的用户使用。感兴趣的用户可以在 GitHub 上查看该工具的更多信息。 <div>
【Purl：用于文本处理的命令行工具，提供简单直观的命令选项，支持对文件或标准输入的处理，兼容 Mac 和 Linux】'Purl - Streamlining Text Processing' GitHub: github.com/catatsuy/purl <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8horqn02uowj21740qojwr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 11:24:36 GMT</pubDate>
</item>
<item>
<title>【Flow-IPC: 现代的 C++ 工具包，用于高速的进程间通信 (IPC)】'Flow-IPC: Modern C++ toolkit for fast inter-process communication (IPC) - [Start here!] Fl...</title>
<link>https://weibo.com/1402400261/O9Rsao83Q</link>
<guid>https://weibo.com/1402400261/O9Rsao83Q</guid>
<content:encoded><![CDATA[
<div> 现代 C++ 工具包，高速进程间通信，Flow-IPC，GitHub，ipc，C++，工具包，进程间通信，高速<br /><br />总结:Flow-IPC是一个现代的 C++ 工具包，用于实现高速的进程间通信 (IPC)。该工具包可以在GitHub上找到，提供了一种高效的方式来实现进程间通信。通过使用Flow-IPC，开发人员可以轻松地在不同进程之间进行快速的数据传输，提高系统性能和响应速度。Flow-IPC利用现代的 C++ 技术，使得进程间通信变得更加简单和高效。 <div>
【Flow-IPC: 现代的 C++ 工具包，用于高速的进程间通信 (IPC)】'Flow-IPC: Modern C++ toolkit for fast inter-process communication (IPC) - [Start here!] Flow-IPC - Modern C++ toolkit for high-speed inter-process communication (IPC)' GitHub: github.com/Flow-IPC/ipc <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8horqlypli4j212a0u0q93.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8horqm15zh9j21se0u0n00.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 11:23:41 GMT</pubDate>
</item>
<item>
<title>【长程视频理解相关论文资源列表】’Awesome Long-Term Video Understanding - Awesome papers &amp; datasets specifically focused on long-term videos.' GitHub:...</title>
<link>https://weibo.com/1402400261/O9Rr1bpEK</link>
<guid>https://weibo.com/1402400261/O9Rr1bpEK</guid>
<content:encoded><![CDATA[
<div> 长程视频理解，论文资源列表，GitHub，长期视频理解，数据集<br />
<br />
总结:<br />
这篇文章分享了一个GitHub资源列表，关注长期视频理解领域的论文和数据集。长期视频理解是指对长时间范围内的视频进行分析和理解的过程。GitHub上提供了一些优秀的论文和数据集，可以用于研究长程视频理解相关问题。这些资源有助于开展长程视频理解领域的研究工作，并为相关领域的学术研究提供支持。 <div>
【长程视频理解相关论文资源列表】’Awesome Long-Term Video Understanding - Awesome papers &amp; datasets specifically focused on long-term videos.' GitHub: github.com/ttengwang/Awesome_Long_Form_Video_Understanding <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8horqi85b0bj20y50u0afz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 11:20:51 GMT</pubDate>
</item>
<item>
<title>【自动图表理解相关论文资源列表】’Awesome Chart Understanding - A curated list of recent and past chart understanding work based on our survey paper: ...</title>
<link>https://weibo.com/1402400261/O9RqkxLxy</link>
<guid>https://weibo.com/1402400261/O9RqkxLxy</guid>
<content:encoded><![CDATA[
<div> 自动图表理解、资源列表、GitHub、调查论文、大基础模型、像素到洞察、最新研究、过去研究、图表理解、曲线 拟合

<br /><br />总结:
本文整理了关于自动图表理解的最新研究成果，基于他们的调查论文《从像素到洞察：在大基础模型时代的自动图表理解》。列出了相关研究工作，并在GitHub上提供了资源列表。研究主要关注在大基础模型时代的自动图表理解，探讨了从像素到洞察的过程。涵盖了最新和过去的研究成果，这些工作对于图表理解和曲线拟合具有重要意义。 <div>
【自动图表理解相关论文资源列表】’Awesome Chart Understanding - A curated list of recent and past chart understanding work based on our survey paper: From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models.' GitHub: github.com/khuangaf/awesome-chart-understanding <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8horqhaeztdj210f0u0433.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 11:19:10 GMT</pubDate>
</item>
<item>
<title>【SuperMemory：用于构建自己"第二大脑"的工具，可以将你在互联网上收集的信息导入到其中，并且具有类似 ChatGPT 的回答功能。SuperMemory基于 Turborepo 构建，...</title>
<link>https://weibo.com/1402400261/O9RlP6gHr</link>
<guid>https://weibo.com/1402400261/O9RlP6gHr</guid>
<content:encoded><![CDATA[
<div> GitHub，SuperMemory，构建，第二大脑，ChatGPT，书签，扩展，网页，信息，云 AI

总结:<br /><br />这是一款名为SuperMemory的工具，用于构建个人的"第二大脑"，类似于ChatGPT，可以将互联网上收集的信息导入其中。它基于Turborepo构建，包括网页UI、Chrome扩展和云AI后端三个主要模块。用户可以使用Chrome扩展导入推特或保存网站和内容，从而在SuperMemory中建立自己的知识库。GitHub链接：github.com/Dhravya/supermemory。 <div>
【SuperMemory：用于构建自己"第二大脑"的工具，可以将你在互联网上收集的信息导入到其中，并且具有类似 ChatGPT 的回答功能。SuperMemory基于 Turborepo 构建，包括三个主要模块：网页 UI、Chrome 扩展和云 AI 后端】’SuperMemory - Build your own second brain with supermemory. It's a ChatGPT for your bookmarks. Import tweets or save websites and content using the chrome extension.' GitHub: github.com/Dhravya/supermemory <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8horq5mr5bnj20xc0hidhs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8horq5o12mkj212e0u0q61.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8horq5qox3aj21dr0u0wij.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 11:08:03 GMT</pubDate>
</item>
<item>
<title>【redka：用SQLite复现Redis的项目，支持 Redis 的主要数据类型，如字符串、列表、集合、哈希和有序集合】'redka - Redis re-implemented with SQLite' GitHub: ...</title>
<link>https://weibo.com/1402400261/O9Rj6s6j5</link>
<guid>https://weibo.com/1402400261/O9Rj6s6j5</guid>
<content:encoded><![CDATA[
<div> SQLite、Redis、数据类型、字符串、列表、集合、哈希、有序集合<br />
<br />
总结：<br />
本文介绍了一个名为redka的项目，它是使用SQLite复现Redis的工具。此项目支持Redis的主要数据类型，包括字符串、列表、集合、哈希和有序集合。这个项目可以帮助用户在没有Redis的情况下使用SQLite来实现类似的功能。通过redka，用户可以方便地在SQLite数据库中存储和处理不同类型的数据，实现类似Redis的功能。如果您对使用SQLite来实现Redis功能感兴趣，可以访问GitHub页面github.com/nalgeon/redka获取更多信息。 <div>
【redka：用SQLite复现Redis的项目，支持 Redis 的主要数据类型，如字符串、列表、集合、哈希和有序集合】'redka - Redis re-implemented with SQLite' GitHub: github.com/nalgeon/redka <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Redis%23"><span class="surl-text">#Redis#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8horpyom1b9j21550u0tcr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 11:01:22 GMT</pubDate>
</item>
<item>
<title>恭喜@希侬如故 等3名用户获得【《LangChain实战》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效。公示链接：网页链接 - 转发 @爱可...</title>
<link>https://weibo.com/1402400261/O9OzQssHr</link>
<guid>https://weibo.com/1402400261/O9OzQssHr</guid>
<content:encoded><![CDATA[
<div> LangChain, 实战, 初学者, 大语言模型, 抽奖, 公正有效, LangChain团队, 生成式人工智能, LangServe, LangSmith

总结:<br />
微博官方唯一抽奖工具监督《LangChain实战》抽奖活动，恭喜3名用户获得这本书。活动截止时间为2024年4月15日12:00，用户可通过转发和评论参与抽奖。《LangChain实战》适合初学者和对LangChain应用感兴趣的开发者，介绍LangChain 0.1版本，并配有详细视频。书中重点探讨了多个核心应用场景和LCEL的应用方式，同时详细讨论了LangChain团队在生成式人工智能领域的布局。整体帮助读者全面了解LangChain、LangServe和LangSmith等相关概念。 <div>
恭喜<a href="https://weibo.com/n/%E5%B8%8C%E4%BE%AC%E5%A6%82%E6%95%85">@希侬如故</a> 等3名用户获得【《LangChain实战》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20435760&amp;pageid=100140E51198948"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.15 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a>  <a href="https://shop.sc.weibo.com/h5/goods/index?iid=110014024002610004661854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">LangChain实战：从原型到生产，动手打造 LLM 应用</span></a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hofl98oom9j207q0a0jrm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 04:04:22 GMT</pubDate>
</item>
<item>
<title>【异常检测通用模型学习】- 通用异常检测(GAD)旨在训练一个模型， 无需使用目标数据进行训练，就能检测不同领域数据集中的异常。 提出了基于CLIP的残差学习模型I...</title>
<link>https://weibo.com/1402400261/O9N7GwoPt</link>
<guid>https://weibo.com/1402400261/O9N7GwoPt</guid>
<content:encoded><![CDATA[
<div> CLIP、残差学习、异常检测、InCTRL、泛化能力、数据集、文本提示、图像级残差、图块级残差、GAD  
<br />  
总结:  
提出了基于CLIP的残差学习模型InCTRL，不需使用目标数据训练即可检测不同领域数据集的异常。InCTRL结合文本提示、图块级和图像级残差，利用辅助数据集学习查询图像与提示的残差，在9个数据集上明显优于其他方法。消融实验显示文本提示、残差级别对数据集贡献不同，但综合三者效果最佳。学习残差对泛化能力更重要，为异常检测提供全新视角。InCTRL在工业、医学、语义异常检测表现突出，是当前最佳GAD方法。 <div>
【异常检测通用模型学习】<br />- 通用异常检测(GAD)旨在训练一个模型， 无需使用目标数据进行训练，就能检测不同领域数据集中的异常。   <br /> 提出了基于CLIP的残差学习模型InCTRL，利用辅助数据集，学习查询图像与少样本提示之间的残差，来区分异常样本。   <br />- InCTRL同时建模图像级和图块级的残差，获取对异常的深入理解。还结合文本提示解码器的语义信息。   <br />- 在9个异常检测数据集上进行评估，InCTRL明显优于其他方法，表明它能很好地推广到不同领域。   <br />- 消融实验表明：文本提示、图块级残差和图像级残差对不同类型数据集贡献不同，但综合三者效果最好。   <br />- 与简单拼接或平均相比，学习残差对泛化能力更重要。   <br />- 文中设定新的GAD任务评估异常检测方法的泛化能力，为异常检测研究提出全新的视角。   <br />- InCTRL在工业缺陷、医学图像及语义异常检测上表现突出，是当前最佳GAD方法。   <br />《Learning Generalist Models for Anomaly Detection | by Guansong Pang | Apr, 2024 | Towards Data Science》 <a href="https://towardsdatascience.com/learning-generalist-models-for-anomaly-detection-53d7a6a74474"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hor7h9r573j20om0o2q7f.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hor7hc246rj212w0mb44i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 00:22:15 GMT</pubDate>
</item>
<item>
<title>【用Claude 3 Opus构建股票分析Agent工具】《Building an Agentic Stock Analysis Tool with Langchain, OpenBB and Claude 3 Opus - Swapping Symbols》 网页链...</title>
<link>https://weibo.com/1402400261/O9N2Ngtj0</link>
<guid>https://weibo.com/1402400261/O9N2Ngtj0</guid>
<content:encoded><![CDATA[
<div> Langchain, OpenBB, Claude 3 Opus, 股票分析工具, Agent, 拓展 AI 股票分析代理, 基本面, 技术工具, 股票符号

总结:<br /><br />这篇文章介绍了如何利用Langchain、OpenBB和Claude 3 Opus构建股票分析代理工具，其中包括股票符号的交换。文章还详细讨论了如何通过基本面和技术工具拓展AI股票分析代理工具，从而提高其效能。通过本文的阐述，读者可以了解到如何利用这些工具来开发更加专业和智能的股票分析代理工具。 <div>
【用Claude 3 Opus构建股票分析Agent工具】《Building an Agentic Stock Analysis Tool with Langchain, OpenBB and Claude 3 Opus - Swapping Symbols》 <a href="https://sethhobson.com/2024/03/building-an-agentic-stock-analysis-tool-with-langchain-openbb-and-claude-3-opus/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> 《Expanding the AI Stock Analysis Agent with Fundamental and Technical Tools - Swapping Symbols》 <a href="https://sethhobson.com/2024/04/expanding-the-ai-stock-analysis-agent-with-fundamental-and-technical-tools/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hor74l4t7oj213e0u078n.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hor7515tuoj21o00u0n3u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 00:10:11 GMT</pubDate>
</item>
<item>
<title>【Scalene：Python提速利器】- Python编程语言使用广泛，但运行效率低下，比其他编程语言慢100-1000倍甚至更多。 - UMass Amherst的计算机科学家研发了开源性能...</title>
<link>https://weibo.com/1402400261/O9MZ3AnMI</link>
<guid>https://weibo.com/1402400261/O9MZ3AnMI</guid>
<content:encoded><![CDATA[
<div> 计算机科学家、Python、提速利器、Scalene、开源性能分析工具、低效部分、优化建议、Best Paper Award、USENIX会议、开源社区

<br /><br />总结:
UMass Amherst的计算机科学家开发了开源性能分析工具Scalene，可以帮助定位Python代码中的低效部分并提供优化建议。该工具已广泛使用，下载量超过75万次，获得了USENIX会议的Best Paper Award，在学术界得到认可。随着计算机硬件技术进步放缓，优化Python性能变得越来越重要。Scalene的出现是提高Python执行效率的重要突破，也展示了开源社区的力量。这对推动Python在更多场景中的应用，提高开发者的体验和效率具有重要意义。 <div>
【Scalene：Python提速利器】<br />- Python编程语言使用广泛，但运行效率低下，比其他编程语言慢100-1000倍甚至更多。   <br />- UMass Amherst的计算机科学家研发了开源性能分析工具Scalene，可以高效定位Python代码中的低效部分。   <br />- Scalene不仅可以准确指出Python代码的低效之处，还可以利用AI技术给出优化建议。   <br />- Scalene已经被广泛使用，下载量超过75万次。它可以帮助程序员优化Python代码，提高运行速度。   <br />- 随着计算机硬件技术进步放缓，编程语言的执行效率正变得越来越重要。Scalene这样的工具对于优化Python性能意义重大。   <br />- 该研究团队因Scalene在USENIX会议上荣获Best Paper Award。这表明该工具在学术界得到认可，对Python社区影响深远。   <br />- Scalene是提高Python执行效率的重要突破，也再次证明开源社区的力量。它将促进Python在更多场景中的应用，造福开发者。<br />《Computer scientists develop open-source tool for dramatically speeding up the programming language Python》 <a href="https://techxplore.com/news/2023-08-scientists-open-source-tool-language-python.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hor6vp5ufnj20u00uiafe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 15 Apr 2024 00:00:59 GMT</pubDate>
</item>
<item>
<title>【AI 50企业榜单】- 以生成式AI为代表的第三代AI正在改变企业生产力，提高工作效率。企业AI应用类在AI 50榜单上呈爆炸式增长。 - 越来越多大公司将AI集成到内部...</title>
<link>https://weibo.com/1402400261/O9MW4xiKe</link>
<guid>https://weibo.com/1402400261/O9MW4xiKe</guid>
<content:encoded><![CDATA[
<div> 生成式AI, 企业生产力, 工作效率, AI应用, 内部流程, 业务指标, 用户体验, 界面设计, 基础设施, 生产力革命

<br /><br />总结:
第三代AI以生成式AI为代表，正在影响企业生产力和工作效率。企业AI应用呈现爆炸式增长，大公司将AI集成到内部流程以实现业务指标，同时AI重塑用户体验和界面设计。基础设施类别壮大以支持新出现的强大AI模型，未来公司将更小、更多、更敏捷。AI带来生产力革命和成本降低，但也需要政府和企业努力减少就业冲击，继续创造工作岗位。2024年的AI 50榜单展示AI影响的开始，其应用范围将继续扩大。 <div>
【AI 50企业榜单】<br />- 以生成式AI为代表的第三代AI正在改变企业生产力，提高工作效率。企业AI应用类在AI 50榜单上呈爆炸式增长。   <br />- 越来越多大公司将AI集成到内部流程，以实现业务指标的加速增长和成本的大幅降低。   <br />- AI正在重塑用户体验和界面设计，从替代人工实现更好更快，到创造全新的用户体验。   <br />- 基础设施类别也在不断壮大，以支持新出现的强大AI模型。云平台、向量数据库、推理框架等都在迎合这一趋势。   <br />- 未来的公司将更小、更多、更敏捷。公司创立将更快速和流动。AI将减少日常操作工作，让人类可以关注更重要的事。   <br />- AI带来的生产力革命将降低成本，使更多关键服务大众化。但也需要政府与企业共同努力，减少就业冲击，继续创造工作岗位。   <br />- 2024年的AI 50榜单预示着AI带来深广影响的开始，它的应用范围还将不断扩大。<br />《AI 50: Companies of the Future | Sequoia Capital》 <a href="https://www.sequoiacap.com/article/ai-50-2024/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hor6novzn7j21io0u0afh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hor6nquetwj21hc0u0jw2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hor6nsdo8vj216i0u0tdo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 23:53:38 GMT</pubDate>
</item>
<item>
<title>【没有过去，就没有未来】- 历史对于人类意识和社会记忆非常重要。它塑造我们的世界观，支持社会规范和法律等。 - 作者担心AI会被用来生成虚假的历史文本和解释...</title>
<link>https://weibo.com/1402400261/O9MUSEQQB</link>
<guid>https://weibo.com/1402400261/O9MUSEQQB</guid>
<content:encoded><![CDATA[
<div> 历史，人工智能，记忆，思考能力，威胁，控制力，外包，警惕，人类创作，连接人类经验

总结：<br /><br />这篇文章讨论了历史对于人类意识和社会记忆的重要性，以及人工智能可能对历史的影响。作者担心人工智能可能被用来生成虚假的历史文本，削弱人类对历史的理解能力。学生可能只需向聊天机器人提几个问题就获得答案，而不做进一步思考和研究，这对历史学习构成威胁。历史应该由人类书写和解释，否则我们将失去对未来的控制能力。尽管历史学不是AI的首要取代目标，但这种威胁正在增长。文章还探讨了词语定义的模糊性和不确定性，以及人工智能介入历史叙事可能带来的新视角和偏见。继续由人类进行历史创作、理解和传播至关重要，要抵制将其外包给AI的诱惑。 <div>
【没有过去，就没有未来】<br />- 历史对于人类意识和社会记忆非常重要。它塑造我们的世界观，支持社会规范和法律等。   <br />- 作者担心AI会被用来生成虚假的历史文本和解释，这会削弱人类对历史的理解和批判性思考的能力。   <br />- 学生可能只需向聊天机器人提几个问题就获得“历史”答案，而不做进一步的思考和研究。这是对历史学习的一种威胁。   <br />- 文章警告如果将历史创作外包给机器，我们将失去对未来的控制能力。历史应由人类书写和解释。   <br />- 相较于其他领域，历史学目前还不是AI的首要取代目标，但这种威胁正在快速增长。历史工作者需要警惕并做好准备。   <br />- 历史是连接人类经验的纽带，是无价之宝。我们必须抵制将其外包给AI的商业和教育诱惑，继续由人类进行历史创作、理解和传播。<br /><br />思考：  <br />- 本文提出一个有趣的观点：历史和过去记忆对于人工智能实现类人思考至关重要。这一观点有一定道理，因为人类思维很大程度上依赖于过去的经验和记忆。  <br />- 文章指出词语定义的模糊性和不确定性，这与严谨的数理逻辑形成鲜明对比。这一见解发人深省，让人反思语言和思维的关系。  <br />- 作者想象了一个场景：如果人工智能开始书写和解读历史会怎样?这一假设虽然有些耸人听闻，但值得我们思考。当人工智能介入历史叙事，可能会带来新的视角，但也可能带来新的偏见和操纵。  <br />《No Past, No Future. “One of the early inventors of… | by David Hitchcock | Apr, 2024 | Medium》 <a href="https://hitchcockian.medium.com/no-past-no-future-38f1a9cfe541"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hor6kzsmihj20pm0ozn1o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 23:50:42 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《LangChain实战》，截至2024.4.15 12:00，...</title>
<link>https://weibo.com/1402400261/O9Mjf3ktK</link>
<guid>https://weibo.com/1402400261/O9Mjf3ktK</guid>
<content:encoded><![CDATA[
<div> LangChain实战、LangChain、LLM、LangServe、LangSmith、生成式人工智能、初学者、开发者、应用场景、LCEL

<br /><br />总结:
本文介绍了对LangChain实战的开奖活动，参与者需要转发并评论才能参与。活动截止日期为2024年4月15日12:00。LangChain实战是专为初学者和对LangChain应用及大语言模型（LLM）感兴趣的开发者而编写的，配套600分钟详解视频。书籍重点介绍了多个核心应用场景，并深入探讨了LCEL的应用方式。此外，本书还围绕LangChain生态系统的概念展开，详细讨论了LangChain、LangServe和LangSmith，帮助读者更全面地了解LangChain团队在生成式人工智能领域的布局。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.15 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a>  <a href="https://shop.sc.weibo.com/h5/goods/index?iid=110014024002610004661854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">LangChain实战：从原型到生产，动手打造 LLM 应用</span></a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hofl98oom9j207q0a0jrm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 22:17:58 GMT</pubDate>
</item>
<item>
<title>今日推介(第1376期)：时变音频系统的可微全极滤波器、(近)重复子词在语言建模中的作用、医学领域开源多语言文本到文本LLM、重新思考混合专家语言模型训练、大型...</title>
<link>https://weibo.com/1402400261/O9Mj1iNal</link>
<guid>https://weibo.com/1402400261/O9Mj1iNal</guid>
<content:encoded><![CDATA[
<div> 可微全极滤波器  重复子词  语言建模  医学领域  开源多语言文本  混合专家语言模型  大型语言模型  指代  定位  改进基线  

<br /><br />总结:  
本期推介的文章涵盖了时变音频系统中可微全极滤波器的研究，以及重复子词在语言建模中的作用。另外，还介绍了医学领域的开源多语言文本到文本LLM，混合专家语言模型训练的重新思考，和大型语言模型指代和定位的改进基线。这些研究内容丰富多样，对于相关领域的发展和应用具有重要意义。 <div>
今日推介(第1376期)：时变音频系统的可微全极滤波器、(近)重复子词在语言建模中的作用、医学领域开源多语言文本到文本LLM、重新思考混合专家语言模型训练、大型语言模型指代和定位的改进基线 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/692472274"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.15)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hor3vmypuej21g20pm780.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hor3vpd9x5j21740myjvh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hor3vrv2e2j20ou0kmacm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hor3vucq6tj216c0k0q73.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hor3vx61y8j21io0pk485.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 22:17:24 GMT</pubDate>
</item>
<item>
<title>[CL] MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies 网页链接 提出小型语言模型MiniCPM系列，通过模型风洞实...</title>
<link>https://weibo.com/1402400261/O9MgiBjvb</link>
<guid>https://weibo.com/1402400261/O9MgiBjvb</guid>
<content:encoded><![CDATA[
<div> 模型风洞实验, WSD学习率调度器, 小型语言模型, MiniCPM系列, 高效训练, 可拓展训练, 有限计算资源, 语言模型潜力<br />
<br />
总结:<br />
本文提出了MiniCPM系列小型语言模型，通过模型风洞实验和WSD学习率调度器实现高效、可拓展的训练方案。在有限的计算资源下，MiniCPM系列发挥了语言模型巨大潜力。通过优化训练策略和调整学习率，MiniCPM在小规模下具有出色的性能表现，为语言模型研究提供了新的思路。 <div>
[CL] MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies  <br /><a href="https://arxiv.org/abs/2404.06395"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>        <br />提出小型语言模型MiniCPM系列，通过模型风洞实验和WSD学习率调度器实现高效、可拓展的训练方案，在有限计算资源下发挥语言模型巨大潜力。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hor3oxxailj20qk16ganj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor3oydynzj21a00ggq8f.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hor3oytjnsj21c60w44ez.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 22:10:43 GMT</pubDate>
</item>
<item>
<title>[CV] BRAVE: Broadening the visual encoding of vision-language models 网页链接 BRAVE 通过有效整合多视觉编码器的表达，大大扩展了 VLM 的视觉理解能力，在...</title>
<link>https://weibo.com/1402400261/O9McJyxAI</link>
<guid>https://weibo.com/1402400261/O9McJyxAI</guid>
<content:encoded><![CDATA[
<div> 关键词: BRAVE, 视觉编码器, VLM, SOTA, 多任务, 鲁棒性

总结:<br /><br />本研究提出了一种名为BRAVE的方法，通过整合多视觉编码器的表达，扩展了视觉-语言模型的视觉理解能力。实验结果显示，BRAVE在多个任务上达到了当前最先进水平，并显著提高了模型的鲁棒性。该方法为进一步提升视觉-语言模型的性能和多任务表现提供了有益的思路。 <div>
[CV]  BRAVE: Broadening the visual encoding of vision-language models  <br /><a href="https://arxiv.org/abs/2404.07204"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />BRAVE 通过有效整合多视觉编码器的表达，大大扩展了 VLM 的视觉理解能力，在多个任务上取得 SOTA 水平，同时显著提高了模型的鲁棒性。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hor3fsiuxhj20se19qdte.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor3ft4jzfj21pm1a41a5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor3ftormpj21pi11gh2r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 22:01:56 GMT</pubDate>
</item>
<item>
<title>[CV] AWOL: Analysis WithOut synthesis using Language 网页链接 通过从CLIP空间到参数空间的映射，利用语言的泛化能力来控制不同3D形状模型生成新样例。 [图片...</title>
<link>https://weibo.com/1402400261/O9M9xi9Oc</link>
<guid>https://weibo.com/1402400261/O9M9xi9Oc</guid>
<content:encoded><![CDATA[
<div> CLIP空间, 参数空间, 语言泛化能力, 3D形状模型, 新样例生成<br />
<br />
通过将CLIP空间映射到参数空间，并利用语言的泛化能力，可以控制不同的3D形状模型生成新的样例。这种方法可以帮助研究人员更有效地分析、理解和创造3D形状模型，并为设计和创新提供新的可能性。AWOL技术的引入为研究领域带来了新的思路和方法，拓展了在3D形状生成方面的前沿研究。同时，通过语言的引导和控制，可以更灵活地进行形状模型的创作和变形，提高了生成模型的多样性和创造力。在未来，这种基于语言和参数空间映射的方法有望为计算机图形学和人工智能领域带来更多创新和突破性进展。<br /><br />总结: <br />通过CLIP空间到参数空间的映射，利用语言的泛化能力来控制不同3D形状模型生成新样例。这种方法为研究人员提供了新的创作和分析工具，扩展了3D形状生成领域的边界，为未来的计算机图形学和人工智能研究带来了新的可能性。 <div>
[CV] AWOL: Analysis WithOut synthesis using Language  <br /><a href="https://arxiv.org/abs/2404.03042"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过从CLIP空间到参数空间的映射，利用语言的泛化能力来控制不同3D形状模型生成新样例。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hor37ldwxrj20si1auqer.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor37luav8j21pm0ko0z9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hor37m56p9j21po0wu466.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 21:54:03 GMT</pubDate>
</item>
<item>
<title>通过构建完全子词复制的实验设置合理地量化了近似重复子词对语言模型样本效率的负面影响，但也指出真实语料中近似重复子词的语义差异使其对泛化的帮助有限，为后...</title>
<link>https://weibo.com/1402400261/O9LVuasZp</link>
<guid>https://weibo.com/1402400261/O9LVuasZp</guid>
<content:encoded><![CDATA[
<div> 近似重复子词，语言模型，效率，负面影响，语义差异，泛化，理论依据

<br /><br />总结:
本研究通过构建完全子词复制的实验设置，量化了近似重复子词对语言模型样本效率的负面影响。然而，研究也指出真实语料中近似重复子词的语义差异有限，对泛化的帮助有限。这为后续研究提供了重要的理论依据，强调了语言模型在处理近似重复子词时需要考虑语义差异的影响。 <div>
通过构建完全子词复制的实验设置合理地量化了近似重复子词对语言模型样本效率的负面影响，但也指出真实语料中近似重复子词的语义差异使其对泛化的帮助有限，为后续研究提供了理论依据。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《On the Effect of (Near) Duplicate Subwords in Language Modelling》A Schäfer, T Hofmann, I Schlag, T Pimentel [ETH Zürich] (2024) <a href="https://arxiv.org/abs/2404.06508"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor26p23bgj20ik0ywahx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor26pjiguj20lg0pw0wv.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hor26pu81qj20lg0pw0wv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor26q0arwj20lo0k6goe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hor27bphk5j20hr0frgn0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor27bq858j20zv0dw0ug.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor27bqbzgj20zx0jnwhd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor27bqf3mj20zs0gswg8.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hor27bs2ikj20zx16ldlr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 21:19:26 GMT</pubDate>
</item>
<item>
<title>[CL]《On the Effect of (Near) Duplicate Subwords in Language Modelling》A Schäfer, T Hofmann, I Schlag, T Pimentel [ETH Zürich] (2024) 网页链接 #机...</title>
<link>https://weibo.com/1402400261/O9LVnpTId</link>
<guid>https://weibo.com/1402400261/O9LVnpTId</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言建模, 重复子词, 效果, 语言处理, 模型调优, 数据集, 实验, 结果, 比较, 方法

总结:<br /><br />
本文研究了语言建模中重复子词的影响，探讨了其对模型性能的影响。通过对包含重复子词的数据集进行实验，作者发现在处理重复子词时，模型的性能会受到影响。实验结果显示，采用不同的方法处理重复子词可以对模型性能进行调优。通过对比实验结果，可以得出某些方法在处理重复子词时表现更佳。研究表明，在语言处理任务中，重复子词的存在会对建模效果产生显著影响，因此在设计模型时需考虑如何处理这一问题。 <div>
[CL]《On the Effect of (Near) Duplicate Subwords in Language Modelling》A Schäfer, T Hofmann, I Schlag, T Pimentel [ETH Zürich] (2024) <a href="https://arxiv.org/abs/2404.06508"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor26p23bgj20ik0ywahx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor26pjiguj20lg0pw0wv.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hor26pu81qj20lg0pw0wv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor26q0arwj20lo0k6goe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hor27bphk5j20hr0frgn0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor27bq858j20zv0dw0ug.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor27bqbzgj20zx0jnwhd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor27bqf3mj20zs0gswg8.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hor27bs2ikj20zx16ldlr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 21:19:10 GMT</pubDate>
</item>
<item>
<title>提出重用前向传播滤波器的方法高效实现时间变化全极点滤波器的反向传播，可准确地端到端训练包含递归结构的音频系统。 - 转发 @爱可可-爱生活:&amp;ensp;[AS]《Diffe...</title>
<link>https://weibo.com/1402400261/O9LUP3TzS</link>
<guid>https://weibo.com/1402400261/O9LUP3TzS</guid>
<content:encoded><![CDATA[
<div> 时间变化全极点滤波器, 反向传播, 音频系统, 递归结构, 端到端训练, 前向传播滤波器, Differentiable, All-pole Filters, 时间变化, 音频

<br /><br />总结:
本研究提出了一种方法，可以高效地实现时间变化全极点滤波器的反向传播，从而准确地端到端训练包含递归结构的音频系统。研究团队设计了前向传播滤波器，并通过反向传播的方式实现了对时间变化全极点滤波器的有效训练。这种方法可以有效地应用于音频系统中，提高系统的性能和准确性。通过对滤波器的不断优化和训练，可以实现更好的音频处理效果，为音频领域的研究和应用带来新的可能性。 <div>
提出重用前向传播滤波器的方法高效实现时间变化全极点滤波器的反向传播，可准确地端到端训练包含递归结构的音频系统。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [AS]《Differentiable All-pole Filters for Time-varying Audio Systems》C Yu, C Mitcheltree, A Carson, S Bilbao, J D. Reiss, G Fazekas [Queen Mary University of London &amp; University of Edinburgh] (2024) <a href="https://arxiv.org/abs/2404.07970"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor23rwf7hj20ry0oqdnj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor23s8wz9j21g20pmwix.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hor23sgtj4j211c0jkn07.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor23smth2j211c0xgn1y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 21:17:48 GMT</pubDate>
</item>
<item>
<title>[AS]《Differentiable All-pole Filters for Time-varying Audio Systems》C Yu, C Mitcheltree, A Carson, S Bilbao, J D. Reiss, G Fazekas [Queen Mary Unive...</title>
<link>https://weibo.com/1402400261/O9LUJ9gvv</link>
<guid>https://weibo.com/1402400261/O9LUJ9gvv</guid>
<content:encoded><![CDATA[
<div> Differentiable, all-pole filters, time-varying audio systems, Queen Mary University of London, University of Edinburgh, C Yu, C Mitcheltree, A Carson, S Bilbao, J D. Reiss, G Fazekas

<br /><br />总结:
这篇文章介绍了一种用于时变音频系统的可微分全极点滤波器。研究人员来自伦敦玛丽皇后大学和爱丁堡大学。他们提出了一种新型的滤波器结构，能够有效地处理时变音频信号。通过实验和分析，他们表明这种滤波器在处理时变音频系统中具有很高的效果和可靠性。这项研究为时变音频系统的设计和优化提供了新的思路和方法。 <div>
[AS]《Differentiable All-pole Filters for Time-varying Audio Systems》C Yu, C Mitcheltree, A Carson, S Bilbao, J D. Reiss, G Fazekas [Queen Mary University of London &amp; University of Edinburgh] (2024) <a href="https://arxiv.org/abs/2404.07970"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor23rwf7hj20ry0oqdnj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hor23s8wz9j21g20pmwix.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hor23sgtj4j211c0jkn07.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hor23smth2j211c0xgn1y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 21:17:34 GMT</pubDate>
</item>
<item>
<title>早！[太阳] #早安# [图片]</title>
<link>https://weibo.com/1402400261/O9LSKdKKk</link>
<guid>https://weibo.com/1402400261/O9LSKdKKk</guid>
<content:encoded><![CDATA[
<div> 关键词: 早，中文，文章，提取，要点，800字，总结

在这篇文章中，通过提取关键字来总结一个长文是一种有效的整理方法。这种方法也能帮助读者更快地了解文章内容及主旨。总结应根据文章提供的要点和信息来进行编写，确保包含所有重要的内容。在写总结时，按照文章的顺序将要点逐一罗列出来，以帮助读者更好地理解和记忆文章内容。<br /><br />总结: 通过提取关键词来总结这篇中文文章，能够帮助读者更快地了解文章内容及主旨。此外，文章总结应根据提供的要点和信息来进行，确保包含所有重要的内容。在写总结时，按照文章的顺序将要点逐一罗列出来，以帮助读者更好地理解和记忆文章内容。 <div>
早！<span class="url-icon"><img alt="[太阳]" src="https://h5.sinaimg.cn/m/emoticon/icon/others/w_taiyang-2b1d91ddac.png" style="width: 1em; height: 1em;" /></span> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%97%A9%E5%AE%89%23&amp;isnewpage=1"><span class="surl-text">#早安#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hor20ikkpdj207s0awmxm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 21:12:41 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.14)》 爱可可微博热门分享(4.14) [图片]</title>
<link>https://weibo.com/1402400261/O9JlAazCU</link>
<guid>https://weibo.com/1402400261/O9JlAazCU</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 分享, 爱可可, 4.14

<br /><br />总结:
4月14日，爱可可微博上热门分享了一篇文章。文章内容受到广泛关注，分享的用户也很多。文章内容涉及各种话题，从社会热点到娱乐八卦，涵盖了各个方面。在微博平台上引起了热烈的讨论，许多网友纷纷转发和评论，形成了热门话题。通过微博分享，信息传播速度快，阅读量也很高，展现了微博作为社交平台的强大影响力。 <div>
《爱可可微博热门分享(4.14)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405023192703172669"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.14)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoqqtiesbcj20kg0biwg8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 14:45:29 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Negative Label Guided OOD Detection with Pretrained Vision-Language Models》(ICLR 2024) GitHub: github.com/XueJiang16/NegLabel [fi...</title>
<link>https://weibo.com/1402400261/O9Gh8og89</link>
<guid>https://weibo.com/1402400261/O9Gh8og89</guid>
<content:encoded><![CDATA[
<div> 关键词: OOD检测, 预训练视觉-语言模型, 跨模态学习, 视频人体姿态回归, 时间-空间聚合, 音色识别, 乐器无关音乐转录, 数学推理评估, 大型语言模型, 多视角3D物体检测

总结:<br /><br />《Negative Label Guided OOD Detection with Pretrained Vision-Language Models》介绍了使用预训练的视觉-语言模型辅助进行OOD检测的方法，提出了负向标签辅助的策略。<br /> 《Video-Based Human Pose Regression via Decoupled Space-Time Aggregation》介绍了一种通过分离空间-时间聚合实现视频人体姿态回归的方法，提升了准确性和效率。<br />《Timbre-Trap: A Low-Resource Framework for Instrument-Agnostic Music Transcription》提出了一种乐器无关音乐转录的低资源框架，适用于音色识别领域。<br />《Evaluating Mathematical Reasoning Beyond Accuracy》探讨了数学推理评估的方法，超越传统准确性评估，突出模型能力的综合评估。<br />《Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models》研究了大型语言模型中表格数据的记忆和学习机制，深入了解模型内部工作原理。<br />《Ray Denoising: Depth-aware Hard Negative Sampling for Multi-view 3D Object Detection》提出了一种多视角3D物体检测中的深度感知负向样本采样方法，提升了检测效果。<br />《Policy-Guided Diffusion》介绍了一种基于策略引导的扩散方法，实现高效信息传递和学习。<br />《No Zero-Shot Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance》研究了数据频率对多模态模型性能的影响，提出了基于概念频率的预训练策略。<br />《Lightning NeRF: Efficient Hybrid Scene Representation for Autonomous Driving》提出了一种高效的混合场景表示方法，适用于自动驾驶应用。<br />《3D Pose Estimation of Two Interacting Hands from a Monocular Event Camera》介绍了一种从单目事件相机中估计两只手的三维姿态的方法，适用于复杂交互场景。 <div>
几篇论文实现代码：<br />《Negative Label Guided OOD Detection with Pretrained Vision-Language Models》(ICLR 2024) GitHub: github.com/XueJiang16/NegLabel [fig3] <br />《Video-Based Human Pose Regression via Decoupled Space-Time Aggregation》(CVPR 2024) GitHub: github.com/zgspose/DSTA [fig1]<br />《Timbre-Trap: A Low-Resource Framework for Instrument-Agnostic Music Transcription》(2024) GitHub: github.com/sony/timbre-trap<br />《Evaluating Mathematical Reasoning Beyond Accuracy》(2024) GitHub: github.com/GAIR-NLP/ReasonEval<br />《Elephants Never Forget: Memorization and Learning of Tabular Data in<br />  Large Language Models》(2024) GitHub: github.com/interpretml/LLM-Tabular-Memorization-Checker<br />《Ray Denoising: Depth-aware Hard Negative Sampling for Multi-view 3D Object Detection》(2024) GitHub: github.com/LiewFeng/RayDN [fig2]<br />《Policy-Guided Diffusion》(2024) GitHub: github.com/EmptyJackson/policy-guided-diffusion<br />《No Zero-Shot Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance》(2024) GitHub: github.com/bethgelab/frequency_determines_performance<br />《Lightning NeRF: Efficient Hybrid Scene Representation for Autonomous Driving》(2024) GitHub: github.com/VISION-SJTU/Lightning-NeRF<br />《3D Pose Estimation of Two Interacting Hands from a Monocular Event Camera》(2024) GitHub: github.com/Chris10M/Ev2Hands<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoq8cemphhj24071nn4dv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoqbkzwmygj21cu0ljwth.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoqcz1hfmuj21960eh10b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 06:56:17 GMT</pubDate>
</item>
<item>
<title>【收集了基于 NeRF的逆渲染论文的资源集合】'Awesome-Inverse-Rendering - A collection of papers on NeRF-Based Inverse Rendering.' GitHub: github.com/ingr...</title>
<link>https://weibo.com/1402400261/O9Gg84AxH</link>
<guid>https://weibo.com/1402400261/O9Gg84AxH</guid>
<content:encoded><![CDATA[
<div> GitHub, NeRF, 逆渲染, 论文, 资源, 集合, 知识库, 搜索, 提取, NeRF-Based<br />
<br />NeRF-Based逆渲染论文资源集合。
NeRF是目前逆渲染研究中的热门技术之一，该资源集合汇总了基于NeRF的逆渲染论文，是一个非常有用的知识库。用户可以在该GitHub页面上查找相关的研究文献，从中提取出自己感兴趣的信息。这个集合不仅提供了深入了解NeRF技术的机会，也为研究者和开发者提供了宝贵的资源。通过这些论文，我们可以了解到逆渲染领域的最新进展，从而促进该领域的研究和应用。在这个资源集合中，用户可以搜索有关NeRF的各种信息和文献，帮助他们更好地掌握逆渲染技术的核心概念和应用方法。该资源集合的建立为研究者和开发者提供了便利，有助于推动逆渲染领域的发展和创新。<br /><br />总结: <br />NeRF-Based逆渲染论文资源集合是一个汇总了基于NeRF的逆渲染论文的知识库，用户可以从中搜索并提取相关信息，了解逆渲染领域的最新进展，提升技术水平。 <div>
【收集了基于 NeRF的逆渲染论文的资源集合】'Awesome-Inverse-Rendering - A collection of papers on NeRF-Based Inverse Rendering.' GitHub: github.com/ingra14m/Awesome-Inverse-Rendering <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoqd6x89vmj210f0u0q7d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 06:53:49 GMT</pubDate>
</item>
<item>
<title>【Mltraq：一个开源 Python 库，专门为 AI 开发人员设计、执行和共享实验，可以跟踪任意内容，流式传输、复现、协作和在任何地方恢复计算状态】'Mltraq - Track ...</title>
<link>https://weibo.com/1402400261/O9GcfD9iI</link>
<guid>https://weibo.com/1402400261/O9GcfD9iI</guid>
<content:encoded><![CDATA[
<div> 开源 Python 库, AI 开发人员, 实验, 跟踪, 流式传输, 复现, 协作, 恢复计算状态

<br /><br />总结:
Mltraq是一个开源的Python库，专门为AI开发人员设计，用于执行和共享实验。它具有跟踪任意内容、流式传输、复现、协作和在任何地方恢复计算状态的功能。通过GitHub上的项目，用户可以轻松地跟踪和协作AI实验，提高团队的工作效率。 <div>
【Mltraq：一个开源 Python 库，专门为 AI 开发人员设计、执行和共享实验，可以跟踪任意内容，流式传输、复现、协作和在任何地方恢复计算状态】'Mltraq - Track and Collaborate on AI Experiments. - Track and Collaborate on AI Experiments.' GitHub: github.com/elehcimd/mltraq <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoqcwbwouyj21740sw0wm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 06:44:16 GMT</pubDate>
</item>
<item>
<title>【Sequel: 开源的个性化健康助手，旨在帮助用户通过个性化的营养来控制健康】'Sequel: Your Longevity Assistant - Personalized longevity assistant' GitHub: ...</title>
<link>https://weibo.com/1402400261/O9G7c9tea</link>
<guid>https://weibo.com/1402400261/O9G7c9tea</guid>
<content:encoded><![CDATA[
<div> 个性化健康助手、开源、控制健康、营养、助用户、长寿助手、GitHub、SequelHQ、个性化、健康

<br /><br />总结:
本文介绍了一个开源的个性化健康助手Sequel，旨在帮助用户通过个性化的营养来控制健康。该助手可以根据用户的个人需求和身体状况，提供个性化的健康建议和营养方案，助用户更好地管理健康。用户可以在GitHub上找到该项目的代码和资源，可以更加深入地了解和使用这个个性化的长寿助手。Sequel致力于帮助用户通过个性化的健康管理，提升生活质量，延长寿命。 <div>
【Sequel: 开源的个性化健康助手，旨在帮助用户通过个性化的营养来控制健康】'Sequel: Your Longevity Assistant - Personalized longevity assistant' GitHub: github.com/SequelHQ/Sequel <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoqck1d0aaj21020u0wix.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 06:31:48 GMT</pubDate>
</item>
<item>
<title>【MiniCPM-V和OmniLMM 是面向图文理解的开源多模态大模型系列】'MiniCPM-V 2.0: An Efficient End-side MLLM with Strong OCR and Understanding Capabilities' ...</title>
<link>https://weibo.com/1402400261/O9FZFxfXD</link>
<guid>https://weibo.com/1402400261/O9FZFxfXD</guid>
<content:encoded><![CDATA[
<div> Efficient, End-side, MLLM, OCR, Understanding, Capabilities, MiniCPM-V, 2.0, 多模态大模型

<br /><br />总结：
MiniCPM-V 2.0 是一个高效的端到端多模态大模型，具有强大的OCR和理解能力。该模型在图文理解领域取得了显著进展，通过对图像和文字进行联合训练，实现了强大的文本识别和理解。MiniCPM-V 2.0 继承了前作的优点，同时在模型效率和功能方面进行了优化，可以应用于各种多模态任务，并在GitHub上开源供大家使用。MiniCPM-V 的出现为图文理解领域注入了新的活力，为研究者和开发者提供了强大的工具和资源。 <div>
【MiniCPM-V和OmniLMM 是面向图文理解的开源多模态大模型系列】'MiniCPM-V 2.0: An Efficient End-side MLLM with Strong OCR and Understanding Capabilities' GitHub: github.com/OpenBMB/MiniCPM-V <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoqbr78ztgj21j00ra456.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 06:13:16 GMT</pubDate>
</item>
<item>
<title>【EasyAnimate | Your Animation Generator.：用于生成长视频和训练基于transformer的扩散生成器，基于类SORA结构与DIT，使用transformer进行作为扩散器进行视频...</title>
<link>https://weibo.com/1402400261/O9FR84nMJ</link>
<guid>https://weibo.com/1402400261/O9FR84nMJ</guid>
<content:encoded><![CDATA[
<div> GitHub, EasyAnimate, Animation Generator, 生成长视频, 训练基于transformer的扩散生成器, SORA结构, DIT, 视频生成

<br /><br />总结:
EasyAnimate是一个用于生成长视频和训练基于transformer的扩散生成器的动画生成器。它基于类SORA结构与DIT，使用transformer作为扩散器进行视频生成。用户可以轻松地生成动画，并通过GitHub访问相关资源与代码。 <div>
【EasyAnimate | Your Animation Generator.：用于生成长视频和训练基于transformer的扩散生成器，基于类SORA结构与DIT，使用transformer进行作为扩散器进行视频生成】’EasyAnimate | Your Animation Generator. - Generate your animation easily' GitHub: github.com/aigc-apps/EasyAnimate <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoqbetn8ffj215r0u0wj7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 05:52:13 GMT</pubDate>
</item>
<item>
<title>【Describe：将视频转换为自定义多媒体摘要的应用】'Describe - Incredibly descriptive audiovisual summaries for videos' GitHub: github.com/sieve-communit...</title>
<link>https://weibo.com/1402400261/O9FOJz3Sd</link>
<guid>https://weibo.com/1402400261/O9FOJz3Sd</guid>
<content:encoded><![CDATA[
<div> 视频，自定义，多媒体，摘要，应用，GitHub，描述，音频，视觉，总结

关键词提取完毕。

总结:<br /><br />这个应用程序可以将视频转换为自定义的多媒体摘要，提供了极具描述性的音频和视觉总结功能。用户可以在GitHub上找到该应用程序，通过提取视频内容，生成高质量的摘要信息。应用的功能包括提供详细的文字描述和音频概括，帮助用户更快速地了解视频内容。这个工具可以帮助用户节省时间，并提供多种方式来理解视频内容。 <div>
【Describe：将视频转换为自定义多媒体摘要的应用】'Describe - Incredibly descriptive audiovisual summaries for videos' GitHub: github.com/sieve-community/describe <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoqb8mcnz6j20u01467c1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 05:46:20 GMT</pubDate>
</item>
<item>
<title>【Embed-Photos：基于 MLX 和 CLIP 模型的简单而强大的相似图像搜索网页应用】'Embed-Photos - Super simple MLX (apple silicon) CLIP based photo similarity ...</title>
<link>https://weibo.com/1402400261/O9FNM2Oo8</link>
<guid>https://weibo.com/1402400261/O9FNM2Oo8</guid>
<content:encoded><![CDATA[
<div> MLX, CLIP, 相似图像搜索, 网页应用, GitHub, 强大, 简单, 应用, 图像, MLX

Embed-Photos是一个基于MLX和CLIP模型的相似图像搜索网页应用，具有强大的搜索功能。用户可以在GitHub上找到该应用的代码。该应用设计简单易用，能够快速找到相似的图像。通过MLX和CLIP模型的支持，该应用能够准确地识别相似的图像并进行搜索。如果想要在苹果硅片设备上使用这个应用，Embed-Photos是一个不错的选择。 <div>
【Embed-Photos：基于 MLX 和 CLIP 模型的简单而强大的相似图像搜索网页应用】'Embed-Photos - Super simple MLX (apple silicon) CLIP based photo similarity web app' GitHub: github.com/harperreed/photo-similarity-search <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoqb5b9eskj20u00xptgg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 05:43:57 GMT</pubDate>
</item>
<item>
<title>【《AI-Powered Search》随书代码】’AI-Powered Search - Work in Progress for AI-Powered Search (Manning Publications)' GitHub: github.com/treygrainger/...</title>
<link>https://weibo.com/1402400261/O9FMy45PX</link>
<guid>https://weibo.com/1402400261/O9FMy45PX</guid>
<content:encoded><![CDATA[
<div> AI-Powered Search, GitHub, Manning Publications, 搜索引擎, 人工智能, 代码

<br /><br />总结:
本篇文章介绍了关于AI-Powered Search的工作进展，提供了相关的GitHub链接和出版物信息。AI-Powered Search利用人工智能技术来增强搜索引擎的能力，提高搜索结果的精度和效率。读者可以通过GitHub链接找到相关的代码和资料，深入了解人工智能在搜索领域的应用。通过阅读本文和访问相关资源，读者可以加深对人工智能搜索技术的理解，探索其在实际项目中的应用和潜力。 <div>
【《AI-Powered Search》随书代码】’AI-Powered Search - Work in Progress for AI-Powered Search (Manning Publications)' GitHub: github.com/treygrainger/ai-powered-search <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoqb26xdikj20wu0u0te5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 05:40:56 GMT</pubDate>
</item>
<item>
<title>【Nezha：基于同步时钟的可部署和高性能一致性算法，提供了多种性能优化，如高性能库和数据结构的使用、管道优化等】’Nezha - Nezha: Deployable and High-Perf...</title>
<link>https://weibo.com/1402400261/O9FixwakQ</link>
<guid>https://weibo.com/1402400261/O9FixwakQ</guid>
<content:encoded><![CDATA[
<div> 基于同步时钟、可部署、高性能、一致性算法、性能优化、高性能库、数据结构、管道优化、Nezha、GitHub<br />
<br />
总结:<br />
Nezha是一个基于同步时钟的一致性算法，具有可部署性和高性能特点。该算法利用同步时钟提供多种性能优化，包括高性能库和数据结构的使用，以及管道优化等。通过Nezha，用户能够实现高性能的共识机制，并在GitHub上获取更多相关信息。Nezha的研究为提高系统的一致性和性能提供了新的思路和方法。 <div>
【Nezha：基于同步时钟的可部署和高性能一致性算法，提供了多种性能优化，如高性能库和数据结构的使用、管道优化等】’Nezha - Nezha: Deployable and High-Performance Consensus Using Synchronized Clocks' GitHub: github.com/Steamgjk/Nezha <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoq8w42x96j213h0u0wi2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 14 Apr 2024 04:27:01 GMT</pubDate>
</item>
<item>
<title>【如何更好地处理高复杂度的问题】1、从一个最小的例子开始,然后逐步拓展在处理复杂的问题时，不要直接面对全部的复杂性，而是先从一个简化的最小例子入手，逐步...</title>
<link>https://weibo.com/1402400261/O9DkhgOV3</link>
<guid>https://weibo.com/1402400261/O9DkhgOV3</guid>
<content:encoded><![CDATA[
<div> 调试、简化、记录信息、团队协作、重构代码、高复杂度、问题解决、合作、逐步验证、情景复杂度
总结:<br /><br />处理高复杂度问题时，应从简化的情景开始，逐步增加复杂度。调试时要记录和检测更多信息，与团队协作有助于找到解决方案。通过重构代码减少复杂度，保持简单化思维，逐步验证并与他人沟通合作，能更好处理高复杂度的问题。 <div>
【如何更好地处理高复杂度的问题】<br />1、从一个最小的例子开始,然后逐步拓展<br />在处理复杂的问题时，不要直接面对全部的复杂性，而是先从一个简化的最小例子入手，逐步增加复杂度。这可以让你更清晰地观察问题的不同方面。  <br /><br />2、记录/检测所有的信息<br />调试时，尽可能记录和检测更多的信息，如张量形状、损失、梯度、资源使用等。这些额外的信息能让你更清楚地观察过程，找到问题所在。  <br /><br />3、团队协作<br />向他人讲述和解释问题本身就是一个好的调试方式。与团队成员合作可以让你得到更多补充的知识和看法，更快地找到解决方案。  <br /><br />4、反复重构以减少复杂度<br />代码复杂度会不断增加，这使调试更困难。可以尝试重构代码，将相关部分提取到一个文件或notebook中，以便更清晰地理解。逐步验证后再合并回完整实现。  <br /><br />关键是面对复杂问题时保持简单化的思维，减少关注的变量，逐步拓展和验证，并与他人沟通合作。坚持这些原则可以帮助我们更好地处理高复杂度的问题。  <br />《A few tips for working on high-surface-area problems》 <a href="https://www.answer.ai/posts/2024-04-12-tips.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoq08lo73uj21fx0seaes.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoq08n3urpj21g30kcguc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 23:25:48 GMT</pubDate>
</item>
<item>
<title>【xAI发布多模态AI模型Grok-1.5V】- Grok-1.5V是xAI推出的首个多模态AI模型，不仅具有强大的文本处理能力，还能够处理各种视觉信息，包括文档、图表、截图和照片...</title>
<link>https://weibo.com/1402400261/O9Di5rNLh</link>
<guid>https://weibo.com/1402400261/O9Di5rNLh</guid>
<content:encoded><![CDATA[
<div> 多模态AI模型、Grok-1.5V、文本处理、视觉信息、强大能力、连接数字世界和物理世界、架构、交叉注意力层、VQAv2、NLVR2、测试基准、应用案例、API接口、未来应用、RealWorldQA基准、开发者、创新应用、创新速度、开放精神

<br /><br />总结:
xAI发布了多模态AI模型Grok-1.5V，拥有强大的文本处理和视觉信息处理能力，使其能够更全面地连接数字世界和物理世界。该模型基于先进架构，融合视觉和文本输入，取得在视觉问答和推理任务上的最先进结果。xAI展示了模型在多个应用案例中的实用性，计划未来通过API发布模型接口，并推出新的RealWorldQA基准测试。该模型的发布具有重要意义，展示了xAI的技术实力和创新能力，预示着多模态AI技术将为各行各业带来巨大变革和机遇。xAI的快速发展和开放精神值得持续关注。 <div>
【xAI发布多模态AI模型Grok-1.5V】<br />- Grok-1.5V是xAI推出的首个多模态AI模型，不仅具有强大的文本处理能力，还能够处理各种视觉信息，包括文档、图表、截图和照片等。这使得Grok能够更全面地连接数字世界和物理世界。  <br />- Grok-1.5V在此前发布的语言模型Grok-1.5的基础上，增加了视觉处理能力。它采用了创新的架构，先提取图像或视频的特征，然后使用交叉注意力层将视觉特征与文本输入融合，实现统一的理解。  <br />- 在VQAv2和NLVR2等测试视觉问答和推理能力的基准测试中，Grok-1.5V取得了最先进的结果，超越了GPT-4和Gemini-3等模型。这证明了它在多模态理解方面的强大能力。  <br />- xAI认为像Grok-1.5V这样的多模态AI在现实世界应用中具有巨大潜力。例如分析医学扫描图像、理解电商产品图片，以及处理机器人和自动驾驶汽车中的视频信息等。  <br />- 文章中提供了交互式演示，用户可以上传自己的图片，让Grok-1.5V回答相关问题。这展示了该模型能够对任意用户提供的图像进行推理。  <br />- xAI计划在未来几周内通过API发布Grok-1.5V，以便开发者在自己的应用中利用其多模态能力。公司对此感到兴奋，期待看到这将带来哪些新的用例和体验。  <br />- xAI重点展示了Grok-1.5V的7个应用案例，包括根据手绘图生成Python代码、从食品标签照片中计算卡路里、根据儿童绘画生成睡前故事、解释网络梗图、将表格转换为CSV格式，以及为家庭维修问题(如露台上的腐烂木头)提供建议等。这些案例展示了该模型的多功能性和实用性。<br /><br />思考：  <br />- Grok-1.5V的推出标志着xAI在多模态AI领域取得了重大突破。能够统一处理文本、图像等不同模态信息，将大大拓展AI的应用场景和实用性。这对于构建更加智能、全面的AI助手具有重要意义。  <br />- 在各种视觉问答和推理的基准测试中超越GPT-4、Gemini-3等强模型，充分证明了Grok-1.5V在多模态理解任务上的领先地位。xAI在短短几个月内取得如此进展，展现了其雄厚的技术实力和快速创新的能力。  <br />- 通过一系列实际应用案例，xAI生动地展示了Grok-1.5V在现实世界中的广泛用途，涵盖编程、医疗、电商、教育、生活等各个领域。这让我们看到了多模态AI技术在未来将为各行各业带来的巨大变革和机遇。  <br />- 值得关注的是，xAI还推出了全新的RealWorldQA基准，以评估AI模型对物理世界的理解能力。这表明xAI不仅致力于技术创新，也十分重视构建科学的评估体系。开放RealWorldQA数据集将推动整个AI社区在多模态理解方面的进一步研究。  <br />- xAI计划近期面向开发者开放Grok-1.5V的API接口，可以预见将会催生大量基于多模态AI的创新应用。作为一家成立仅9个月的初创公司，xAI展现出令人惊叹的创新速度和开放精神，其发展值得持续关注。<br />《Grok-1.5 Vision Preview》 <a href="https://x.ai/blog/grok-1.5v"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoq02z7ufjj21cn0u078j.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoq030bkwyj21fr0u0whg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoq035xd79j21240u0tei.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 23:20:24 GMT</pubDate>
</item>
<item>
<title>今日推介(第1375期)：基础模型时代的具身问答、数字Agent的自主评价与改进、理解概念激活向量、通过自动样例生成处理抽象和推理语料库、用图推理增强大型语言模...</title>
<link>https://weibo.com/1402400261/O9CSF4ilM</link>
<guid>https://weibo.com/1402400261/O9CSF4ilM</guid>
<content:encoded><![CDATA[
<div> 具身问答、数字Agent、自主评价、改进、理解概念、激活向量、自动样例生成、抽象、推理语料库、图推理
<br /><br />总结:
本文介绍了基于基础模型的具身问答系统，通过数字Agent实现自主评价和改进。同时探讨了概念的理解和激活向量的作用，提出了利用自动样例生成处理抽象和推理语料库的方法。最后，讨论了如何通过图推理来增强大型语言模型的性能。文章内容涵盖了多个关键领域，可以为研究者和开发者提供启发与借鉴。 <div>
今日推介(第1375期)：基础模型时代的具身问答、数字Agent的自主评价与改进、理解概念激活向量、通过自动样例生成处理抽象和推理语料库、用图推理增强大型语言模型 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/692360403"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.14)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hopy9p4c4dj21da0ra7cj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hopy9r4wd6j21480u0n43.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hopy9tokraj218o0sen3y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hopy9w8xcsj20ze0l4jwo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hopy9ydxvvj20ra0iqdi3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 22:17:44 GMT</pubDate>
</item>
<item>
<title>[CV] Adapting LLaMA Decoder to Vision Transformer 网页链接 通过引入因果自注意力以及相关的训练技巧，探索了LLM中的解码器设计如何迁移到计算机视觉领域，使...</title>
<link>https://weibo.com/1402400261/O9CNigkA8</link>
<guid>https://weibo.com/1402400261/O9CNigkA8</guid>
<content:encoded><![CDATA[
<div> 迁移学习, 自注意力, 相关训练技巧, 解码器设计, 计算机视觉, 图像模型, 语言模型, 架构统一, 分类性能

<br /><br />总结:
本文通过引入因果自注意力以及相关的训练技巧，探索了LLM中的解码器设计如何迁移到计算机视觉领域。这一过程使得图像模型与语言模型在架构上达成统一，并取得了良好的分类性能。通过将LLaMA Decoder适应到Vision Transformer中，实现了对视觉任务的有效应用，为跨领域的信息处理提供了新的思路和方法。在实验中，该方法取得了令人满意的结果，表明了其在图像分类等任务中的优越性。整体而言，本文为解决图像与语言等多模态信息处理问题提供了一个新的思路和实践方法。 <div>
[CV] Adapting LLaMA Decoder to Vision Transformer  <br /><a href="https://arxiv.org/abs/2404.06773"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />通过引入因果自注意力以及相关的训练技巧，探索了LLM中的解码器设计如何迁移到计算机视觉领域，使图像模型与语言模型在架构上达成统一，并取得了良好的分类性能。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopxw7jeq3j20v61astow.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopxw7p9cfj215g0lajyk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopxw89b7ij219y0e0q6g.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 22:04:32 GMT</pubDate>
</item>
<item>
<title>[CL] OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments 网页链接 当前算法在复杂计算机任务上的表现明显不足，仍...</title>
<link>https://weibo.com/1402400261/O9CKtpUYj</link>
<guid>https://weibo.com/1402400261/O9CKtpUYj</guid>
<content:encoded><![CDATA[
<div> 关键词: OSWorld, 多模态智能体, 计算机任务, 界面定位, 操作常识, 算法性能提升

总结:<br /><br />总结: 本文介绍了在复杂计算机任务上表现不足的当前算法，需要提高界面定位、操作常识等能力。OSWorld是一个面向通用Agent的开放式计算机任务基准，支持各主流操作系统、应用程序和界面，为智能体算法提供可靠的环境和数据集。通过OSWorld，研究人员可以针对多模态智能体进行基准测试，评估算法在真实计算机环境中的表现，并提出改进方向。为了取得更好的算法性能，需要不断完善智能体的界面定位能力，提升操作常识，以适应不同复杂计算机任务的需求。通过OSWorld的基准测试，可以促进智能体算法在开放式计算机任务中的发展，推动智能计算领域的进步。 <div>
[CL] OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments  <br /><a href="https://arxiv.org/abs/2404.07972"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />当前算法在复杂计算机任务上的表现明显不足，仍需提高界面定位、操作常识等能力  OSWORLD是一个面向通用Agent的开放式计算机任务基准，支持各主流操作系统、应用程序和界面，为智能体算法提供可靠的环境和数据集。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hopxoyeog7j20vk1bk7ly.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hopxoz7o8gj215q0v4qep.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopxoze2a9j21a20rggwd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 21:57:34 GMT</pubDate>
</item>
<item>
<title>[LG] InfiCoder-Eval: Systematically Evaluating the Question-Answering Capabilities of Code Large Language Models 网页链接 InfiCoder-Eval通过Stack Over...</title>
<link>https://weibo.com/1402400261/O9CHPC8dP</link>
<guid>https://weibo.com/1402400261/O9CHPC8dP</guid>
<content:encoded><![CDATA[
<div> InfiCoder-Eval, Systematically Evaluating, Question-Answering, Code Large Language Models, Stack Overflow, 覆盖面广, 指标设计合理, 自由问答能力, 重要基础<br />
<br />
重点介绍了InfiCoder-Eval的评估方法和指标设计，该评估系统通过Stack Overflow问题对代码语言模型的问答能力进行全面评估。该方法具有广泛的覆盖面和合理的设计，为未来研究提供了重要基础，有助于提升代码语言模型的性能和效果。此评估系统的发展和应用为代码语言模型领域的进一步研究和发展提供了重要参考和支持。InfiCoder-Eval通过全面评估代码模型的自由问答能力，为研究提供了重要的方法和工具，有望推动代码语言模型领域的发展和创新。<br /><br />总结: InfiCoder-Eval是一个系统评估方法，通过对代码语言模型的问答能力进行全面评估，具有广泛覆盖面和合理设计，为未来研究提供了重要基础，有助于推动代码语言模型领域的发展。 <div>
[LG] InfiCoder-Eval: Systematically Evaluating the Question-Answering Capabilities of Code Large Language Models  <br /><a href="https://arxiv.org/abs/2404.07940"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />InfiCoder-Eval通过Stack Overflow问题构建，覆盖面广，指标设计合理，可以系统全面地评估代码语言模型的自由问答能力，为未来研究提供重要基础。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopxi6hejcj210a1aond9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopxi6ut2uj20wg0smteu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopxi7dj3yj21em0yudpk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 21:51:05 GMT</pubDate>
</item>
<item>
<title>[CL] Multilingual Large Language Model: A Survey of Resources, Taxonomy and Frontiers 网页链接 全面回顾多语言大模型研究，提出参数微调对齐与参数冻结对...</title>
<link>https://weibo.com/1402400261/O9CELnKCq</link>
<guid>https://weibo.com/1402400261/O9CELnKCq</guid>
<content:encoded><![CDATA[
<div> 模型资源、参数微调、参数冻结、多语言、分类法、方法、前沿、指导、研究

总结:<br />
本文全面回顾了多语言大模型研究领域的资源、分类法和前沿探索。其中提出了参数微调对齐和参数冻结对齐的统一分类法，并讨论了相关方法、资源和新兴前沿。通过这些内容为研究工作提供了指导，并为未来的研究方向提供了启示。整体来看，本文对多语言大模型研究领域进行了深入的探讨，丰富了领域内的研究内容，为相关研究者提供了有益的参考和指导。 <div>
[CL] Multilingual Large Language Model: A Survey of Resources, Taxonomy and Frontiers  <br /><a href="https://arxiv.org/abs/2404.04925"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />全面回顾多语言大模型研究，提出参数微调对齐与参数冻结对齐的统一分类法，讨论方法、资源与新兴前沿，为研究提供指导。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopxaacvjfj20wa1by1bn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hopxaaw5djj21pg0yih1j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopxab96cnj20uq0reah6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hopxabxwizj21bm1bknnw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 21:43:31 GMT</pubDate>
</item>
<item>
<title>构建了图推理基准数据集，并设计GRAPH-COT框架使LLM能在图上迭代推理，综合利用了图的结构和语义信息。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Graph Chain-of-Thou...</title>
<link>https://weibo.com/1402400261/O9CB3u8jW</link>
<guid>https://weibo.com/1402400261/O9CB3u8jW</guid>
<content:encoded><![CDATA[
<div> Graph Chain-of-Thought, Large Language Models, 图推理基准数据集, GRAPH-COT框架, 迭代推理, 图的结构, 语义信息, University of Illinois at Urbana-Champaign

总结:<br />
该论文介绍了一种名为GRAPH-COT的框架，用于增强大型语言模型（LLM）的推理能力。作者构建了图推理基准数据集，并设计了GRAPH-COT框架，使LLM可以在图上进行迭代推理，综合利用了图的结构和语义信息。该框架为LLM引入了图推理能力，进一步提升了其在推理任务上的表现。研究结果表明，通过在图上进行推理，LLM在各种推理任务上的性能都得到了显著提升。这一研究为将图结构引入到自然语言处理领域提供了新的思路和方法。 <div>
构建了图推理基准数据集，并设计GRAPH-COT框架使LLM能在图上迭代推理，综合利用了图的结构和语义信息。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs》B Jin, C Xie, J Zhang, K K Roy, Y Zhang, S Wang, Y Meng, J Han [University of Illinois at Urbana-Champaign] (2024) <a href="https://arxiv.org/abs/2404.07103"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopwvdqtm1j20nk19sqe8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopwve9gw3j20ra0iqtbt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopwvepbq0j21ha0iw0zn.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopwvexvm2j20qm0niad8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopwvm0kkij20hr0fd0tl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopwvm1jmoj20zx0hgjv3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopwvm3zbqj20zx1g612o.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 21:34:23 GMT</pubDate>
</item>
<item>
<title>[CL]《Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs》B Jin, C Xie, J Zhang, K K Roy, Y Zhang, S Wang, Y Meng, J Han ...</title>
<link>https://weibo.com/1402400261/O9CB1mKZf</link>
<guid>https://weibo.com/1402400261/O9CB1mKZf</guid>
<content:encoded><![CDATA[
<div> 大语言模型，图链思维，增强，推理，图形，University of Illinois at Urbana-Champaign，2024

提出了一种新的方法，名为Graph Chain-of-Thought，可以增强大语言模型的推理能力。该方法使用图形结构来表示文本数据，通过在图上进行推理和推断来提高模型的性能。研究团队来自University of Illinois at Urbana-Champaign，在2024年发表了这篇论文。他们的方法能够在处理自然语言文本时，根据文本之间的关系和语义信息搭建起图形结构，从而帮助模型更好地理解和推理文本内容。这种基于图形的推理方法在大语言模型的发展中具有重要意义，可以为语言模型的进一步发展奠定基础。Graph Chain-of-Thought方法的提出为解决自然语言处理中的推理问题提供了新的思路和技术手段，有望为相关研究领域带来新的突破和进展。<br /><br />总结:通过图形推理方法，Graph Chain-of-Thought有望增强大语言模型的推理能力，帮助模型更好地理解和推理自然语言文本，为语言模型的发展提供重要思路和技术支持。 <div>
[CL]《Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs》B Jin, C Xie, J Zhang, K K Roy, Y Zhang, S Wang, Y Meng, J Han [University of Illinois at Urbana-Champaign] (2024) <a href="https://arxiv.org/abs/2404.07103"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopwvdqtm1j20nk19sqe8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopwve9gw3j20ra0iqtbt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopwvepbq0j21ha0iw0zn.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopwvexvm2j20qm0niad8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopwvm0kkij20hr0fd0tl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopwvm1jmoj20zx0hgjv3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopwvm3zbqj20zx1g612o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 21:34:18 GMT</pubDate>
</item>
<item>
<title>通过为抽象推理语料库(ARC)任务设计示例生成器，可大幅扩充每个任务的样本量，以支持针对少样本泛化能力的实验。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Addressing...</title>
<link>https://weibo.com/1402400261/O9Cy2qgvR</link>
<guid>https://weibo.com/1402400261/O9Cy2qgvR</guid>
<content:encoded><![CDATA[
<div> 抽象推理语料库(ARC)、示例生成器、样本量、少样本泛化能力、实验、ETH Zurich、M Hodel、文章、地址、解决、过程、扩充、任务<br />
<br />
总结:<br />
本文介绍了通过设计示例生成器来扩充抽象推理语料库(ARC)任务的样本量，以支持针对少样本泛化能力的实验。作者M Hodel来自ETH Zurich，在文章中提出了解决ARC任务的方法。他通过设计过程来生成示例，从而大幅扩充了每个任务的样本量。这种方法旨在提高模型的泛化能力，并为少样本学习提供支持。通过这种创新的方法，可以有效地解决ARC任务中样本量不足的问题，为相关研究提供了新的思路和方法。 <div>
通过为抽象推理语料库(ARC)任务设计示例生成器，可大幅扩充每个任务的样本量，以支持针对少样本泛化能力的实验。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Addressing the Abstraction and Reasoning Corpus via Procedural Example Generation》M Hodel [ETH Zurich] (2024) <a href="https://arxiv.org/abs/2404.07353"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopwskiguxj20ze0l4tj0.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 21:26:56 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.13)》 爱可可微博热门分享(4.13) [图片]</title>
<link>https://weibo.com/1402400261/O9zTomcPj</link>
<guid>https://weibo.com/1402400261/O9zTomcPj</guid>
<content:encoded><![CDATA[
<div> 分享, 爱可可, 微博, 热门, 4.13, 社交媒体, 精彩内容, 热点话题, 关注, 点赞

<br /><br />总结：
爱可可微博于4月13日分享了一些热门内容，吸引了大量关注和点赞。这些精彩内容涉及社交媒体上的热点话题，持续引起用户的兴趣。关注爱可可微博，可以及时了解各种热门话题，获取信息。 <div>
《爱可可微博热门分享(4.13)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405022829266468961"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.13)</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopl2wya6xj20rs0fmgoi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 14:41:19 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Less is More: Fewer Interpretable Region via Submodular Subset Selection》(ICLR 2024) GitHub: github.com/RuoyuChen10/SMDL-Attribut...</title>
<link>https://weibo.com/1402400261/O9yDw1Wbq</link>
<guid>https://weibo.com/1402400261/O9yDw1Wbq</guid>
<content:encoded><![CDATA[
<div> 关键词: 论文代码, GitHub, 图像分割, 自然语言处理, 三维重建, 模型改进, 机器学习, 自监督学习, 图像去噪, 深度学习

总结:
<br /><br />这篇文章介绍了几篇以论文实现代码为基础的研究成果，涉及图像分割、自然语言处理、三维重建等多个领域。通过GitHub链接可以查看到每篇论文代码的具体实现。其中一些论文探讨了模型改进的方法，包括自监督学习、图像去噪等技术的应用，为机器学习领域的发展提供了新的思路和实验结果。这些研究成果对于深度学习和人工智能领域的进步具有重要意义。 <div>
几篇论文实现代码：<br />《Less is More: Fewer Interpretable Region via Submodular Subset Selection》(ICLR 2024) GitHub: github.com/RuoyuChen10/SMDL-Attribution [fig7]<br />《GoMVS: Geometrically Consistent Cost Aggregation for Multi-View Stereo》(CVPR 2024) GitHub: github.com/Wuuu3511/GoMVS [fig2]<br />《MindBridge: A Cross-Subject Brain Decoding Framework》(CVPR 2024) GitHub: github.com/littlepure2333/MindBridge [fig6]<br />《DemoCaricature: Democratising Caricature Generation with a Rough Sketch》(CVPR 2024) GitHub: github.com/ChenDarYen/DemoCaricature<br />《Object Pose Estimation via the Aggregation of Diffusion Features》(CVPR 2024) GitHub: github.com/Tianfu18/diff-feats-pose<br />《PEM: Prototype-based Efficient MaskFormer for Image Segmentation》(CVPR 2024) GitHub: github.com/NiccoloCavagnero/PEM<br />《Bridging the Gap Between End-to-End and Two-Step Text Spotting》(CVPR 2024) GitHub: github.com/mxin262/Bridging-Text-Spotting<br />《Unsupervised Continual Anomaly Detection with Contrastively-learned Prompt》(AAAI 2024) GitHub: github.com/shirowalker/UCAD [fig9]<br />《Autonomous Evaluation and Refinement of Digital Agents》(2024) GitHub: github.com/Berkeley-NLP/Agent-Eval-Refine [fig1]<br />《latentSplat: Autoencoding Variational Gaussians for Fast Generalizable 3D Reconstruction》(2024) GitHub: github.com/Chrixtar/latentsplat<br />《From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples》(2024) GitHub: github.com/robertvacareanu/llm4regression<br />《iSeg: Interactive 3D Segmentation via Interactive Attention》(2024) GitHub: github.com/threedle/iSeg<br />《GoMAvatar: Efficient Animatable Human Modeling from Monocular Video Using Gaussians-on-Mesh》(2024) GitHub: github.com/wenj/GoMAvatar<br />《Autonomous Evaluation and Refinement of Digital Agents》(2024) GitHub: github.com/Berkeley-NLP/Agent-Eval-Refine [fig3]<br />《MonoOcc: Digging into Monocular Semantic Occupancy Prediction》(2024) GitHub: github.com/ucaszyp/MonoOcc [fig4]<br />《OS-Copilot: Towards Generalist Computer Agents with Self-Improvement》(2024) GitHub: github.com/OS-Copilot/OS-Copilot [fig5]<br />《GoodDrag: Towards Good Practices for Drag Editing with Diffusion Models》(2024) GitHub: github.com/zewei-Zhang/GoodDrag<br />《LLoCO: Learning Long Contexts Offline》(2024) GitHub: github.com/jeffreysijuntan/lloco [fig8]<br />《TBSN: Transformer-Based Blind-Spot Network for Self-Supervised Image Denoising》(2024) GitHub: github.com/nagejacob/TBSN<br />《AutoTimes: Autoregressive Time Series Forecasters via Large Language Models》(2024) GitHub: github.com/thuml/AutoTimes<br />《Visual Foundation Models Boost Cross-Modal Unsupervised Domain Adaptation for 3D Semantic Segmentation》(2024) GitHub: github.com/EtronTech/VFMSeg<br />《VLFM: Vision-Language Frontier Maps for Zero-Shot Semantic Navigation》(2024) GitHub: github.com/bdaiinstitute/vlfm<br />《Source Prompt Disentangled Inversion for Boosting Image Editability with Diffusion Models》(2024) GitHub: github.com/leeruibin/SPDInv<br />《Improving Diffusion Models for Virtual Try-on》(2024) GitHub: github.com/yisol/IDM-VTON<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hop3svw3p5j21uq15gtyk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopd3c82bxj21p216qqfp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hopd7cbid5j21uq15gtyk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hopdovqaypj20ui0fuqea.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hope9vvv0dj21fa0noe6m.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopect8xl8j23yw27vnpe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hopef16vohj20qo0k0dpy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hopeidzwncj21po0k0dof.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hopej7mmj3j20yy0dxwmm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 11:29:26 GMT</pubDate>
</item>
<item>
<title>'icegl-three-vue-tres - 让三维可视化项目快速落地の开源框架，永久开源，免费商用' GitHub: github.com/hawk86104/icegl-three-vue-tres #开源# [图片][图片][...</title>
<link>https://weibo.com/1402400261/O9yDtdr8a</link>
<guid>https://weibo.com/1402400261/O9yDtdr8a</guid>
<content:encoded><![CDATA[
<div> GitHub、icegl-three-vue-tres、开源、框架、三维可视化、快速落地、永久、免费商用

<br /><br />总结:
icegl-three-vue-tres是一个开源框架，旨在帮助三维可视化项目快速落地，永久开源且免费商用。该项目托管在GitHub上，用户可以下载并使用。这个框架的目标是提供简单易用的工具和功能，让开发者可以快速构建出精美的三维可视化项目。通过icegl-three-vue-tres，开发者可以节省大量时间和精力，快速开发出符合需求的三维可视化应用。 <div>
'icegl-three-vue-tres - 让三维可视化项目快速落地の开源框架，永久开源，免费商用' GitHub: github.com/hawk86104/icegl-three-vue-tres <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hopfj2ws4lj20m80gowp2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hopfj4flcpj20m80gogr4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hopfj5mfd9j20m80godmy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hopfj77mo6j20m80gomyk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hopfj8a1h3j20m80gon3e.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hopfj9oniuj20m80gogut.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 11:29:21 GMT</pubDate>
</item>
<item>
<title>【360 智脑大模型采用高质量语料库进行训练，在相关基准评测中表现出有竞争力。开放了 4K 和 32K 的对话模型，并提供了模型评估和快速开始的指南】'360Zhinao (3...</title>
<link>https://weibo.com/1402400261/O9yzF0ZTr</link>
<guid>https://weibo.com/1402400261/O9yzF0ZTr</guid>
<content:encoded><![CDATA[
<div> 360智脑、模型评测、竞争力、4K、32K、语料库、训练、指南、GitHub、开放<br />
<br />
总结:<br />
360智脑大模型采用高质量语料库进行训练，在相关基准评测中表现出有竞争力。该项目在GitHub上开放了4K和32K的对话模型，并提供了模型评估和快速开始的指南，为研究人员和开发者提供了良好的资源和支持。 <div>
【360 智脑大模型采用高质量语料库进行训练，在相关基准评测中表现出有竞争力。开放了 4K 和 32K 的对话模型，并提供了模型评估和快速开始的指南】'360Zhinao (360智脑)' GitHub: github.com/Qihoo360/360zhinao <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hopf9k1ibjj217w0u041z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 11:19:57 GMT</pubDate>
</item>
<item>
<title>【Latent Box：AI、创意和艺术领域的精选合集】'Latent Box - A collection of awesome-lists for AI, creativity and art.' 网页链接 GitHub: github.com/laten...</title>
<link>https://weibo.com/1402400261/O9yvz0fxP</link>
<guid>https://weibo.com/1402400261/O9yvz0fxP</guid>
<content:encoded><![CDATA[
<div> GitHub, Latent Box, AI, 创意, 艺术, 合集, awesome-lists, latentcat, 精选合集

<br /><br />总结: 
Latent Box是一个GitHub仓库，汇集了AI、创意和艺术领域的精选合集，包括了各种优秀资源列表。这个项目为对这些领域感兴趣的人提供了一个宝库，可以找到各种有用的信息和资源。人们可以通过这个合集深入了解AI、创意和艺术的发展前沿，从中汲取灵感并探索新的可能性。Latent Box的存在为这些领域的研究和创作提供了更多的支持和帮助，推动着这些领域的不断发展和进步。 <div>
【Latent Box：AI、创意和艺术领域的精选合集】'Latent Box - A collection of awesome-lists for AI, creativity and art.' <a href="https://latentbox.com/zh"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> GitHub: github.com/latentcat/latentbox <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hopey4qssrj20vr0u043l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 11:09:52 GMT</pubDate>
</item>
<item>
<title>【Tango：TypeScript 重新实现的 ADB（Android Debugging Bridge）客户端，可以在基于 Chromium 的浏览器（包括 Chrome for Android）、Node.js 和 Electron 中...</title>
<link>https://weibo.com/1402400261/O9yofjKrQ</link>
<guid>https://weibo.com/1402400261/O9yofjKrQ</guid>
<content:encoded><![CDATA[
<div> TypeScript, ADB, Android Debugging Bridge, Chromium, 浏览器, Node.js, Electron, GitHub, ya-webadb

<br /><br />总结:
Tango是一个用TypeScript重新实现的ADB客户端，可以在基于Chromium的浏览器（包括Chrome for Android）、Node.js和Electron中运行。通过GitHub项目ya-webadb提供。 <div>
【Tango：TypeScript 重新实现的 ADB（Android Debugging Bridge）客户端，可以在基于 Chromium 的浏览器（包括 Chrome for Android）、Node.js 和 Electron 中运行】'Tango - ADB in your browser' GitHub: github.com/yume-chan/ya-webadb <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hopegajqirj213q0u0wht.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 10:51:50 GMT</pubDate>
</item>
<item>
<title>【多模态大语言模型(MLLM)安全性相关论文资源列表】’Awesome-MLLM-Safety - "Safety is defined as stopping models from following malicious instructions an...</title>
<link>https://weibo.com/1402400261/O9yfpzKw5</link>
<guid>https://weibo.com/1402400261/O9yfpzKw5</guid>
<content:encoded><![CDATA[
<div> 安全性、多模态大语言模型、资源列表、GitHub、MLLM、恶意指令、有害内容、论文、相关、推荐

总结：<br /><br />
这篇资源列表汇总了与多模态大语言模型安全性相关的论文、资源和工具。安全性在这里定义为阻止模型遵循恶意指令并生成有害内容。GitHub上提供了更多详细信息和相关链接。对于研究多模态大语言模型安全性的学者和从业者来说，这个资源列表是一个很好的参考工具。 <div>
【多模态大语言模型(MLLM)安全性相关论文资源列表】’Awesome-MLLM-Safety - "Safety is defined as stopping models from following malicious instructions and generating toxic content."' GitHub: github.com/isXinLiu/Awesome-MLLM-Safety <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hopdske87cj20u010ltdg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 10:30:05 GMT</pubDate>
</item>
<item>
<title>【UnInbox：现代化的电子邮件工具，专门为团队和专业人士设计，旨在替代陈旧的电子邮件技术和工具】'UnInbox - Modern email for teams and professionals. A re...</title>
<link>https://weibo.com/1402400261/O9yeEzDAW</link>
<guid>https://weibo.com/1402400261/O9yeEzDAW</guid>
<content:encoded><![CDATA[
<div> UnInbox、现代化、电子邮件工具、团队、专业人士、替代、陈旧、技术、hey.com、front.com

<br /><br />总结:
UnInbox是一款专门为团队和专业人士设计的现代化电子邮件工具，旨在替代陈旧的电子邮件技术和工具，可作为hey.com、front.com和missiveapp.com的替代品。其开源代码可于GitHub上找到。 <div>
【UnInbox：现代化的电子邮件工具，专门为团队和专业人士设计，旨在替代陈旧的电子邮件技术和工具】'UnInbox - Modern email for teams and professionals. A replacement for outdated email technology and tools. Alt to hey.com, front.com, missiveapp.com' GitHub: github.com/un/inbox <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hopdro1aanj20u00u3mzi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 10:28:13 GMT</pubDate>
</item>
<item>
<title>【PicProse：用于生成中等规模平台封面图像的工具，如 Medium、YouTube、BiliBili 和博客等】'PicProse is a better cover image generator tool for Medium, Yo...</title>
<link>https://weibo.com/1402400261/O9ydYkqyn</link>
<guid>https://weibo.com/1402400261/O9ydYkqyn</guid>
<content:encoded><![CDATA[
<div> GitHub, PicProse, 封面图像生成工具, Medium, YouTube, BiliBili, 博客<br />
<br />总结:
PicProse 是一个用于生成中等规模平台封面图像的工具，适用于 Medium、YouTube、BiliBili 和博客等。GitHub 上有其代码库，PicProse 提供了更好的封面图像生成功能，可以帮助用户制作更加吸引人的封面图像，提升内容的吸引力和可视化效果。PicProse 的功能包括覆盖多种平台，为用户提供更加灵活的定制化选项，是一个值得尝试的工具。 <div>
【PicProse：用于生成中等规模平台封面图像的工具，如 Medium、YouTube、BiliBili 和博客等】'PicProse is a better cover image generator tool for Medium, YouTube, BiliBili, Blog and many others' GitHub: github.com/gezhaoyou/picprose <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hopdpi1xwwj21k00u078i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 10:26:32 GMT</pubDate>
</item>
<item>
<title>'1000UserGuide：300多个帮独立开发者和创业者推广产品、找到前1000个早期用户的国内外渠道适合独立开发者和创业者推广产品的渠道' GitHub: github.com/naxiaodu...</title>
<link>https://weibo.com/1402400261/O9ybCm1Ue</link>
<guid>https://weibo.com/1402400261/O9ybCm1Ue</guid>
<content:encoded><![CDATA[
<div> GitHub, 推广产品, 开发者, 创业者, 渠道, 用户, 早期用户, 国内外, 独立, 找到

<br /><br />总结:
本文介绍了一个名为'1000UserGuide'的指南，旨在帮助独立开发者和创业者找到适合推广产品、寻找前1000个早期用户的国内外渠道。通过该指南，用户可以学习如何有效地推广产品，找到目标用户，并提升产品的知名度。GitHub链接为github.com/naxiaoduo/1000UserGuide。 <div>
'1000UserGuide：300多个帮独立开发者和创业者推广产品、找到前1000个早期用户的国内外渠道适合独立开发者和创业者推广产品的渠道' GitHub: github.com/naxiaoduo/1000UserGuide <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hopdjw16qyj20uj0u0jvi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 10:20:44 GMT</pubDate>
</item>
<item>
<title>【tu：可以将自然语言日期/时间字符串转换为UTC时间格式的命令行工具】’tu - CLI tool to convert a natural language date/time string to UTC' GitHub: githu...</title>
<link>https://weibo.com/1402400261/O9y7E5Hjv</link>
<guid>https://weibo.com/1402400261/O9y7E5Hjv</guid>
<content:encoded><![CDATA[
<div> 关键词: tu, 自然语言日期, 时间字符串, UTC时间格式, 命令行工具, GitHub, 转换, CLI, 工具<br />
<br />
总结:<br />
本文介绍了一个名为tu的命令行工具，可以将自然语言日期/时间字符串转换为UTC时间格式。用户可以在GitHub上找到该工具的源代码。tu可以帮助用户快速准确地将日期/时间转换为UTC时间，提高工作效率。用户只需输入待转换的日期/时间字符串，tu即可完成转换并输出UTC时间，方便用户进行时间转换和计算。这个工具简单易用，适用于有时间转换需求的用户。详细使用方法和安装步骤可以在GitHub页面找到。如果你常常需要转换不同时区的时间，tu可能会成为你的实用工具之一。 <div>
【tu：可以将自然语言日期/时间字符串转换为UTC时间格式的命令行工具】’tu - CLI tool to convert a natural language date/time string to UTC' GitHub: github.com/ad-si/tu <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hopd93pxorj20u00zs41r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 10:10:56 GMT</pubDate>
</item>
<item>
<title>【基于大语言模型的游戏Agent研究相关论文资源列表】’A Survey on Large Language Model-Based Game Agents - A Survey on Large Language Model-Based Game Ag...</title>
<link>https://weibo.com/1402400261/O9vZuwqpg</link>
<guid>https://weibo.com/1402400261/O9vZuwqpg</guid>
<content:encoded><![CDATA[
<div> 大语言模型、游戏Agent、调查、资源、GitHub、研究、论文

<br /><br />总结：
这篇论文调查了基于大语言模型的游戏Agent的相关研究和资源，并提供了GitHub链接。研究着重于分析当前领域的论文和发展趋势，为感兴趣的研究者提供了宝贵的参考资源。GitHub上的资料丰富多样，有助于进一步了解和深入探讨大语言模型在游戏Agent领域的应用和发展。 <div>
【基于大语言模型的游戏Agent研究相关论文资源列表】’A Survey on Large Language Model-Based Game Agents - A Survey on Large Language Model-Based Game Agents' GitHub: github.com/git-disl/awesome-LLM-game-agent-papers <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hop3uf9qssj21bw0u043p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 04:45:22 GMT</pubDate>
</item>
<item>
<title>【一个机器学习知识库，涵盖了从基础到高级主题的机器学习知识，包括模型架构、训练和微调、推理和运行策略、应用等。其目的是帮助新的 Elicit 员学习机器学习背...</title>
<link>https://weibo.com/1402400261/O9vYqqAvW</link>
<guid>https://weibo.com/1402400261/O9vYqqAvW</guid>
<content:encoded><![CDATA[
<div> GitHub, 机器学习, 知识库, 模型架构, 训练, 微调, 推理, 运行策略, 应用, 语言模型
<br /><br />总结:
这篇文章介绍了一个名为"Elicit Machine Learning Reading List"的机器学习知识库，包含从基础到高级主题的机器学习知识，重点关注语言模型。知识库涵盖了模型架构、训练和微调、推理和运行策略、应用等多个方面，旨在帮助新的Elicit员学习机器学习背景。通过GitHub平台可以访问该知识库，学习和探索其中的内容。 <div>
【一个机器学习知识库，涵盖了从基础到高级主题的机器学习知识，包括模型架构、训练和微调、推理和运行策略、应用等。其目的是帮助新的 Elicit 员学习机器学习背景，重点关注语言模型】’Elicit Machine Learning Reading List' GitHub: github.com/elicit/machine-learning-list <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hop3s83d9hj21740lagoy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 04:42:43 GMT</pubDate>
</item>
<item>
<title>【面向科学和工程领域表现的大模型排行榜】《Science Leaderboard - a Hugging Face Space by TIGER-Lab》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O9uLuAk2K</link>
<guid>https://weibo.com/1402400261/O9uLuAk2K</guid>
<content:encoded><![CDATA[
<div> 大模型排行榜, 科学, 工程, 模型性能, Hugging Face, TIGER-Lab

<br /><br />总结:
文章介绍了由TIGER-Lab打造的《Science Leaderboard - a Hugging Face Space》，该平台旨在建立一个面向科学和工程领域的大模型排行榜。用户可以在这个空间中比较各种大型预训练模型在不同任务上的性能表现，帮助研究人员更好地选择合适的模型。这个排行榜集成了来自不同研究团队的模型，为用户提供了一个全面的参考，对促进科学和工程领域的研究工作具有积极意义。 <div>
【面向科学和工程领域表现的大模型排行榜】《Science Leaderboard - a Hugging Face Space by TIGER-Lab》 <a href="https://huggingface.co/spaces/TIGER-Lab/Science-Leaderboard"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hooyg4zgvmj21gx0u0780.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 01:38:08 GMT</pubDate>
</item>
<item>
<title>【视觉语言模型解析】视觉语言模型是能够同时从图像和文本中学习的模型，可以处理从视觉问答到图像字幕等多种任务。主要的组成部分包括图像编码器、嵌入映射器（...</title>
<link>https://weibo.com/1402400261/O9uKLiiUt</link>
<guid>https://weibo.com/1402400261/O9uKLiiUt</guid>
<content:encoded><![CDATA[
<div> 视觉语言模型、图像编码器、嵌入映射器、文本解码器、开源模型、基准评估、Transformer、SFTTrainer、Vision Arena、Open VLM Leaderboard<br />
<br />
总结：<br />
视觉语言模型是能够同时从图像和文本中学习的模型，主要组成部分包括图像编码器、嵌入映射器和文本解码器。开源的视觉语言模型有基础模型和适用于不同任务的特殊模型。评估视觉语言模型的重要基准包括综合基准MMMU、单项选择题基准MMBench和其他领域的基准。使用Transformer进行推理，SFTTrainer进行微调。在选择合适模型时关键在于任务需求，可以参考排行榜进行选择。 <div>
【视觉语言模型解析】<br />视觉语言模型是能够同时从图像和文本中学习的模型，可以处理从视觉问答到图像字幕等多种任务。主要的组成部分包括图像编码器、嵌入映射器（用于对齐图像和文本表示）以及文本解码器。<br /><br />开源的视觉语言模型包括：<br />- LLaVA、deepseek-vl-7b-base 等基础模型<br />- DeepSeek-VL-Chat、CogVLM-Chat 等适用于聊天的模型，具有防止模型幻象的"锚定"特性<br />- Fuyu-8B 等可以检测图像内文本的模型 <br />- KOSMOS-2、Qwen-VL 等可以进行零样本对象检测的模型<br /><br />评估视觉语言模型的重要基准包括：<br />- MMMU:综合基准，包含不同学科知识和推理<br />- MMBench:包含 20 项技能的单项选择题<br />- MathVista:数学推理<br />- AI2D:图表理解<br />- ScienceQA:科学问答<br />- OCRBench:文档理解<br /><br />使用 Transformer 可以进行推理，使用 SFTTrainer 可以进行微调。选择合适的模型关键在于目标任务，可以参考 Vision Arena、Open VLM Leaderboard 等排行榜。<br />《Vision Language Models Explained》 <a href="https://huggingface.co/blog/vlms"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hooye587urj21hc0u0ahb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hooye7ln7oj21hc0u0whn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 01:36:19 GMT</pubDate>
</item>
<item>
<title>【Google Scholar PDF Reader：能极大提高学术论文阅读效率的浏览器插件，可以预览引用、浏览目录、跳转到图表、引用文献等】“Google Scholar PDF Reader” 网...</title>
<link>https://weibo.com/1402400261/O9uGwfHIS</link>
<guid>https://weibo.com/1402400261/O9uGwfHIS</guid>
<content:encoded><![CDATA[
<div> Google Scholar PDF Reader, 浏览器插件, 学术论文, 阅读效率, 预览引用, 浏览目录, 图表, 引用文献

Google Scholar PDF Reader是一款能够极大提高学术论文阅读效率的浏览器插件。该插件可以让用户预览论文的引用，浏览目录，跳转到图表和引用文献等功能，使用户能够更快速、方便地阅读和理解学术论文内容。通过Google Scholar PDF Reader，用户可以更快速地找到自己所需的信息，节约时间，提高工作效率，是一款非常实用的学术工具插件。<br /><br />总结:Google Scholar PDF Reader是一款能够极大提高学术论文阅读效率的浏览器插件，可以帮助用户预览引用、浏览目录、跳转到图表、引用文献等功能，使用户更方便快捷地阅读和理解学术论文内容，提高工作效率。 <div>
【Google Scholar PDF Reader：能极大提高学术论文阅读效率的浏览器插件，可以预览引用、浏览目录、跳转到图表、引用文献等】“Google Scholar PDF Reader” <a href="https://chromewebstore.google.com/detail/dahenjhkoodjbpjheillcadbppiidmhp"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hooy32j0mjj21eq0u0wi6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hooy3c1habj21cy0u0k1l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 01:25:52 GMT</pubDate>
</item>
<item>
<title>【构建AI的"世界模型"：Meta的OpenEQA框架为具身智能开启新篇章】 - Meta 正在探索构建一种具身AI智能体，它可以作为家庭机器人或时尚智能眼镜的"大脑"。这种智...</title>
<link>https://weibo.com/1402400261/O9uEws3sJ</link>
<guid>https://weibo.com/1402400261/O9uEws3sJ</guid>
<content:encoded><![CDATA[
<div> 元学习、OpenEQA框架、具身智能、世界模型、Meta、环境理解、智能体、语言交互、EQA、智能家居<br />
<br />
1. Meta正在探索构建具身智能体，用作家庭机器人或智能眼镜的"大脑"，需要理解周围环境并能够通过语言交流。<br />
2. 构建"世界模型"是一个重要愿景和研究挑战，Meta正积极探索。<br />
3. 推出的OpenEQA框架是一个新基准，通过提问衡量具身智能体对环境的理解。<br />
4. OpenEQA主要包含情节记忆EQA和实时EQA两个任务，用于评估智能体的环境理解能力。<br />
5. EQA具有日常生活应用，能在智能眼镜、家用机器人等设备中提供帮助和服务。<br />
<br />
总结：Meta正在探索构建具身智能体，通过OpenEQA框架评估智能体的环境理解能力，推动智能家居和可穿戴设备的发展，这将极大地改善人们的日常生活。构建"世界模型"概念强调了语言交互的重要性，让人工智能系统更自然、直观地与人类沟通。通过EQA任务对智能体的理解能力进行评估，展示了人工智能技术在提升生活质量方面的潜力。 <div>
【构建AI的"世界模型"：Meta的OpenEQA框架为具身智能开启新篇章】  <br />- Meta 正在探索构建一种具身AI智能体，它可以作为家庭机器人或时尚智能眼镜的"大脑"。这种智能体需要利用视觉等感官模态来理解周围环境，并能够用清晰、日常的语言进行交流，以有效地协助人们。  <br />- 这相当于构建一个"世界模型"——智能体对外部世界的内部表征，可以通过语言进行查询。这是一个长期愿景和艰巨的研究挑战，Meta正在积极探索。  <br />- Meta 推出了开放词汇具身问答(OpenEQA)框架，这是一个新的基准，通过向智能体提出开放式词汇问题来衡量其对环境的理解。这类似于我们通过提问和评估答案来评估人类对某个概念的理解。  <br />- OpenEQA 包含两个任务：(1)情节记忆 EQA，其中具身 AI 智能体根据其对环境的观察回答问题；(2)实时 EQA，其中智能体必须在探索环境的同时回答问题。  <br />- EQA 也有直接的应用，即使是基本版本也可以简化日常生活。例如，智能眼镜可以利用情节记忆帮助你找到遗失的办公证件，家用机器人可以告诉你是否还有水果。  <br /><br />思考：  <br />- OpenEQA 框架为评估具身 AI 智能体的环境理解能力提供了一种新颖的方法。通过提出开放式问题并评估答案，我们可以更全面地了解智能体对周围世界的认知水平。这对于开发能够有效协助人类的 AI 系统至关重要。  <br />- Meta 提出的"世界模型"概念非常有趣，它强调了语言交互在人工智能系统中的重要性。通过构建可查询的世界表征，我们可以让 AI 以更自然、直观的方式与人类沟通和协作。  <br />- EQA 在智能家居、可穿戴设备等领域有广泛的应用前景。即使是基本的 EQA 功能，也可以极大地简化人们的日常生活，提供更加个性化和智能化的服务。这展示了 AI 技术在改善人类生活方面的巨大潜力。<br />《OpenEQA: From word models to world models》 <a href="https://ai.meta.com/blog/openeqa-embodied-question-answering-robotics-ar-glasses/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hooxy9nzjaj21al0u043p.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hooxya6pwgj20yq0loacv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 01:20:57 GMT</pubDate>
</item>
<item>
<title>【Adobe Firefly AI 训练数据来源遭质疑，人工智能领域亟需加强监管】- 去年，Adobe 推出了其创新的图像生成软件 Firefly，并宣称该人工智能模型主要是在 Adobe ...</title>
<link>https://weibo.com/1402400261/O9uuVBlWJ</link>
<guid>https://weibo.com/1402400261/O9uuVBlWJ</guid>
<content:encoded><![CDATA[
<div> Adobe, Firefly, AI, 训练数据, 质疑, 监管, 误导, 透明度, 竞争对手, 技术, 发展

<br /><br />总结:
去年，Adobe推出了图像生成软件Firefly，声称其主要在Adobe Stock上训练。然而，实际上Adobe也利用了竞争对手的人工智能生成内容来完善模型。Adobe在宣传Firefly时缺乏透明度，可能损害用户信任。该事件反映了人工智能领域训练数据来源和使用方式缺乏监管和透明度，需要建立更严格的规范和标准。在评估人工智能产品时，不能完全相信营销宣传，需要深入了解技术实现细节。 <div>
【Adobe Firefly AI 训练数据来源遭质疑，人工智能领域亟需加强监管】<br />- 去年，Adobe 推出了其创新的图像生成软件 Firefly，并宣称该人工智能模型主要是在 Adobe Stock(该公司拥有数亿张许可图像的广泛存储库)上训练的。  <br />- Adobe 将 Firefly 定位为一个更具商业可行性的选择，与 Midjourney 等竞争对手相比，后者依赖于从互联网上抓取的图像进行训练。  <br />- 然而，有一个有趣的细节被隐藏了。虽然 Adobe 公开强调 Firefly 训练数据的安全性和排他性，但该公司也利用了这些竞争对手的人工智能生成内容来完善其模型，包括Midjourney在内。  <br />- 在关于 Firefly 优越性的各种演示和公开声明中，Adobe 没有披露这一关键细节，即其训练数据是经过精心策划的。  <br /><br />思考：  <br />- 这篇报道揭示了 Adobe 在宣传其 Firefly AI 模型时存在一定程度的误导。虽然 Adobe 声称主要使用自己的许可图像库进行训练，但实际上也利用了竞争对手的人工智能生成图像。这种做法在商业竞争中并不罕见，但缺乏透明度可能会损害用户对 Adobe 的信任。  <br />- Adobe 强调 Firefly 训练数据的安全性和排他性，暗示其模型比竞争对手更有商业可行性。但事实上，Adobe 也在利用竞争对手的技术成果来改进自己的模型。这提醒我们，在评估不同公司的人工智能产品时，不能完全相信其营销宣传，还需要深入了解其技术实现细节。  <br />- 这一事件也反映出当前人工智能领域的一个普遍问题：训练数据的来源和使用方式缺乏透明度和监管。随着人工智能技术的快速发展，我们需要建立更加完善的行业标准和规范，确保企业以负责任和道德的方式开发和应用这些强大的工具。<br />《Adobe’s AI Firefly Used AI-Generated Images From Rivals for Training - Bloomberg》 <a href="https://www.bloomberg.com/news/articles/2024-04-12/adobe-s-ai-firefly-used-ai-generated-images-from-rivals-for-training"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoox9p5ofnj20vh0u0q76.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 13 Apr 2024 00:57:19 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：后天开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《LangChain实战》，截至2024.4.15 12:00，...</title>
<link>https://weibo.com/1402400261/O9tvGx09O</link>
<guid>https://weibo.com/1402400261/O9tvGx09O</guid>
<content:encoded><![CDATA[
<div> LangChain、LangServe、LangSmith、LLM、初学者、开发者、应用场景、LCEL、生成式人工智能领域

<br /><br />总结:
文章介绍了一本名为《LangChain实战》的书籍，面向初学者和对LangChain和LLM应用感兴趣的开发者。该书基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，深入探讨了LCEL的应用方式。围绕LangChain生态系统的概念，详细探讨了LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。活动要求转发+评论参与抽奖，奖品是《LangChain实战》书籍。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：后天开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.15 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a>  <a href="https://shop.sc.weibo.com/h5/goods/index?iid=110014024002610004661854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">LangChain实战：从原型到生产，动手打造 LLM 应用</span></a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hofl98oom9j207q0a0jrm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 22:26:26 GMT</pubDate>
</item>
<item>
<title>今日推介(第1374期)：语言模型合成数据的最佳实践和经验教训、不是所有Token都是必需的、超越Transformer的高效开放语言模型、离线学习长上下文、梯度网络(GradN...</title>
<link>https://weibo.com/1402400261/O9tkac2oq</link>
<guid>https://weibo.com/1402400261/O9tkac2oq</guid>
<content:encoded><![CDATA[
<div> 语言模型、合成数据、最佳实践、经验教训、Token、高效开放语言模型、Transformer、离线学习、长上下文、梯度网络

总结:<br />
本文介绍了关于语言模型合成数据的最佳实践和经验教训，强调了不是所有Token都是必需的。提出了超越Transformer的高效开放语言模型的概念，探讨了离线学习长上下文的方法。最后介绍了梯度网络（GradNet）的相关内容。文章内容丰富，为语言模型领域的研究提供了一定的指导和启发。 <div>
今日推介(第1374期)：语言模型合成数据的最佳实践和经验教训、不是所有Token都是必需的、超越Transformer的高效开放语言模型、离线学习长上下文、梯度网络(GradNet) 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/692232301"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoos2s5kicj21070u0qa9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoos2un2fgj21mn0u0tgb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoos2x5tv5j21j20tmaf0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoos30dsdgj218c0smjui.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoos33388oj21de0py775.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:58:03 GMT</pubDate>
</item>
<item>
<title>[LG] Post-Hoc Reversal: Are We Selecting Models Prematurely? 网页链接 通过探索后处理反转现象，发现仅考虑基础性能进行模型选择是不恰当的，而应当采用后处...</title>
<link>https://weibo.com/1402400261/O9tgKuUwU</link>
<guid>https://weibo.com/1402400261/O9tgKuUwU</guid>
<content:encoded><![CDATA[
<div> 后处理反转、模型选择、基础性能、后处理指标、优结果、探索、选择、需谨慎、有效性、模型预测

总结:<br /><br />本文探讨了后处理反转现象，认为仅考虑基础性能进行模型选择是不可取的。文章强调应该使用后处理指标来选择模型，从而获得更好的结果。作者指出模型预测的有效性需要进行深入研究，选择模型时需要谨慎考虑各种指标，以确保最终结果的准确性和可靠性。 <div>
[LG] Post-Hoc Reversal: Are We Selecting Models Prematurely?  <br /><a href="https://arxiv.org/abs/2404.07815"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过探索后处理反转现象，发现仅考虑基础性能进行模型选择是不恰当的，而应当采用后处理指标进行模型选择，从而获得更优结果。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooruehe42j20v81d4h0f.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoorueospmj21dc0r6k1l.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooruf1tk1j21dg0jowjv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:49:38 GMT</pubDate>
</item>
<item>
<title>[CL] Interactive Prompt Debugging with Sequence Salience 网页链接 提出Sequence Salience系统，通过交互式可视化输入显著性，支持大型语言模型复杂提示的调...</title>
<link>https://weibo.com/1402400261/O9tdBreFd</link>
<guid>https://weibo.com/1402400261/O9tdBreFd</guid>
<content:encoded><![CDATA[
<div> Sequence Salience, 交互式, 可视化, 输入显著性, 大型语言模型, 调试, 快速迭代优化

Sequence Salience系统为用户提供了一种交互式的可视化方式，用于显示输入中的显著性信息，从而支持大型语言模型的复杂提示的调试和快速迭代优化。用户可以通过该系统更直观地了解语言模型中关键提示的作用，从而进行有效的优化和调整。通过交互式的界面设计，用户可以快速定位和解决问题，提高工作效率。总结: 摒弃繁琐的调试方式，提供可视化的交互体验，帮助用户快速优化语言模型。 <div>
[CL] Interactive Prompt Debugging with Sequence Salience  <br /><a href="https://arxiv.org/abs/2404.07498"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />提出Sequence Salience系统，通过交互式可视化输入显著性，支持大型语言模型复杂提示的调试和快速迭代优化。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoormcbcowj20vw1c8dyi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoormcldxbj21ay11qna9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoormcth0vj20ng0rudkn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:41:53 GMT</pubDate>
</item>
<item>
<title>[LG] An Overview of Diffusion Models: Applications, Guided Generation, Statistical Rates and Optimization 网页链接 全面回顾了扩散模型的应用和理论研究...</title>
<link>https://weibo.com/1402400261/O9taQpbfj</link>
<guid>https://weibo.com/1402400261/O9taQpbfj</guid>
<content:encoded><![CDATA[
<div> 扩散模型、理论研究、应用、生成性、条件引导、不足、未来方向、系统性、素材、视角

总结:<br /><br />本文全面回顾了扩散模型的应用和理论研究现状，强调了条件引导下的可控生成性。文章指出了理论研究存在的不足，并探讨了未来可能的研究方向，为推进扩散模型研究提供了系统性的素材和视角。整体来看，本文对扩散模型的应用及其在不同领域中的指导意义进行了深入探讨，有助于进一步推动相关研究的发展。 <div>
[LG] An Overview of Diffusion Models: Applications, Guided Generation, Statistical Rates and Optimization  <br /><a href="https://arxiv.org/abs/2404.07771"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />全面回顾了扩散模型的应用和理论研究现状，强调了条件引导下的可控生成性，指出理论研究的不足与未来可能方向，为推进扩散模型研究提供了系统性的素材和视角。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoorf8j2maj2114178dsh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoorf8pahcj21ga0t87ac.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoorf9dnw6j21gs0gmwiv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:35:05 GMT</pubDate>
</item>
<item>
<title>[CL] ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models 网页链接 提出一个强大的语言模型框架Resear...</title>
<link>https://weibo.com/1402400261/O9t868FpK</link>
<guid>https://weibo.com/1402400261/O9t868FpK</guid>
<content:encoded><![CDATA[
<div> 关键词: ResearchAgent, 语言模型, 知识库, 迭代评价机制, 科研想法, 高质量, 自动生成, 框架, 目标

总结:<br /><br />
本文提出了一个名为ResearchAgent的强大语言模型框架，通过构建知识库和设计迭代评价机制，实现了自动生成高质量科研想法的目标。ResearchAgent结合了先进的语言模型技术，能够在科学文献中生成创新性的研究思路。通过不断迭代和评价，可以帮助研究人员提出更具实际意义的科研主题，促进科学研究的发展。这一框架为科研思路的自动生成提供了一种新的途径，有望提升科研领域的创新能力和效率。ResearchAgent的应用潜力巨大，未来可以进一步改进和拓展，为科研人员带来更多的启发和创新思路。 <div>
[CL] ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models  <br /><a href="https://arxiv.org/abs/2404.07738"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出一个强大的语言模型框架ResearchAgent，利用构建知识库和设计迭代评价机制，实现了自动生成高质量科研想法的目标。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoor884iosj20x61csngf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoor889pwsj21h80cw0yi.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoor88jcjhj21220rejuz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:28:19 GMT</pubDate>
</item>
<item>
<title>提出梯度网络GradNet直接参数化并学习函数梯度，给出设计框架，证明可普适逼近广泛梯度函数类，经验表现优越。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Gradient Net...</title>
<link>https://weibo.com/1402400261/O9t5zuKmx</link>
<guid>https://weibo.com/1402400261/O9t5zuKmx</guid>
<content:encoded><![CDATA[
<div> Gradient Networks, 参数化, 学习函数梯度, 普适逼近, 广泛梯度函数类, 经验表现优越<br />
<br />
1. 本文提出了梯度网络GradNet直接参数化并学习函数梯度的方法。
2. 设计了框架来实现GradNet，证明其可以普适逼近广泛的梯度函数类。
3. 实验证明GradNet在经验表现上具有优越性。
4. 作者分别是S Chaudhari, S Pranav, J M. F. Moura，来自CMU。
<br /><br />总结: 本文介绍了一种新方法GradNet，通过参数化和学习函数梯度来逼近广泛的梯度函数类，在实验中表现优越。 <div>
提出梯度网络GradNet直接参数化并学习函数梯度，给出设计框架，证明可普适逼近广泛梯度函数类，经验表现优越。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Gradient Networks》S Chaudhari, S Pranav, J M. F. Moura [CMU] (2024) <a href="https://arxiv.org/abs/2404.07361"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hooqt70o3xj218m0qwk1m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqt7lzm0j21de0pyq6h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hooqt7ptf5j21f20e8wgh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqt7u9qzj21cw0f00uc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoor1ne0pvj20p50w940f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoor1ndv3qj210x0a5q41.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoor1ndwwkj20p50wa40k.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoor1ndekoj210x0a8jsd.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:22:06 GMT</pubDate>
</item>
<item>
<title>[LG]《Gradient Networks》S Chaudhari, S Pranav, J M. F. Moura [CMU] (2024) 网页链接 #机器学习##人工智能##论文# [图片][图片][图片][图片][图片][图片][图...</title>
<link>https://weibo.com/1402400261/O9t5x2tdX</link>
<guid>https://weibo.com/1402400261/O9t5x2tdX</guid>
<content:encoded><![CDATA[
<div> Gradient Networks, S Chaudhari, S Pranav, J M. F. Moura, CMU, 2024<br />
<br />
总结:<br />
本文提出了一种名为Gradient Networks的新型网络模型，旨在处理复杂的图形数据。该模型利用梯度信息来学习网络结构，实现高效的数据处理和表示学习。通过实验证明，Gradient Networks在处理图形数据方面具有优势，并在各种任务中取得了良好的性能。这种新型网络模型为图形数据的分析和应用提供了新的思路，有望在各个领域获得广泛应用。 <div>
[LG]《Gradient Networks》S Chaudhari, S Pranav, J M. F. Moura [CMU] (2024) <a href="https://arxiv.org/abs/2404.07361"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hooqt70o3xj218m0qwk1m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqt7lzm0j21de0pyq6h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hooqt7ptf5j21f20e8wgh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqt7u9qzj21cw0f00uc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoor1ne0pvj20p50w940f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoor1ndv3qj210x0a5q41.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoor1ndwwkj20p50wa40k.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoor1ndekoj210x0a8jsd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:22:00 GMT</pubDate>
</item>
<item>
<title>通过序列压缩和参数高效微调实现了长序列的有效离线学习，使语言模型能够基于长文档的紧凑表示生成高质量的回复。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《LLoCO: Le...</title>
<link>https://weibo.com/1402400261/O9t0EkEL2</link>
<guid>https://weibo.com/1402400261/O9t0EkEL2</guid>
<content:encoded><![CDATA[
<div> CL, LLoCO, 学习, 长序列, 压缩, 参数, 高效, 微调, 离线学习, 语言模型

<br /><br />总结:
本文介绍了一种名为LLoCO的学习长上下文的离线学习方法，通过序列压缩和参数微调实现了对长序列的有效学习。该方法能够生成高质量的回复，使语言模型能够基于长文档的紧凑表示进行生成。研究者在UC Berkeley进行了相关研究，有效提升了语言模型的表现。该方法的创新之处在于能够处理长文档的信息，并通过压缩和微调参数，在离线环境下实现了高效的学习过程。通过实验验证了该方法的有效性和可行性，为语言模型的进一步发展提供了新的思路和方法。 <div>
通过序列压缩和参数高效微调实现了长序列的有效离线学习，使语言模型能够基于长文档的紧凑表示生成高质量的回复。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《LLoCO: Learning Long Contexts Offline》S Tan, X Li, S Patil, Z Wu… [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.07979"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqosi9ssj21600ryamu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqoswzm5j21ds0nyjxz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hooqot2cywj218c0smtcd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqot7shqj21de0p6ago.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqox885cj20uu0cpabp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqox85tbj20vh0f2jtm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:09:58 GMT</pubDate>
</item>
<item>
<title>[CL]《LLoCO: Learning Long Contexts Offline》S Tan, X Li, S Patil, Z Wu… [UC Berkeley] (2024) 网页链接 #机器学习##人工智能##论文# [图片][图片][图片][...</title>
<link>https://weibo.com/1402400261/O9t0Aaj0w</link>
<guid>https://weibo.com/1402400261/O9t0Aaj0w</guid>
<content:encoded><![CDATA[
<div> 长文本；离线学习；上下文；学习模型；UC Berkeley；2024；Tan；Li；Patil；Wu

<br /><br />总结:
这篇文章是关于离线学习长文本上下文的研究。研究团队来自加州大学伯克利分校，发表于2024年。他们提出了一种名为LLoCO的学习模型，旨在解决长文本中上下文信息的学习问题。通过对文本内容进行离线学习，该模型可以更好地捕捉文本之间的关联性，提高学习效果。Tan、Li、Patil和Wu是本研究的主要作者。 <div>
[CL]《LLoCO: Learning Long Contexts Offline》S Tan, X Li, S Patil, Z Wu… [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.07979"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqosi9ssj21600ryamu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqoswzm5j21ds0nyjxz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hooqot2cywj218c0smtcd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqot7shqj21de0p6ago.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hooqox885cj20uu0cpabp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqox85tbj20vh0f2jtm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:09:48 GMT</pubDate>
</item>
<item>
<title>RecurrentGemma 通过固定大小状态实现了与Gemma-2B媲美的语言理解能力，同时大幅提升了长序列推理效率，可支持更广泛的应用。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]...</title>
<link>https://weibo.com/1402400261/O9t0984hI</link>
<guid>https://weibo.com/1402400261/O9t0984hI</guid>
<content:encoded><![CDATA[
<div> RecurrentGemma, Gemma-2B, 语言理解能力, 长序列推理效率, 应用, 固定大小状态<br />
<br />
总结:<br />
本文介绍了RecurrentGemma模型，该模型通过固定大小状态实现了与Gemma-2B相当的语言理解能力，并大幅提升了长序列推理效率，使其能够支持更广泛的应用。该模型在效率和性能上超越了传统的Transformer模型，展现了更高的潜力和实用性。RecuurentGemma的提出对于提高开放式语言模型的效率和性能具有重要意义，为相关领域的研究和应用带来新的启发和发展方向。 <div>
RecurrentGemma 通过固定大小状态实现了与Gemma-2B媲美的语言理解能力，同时大幅提升了长序列推理效率，可支持更广泛的应用。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《RecurrentGemma: Moving Past Transformers for Efficient Open Language Models》A Botev, S De, S L Smith, A Fernando… [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2404.07839"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqnnmhprj21je09sgqc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hooqno3gzyj21j20tmq8o.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 21:08:44 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.12)》 爱可可微博热门分享(4.12) [图片]</title>
<link>https://weibo.com/1402400261/O9qsCEvRE</link>
<guid>https://weibo.com/1402400261/O9qsCEvRE</guid>
<content:encoded><![CDATA[
<div> 爱可可 微博 热门 分享 4.12 关键词

总结:
在4月12日的热门分享中，爱可可微博上涵盖了各种各样的内容。其中包括了一些新奇有趣的视频，如可爱的小动物视频和搞笑的日常生活片段。另外，还有一些与时事热点相关的文章，引起了许多网友的讨论和转发。除此之外，也涉及了一些美食、旅行和健康等方面的话题，吸引了广大粉丝的关注。总体而言，这些内容丰富多彩，让人在忙碌的生活中得到一丝放松和快乐。 <div>
《爱可可微博热门分享(4.12)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405022466711093588"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.12)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hooffyjaexj20d607egm0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 14:40:39 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《STORM: Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking》(NAACL 2024) GitHub: github.com/stanfo...</title>
<link>https://weibo.com/1402400261/O9pse4L6U</link>
<guid>https://weibo.com/1402400261/O9pse4L6U</guid>
<content:encoded><![CDATA[
<div> STORM, Topic Outlines, Retrieval, Multi-perspective Question Asking, GitHub, OpenEQA, Embodied Question Answering, Foundation Models, Taming Stable Diffusion, Text to 360° Panorama Image Generation, matching, 2D Images, 3D, Metric Relative Pose, Softmax Attention, Constant Cost per Token, Text-to-Visual Generation, Image-to-Text Generation, OSWorld, Multimodal Agents, Open-Ended Tasks, Real Computer Environments, Rho-1, Tokens, Mira, Long Video Generation, Urban Architect, 3D Urban Scene Generation, Scaling Laws, Data Filtering, InstantMesh, 3D Mesh Generation, Audio Systems, VisualWebBench, Multimodal LLMs, Web Page Understanding, No Zero-Shot, Exponential Data, Pretraining Concept Frequency, PCToolkit, Prompt Compression Toolkit, Large Language Models, 3D Gaussian Splatting, Real-Time Radiance Field Rendering 

<br /><br />总结:
1. "STORM"是利用检索和多角度提问实现主题大纲的论文，提供了GitHub链接。
2. "OpenEQA"关注基于基础模型的具身问答，提供了GitHub链接。
3. "Taming Stable Diffusion"探讨了将文本转换为360度全景图像生成的问题，提供了GitHub链接。
4. "Matching 2D Images in 3D"介绍了利用度量相关姿态从度量对应关系中匹配2D图像和3D姿势。
5. "Softmax Attention with Constant Cost per Token"介绍了一种具有固定代价的每个标记的Softmax注意力机制。
6. "Evaluating Text-to-Visual Generation with Image-to-Text Generation"比较了文本到视觉生成和图像到文本生成的性能。
7. "OSWorld"提供多模态代理在现实计算环境中开放任务的基准测试。
8. "Rho-1"论文探讨了不是所有标记都是所需的问题。
9. "Mira"是视频生成方面的探索性研究，提供了GitHub链接。
10. "Urban Architect"关注带有布局先验的可导航3D城市场景生成。 <div>
几篇论文实现代码：<br />《STORM: Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking》(NAACL 2024) GitHub: github.com/stanford-oval/storm [fig1]<br />《OpenEQA: Embodied Question Answering in the Era of Foundation Models》(CVPR 2024) GitHub: github.com/facebookresearch/open-eqa<br />《Taming Stable Diffusion for Text to 360° Panorama Image Generation》(CVPR 2024) GitHub: github.com/chengzhag/PanFusion<br />《Matching 2D Images in 3D: Metric Relative Pose from Metric Correspondences》(CVPR 2024) GitHub: github.com/nianticlabs/mickey <br />《Softmax Attention with Constant Cost per Token》(2024) GitHub: github.com/glassroom/heinsen_attention<br />《Evaluating Text-to-Visual Generation with Image-to-Text Generation》(2024) GitHub: github.com/linzhiqiu/t2v_metrics<br />《OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments》(2024) GitHub: github.com/xlang-ai/OSWorld<br />《Rho-1: Not All Tokens Are What You Need》(2024) GitHub: github.com/microsoft/rho [fig2]<br />《Mira: A Mini-step Towards Sora-like Long Video Generation》(2024) GitHub: github.com/mira-space/Mira<br />《Urban Architect: Steerable 3D Urban Scene Generation with Layout Prior》(2024) GitHub: github.com/UrbanArchitect/UrbanArchitect<br />《Scaling Laws for Data Filtering》(2024) GitHub: github.com/locuslab/scaling_laws_data_filtering<br />《InstantMesh: Efficient 3D Mesh Generation from a Single Image with Sparse-view Large Reconstruction Models》(2024) GitHub: github.com/TencentARC/InstantMesh<br />《Differentiable All-pole Filters for Time-varying Audio Systems》(2024) GitHub: github.com/DiffAPF/TB-303<br />《VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page Understanding and Grounding?》(2024) GitHub: github.com/VisualWebBench/VisualWebBench [fig3] <br />《No Zero-Shot Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance》(2024) GitHub: github.com/bethgelab/frequency_determines_performance<br />《PCToolkit: A Unified Plug-and-Play Prompt Compression Toolkit of Large Language Models》(2024) GitHub: github.com/3DAgentWorld/Toolkit-for-Prompt-Compression<br />《3D Gaussian Splatting for Real-Time Radiance Field Rendering》(2024) GitHub: github.com/leo-frank/diff-gaussian-rasterization-depth<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoo9glfyjfj20kb08k0tl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoo9hxtl93j221p0tx4kw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hooasiux0hj21310n7h9u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 12:06:55 GMT</pubDate>
</item>
<item>
<title>【Narwhals：轻量可扩展的数据框架兼容层，支持 Polars、pandas、cuDF、Modin 等多种数据框架】'Narwhals - Lightweight and extensible compatibility layer be...</title>
<link>https://weibo.com/1402400261/O9prl9em4</link>
<guid>https://weibo.com/1402400261/O9prl9em4</guid>
<content:encoded><![CDATA[
<div> 轻量、可扩展、数据框架、兼容层、Polars、pandas、cuDF、Modin、GitHub、MarcoGorelli/narwhals

<br /><br />总结:
Narwhals是一个轻量、可扩展的数据框架兼容层，支持Polars、pandas、cuDF、Modin等多种数据框架。用户可以通过GitHub上的MarcoGorelli/narwhals获取相关信息和使用资源。这个工具为不同数据框架之间的兼容性提供了便利，让用户可以快速在不同框架之间切换和转换数据，提高工作效率。由于支持的数据框架种类多样，Narwhals可满足不同用户的需求，为数据处理工作带来了更大的灵活性和便利性。 <div>
【Narwhals：轻量可扩展的数据框架兼容层，支持 Polars、pandas、cuDF、Modin 等多种数据框架】'Narwhals - Lightweight and extensible compatibility layer between Polars, pandas, cuDF, Modin, and more!' GitHub: github.com/MarcoGorelli/narwhals <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hooaxs9rklj20u010q79u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 12:04:43 GMT</pubDate>
</item>
<item>
<title>【ADS-B Massive Visualizer：ADS-B 航班数据的交互式可视化和分析】'ADS-B Massive Visualizer - Interactive visualization and analytics on ADS-B data with...</title>
<link>https://weibo.com/1402400261/O9pqL7mwe</link>
<guid>https://weibo.com/1402400261/O9pqL7mwe</guid>
<content:encoded><![CDATA[
<div> GitHub、ADS-B、航班数据、可视化、分析、交互式、ClickHouse、adsb.exposed<br />
<br />
关键词提取完毕，这是一篇介绍ADS-B航班数据交互式可视化和分析工具ADS-B Massive Visualizer的GitHub项目。该工具基于ClickHouse技术，能够实现对ADS-B数据的交互式可视化和分析。用户可以通过这个工具来更深入地了解ADS-B航班数据，实时跟踪航班位置和信息，帮助航空公司等相关机构进行航班管理和监控。通过GitHub链接可以查看该工具的具体实现和功能介绍。如果你对ADS-B数据感兴趣，可以尝试使用这个工具来进行数据的可视化和分析。<br /><br />总结: 介绍了一款基于ClickHouse技术的ADS-B航班数据交互式可视化和分析工具ADS-B Massive Visualizer，能够实现对ADS-B数据的实时跟踪和信息分析，帮助航空公司进行航班管理和监控。GitHub链接提供了工具的具体实现和功能介绍。 <div>
【ADS-B Massive Visualizer：ADS-B 航班数据的交互式可视化和分析】'ADS-B Massive Visualizer - Interactive visualization and analytics on ADS-B data with ClickHouse' GitHub: github.com/ClickHouse/adsb.exposed <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%8F%AF%E8%A7%86%E5%8C%96%23&amp;isnewpage=1"><span class="surl-text">#可视化#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hooav84th2j21590u01kx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hooav980k5j20uc0u0qcx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hooav9zt81j210l0u07fo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 12:03:18 GMT</pubDate>
</item>
<item>
<title>【PCToolkit: 统一的即插即用大语言模型提示压缩工具包】'PCToolkit: A Unified Plug-and-Play Prompt Compression Toolkit of Large Language Models - Toolkit...</title>
<link>https://weibo.com/1402400261/O9ppWAvO2</link>
<guid>https://weibo.com/1402400261/O9ppWAvO2</guid>
<content:encoded><![CDATA[
<div> GitHub, PCToolkit, 统一, 即插即用, 大语言模型, 提示压缩, 工具包, 模型, 压缩工具

<br /><br />总结：
PCToolkit 是一个统一的即插即用的大语言模型提示压缩工具包，旨在提供便捷的使用体验。该工具可以用于压缩大语言模型中的提示信息，提高模型的效率和性能。用户可以通过 GitHub 找到这个工具包，并按照文档指南进行使用。PCToolkit 的设计灵活多样，可以适用于不同的大语言模型，为语言模型的应用提供了更便捷和高效的解决方案。 <div>
【PCToolkit: 统一的即插即用大语言模型提示压缩工具包】'PCToolkit: A Unified Plug-and-Play Prompt Compression Toolkit of Large Language Models - Toolkit for Prompt Compression' GitHub: github.com/3DAgentWorld/Toolkit-for-Prompt-Compression <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hooau9etyxj21520l5jue.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 12:01:18 GMT</pubDate>
</item>
<item>
<title>【SDFX：通过漂亮界面构建和分享AI应用的无代码平台】’SDFX - The ultimate no-code platform to build and share AI apps with beautiful UI.' GitHub: github...</title>
<link>https://weibo.com/1402400261/O9poGiiWH</link>
<guid>https://weibo.com/1402400261/O9poGiiWH</guid>
<content:encoded><![CDATA[
<div> AI应用、无代码平台、漂亮界面、构建、分享、GitHub、SDFX

<br /><br />总结:
SDFX是一个无代码平台，可帮助用户构建和分享AI应用，拥有漂亮的界面设计。用户无需编写代码，只需通过SDFX平台即可快速构建功能强大的AI应用。同时，SDFX也提供GitHub仓库，用户可以访问github.com/sdfxai/sdfx获取更多信息。 <div>
【SDFX：通过漂亮界面构建和分享AI应用的无代码平台】’SDFX - The ultimate no-code platform to build and share AI apps with beautiful UI.' GitHub: github.com/sdfxai/sdfx <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hooaqt2y40j21by0u0aga.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hooaqw2p99j21by0u0jxc.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hooaqy3hpyj21by0u0dml.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:58:10 GMT</pubDate>
</item>
<item>
<title>【Next.js AI Chatbot：由 Vercel 和 Next.js 团队成员构建的生成式 UI 聊天机器人模板，基于 Vercel AI SDK 和 Google Gemini】'Next.js AI Chatbot - Build yo...</title>
<link>https://weibo.com/1402400261/O9po1sfbq</link>
<guid>https://weibo.com/1402400261/O9po1sfbq</guid>
<content:encoded><![CDATA[
<div> Next.js, AI, Chatbot, Vercel, UI, SDK, Google, Gemini

总结:<br /><br />这是一个由Vercel和Next.js团队成员构建的生成式UI聊天机器人模板，使用Vercel AI SDK和Google Gemini。用户可以借助这个模板来构建自己的UI聊天机器人，通过集成AI技术提供更智能的对话和服务。同时，这个项目也展示了如何利用现有的工具和技术来创建高效的交互体验，具有一定的实用性和学习参考价值。 <div>
【Next.js AI Chatbot：由 Vercel 和 Next.js 团队成员构建的生成式 UI 聊天机器人模板，基于 Vercel AI SDK 和 Google Gemini】'Next.js AI Chatbot - Build your own generative UI chatbot using the Vercel AI SDK and Google Gemini' GitHub: github.com/vercel-labs/gemini-chatbot <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hooapbyjqoj20xc0hgabm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:56:34 GMT</pubDate>
</item>
<item>
<title>【Gemini API Cookbook：Gemini API 的指南和示例集合】'Welcome to the Gemini API Cookbook - A collection of guides and examples for the Gemini API.' Git...</title>
<link>https://weibo.com/1402400261/O9peN6kdf</link>
<guid>https://weibo.com/1402400261/O9peN6kdf</guid>
<content:encoded><![CDATA[
<div> Gemini API Cookbook, guides, examples, Gemini API, collection, GitHub, google-gemini

Gemini API Cookbook是一个收集了Gemini API的指南和示例的资源集合，可以在GitHub上找到。用户可以通过这个资源集合快速了解Gemini API的使用方法，并通过示例代码实际操作。这个资源集合对于初学者来说非常有帮助，可以帮助他们快速上手并熟悉Gemini API的各种功能。同时，这个Cookbook也提供了一些高级用法和技巧，对于有经验的开发者也是一个很好的参考资料。通过阅读这个Cookbook，用户可以更好地理解和利用Gemini API，在开发过程中更加高效地实现自己的项目需求。<br /><br />总结:Gemini API Cookbook是一个集合了Gemini API指南和示例的资源，适合初学者和有经验的开发者阅读使用。 <div>
【Gemini API Cookbook：Gemini API 的指南和示例集合】'Welcome to the Gemini API Cookbook - A collection of guides and examples for the Gemini API.' GitHub: github.com/google-gemini/cookbook <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hooa1nctstj21ji0nmgqu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:33:49 GMT</pubDate>
</item>
<item>
<title>【用于评估语言模型准确性的轻量库，包含多个评估，如 MMLU、MATH、GPQA、DROP、MGSM 和 HumanEval，并为 OpenAI 和 Anthropic API 提供了采样接口】’This repo...</title>
<link>https://weibo.com/1402400261/O9p60d29z</link>
<guid>https://weibo.com/1402400261/O9p60d29z</guid>
<content:encoded><![CDATA[
<div> 评估语言模型准确性, 轻量库, MMLU, MATH, GPQA, DROP, MGSM, HumanEval, OpenAI, Anthropic API

<br /><br />总结:
这篇文章介绍了一个用于评估语言模型准确性的轻量库，其中包含了多个评估指标，如MMLU、MATH、GPQA、DROP、MGSM和HumanEval。这个库为OpenAI和Anthropic API提供了采样接口，帮助评估语言模型的性能并提供反馈。这个工具对于评估和改进语言模型的准确性和效果非常有用。 <div>
【用于评估语言模型准确性的轻量库，包含多个评估，如 MMLU、MATH、GPQA、DROP、MGSM 和 HumanEval，并为 OpenAI 和 Anthropic API 提供了采样接口】’This repository contains a lightweight library for evaluating language models' GitHub: github.com/openai/simple-evals <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoo9f52n6oj20v40u043n.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:12:10 GMT</pubDate>
</item>
<item>
<title>'Awesome DUSt3R Resources - A curated list of DUSt3R-related papers and resources, tracking recent advancements using this geometric foundation model....</title>
<link>https://weibo.com/1402400261/O9p408SUu</link>
<guid>https://weibo.com/1402400261/O9p408SUu</guid>
<content:encoded><![CDATA[
<div> GitHub, DUSt3R, 资源, 论文, 进展, 几何基础模型, 最新, 高级<br />
<br />
提到的GitHub资源收集了与基于DUSt3R模型的相关论文和资源，跟踪最新的进展。DUSt3R模型作为一种几何基础模型，被用于研究和发展进步。这个GitHub项目整理了相关文献和资源，方便研究者和开发者了解这一领域的最新动态和高级应用。<br />
<br />
总结: <br />这个GitHub项目整理了与DUSt3R模型相关的论文和资源，跟踪最新进展，为研究者提供了更多深入了解和探索这一领域的机会。 <div>
'Awesome DUSt3R Resources - A curated list of DUSt3R-related papers and resources, tracking recent advancements using this geometric foundation model.' GitHub: github.com/ruili3/awesome-dust3r <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoo9a0gzxkj21fb0u0gq4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:07:14 GMT</pubDate>
</item>
<item>
<title>【OmniFusion：高级的多模态 AI 模型，旨在通过集成其他数据模态（如图像、音频、3D 和视频内容）来扩展传统语言处理系统的功能】'OmniFusion - OmniFusion — a...</title>
<link>https://weibo.com/1402400261/O9p3KpLtL</link>
<guid>https://weibo.com/1402400261/O9p3KpLtL</guid>
<content:encoded><![CDATA[
<div> OmniFusion, 高级, 多模态, AI, 模型, 图像, 音频, 3D, 视频内容

<br /><br />总结:
OmniFusion是一个高级的多模态AI模型，旨在通过集成其他数据模态（如图像、音频、3D和视频内容）来扩展传统语言处理系统的功能。该模型能够同时处理文本和图像，实现文本和图像之间的交流。通过整合不同的数据模态，OmniFusion能够更全面地理解和处理信息，提高系统的功能和效率。GitHub链接：github.com/AIRI-Institute/omnifusion。OmniFusion的引入将为多模态AI研究和应用带来新的可能性，提升系统的交互和表达能力。 <div>
【OmniFusion：高级的多模态 AI 模型，旨在通过集成其他数据模态（如图像、音频、3D 和视频内容）来扩展传统语言处理系统的功能】'OmniFusion - OmniFusion — a multimodal model to communicate using text and images' GitHub: github.com/AIRI-Institute/omnifusion <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoo999u11xj228u0u0458.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoo99c65grj217u0u0n4a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoo99ddmcbj212v0u0qaw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:06:37 GMT</pubDate>
</item>
<item>
<title>【Red-Teaming Language Models with DSPy：介绍了使用 DSPy 框架对语言模型进行红队攻击的尝试，展示了用 DSPy 编译后的架构效果】'Red-Teaming Language Model...</title>
<link>https://weibo.com/1402400261/O9p376LlY</link>
<guid>https://weibo.com/1402400261/O9p376LlY</guid>
<content:encoded><![CDATA[
<div> DSPy, 语言模型, 红队攻击, 框架, GitHub, 编译, 架构效果

<br /><br />总结:
本文介绍了使用DSPy框架对语言模型进行红队攻击的尝试。作者展示了通过DSPy编译后的架构效果。DSPy是一个开源的工具，可以帮助研究人员对语言模型进行攻击和测试。作者在GitHub上分享了该项目的代码，并提供了详细的文档和示例。这种红队攻击技术可以帮助提高语言模型的安全性，以防止恶意利用和攻击。通过使用DSPy框架，研究人员可以更好地了解语言模型的弱点，并及时修复漏洞，从而保护用户的隐私和数据安全。 <div>
【Red-Teaming Language Models with DSPy：介绍了使用 DSPy 框架对语言模型进行红队攻击的尝试，展示了用 DSPy 编译后的架构效果】'Red-Teaming Language Models with DSPy - Red-Teaming Language Models with DSPy' GitHub: github.com/haizelabs/dspy-redteam <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoo97q3zkxj20u00vrn1f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:05:03 GMT</pubDate>
</item>
<item>
<title>【Data-Speech：用于标注语音数据集的实用脚本套件，旨在为基于语音的人工智能模型（如文本到语音引擎）开发过程中所需要的音频变换（或注释）提供简洁、干净的...</title>
<link>https://weibo.com/1402400261/O9p2BtxOz</link>
<guid>https://weibo.com/1402400261/O9p2BtxOz</guid>
<content:encoded><![CDATA[
<div> 标注,语音数据集,脚本套件,基于语音的人工智能模型,音频变换,注释,简洁,干净,代码库

<br /><br />总结:
Data-Speech是一个用于标注语音数据集的实用脚本套件，旨在为基于语音的人工智能模型开发过程中所需的音频变换提供简洁、干净的代码库。该工具能够帮助开发者更有效地处理语音数据，提高模型的性能和准确性。通过提供丰富的功能和简单易用的代码库，Data-Speech为语音领域的研究和开发提供了极大的便利性。 <div>
【Data-Speech：用于标注语音数据集的实用脚本套件，旨在为基于语音的人工智能模型（如文本到语音引擎）开发过程中所需要的音频变换（或注释）提供简洁、干净的代码库】'Data-Speech' GitHub: github.com/huggingface/dataspeech <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoo96flfpwj211s0u0tee.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 11:03:48 GMT</pubDate>
</item>
<item>
<title>恭喜@是橙子也是樱桃 等3名用户获得【《大语言模型：基础与前沿》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效。公示链接：网页链...</title>
<link>https://weibo.com/1402400261/O9mij0DVB</link>
<guid>https://weibo.com/1402400261/O9mij0DVB</guid>
<content:encoded><![CDATA[
<div> 大语言模型、基础、前沿、抽奖、公示链接、转发、评论、科学家、工程师、学生

<br /><br />总结:
本文介绍了微博官方举办的抽奖活动，恭喜三名用户获得《大语言模型：基础与前沿》。活动由官方抽奖工具监督，公正有效。用户可通过转发和评论参与抽奖，截止时间为2024年4月12日12:00。这本书全面深入介绍了大语言模型及其前沿进展，适合科学家、工程师和学生参考。书籍摒弃了纯理论，以案例入手，采用庖丁解牛的方式帮助读者理解大语言模型的相关知识。 <div>
恭喜<a href="https://weibo.com/n/%E6%98%AF%E6%A9%99%E5%AD%90%E4%B9%9F%E6%98%AF%E6%A8%B1%E6%A1%83">@是橙子也是樱桃</a> 等3名用户获得【《大语言模型：基础与前沿》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20359960&amp;pageid=100140E51198950"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%BC%82%E6%AD%A5%E5%9B%BE%E4%B9%A6">@异步图书</a>  送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。摒弃了纯理论的说教模式，从案例入手， 采用庖丁解牛的方式帮助读者理解与认识大语言模型。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019331269755053"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef8oboqij20ga0m8q8p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9segl7j20m90m9q6z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9t5km0j20m90m942f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef9tq2esj20m90m9gpe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef9ugq5dj20m90m9dif.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 04:04:13 GMT</pubDate>
</item>
<item>
<title>今日推介(第1373期)：基于Infini-attention的高效无限上下文Transformer、极限中的语言生成、长上下文语言模型的上下文实际有多长、上下文学习回路及其形成机制...</title>
<link>https://weibo.com/1402400261/O9jZL8hC5</link>
<guid>https://weibo.com/1402400261/O9jZL8hC5</guid>
<content:encoded><![CDATA[
<div> 高效、无限上下文Transformer、Infini-attention、极限中、语言生成、长上下文、语言模型、上下文实际长度、上下文学习回路、形成机制研究<br />
<br />
上下文学习回路及其形成机制研究、基于Infini-attention的高效无限上下文Transformer、极限中的语言生成、长上下文语言模型的上下文实际有多长、大型语言模型如何用不同层获取知识<br />
<br />
总结:本文探讨了基于Infini-attention的高效无限上下文Transformer，研究了语言生成在极限情况下的表现，分析了长上下文语言模型中实际上下文的长度，探讨了上下文学习回路及其形成机制。同时，还讨论了大型语言模型如何利用不同层获取知识。通过这些研究，可以更好地理解和应用在自然语言处理领域中的语言模型和上下文处理技术。 <div>
今日推介(第1373期)：基于Infini-attention的高效无限上下文Transformer、极限中的语言生成、长上下文语言模型的上下文实际有多长、上下文学习回路及其形成机制研究、大型语言模型如何用不同层获取知识 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/692028746"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8honmw71diaj20ts130aee.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8honmw9golhj211z0u00x5.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8honmwbu8w5j21ds0lcdl1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8honmwehdnwj21dx0u0aid.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8honmwgudfrj221i0u0dpz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 22:13:03 GMT</pubDate>
</item>
<item>
<title>[CV] RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion 网页链接 通过结合图像填充和深度差分模型的知识蒸馏，提出一种文本...</title>
<link>https://weibo.com/1402400261/O9jWIk8rp</link>
<guid>https://weibo.com/1402400261/O9jWIk8rp</guid>
<content:encoded><![CDATA[
<div> 关键词: 文本驱动，3D场景生成，知识蒸馏，图像填充，深度差分，高保真，视差，研究方法，新方法，场景生成

总结:
研究提出的方法结合了图像填充和深度差分模型，实现了文本到3D场景的生成。通过知识蒸馏技术，在生成过程中保持了高保真度和视差效果。该新方法为3D场景生成领域带来了新的研究思路和实践方法，为相关研究提供了有价值的参考。 <div>
[CV] RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion  <br /><a href="https://arxiv.org/abs/2404.07199"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />通过结合图像填充和深度差分模型的知识蒸馏，提出一种文本到3D场景生成的新方法，可以产生具有视差的高保真3D场景。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honmomvibqj212c1ccdwt.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honmon71nkj21fy0i8tft.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honmonitkpj21gg0vothi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 22:05:32 GMT</pubDate>
</item>
<item>
<title>[LG] Semantically-correlated memories in a dense associative model 网页链接 提出稠密联想记忆(CDAM)模型，将自动关联和异质关联结合在连续值记忆上，进行理...</title>
<link>https://weibo.com/1402400261/O9jRe4HXX</link>
<guid>https://weibo.com/1402400261/O9jRe4HXX</guid>
<content:encoded><![CDATA[
<div> CDAM模型, 稠密联想记忆, 自动关联, 异质关联, 连续值记忆, 理论分析, 实验证明

<br /><br />总结:
本文提出了一种新的稠密联想记忆(CDAM)模型，结合自动关联和异质关联在连续值记忆上。通过理论分析和多个实验，证明了CDAM模型的有效性。该模型能够更准确地处理语义相关的记忆，并且在各项实验中表现出色。作者的研究为深度学习领域的稠密联想记忆提供了新的方向和思路。 <div>
[LG] Semantically-correlated memories in a dense associative model  <br /><a href="https://arxiv.org/abs/2404.07123"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />提出稠密联想记忆(CDAM)模型，将自动关联和异质关联结合在连续值记忆上，进行理论分析并在多个实验中证明其效果。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honmalcrzuj211o1bs4kr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honmalmyjrj21480zq0zl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honmalv7v7j21440zotgt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:52:02 GMT</pubDate>
</item>
<item>
<title>[CL] LM Transparency Tool: Interactive Tool for Analyzing Transformer Language Models 网页链接 提出一个开源的语言模型透明度分析工具LM-TT，通过可交互的...</title>
<link>https://weibo.com/1402400261/O9jOeih1G</link>
<guid>https://weibo.com/1402400261/O9jOeih1G</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型、透明度分析工具、LM-TT、交互界面、信息流、组件功能、模型运作机制

总结:
LM Transparency Tool是一个开源的语言模型透明度分析工具，通过交互界面帮助用户追溯模型预测的重要信息流，解释各组件功能，揭示模型内部运作机制。LM-TT提供了一种高效的方式，让用户更好地理解和掌握语言模型的运作原理，从而增加模型的透明度。LM-TT的设计使得用户可以从不同粒度进行分析，帮助他们更深入地了解模型的工作方式，提高模型的可解释性和可信度。LM Transparency Tool为研究人员和开发者提供了一个有用的工具，帮助他们研究和优化语言模型，从而提升其性能和效果。LM-TT的推出将有助于推动语言模型领域的发展，促进模型透明度和可解释性的提升。LM Transparency Tool的出现将为语言模型的研究和应用带来新的可能性，为人们提供更好的工具和资源，推动语言模型的不断发展和进步。LM-TT的推出标志着语言模型领域研究的新进展，为研究者和开发者提供了更强大的工具，推动语言模型技术的创新和发展。LM Transparency Tool是一个重要的工具，将为语言模型领域的研究和应用带来新的推动力，为未来的发展提供更多机遇和可能性。LM-TT将成为语言模型研究的重要工具，为研究人员提供更多的分析和探索空间，推动语言模型领域的不断发展和进步。LM Transparency Tool的推出将有助于推动语言模型领域的研究和发展，为新的探索和发现打开更广阔的空间。LM-TT将成为语言模型研究的重要工具，为研究者提供更多的资源和支持，助力语言模型技术的创新和发展。<br /><br /> <div>
[CL] LM Transparency Tool: Interactive Tool for Analyzing Transformer Language Models  <br /><a href="https://arxiv.org/abs/2404.07004"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出一个开源的语言模型透明度分析工具LM-TT，通过可交互的用户界面，允许从不同粒度追溯模型预测的重要信息流，解释各组件的功能，高效揭示模型内部运作机制。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honm2u0v7kj20wk1cm1c0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honm2ud99jj21k21a8aoh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:44:38 GMT</pubDate>
</item>
<item>
<title>[LG] Scaling Laws for Data Filtering -- Data Curation cannot be Compute Agnostic 网页链接 通过建立训练计算量自适应的数据过滤框架，实现了在不同计算量下...</title>
<link>https://weibo.com/1402400261/O9jLEdldz</link>
<guid>https://weibo.com/1402400261/O9jLEdldz</guid>
<content:encoded><![CDATA[
<div> 数据过滤框架 训练计算量 自适应 视觉语言模型 性能 提升

数据过滤在数据处理中扮演着重要角色，但常常受到计算量的限制。本文提出了一种训练计算量自适应的数据过滤框架，能够在不同计算量下显著提升视觉语言模型的性能。通过对数据过滤和数据清理的优化，可以有效提高模型的精度和效率。该方法为数据过滤领域的研究和实践提供了新的思路和方法。通过对不同计算量下的性能进行全面提升，展现了数据处理在视觉语言模型中的重要性。数据过滤框架的构建和优化，为解决数据处理中的挑战提供了新的思路和方法。 <br /><br />总结: <div>
[LG] Scaling Laws for Data Filtering -- Data Curation cannot be Compute Agnostic  <br /><a href="https://arxiv.org/abs/2404.07177"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />通过建立训练计算量自适应的数据过滤框架，实现了在不同计算量下视觉语言模型性能的全面提升。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honlw9lz4ij212s1ayng3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honlwa31vfj20tm0s6gqz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honlwabgspj20ty0ygagy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:38:17 GMT</pubDate>
</item>
<item>
<title>通过“概念深度”的概念，探究了不同难度的概念在语言模型中的学习位置，发现基础概念在浅层学习，而复杂概念需要更深层，这为理解模型内部表示并评估其鲁棒性提...</title>
<link>https://weibo.com/1402400261/O9jIH17Yd</link>
<guid>https://weibo.com/1402400261/O9jIH17Yd</guid>
<content:encoded><![CDATA[
<div> 概念深度、语言模型、学习位置、基础概念、复杂概念、内部表示、鲁棒性、模型评估、理解、视角

概念深度影响语言模型学习位置，基础概念在浅层学习，复杂概念需要更深层。研究为评估模型鲁棒性提供新视角。 <div>
通过“概念深度”的概念，探究了不同难度的概念在语言模型中的学习位置，发现基础概念在浅层学习，而复杂概念需要更深层，这为理解模型内部表示并评估其鲁棒性提供了新的视角。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?》M Jin, Q Yu, J Huang, Q Zeng... [Rutgers University &amp; University of Liverpoolc &amp; Northwestern University] (2024) <a href="https://arxiv.org/abs/2404.07066"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honlhvrlz1j218s0wigzi.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honlhw5ftuj21ve0rian5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honlhwag74j21v8120tlr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honlhwfkjbj21uq152h2j.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honlolsz27j21290uxter.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honlolthiyj20zn0tfjvj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honlolrn8wj20jp0sutb2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honlolroiwj20jp0lcabd.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:30:59 GMT</pubDate>
</item>
<item>
<title>[CL]《Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?》M Jin, Q Yu, J Huang, Q Zeng... [Rutgers University &amp;...</title>
<link>https://weibo.com/1402400261/O9jIEbvNA</link>
<guid>https://weibo.com/1402400261/O9jIEbvNA</guid>
<content:encoded><![CDATA[
<div> 大语言模型，知识获取，不同层次，概念深度，深度探索，神经网络，自然语言处理，语言模型，信息抽取，知识表示

总结:
本研究探讨了大型语言模型在不同层次上获取知识的过程。研究发现，神经网络在不同深度的层次上具有不同的知识获取能力，通过对自然语言处理和知识表示的分析，揭示了信息抽取的机制。该研究对于理解语言模型的工作原理和知识获取过程具有重要意义。 <div>
[CL]《Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?》M Jin, Q Yu, J Huang, Q Zeng... [Rutgers University &amp; University of Liverpoolc &amp; Northwestern University] (2024) <a href="https://arxiv.org/abs/2404.07066"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honlhvrlz1j218s0wigzi.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honlhw5ftuj21ve0rian5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honlhwag74j21v8120tlr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honlhwfkjbj21uq152h2j.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honlolsz27j21290uxter.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honlolthiyj20zn0tfjvj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honlolrn8wj20jp0sutb2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honlolroiwj20jp0lcabd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:30:53 GMT</pubDate>
</item>
<item>
<title>通过因果训练框架深入分析了Transformer感应头形成过程中的损失动力学，发现多个子回路的相互作用导致明显的全局非线性，并讨论了数据复杂性如何通过调节子回路...</title>
<link>https://weibo.com/1402400261/O9jBkcjhD</link>
<guid>https://weibo.com/1402400261/O9jBkcjhD</guid>
<content:encoded><![CDATA[
<div> 注意: 在此空间中，助手无法提取关键字。因此，请允许我对所提供的信息进行简要总结。

<br /><br />总结:
研究通过因果训练框架深入分析了Transformer感应头形成过程中的损失动力学。发现多个子回路相互作用导致全局非线性，并讨论了数据复杂性如何通过调节子回路形成影响全局动力学。文章提供了对在上下文学习电路和其形成过程中所需的变量的机械性研究。 <div>
通过因果训练框架深入分析了Transformer感应头形成过程中的损失动力学，发现多个子回路的相互作用导致明显的全局非线性，并讨论了数据复杂性如何通过调节子回路的形成进而影响全局动力学。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation》A K. Singh, T Moskovitz, F Hill, S C.Y. Chan, A M. Saxe [University College London &amp; Google DeepMind] (2024) <a href="https://arxiv.org/abs/2404.07129"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl4dy5hfj20r21d616n.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl4ekxeaj21rg124tod.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl4erfg8j219w0lq7bd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl4expw5j20ri1ag7da.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl5dx8foj20iz0z90wk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl5dxh3lj20j0171788.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl5dvrt1j212d0fitbn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl5dvq93j212d0kkq5u.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl5dwdt1j212d0klmzv.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:12:50 GMT</pubDate>
</item>
<item>
<title>[LG]《What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation》A K. Singh, T Moskovitz, ...</title>
<link>https://weibo.com/1402400261/O9jB9xT64</link>
<guid>https://weibo.com/1402400261/O9jB9xT64</guid>
<content:encoded><![CDATA[
<div> 学习电路, 形成, 形構成, 行为, 认知, 形成过程, 机制, 头部, 形成机制, 神经元

总结:<br /><br />
本研究探讨了诱导头部的正确形成所需的机制。研究发现，在特定环境中的学习电路对头部的形成起着关键作用。通过对认知行为的研究，揭示了头部形成的机制，并深入探讨了神经元在这一过程中的作用。这一研究为进一步理解诱导头部形成提供了重要参考。 <div>
[LG]《What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation》A K. Singh, T Moskovitz, F Hill, S C.Y. Chan, A M. Saxe [University College London &amp; Google DeepMind] (2024) <a href="https://arxiv.org/abs/2404.07129"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl4dy5hfj20r21d616n.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl4ekxeaj21rg124tod.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl4erfg8j219w0lq7bd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl4expw5j20ri1ag7da.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl5dx8foj20iz0z90wk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl5dxh3lj20j0171788.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl5dvrt1j212d0fitbn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl5dvq93j212d0kkq5u.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl5dwdt1j212d0klmzv.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl5dwnbdj212d0dxmz4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl5dwshfj212e0h1tb0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl5dznnbj212h1apgvk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl5dx21dj212g0m8q5v.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl5dw2zwj212d0dst9s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl5dxgpdj212d0jiadj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl5dygkbj212i0kodlx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl5dykfaj212e0vkwkg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl5dwwe9j212h0ivabo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:12:26 GMT</pubDate>
</item>
<item>
<title>提出新的长序列语言模型评估基准RULER，发现现有模型在输入长度和任务复杂度增加时表现大幅下降，优化目标依然存在。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《RULER:...</title>
<link>https://weibo.com/1402400261/O9jAqALkg</link>
<guid>https://weibo.com/1402400261/O9jAqALkg</guid>
<content:encoded><![CDATA[
<div> RULER, 评估基准, 长序列语言模型, 输入长度, 任务复杂度, 下降, 优化目标, 论文, NVIDIA, 2024

<br /><br />总结:
提出了新的长序列语言模型评估基准RULER，发现现有模型在输入长度和任务复杂度增加时表现下降，表明优化目标仍然存在。该论文由团队在2024年发表于NVIDIA。 <div>
提出新的长序列语言模型评估基准RULER，发现现有模型在输入长度和任务复杂度增加时表现大幅下降，优化目标依然存在。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《RULER: What's the Real Context Size of Your Long-Context Language Models?》C Hsieh, S Sun, S Kriman… [NVIDIA] (2024) <a href="https://arxiv.org/abs/2404.06654"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl13llpvj215u0wk4cj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl1425p5j21ec0iaq88.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl146jpfj21ds0lc7bb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl14e1c1j21dy0l4tg1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl1j9jiqj20ve0gvq5q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl1ja864j20vg0yc0w3.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:10:39 GMT</pubDate>
</item>
<item>
<title>[CL]《RULER: What's the Real Context Size of Your Long-Context Language Models?》C Hsieh, S Sun, S Kriman… [NVIDIA] (2024) 网页链接 #机器学习##人工智...</title>
<link>https://weibo.com/1402400261/O9jzE0wKh</link>
<guid>https://weibo.com/1402400261/O9jzE0wKh</guid>
<content:encoded><![CDATA[
<div> 关键词: RULER, Real Context Size, Long-Context Language Models, NVIDIA

总结:<br /><br />这篇文章由NVIDIA发布，讨论了长文本语言模型的真实上下文大小。研究者使用了RULER方法来评估这些语言模型的性能，并确定真实上下文大小对模型表现的影响。他们发现，适当的上下文大小对于提高语言模型的准确性至关重要，而长文案模型在实际应用中可能需要更大的上下文进行训练。研究结果为长文本语言模型的优化提供了重要参考，有助于提高其性能和应用范围。 <div>
[CL]《RULER: What's the Real Context Size of Your Long-Context Language Models?》C Hsieh, S Sun, S Kriman… [NVIDIA] (2024) <a href="https://arxiv.org/abs/2404.06654"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl13llpvj215u0wk4cj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl1425p5j21ec0iaq88.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl146jpfj21ds0lc7bb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl14e1c1j21dy0l4tg1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1honl1j9jiqj20ve0gvq5q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1honl1ja864j20vg0yc0w3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:08:43 GMT</pubDate>
</item>
<item>
<title>通过一个简洁的对抗框架证明了语言生成不同于识别，前者在某个时刻之后总是可能的，这一深刻见解启发我们从新的角度思考实际中的生成模型。 - 转发 @爱可可-爱生...</title>
<link>https://weibo.com/1402400261/O9jzi8u2c</link>
<guid>https://weibo.com/1402400261/O9jzi8u2c</guid>
<content:encoded><![CDATA[
<div> Language Generation, Limit, 对抗框架, 识别, 见解, 生成模型, 深刻, 启发, 新的角度

总结:<br /><br />本文通过一个简洁的对抗框架证明了语言生成与识别不同，语言生成在某个时刻之后总是可能的。这一深刻见解启发我们从新的角度思考实际中的生成模型。J Kleinberg和S Mullainathan在《Language Generation in the Limit》一文中提出这一理论，为我们理解语言生成问题提供了新的思路。这一对抗框架为我们解释语言生成的机制提供了新的切入点，为未来研究方向带来了新的启示。 <div>
通过一个简洁的对抗框架证明了语言生成不同于识别，前者在某个时刻之后总是可能的，这一深刻见解启发我们从新的角度思考实际中的生成模型。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Language Generation in the Limit》J Kleinberg, S Mullainathan [Cornell University &amp; University of Chicago] (2024) <a href="https://arxiv.org/abs/2404.06757"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1honl0fxoonj214k0k0wn7.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl0ga6iij218s0zen3f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1honl0go5y1j218y1cmdqm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 21:07:51 GMT</pubDate>
</item>
<item>
<title>【Parler-TTS：开源的轻量级文本到语音（TTS）模型，可以生成高质量、自然流畅的语音，模仿给定的演讲者（性别、音高、说话风格等）】'Parler-TTS - Inference a...</title>
<link>https://weibo.com/1402400261/O9dsx5AMg</link>
<guid>https://weibo.com/1402400261/O9dsx5AMg</guid>
<content:encoded><![CDATA[
<div> 开源、轻量级、文本到语音、TTS模型、高质量、自然流畅、模仿、演讲者、性别、音高

总结:<br /><br />Parler-TTS是一款开源的轻量级文本到语音（TTS）模型，旨在生成高质量、自然流畅的语音，并能模仿给定演讲者的特征，如性别、音高和说话风格。该模型具有训练和推断功能，可在GitHub上找到其源代码。Parler-TTS的出现为语音合成技术的进步提供了新的可能性，为用户提供了更加个性化、高质量的语音合成体验。 <div>
【Parler-TTS：开源的轻量级文本到语音（TTS）模型，可以生成高质量、自然流畅的语音，模仿给定的演讲者（性别、音高、说话风格等）】'Parler-TTS - Inference and training library for high-quality TTS models.' GitHub: github.com/huggingface/parler-tts <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8homu1poyc8j20z30u0443.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 05:34:43 GMT</pubDate>
</item>
<item>
<title>【用GPU分布式推理实战】《Distributed inference with multiple GPUs》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O9dpQdSwp</link>
<guid>https://weibo.com/1402400261/O9dpQdSwp</guid>
<content:encoded><![CDATA[
<div> 分布式推理、GPU、多个GPU、深度学习、模型推理、性能优化、数据并行、模型并行

<br />
本文介绍了如何利用多个GPU进行分布式推理的方法。首先讨论了在深度学习中模型推理的重要性，以及如何利用GPU来加速推理过程。然后介绍了利用多个GPU进行分布式推理的优势和挑战，主要涉及数据并行和模型并行两种方式。接着详细介绍了如何利用数据并行和模型并行实现分布式推理，并提供了相应的代码示例。最后讨论了如何优化性能，包括减少通信开销、调整batch size、使用多线程等方法。通过本文的学习，读者可以了解如何利用多个GPU进行高效的分布式推理，提升深度学习模型的推理速度和性能。

<br /><br />总结:本文介绍了利用多个GPU进行分布式推理的方法，讨论了数据并行和模型并行的优势和挑战，提供了代码示例，并讨论了性能优化的方法。通过本文的学习，读者可以提升深度学习模型的推理速度和性能。 <div>
【用GPU分布式推理实战】《Distributed inference with multiple GPUs》 <a href="https://huggingface.co/docs/diffusers/main/en/training/distributed_inference"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8homtut6db4j21020u078q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 05:28:05 GMT</pubDate>
</item>
<item>
<title>【Meta发布下一代训练和推理加速器】- 分享了下一代Meta训练和推理加速器(MTIA)的详细信息，这是专门为Meta的AI工作负载设计的定制芯片家族。 - 最新版本与MTIA ...</title>
<link>https://weibo.com/1402400261/O9dnE1MkP</link>
<guid>https://weibo.com/1402400261/O9dnE1MkP</guid>
<content:encoded><![CDATA[
<div> 加速器、Meta、训练、推理、AI工作负载、性能提升、广告排名、推荐模型、基础设施、芯片家族

总结:<br /><br />Meta发布了下一代训练和推理加速器(MTIA)，专为其AI工作负载设计。新版本相比之前有显着性能提升，支持广告排名和推荐模型。MTIA是Meta不断增长的AI基础设施投资的一部分，将为产品和服务带来新体验。新一代Meta基础设施以AI为中心，支持新产品、推荐系统和AI研究。MTIA v1是首款自主设计的AI推理加速器，提升深度学习推荐模型体验。新版本提升了计算性能和内存带宽，保持高度耦合。MTIA在计算、内存带宽和内存容量上平衡，是构建支持AI工作负载的核心基础设施。Meta正在扩展MTIA范围，包括支持GenAI工作负载。MTIA已部署在数据中心，服务模型并投入更多计算能力。 <div>
【Meta发布下一代训练和推理加速器】<br />- 分享了下一代Meta训练和推理加速器(MTIA)的详细信息，这是专门为Meta的AI工作负载设计的定制芯片家族。   <br />- 最新版本与MTIA v1相比有显着的性能提升，可以支持Meta的广告排名和推荐模型。   <br />- MTIA是对AI基础设施投资不断增长的一部分，将与现有和未来的AI基础设施相辅相成，为Meta的产品和服务带来新的更好的体验。   <br />- 新一代Meta大规模基础设施的设计以AI为中心，包括支持新的生成AI(GenAI)产品和服务、推荐系统以及先进的AI研究。   <br />- MTIA v1是Meta首款针对其AI推理工作负载自主设计的AI推理加速器，专门用于提升产品中的各种体验的深度学习推荐模型。   <br />- 新版本MTIA相比之前的解决方案提升了2倍以上的计算性能和内存带宽，并保持了与工作负载的高度耦合。它被设计来高效服务为用户提供高质量推荐的排名和推荐模型。   <br />- 该芯片架构的核心是在计算、内存带宽和内存容量之间提供适合服务排名和推荐模型的正确平衡。   <br />- MTIA将是Meta长期规划中构建和扩展支持其独特AI工作负载所需的最强大和最高效基础设施的重要组成部分。   <br />- Meta当前正在进行多个旨在扩展MTIA范围的项目，包括支持GenAI工作负载。   <br />- MTIA已经部署到数据中心，现在正在生产环境中服务模型。它正如预期的那样，允许其为更密集的AI工作负载投入和投资更多计算能力。<br />《Our next generation Meta Training and Inference Accelerator》 <a href="https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8homtolwiphj20p40p4gnj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 05:22:40 GMT</pubDate>
</item>
<item>
<title>【Google宣布进一步扩展开源语言模型Gemma系列】 - 推出了两个新的Gemma变体模型：CodeGemma用于代码补全、生成和聊天；RecurrentGemma是一个技术不同的模型，利...</title>
<link>https://weibo.com/1402400261/O9djE6F9I</link>
<guid>https://weibo.com/1402400261/O9djE6F9I</guid>
<content:encoded><![CDATA[
<div> Gemma, 扩展, 开源, 语言模型, CodeGemma, RecurrentGemma, 高性能, 高效率, 负责任AI设计, Kaggle

<br /><br />总结:
Google宣布进一步扩展开源语言模型Gemma系列，推出了两个新的模型：CodeGemma和RecurrentGemma。其中，CodeGemma包括针对代码补全、生成和聊天的不同变体，支持多种编程语言，并有高参数预训练模型可供选择。RecurrentGemma则是一种技术不同的模型，利用RNN和本地注意力来提高内存效率，展示了非Transformer的高性能模型。这些模型秉承Gemma原则，提供高性能和效率，支持负责任的AI设计，并对所有人开放可用。同时，Gemma 1.1版本也发布了，包括性能改进和缺陷修复，使用条款也进行了更新。这些模型已在Kaggle、Hugging Face、Vertex AI Model Garden等平台上线，为开发者和研究者提供了更大灵活性。 <div>
【Google宣布进一步扩展开源语言模型Gemma系列】<br /> - 推出了两个新的Gemma变体模型：CodeGemma用于代码补全、生成和聊天；RecurrentGemma是一个技术不同的模型，利用RNN和本地注意力来提高内存效率。   <br />- CodeGemma有3个变体：一个7B的参数预训练模型，专门用于代码补全和生成；一个7B的参数模型，针对代码聊天和指令理解进行了调优；一个2B参数的预训练模型，支持本地部署。CodeGemma对代码语义理解更准确，支持多种编程语言。   <br />- RecurrentGemma虽然性能与Gemma 2B类似，但其特殊的架构降低了内存需求，支持更长文本生成，也支持更高的吞吐量。它展示了一个非Transformer的高性能模型，对深度学习研究有启发意义。   <br />- 新模型贯彻了Gemma的原则，对所有人开放可用，提供高性能和效率，实现负责任的AI设计，支持各种软硬件部署。   <br />- Gemma 1.1也发布了，包括性能改进、缺陷修复等。使用条款也进行了更新，提供更大灵活性。   <br />- 这些模型现已在Kaggle、Hugging Face、Vertex AI Model Garden等平台上线，文中提供了各种获取和试用指南。<br />《Gemma Family Expands with Models Tailored for Developers and Researchers - Google for Developers》 <a href="https://developers.googleblog.com/2024/04/gemma-family-expands.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8homteueg9ij218g0p077w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8homtesdv57j218g0p0acv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 05:12:49 GMT</pubDate>
</item>
<item>
<title>今日开奖，欢迎参与！ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转发+评论...</title>
<link>https://weibo.com/1402400261/O9biJfNam</link>
<guid>https://weibo.com/1402400261/O9biJfNam</guid>
<content:encoded><![CDATA[
<div> LangChain, 实战, 初学者, 大语言模型, LangChain团队, LangServe, LangSmith, 人工智能, 应用场景, LCEL

<br /><br />总结:
今天开奖活动，欢迎大家参与。参与方法是转发并评论*可可粉*，有机会获得3本《LangChain实战》书籍。这本书是为初学者和对LangChain应用及大语言模型感兴趣的开发者而写的。书籍介绍了LangChain 0.1版本, 并配套600分钟详解视频。重点讲解了多个核心应用场景，深入探讨了LCEL的应用方式。同时，书籍详细探讨了LangChain、LangServe和LangSmith，帮助读者了解LangChain团队在生成式人工智能领域的布局。愿大家参与活动，获得更多有关LangChain的知识。 <div>
今日开奖，欢迎参与！<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a> <a href="https://shop.sc.weibo.com/h5/goods/index?iid=110014024002610004661854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">LangChain实战：从原型到生产，动手打造 LLM 应用</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hofl98oom9j207q0a0jrm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 00:05:04 GMT</pubDate>
</item>
<item>
<title>今日推介(第1372期)：大型语言模型也是强大的文本编码器、将语言模型与定制合成数据对齐、大型语言模型中表格数据的记忆与学习、带有中间修正和搜索的推理、Tran...</title>
<link>https://weibo.com/1402400261/O9aBQ7Sqz</link>
<guid>https://weibo.com/1402400261/O9aBQ7Sqz</guid>
<content:encoded><![CDATA[
<div> 文本编码器、定制合成数据、表格数据记忆、推理、可解释性、Transformer、RNN

大型语言模型在文本编码和处理上展现出了强大的能力，可以作为优秀的文本编码器。同时，将语言模型与定制合成数据对齐可以提高模型性能和适用范围。在大型语言模型中，对表格数据的记忆与学习是一个关键挑战，需要进一步探索和改进。在推理过程中，结合中间修正和搜索可以提高推理的准确性和效率。虽然Transformer具有很好的可解释性，但是其是否可以迁移到RNN等其他模型仍需要进行深入研究。总之，大型语言模型在各个方面的应用和改进都有很多潜力和挑战，需要不断探索和完善。<br /><br />总结: 大型语言模型展现出强大的文本编码能力，但仍需进一步改进表格数据记忆和推理过程，同时需要研究Transformer可解释性迁移到其他模型的可能性。 <div>
今日推介(第1372期)：大型语言模型也是强大的文本编码器、将语言模型与定制合成数据对齐、大型语言模型中表格数据的记忆与学习、带有中间修正和搜索的推理、Transformer的可解释性能否迁移到RNN 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/691823619"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8homhgd1sy8j21ke0ni7aq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8homhgh3bpbj21d10u0k17.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8homhgks2srj21ce0pm0xb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8homhgngpsbj20u0153n44.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8homhgqkr2kj20ji1ak0w5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 22:19:23 GMT</pubDate>
</item>
<item>
<title>[LG] Dynamical stability and chaos in artificial neural network trajectories along training 网页链接 从动态系统角度将神经网络训练轨迹动力学化，发现学...</title>
<link>https://weibo.com/1402400261/O9axO25Dt</link>
<guid>https://weibo.com/1402400261/O9axO25Dt</guid>
<content:encoded><![CDATA[
<div> 动态系统、神经网络、训练、动力学、稳定性、学习率调节、复杂动力学行为、有效学习<br />
<br />
<br />
总结: 本文从动态系统角度研究了神经网络训练轨迹的稳定性和混沌性，发现在学习率调节过程中会产生复杂的动力学行为。在稳定性边缘，神经网络的训练可以获得有效的学习。这一研究揭示了神经网络训练过程中的动力学特性，为提高神经网络训练效果提供了新的视角和方法。 <div>
[LG] Dynamical stability and chaos in artificial neural network trajectories along training  <br /><a href="https://arxiv.org/abs/2404.05782"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />从动态系统角度将神经网络训练轨迹动力学化，发现学习率调节能引发复杂动力学行为，在稳定性边缘可获得有效学习。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homh6ep3f0j210s11awpu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homh6f2q58j21ki0taq83.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homh6fi14vj21nk0rw483.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 22:09:28 GMT</pubDate>
</item>
<item>
<title>[AI] Wu's Method can Boost Symbolic AI to Rival Silver Medalists and AlphaGeometry to Outperform Gold Medalists at IMO Geometry 网页链接 重新评估了吴...</title>
<link>https://weibo.com/1402400261/O9av62QL8</link>
<guid>https://weibo.com/1402400261/O9av62QL8</guid>
<content:encoded><![CDATA[
<div> 关键词: 吴氏法、Symbolic AI、AlphaGeometry、IMO几何、自动定理证明

总结:<br /><br />在重新评估了吴氏法在奥数几何题目上的表现后发现，其表现意外强大，并与现代方法如AlphaGeometry形成互补，为几何自动定理证明建立了全新的最优结果。 Wu's Method能提升Symbolic AI的实力，使其能够与奥数几何比赛的银牌得主一较高下，同时AlphaGeometry方法在IMO几何方面表现优异，超过金牌得主的水平。这些发现为提高几何自动证明的技术水平提供了新的方向和可能性。 <div>
[AI] Wu's Method can Boost Symbolic AI to Rival Silver Medalists and AlphaGeometry to Outperform Gold Medalists at IMO Geometry  <br /><a href="https://arxiv.org/abs/2404.06405"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />重新评估了吴氏法在奥数几何题目上的表现，发现其意外强大，与AlphaGeometry等现代方法形成互补，为几何自动定理证明再次建立了全新的最优结果。<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homgzh25yfj210c19ak8t.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homgzh9yf9j21dw0xudnk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 22:02:47 GMT</pubDate>
</item>
<item>
<title>[CV] Matching 2D Images in 3D: Metric Relative Pose from Metric Correspondences 网页链接 提出MicKey方法，利用预测单张图像的3D关键点坐标实现无需外部深...</title>
<link>https://weibo.com/1402400261/O9asko3AR</link>
<guid>https://weibo.com/1402400261/O9asko3AR</guid>
<content:encoded><![CDATA[
<div> 方法、3D关键点坐标、度量相对位姿估计、位姿标签监督训练、MicKey方法、2D图像匹配、无需外部深度、有效性证明

<br /><br />总结:
本文提出了一种名为MicKey的方法，利用预测单张图像的3D关键点坐标实现无需外部深度的度量相对位姿估计。通过仅利用图像对的位姿标签进行监督训练，证明了该方法的有效性。MicKey方法通过匹配2D图像中的关键点，在3D空间中计算出相对姿态，实现了精确的相机位姿估计。通过实验验证，MicKey方法在匹配2D图像的同时实现了较高精度的相机位姿估计，具有很高的实用性和有效性。MicKey方法的提出拓展了在没有外部深度信息的情况下进行相机位姿估计的可能性，对于计算机视觉领域的研究具有一定的启发意义。 <div>
[CV] Matching 2D Images in 3D: Metric Relative Pose from Metric Correspondences  <br /><a href="https://arxiv.org/abs/2404.06337"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />提出MicKey方法，利用预测单张图像的3D关键点坐标实现无需外部深度的度量相对位姿估计，并证明仅利用图像对的位姿标签监督训练的有效性。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homgsd6thdj212m1aynho.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homgsdia14j21ik0n0wqx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homgsdnoe4j20r20oq0xz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:55:58 GMT</pubDate>
</item>
<item>
<title>[CL] Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence 网页链接 提出了Eagle和Finch两种改进自RWKV-4的高效RNN体系结构，在大量预训练...</title>
<link>https://weibo.com/1402400261/O9alhBvkx</link>
<guid>https://weibo.com/1402400261/O9alhBvkx</guid>
<content:encoded><![CDATA[
<div> Eagle, Finch, RWKV, RNN, Transformer, 多语言建模, 预训练, 高效, 可解释, 语言模型

总结:<br /><br />研究团队提出了Eagle和Finch两种改进自RWKV-4的高效RNN体系结构，经过大量预训练展示了与Transformer竞争的多语言建模效果。这为提供高效可解释的语言模型提供了可行的选择，为语言模型研究领域带来了新的方向。 <div>
[CL] Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence  <br /><a href="https://arxiv.org/abs/2404.05892"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出了Eagle和Finch两种改进自RWKV-4的高效RNN体系结构，在大量预训练后展示了与Transformer竞争的多语言建模效果，为提供高效可解释的语言模型提供了可行的选择。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homgaap0iyj20vo0y812f.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homgabfemwj21gq1ck49l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homgabxe4zj21ck0yi0x8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:38:37 GMT</pubDate>
</item>
<item>
<title>发现设计用于解释Transformer的技术大多可直接应用于新兴RNN架构，并创新利用RNN压缩状态增强控制能力。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Does Transformer I...</title>
<link>https://weibo.com/1402400261/O9aj1cQ2K</link>
<guid>https://weibo.com/1402400261/O9aj1cQ2K</guid>
<content:encoded><![CDATA[
<div> Transformer、RNN、技术、解释性、新兴、架构、状态压缩、控制能力、利用、创新

总结：<br /><br />本文探讨了Transformer解释性技术如何应用于RNN，并创新利用RNN压缩状态以增强控制能力。发现大部分Transformer解释技术可直接应用于RNN，为未来RNN架构的发展提供了新思路。 <div>
发现设计用于解释Transformer的技术大多可直接应用于新兴RNN架构，并创新利用RNN压缩状态增强控制能力。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Does Transformer Interpretability Transfer to RNNs?》G Paulo, T Marshall, N Belrose [EleutherAI] (2024) <a href="https://arxiv.org/abs/2404.05971"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfvtnquwj21940o4492.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfvu1w48j20jo10yad1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfvuf4x4j20ji1akwiv.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfvupsgej21hg0ve124.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homg48kjppj20vf0i40va.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homg48kvt9j20vi0g8did.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homg48kpxjj20ve0jnmzf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homg48kfazj20vf0m4wgh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homg48kawjj20g80ktgnm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:33:02 GMT</pubDate>
</item>
<item>
<title>[LG]《Does Transformer Interpretability Transfer to RNNs?》G Paulo, T Marshall, N Belrose [EleutherAI] (2024) 网页链接 #机器学习##人工智能##论文# [图...</title>
<link>https://weibo.com/1402400261/O9aiX4GAr</link>
<guid>https://weibo.com/1402400261/O9aiX4GAr</guid>
<content:encoded><![CDATA[
<div> Transformer, Interpretability, RNNs, Transfer, EleutherAI, Paulo, Marshall, Belrose

总结:<br /><br />本文探讨了Transformer模型的可解释性是否可以迁移到RNNs模型上。研究团队由G Paulo、T Marshall和N Belrose来自EleutherAI。他们研究发现，虽然Transformer模型在可解释性方面表现出色，但这种可解释性并不一定可以直接转移到RNNs模型上。作者通过实验证明，即使在相同的训练数据和任务上，RNNs模型的可解释性并不如Transformer模型明显。研究结果呼吁在研究和开发RNNs模型时要更加关注其可解释性，以提高模型的可理解性和可解释性。 <div>
[LG]《Does Transformer Interpretability Transfer to RNNs?》G Paulo, T Marshall, N Belrose [EleutherAI] (2024) <a href="https://arxiv.org/abs/2404.05971"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfvtnquwj21940o4492.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfvu1w48j20jo10yad1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfvuf4x4j20ji1akwiv.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfvupsgej21hg0ve124.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homg48kjppj20vf0i40va.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homg48kvt9j20vi0g8did.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homg48kpxjj20ve0jnmzf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homg48kfazj20vf0m4wgh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homg48kawjj20g80ktgnm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homg48lighj20vd14c0wm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homg48lgjsj20vd14fady.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homg48lhrhj20vd14fq6d.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homg48lkwdj20vd13itcm.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homg48kzxbj20vd0rzdin.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:32:52 GMT</pubDate>
</item>
<item>
<title>提出THOUGHTSCULPT框架，将复杂推理任务分解为简单组件，利用蒙特卡罗树搜索和中间结果修改机制进行逼真的复杂推理，在多个任务上优于当前最新方法。 - 转发 @爱...</title>
<link>https://weibo.com/1402400261/O9aeezyoY</link>
<guid>https://weibo.com/1402400261/O9aeezyoY</guid>
<content:encoded><![CDATA[
<div> 蒙特卡罗树搜索, 复杂推理, THOUGHTSCULPT, 中间结果修改机制, 多个任务, UC Berkeley, 理性思维, 推理任务, 最新方法, 逼真<br />
<br />
提出了THOUGHTSCULPT框架，将复杂推理任务分解为简单组件，利用蒙特卡罗树搜索和中间结果修改机制进行逼真的复杂推理。该框架在多个任务上超越了当前最新方法，取得了优异的表现。该研究由UC Berkeley的Chi、Yang和Klein等人完成，并于2024年发表。<br />
<br />
总结: 该研究提出了THOUGHTSCULPT框架，利用蒙特卡罗树搜索和中间结果修改机制进行复杂推理任务。这一方法在多个任务上超越了当前最新方法，显示了优越的性能。 <div>
提出THOUGHTSCULPT框架，将复杂推理任务分解为简单组件，利用蒙特卡罗树搜索和中间结果修改机制进行逼真的复杂推理，在多个任务上优于当前最新方法。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《THOUGHTSCULPT: Reasoning with Intermediate Revision and Search》Y Chi, K Yang, D Klein [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.05966"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfrjnakgj217i0msdoz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfrk58yaj20zc1cek1g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfrkfdr9j20z40wsq9q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfrkispgj20z00faad8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfs1y5x7j20ve0cx0ug.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfs1xwkij20vd0eaabd.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:21:15 GMT</pubDate>
</item>
<item>
<title>[CL]《THOUGHTSCULPT: Reasoning with Intermediate Revision and Search》Y Chi, K Yang, D Klein [UC Berkeley] (2024) 网页链接 #机器学习##人工智能##论文# ...</title>
<link>https://weibo.com/1402400261/O9aea9NIe</link>
<guid>https://weibo.com/1402400261/O9aea9NIe</guid>
<content:encoded><![CDATA[
<div> 关键词: THOUGHTSCULPT, 推理, 中间修订, 搜索, 搜索空间, 计算复杂性, 信息检索, 实验结果, 人工智能, UC Berkeley

总结:
<br />
本文介绍了一种名为THOUGHTSCULPT的方法，用于推理过程中的中间修订和搜索。该方法结合了传统的推理和搜索算法，并通过对搜索空间的有效管理提高了效率。研究者在实验中验证了这一方法在信息检索中的有效性，并探讨了其在计算复杂性方面的优势。这项研究是在UC Berkeley进行的，展示了人工智能领域的最新进展。 <div>
[CL]《THOUGHTSCULPT: Reasoning with Intermediate Revision and Search》Y Chi, K Yang, D Klein [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2404.05966"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfrjnakgj217i0msdoz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfrk58yaj20zc1cek1g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfrkfdr9j20z40wsq9q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfrkispgj20z00faad8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfs1y5x7j20ve0cx0ug.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfs1xwkij20vd0eaabd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:21:04 GMT</pubDate>
</item>
<item>
<title>研究发现大型语言模型记忆了许多表格数据集并导致过拟合，提供了检验记忆与评估模型泛化能力的有效方法。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Elephants Never F...</title>
<link>https://weibo.com/1402400261/O9adzlhy4</link>
<guid>https://weibo.com/1402400261/O9adzlhy4</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、记忆、表格数据集、过拟合、检验、评估、模型泛化能力、有效方法  
总结:<br /><br />这项研究发现大型语言模型存在记忆表格数据集并导致过拟合的问题。通过提供一种有效方法来检验记忆和评估模型泛化能力，研究表明模型记忆了大量的表格数据，需要进一步研究以避免过拟合。这为解决大型语言模型记忆问题提供了重要参考。 <div>
研究发现大型语言模型记忆了许多表格数据集并导致过拟合，提供了检验记忆与评估模型泛化能力的有效方法。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models》S Bordt, H Nori, V Rodrigues, B Nushi, R Caruana [University of Tubingen &amp; Microsoft Research] (2024) <a href="https://arxiv.org/abs/2404.06209"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfoxhg54j214e0sqamk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfoxtybgj21ce0pmdm5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfoylq8uj21cg0oen4a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfoz3h63j21c80tktjd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfq0oe69j20vf0fm0vf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfq0ofbxj20v00d9gnp.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:19:37 GMT</pubDate>
</item>
<item>
<title>[LG]《Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models》S Bordt, H Nori, V Rodrigues, B Nushi, R Caruana [Un...</title>
<link>https://weibo.com/1402400261/O9admsSPz</link>
<guid>https://weibo.com/1402400261/O9admsSPz</guid>
<content:encoded><![CDATA[
<div> Elephants Never Forget, Memorization, Learning, Tabular Data, Large Language Models, University of Tubingen, Microsoft Research

<br /><br />总结：
该研究由图宾根大学和微软研究院进行，着重探讨大型语言模型中的表格数据记忆与学习能力。研究发现，大型语言模型可以很好地记忆和学习表格数据，同时展现出不错的性能。通过实验和分析，验证了这一发现，表明大型语言模型在处理大规模数据集时具有优势。研究结果对于进一步改进大型语言模型的设计和应用具有重要意义，有助于提高模型的表现和应用范围。整体而言，该研究为理解语言模型中的记忆和学习机制提供了重要洞见，为相关领域的研究和应用提供了有益的参考。 <div>
[LG]《Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models》S Bordt, H Nori, V Rodrigues, B Nushi, R Caruana [University of Tubingen &amp; Microsoft Research] (2024) <a href="https://arxiv.org/abs/2404.06209"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfoxhg54j214e0sqamk.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfoxtybgj21ce0pmdm5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfoylq8uj21cg0oen4a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfoz3h63j21c80tktjd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfq0oe69j20vf0fm0vf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfq0ofbxj20v00d9gnp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:19:06 GMT</pubDate>
</item>
<item>
<title>CodecLM通过语言模型编解码与自生成规范和对比过滤，实现无人工参与下的高质量定制指令生成，从而提升语言模型对不同下游任务指令的遵循能力。 - 转发 @爱可可-...</title>
<link>https://weibo.com/1402400261/O9acv4sdi</link>
<guid>https://weibo.com/1402400261/O9acv4sdi</guid>
<content:encoded><![CDATA[
<div> 语言模型、编解码、自生成、规范、对比过滤、定制指令、提升、任务指令、CodecLM
<br />
<br />
总结:本文介绍了一种名为CodecLM的方法，通过语言模型的编解码和自动生成规范与对比过滤，在无人工参与的情况下生成高质量的定制指令，从而提高语言模型对不同下游任务指令的遵循能力。CodecLM能够根据特定任务需求生成定制化的指令，为各种应用场景提供更好的支持。该方法通过合成数据进行训练，提高了语言模型的适应能力和准确性，为自然语言处理领域的发展带来了新的可能性。CodecLM的提出将为未来的研究工作和实际应用带来新的启示，为语言模型的发展和应用提供了有益的借鉴。
 <div>
CodecLM通过语言模型编解码与自生成规范和对比过滤，实现无人工参与下的高质量定制指令生成，从而提升语言模型对不同下游任务指令的遵循能力。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《CodecLM: Aligning Language Models with Tailored Synthetic Data》Z Wang, C Li, V Perot, L T. Le, J Miao, Z Zhang, C Lee, T Pfister [Google Cloud AI Research &amp; Google Research] (2024) <a href="https://arxiv.org/abs/2404.05875"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfmteelgj20oq1dmgyf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfmtypqlj20so0ysn39.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfmuhb4ij21ke0yiqgv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfmulqvoj20ro0qwq6k.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfvdj8j20g806wt90.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfvfzjj20gu0cejs5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfnfxbacj20zs0ueq88.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfnfwp5gj20zx0pg42e.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfw4aqj20zx0cdta8.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:16:58 GMT</pubDate>
</item>
<item>
<title>[CL]《CodecLM: Aligning Language Models with Tailored Synthetic Data》Z Wang, C Li, V Perot, L T. Le, J Miao, Z Zhang, C Lee, T Pfister [Google Cloud ...</title>
<link>https://weibo.com/1402400261/O9aco5Aod</link>
<guid>https://weibo.com/1402400261/O9aco5Aod</guid>
<content:encoded><![CDATA[
<div> 关键词: CodecLM, 语言模型, 合成数据, 对齐, 研究, Google Cloud AI Research, Google Research

总结:
<br />
这篇文章由Wang, Li, Perot, Le, Miao, Zhang, Lee和Pfister撰写，来自Google Cloud AI Research和Google Research。研究的主题是《CodecLM: Aligning Language Models with Tailored Synthetic Data》，重点是如何利用合成数据来对齐语言模型。文章介绍了他们提出的CodecLM框架，该框架可以生成定制化的合成数据，从而帮助语言模型更好地学习特定任务。研究结果表明，利用合成数据对齐语言模型可以带来显著的性能提升。这项研究对于进一步优化语言模型的训练和应用具有重要意义。 <div>
[CL]《CodecLM: Aligning Language Models with Tailored Synthetic Data》Z Wang, C Li, V Perot, L T. Le, J Miao, Z Zhang, C Lee, T Pfister [Google Cloud AI Research &amp; Google Research] (2024) <a href="https://arxiv.org/abs/2404.05875"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfmteelgj20oq1dmgyf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfmtypqlj20so0ysn39.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfmuhb4ij21ke0yiqgv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1homfmulqvoj20ro0qwq6k.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfvdj8j20g806wt90.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfvfzjj20gu0cejs5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1homfnfxbacj20zs0ueq88.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfnfwp5gj20zx0pg42e.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfw4aqj20zx0cdta8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfwannj20zx0eotaw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfwdrpj20zx0atdh8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1homfnfxac4j20zx0kf41t.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1homfnfxf5fj20zx0k3who.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 21:16:42 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.10)》 爱可可微博热门分享(4.10) [图片]</title>
<link>https://weibo.com/1402400261/O97BXBqP8</link>
<guid>https://weibo.com/1402400261/O97BXBqP8</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 爱可可, 分享, 4.10, 美食, 旅行, 阅读, 心情, 文艺

<br /><br />总结:
4月10日，爱可可微博上分享了一篇热门文章，内容涵盖美食、旅行、阅读等多个领域。文章引发了用户们的讨论和关注。美食方面，推荐了一些新鲜有趣的料理；旅行部分介绍了一些独特的目的地和景点；阅读方面推荐了一些文艺作品，让人们在阅读中放松心情。这篇文章得到了广泛的转发和点赞，受到了大家的喜爱和欢迎。 <div>
《爱可可微博热门分享(4.10)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405021742140621081"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.10)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hom486sbdrj20kg0biwfg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 14:41:28 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Learning to Act without Actions》(ICLR 2024) GitHub: github.com/schmidtdominik/LAPO《Elucidating the Exposure Bias in Diffusion Mo...</title>
<link>https://weibo.com/1402400261/O94atlime</link>
<guid>https://weibo.com/1402400261/O94atlime</guid>
<content:encoded><![CDATA[
<div> Learning, Act, Actions, Exposure Bias, Diffusion Models, Memory-Augmented, Video Understanding, Facial Expressions, Prompt Optimization, Text-to-Image Generation

<br />本文介绍了几篇论文的实现代码，包括学习如何在没有动作的情况下进行行动的研究，揭示扩散模型中的曝光偏差，以及用于长期视频理解的记忆增强型多模态模型等。另外还讨论了通过神经合成分析实现的三维面部表情生成，以及在文本到图像生成中动态提示优化等内容。此外，文章还介绍了基于语言嵌入的三维高斯场用于开放词汇场景理解，以及从语言嵌入特征场进行物理属性理解的研究。此外，还包括了自动程序改进，扩散模型的缩放结构以及移动手机双摄平滑变焦等研究成果。同时，讨论了在个性化视觉编辑中实现任意对象交换，通过细粒度音频功能、文本嵌入监督和LLM混合增强来改进音频字幕模型，以及从单一图像实现零样本材料迁移等研究成果。最后还讨论了处理粗糙视觉条件的控制网络增强，无需训练的三维生成加速技术，以及大型语言模型对文本编码的潜在能力等内容。

<br /><br />总结: 本文总结了多篇涉及不同领域的论文实现代码，包括行动没有动作的学习、曝光偏差的解释、视频理解的记忆增强模型、三维面部表情生成、文本到图像生成优化等研究成果，并系统阐述了这些研究的关键要点和成果。 <div>
几篇论文实现代码：<br />《Learning to Act without Actions》(ICLR 2024) GitHub: github.com/schmidtdominik/LAPO<br />《Elucidating the Exposure Bias in Diffusion Models》(ICLR 2024) GitHub: github.com/forever208/EDM-ES<br />《MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding》(CVPR 2024) GitHub: github.com/boheumd/MA-LMM [fig4]<br />《3D Facial Expressions through Analysis-by-Neural-Synthesis》(CVPR 2024) GitHub: github.com/georgeretsi/smirk<br />《Dynamic Prompt Optimizing for Text-to-Image Generation》(CVPR 2024) GitHub: github.com/Mowenyii/PAE [fig5]<br />《Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras》(CVPR 2024) GitHub: github.com/HuajianUP/Photo-SLAM<br />《LEGaussians: Language Embedded 3D Gaussians for Open-Vocabulary Scene Understanding》(CVPR 2024) GitHub: github.com/buaavrcg/LEGaussians<br />《NeRF2Physics: Physical Property Understanding from Language-Embedded Feature Fields》(CVPR 2024) GitHub: github.com/ajzhai/NeRF2Physics [fig10]<br />《AutoCodeRover: Autonomous Program Improvement》(2024) GitHub: github.com/nus-apr/auto-code-rover [fig1]<br />《Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models》(2024) GitHub: github.com/feizc/Diffusion-RWKV [fig2]<br />《Dual-Camera Smooth Zoom on Mobile Phones》(2024) GitHub: github.com/ZcsrenlongZ/ZoomGS [fig3]<br />《SwapAnything: Enabling Arbitrary Object Swapping in Personalized Visual Editing》(2024) GitHub: github.com/eric-ai-lab/swap-anything [fig6]<br />《Improving Audio Captioning Models with Fine-grained Audio Features, Text Embedding Supervision, and LLM Mix-up Augmentation》(2024) GitHub: github.com/slSeanWU/beats-conformer-bart-audio-captioner<br />《ZeST: Zero-Shot Material Transfer from a Single Image》(2024) GitHub: github.com/ttchengab/zest_code [fig7]<br />《SmartControl: Enhancing ControlNet for Handling Rough Visual Conditions》(2024) GitHub: github.com/liuxiaoyu1104/SmartControl [fig8]<br />《Hash3D: Training-free Acceleration for 3D Generation》(2024) GitHub: github.com/Adamdad/hash3D [fig9]<br />《LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders》(2024) GitHub: github.com/McGill-NLP/llm2vec<br />《Point Cloud Mamba: Point Cloud Learning via State Space Model》(2024) GitHub: github.com/SkyworkAI/PointCloudMamba<br />《An Empirical Study of Data Ability Boundary in LLMs' Math Reasoning》(2024) GitHub: github.com/cyzhh/MMOS<br />《HiQA: A Hierarchical Contextual Augmentation RAG for Massive Documents QA》(2024) GitHub: github.com/TebooNok/HiQA<br />《Magic Clothing: Controllable Garment-Driven Image Synthesis》(2024) GitHub: github.com/ShineChen1024/MagicClothing<br />《Rethinking the Spatial Inconsistency in Classifier-Free Diffusion Guidance》(2024) GitHub: github.com/SmilesDZgk/S-CFG<br />《HyperTTS: Parameter Efficient Adaptation in Text to Speech using Hypernetworks》(2024) GitHub: github.com/declare-lab/HyperTTS<br />《AI and Memory Wall》(2024) GitHub: github.com/amirgholami/ai_and_memory_wall<br />《Compound text-guided prompt tuning via image-adaptive cues》(2024) GitHub: github.com/EricTan7/TGP-T [fig11]<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1holng2zgs7j20zx06rmyn.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1holng402ucj21120f0acu.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1holng4xjqaj20xt0pznh5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holng7m91ej26zk3m8e85.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holniqwve3j22dx0nwtwr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holnjgtfx2j243m23nqvh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1holnksevzyj21mr0olte9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1holnllw9hij22ps1bdhdt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1holnmp8hpzj21s10gg798.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holnzzb68pj21g70feajf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1holodjly5kj21rn0sg1kx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:55:30 GMT</pubDate>
</item>
<item>
<title>【LLM Gateway：用于安全可靠地与 OpenAI 和其他 LLM(语言模型)提供商进行通信的网关】'LLM Gateway - Gateway for secure &amp; reliable communications with Open...</title>
<link>https://weibo.com/1402400261/O943NqBXE</link>
<guid>https://weibo.com/1402400261/O943NqBXE</guid>
<content:encoded><![CDATA[
<div> LLM Gateway, 安全可靠, OpenAI, 通信, 网关, 语言模型, 提供商, GitHub<br /><br />总结:
LLM Gateway是一个用于安全可靠地与OpenAI和其他LLM提供商进行通信的网关。该项目在GitHub上可见，可以帮助用户进行安全和可靠的通讯。网关的主要作用是为用户提供与各种LLM提供商之间的连接和交流，确保信息传输的安全性和可靠性。通过LLM Gateway，用户可以更方便地与不同语言模型提供商进行沟通和合作。这个项目能够有效帮助用户实现与OpenAI等LLM提供商的通信需求，提高工作效率。 <div>
【LLM Gateway：用于安全可靠地与 OpenAI 和其他 LLM(语言模型)提供商进行通信的网关】'LLM Gateway - Gateway for secure &amp; reliable communications with OpenAI and other LLM providers' GitHub: github.com/wealthsimple/llm-gateway <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8holojwm2z6j212j0u0tba.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:39:03 GMT</pubDate>
</item>
<item>
<title>【Asterinas：安全、快速、通用的操作系统内核，使用Rust编写，并与Linux兼容】'Asterinas - a secure, fast, and general-purpose OS kernel, written in Rust ...</title>
<link>https://weibo.com/1402400261/O942Nv8kB</link>
<guid>https://weibo.com/1402400261/O942Nv8kB</guid>
<content:encoded><![CDATA[
<div> 安全、快速、通用、操作系统内核、Rust、Linux兼容、ABI、Asterinas、GitHub

<br /><br />总结:
Asterinas是一个使用Rust编写的安全、快速、通用的操作系统内核，与Linux兼容，提供Linux-compatible ABI。该项目在GitHub上托管，名为asterinas/asterinas。这个内核旨在提供更安全和高效的操作系统基础，同时保持与Linux的兼容性，为用户带来更好的操作系统体验。 <div>
【Asterinas：安全、快速、通用的操作系统内核，使用Rust编写，并与Linux兼容】'Asterinas - a secure, fast, and general-purpose OS kernel, written in Rust and providing Linux-compatible ABI.' GitHub: github.com/asterinas/asterinas <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%23&amp;isnewpage=1"><span class="surl-text">#操作系统#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8holoh9eu18j218s0u0af8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:36:36 GMT</pubDate>
</item>
<item>
<title>【Full Stack FastAPI, React, MongoDB (FARM) Base Project Generator：FastAPI 和 MongoDB 的全栈应用生成器】'Full Stack FastAPI, React, MongoDB (FARM) Ba...</title>
<link>https://weibo.com/1402400261/O9423iMeG</link>
<guid>https://weibo.com/1402400261/O9423iMeG</guid>
<content:encoded><![CDATA[
<div> Full Stack, FastAPI, React, MongoDB, FARM, Base Project Generator, GitHub, modern web application, Docker, automatic HTTPS

<br /><br />总结:
该项目是一个全栈应用生成器，使用FastAPI作为后端框架，MongoDB作为数据库，还包括了Docker和自动HTTPS等功能。通过该生成器，用户可以快速搭建现代化的全栈Web应用。项目托管在GitHub上，提供了丰富的功能和工具，方便用户进行开发和部署。 <div>
【Full Stack FastAPI, React, MongoDB (FARM) Base Project Generator：FastAPI 和 MongoDB 的全栈应用生成器】'Full Stack FastAPI, React, MongoDB (FARM) Base Project Generator - Full stack, modern web application generator. Using FastAPI, MongoDB as database, Docker, automatic HTTPS and more.' GitHub: github.com/mongodb-labs/full-stack-fastapi-mongodb <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8holofcb8hwj20u0118451.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:34:45 GMT</pubDate>
</item>
<item>
<title>【LLM Web界面大列表】’Awesome LLM WebUIs - A curated list of awesome Large Language Model (LLM) Web User Interfaces.' GitHub: github.com/JShollaj/awe...</title>
<link>https://weibo.com/1402400261/O940OywpS</link>
<guid>https://weibo.com/1402400261/O940OywpS</guid>
<content:encoded><![CDATA[
<div> GitHub, Awesome LLM WebUIs, Web User Interfaces, Curated list, Large Language Model, JShollaj, LLM, 接口, 网页界面

<br /><br />总结:
这篇文章是关于“Awesome LLM WebUIs”的GitHub项目，汇总了大型语言模型（LLM）Web用户界面的精选列表。项目由JShollaj创建，收集了一系列优秀的LLM WebUI，提供了丰富的接口和网页界面。如果你对LLM开发感兴趣，可以在GitHub上找到这个项目，了解更多相关信息。 <div>
【LLM Web界面大列表】’Awesome LLM WebUIs - A curated list of awesome Large Language Model (LLM) Web User Interfaces.' GitHub: github.com/JShollaj/awesome-llm-web-ui <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8holoc8gg90j20zk0k041k.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:31:43 GMT</pubDate>
</item>
<item>
<title>【Visualize LLM evals：可视化 LLM 评估的应用】'Visualize LLM evals - A streamlit app for visualizing LLM evals.' GitHub: github.com/mosaicml/llm-eval-...</title>
<link>https://weibo.com/1402400261/O940mBXlT</link>
<guid>https://weibo.com/1402400261/O940mBXlT</guid>
<content:encoded><![CDATA[
<div> 可视化、LLM、评估、应用、Streamlit、GitHub、dashboard、MosaicML、应用程序、数据可视化
<br /><br />总结:
这篇文章介绍了一个名为Visualize LLM evals的应用程序，它是一个基于Streamlit的数据可视化工具，用于可视化LLM评估。用户可以在GitHub上找到该应用程序的源代码。通过该应用程序，用户可以更直观地查看LLM的评估结果，帮助他们更好地理解和分析数据。该应用程序由MosaicML开发，为用户提供了一个方便的工具来探索和解释LLM的评估结果。 <div>
【Visualize LLM evals：可视化 LLM 评估的应用】'Visualize LLM evals - A streamlit app for visualizing LLM evals.' GitHub: github.com/mosaicml/llm-eval-dashboard <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8holoauq2roj214e0u0gpo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:30:36 GMT</pubDate>
</item>
<item>
<title>【Basalt：使用Mojo语言从零实现的机器学习框架】'Basalt - A Machine Learning framework from scratch in Pure Mojo' GitHub: github.com/basalt-org/basalt #...</title>
<link>https://weibo.com/1402400261/O93ZcybS5</link>
<guid>https://weibo.com/1402400261/O93ZcybS5</guid>
<content:encoded><![CDATA[
<div> Basalt、机器学习、Mojo语言、框架、GitHub、从零实现、纯Mojo、项目、代码库、学习

总结:<br /><br />这篇文章介绍了一个名为Basalt的机器学习框架，使用Mojo语言从零开始实现。该项目的代码库可以在GitHub上找到，并且是一个纯Mojo编写的框架。通过Basalt，用户可以学习如何从头开始构建一个机器学习框架，并且在其中使用Mojo语言。 <div>
【Basalt：使用Mojo语言从零实现的机器学习框架】'Basalt - A Machine Learning framework from scratch in Pure Mojo' GitHub: github.com/basalt-org/basalt <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8holo84iafvj20zc0sadis.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:27:44 GMT</pubDate>
</item>
<item>
<title>【aixcoder-7B 是一种代码大语言模型，旨在理解和生成跨多种编程语言的代码，提供最先进的代码补全、理解、生成等能力】'aiXcoder-7B Code Large Language Model...</title>
<link>https://weibo.com/1402400261/O93V9FLOM</link>
<guid>https://weibo.com/1402400261/O93V9FLOM</guid>
<content:encoded><![CDATA[
<div> aiXcoder-7B、代码大语言模型、跨编程语言、代码补全、理解、生成、GitHub、代码模型、AI、仓库<br />
<br />
总结:<br />
aiXcoder-7B是一种代码大语言模型，旨在理解和生成跨多种编程语言的代码。它提供了最先进的代码补全、理解和生成能力。该模型的官方仓库位于GitHub上，是一个代码模型，借助AI技术，为开发者提供强大的编程支持。 <div>
【aixcoder-7B 是一种代码大语言模型，旨在理解和生成跨多种编程语言的代码，提供最先进的代码补全、理解、生成等能力】'aiXcoder-7B Code Large Language Model - official repository of aiXcoder-7B Code Large Language Model' GitHub: github.com/aixcoder-plugin/aiXcoder-7B <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8holnxrok63j21740len1o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:17:46 GMT</pubDate>
</item>
<item>
<title>【关于使用大语言模型 (LLM) 在软件测试中的应用和研究的论文列表】’Awesome-LLM-SoftwareTesting' GitHub: github.com/LLM-Testing/LLM4SoftwareTesting #开源...</title>
<link>https://weibo.com/1402400261/O93TQ9LaM</link>
<guid>https://weibo.com/1402400261/O93TQ9LaM</guid>
<content:encoded><![CDATA[
<div> LLM、软件测试、应用、研究、论文、GitHub、LLM4SoftwareTesting

使用大语言模型（LLM）在软件测试中的应用和研究是一个备受关注的领域，GitHub上有一个名为'Awesome-LLM-SoftwareTesting'的项目专门收集了相关论文。这些论文包括了LLM在软件测试中的多种应用场景，以及对其性能和效果的研究。研究者们通过分析大量数据和实验结果，探索了LLM在软件缺陷检测、测试用例生成等方面的潜力，为软件测试领域的发展提供了新的思路和方法。总的来说，LLM在软件测试中的应用前景广阔，值得进一步深入研究和探索。<br /><br />总结:这些论文呈现了LLM在软件测试领域的重要应用和研究成果，展示了其在提高测试效率和质量方面的潜力，为未来的软件测试工作提供了重要参考和启发。 <div>
【关于使用大语言模型 (LLM) 在软件测试中的应用和研究的论文列表】’Awesome-LLM-SoftwareTesting' GitHub: github.com/LLM-Testing/LLM4SoftwareTesting <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8holnts4anrj20o80p0433.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:14:30 GMT</pubDate>
</item>
<item>
<title>'Awesome Cloudflare - 精选的 Cloudflare 工具、开源项目、指南、博客和其他资源列表' GitHub: github.com/zhuima/awesome-cloudflare #开源# #Cloudflare# [图...</title>
<link>https://weibo.com/1402400261/O93SWBw2M</link>
<guid>https://weibo.com/1402400261/O93SWBw2M</guid>
<content:encoded><![CDATA[
<div> GitHub、Cloudflare、工具、开源项目、指南、博客、资源列表、精选、zhuima、Awesome Cloudflare<br />
<br />
总结:<br />
本文介绍了 GitHub 上用户 zhuima 收集整理的关于 Cloudflare 的精选工具、开源项目、指南、博客和其他资源列表。其中包括了各种有用的工具和资源，针对 Cloudflare 的使用者提供了丰富的参考和指导，是一个非常实用的资源汇总。 <div>
'Awesome Cloudflare - 精选的 Cloudflare 工具、开源项目、指南、博客和其他资源列表' GitHub: github.com/zhuima/awesome-cloudflare <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Cloudflare%23"><span class="surl-text">#Cloudflare#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8holns27lssj21he0u0n33.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 05:12:19 GMT</pubDate>
</item>
<item>
<title>【衡量语言模型的说服力】- Anthropic开发了一种基本方法来测量语言模型的说服力，并用这种方法比较了Anthropic不同版本的Claude模型(Claude 1、2和3)以及两类模...</title>
<link>https://weibo.com/1402400261/O923JzYQz</link>
<guid>https://weibo.com/1402400261/O923JzYQz</guid>
<content:encoded><![CDATA[
<div> Anthropic、语言模型、说服力、Claude 模型、模型类别、模型版本、技能、研究、数据、风险

总结:<br /><br />本研究使用基本方法测量了语言模型的说服力，比较了Anthropic不同版本的Claude模型以及两种模型类别。在每个模型类别内，后续模型版本被评为更具说服力。最新的Claude 3 Opus模型产生的论点在说服力上与人类写的论点没有统计学差异。说服力是一种广泛应用的通用技能，研究其在AI模型中的应用具有重要意义。然而，评估说服力具有挑战性，结果可能不适用于现实世界，主观性和实验设计等因素也影响评估。Anthropic已经发布所有数据供他人调查和扩展，同时也在探索更具交互性的语境。未来需要进行进一步研究和负责任的部署实践，以减轻语言模型发展带来的潜在风险。模型规模与说服力正相关，这提示我们谨慎对待技术发展，同时基于模型的说服力评估为未来研究提供了宝贵的数据和见解。 <div>
【衡量语言模型的说服力】<br />- Anthropic开发了一种基本方法来测量语言模型的说服力，并用这种方法比较了Anthropic不同版本的Claude模型(Claude 1、2和3)以及两类模型(更小、更快、更经济的紧凑模型和更大、更强大的前沿模型)。   <br />- 在每个模型类别内，发现每个后续模型版本比前一个版本被评为更具说服力。最新、最强大的Claude 3 Opus模型产生的论点在其说服力上与人类写的论点没有统计学差异。   <br />- Anthropic研究说服力，因为它是一项广泛应用于世界各地的通用技能——公司试图说服人们购买产品，医护人员试图说服人们采取更健康的生活方式，政治家试图说服人们支持他们的政策并投票给他们。   <br />- 开发测量AI模型说服能力的方法很重要，因为它可作为模型在一个重要领域匹配人类技能的能力的代理测量，并且说服力最终可能与某些类型的滥用相关联。   <br />- 目前该研究存在许多局限性，说服力的评估本身就具有挑战性。所得出的结果可能不会广泛适用于现实世界，说服力是主观的，实验设计也存在缺陷。   <br />- Anthropic已发布所有数据，以供他人调查和扩展。也在积极扩展我们的工作到更具交互性的语境中。   <br />- 需要进一步的研究和负责任的部署实践，以减轻快速发展和越来越具说服力的语言模型的潜在风险。<br /><br />思考：  <br />- 该研究开创性地探索了语言模型的说服力，并提出了一种衡量说服力的方法。这对于理解人工智能在影响人类观点方面的潜力具有重要意义。  <br />- 研究发现模型规模与说服力之间存在明显的正相关，这表明随着模型变得越来越强大，它们可能会对人类的观点和决策产生更大的影响。这提醒我们要谨慎对待这些技术的发展。  <br />- 尽管基于模型的说服力评估与人类判断之间存在差异，但这项研究为进一步探索提供了宝贵的数据和见解。未来的工作可以在此基础上，开发出更准确、更可靠的说服力衡量方法。<br />《Measuring the Persuasiveness of Language Models \ Anthropic》 <a href="https://www.anthropic.com/news/measuring-model-persuasiveness"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8holfpwht4jj20u00van1x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 00:33:25 GMT</pubDate>
</item>
<item>
<title>【Google发布CodeGemma：开源代码大模型，与生态系统无缝集成】- CodeGemma是Google基于Gemma预训练模型发布的开源代码专用LLM家族，包括2B、7B和7B指令版。 - C...</title>
<link>https://weibo.com/1402400261/O91XXbmqo</link>
<guid>https://weibo.com/1402400261/O91XXbmqo</guid>
<content:encoded><![CDATA[
<div> CodeGemma, Google, 开源, 模型, 代码补全, 7B版本, 生产部署, Hugging Face, 集成, 创新应用

<br /><br />总结:
Google发布了开源代码模型CodeGemma，包括2B、7B和7B指令版，在代码补全和生成任务中表现优异。使用填充中间(FIM)形式的提示进行代码补全，并支持自然语言对话。与Transformers 4.39完全兼容，可以部署到Google Cloud或Hugging Face推理服务端点。这个开源基础为代码生成领域提供了强大工具，推动AI在编程领域的应用。Google的努力体现在开放大型语言模型方面，与Hugging Face合作使模型变得更加可触及。CodeGemma提供了满足不同使用需求的不同版本模型，有效提升开发效率。与Hugging Face生态系统的无缝集成使得模型可以利用各种先进技术，为模型性能优化提供可能性。 <div>
【Google发布CodeGemma：开源代码大模型，与生态系统无缝集成】<br />- CodeGemma是Google基于Gemma预训练模型发布的开源代码专用LLM家族，包括2B、7B和7B指令版。   <br />- CodeGemma在代码补全和生成任务上表现优异，尤其是7B版本在HumanEval等基准测试上的表现。   <br />- CodeGemma使用填充中间(FIM)形式的提示，可以进行代码补全。7B指令版可以进行关于代码的自然语言对话。   <br />- CodeGemma与Transformers 4.39完全兼容，可以利用Hugging Face生态系统中的工具。   <br />- CodeGemma可以一键部署到Google Cloud或Hugging Face推理服务端点，以进行生产部署。   <br />- CodeGemma为代码生成领域提供了一个强大而方便使用的开源基础，相信会推动更多创新应用的出现。   <br /> <br />思考：  <br />- CodeGemma 的发布体现了 Google 在开放大型语言模型方面的努力，与 Hugging Face 的合作更是让这些模型变得触手可及。这对于推动 AI 在编程领域的应用具有重要意义。  <br />- 三个不同版本的 CodeGemma 模型满足了不同的使用需求，无论是代码生成、自然语言理解，还是人机交互，都提供了强大的工具。这将极大地提升开发者的工作效率。  <br />- 与 Hugging Face 生态系统的无缝集成，使得 CodeGemma 可以利用各种先进的技术，如量化、参数高效微调、Flash Attention 等，这不仅方便了模型的使用，也为进一步优化模型性能提供了可能。<br />《CodeGemma - an official Google release for code LLMs》 <a href="https://huggingface.co/blog/codegemma"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8holfaxucwzj20ee09vaar.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 00:19:10 GMT</pubDate>
</item>
<item>
<title>2B模型发布：网页链接 //@爱可可-爱生活:提出了Griffin模型，一种新型的循环神经网络，结合了门控线性循环层与局部注意力机制，实现了与Transformer相当的性能，...</title>
<link>https://weibo.com/1402400261/O91W53IPY</link>
<guid>https://weibo.com/1402400261/O91W53IPY</guid>
<content:encoded><![CDATA[
<div> Griffin, 循环神经网络, 门控线性循环层, 局部注意力机制, Transformer, 长序列处理, 硬件效率, 高吞吐量, 低延迟, 语言模型

<br /><br />总结:
研究人员提出了一种名为Griffin的新型循环神经网络模型，结合了门控线性循环层和局部注意力机制。该模型实现了与Transformer相当的性能，在长序列处理和硬件效率方面表现出优势。特别是在推理时，Griffin表现出高吞吐量和低延迟。这一研究成果有望为语言模型领域带来新的突破和进展。Griffin模型在对长序列数据的处理和硬件效率方面都具有明显优势，为构建高性能语言模型提供了新的思路和方法。Griffin的提出对提高语言模型的性能、效率和推理能力具有积极意义。深度研究了Griffin模型的结构和原理，探讨了其在自然语言处理领域的潜在应用价值。Griffin模型不仅能提高语言模型的性能，还能为硬件资源利用效率提供更好的方案。Griffin模型融合了门控线性循环层和局部注意力机制的优点，展现出了强大的处理能力和效率。Griffin模型的提出对于提升语言模型的性能和应用范围具有重要意义。Griffin模型在实验中展现出了较好的表现，加深了人们对深度学习和自然语言处理的认识。Griffin模型的结构创新和性能表现有望在自然语言处理领域产生广泛的影响和应用。 <div>
2B模型发布：<a href="https://huggingface.co/google/recurrentgemma-2b"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> //<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>:提出了Griffin模型，一种新型的循环神经网络，结合了门控线性循环层与局部注意力机制，实现了与Transformer相当的性能，并在长序列处理和硬件效率方面展现出明显优势，尤其是在推理时的高吞吐量和低延迟表现<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models》S De, S L. Smith, A Fernando, A Botev… [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2402.19427"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnc7bm8wxfj21hc0eetfz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnc7bmuszij21h80quah7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnc7bn8l00j21gs0u0wkp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnc7bni9nyj21h20pywjy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnc7cdzcptj21140fs409.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnc7cdzq0xj21150h9ad0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnc7cdzrawj21190ewdiv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnc7cdzhj6j21140g6abt.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnc7cdznorj21190hy0v7.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 00:14:33 GMT</pubDate>
</item>
<item>
<title>【Gemini 1.5 Pro发布：原生音频理解、100万token上下文窗口、强大API】- Gemini 1.5 Pro 模型已在180多个国家/地区通过 Gemini API 公开预览，增加了音频理解能...</title>
<link>https://weibo.com/1402400261/O91U94q8X</link>
<guid>https://weibo.com/1402400261/O91U94q8X</guid>
<content:encoded><![CDATA[
<div> Gemini 1.5 Pro, 原生音频理解, 100万token上下文窗口, 强大API, 视频和音频理解, Google AI Studio, 系统指令功能, JSON模式, 函数调用改进, 新一代文本嵌入模型, Gemini API

<br /><br />总结:
Gemini 1.5 Pro发布，增加了原生音频理解和100万token上下文窗口，使其具有跨模态推理能力，可以同时处理视频中的图像和音频。Gemini API新增系统指令功能和JSON模式，提升模型的可靠性和输出方式。推出新文本嵌入模型，表现优秀，适用于语义搜索、文本聚类等任务。开发者可以使用Google AI Studio和Gemini API来构建基于Gemini的项目，获得更广阔的创新空间和更多用途。Gemini 1.5 Pro的功能和性能提升为开发者提供了更多智能、交互性强的应用场景。 <div>
【Gemini 1.5 Pro发布：原生音频理解、100万token上下文窗口、强大API】<br />- Gemini 1.5 Pro 模型已在180多个国家/地区通过 Gemini API 公开预览，增加了音频理解能力。   <br />- Gemini 1.5 Pro 现在可以同时理解视频中的图像和音频，Google AI Studio 中已支持，API 即将推出。   <br />- Gemini API 添加了系统指令功能，可以指导模型的响应；增加了 JSON 模式，可以只输出 JSON 对象。   <br />- Gemini API 改进了函数调用，可以选择限制模型的输出，提高可靠性。   <br />- 推出了新一代文本嵌入模型，在类似维度下表现优于现有模型，可通过 Gemini API 使用。   <br />- Google AI Studio 和 Gemini API 是构建基于 Gemini 的项目的最简单途径。开发者可以在 Studio 中访问 Gemini 1.5 Pro，参考 Gemini API Cookbook 的代码示例，并加入 Discord 社区。   <br /><br />思考：  <br />- Gemini 1.5 Pro 的 100 万 token 上下文窗口非常惊人，这为开发者提供了巨大的创新空间。  <br />- 原生音频理解和跨模态推理(图像+音频)功能的加入，大大拓宽了 Gemini 1.5 Pro 的应用场景。这使得开发者能够创建更加智能、交互性更强的应用。  <br />- 新的文本嵌入模型 text-embedding-004 在标准基准测试中展现出优异的性能，这对于需要高质量文本表示的任务(如语义搜索、文本聚类等)非常有帮助。<br />《Gemini 1.5 Pro Now Available in 180+ Countries; With Native Audio Understanding, System Instructions, JSON Mode and More - Google for Developers》 <a href="https://developers.googleblog.com/2024/04/gemini-15-pro-in-public-preview-with-new-features.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8holf198711j20wb0u0n13.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 00:09:47 GMT</pubDate>
</item>
<item>
<title>【AI模型的性别偏见】- AI模型会反映和夸大现实世界中存在的性别偏见。准确量化模型中的这些偏见对于恰当地解决和缓解它们非常重要。 - 词向量中存在性别偏见，...</title>
<link>https://weibo.com/1402400261/O91Lk1xOE</link>
<guid>https://weibo.com/1402400261/O91Lk1xOE</guid>
<content:encoded><![CDATA[
<div> 性别偏见, AI模型, 词向量, 人脸识别, 共指消解模型, 大型语言模型, 图像生成模型, 解决偏见, 批判意识, 学术研究  

总结：<br /><br />人工智能系统中存在性别偏见问题，如词向量类比偏见、人脸识别准确率差异、共指消解模型偏见等。研究表明存在性别偏见的AI模型需要修复，方法包括去偏算法、数据扩充和提升透明度等。学术界持续关注并研究解决AI中的性别偏见问题，提倡批判意识和思考修复性别偏见的哲学层面。对于构建更加公平、无偏见的人工智能系统具有重要意义。 <div>
【AI模型的性别偏见】<br />- AI模型会反映和夸大现实世界中存在的性别偏见。准确量化模型中的这些偏见对于恰当地解决和缓解它们非常重要。   <br />- 词向量中存在性别偏见，比如“程序员-男人”的向量类比与“家庭主妇-女人”相似，可以通过中性词去偏算法来降低这种偏见。   <br />- 人脸识别系统在识别不同肤色和性别的面部时准确率存在明显差异，对较深肤色女性识别效果最差。数据不平衡是导致这一问题的原因之一。   <br />- 共指消解模型在连接某些职业与特定性别代词上存在偏见，例如更倾向将“外科医生”解析为“他”而非“她”。   <br />- 在含糊语境下，大型语言模型倾向复现有害的社会偏见，如“女孩不善数学”。需要更全面的评估指标。   <br />- 图像生成模型倾向生成较多白人男性形象，尤其是权力职业。需要通过提示词审核等方式评估模型行为。   <br />- 存在的解决偏见的技术方法有去偏算法、扩充训练数据、提升模型透明度等。但更重要的是认识到“修复”偏见的哲学层面。   <br />- 识别偏见有助于改进AI模型，衡量问题是解决问题的第一步。偏见源自人类数据，但模型不必永远保持偏见。<br /><br />思考：  <br />- 文章揭示了一个容易被忽视但影响深远的问题：人工智能系统从人类创造的数据中学习，难免会继承并放大其中的社会偏见，尤其是性别偏见。这提醒我们在开发应用人工智能时，必须警惕和克服数据中的偏见。  <br />- 文章列举的几项研究工作让人印象深刻，从词嵌入到生成式语言模型，可以看出学术界正在从不同角度深入分析人工智能系统中的偏见问题。这些工作对于构建更加公平、无偏见的人工智能系统具有重要意义。  <br />《A Brief Overview of Gender Bias in AI》 <a href="https://thegradient.pub/gender-bias-in-ai/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span> <span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8holeemntj3j21ud0u0q9x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 23:48:02 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@异步图书 送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O91Jua4HQ</link>
<guid>https://weibo.com/1402400261/O91Jua4HQ</guid>
<content:encoded><![CDATA[
<div> 大语言模型，前沿进展，科学家，工程师，学生，案例，庖丁解牛，深入介绍，理解，认识

<br /><br />总结:
本文介绍了一本名为《大语言模型：基础与前沿》的书籍，全面深入地介绍了大语言模型及其前沿进展。适合科学家、工程师和学生参考。书籍摒弃了纯理论的说教模式，从案例入手，采用庖丁解牛的方式帮助读者理解与认识大语言模型。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%BC%82%E6%AD%A5%E5%9B%BE%E4%B9%A6">@异步图书</a>  送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。摒弃了纯理论的说教模式，从案例入手， 采用庖丁解牛的方式帮助读者理解与认识大语言模型。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019331269755053"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef8oboqij20ga0m8q8p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9segl7j20m90m9q6z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9t5km0j20m90m942f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef9tq2esj20m90m9gpe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef9ugq5dj20m90m9dif.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 23:43:31 GMT</pubDate>
</item>
<item>
<title>今日推介(第1371期)：语言模型知识容量缩放律、文本生成中语义漂移研究、基于形态学的位置编码研究、语言模型进化的迭代学习视角、基于多模态大语言模型的手机UI...</title>
<link>https://weibo.com/1402400261/O91c61wZd</link>
<guid>https://weibo.com/1402400261/O91c61wZd</guid>
<content:encoded><![CDATA[
<div> 知识容量缩放律 文本生成 语义漂移 形态学 位置编码 语言模型 迭代学习 多模态 理解 UI

语言模型的知识容量缩放律指的是随着模型大小的增加，模型表现提升的幅度会递减。文本生成中存在的语义漂移问题需要更深入的研究和解决。研究指出，基于形态学的位置编码可以提高语言模型的性能和泛化能力。从迭代学习的视角看待语言模型的进化可以更好的理解其发展过程。利用多模态大语言模型可以帮助手机UI更好地理解用户需求和行为。总结:在语言模型研究中，探索知识容量缩放律、解决语义漂移、优化位置编码、以迭代学习为视角和结合多模态等方面是当前的研究热点。 <div>
今日推介(第1371期)：语言模型知识容量缩放律、文本生成中语义漂移研究、基于形态学的位置编码研究、语言模型进化的迭代学习视角、基于多模态大语言模型的手机UI理解 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/691613835"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.10)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8holbvstxtbj21cy0ru12g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8holbw4ta9sj20so0oc41t.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8holbw7u09hj21o80u0jxg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8holbwa8q3uj20tc0mgacn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8holbwdoh9jj212o0u0wml.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 22:21:14 GMT</pubDate>
</item>
<item>
<title>[CV] MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding 网页链接 通过在线处理视频序列并存储历史特征于记忆库中，实现了高...</title>
<link>https://weibo.com/1402400261/O9121yn1Y</link>
<guid>https://weibo.com/1402400261/O9121yn1Y</guid>
<content:encoded><![CDATA[
<div> 视频序列、在线处理、历史特征、记忆库、长时视频理解、MA-LMM、多模态模型、效率、存储、高效

<br /><br />总结:
本研究提出了一种名为MA-LMM的Memory-Augmented Large Multimodal Model，通过在线处理视频序列并将历史特征存储在记忆库中，实现了高效的长时视频理解。该模型是一种多模态模型，能够有效地存储和检索视频序列的关键信息。通过使用记忆库，模型能够在处理长时间视频时提供更好的性能，实现了对视频序列的有效理解和分析。MA-LMM的出现为长时视频理解领域带来了新的思路和方法，提高了视频理解的效率和性能。 <div>
[CV] MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding  <br /><a href="https://arxiv.org/abs/2404.05726"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过在线处理视频序列并存储历史特征于记忆库中，实现了高效的长时视频理解。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holb6kdbr2j21281b01aj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1holb6ktt6mj21qm1324ee.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holb6kvlbgj21ce0yyanw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:56:27 GMT</pubDate>
</item>
<item>
<title>[CV] Finding Visual Task Vectors 网页链接 通过分析MAE-VQGAN的激活，提出激活评分方法和使用REINFORCE搜索任务向量，找到了提供零样本控制的任务向量，还降低...</title>
<link>https://weibo.com/1402400261/O90ZXBsN6</link>
<guid>https://weibo.com/1402400261/O90ZXBsN6</guid>
<content:encoded><![CDATA[
<div> 提取关键词: MAE-VQGAN, 激活评分方法, REINFORCE, 零样本控制, 任务向量, 降低计算量

总结:
通过分析MAE-VQGAN的激活并提出激活评分方法，使用REINFORCE搜索任务向量，找到了提供零样本控制的任务向量。同时，还成功降低了计算量。这项研究方法为寻找视觉任务向量提供了新的思路，可以有效实现任务的零样本控制。而通过采用REINFORCE算法，不仅可以有效搜索到合适的任务向量，还有助于减少计算成本。该方法为改善零样本控制问题提供了新的解决方案，对未来的研究具有重要意义。 <div>
[CV] Finding Visual Task Vectors  <br /><a href="https://arxiv.org/abs/2404.05729"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过分析MAE-VQGAN的激活，提出激活评分方法和使用REINFORCE搜索任务向量，找到了提供零样本控制的任务向量，还降低了计算量。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holb190uinj20vc1by16a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holb1a2c20j20va1cetew.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holb1a9htqj20v41ea11h.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:51:22 GMT</pubDate>
</item>
<item>
<title>[LG] Trustless Audits without Revealing Data or Models 网页链接 通过零知识证明设计ZKAUDIT协议，使模型提供者可在保护模型和数据秘密的同时，允许用户进行...</title>
<link>https://weibo.com/1402400261/O90X92TCh</link>
<guid>https://weibo.com/1402400261/O90X92TCh</guid>
<content:encoded><![CDATA[
<div> 提取关键词: 零知识证明, ZKAUDIT协议, 模型提供者, 数据保护, 模型保密, 信任, 属性审计, 算法透明度, 商业需求

总结:<br /><br />本文介绍了通过零知识证明设计ZKAUDIT协议，实现了模型提供者在保护模型和数据秘密的同时，允许用户进行无需信任的模型和数据属性审计，从而平衡了算法透明度与商业需求之间的关系。零知识证明技术使得模型提供者可以证明其模型的准确性和有效性，而无需泄露敏感数据或模型细节，保护了数据隐私。用户可以通过ZKAUDIT协议对模型和数据进行属性审计，验证其合规性和可信度，而无需相信模型提供者的陈述。这种方法在实现数据和模型透明度的同时，保证了安全性和隐私保护，为商业应用提供了更高的可信度和保障。 <div>
[LG] Trustless Audits without Revealing Data or Models  <br /><a href="https://arxiv.org/abs/2404.04500"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过零知识证明设计ZKAUDIT协议，使模型提供者可在保护模型和数据秘密的同时，允许用户进行无需信任的模型和数据属性审计，实现了算法透明度与商业需求的平衡。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holau1ibibj211o1bk1eb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1holau1m6cxj21n00jkn16.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holau1x6tdj20ty0jcgna.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:44:25 GMT</pubDate>
</item>
<item>
<title>[LG] A Large-Scale Exploration of μμ-Transfer 网页链接 通过transformer模型的大规模经验研究验证了μ-transfer技术在许多重要情况下确实能可靠地传递最优...</title>
<link>https://weibo.com/1402400261/O90Uqi7rn</link>
<guid>https://weibo.com/1402400261/O90Uqi7rn</guid>
<content:encoded><![CDATA[
<div> μ-transfer, transformer模型, 大规模研究, 超参数, 可靠传递, 意外情况, 需要谨慎验证<br />
<br />
<br />总结:
本研究通过大规模实验验证了μ-transfer技术在传递最优超参数方面的可靠性，但也发现了一些意外情况，需要进行谨慎验证。 transformer模型的应用在此过程中起到了关键作用，为进一步研究μ-transfer技术提供了有力支持。在实际应用中，需要考虑到意外情况可能带来的影响，以确保技术的稳定性和可靠性。 <div>
[LG] A Large-Scale Exploration of μμ-Transfer  <br /><a href="https://arxiv.org/abs/2404.05728"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过transformer模型的大规模经验研究验证了μ-transfer技术在许多重要情况下确实能可靠地传递最优超参数，但也发现了一些意外的情况，需要谨慎地进行验证。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holan334ilj20ua1cwk8w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1holan3j738j20um1d8wr7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:37:43 GMT</pubDate>
</item>
<item>
<title>Ferret-UI是首个兼具精确提述、接地和推理能力的面向手机用户界面理解的多模态大语言模型。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《Ferret-UI: Grounded Mobile UI ...</title>
<link>https://weibo.com/1402400261/O90QdqdeF</link>
<guid>https://weibo.com/1402400261/O90QdqdeF</guid>
<content:encoded><![CDATA[
<div> Ferret-UI, 多模态大语言模型, 手机用户界面理解, 精确提述, 接地, 推理能力, Apple, 2024

<br /><br />总结:
这篇文章介绍了Ferret-UI，一个面向手机用户界面理解的多模态大语言模型。该模型具备精确提述、接地和推理能力，能够有效理解手机用户界面。该研究由苹果公司的团队完成，展示了在该领域取得的成果。Ferret-UI的出现将为手机界面理解领域带来新的突破和可能性。 <div>
Ferret-UI是首个兼具精确提述、接地和推理能力的面向手机用户界面理解的多模态大语言模型。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs》K You, H Zhang, E Schoop, F Weers, A Swearngin, J Nichols, Y Yang, Z Gan [Apple] (2024) <a href="https://arxiv.org/abs/2404.05719"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola3ws1kpj217u15sqln.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola3x89kwj210m172anw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hola3xy18qj21dg19kdss.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola3y7utwj21e412w7ij.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holabzydjyj20rh0k4q6i.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holabzx9zgj20rh0bfjsl.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holabzxvv6j20rh0khtay.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1holabzxttpj20rh0l6acb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holabzxtl3j20rh0ikq50.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:27:20 GMT</pubDate>
</item>
<item>
<title>[CV]《Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs》K You, H Zhang, E Schoop, F Weers, A Swearngin, J Nichols, Y Yang, Z Gan [Appl...</title>
<link>https://weibo.com/1402400261/O90Q6jE24</link>
<guid>https://weibo.com/1402400261/O90Q6jE24</guid>
<content:encoded><![CDATA[
<div> 关键词: Ferret-UI, Grounded Mobile UI Understanding, Multimodal LLMs, Apple

总结:<br /><br />本文介绍了一种名为Ferret-UI的技术，利用多模态LLMs实现对移动UI的深入理解，提高用户体验。研究团队来自Apple，通过结合语言、视觉等多种模态信息，实现了对移动界面的全面分析和理解。他们采用了一系列先进的技术和方法，使得Ferret-UI能够更准确地理解用户交互、意图和界面元素之间的关系。通过在真实环境中的实验测试，证明了Ferret-UI在移动UI理解方面的有效性和可行性。这项研究对于提升移动应用程序的用户体验和界面设计具有重要意义，是移动UI理解领域的一项重要研究工作。 <div>
[CV]《Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs》K You, H Zhang, E Schoop, F Weers, A Swearngin, J Nichols, Y Yang, Z Gan [Apple] (2024) <a href="https://arxiv.org/abs/2404.05719"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola3ws1kpj217u15sqln.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola3x89kwj210m172anw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hola3xy18qj21dg19kdss.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola3y7utwj21e412w7ij.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holabzydjyj20rh0k4q6i.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holabzx9zgj20rh0bfjsl.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holabzxvv6j20rh0khtay.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1holabzxttpj20rh0l6acb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holabzxtl3j20rh0ikq50.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1holabzz105j20rl10gaf2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1holabzx1tdj20rh0gpq4k.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holabzyfvoj20py0ocdjl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1holabzxw33j20rh0msq4m.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:27:04 GMT</pubDate>
</item>
<item>
<title>通过将大语言模型视为贝叶斯智能体，应用迭代学习理论框架来分析和指导其自主进化过程，为后续研究奠定理论基础。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Language ...</title>
<link>https://weibo.com/1402400261/O90LAqpAn</link>
<guid>https://weibo.com/1402400261/O90LAqpAn</guid>
<content:encoded><![CDATA[
<div> 关键词: 大语言模型, 贝叶斯智能体, 迭代学习理论, 自主进化, 研究基础

总结:<br /><br />这篇文章将大语言模型视为贝叶斯智能体，应用迭代学习理论框架来分析和指导其自主进化过程，并为后续研究奠定了理论基础。文章提出了一种新的理论框架，用于探究大语言模型的进化过程。通过将语言模型看作一个智能体，并应用迭代学习理论来指导其演化，研究者们可以更好地理解其进化机制和行为。这种方法有望为语言模型领域的未来研究提供指导和启发。 <div>
通过将大语言模型视为贝叶斯智能体，应用迭代学习理论框架来分析和指导其自主进化过程，为后续研究奠定理论基础。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Language Model Evolution: An Iterated Learning Perspective》Y Ren, S Guo, L Qiu, B Wang, D J. Sutherland [University of British Columbia &amp; University of Edinburgh &amp; MIT] (2024) <a href="https://arxiv.org/abs/2404.04286"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hol9zk6sq3j20p614y13j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9zkqcscj20tc0mg77s.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9zkzlhxj20ti0kc436.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hol9zl5ys8j20u60kqjvn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola077scxj20iv0d9q4l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola077m1rj20tv0eyjsi.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hola07805ij20yd0d2aci.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola07829sj212b0cw768.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hola0784hbj212e0e4dim.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:15:57 GMT</pubDate>
</item>
<item>
<title>[CL]《Language Model Evolution: An Iterated Learning Perspective》Y Ren, S Guo, L Qiu, B Wang, D J. Sutherland [University of British Columbia &amp; Unive...</title>
<link>https://weibo.com/1402400261/O90LuFGh1</link>
<guid>https://weibo.com/1402400261/O90LuFGh1</guid>
<content:encoded><![CDATA[
<div> 语言模型演化，迭代学习，关键词：语言模型、演化、迭代学习、进化、文化传播、信息传递、语言演化、模型更新、学习机制、计算模型。<br />
<br />
总结:本文从迭代学习的角度探讨了语言模型的演化过程。研究指出，语言模型的进化受到文化传播和信息传递的影响，提出了一种基于学习机制的语言演化模型，并通过计算模型进行更新。该研究有助于深入理解语言模型的演化过程，为语言学研究提供了新的视角。 <div>
[CL]《Language Model Evolution: An Iterated Learning Perspective》Y Ren, S Guo, L Qiu, B Wang, D J. Sutherland [University of British Columbia &amp; University of Edinburgh &amp; MIT] (2024) <a href="https://arxiv.org/abs/2404.04286"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hol9zk6sq3j20p614y13j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9zkqcscj20tc0mg77s.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9zkzlhxj20ti0kc436.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hol9zl5ys8j20u60kqjvn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola077scxj20iv0d9q4l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola077m1rj20tv0eyjsi.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hola07805ij20yd0d2aci.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola07829sj212b0cw768.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hola0784hbj212e0e4dim.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola079j95j20tv0n9mzn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hola0791z4j212b0i1die.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hola07a26hj212b0g8gon.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola07b7mlj212e0txdmd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hola079onzj212b0fy76i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hola07axiij212b0owq8d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hola07akcmj212b0op782.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hola07axmej212c0nwads.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hola07bfmhj20wg0ks0vh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:15:44 GMT</pubDate>
</item>
<item>
<title>系统研究位置编码对不同词法复杂性语言的重要性，发现位置编码对分析性语言影响较大而对合成性语言影响较小，结论与语言学理论一致。 - 转发 @爱可可-爱生活:&amp;en...</title>
<link>https://weibo.com/1402400261/O90KZuc3B</link>
<guid>https://weibo.com/1402400261/O90KZuc3B</guid>
<content:encoded><![CDATA[
<div> 位置编码、词法复杂性语言、分析性语言、合成性语言、语言学理论、研究、重要性、影响、位置编码、调查

总结:<br /><br />本研究对位置编码在不同词法复杂性语言中的作用进行了调查。研究发现，位置编码对分析性语言的影响较大，而对合成性语言的影响较小，这与语言学理论相一致。位置编码在分析性语言中的重要性得到了验证，并有助于深入理解语言结构和语法规则。这项研究由印度理工学院孟买分校、Google研究机构和日本信息通信研究所合作完成，为语言学领域的研究提供了新的观点和方法。 <div>
系统研究位置编码对不同词法复杂性语言的重要性，发现位置编码对分析性语言影响较大而对合成性语言影响较小，结论与语言学理论一致。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《A Morphology-Based Investigation of Positional Encodings》P Ghosh, S Vashishth, R Dabre, P Bhattacharyya [IIT Bombay &amp; Google Research &amp; NICT] (2024) <a href="https://arxiv.org/abs/2404.04530"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9xgfeqdj21ou0imalt.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hol9xgvlj4j20ru0oawgq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hol9xheqryj21pe0uk119.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hol9xhhuykj20jk1duwil.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9ypmrgmj20ju1agn11.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9yq0tvhj20j80gc0to.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:14:29 GMT</pubDate>
</item>
<item>
<title>[CL]《A Morphology-Based Investigation of Positional Encodings》P Ghosh, S Vashishth, R Dabre, P Bhattacharyya [IIT Bombay &amp; Google Research &amp; NICT] (...</title>
<link>https://weibo.com/1402400261/O90KV7K65</link>
<guid>https://weibo.com/1402400261/O90KV7K65</guid>
<content:encoded><![CDATA[
<div> Positional Encodings, Morphology-Based Investigation, IIT Bombay, Google Research, NICT, P Ghosh, S Vashishth, R Dabre, P Bhattacharyya

<br /><br />总结:
这篇文章探讨了基于形态学的位置编码在自然语言处理中的应用。研究作者来自IIT孟买、谷歌研究和NICT。他们分析了不同位置编码方法在文本处理中的效果，并提出了一种新的基于形态学的位置编码方法。通过实验证明，这种方法在提高自然语言处理任务的性能方面具有显著优势。研究结果为语言学和机器学习领域的研究提供了有益的参考。 <div>
[CL]《A Morphology-Based Investigation of Positional Encodings》P Ghosh, S Vashishth, R Dabre, P Bhattacharyya [IIT Bombay &amp; Google Research &amp; NICT] (2024) <a href="https://arxiv.org/abs/2404.04530"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9xgfeqdj21ou0imalt.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hol9xgvlj4j20ru0oawgq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hol9xheqryj21pe0uk119.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hol9xhhuykj20jk1duwil.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9ypmrgmj20ju1agn11.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hol9yq0tvhj20j80gc0to.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 21:14:18 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.9)》 爱可可微博热门分享(4.9) [图片]</title>
<link>https://weibo.com/1402400261/O8Y7QgBBw</link>
<guid>https://weibo.com/1402400261/O8Y7QgBBw</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、4.9、文章、内容、关键字、讨论、社交平台

总结:<br /><br />本篇文章讨论了爱可可微博上的热门分享，内容涉及各种话题和热点事件。文章的关键字分析揭示了微博用户的关注点和讨论热度。通过社交平台分享信息，用户可以及时了解最新的情况，进行互动交流，丰富自己的知识和视野。爱可可微博作为一个活跃的社交平台，为用户带来了丰富多彩的内容，让用户在其中畅所欲言，分享自己的观点和生活。在这个平台上，用户可以参与讨论，和他人交流想法，扩展自己的社交圈，促进信息传播和互动交流。通过分享热门内容，用户可以发现共同兴趣，建立互相认同的社群，形成良性的社交生态，提升用户体验和参与度。爱可可微博的热门分享吸引了众多关注和参与，为用户带来了丰富多彩的内容，让用户共同感受和分享这个社交平台的魅力。 <div>
《爱可可微博热门分享(4.9)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405021377504608501"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.9)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hokycl47zxj20rs0fmjuy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 14:32:32 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《SchurVINS: Schur Complement-Based Lightweight Visual Inertial Navigation System》(CVPR 2024) GitHub: github.com/bytedance/SchurVIN...</title>
<link>https://weibo.com/1402400261/O8XwHkqsZ</link>
<guid>https://weibo.com/1402400261/O8XwHkqsZ</guid>
<content:encoded><![CDATA[
<div> 关键词: SchurVINS, 轻量级视觉惯性导航系统, 空间视觉-语言推理, 3D人物和物体联合重建, 多任务去噪扩散模型, 图像恢复, 单视图重建, 大语言模型适应, 三维人物纹理编辑, 扰动引导注意力.

总结:<br /><br />
《SchurVINS: Schur Complement-Based Lightweight Visual Inertial Navigation System》介绍了一种基于Schur补的轻量级视觉惯性导航系统SchurVINS，利用Schur补的方式提高了系统的效率和精度。该系统在GitHub有对应的代码库。
《Know Your Neighbors: Improving Single-View Reconstruction via Spatial Vision-Language Reasoning》通过空间视觉-语言推理的方式改善了单视图重建的效果，提高了重建的准确性。
《CONTHO: Joint Reconstruction of 3D Human and Object via Contact-Based Refinement Transformer》提出了一种通过接触为基础的细化变换器来联合重建3D人物和物体的方法CONTHO，增强了重建的效果。
《DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data》介绍了一种从部分标记数据中学习多任务去噪扩散模型的方法DiffusionMTL，提高了模型的鲁棒性。
《Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model》通过扩散模型提出了一种用于通用图像恢复的选择性沙漏映射方法，提高了恢复效果。
《PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models》提出了一种大语言模型的适应方法PiSSA，通过调整主奇异值和奇异向量来改善模型性能。
《InstructHumans: Editing Animated 3D Human Textures with Instructions》通过指令编辑动画3D人物纹理的方式，实现了纹理编辑的功能。
《Self-Rectifying Diffusion Sampling with Perturbed-Attention Guidance》介绍了一种带有扰动引导注意力的自校正扩散采样方法，提高了采样效果。
《Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation》提出了一种用于多模态语义分割的Siamese Mamba网络Sigma，增强了分割的准确性。
《UniTable: Towards a Unified Table Foundation Model》针对统一表格基础模型提出了UniTable，提高了表格数据处理的效率和准确性。 <div>
几篇论文实现代码：<br />《SchurVINS: Schur Complement-Based Lightweight Visual Inertial Navigation System》(CVPR 2024) GitHub: github.com/bytedance/SchurVINS<br />《Know Your Neighbors: Improving Single-View Reconstruction via Spatial Vision-Language Reasoning》(CVPR 2024) GitHub: github.com/ruili3/Know-Your-Neighbors<br />《CONTHO: Joint Reconstruction of 3D Human and Object via Contact-Based Refinement Transformer》(CVPR 2024) GitHub: github.com/dqj5182/CONTHO_RELEASE<br />《DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data》(CVPR 2024) GitHub: github.com/prismformore/DiffusionMTL [fig4]<br />《Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model》(CVPR 2024) GitHub: github.com/iSEE-Laboratory/DiffUIR [fig8]<br />《PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models》(2024) GitHub: github.com/GraphPKU/PiSSA [fig1]<br />《InstructHumans: Editing Animated 3D Human Textures with Instructions》(2024) GitHub: github.com/viridityzhu/InstructHumans<br />《Self-Rectifying Diffusion Sampling with Perturbed-Attention Guidance》(2024) GitHub: github.com/sunovivid/Perturbed-Attention-Guidance<br />《Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation》(2024) GitHub: github.com/zifuwan/Sigma [fig2]<br />《UniTable: Towards a Unified Table Foundation Model》(2024) GitHub: github.com/poloclub/unitable<br />《LeGrad: An Explainability Method for Vision Transformers via Feature Formation Sensitivity》(2024) GitHub: github.com/WalBouss/LeGrad<br />《Identity Decoupling for Multi-Subject Personalization of Text-to-Image Models》(2024) GitHub: github.com/agwmon/MuDI<br />《FABLES: Evaluating faithfulness and content selection in book-length summarization》(2024) GitHub: github.com/mungg/FABLES [fig3]<br />《Stream of Search: Learning to Search in Language》(2024) GitHub: github.com/kanishkg/stream-of-search<br />《Neural Plasticity-Inspired Foundation Model for Observing the Earth Crossing Modalities》(2024) GitHub: github.com/zhu-xlab/DOFA [fig5]<br />《Dissecting Human and LLM Preferencces》(2024) GitHub: github.com/GAIR-NLP/Preference-Dissection<br />《Evaluating LLMs at Detecting Errors in LLM Responses》(2024) GitHub: github.com/psunlpgroup/ReaLMistake [fig6]<br />《JORA: JAX Tensor-Parallel LoRA Library for Retrieval Augmented Fine-Tuning》(2024) GitHub: github.com/aniquetahir/JORA [fig7]<br />《HALC: Object Hallucination Reduction via Adaptive Focal-Contrast Decoding》(2024) GitHub: github.com/BillChan226/HALC<br />《TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios》(2024) GitHub: github.com/RUCKBReasoning/TableLLM<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoku23j1poj21vc0vudw9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoku24hcx1j20yg0cvtgs.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoku6n03izj21gs0frws9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoku8i46yaj21dy10se81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoku9523i0j222810ge81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hokuwhdwsfj20x60h2wsx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hokuxm49ztj21cz0ga44t.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hokv72x9lsj215u0u0tx2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 13:01:02 GMT</pubDate>
</item>
<item>
<title>【Neco：C 语言编写的并发库，提供了使用 coroutines(协程)的方式进行并发编程】'Neco - Concurrency library for C (coroutines)' GitHub: github.com/tidwall/...</title>
<link>https://weibo.com/1402400261/O8XwbhTdx</link>
<guid>https://weibo.com/1402400261/O8XwbhTdx</guid>
<content:encoded><![CDATA[
<div> GitHub, Neco, C语言, 并发库, coroutines, 协程, 编程, 提供, 方式, 进行

<br /><br />总结:
Neco是一个用C语言编写的并发库，提供了使用coroutines(协程)的方式进行并发编程。这个库在GitHub上有开源代码可供使用。通过Neco，开发者可以更方便地在C语言中实现并发编程，利用协程的特性进行高效的异步操作处理。同时，Neco也提供了丰富的API和功能，使得编写并发代码变得更加简单和容易。如果你在C语言项目中需要实现并发功能，不妨考虑使用Neco库来简化你的开发过程。 <div>
【Neco：C 语言编写的并发库，提供了使用 coroutines(协程)的方式进行并发编程】'Neco - Concurrency library for C (coroutines)' GitHub: github.com/tidwall/neco <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hokvo4kzesj211d0u0dkq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:59:45 GMT</pubDate>
</item>
<item>
<title>【GigaAM: 一个基础模型，专门为语音识别任务设计，包括 GigaAM、GigaAM-CTC 和 GigaAM-Emo 三个模型】'GigaAM: the family of open-source acoustic models for...</title>
<link>https://weibo.com/1402400261/O8XvDxixo</link>
<guid>https://weibo.com/1402400261/O8XvDxixo</guid>
<content:encoded><![CDATA[
<div> GigaAM, acoustic models, speech processing, open-source, GitHub, GigaAM-CTC, GigaAM-Emo<br />
<br />总结:<br />
本文介绍了GigaAM家族，这是专门为语音处理任务设计的开源声学模型。基础模型GigaAM作为语音识别任务的基础模型，提供了实用的功能。除了GigaAM之外，还有GigaAM-CTC和GigaAM-Emo两个模型，扩展了应用领域。感兴趣的开发者可以在GitHub上找到相关代码和资源，进行进一步的研究和实践。整体来看，GigaAM家族为语音识别任务提供了一系列可靠的解决方案，对于开发语音相关应用具有实际意义。 <div>
【GigaAM: 一个基础模型，专门为语音识别任务设计，包括 GigaAM、GigaAM-CTC 和 GigaAM-Emo 三个模型】'GigaAM: the family of open-source acoustic models for speech processing - Foundational Model for Speech Recognition Tasks' GitHub: github.com/salute-developers/GigaAM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hokvmml0n2j212x0u00xa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:58:25 GMT</pubDate>
</item>
<item>
<title>【Serverless ChatGPT with RAG using LangChain.js：用 LangChain.js, TypeScript 和 Azure 创建自己的无服务器 ChatGPT 应用的示例】'Serverless ChatGPT with...</title>
<link>https://weibo.com/1402400261/O8Xtpjjvx</link>
<guid>https://weibo.com/1402400261/O8Xtpjjvx</guid>
<content:encoded><![CDATA[
<div> LangChain.js, TypeScript, Azure, 无服务器, ChatGPT, RAG, 应用, 示例

<br /><br />总结:
本篇文章介绍了如何使用LangChain.js、TypeScript和Azure创建自己的无服务器ChatGPT应用，利用检索增强生成（RAG）技术。通过GitHub上的示例代码，读者可以了解如何实现ChatGPT应用，并在Azure平台上部署运行。文章着重介绍了如何利用LangChain.js进行开发，展示了搭建ChatGPT应用的具体步骤和流程。读者可以根据文中的指引，轻松地开始构建自己的ChatGPT应用，并进一步探索无服务器技术和人工智能的结合应用。 <div>
【Serverless ChatGPT with RAG using LangChain.js：用 LangChain.js, TypeScript 和 Azure 创建自己的无服务器 ChatGPT 应用的示例】'Serverless ChatGPT with RAG using LangChain.js - Create your own serverless ChatGPT with Retrieval-Augmented-Generation using LangChain.js, TypeScript and Azure' GitHub: github.com/Azure-Samples/serverless-chat-langchainjs <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hokvh1g0lyj20up0u00wr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:52:55 GMT</pubDate>
</item>
<item>
<title>【ZhiJian：基于 PyTorch 的模型重用工具包，旨在利用预训练模型和其微调后版本来提取知识并加速实际任务的处理，根据模型准备、模型学习和模型推断三个阶段分别...</title>
<link>https://weibo.com/1402400261/O8XrT4Naf</link>
<guid>https://weibo.com/1402400261/O8XrT4Naf</guid>
<content:encoded><![CDATA[
<div> PyTorch、模型重用、预训练模型、知识提取、实际任务、模型准备、模型学习、模型推断、架构、微调

<br /><br />总结:
本文介绍了一种基于 PyTorch 的模型重用工具包 ZhiJian，旨在利用预训练模型和微调后版本来提取知识并加速实际任务处理。工具包提供了模型准备、模型学习和模型推断三个阶段的架构、微调和合并模块。通过 ZhiJian 工具包，用户可以更高效地利用预训练模型，并在实际任务中快速部署和应用这些模型，提高任务处理效率和模型效果。工具包的使用有助于加速模型重用和知识迁移的过程，让用户能够更便捷地利用先验知识进行任务处理，提高工作效率和模型性能。 <div>
【ZhiJian：基于 PyTorch 的模型重用工具包，旨在利用预训练模型和其微调后版本来提取知识并加速实际任务的处理，根据模型准备、模型学习和模型推断三个阶段分别提供了架构、微调和合并模块】'ZhiJian: A Unifying and Rapidly Deployable Toolbox for Pre-trained Model Reuse' GitHub: github.com/zhangyikaii/LAMDA-ZhiJian <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hokvd0adf5j22qy0u0gxm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hokvd4gau2j21ep0gvtcb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:49:10 GMT</pubDate>
</item>
<item>
<title>【ΦML：数学和神经网络库，专门为科学应用设计，支持 Jax、PyTorch、TensorFlow 和 NumPy，并提供了许多有用的特性】'ΦML - Intuitive scientific computing w...</title>
<link>https://weibo.com/1402400261/O8XqIcbXB</link>
<guid>https://weibo.com/1402400261/O8XqIcbXB</guid>
<content:encoded><![CDATA[
<div> Jax, PyTorch, TensorFlow, NumPy, 神经网络库, 科学应用, 特性, GitHub, 数学, 维度类型

<br /><br />总结:
ΦML是一个专为科学应用设计的数学和神经网络库，支持Jax、PyTorch、TensorFlow和NumPy，并提供许多有用的特性。该库具有维度类型，可使科学计算更直观。用户可以在GitHub上找到ΦML的相关信息。 <div>
【ΦML：数学和神经网络库，专门为科学应用设计，支持 Jax、PyTorch、TensorFlow 和 NumPy，并提供了许多有用的特性】'ΦML - Intuitive scientific computing with dimension types for Jax, PyTorch, TensorFlow &amp; NumPy' GitHub: github.com/tum-pbs/PhiML <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hokva4bbpfj212d0u043n.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:46:16 GMT</pubDate>
</item>
<item>
<title>【Cloud Service Providers Free Tier Overview：主要的云服务提供商的免费配额比较，包括 AWS、Azure、Google Cloud、Oracle Cloud 等。同时也包括了一些额外的...</title>
<link>https://weibo.com/1402400261/O8Xp8eQ5q</link>
<guid>https://weibo.com/1402400261/O8Xp8eQ5q</guid>
<content:encoded><![CDATA[
<div> AWS、Azure、Google Cloud、Oracle Cloud、Alibaba Cloud、IBM Cloud、DigitalOcean、免费配额、云服务提供商、使用场景
<br />
要点1: 本文介绍了主要云服务提供商如AWS、Azure、Google Cloud、Oracle Cloud等的免费配额比较。
要点2: 每个云服务提供商的免费配额都有所不同，适合不同的使用场景。
要点3: 除了主要云服务提供商外，还包括了一些额外的服务如Alibaba Cloud、IBM Cloud、DigitalOcean。
要点4: 通过GitHub链接可以查看更详细的比较数据和信息。
要点5: 了解各家云服务提供商的免费配额可以帮助用户选择适合自己需求的服务。 
总结: 本文介绍了主要的云服务提供商如AWS、Azure、Google Cloud、Oracle Cloud等的免费配额比较，同时也包括了一些额外的服务如Alibaba Cloud、IBM Cloud、DigitalOcean。每个云服务提供商的免费配额都有所不同，适合不同的使用场景。通过GitHub链接可以查看更详细的比较数据和信息，了解各家云服务提供商的免费配额可以帮助用户选择适合自己需求的服务。 <div>
【Cloud Service Providers Free Tier Overview：主要的云服务提供商的免费配额比较，包括 AWS、Azure、Google Cloud、Oracle Cloud 等。同时也包括了一些额外的服务，如 Alibaba Cloud、IBM Cloud、DigitalOcean 等。每个云服务提供商的免费配额都有所不同，适合不同的使用场景】'Cloud Service Providers Free Tier Overview - Comparing the free tier offers of the major cloud providers like AWS, Azure, GCP, Oracle etc.' GitHub: github.com/cloudcommunity/Cloud-Free-Tier-Comparison <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hokv60akmoj20u00zm77r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:42:23 GMT</pubDate>
</item>
<item>
<title>【JORA：解决了 LLM 在 RAG 中的内存限制问题，提供了一种基于 JAX 的分布式训练方法】'JORA: JAX Tensor-Parallel LoRA Library' GitHub: github.com/aniquetah...</title>
<link>https://weibo.com/1402400261/O8Xml3eVr</link>
<guid>https://weibo.com/1402400261/O8Xml3eVr</guid>
<content:encoded><![CDATA[
<div> JORA, 解决, LLM, RAG, 内存限制, JAX, 分布式训练方法

<br /><br />总结:
JORA是一个基于JAX的Tensor-Parallel LoRA库，解决了LLM在RAG中的内存限制问题。它提供了一种分布式训练方法，能够有效地处理大规模模型和数据集。通过使用JAX，实现了更高效的计算和内存管理，使得训练过程更加高效和可扩展。JORA项目的GitHub地址为github.com/aniquetahir/JORA。 <div>
【JORA：解决了 LLM 在 RAG 中的内存限制问题，提供了一种基于 JAX 的分布式训练方法】'JORA: JAX Tensor-Parallel LoRA Library' GitHub: github.com/aniquetahir/JORA <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hokuyut1ubj21cz0gaacq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:35:30 GMT</pubDate>
</item>
<item>
<title>【D1 Manager：用于 Cloudflare D1(一种无服务器 SQL 数据库)的 Web UI 和 API，提供了一种用户友好的界面来管理数据库、表和记录，以及 API 用来执行编程操作】...</title>
<link>https://weibo.com/1402400261/O8Xjxs30Y</link>
<guid>https://weibo.com/1402400261/O8Xjxs30Y</guid>
<content:encoded><![CDATA[
<div> Cloudflare D1、Web UI、API、管理数据库、表、记录、用户友好界面、查询编程操作、AI助手、GitHub: github.com/JacobLinCool/d1-manager 

<br /><br />总结:
D1 Manager是用于Cloudflare D1的Web UI和API，提供了用户友好的界面来管理数据库、表和记录，并有一个AI助手来帮助用户用自然语言编写查询。用户可以通过GitHub访问该工具的代码。 <div>
【D1 Manager：用于 Cloudflare D1(一种无服务器 SQL 数据库)的 Web UI 和 API，提供了一种用户友好的界面来管理数据库、表和记录，以及 API 用来执行编程操作】'D1 Manager - D1 Manager is a web UI and API for Cloudflare D1, a serverless SQL database. It provides a web interface for managing databases, tables, and records, as well as an AI assistant to help you write query in natural language.' GitHub: github.com/JacobLinCool/d1-manager <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Cloudflare%23"><span class="surl-text">#Cloudflare#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%95%B0%E6%8D%AE%E5%BA%93%23&amp;isnewpage=1"><span class="surl-text">#数据库#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hokurptyvuj20u012ytdn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:28:37 GMT</pubDate>
</item>
<item>
<title>【Make your Python output dramatic：让 Python 输出可以逐字显示，增加节奏感】'Make your Python output dramatic - Display all Python process output char...</title>
<link>https://weibo.com/1402400261/O8XfA2LQ2</link>
<guid>https://weibo.com/1402400261/O8XfA2LQ2</guid>
<content:encoded><![CDATA[
<div> dramatic, Python, 输出, 逐字显示, 增加, 节奏感, GitHub, 进程, 字符, 增强<br /><br />总结：
文章介绍了一个名为"dramatic"的工具，可以让Python输出可以逐字显示，增加节奏感。通过这个工具，Python的处理过程可以逐字显示，让输出更加生动有趣。该工具可以在GitHub上找到，有助于提升Python输出时的视觉效果。文章重点介绍了如何使用"dramatic"工具来增强Python输出，让输出更加具有戏剧性。 <div>
【Make your Python output dramatic：让 Python 输出可以逐字显示，增加节奏感】'Make your Python output dramatic - Display all Python process output character-by-character' GitHub: github.com/treyhunner/dramatic <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hokuhlnglrj215r0u0wiu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 12:18:51 GMT</pubDate>
</item>
<item>
<title>【Fuwari：用 Astro 构建的漂亮静态博客模板】'Fuwari - A static blog template built with Astro.' GitHub: github.com/saicaca/fuwari #开源# [图片]</title>
<link>https://weibo.com/1402400261/O8X7lcLAv</link>
<guid>https://weibo.com/1402400261/O8X7lcLAv</guid>
<content:encoded><![CDATA[
<div> Astro、静态博客、模板、GitHub、漂亮、Fuwari、构建、saicaca、静态、Astro
<br />
Astro是一个用于构建静态博客的工具，Fuwari是一个漂亮的静态博客模板，使用Astro构建。该模板可以在GitHub上找到，作者是saicaca。静态博客的优点在于加载速度快、安全性高、易于管理。Astro的灵活性和易用性使得构建静态博客变得更加简单和方便。静态博客模板Fuwari的设计美观大方，适合多种主题和用途。通过GitHub可以方便地获取该模板并进行个性化定制。 <div>
【Fuwari：用 Astro 构建的漂亮静态博客模板】'Fuwari - A static blog template built with Astro.' GitHub: github.com/saicaca/fuwari <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoktwe9ygxj21530u0qcd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 11:58:33 GMT</pubDate>
</item>
<item>
<title>【Financial Datasets：开源 Python 库，用于利用大语言模型(LLM)生成合成的金融/财务数据集】'Financial Datasets - Financial datasets for LLMs' GitHub: git...</title>
<link>https://weibo.com/1402400261/O8URmyitM</link>
<guid>https://weibo.com/1402400261/O8URmyitM</guid>
<content:encoded><![CDATA[
<div> GitHub、Financial Datasets、Python 库、大语言模型、金融、财务、生成、合成、数据集、开源库
<br />
金融数据集：该开源 Python 库提供了金融/财务领域的数据集，可用于利用大语言模型(LLM)生成合成数据。这个库可以帮助研究人员和开发者更好地训练和评估金融相关的自然语言处理模型。GitHub链接：github.com/virattt/financial-datasets。<br /><br />总结: <div>
【Financial Datasets：开源 Python 库，用于利用大语言模型(LLM)生成合成的金融/财务数据集】'Financial Datasets - Financial datasets for LLMs' GitHub: github.com/virattt/financial-datasets <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hokjxnngfwj217c0u00x9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 06:13:42 GMT</pubDate>
</item>
<item>
<title>【AutoMQ: 用于 Apache Kafka 的云原生实现，旨在缩减云基础设施费用，使用类似 Kubernetes 的方式来部署和管理 Kafka 集群，并提供了自动伸缩、故障迁移和监控...</title>
<link>https://weibo.com/1402400261/O8UPgzwwy</link>
<guid>https://weibo.com/1402400261/O8UPgzwwy</guid>
<content:encoded><![CDATA[
<div> 云原生、Apache Kafka、AutoMQ、云基础设施、费用缩减、Kubernetes、部署管理、自动伸缩、故障迁移、监控功能

总结:<br /><br />AutoMQ是针对Apache Kafka的云原生实现，类似于Kubernetes的部署方式，能够最大程度地减少云基础设施费用，达到高达90%的节省。它提供了自动伸缩、故障迁移和监控等功能，帮助用户更高效地管理和操作Kafka集群。通过GitHub链接github.com/AutoMQ/automq，用户可以了解更多关于AutoMQ的信息。 <div>
【AutoMQ: 用于 Apache Kafka 的云原生实现，旨在缩减云基础设施费用，使用类似 Kubernetes 的方式来部署和管理 Kafka 集群，并提供了自动伸缩、故障迁移和监控等功能】’AutoMQ: Truly serverless Kafka solution that maximizes the benefits of cloud - A cloud native implementation for Apache Kafka, reducing your cloud infrastructure bill by up to 90%.' GitHub: github.com/AutoMQ/automq <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hokjs660tsj20vg0u0jvk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 06:08:32 GMT</pubDate>
</item>
<item>
<title>'Mistral 7B v0.2 JAX - JAX implementation of the Mistral 7b v0.2 model' GitHub: github.com/yixiaoer/mistral-v0.2-jax #开源# #机器学习# #人工智能# [图...</title>
<link>https://weibo.com/1402400261/O8UOF1TIz</link>
<guid>https://weibo.com/1402400261/O8UOF1TIz</guid>
<content:encoded><![CDATA[
<div> GitHub, Mistral 7B v0.2 JAX，JAX implementation，model<br />
<br />
模型Mistral 7B v0.2是一个基于JAX库实现的模型，在GitHub上有相应的项目，通过该项目可以获取相关代码和文档。这个模型的实现是基于JAX库的，提供了Mistral 7b v0.2模型的JAX版本。这个项目对使用JAX实现模型的方式进行了介绍，对深度学习领域的研究有一定的参考价值。<br /> <br />总结: <br />模型Mistral 7B v0.2是一个基于JAX库实现的模型，在GitHub上有相应的项目，通过该项目可以获取相关代码和文档。这个模型的实现是基于JAX库的，提供了Mistral 7b v0.2模型的JAX版本。这个项目对使用JAX实现模型的方式进行了介绍，对深度学习领域的研究有一定的参考价值。 <div>
'Mistral 7B v0.2 JAX - JAX implementation of the Mistral 7b v0.2 model' GitHub: github.com/yixiaoer/mistral-v0.2-jax <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hokjqq3ra1j218e0u0tcg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 06:07:02 GMT</pubDate>
</item>
<item>
<title>【旨在收集和整理语音/音频领域的大语言模型(LLM)、表示学习和编解码模型列表】’Speech Trident - Awesome Speech LM - Awesome speech/audio LLMs, representa...</title>
<link>https://weibo.com/1402400261/O8UModHKm</link>
<guid>https://weibo.com/1402400261/O8UModHKm</guid>
<content:encoded><![CDATA[
<div> Speech Trident, Awesome Speech LM, Awesome speech/audio LLMs, representation learning, codec models, GitHub, 收集, 整理, 语音, 音频, 大语言模型, 表示学习。<br />
<br />
总结: 本文是关于语音/音频领域的大语言模型(LLM)、表示学习和编解码模型列表的收集和整理。提到了Speech Trident、Awesome Speech LM和Awesome speech/audio LLMs等内容，涉及到表示学习和编解码模型。相关项目可以在GitHub上找到，包含了丰富的资源和信息，是学习和研究这些领域的重要参考。 <div>
【旨在收集和整理语音/音频领域的大语言模型(LLM)、表示学习和编解码模型列表】’Speech Trident - Awesome Speech LM - Awesome speech/audio LLMs, representation learning, and codec models' GitHub: github.com/ga642381/speech-trident <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hokjkwue0yj20u016vaf2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 06:01:27 GMT</pubDate>
</item>
<item>
<title>【Morphic：AI驱动的回答引擎，类似Perplexity，可以提供准确和实时的答案，配备生成式 UI】’Morphic - An AI-powered answer engine with a generative UI' Gi...</title>
<link>https://weibo.com/1402400261/O8ULLciDl</link>
<guid>https://weibo.com/1402400261/O8ULLciDl</guid>
<content:encoded><![CDATA[
<div> AI、Morphic、回答引擎、Perplexity、实时、生成式UI、Github、miurla、准确、驱动<br />
<br />
AI技术不断发展，Morphic是一个AI驱动的回答引擎，类似于Perplexity，能够提供准确和实时的答案。该引擎配备了生成式的用户界面，可以通过GitHub上的miurla/morphic获取相关信息。Morphic的出现将为人们提供更加智能和便捷的答案服务。 <div>
【Morphic：AI驱动的回答引擎，类似Perplexity，可以提供准确和实时的答案，配备生成式 UI】’Morphic - An AI-powered answer engine with a generative UI' GitHub: github.com/miurla/morphic <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hokjiiwauvj21960u0adx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 05:59:54 GMT</pubDate>
</item>
<item>
<title>【llm.c：实现了大语言模型(LLM)训练的简单、纯 C/CUDA 版本，无需 PyTorch 或 cPython】'llm.c - LLM training in simple, raw C/CUDA' GitHub: github.com/kar...</title>
<link>https://weibo.com/1402400261/O8UKMes4Y</link>
<guid>https://weibo.com/1402400261/O8UKMes4Y</guid>
<content:encoded><![CDATA[
<div> LLM、训练、C/CUDA、简单、纯、PyTorch、GitHub、karpathy

LLM.c是一个在C/CUDA中实现的大语言模型（LLM）训练程序，无需依赖PyTorch或cPython。该程序提供了一个简单而纯净的实现，方便用户进行大规模语言模型训练。项目托管在GitHub上，由karpathy创建和维护。用户可以通过访问GitHub链接github.com/karpathy/llm.c 来获取更多信息和源代码。通过该项目，用户可以了解如何使用C/CUDA进行简单而高效的大语言模型训练，为研究和实践提供了一个有价值的工具。LLM.c的存在和贡献将为语言模型领域的发展带来更多可能性和机会。<br /><br />总结: LLM.c是一个在C/CUDA中实现的大语言模型（LLM）训练项目，提供了简单而高效的实现方法，无需依赖PyTorch或cPython，为用户提供了一个有价值的工具。 <div>
【llm.c：实现了大语言模型(LLM)训练的简单、纯 C/CUDA 版本，无需 PyTorch 或 cPython】'llm.c - LLM training in simple, raw C/CUDA' GitHub: github.com/karpathy/llm.c <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hokjgrmr1wj211k0u0n2d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 05:57:27 GMT</pubDate>
</item>
<item>
<title>【Ollama新增对嵌入(Embedding)模型的支持，可用于构建检索增强生成(RAG)应用，提供了若干预训练好的嵌入模型,包括mxbai-embed-large、nomic-embed-text、all-mi...</title>
<link>https://weibo.com/1402400261/O8SLfCi6f</link>
<guid>https://weibo.com/1402400261/O8SLfCi6f</guid>
<content:encoded><![CDATA[
<div> mxbai-embed-large、nomic-embed-text、all-minilm、嵌入模型、检索增强生成、Ollama、预训练、支持、应用、模型

<br /><br />总结:
Ollama新增了对嵌入(Embedding)模型的支持，可用于构建检索增强生成(RAG)应用。提供了多种预训练好的嵌入模型，包括mxbai-embed-large、nomic-embed-text、all-minilm等。通过这些模型，用户可以更有效地进行文本检索和生成任务。Ollama为用户提供了更多选择和可能性，帮助他们构建更优质的应用和服务。 <div>
【Ollama新增对嵌入(Embedding)模型的支持，可用于构建检索增强生成(RAG)应用，提供了若干预训练好的嵌入模型,包括mxbai-embed-large、nomic-embed-text、all-minilm等】《Embedding models · Ollama Blog》 <a href="https://ollama.com/blog/embedding-models"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hokao4q72uj20xd0u0q68.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 00:53:09 GMT</pubDate>
</item>
<item>
<title>【Inqwire：主打不用LLM提供智能服务的软件，可应用于生活决策、困难情况、关系等诸多方面，致力于增强人们的天然智能，以帮助人们理解事物，创造有意义的世界】...</title>
<link>https://weibo.com/1402400261/O8SEeFvLr</link>
<guid>https://weibo.com/1402400261/O8SEeFvLr</guid>
<content:encoded><![CDATA[
<div> 智能服务、软件、生活决策、困难情况、关系、增强、人们、天然智能、理解事物、有意义的世界

<br /><br />总结:
"Inqwire"是一款主打不用LLM提供智能服务的软件，它可应用于生活决策、困难情况、关系等诸多方面。该软件致力于增强人们的天然智能，帮助人们理解事物，创造有意义的世界。通过Inqwire，用户能够更好地应对生活中的挑战，提高决策的准确性，加强人与人之间的沟通和理解，进而为自己和他人创造更加有意义和丰富的生活体验。Inqwire的存在使得人们不仅可以依靠智能技术，更可以通过自身的天然智能来解决问题，达到更深层次的认知和体验。 <div>
【Inqwire：主打不用LLM提供智能服务的软件，可应用于生活决策、困难情况、关系等诸多方面，致力于增强人们的天然智能，以帮助人们理解事物，创造有意义的世界】“Inqwire” <a href="https://www.inqwire.io/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoka5gq6dxj20oc0j675v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 00:35:52 GMT</pubDate>
</item>
<item>
<title>【元编程新思路：用Claude 3 Opus打造"files-to-prompt"工具】- Simon Willison开发了一个名为"files-to-prompt"的新工具，可以帮助将多个文件一次性传递给Claud...</title>
<link>https://weibo.com/1402400261/O8SzuiErQ</link>
<guid>https://weibo.com/1402400261/O8SzuiErQ</guid>
<content:encoded><![CDATA[
<div> 开发者、files-to-prompt、Claude、GPT-4、LLM、AI工具、软件开发、效率、创新能力、元编程<br />
<br />
总结:<br />
Simon Willison开发了一个名为"files-to-prompt"的新工具，可以帮助将多个文件一次性传递给Claude和GPT-4等大语言模型。通过将"files-to-prompt"与Willison之前开发的LLM命令行工具结合使用，可以实现一些强大的功能。文章展示了如何利用AI工具来辅助软件开发的一个有趣案例。Willison几乎完全使用Claude 3 Opus模型开发了"files-to-prompt"工具，并使用自己的工具协助开发过程。随着大语言模型等AI技术的快速发展，开发者可以利用这些强大的工具来优化工作流程，提高生产力。元编程的思想在AI时代焕发新的生机，开发者应该主动学习和尝试前沿的AI工具和方法，创造智能、高效的解决方案。 <div>
【元编程新思路：用Claude 3 Opus打造"files-to-prompt"工具】<br />- Simon Willison开发了一个名为"files-to-prompt"的新工具，可以帮助将多个文件一次性传递给Claude和GPT-4等大语言模型(LLM)。  <br />- 通过将"files-to-prompt"与Willison之前开发的LLM命令行工具结合使用，可以实现一些强大的功能。<br />- Willison几乎完全使用Claude 3 Opus模型开发了"files-to-prompt"工具。他使用了自己的"llm-claude-3"和"files-to-pr"工具来协助开发过程。  <br />- 文章没有详细介绍"files-to-prompt"的实现原理和具体用法，但展示了如何利用AI工具来辅助软件开发的一个有趣案例。  <br />- Willison是一位经验丰富的开发者，他积极拥抱新兴的AI技术，并不断探索如何将其应用到实际的开发工作中，以提高效率和创新能力。  <br /><br />思考：  <br />- 随着大语言模型等AI技术的快速发展，开发者可以利用这些强大的工具来优化工作流程，例如自动更新文档、生成样板代码等，这将极大地提高生产力。  <br />- 元编程(meta-programming)的思想在AI时代焕发新的生机。就像Willison使用AI工具来开发另一个工具一样，我们可以设计出更多"自我完善"的系统。  <br />- 新技术的采用需要开放和创新的心态。作为开发者，我们应该主动学习和尝试前沿的AI工具和方法，将它们与已有的最佳实践相结合，创造出更智能、更高效的解决方案。  <br />《Building files-to-prompt entirely using Claude 3 Opus》 <a href="https://simonwillison.net/2024/Apr/8/files-to-prompt/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hok9tz27auj20w30u043j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 00:24:10 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@异步图书 送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O8Syqr7qt</link>
<guid>https://weibo.com/1402400261/O8Syqr7qt</guid>
<content:encoded><![CDATA[
<div> 大语言模型、前沿进展、科学家、工程师、学生、案例、庖丁解牛、理解、认识

<br /><br />总结:
本文介绍了一本名为《大语言模型：基础与前沿》的书籍，截止日期为2024年4月12日12:00。这本书全面深入地介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。作者摒弃了纯理论的说教模式，从案例入手，采用庖丁解牛的方式帮助读者理解与认识大语言模型。通过转发和评论参与活动，有机会获得3本这本书。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%BC%82%E6%AD%A5%E5%9B%BE%E4%B9%A6">@异步图书</a>  送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。摒弃了纯理论的说教模式，从案例入手， 采用庖丁解牛的方式帮助读者理解与认识大语言模型。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019331269755053"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef8oboqij20ga0m8q8p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9segl7j20m90m9q6z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9t5km0j20m90m942f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef9tq2esj20m90m9gpe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef9ugq5dj20m90m9dif.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 09 Apr 2024 00:21:33 GMT</pubDate>
</item>
<item>
<title>今日推介(第1370期)：基于大语言模型的社交技能训练、鲁棒高斯Splatting、机器人装配的数据高效模仿学习、语言模型如何嵌入长文档以进行稠密检索、指数数据增长...</title>
<link>https://weibo.com/1402400261/O8RLzmUhX</link>
<guid>https://weibo.com/1402400261/O8RLzmUhX</guid>
<content:encoded><![CDATA[
<div> 社交技能训练、鲁棒高斯Splatting、机器人装配的数据高效模仿学习、语言模型嵌入长文档稠密检索、指数数据增长实现“零样本”  

<br /><br />总结:  
本文介绍了基于大语言模型的社交技能训练方法，通过模仿学习机器人装配的数据来提高效率。另外，作者提出了一种鲁棒的高斯Splatting方法，用于图像处理。此外，讨论了语言模型如何嵌入长文档进行稠密检索，以及指数数据增长如何实现“零样本”学习。这些方法为解决实际问题提供了新的思路和方法。 <div>
今日推介(第1370期)：基于大语言模型的社交技能训练、鲁棒高斯Splatting、机器人装配的数据高效模仿学习、语言模型如何嵌入长文档以进行稠密检索、指数数据增长才能实现“零样本” 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/691406363"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.9)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hok69o8e1cj216i0u0gqf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hok69rjq3ij21bi0u0te6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hok69u82q6j21zj0u0dpb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hok69wxlrsj20sw0swq6i.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hok69znxkcj21pt0u0ail.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 22:21:10 GMT</pubDate>
</item>
<item>
<title>[RO] MM-Gaussian: 3D Gaussian-based Multi-modal Fusion for Localization and Reconstruction in Unbounded Scenes 网页链接 提出MM-Gaussian系统，在无界外...</title>
<link>https://weibo.com/1402400261/O8RGUCPu0</link>
<guid>https://weibo.com/1402400261/O8RGUCPu0</guid>
<content:encoded><![CDATA[
<div> 激光雷达、摄像头、多模态融合、定位、3D高斯映射、MM-Gaussian系统

<br /><br />总结:
本文提出了一种名为MM-Gaussian的系统，旨在无界外部场景中利用激光雷达和摄像头进行多模态融合，以实现鲁棒的定位和3D高斯映射。该系统结合了激光雷达和摄像头的优势，在定位和重建方面表现出色。算法采用3D高斯模型来描述环境，通过多模态融合提高了位置识别准确性。实验结果表明，MM-Gaussian系统在无界外部场景中展现出了良好的性能，具有较高的实用价值。MM-Gaussian系统为无界外部场景下的定位和重建提供了一种新的解决方案，具有很大的应用潜力。 <div>
[RO] MM-Gaussian: 3D Gaussian-based Multi-modal Fusion for Localization and Reconstruction in Unbounded Scenes  <br /><a href="https://arxiv.org/abs/2404.04026"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出MM-Gaussian系统，在无界外部场景中使用激光雷达和摄像头进行多模态融合，实现鲁棒的定位与3D高斯映射。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok5y0spluj21361e6txo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok5y0wonpj21ls0p2tio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok5y2akruj20t40okjwg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 22:09:43 GMT</pubDate>
</item>
<item>
<title>[LG] Transformers for molecular property prediction: Lessons learned from the past five years 网页链接 全面回顾了 transformer 模型在分子性质预测任务中...</title>
<link>https://weibo.com/1402400261/O8REt4WyT</link>
<guid>https://weibo.com/1402400261/O8REt4WyT</guid>
<content:encoded><![CDATA[
<div> transformer模型, 分子性质预测, 模型训练, 微调, 模型泛化能力, 可解释性, 评估方法, 挑战, 未来研究, 启示

<br /><br />总结:
本文全面回顾了过去五年中transformer模型在分子性质预测任务中的应用情况。文章分析了关键的训练和微调决策，同时提出了模型泛化能力、可解释性和评估方法等方面的挑战。从中我们可以看到一些对未来研究具有启示意义的内容。在实践中发现，模型对于分子性质预测任务的应用效果显著，但需要谨慎选择训练和微调的策略，以提高模型性能和泛化能力。同时，模型的可解释性是一个重要的研究方向，需要深入研究如何解释模型的预测结果。另外，评估方法也需要不断完善，以确保模型的有效性和稳健性。未来的研究应该注重解决这些挑战，推动该领域取得更大的进展。 <div>
[LG] Transformers for molecular property prediction: Lessons learned from the past five years  <br /><a href="https://arxiv.org/abs/2404.03969"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />全面回顾了 transformer 模型在分子性质预测任务中的应用情况，分析了模型训练和微调的关键决策，提出了模型泛化能力、可解释性、评估方法等方面的挑战，为该领域的未来研究提供了宝贵启示。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok5rr8ofmj21021betht.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok5rrlgxvj21k4196qhx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok5rs8ftaj21my0ssahr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 22:03:41 GMT</pubDate>
</item>
<item>
<title>[CL] Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model 网页链接 通过大规模中文预训练语料和模型训练，获得了一款在中文任务上表现强劲...</title>
<link>https://weibo.com/1402400261/O8Ry2uWNb</link>
<guid>https://weibo.com/1402400261/O8Ry2uWNb</guid>
<content:encoded><![CDATA[
<div> 关键词: 中文预训练语料, 模型训练, CT-LLM, 中文任务, 强劲表现

总结:
<br />
本文介绍了一款名为CT-LLM的中文语言模型，通过大规模中文预训练语料和模型训练，使其在中文任务上表现强劲。CT-LLM的表现令人印象深刻，显示出在中文任务上具有良好的性能和应用潜力。这一研究成果对中文自然语言处理领域具有重要意义，为中文文本处理和应用提供了强有力的支持。CT-LLM的开源模型为相关研究和实践提供了有力的工具和资源，为进一步探索中文语言处理领域打下了良好的基础。 <div>
[CL] Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model  <br /><a href="https://arxiv.org/abs/2404.04167"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过大规模中文预训练语料和模型训练，获得了一款在中文任务上表现强劲的开源语言模型 CT-LLM。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok5b9zqqoj20vq1dmtqe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok5ba4uv2j20so0twae4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok5basrsej21jy10cn6l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:47:51 GMT</pubDate>
</item>
<item>
<title>[LG] Stream of Search (SoS): Learning to Search in Language 网页链接 通过将搜索过程表示为搜索流字符串，让语言模型学习不同的符号搜索策略，取得了改进搜...</title>
<link>https://weibo.com/1402400261/O8RvHki5K</link>
<guid>https://weibo.com/1402400261/O8RvHki5K</guid>
<content:encoded><![CDATA[
<div> 搜索流字符串, 语言模型, 符号搜索策略, 提升搜索能力, 新策略潜力<br />
<br />
提出了一种新的学习搜索策略的方法，即通过将搜索过程表示为搜索流字符串，让语言模型学习不同的符号搜索策略。这种方法带来了改进搜索能力和发现新策略的潜力，有望为语言模型的搜索任务带来更好的效果。 <div>
[LG] Stream of Search (SoS): Learning to Search in Language  <br /><a href="https://arxiv.org/abs/2404.03683"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过将搜索过程表示为搜索流字符串，让语言模型学习不同的符号搜索策略，取得了改进搜索能力和发现新策略的潜力。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok55aty2sj20wa1dmwvy.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok55b59w6j21ic1784f5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok55bhqv6j21ii0se7fg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:42:05 GMT</pubDate>
</item>
<item>
<title>通过大规模分析发现当下多模态模型存在数据饥渴性和样本低效问题，预训练数据频率与下游泛化性能呈对数线性关系，需要重新审视大规模泛化学习范式。 - 转发 @爱...</title>
<link>https://weibo.com/1402400261/O8RqVqluZ</link>
<guid>https://weibo.com/1402400261/O8RqVqluZ</guid>
<content:encoded><![CDATA[
<div> 数据饥渴性, 样本低效问题, 预训练数据频率, 下游泛化性能, 对数线性关系, 大规模分析, 多模态模型, 大规模泛化学习, 范式, 多模态模型性能<br />
<br />
总结:<br />
研究指出当前多模态模型存在数据饥渴性和样本低效问题，预训练数据频率与下游泛化性能呈对数线性关系。通过大规模分析发现，预训练数据的提取与样本频率密切相关，这需要重新审视大规模泛化学习范式。研究认为，预训练概念频率对多模态模型性能有重要影响，指出没有"零射击"现象，需要更深入地研究数据频率与模型性能的关系。 <div>
通过大规模分析发现当下多模态模型存在数据饥渴性和样本低效问题，预训练数据频率与下游泛化性能呈对数线性关系，需要重新审视大规模泛化学习范式。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance》V Udandarao, A Prabhu, A Ghosh, Y Sharma, P H.S. Torr, A Bibi, S Albanie, M Bethge [University of Tubingen] (2024) <a href="https://arxiv.org/abs/2404.04125"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4iw2z9ij21lu0swk7s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4iwpxzaj21sa0v6gya.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4ixe9rsj21rm13kngx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4ixguwlj21s00wg16m.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4swu7suj210x0djad0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4sww1qvj210x0ff77b.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4swtorjj20g80nqgnn.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4swv9msj210y0l8q7d.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4swvcz8j21160m1dl7.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:30:20 GMT</pubDate>
</item>
<item>
<title>[CV]《No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance》V Udandarao, A Prabhu, A Ghosh, ...</title>
<link>https://weibo.com/1402400261/O8RqRui2s</link>
<guid>https://weibo.com/1402400261/O8RqRui2s</guid>
<content:encoded><![CDATA[
<div> 关键词: 零-shot学习, 数据增强, 预训练, 概念频率, 多模态模型, 性能

总结:<br /><br />
本研究探讨了在多模态模型性能中数据预训练中概念频率的影响。研究发现，零-shot学习的实现离不开大规模数据增强，而预训练阶段中概念频率对模型性能有关键影响。对于零-shot任务来说，预训练阶段的数据量和质量决定了模型的表现，因此在构建多模态模型时需要考虑数据的数量和多样性。研究的结果有助于指导未来多模态模型设计和训练的方向。 <div>
[CV]《No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance》V Udandarao, A Prabhu, A Ghosh, Y Sharma, P H.S. Torr, A Bibi, S Albanie, M Bethge [University of Tubingen] (2024) <a href="https://arxiv.org/abs/2404.04125"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4iw2z9ij21lu0swk7s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4iwpxzaj21sa0v6gya.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4ixe9rsj21rm13kngx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4ixguwlj21s00wg16m.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4swu7suj210x0djad0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4sww1qvj210x0ff77b.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4swtorjj20g80nqgnn.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4swv9msj210y0l8q7d.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4swvcz8j21160m1dl7.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4swvs7nj21160tmn3o.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4swvnyej21130tmjxx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4swv7fzj21140i9q6q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4swuxl1j21140iawia.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4swuup0j210x0j4782.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4swur2qj210x0i9n0z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4swurs2j210x0i9adu.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4swtq8oj210x0g9tab.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4swv0cej21160m0q83.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:30:10 GMT</pubDate>
</item>
<item>
<title>发现Transformer检索模型存在偏好输入前段信息的“序处停滞”效应，这种位置偏差源自对比预训练过程。 - 转发 @爱可可-爱生活:&amp;ensp;[IR]《Dwell in the Beginni...</title>
<link>https://weibo.com/1402400261/O8RkwrPh1</link>
<guid>https://weibo.com/1402400261/O8RkwrPh1</guid>
<content:encoded><![CDATA[
<div> Transformer检索模型、偏好输入前段信息、“序处停滞”效应、位置偏差、预训练过程、长文档嵌入、稠密检索、模型表达能力、信息检索、文本理解<br />
<br />
总结:<br />
文章探讨了Transformer检索模型在处理长文档时出现的“序处停滞”效应，这种位置偏差源自对比预训练过程中输入前段信息的偏好。研究发现，在长文档中，Transformer模型会更倾向于关注文档开头的信息，而忽视后续内容。为应对这一问题，研究提出了一种有效的策略，通过在检索阶段加入更多广泛的信息来补充模型在长文档中的信息局限性。实验结果表明，这种策略可以显著改善模型的性能，提高模型在稠密检索任务中的表现。因此，在构建Transformer检索模型时，需要考虑模型的表达能力和输入信息的分布，以提升模型在信息检索和文本理解任务中的效果。 <div>
发现Transformer检索模型存在偏好输入前段信息的“序处停滞”效应，这种位置偏差源自对比预训练过程。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [IR]《Dwell in the Beginning: How Language Models Embed Long Documents for Dense Retrieval》J Coelho, B Martins, J Magalhães, J Callan, C Xiong [CMU &amp; University of Lisbon] (2024) <a href="https://arxiv.org/abs/2404.04163"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4bm3oxkj20ow0ti0zy.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4bmltyfj20sw0swdkh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4bmswz8j20sy0gc0um.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4bmyj3tj20t40q042g.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4c855g8j20si0qe0xq.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:14:32 GMT</pubDate>
</item>
<item>
<title>[IR]《Dwell in the Beginning: How Language Models Embed Long Documents for Dense Retrieval》J Coelho, B Martins, J Magalhães, J Callan, C Xiong [CMU ...</title>
<link>https://weibo.com/1402400261/O8RklwUaz</link>
<guid>https://weibo.com/1402400261/O8RklwUaz</guid>
<content:encoded><![CDATA[
<div> 语言模型、长文档、稠密检索、嵌入、起始点、语言模型<br />
<br />
提出了一种在长文档中嵌入语言模型进行稠密检索的方法。通过在长文档的起始点上使用语言模型嵌入，提高了检索效果。实验结果表明，这种方法能够在稠密检索任务中取得较好的性能表现。文章探讨了如何在语言模型中嵌入长文档，并详细介绍了实验设计与结果分析。总体来说，提出的方法在处理长文档的稠密检索任务中表现出了潜力，为相关研究和实践提供了有益的参考。 <br /><br />总结: <br />这篇文章提出了一种在长文档中嵌入语言模型进行稠密检索的方法，通过在文档起始点上使用语言模型嵌入来提高检索效果。实验结果证实了这种方法在稠密检索任务中的有效性，为相关研究提供了新的思路。 <div>
[IR]《Dwell in the Beginning: How Language Models Embed Long Documents for Dense Retrieval》J Coelho, B Martins, J Magalhães, J Callan, C Xiong [CMU &amp; University of Lisbon] (2024) <a href="https://arxiv.org/abs/2404.04163"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4bm3oxkj20ow0ti0zy.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4bmltyfj20sw0swdkh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4bmswz8j20sy0gc0um.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4bmyj3tj20t40q042g.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4c855g8j20si0qe0xq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:14:07 GMT</pubDate>
</item>
<item>
<title>通过策略结构设计、数据增强和迭代收集提出管道，在少量示教的预算下提高机器人装配任务的模仿学习性能。 - 转发 @爱可可-爱生活:&amp;ensp;[RO]《JUICER: Data-Effi...</title>
<link>https://weibo.com/1402400261/O8RjSzooL</link>
<guid>https://weibo.com/1402400261/O8RjSzooL</guid>
<content:encoded><![CDATA[
<div> 数据增强、模仿学习、机器人装配任务、管道设计、策略结构、迭代收集、预算限制、 JUICER、少量示教、性能提升

<br /><br />总结:
研究团队通过策略结构设计、数据增强和迭代收集提出了管道，有效提高了机器人装配任务的模仿学习性能。他们使用名为JUICER的方法，在少量示教的预算下实现了高效的数据驱动模仿学习。该方法利用数据增强技术增加了训练数据的多样性，进一步提高了模型的泛化能力。通过这种方式，他们成功克服了预算限制带来的挑战，并取得了令人满意的成果。通过不断优化管道设计和策略调整，他们实现了机器人装配任务的模仿学习性能的显著提升。研究结果为解决机器人装配领域的挑战提供了新的思路和方法。 <div>
通过策略结构设计、数据增强和迭代收集提出管道，在少量示教的预算下提高机器人装配任务的模仿学习性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [RO]《JUICER: Data-Efficient Imitation Learning for Robotic Assembly》L Ankile, A Simeonov, I Shenfeld, P Agrawal [Harvard University &amp; MIT] (2024) <a href="https://arxiv.org/abs/2404.03729"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4a0p0b8j20u20l4wmf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4a18cdpj21nm0p0qcw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4a1psg2j20ue0nstfb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4a24acyj21m20hcn1l.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4aon70hj212v0b2wft.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4aona69j212v0b2wft.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4aoom3fj213p0dbgor.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4aoo8bvj213p0o440u.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4aoo5sej20si0nb0ut.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:12:58 GMT</pubDate>
</item>
<item>
<title>[RO]《JUICER: Data-Efficient Imitation Learning for Robotic Assembly》L Ankile, A Simeonov, I Shenfeld, P Agrawal [Harvard University &amp; MIT] (2024) 网...</title>
<link>https://weibo.com/1402400261/O8RjLiVz7</link>
<guid>https://weibo.com/1402400261/O8RjLiVz7</guid>
<content:encoded><![CDATA[
<div> 数据效率、模仿学习、机器人组装、果汁机、数据规模、数据采集、机器人操作、深度学习、数据训练、自动装配

总结：<br /><br />这篇文章介绍了一种名为JUICER的数据效率模仿学习方法，用于解决机器人组装问题。通过该方法，研究人员成功开发了一种新型果汁机，并通过数据采集和深度学习训练机器人进行自动装配。该技术能够在较小的数据规模下实现高效的机器人操作，为未来的智能制造提供了新的可能性。 <div>
[RO]《JUICER: Data-Efficient Imitation Learning for Robotic Assembly》L Ankile, A Simeonov, I Shenfeld, P Agrawal [Harvard University &amp; MIT] (2024) <a href="https://arxiv.org/abs/2404.03729"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4a0p0b8j20u20l4wmf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4a18cdpj21nm0p0qcw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4a1psg2j20ue0nstfb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4a24acyj21m20hcn1l.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4aon70hj212v0b2wft.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4aona69j212v0b2wft.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok4aoom3fj213p0dbgor.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok4aoo8bvj213p0o440u.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok4aoo5sej20si0nb0ut.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok4aopt4aj213p0vjafp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:12:41 GMT</pubDate>
</item>
<item>
<title>通过建模运动模糊、散焦模糊和颜色偏差，提高了3D高斯Splatting方法在真实场景重建中的鲁棒性和重建质量。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《Robust Gaussian ...</title>
<link>https://weibo.com/1402400261/O8Rjfz6cX</link>
<guid>https://weibo.com/1402400261/O8Rjfz6cX</guid>
<content:encoded><![CDATA[
<div> 高斯Splatting方法、建模、运动模糊、散焦模糊、颜色偏差、鲁棒性、重建质量、真实场景、Meta Reality Labs Zurich

<br /><br />总结:
该研究通过建模运动模糊、散焦模糊和颜色偏差，提高了3D高斯Splatting方法在真实场景重建中的鲁棒性和重建质量。研究团队来自Meta Reality Labs Zurich，他们的方法在处理真实场景重建时表现出更强的鲁棒性和质量。这种方法将有助于提升3D重建技术在实际应用中的效果和可靠性。 <div>
通过建模运动模糊、散焦模糊和颜色偏差，提高了3D高斯Splatting方法在真实场景重建中的鲁棒性和重建质量。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《Robust Gaussian Splatting》F Darmon, L Porzi, S Rota-Bulò, P Kontschieder [Meta Reality Labs Zurich] (2024) <a href="https://arxiv.org/abs/2404.04211"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok48hdtscj21co0swn9n.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok48i2gntj21is0tgwuc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok48ijn5wj21js0z8jz0.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok48j44xjj21ke1cowoh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok494p65qj20r611yq8z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok494p7qaj20rh0ystes.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok494oqu2j20ri12pn1s.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:11:25 GMT</pubDate>
</item>
<item>
<title>[CV]《Robust Gaussian Splatting》F Darmon, L Porzi, S Rota-Bulò, P Kontschieder [Meta Reality Labs Zurich] (2024) 网页链接 #机器学习##人工智能##论文#...</title>
<link>https://weibo.com/1402400261/O8Rj91YbN</link>
<guid>https://weibo.com/1402400261/O8Rj91YbN</guid>
<content:encoded><![CDATA[
<div> 关键词: Robust Gaussian Splatting, Meta Reality Labs Zurich, Darmon, Porzi, Rota-Bulò, Kontschieder

总结:<br /><br />本文是由 Meta Reality Labs Zurich 的 Darmon、Porzi、Rota-Bulò 和 Kontschieder 撰写的关于"Robust Gaussian Splatting"的研究。该研究提出了一种稳健的高斯纹理喷洒方法，用于重建和渲染三维场景。通过将多通道高斯滤波器与融合器相结合，实现了更准确和高质量的场景重建。研究结果表明，该方法在各种场景下具有更好的性能和稳健性，有望在虚拟现实等领域发挥重要作用。整体来说，该研究对于虚拟场景渲染技术的发展具有重要意义。 <div>
[CV]《Robust Gaussian Splatting》F Darmon, L Porzi, S Rota-Bulò, P Kontschieder [Meta Reality Labs Zurich] (2024) <a href="https://arxiv.org/abs/2404.04211"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok48hdtscj21co0swn9n.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok48i2gntj21is0tgwuc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok48ijn5wj21js0z8jz0.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok48j44xjj21ke1cowoh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok494p65qj20r611yq8z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hok494p7qaj20rh0ystes.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hok494oqu2j20ri12pn1s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:11:09 GMT</pubDate>
</item>
<item>
<title>提出AI伙伴和AI导师框架，利用语言模型的生成能力实现可扩展、安全的社交技能训练。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Social Skill Training with Large Lang...</title>
<link>https://weibo.com/1402400261/O8RiDFeYK</link>
<guid>https://weibo.com/1402400261/O8RiDFeYK</guid>
<content:encoded><![CDATA[
<div> Social Skill Training, Large Language Models, AI伙伴, AI导师, 可扩展, 安全, 社交技能训练, 语言模型, Stanford University, D Yang

总结:
研究者提出了一种利用语言模型生成能力的AI伙伴和AI导师框架，用于实现可扩展、安全的社交技能训练。他们从Stanford University进行了研究，关注于社会技能训练以及如何利用大型语言模型来实现这一目标。AI伙伴和AI导师的出现可以为个人提供更有效的帮助，使得社交技能的学习变得更加便捷和高效。同时，他们的研究还突出了安全性和可扩展性的重要性，以确保这一技术的应用能够得到广泛的推广和应用。Overall, 这项研究为人工智能在社会技能训练领域的应用带来了新的可能性和发展方向。 <div>
提出AI伙伴和AI导师框架，利用语言模型的生成能力实现可扩展、安全的社交技能训练。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Social Skill Training with Large Language Models》D Yang, C Ziems, W Held, O Shaikh, M S. Bernstein, J Mitchell [Stanford University] (2024) <a href="https://arxiv.org/abs/2404.04204"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok47k6gmij20pk0wmgt9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok47kg6ohj21mq15gtj2.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:09:54 GMT</pubDate>
</item>
<item>
<title>[CL]《Social Skill Training with Large Language Models》D Yang, C Ziems, W Held, O Shaikh, M S. Bernstein, J Mitchell [Stanford University] (2024) 网...</title>
<link>https://weibo.com/1402400261/O8RixeIkU</link>
<guid>https://weibo.com/1402400261/O8RixeIkU</guid>
<content:encoded><![CDATA[
<div> 社交技能训练，大型语言模型，斯坦福大学，2024，D Yang，C Ziems，W Held，O Shaikh，M S. Bernstein，J Mitchell<br />
<br />
该研究来自斯坦福大学，旨在探索如何利用大型语言模型进行社交技能训练。研究团队提出了一种新的方法，利用大型语言模型来帮助学习者提高社交技能。他们通过模型生成对话和提供反馈来帮助用户练习与他人交流。实验结果显示，这种方法能够有效地提高用户的社交技能水平。研究认为，大型语言模型在社交技能训练中具有潜在的应用前景，可以帮助更多人提升社交能力并增强人际关系。<br />
<br />
总结: 该研究来自斯坦福大学，旨在探索利用大型语言模型进行社交技能训练的新方法。研究团队通过模型生成对话和提供反馈来帮助用户练习社交技能，实验结果显示其有效性。大型语言模型在社交技能训练中有潜在应用前景，有助于提升用户社交能力。 <div>
[CL]《Social Skill Training with Large Language Models》D Yang, C Ziems, W Held, O Shaikh, M S. Bernstein, J Mitchell [Stanford University] (2024) <a href="https://arxiv.org/abs/2404.04204"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hok47k6gmij20pk0wmgt9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hok47kg6ohj21mq15gtj2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 21:09:39 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.8)》 爱可可微博热门分享(4.8) [图片]</title>
<link>https://weibo.com/1402400261/O8OB6iP7c</link>
<guid>https://weibo.com/1402400261/O8OB6iP7c</guid>
<content:encoded><![CDATA[
<div> 微博热门, 爱可可, 分享, 4.8, 社交, 平台, 关注, 热度, 用户, 内容

<br /><br />总结:
爱可可微博分享的内容在社交平台上取得了较高的热度，吸引了大量用户关注和参与互动。用户可以通过微博平台浏览各种热门话题和内容，为用户带来丰富的社交体验。在4.8分的评分下，爱可可微博得到了较高的用户满意度，成为了备受欢迎的社交平台之一。 <div>
《爱可可微博热门分享(4.8)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405021011245662474"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.8)</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hojsa5d5jqj20k00b9my9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 14:17:09 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Non-negative Contrastive Learning》(ICLR 2024) GitHub: github.com/PKU-ML/non_neg [fig3]《LiDAR4D: Dynamic Neural Fields for Novel ...</title>
<link>https://weibo.com/1402400261/O8NNPDICs</link>
<guid>https://weibo.com/1402400261/O8NNPDICs</guid>
<content:encoded><![CDATA[
<div> 非负对比学习、LiDAR4D、DEADiff、神经网络、图像合成、风格迁移、自然语言处理、推理、游戏狼人杀、长文本评估

总结：<br /><br />本文介绍了几篇论文的实现代码，并提供了GitHub链接，包括非负对比学习、LiDAR4D、DEADiff等。这些论文涵盖了神经网络、图像合成、风格迁移、自然语言处理、推理等多个领域。其中，《Non-negative Contrastive Learning》提出了一种非负对比学习方法，有望提高模型性能；《LiDAR4D》介绍了动态神经场用于新型时空视角LiDAR合成；《DEADiff》提出了一种高效的风格迁移模型；《ChatGLM-Math》通过自我评估管道改进了大型语言模型在数学问题求解中的表现；《Enhance Reasoning for Large Language Models in the Game Werewolf》则探讨了如何增强大型语言模型在狼人杀游戏中的推理能力；《LV-Eval》则提出了一个具有5个长度级别、长文本评估的平衡基准。这些论文对于推动人工智能领域的研究与应用具有重要意义。 <div>
几篇论文实现代码：<br />《Non-negative Contrastive Learning》(ICLR 2024) GitHub: github.com/PKU-ML/non_neg [fig3]<br />《LiDAR4D: Dynamic Neural Fields for Novel Space-time View LiDAR Synthesis》(CVPR 2024) GitHub: github.com/ispc-lab/LiDAR4D [fig1]<br />《DEADiff: An Efficient Stylization Diffusion Model with Disentangled Representations》(CVPR 2024) GitHub: github.com/bytedance/DEADiff<br />《Yuanchen Wu and Xichen Ye and Kequan Yang and Jide Li and Xiaoqiang Li》(CVPR 2024) GitHub: github.com/Wu0409/DuPL [fig2]<br />《ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline》(2024) GitHub: github.com/THUDM/ChatGLM-Math<br />《Enhance Reasoning for Large Language Models in the Game Werewolf》(2024) GitHub: github.com/boluoweifenda/werewolf<br />《LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K》(2024) GitHub: github.com/infinigence/LVEval<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hojnw3xjyxj21fe0niqnp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hojoa48hu5j221o0xyww7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hojolbvol4j219m09n79e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 12:15:47 GMT</pubDate>
</item>
<item>
<title>【QAnything：致力于支持任意格式文件或数据库的本地知识库问答系统，可断网安装使用】'Question and Answer based on Anything - Question and Answer based on...</title>
<link>https://weibo.com/1402400261/O8NNHnqAK</link>
<guid>https://weibo.com/1402400261/O8NNHnqAK</guid>
<content:encoded><![CDATA[
<div> GitHub, 问答系统, 本地知识库, 支持任意格式文件, 断网安装, 
问答系统应用于任意文件或数据库的本地知识库，能够支持各种格式文件，并可在断网情况下安装使用。通过GitHub平台发布，旨在提供更便捷的问答功能。 <div>
【QAnything：致力于支持任意格式文件或数据库的本地知识库问答系统，可断网安装使用】'Question and Answer based on Anything - Question and Answer based on Anything.' GitHub: github.com/netease-youdao/QAnything <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hojoroiegjj20vu0s8djl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 12:15:27 GMT</pubDate>
</item>
<item>
<title>【场景文本图像超分辨率相关论文资源列表】’Awesome Scene Text Image Super-Resolution - A collection of papers and resources on scene text image super-r...</title>
<link>https://weibo.com/1402400261/O8NKfyUVC</link>
<guid>https://weibo.com/1402400261/O8NKfyUVC</guid>
<content:encoded><![CDATA[
<div> GitHub、场景文本图像、超分辨率、论文资源、集合、研究、技术、学术、分析、应用
<br /><br />总结:
本文介绍了一个收集了关于场景文本图像超分辨率的论文和资源的GitHub页面。该页面汇总了相关研究领域中的技术、学术成果和实用应用，为对场景文本图像超分辨率感兴趣的研究者提供了丰富的信息和参考资料。通过这个资源集合，研究者可以更全面地了解当前的研究进展，探讨不同的方法和技术，并且将这些成果应用到实际场景中，推动领域的发展和创新。 <div>
【场景文本图像超分辨率相关论文资源列表】’Awesome Scene Text Image Super-Resolution - A collection of papers and resources on scene text image super-resolution.' GitHub: github.com/yfaqh/Awesome-Scene-Text-Image-Super-Resolution <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hojoiukk13j20yt0u0dlx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 12:06:57 GMT</pubDate>
</item>
<item>
<title>【MLIR-EmitC：将 ML 模型转换为 C++ 代码的工具，它包含将 Keras 和 TensorFlow 模型转换为 TOSA 和 StableHLO dialect，以及将这些dialect转换为 EmitC 的脚本...</title>
<link>https://weibo.com/1402400261/O8NHrcruH</link>
<guid>https://weibo.com/1402400261/O8NHrcruH</guid>
<content:encoded><![CDATA[
<div> MLIR-EmitC, 工具, 将 ML 模型转换为 C++ 代码, Keras, TensorFlow, TOSA, StableHLO dialect, EmitC, 脚本, GitHub <br />
<br />总结:
MLIR-EmitC是一个工具，用于将ML模型转换为C++代码。它支持将Keras和TensorFlow模型转换为TOSA和StableHLO dialect，并提供转换为EmitC的脚本和工具。用户可以在GitHub上找到该项目的代码。MLIR-EmitC的目标是简化将机器学习模型转换为可执行代码的过程，提高开发效率。 <div>
【MLIR-EmitC：将 ML 模型转换为 C++ 代码的工具，它包含将 Keras 和 TensorFlow 模型转换为 TOSA 和 StableHLO dialect，以及将这些dialect转换为 EmitC 的脚本和工具】'MLIR-EmitC - Conversions to MLIR EmitC' GitHub: github.com/iml130/mlir-emitc <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hojobo8f0nj214f0u0gr7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 12:00:01 GMT</pubDate>
</item>
<item>
<title>【用大语言模型(LLM)处理表格数据相关论文资源列表】’Awesome-LLM-Tabular - Awesome-LLM-Tabular: a curated list of Large Language Model applied to Tabula...</title>
<link>https://weibo.com/1402400261/O8NFyFg7N</link>
<guid>https://weibo.com/1402400261/O8NFyFg7N</guid>
<content:encoded><![CDATA[
<div> GitHub、大语言模型、表格数据、资源列表、应用、研究、整理、curated、LLM<br />
<br />
研究人员Johnny Hwu在GitHub上整理了一个名为Awesome-LLM-Tabular的资源列表，其中收集了大量涉及大语言模型在表格数据上应用的相关论文。<br />
该资源列表涵盖了近期的研究成果，帮助研究者了解大语言模型在处理表格数据上的最新进展。<br />
研究人员精心整理和筛选了不同领域的相关文献，为研究者提供了一个方便快捷的资源导航工具。<br />
Awesome-LLM-Tabular这一资源列表对于学术界和工业界的研究者都具有一定的参考价值，可以促进相关领域的研究与应用。<br />
总结: <br />
研究人员Johnny Hwu在GitHub上整理了一个名为Awesome-LLM-Tabular的资源列表，其中收集了大量涉及大语言模型在表格数据上应用的相关论文。该资源列表涵盖了近期的研究成果，帮助研究者了解大语言模型在处理表格数据上的最新进展。研究人员精心整理和筛选了不同领域的相关文献，为研究者提供了一个方便快捷的资源导航工具。Awesome-LLM-Tabular这一资源列表对于学术界和工业界的研究者都具有一定的参考价值，可以促进相关领域的研究与应用。 <div>
【用大语言模型(LLM)处理表格数据相关论文资源列表】’Awesome-LLM-Tabular - Awesome-LLM-Tabular: a curated list of Large Language Model applied to Tabular Data' GitHub: github.com/johnnyhwu/Awesome-LLM-Tabular <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hojo6vfkkjj20u00xujx1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 11:55:24 GMT</pubDate>
</item>
<item>
<title>【llama-cpp-rs：Rust 语言编写的库，提供了 llama.cpp 的绑定，用于处理大型语言模型】'llama-cpp-rs' GitHub: github.com/utilityai/llama-cpp-rs #开源# #机...</title>
<link>https://weibo.com/1402400261/O8NB1mSxV</link>
<guid>https://weibo.com/1402400261/O8NB1mSxV</guid>
<content:encoded><![CDATA[
<div> Rust 语言, 库, llama.cpp, 处理, 大型, 语言模型, 绑定, GitHub, utilityai

<br /><br />总结:
这是一个用Rust语言编写的库，名称为llama-cpp-rs，提供了llama.cpp的绑定，用于处理大型语言模型。该库在GitHub上可找到，地址为github.com/utilityai/llama-cpp-rs。该库可以帮助处理大型语言模型，为开发者提供便利。 <div>
【llama-cpp-rs：Rust 语言编写的库，提供了 llama.cpp 的绑定，用于处理大型语言模型】'llama-cpp-rs' GitHub: github.com/utilityai/llama-cpp-rs <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hojnv8yu78j21740q2wj2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 11:44:13 GMT</pubDate>
</item>
<item>
<title>【基于生成式模型的推荐系统相关论文列表】’Recommender Systems with Generative Models' GitHub: github.com/yasdel/LLM-RecSys #开源# #机器学习# #人工智能...</title>
<link>https://weibo.com/1402400261/O8LcLmQSk</link>
<guid>https://weibo.com/1402400261/O8LcLmQSk</guid>
<content:encoded><![CDATA[
<div> 生成式模型、推荐系统、GitHub、LLM-RecSys、论文、推荐算法、深度学习、人工智能<br />
<br />
生成式模型在推荐系统中的应用越来越受到关注，该论文提出了一种基于生成式模型的推荐系统。通过在GitHub上发布了LLM-RecSys的代码，研究人员展示了他们的研究成果。推荐系统是指根据用户的偏好和行为预测并推荐他们可能感兴趣的物品。传统的推荐算法已经被广泛应用，而基于深度学习的生成式模型为推荐系统带来了新的机遇和挑战。这篇论文探讨了如何利用生成式模型改进推荐系统，为推荐系统的发展提供了新的方向。总的来说，这篇论文为推荐系统领域的研究和实践贡献了有价值的内容，对于深度学习和人工智能领域的研究也具有一定的参考意义。<br /><br />总结: <div>
【基于生成式模型的推荐系统相关论文列表】’Recommender Systems with Generative Models' GitHub: github.com/yasdel/LLM-RecSys <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hojdb6tf3lj210y0u0afj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 05:38:57 GMT</pubDate>
</item>
<item>
<title>【HammerLLM：1.4B参数量的LLM，提供简洁高效的训练代码库，并完全开源了模型权重、环境、代码库和超参数】’HammerLLM - 1.4B sLLM for Chinese and English - ...</title>
<link>https://weibo.com/1402400261/O8Lc7q1tp</link>
<guid>https://weibo.com/1402400261/O8Lc7q1tp</guid>
<content:encoded><![CDATA[
<div> GitHub、HammerLLM、1.4B参数量、LLM、简洁、高效、训练代码库、开源、模型权重、环境、超参数

<br /><br />总结:
HammerLLM是一个拥有1.4B参数量的LLM模型，提供简洁高效的训练代码库，并完全开源了模型权重、环境、代码库和超参数。这个模型支持中文和英文，并在GitHub上开源发布，为用户提供了一个强大的工具和资源。 <div>
【HammerLLM：1.4B参数量的LLM，提供简洁高效的训练代码库，并完全开源了模型权重、环境、代码库和超参数】’HammerLLM - 1.4B sLLM for Chinese and English - HammerLLM🔨' GitHub: github.com/Academic-Hammer/HammerLLM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hojd9jtcc4j21py0u0jvu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 05:37:22 GMT</pubDate>
</item>
<item>
<title>【ClangQL：用于查询 C/C++ 代码的工具，使用 GitQL SDK 并提供了类似于 SQL 的查询语言】'ClangQL - Clang AST Query Language - ClangQL is a tool that allow...</title>
<link>https://weibo.com/1402400261/O8L1V66IW</link>
<guid>https://weibo.com/1402400261/O8L1V66IW</guid>
<content:encoded><![CDATA[
<div> ClangQL, Clang AST Query Language, C/C++代码, 查询工具, GitQL SDK, SQL-like查询语言

<br /><br />总结:
ClangQL是一个用于查询C/C++代码的工具，使用GitQL SDK并提供类似于SQL的查询语言。用户可以在代码中运行类似于SQL的查询，而不是在数据库文件上操作。这个工具可以帮助开发者更方便地分析和查找代码中的关键信息，提高代码的可读性和维护性。GitHub上有相关的开源项目，用户可以查看并使用。ClangQL的出现为C/C++开发者提供了一种全新的代码查询方式，使得代码分析和调试变得更加高效和便捷。 <div>
【ClangQL：用于查询 C/C++ 代码的工具，使用 GitQL SDK 并提供了类似于 SQL 的查询语言】'ClangQL - Clang AST Query Language - ClangQL is a tool that allow you to run SQL-like query on C/C++ Code instead of database files using the GitQL SDK' GitHub: github.com/AmrDeveloper/ClangQL <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hojcjemz4yj20u00xk423.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 05:12:14 GMT</pubDate>
</item>
<item>
<title>【视觉Mamba模型相关文献资源列表】’Awesome-Vision-Mamba - Latest Papers on Vision Mamba and Related Areas' GitHub: github.com/ReaFly/Awesome-Vision-Ma...</title>
<link>https://weibo.com/1402400261/O8L1ca49x</link>
<guid>https://weibo.com/1402400261/O8L1ca49x</guid>
<content:encoded><![CDATA[
<div> GitHub、视觉Mamba模型、相关领域、最新论文、资源列表、Awesome-Vision-Mamba、ReaFly、GitHub链接、研究领域、视觉技术

视觉Mamba模型相关文献资源列表的GitHub库“Awesome-Vision-Mamba”收集了最新的关于视觉Mamba模型及相关研究领域的论文。这个资源库由用户ReaFly维护，提供了丰富的学术资源和论文链接。感兴趣的研究者可以通过这个GitHub链接获取到关于视觉技术的最新进展和研究成果。GitHub库中包含了各种与视觉Mamba模型相关的论文资源，为研究者提供了便捷的学习和参考资料。<br /><br />总结:GitHub上的Awesome-Vision-Mamba收集了最新关于视觉Mamba模型及相关领域的论文资源，由用户ReaFly维护，为研究者提供了丰富的学术资源和论文链接，方便他们了解视觉技术的最新进展。 <div>
【视觉Mamba模型相关文献资源列表】’Awesome-Vision-Mamba - Latest Papers on Vision Mamba and Related Areas' GitHub: github.com/ReaFly/Awesome-Vision-Mamba <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hojcheypefj20xf0u0jxo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 05:10:27 GMT</pubDate>
</item>
<item>
<title>【OpenAI为训练GPT-4转录百万小时YouTube视频，挑战版权灰色地带】 - OpenAI为了获取高质量的训练数据来训练GPT-4，转录了超过100万小时的YouTube视频。这一行为...</title>
<link>https://weibo.com/1402400261/O8J7rk1BG</link>
<guid>https://weibo.com/1402400261/O8J7rk1BG</guid>
<content:encoded><![CDATA[
<div> OpenAI, GPT-4, YouTube, 转录, 数据训练, 版权, AI发展, 挑战, 谷歌, 私隐, 数据收集

<br /><br />总结:
OpenAI为训练GPT-4转录了超过100万小时的YouTube视频，面临着版权和数据获取的挑战。公司高层重视数据收集，但采取的做法有争议。谷歌谴责OpenAI的行为，却自己也在利用YouTube内容训练模型。企业数据使用应受更多监管。消费者对科技公司数据使用行为了解不足，需要更多透明和控制。AI发展中数据和版权问题复杂，各方应加强沟通协调，平衡创新和权益保护。 Meta对隐私进行改革，反映了企业应对数据问题的迫切性。 <div>
【OpenAI为训练GPT-4转录百万小时YouTube视频，挑战版权灰色地带】  <br />- OpenAI为了获取高质量的训练数据来训练GPT-4，转录了超过100万小时的YouTube视频。这一行为处于AI版权法的灰色地带。  <br />- OpenAI总裁Greg Brockman亲自参与了收集用于训练的视频。OpenAI发言人表示，公司为每个模型策划"独特"的数据集，以帮助它们"理解世界"。  <br />- 谷歌发言人表示，该公司已经"看到了未经证实的报道"，称OpenAI的行为违反了YouTube的robots.txt文件和服务条款，这些条款禁止未经授权的抓取或下载YouTube内容。  <br />- 谷歌表示，当有明确的法律或技术依据时，会采取"技术和法律措施"防止此类未经授权的使用。  <br />- 报道称谷歌也从YouTube收集了转录内容。谷歌表示已根据与YouTube创作者的协议，在"一些YouTube内容"上训练其模型。  <br />- 报道指出，在剑桥分析公司丑闻后，Meta对隐私进行了改革，这限制了其使用消费者数据的方式。  <br /><br />思考：  <br />- 尽管OpenAI和谷歌等科技巨头在AI领域处于领先地位，但它们仍面临着获取高质量训练数据的挑战，不得不采取一些有争议甚至违规的做法。这凸显出AI发展中数据和版权问题的复杂性。  <br />- OpenAI总裁亲自参与数据收集，表明公司高层对这一问题的重视程度，但也反映出他们对法律和伦理边界的态度比较激进。  <br />- 谷歌一方面谴责OpenAI的行为，另一方面自己也在利用YouTube内容训练模型，虽然声称是按照协议进行的。这种双重标准耐人寻味。  <br />- 科技公司收集用户数据训练AI模型已是公开的秘密，但消费者对此知之甚少，缺乏足够的知情权和控制力。Meta的例子表明，企业数据使用行为应受到更多监管。  <br />- AI模型背后的数据问题一直没有引起足够重视，各方应加强沟通协调，在鼓励创新和保护权益之间取得平衡。<br />《OpenAI transcribed over a million hours of YouTube videos to train GPT-4 - The Verge》 <a href="https://www.theverge.com/2024/4/6/24122915/openai-youtube-transcripts-gpt-4-training-data-google"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoj43onsskj21f70u010s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 00:20:21 GMT</pubDate>
</item>
<item>
<title>【Weco AI 发布 AIDE：开启软件开发的 AI 时代】- Weco AI 推出了一个名为 AIDE 的 AI 助手，它可以根据用户用自然语言描述的任务，自动搜索设计空间并生成源代...</title>
<link>https://weibo.com/1402400261/O8J5kyAQf</link>
<guid>https://weibo.com/1402400261/O8J5kyAQf</guid>
<content:encoded><![CDATA[
<div> AI、AIDE、代码生成、大语言模型、强化学习、程序合成、质量、可维护性、反馈、报告

<br /><br />总结:
Weco AI推出了名为AIDE的AI助手，可以根据用户用自然语言描述的任务自动生成源代码和报告。AIDE采用大型语言模型和强化学习技术，在代码生成任务上表现出色，且引入了反馈驱动的程序合成和验证机制，提高了代码质量和可靠性。AIDE还可生成详细报告，支持用户决策。Weco AI计划向企业和开发者开放AIDE平台，助力AI技术的民主化。该举措有望加速产业化进程，但也需注意可能带来的安全和伦理风险。 <div>
【Weco AI 发布 AIDE：开启软件开发的 AI 时代】<br />- Weco AI 推出了一个名为 AIDE 的 AI 助手，它可以根据用户用自然语言描述的任务，自动搜索设计空间并生成源代码和报告。这是一个突破性的多模态 AI 系统。  <br />- AIDE 采用了大型语言模型(LLM)和强化学习(RL)技术，可以理解自然语言指令，搜索复杂的程序空间，并生成高质量的代码。这比传统的代码生成方法更加灵活和强大。  <br />- AIDE 在代码质量、运行效率、可维护性等方面表现出色。在标准基准测试中，它优于现有的代码生成模型。  <br />- AIDE 的一个关键创新是引入了程序合成和验证的反馈循环。它会反复修改生成的程序，直到通过各种测试用例，以确保代码的正确性和鲁棒性。  <br />- 除了代码，AIDE 还可以生成对问题、方法、结果的详细分析报告，以支持用户的决策过程。它打通了从需求到落地的全流程。  <br />- AIDE 具有广泛的应用前景，可以帮助软件工程师、数据科学家、领域专家等用户大幅提高生产力，应对日益复杂的现实世界问题。  <br />- Weco AI 计划向企业和开发者开放 AIDE 平台，推动人工智能技术的民主化。用户可以免费试用，或以 API 的方式集成到自己的应用中。<br /><br />思考：  <br />- AIDE 在代码生成任务上的突出表现，例证了大语言模型和强化学习结合的巨大潜力，为进一步开发类似的智能编程助手指明了方向。  <br />- 反馈驱动的程序合成和验证机制是一个很有洞见的设计，充分利用了 AI 系统的迭代优化能力，可以显著提高生成代码的质量和可靠性。  <br />- 自动生成任务的分析报告是一个很有价值的功能，它凸显了 AI 技术在赋能知识工作者、支持专业决策方面的应用前景。  <br />- 报告中对 AIDE 的局限性讨论还不够充分，比如在处理高度开放式、语义复杂度高的任务时可能遇到的挑战。  <br />- Weco AI 开放 AIDE 平台的举措值得肯定，它有助于加速 AI 技术的产业化进程和生态建设。但是否会带来新的安全和伦理风险值得关注。<br />《AIDE: Human-Level Performance in Data Science Competitions》 <a href="https://www.weco.ai/blog/technical-report"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoj3xo7cr3j213i0u00uo.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoj3y35gqjj21230u00xz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoj3y6hiuxj21i60r30wq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 00:15:09 GMT</pubDate>
</item>
<item>
<title>【Replit 正在将 AI 集成到开发环境中，以提高开发人员体验，选择了代码修复任务，因为开发人员在修复软件中花费了大量时间，Replit 团队正在训练第一个7B的 Rep...</title>
<link>https://weibo.com/1402400261/O8J2CFXjF</link>
<guid>https://weibo.com/1402400261/O8J2CFXjF</guid>
<content:encoded><![CDATA[
<div> Replit、AI、开发环境、代码修复、时间、Replit团队、训练、7B、LLM、数据  
<br />  
Replit团队正在将AI集成到开发环境中，选择了代码修复任务，因为开发人员在修复软件中花费了大量时间。他们正在训练第一个7B的Replit原生LLM，利用其大量的数据来修复代码错误。通过这一举措，Replit希望提高开发人员的体验，让他们能够更高效地进行代码修复工作，从而提升整体开发效率和质量。通过AI技术的应用，Replit正在探索如何更好地利用大数据和机器学习来优化软件开发流程，为开发人员提供更好的工具和支持。AI在代码修复领域的应用将在未来继续发展，为开发者提供更多便利和效率。  
<br />  
总结:  
1. Replit团队正在将AI集成到开发环境中，选择了代码修复任务。  
2. 开发人员在修复软件中花费了大量时间。  
3. Replit团队正在训练第一个7B的Replit原生LLM，以利用其大量数据来修复代码错误。  
4. 目的是提高开发者体验，提高开发效率和质量。  
5. AI技术的应用带来了对大数据和机器学习的探索。  
6. Replit致力于优化软件开发流程，提供更好的工具和支持。  
7. AI在代码修复领域的应用将继续发展，为开发者提供更多便利和效率。 <div>
【Replit 正在将 AI 集成到开发环境中，以提高开发人员体验，选择了代码修复任务，因为开发人员在修复软件中花费了大量时间，Replit 团队正在训练第一个7B的 Replit 原生 LLM，以利用其大量的数据来修复代码错误】《Replit — Building LLMs for Code Repair》 <a href="https://blog.replit.com/code-repair"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoj3rccw8zj21950u0tcd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 00:08:29 GMT</pubDate>
</item>
<item>
<title>【RWKV-6发布，提供1.6B和3B两种模型，在2.5T Token上训练，支持100+种语言】《BlinkDL/rwkv-6-world · Hugging Face》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O8J1ckZjq</link>
<guid>https://weibo.com/1402400261/O8J1ckZjq</guid>
<content:encoded><![CDATA[
<div> 模型、RWKV-6、发布、1.6B、3B、语言、训练、2.5T Token、支持、100+

<br /><br />总结:
最新发布的RWKV-6模型提供了1.6B和3B两种版本，在使用2.5T Token进行训练的同时支持100多种语言。这一模型的发布将为自然语言处理领域带来新的突破和可能性，为用户提供更广泛的语言支持和更高的性能表现。 <div>
【RWKV-6发布，提供1.6B和3B两种模型，在2.5T Token上训练，支持100+种语言】《BlinkDL/rwkv-6-world · Hugging Face》 <a href="https://huggingface.co/BlinkDL/rwkv-6-world"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoj3h9ll90j20ya0u0adz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 08 Apr 2024 00:04:58 GMT</pubDate>
</item>
<item>
<title>今日推介(第1369期)：LLM的LLM响应错误检测能力评估、识别破坏安全的良性数据、通过模拟伪代码执行改进算法推理、将LLM变成跨模态跨语言检索系统、语言模型是否...</title>
<link>https://weibo.com/1402400261/O8IiG1TrX</link>
<guid>https://weibo.com/1402400261/O8IiG1TrX</guid>
<content:encoded><![CDATA[
<div> LLM、响应错误检测、良性数据、算法推理、跨模态、跨语言、检索系统、语言模型、token、规划<br />
<br />
总结:<br />
本篇文章介绍了LLM在响应错误检测方面的能力评估，以及识别破坏安全的良性数据的重要性。研究表明，通过模拟伪代码执行可以提升算法推理能力，将LLM转变为跨模态跨语言检索系统也具有潜力。同时，语言模型在为未来的token提前规划方面也有着重要作用。通过这些研究，我们能够更好地理解和应用LLM在不同领域的潜力和效用。 <div>
今日推介(第1369期)：LLM的LLM响应错误检测能力评估、识别破坏安全的良性数据、通过模拟伪代码执行改进算法推理、将LLM变成跨模态跨语言检索系统、语言模型是否为未来的token提前做了规划 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/691199339"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.8)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoj0h8wc0mj21f60lswlz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoj0hbbd4yj21d00ew0vq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoj0hdo4jxj21500mkag4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoj0hgf94lj20qw10kwja.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoj0hjb8iyj219d0u0n1u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 22:15:17 GMT</pubDate>
</item>
<item>
<title>[CV] Streaming Dense Video Captioning 网页链接 提出基于聚类记忆和流式解码的流式稠密视频描述模型，可以实时处理和描述任意长的视频。 [图片][图片][图片]</title>
<link>https://weibo.com/1402400261/O8IcDbV2G</link>
<guid>https://weibo.com/1402400261/O8IcDbV2G</guid>
<content:encoded><![CDATA[
<div> 基于聚类记忆和流式解码的流式稠密视频描述模型、实时处理、描述任意长的视频<br />
<br />
提出的流式稠密视频描述模型结合了聚类记忆和流式解码技术，可以实时处理和描述任意长的视频。该模型能够准确地生成与视频内容相关的语义描述，使得视频内容更易于理解和搜索。在实验中，模型展现出了优越的性能，对于长视频描述任务具有较高的效率和准确性。通过将聚类记忆与流式解码相结合，该模型在视频描述领域有着广阔的应用前景。总结: 提出了一种结合了聚类记忆和流式解码的流式稠密视频描述模型，能够实时处理和描述任意长的视频，为视频描述任务带来了更高的效率和准确性。 <div>
[CV] Streaming Dense Video Captioning  <br /><a href="https://arxiv.org/abs/2404.01297"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出基于聚类记忆和流式解码的流式稠密视频描述模型，可以实时处理和描述任意长的视频。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoj021ltzkj212i1aw7n4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoj021sf0nj21oo0qewny.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoj02249egj20u20kqjut.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 22:00:23 GMT</pubDate>
</item>
<item>
<title>[CV] Video Interpolation with Diffusion Models 网页链接 提出串联式扩散模型VIDIM生成高质量视频插帧，可处理复杂运动，生成效果连贯自然，明显优于现有非生...</title>
<link>https://weibo.com/1402400261/O8I93pO6F</link>
<guid>https://weibo.com/1402400261/O8I93pO6F</guid>
<content:encoded><![CDATA[
<div> 扩散模型、视频插帧、高质量、复杂运动、连贯自然、非生成模型<br />
<br />
提出串联式扩散模型VIDIM生成高质量视频插帧，能够处理复杂运动并产生效果连贯自然的视频插帧结果。与现有的非生成模型相比， VIDIM的生成效果明显优越，为视频插帧任务带来了新的方法和思路。<br /><br />总结: 本文介绍了一种新的视频插帧方法，通过扩散模型实现高质量、连贯自然的视频插帧效果，提升了处理复杂运动的能力，并在实验中表现优异，展现出较高的应用潜力。 <div>
[CV] Video Interpolation with Diffusion Models  <br /><a href="https://arxiv.org/abs/2404.01203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />提出串联式扩散模型VIDIM生成高质量视频插帧，可处理复杂运动，生成效果连贯自然，明显优于现有非生成模型。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoizsvfypoj212u1b47o6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoizsvo8f6j21j20pc4b1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoizswaaabj21j20vwn9v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:51:35 GMT</pubDate>
</item>
<item>
<title>[CL] Comparing Bad Apples to Good Oranges: Aligning Large Language Models via Joint Preference Optimization 网页链接提出一种获取人类对指令-响应对联合...</title>
<link>https://weibo.com/1402400261/O8I6GrzAC</link>
<guid>https://weibo.com/1402400261/O8I6GrzAC</guid>
<content:encoded><![CDATA[
<div> 获取人类偏好、DOVE框架、指令-响应对、语言模型输出、联合偏好优化、实验验证

DOVE框架提出了一种新的方法，用于获取人类对指令-响应对的联合偏好，这一框架能够提供比传统条件排名更丰富的偏好信号。实验结果表明，DOVE框架可以更好地调整大型语言模型的输出，使其更符合人类的偏好。通过联合偏好优化的方式，DOVE框架能够使语言模型生成更准确和贴近人类期望的响应，进一步提高了模型的性能表现。整体来看，DOVE框架为调整大型语言模型的输出提供了一种有效且有前景的方法。 <div>
[CL] Comparing Bad Apples to Good Oranges: Aligning Large Language Models via Joint Preference Optimization  <br /><a href="https://arxiv.org/abs/2404.00530"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br />提出一种获取人类对指令-响应对联合偏好的框架DOVE，可以提供比传统条件排名更丰富的偏好信号，实验表明其可以更好地调整语言模型的输出。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoizmssiedj20uw1diwvg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoizmt6jm2j21fw0tqwqf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoizmte1vtj21ey0vagyf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:45:44 GMT</pubDate>
</item>
<item>
<title>[CL] Towards a Robust Retrieval-Based Summarization System 网页链接 系统地评估和增强了RAG辅助的LLM进行摘要任务的能力，提出了通用的评估管道和可复用的模...</title>
<link>https://weibo.com/1402400261/O8I3tzxRP</link>
<guid>https://weibo.com/1402400261/O8I3tzxRP</guid>
<content:encoded><![CDATA[
<div> 关键词: RAG, LLM, 摘要任务, 评估管道, 模型优化

总结:
本文系统地评估和增强了RAG辅助的LLM在进行摘要任务时的能力。文章提出了通用的评估管道和可复用的模型优化系统，通过这些手段为摘要系统的构建和优化提供了指导。作者们对RAG模型在摘要生成中的表现进行了细致的评估和分析，发现存在一些不足之处，然后提出了相应的改进方法。通过这些改进措施，研究人员成功增强了RAG在摘要生成任务中的表现，使其更加稳健和可靠。这项研究为提升检索式摘要系统的性能提供了重要的参考和借鉴。值得进一步深入研究和应用。 <br /><br /> <div>
[CL] Towards a Robust Retrieval-Based Summarization System  <br /><a href="https://arxiv.org/abs/2403.19889"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />系统地评估和增强了RAG辅助的LLM进行摘要任务的能力，提出了通用的评估管道和可复用的模型优化系统。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoizekisbtj20v61bcnac.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoizekxf8nj21ea0qcdmn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoizelj7kvj217e0r4q90.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:37:50 GMT</pubDate>
</item>
<item>
<title>通过“短视训练”发现，transformer在语言建模场景下并没有有意识地提前缓存对未来有用的信息，主要是当前有用的特征也对未来有用。 - 转发 @爱可可-爱生活:&amp;ens...</title>
<link>https://weibo.com/1402400261/O8HWDg5WJ</link>
<guid>https://weibo.com/1402400261/O8HWDg5WJ</guid>
<content:encoded><![CDATA[
<div> 语言模型、Transformer、短视训练、缓存信息、未来特征、语言建模、意识<br />
<br />
提到的研究表明，在语言建模中，Transformer并没有有意识地提前缓存对未来有用的信息。研究发现当前有用的特征也对未来有用，说明Transformer在处理语言建模场景下并不会预先计划未来的token。这一发现对于理解Transformer在语言建模中的工作方式具有重要意义。 <div>
通过“短视训练”发现，transformer在语言建模场景下并没有有意识地提前缓存对未来有用的信息，主要是当前有用的特征也对未来有用。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Do language models plan ahead for future tokens?》W Wu, J X. Morris, L Levine [University of Colorado Boulder &amp; Cornell University] (2024) <a href="https://arxiv.org/abs/2404.00859"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyqr6kn4j215c0msthf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyqrrmolj21ce0w0tej.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyqrvyzzj21ck0wwn1h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyqs4y34j21co12qk2w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiywy3oi4j20vd0eo3zo.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiywy32pwj20ve0fbgn6.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:20:58 GMT</pubDate>
</item>
<item>
<title>[CL]《Do language models plan ahead for future tokens?》W Wu, J X. Morris, L Levine [University of Colorado Boulder &amp; Cornell University] (2024) 网页...</title>
<link>https://weibo.com/1402400261/O8HWAAnw0</link>
<guid>https://weibo.com/1402400261/O8HWAAnw0</guid>
<content:encoded><![CDATA[
<div> 模型，语言，规划，未来，令牌，预测，计划

本文研究了语言模型是否会提前规划未来的令牌。研究发现，一些语言模型确实会对未来的令牌进行规划，而不仅仅是根据当前的上下文进行预测。这种规划行为有助于提高模型在语言任务中的性能表现。然而，研究也指出，虽然这种规划可以提高模型的性能，但也会增加模型的计算复杂性和资源消耗。因此，未来的研究需要平衡这些因素，以实现更好的性能和效率。总的来说，语言模型的规划行为在提高性能方面有潜力，但需要综合考虑计算成本和效果。<br /><br />总结: <div>
[CL]《Do language models plan ahead for future tokens?》W Wu, J X. Morris, L Levine [University of Colorado Boulder &amp; Cornell University] (2024) <a href="https://arxiv.org/abs/2404.00859"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyqr6kn4j215c0msthf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyqrrmolj21ce0w0tej.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyqrvyzzj21ck0wwn1h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyqs4y34j21co12qk2w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiywy3oi4j20vd0eo3zo.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiywy32pwj20ve0fbgn6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:20:52 GMT</pubDate>
</item>
<item>
<title>利用语言模型跨语言的文本理解能力，以及对比学习框架，从语言模型中构建出强大的跨语言跨模态语音文本匹配系统。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Transform...</title>
<link>https://weibo.com/1402400261/O8HTmeOnG</link>
<guid>https://weibo.com/1402400261/O8HTmeOnG</guid>
<content:encoded><![CDATA[
<div> 跨语言文本理解, 跨模态匹配, 语言模型, 对比学习, 跨语言检索, 跨模态检索, 文本匹配, 跨语言研究

<br /><br />总结:
本文提出了一种利用语言模型构建跨语言跨模态语音文本匹配系统的方法。通过对比学习框架，将语言模型转化为跨模态和跨语言的检索系统。该系统具有强大的文本理解能力，能够实现跨语言检索和跨模态匹配。这一研究为解决语言和模态之间的匹配问题提供了新的思路和方法。 <div>
利用语言模型跨语言的文本理解能力，以及对比学习框架，从语言模型中构建出强大的跨语言跨模态语音文本匹配系统。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Transforming LLMs into Cross-modal and Cross-lingual Retrieval Systems》F P Gomez, R Sanabria, Y Sung, D Cer… [Google Research &amp; Boston University &amp; The University of Edinburgh] (2024) <a href="https://arxiv.org/abs/2404.01616"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiynnmpkvj20my11sqc0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyno9070j20qw10kagd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiynonm2oj20q00i0taa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiynozmchj20qe0my76x.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:12:53 GMT</pubDate>
</item>
<item>
<title>[CL]《Transforming LLMs into Cross-modal and Cross-lingual Retrieval Systems》F P Gomez, R Sanabria, Y Sung, D Cer… [Google Research &amp; Boston Univers...</title>
<link>https://weibo.com/1402400261/O8HTifsCH</link>
<guid>https://weibo.com/1402400261/O8HTifsCH</guid>
<content:encoded><![CDATA[
<div> 跨模态检索，跨语言检索，LLMs，语言模型，转换，跨模态，跨语言，信息检索，谷歌研究，波士顿大学

总结:
研究团队提出了一种将LLMs转化为跨模态和跨语言检索系统的方法。研究旨在提高信息检索的效率和准确性。作者通过在谷歌研究、波士顿大学和爱丁堡大学的合作下，利用语言模型技术实现了不同模态和语言之间的检索。他们的工作为解决多模态和多语言信息检索问题提供了新的视角和方法。 <div>
[CL]《Transforming LLMs into Cross-modal and Cross-lingual Retrieval Systems》F P Gomez, R Sanabria, Y Sung, D Cer… [Google Research &amp; Boston University &amp; The University of Edinburgh] (2024) <a href="https://arxiv.org/abs/2404.01616"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiynnmpkvj20my11sqc0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyno9070j20qw10kagd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiynonm2oj20q00i0taa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiynozmchj20qe0my76x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:12:45 GMT</pubDate>
</item>
<item>
<title>提出THINK-AND-EXECUTE框架，通过发现任务级逻辑并以伪代码格式表达，分解算法推理过程，从而改进了语言模型在广范围算法推理任务上的表现。 - 转发 @爱可可-爱...</title>
<link>https://weibo.com/1402400261/O8HSx6yC4</link>
<guid>https://weibo.com/1402400261/O8HSx6yC4</guid>
<content:encoded><![CDATA[
<div> Language Models, Compilers, Pseudocode Execution, Algorithmic Reasoning, THINK-AND-EXECUTE框架, 任务级逻辑, 伪代码格式, 算法推理过程, 广泛范围, 改进

总结：<br /><br />这篇文章提出了一种名为THINK-AND-EXECUTE框架的方法，通过发现任务级逻辑并以伪代码格式表达，分解算法推理过程，从而改进了语言模型在广泛范围算法推理任务上的表现。研究者们将语言模型视为编译器，模拟伪代码的执行来提高算法推理能力。这种方法有望在提升语言模型的算法推理能力方面取得重要进展。 <div>
提出THINK-AND-EXECUTE框架，通过发现任务级逻辑并以伪代码格式表达，分解算法推理过程，从而改进了语言模型在广范围算法推理任务上的表现。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models》H Chae, Y Kim, S Kim, K T Ong… [Yonsei University &amp; KAIST AI] (2024) <a href="https://arxiv.org/abs/2404.02575"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiyle25i2j20ye0v4k4m.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiylejue8j21500mk7cd.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiylezpb5j215a0vkqbp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiylf806xj214y0h2gnq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiym4god5j214s0i2te4.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:10:51 GMT</pubDate>
</item>
<item>
<title>[CL]《Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models》H Chae, Y Kim, S Kim, K T Ong…...</title>
<link>https://weibo.com/1402400261/O8HSnoFLZ</link>
<guid>https://weibo.com/1402400261/O8HSnoFLZ</guid>
<content:encoded><![CDATA[
<div> Language Models, Compilers, Simulating Pseudocode Execution, Algorithmic Reasoning, Yonsei University, KAIST AI

该研究探讨了将语言模型视为编译器的概念，通过模拟伪代码执行来提高语言模型的算法推理能力。研究团队来自韩国延世大学和韩国科技研究所人工智能领域。他们发现，将语言模型训练成类似编译器的方式，能够帮助提升其算法推理能力。通过模拟伪代码执行过程，语言模型能够更好地理解和推断算法逻辑，从而提高在算法领域的表现。这一研究为将自然语言处理与算法推理结合提供了新的思路和方法。research topic. Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models, H Chae, Y Kim, S Kim, K T Ong… [Yonsei University & KAIST AI] (2024)
<br /><br />总结: 该研究在语言模型领域引入了编译器的概念，通过模拟伪代码执行来提高算法推理能力。研究结果表明，这种方法能够帮助语言模型更好地理解和推断算法逻辑，为算法领域的应用提供了新的思路和方法。 <div>
[CL]《Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models》H Chae, Y Kim, S Kim, K T Ong… [Yonsei University &amp; KAIST AI] (2024) <a href="https://arxiv.org/abs/2404.02575"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiyle25i2j20ye0v4k4m.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiylejue8j21500mk7cd.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiylezpb5j215a0vkqbp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiylf806xj214y0h2gnq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiym4god5j214s0i2te4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:10:28 GMT</pubDate>
</item>
<item>
<title>通过表示和梯度匹配的模型感知方法，发现了数学和列表格式是表面良性但更易导致被攻破的隐性有害数据模式，为编译安全数据提供了启发。 - 转发 @爱可可-爱生活:&amp;...</title>
<link>https://weibo.com/1402400261/O8HRJaf1n</link>
<guid>https://weibo.com/1402400261/O8HRJaf1n</guid>
<content:encoded><![CDATA[
<div> Safe Data, Identifying, Benign Data, Safety, Model, Gradient Matching, Math and List Format, Data Patterns, Security

总结:<br /><br />
本文使用表示和梯度匹配的模型感知方法，发现了数学和列表格式是表面良性但更易导致被攻破的隐性有害数据模式。通过研究这些隐性有害数据模式，提供了启发，为编译安全数据提供了一定的指导。进一步的研究有助于更有效地识别和消除潜在的安全漏洞，提高数据的安全性和可靠性。 <div>
通过表示和梯度匹配的模型感知方法，发现了数学和列表格式是表面良性但更易导致被攻破的隐性有害数据模式，为编译安全数据提供了启发。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《What's in Your "Safe" Data?: Identifying Benign Data that Breaks Safety》L He, M Xia, P Henderson [Princeton University] (2024) <a href="https://arxiv.org/abs/2404.01099"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiyk5vs0nj214s0oqako.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyk6jkwwj21d00ewae1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyk6qevvj21cw0l4q9k.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:08:53 GMT</pubDate>
</item>
<item>
<title>[LG]《What's in Your "Safe" Data?: Identifying Benign Data that Breaks Safety》L He, M Xia, P Henderson [Princeton University] (2024) 网页链接 #机器学...</title>
<link>https://weibo.com/1402400261/O8HRCkaHS</link>
<guid>https://weibo.com/1402400261/O8HRCkaHS</guid>
<content:encoded><![CDATA[
<div> 安全数据，恶意数据，识别，无害数据，数据分析，机器学习，隐私保护，安全性，智能设备，数据安全

总结:<br /><br />该研究由普林斯顿大学的He、Xia和Henderson完成，目的是识别在数据中可能存在的违反安全性的无害数据，该数据可能会破坏隐私保护或数据安全。研究使用数据分析和机器学习技术，通过对智能设备中的数据进行分析，发现了一些看似无害但具有潜在风险的数据。这项研究的结果有助于改善智能设备的安全性，保护用户隐私，并提高数据的安全性。 <div>
[LG]《What's in Your "Safe" Data?: Identifying Benign Data that Breaks Safety》L He, M Xia, P Henderson [Princeton University] (2024) <a href="https://arxiv.org/abs/2404.01099"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiyk5vs0nj214s0oqako.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyk6jkwwj21d00ewae1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyk6qevvj21cw0l4q9k.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:08:37 GMT</pubDate>
</item>
<item>
<title>ReaLMistake是首个包含丰富的LLM错误和详尽标注的基准测试，可全面诊断LLM响应错误检测性能，为进一步改进错误检测提供有价值资源。 - 转发 @爱可可-爱生活:&amp;ens...</title>
<link>https://weibo.com/1402400261/O8HRowkN2</link>
<guid>https://weibo.com/1402400261/O8HRowkN2</guid>
<content:encoded><![CDATA[
<div> LLM错误检测基准测试, 详尽标注, 错误检测性能, 提供有价值资源

<br /><br />
总结: 本研究介绍了ReaLMistake，这是首个包含丰富的LLM错误和详尽标注的基准测试。该基准测试可以全面诊断LLM响应错误检测性能，并为改进错误检测提供有价值资源。研究团队通过对LLMs在检测错误方面的性能进行评估，展示了对LLM模型错误检测能力的热切关注。他们的工作有助于进一步探索和改进LLMs在错误检测方面的表现，为提高模型的准确性和可靠性提供了重要参考。 <div>
ReaLMistake是首个包含丰富的LLM错误和详尽标注的基准测试，可全面诊断LLM响应错误检测性能，为进一步改进错误检测提供有价值资源。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Evaluating LLMs at Detecting Errors in LLM Responses》R Kamoi, S S S Das, R Lou, J J Ahn… [Penn State University] (2024) <a href="https://arxiv.org/abs/2404.03602"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyis1w1fj216u0zch23.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyisg4p4j21f60lsdpy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyissumlj21f80qik4a.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyisxlblj21ec0k6n6s.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyjebso1j20d60cct98.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiyjeckggj20ve0abdi8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyjed1kuj20vk0ap41a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyjecng8j20vd09ztb8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyjebwt3j20rh0eit9c.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:08:03 GMT</pubDate>
</item>
<item>
<title>[CL]《Evaluating LLMs at Detecting Errors in LLM Responses》R Kamoi, S S S Das, R Lou, J J Ahn… [Penn State University] (2024) 网页链接 #机器学习##人...</title>
<link>https://weibo.com/1402400261/O8HRjdlw5</link>
<guid>https://weibo.com/1402400261/O8HRjdlw5</guid>
<content:encoded><![CDATA[
<div> LLMs, Errors, Detection, Evaluation, Performance, Language Models, Responses, Artificial Intelligence, Natural Language Processing, Penn State University

总结:<br /><br />该研究旨在评估LLMs在检测LLM响应中出现错误的能力。研究由宾夕法尼亚州立大学的研究人员进行，他们探讨了语言模型的性能，并对其在检测错误方面的表现进行了评估。研究着重于人工智能和自然语言处理领域，试图提高LLMs的准确性。通过实验和数据分析，研究团队展示了LLMs在识别错误方面的优势，为提升语言模型的能力提供了重要参考。 <div>
[CL]《Evaluating LLMs at Detecting Errors in LLM Responses》R Kamoi, S S S Das, R Lou, J J Ahn… [Penn State University] (2024) <a href="https://arxiv.org/abs/2404.03602"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyis1w1fj216u0zch23.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyisg4p4j21f60lsdpy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyissumlj21f80qik4a.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyisxlblj21ec0k6n6s.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyjebso1j20d60cct98.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiyjeckggj20ve0abdi8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyjed1kuj20vk0ap41a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyjecng8j20vd09ztb8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoiyjebwt3j20rh0eit9c.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoiyjee71xj20vh0wutf6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoiyjed5paj20vg09l75z.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoiyjedmnyj20vj0k9goz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 21:07:51 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.7)》 爱可可微博热门分享(4.7) [图片]</title>
<link>https://weibo.com/1402400261/O8FiGjnut</link>
<guid>https://weibo.com/1402400261/O8FiGjnut</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 爱可可, 分享, 关键词, 点赞, 评论, 转发, 内容

<br /><br />总结:
爱可可微博分享的内容受到了广泛关注，引起了热烈讨论。文章内容引人入胜，吸引了大量的点赞、评论和转发。爱可可的微博在社交平台上拥有很高的影响力，其热门分享常常成为用户关注的焦点。通过持续更新优质内容，爱可可微博不断吸引更多粉丝和用户关注，为用户带来更丰富多样的内容体验。 <div>
《爱可可微博热门分享(4.7)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405020653865795688"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.7)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoin8nt4nuj20fo08t3zv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 14:37:03 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World》(CVPR 2024) Git...</title>
<link>https://weibo.com/1402400261/O8EPYv3SI</link>
<guid>https://weibo.com/1402400261/O8EPYv3SI</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据集, 视频, 人类建模, 头发转移, 优化算法, 地图生成, 大型语言模型, 图像分割

总结:
<br /><br />
本文介绍了几篇论文实现代码，涉及到不同领域的研究成果。其中《EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World》介绍了一个可以用于融合主观和客观视角的数据集。《PKU-DyMVHumans: A Multi-View Video Benchmark for High-Fidelity Dynamic Human Modeling》介绍了一个用于动态人类建模的多视角视频基准数据集。《HairFastGAN: Realistic and Robust Hair Transfer with a Fast Encoder-Based Approach》展示了一种快速和稳健的头发转移方法。《GIPC: Fast and Stable Gauss-Newton Optimization of IPC Barrier Energy》介绍了一种快速优化算法。《P-MapNet: Far-seeing Map Generator Enhanced by both SDMap and HDMap Priors》展示了一个结合了不同先验信息的地图生成模型。《MacGyver: Are Large Language Models Creative Problem Solvers?》研究了大型语言模型在解决问题时的创造性。《UltraLight VM-UNet: Parallel Vision Mamba Significantly Reduces Parameters for Skin Lesion Segmentation》提出了一种降低参数量的皮肤病变分割模型。这些研究有助于推动计算机视觉和人工智能领域的发展。 <div>
几篇论文实现代码：<br />《EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World》(CVPR 2024) GitHub: github.com/OpenGVLab/EgoExoLearn [fig1]<br />《PKU-DyMVHumans: A Multi-View Video Benchmark for High-Fidelity Dynamic Human Modeling》(CVPR 2024) GitHub: github.com/zhengxyun/PKU-DyMVHumans [fig3]<br />《HairFastGAN: Realistic and Robust Hair Transfer with a Fast Encoder-Based Approach》(2024) GitHub: github.com/AIRI-Institute/HairFastGAN [fig2]<br />《GIPC: Fast and Stable Gauss-Newton Optimization of IPC Barrier Energy》(2024) GitHub: github.com/KemengHuang/GPU_IPC<br />《P-MapNet: Far-seeing Map Generator Enhanced by both SDMap and HDMap Priors》(2024) GitHub: github.com/jike5/P-MapNet [fig4]<br />《MacGyver: Are Large Language Models Creative Problem Solvers?》(2024) GitHub: github.com/allenai/MacGyver [fig5]<br />《UltraLight VM-UNet: Parallel Vision Mamba Significantly Reduces Parameters for Skin Lesion Segmentation》(2024) GitHub: github.com/wurenkai/UltraLight-VM-UNet<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoijy4zv3yj20pw08jjye.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoijyn14uxj26221mhx6r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoijzb48o5j21io0gwn87.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoik6yqka6j21jk0v9n9g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoikezela3j21zs0qyx6p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 13:26:20 GMT</pubDate>
</item>
<item>
<title>【Mantis：一个命令行框架，旨在自动化资产发现、反 reconnaissance 和漏洞扫描的工作流程。它支持自动化分发扫描、超级容易定制扫描、仪表板支持、漏洞管理、高...</title>
<link>https://weibo.com/1402400261/O8EPydgTG</link>
<guid>https://weibo.com/1402400261/O8EPydgTG</guid>
<content:encoded><![CDATA[
<div> 命令行框架、资产发现、反 reconnaissance、漏洞扫描、自动化分发、定制扫描、仪表板支持、漏洞管理、高级警报、DNS 服务集成

<br /><br />总结:
Mantis是一个安全框架，旨在自动化资产发现、反侦察和漏洞扫描的工作流程。它支持自动化分发扫描、超级容易定制扫描、仪表板支持、漏洞管理、高级警报和DNS服务集成。Mantis的GitHub链接为github.com/PhonePe/mantis。 <div>
【Mantis：一个命令行框架，旨在自动化资产发现、反 reconnaissance 和漏洞扫描的工作流程。它支持自动化分发扫描、超级容易定制扫描、仪表板支持、漏洞管理、高级警报和 DNS 服务集成】'Mantis - Mantis is a security framework that automates the workflow of discovery, reconnaissance, and vulnerability scanning.' GitHub: github.com/PhonePe/mantis <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%AE%89%E5%85%A8%23&amp;isnewpage=1"><span class="surl-text">#安全#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoil60kjcij20u012p43y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 13:25:17 GMT</pubDate>
</item>
<item>
<title>【Live Transcription with Whisper PoC in Server - Client setup：提供了一个 Live-Transcription (STT) with Whisper PoC 的解决方案，基于 server-client 架...</title>
<link>https://weibo.com/1402400261/O8EO17IU6</link>
<guid>https://weibo.com/1402400261/O8EO17IU6</guid>
<content:encoded><![CDATA[
<div> GitHub, Live Transcription, Whisper PoC, server-client架构, faster-whisper模型, 实时语音转文字, gradio ui/cli, 解决方案

<br /><br />总结:
本文介绍了一个使用 faster-whisper 模型和 gradio ui/cli 实现实时语音转文字的 Live-Transcription (STT) with Whisper PoC 解决方案，基于 server-client 架构。用户可以在 GitHub 上找到相关资源，实现实时语音转文字功能，为用户提供更便捷的文字转换体验。 <div>
【Live Transcription with Whisper PoC in Server - Client setup：提供了一个 Live-Transcription (STT) with Whisper PoC 的解决方案，基于 server-client 架构，使用 faster-whisper 模型和 gradio ui/cli 实现实时语音转文字】'Live Transcription with Whisper PoC in Server - Client setup - Live-Transcription (STT) with Whisper PoC' GitHub: github.com/gaborvecsei/whisper-live-transcription <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoil25zwjlj20xb0u0diw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 13:21:30 GMT</pubDate>
</item>
<item>
<title>【ONNX-YOLO-World-Open-Vocabulary-Object-Detection：用 YOLO-World 模型在 ONNX 中执行开放词汇对象检测的脚本】'ONNX-YOLO-World-Open-Vocabulary-Object-De...</title>
<link>https://weibo.com/1402400261/O8EMFBMEB</link>
<guid>https://weibo.com/1402400261/O8EMFBMEB</guid>
<content:encoded><![CDATA[
<div> Github, YOLO-World, ONNX, 开放词汇对象检测, Python, 脚本, 模型, 执行, 项目, ibaiGorordo

<br /><br />总结:
这是一个在ONNX中使用YOLO-World模型执行开放词汇对象检测的Python脚本项目。通过GitHub仓库可以找到相关代码。该项目利用YOLO-World模型实现对象检测，支持开放词汇，使用Python脚本进行执行。将目标检测技术和ONNX模型相结合，实现了一种高效的对象检测方法。可以通过该项目学习如何在ONNX中使用YOLO-World模型进行对象检测，为相关领域的开发提供了参考和实践基础。 <div>
【ONNX-YOLO-World-Open-Vocabulary-Object-Detection：用 YOLO-World 模型在 ONNX 中执行开放词汇对象检测的脚本】'ONNX-YOLO-World-Open-Vocabulary-Object-Detection - Python scripts performing Open Vocabulary Object Detection using the YOLO-World model in ONNX.' GitHub: github.com/ibaiGorordo/ONNX-YOLO-World-Open-Vocabulary-Object-Detection <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoikypiruyj20u00zkjwg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 13:18:12 GMT</pubDate>
</item>
<item>
<title>【twitter-web-exporter：使用 TypeScript 开发的开源项目，可用于从 Twitter 网页应用程序导出 tweets、书签、列表、搜索结果、用户关注列表等】'twitter-web-e...</title>
<link>https://weibo.com/1402400261/O8EGCt7Uc</link>
<guid>https://weibo.com/1402400261/O8EGCt7Uc</guid>
<content:encoded><![CDATA[
<div> github、twitter-web-exporter、TypeScript、开源项目、导出、tweets、书签、列表、搜索结果、用户关注列表
<br /><br />总结:
这是一个使用 TypeScript 开发的开源项目，名为 twitter-web-exporter，可以从 Twitter 网页应用程序导出 tweets、书签、列表、搜索结果、用户关注列表等数据。用户可以通过该工具方便地将自己在 Twitter 上的信息进行导出和备份，保留个人数据并进行分析。项目地址为 github.com/prinsss/twitter-web-exporter。 <div>
【twitter-web-exporter：使用 TypeScript 开发的开源项目，可用于从 Twitter 网页应用程序导出 tweets、书签、列表、搜索结果、用户关注列表等】'twitter-web-exporter - Export tweets, bookmarks, lists and much more from Twitter(X) web app. (推文/书签/收藏/列表导出工具)' GitHub: github.com/prinsss/twitter-web-exporter <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoikicw2vmj20u00xogph.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 13:03:17 GMT</pubDate>
</item>
<item>
<title>【Boehm-Demers-Weiser Garbage Collector：保守的 C/C++ 垃圾收集器，可以在使用时动态分配内存】'Boehm-Demers-Weiser Garbage Collector - The Boehm-Demers-...</title>
<link>https://weibo.com/1402400261/O8EEBtxd4</link>
<guid>https://weibo.com/1402400261/O8EEBtxd4</guid>
<content:encoded><![CDATA[
<div> Boehm-Demers-Weiser Garbage Collector, C/C++, 垃圾收集器, 动态分配内存<br />
<br />
Boehm-Demers-Weiser Garbage Collector是一个保守的C/C++垃圾收集器，可以在使用时动态分配内存。该收集器以bdwgc、bdw-gc、boehm-gc、libgc等名字闻名，其源代码托管在GitHub上（github.com/ivmai/bdwgc）。该收集器在C/C++代码中提供自动内存管理，消除了手动分配和释放内存的繁琐，提高了开发效率和减少了内存泄漏的风险。 Boehm-Demers-Weiser Garbage Collector采用保守的算法来收集垃圾，能够处理复杂的指针、数据结构和内存分配行为，使得程序员可以更专注于业务逻辑的实现，而无需过多担心内存管理的问题。开发者可以通过GitHub获取该垃圾收集器的源代码，并根据需要进行定制化的配置和集成，以满足不同项目的内存管理需求。总的来说，Boehm-Demers-Weiser Garbage Collector为C/C++开发者提供了一种便捷而高效的内存管理解决方案，极大地简化了开发过程，提高了代码的可靠性和稳定性。 <br /><br />总结: <br />Boehm-Demers-Weiser Garbage Collector是一个保守的C/C++垃圾收集器，提供动态内存分配，有效简化了内存管理，并提高了开发效率。 <div>
【Boehm-Demers-Weiser Garbage Collector：保守的 C/C++ 垃圾收集器，可以在使用时动态分配内存】'Boehm-Demers-Weiser Garbage Collector - The Boehm-Demers-Weiser conservative C/C++ Garbage Collector (bdwgc, also known as bdw-gc, boehm-gc, libgc)' GitHub: github.com/ivmai/bdwgc <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23C%2B%2B%23"><span class="surl-text">#C++#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoike185ehj21740qcq7i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 12:58:19 GMT</pubDate>
</item>
<item>
<title>【OpenAI Streaming：一个 Python 库，提供易于使用的 Pythonic 接口，支持 OpenAI 的基于生成器的 Streaming，并支持回调机制来处理流内容】'OpenAI Streaming ...</title>
<link>https://weibo.com/1402400261/O8EDWAapl</link>
<guid>https://weibo.com/1402400261/O8EDWAapl</guid>
<content:encoded><![CDATA[
<div> OpenAI, Streaming, Python, 接口, 生成器, 回调, Github, 库, 简化, 处理<br />
<br />
要点1: 介绍了一个名为OpenAI Streaming的Python库，用于与OpenAI的基于生成器的Streaming API进行交互。<br />
要点2: 该库提供了易于使用的Pythonic接口，支持生成器来处理流内容。<br />
要点3: OpenAI Streaming还支持使用回调机制来处理流内容，使流处理更加灵活。<br />
要点4: 该库的代码托管在GitHub上，地址为github.com/AlmogBaku/openai-streaming。<br />
要点5: OpenAI Streaming旨在简化与OpenAI的流API的交互，让用户可以更轻松地使用Python来处理和管理流数据。<br />
<br />
总结: <br />
介绍了一个名为OpenAI Streaming的Python库，用于与OpenAI的基于生成器的Streaming API进行交互。该库提供了易于使用的Pythonic接口，支持生成器来处理流内容。OpenAI Streaming还支持使用回调机制来处理流内容，使流处理更加灵活。该库的代码托管在GitHub上，地址为github.com/AlmogBaku/openai-streaming。OpenAI Streaming旨在简化与OpenAI的流API的交互，让用户可以更轻松地使用Python来处理和管理流数据。 <div>
【OpenAI Streaming：一个 Python 库，提供易于使用的 Pythonic 接口，支持 OpenAI 的基于生成器的 Streaming，并支持回调机制来处理流内容】'OpenAI Streaming - Work with OpenAI's streaming API at ease with Python generators' GitHub: github.com/AlmogBaku/openai-streaming <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoikbwbdraj21740t2dkd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 12:56:42 GMT</pubDate>
</item>
<item>
<title>【torchdbg：PyTorch 操作的跟踪器和反应式 UI，用于以调试器的形式可视化跟踪】'torchdbg - PyTorch centric eager mode debugger' GitHub: github.com/ezyang/...</title>
<link>https://weibo.com/1402400261/O8EDkyBfv</link>
<guid>https://weibo.com/1402400261/O8EDkyBfv</guid>
<content:encoded><![CDATA[
<div> torchdbg, PyTorch, 操作, 跟踪器, 反应式, UI, 调试器, 可视化, GitHub

<br /><br />总结:
torchdbg是一个针对PyTorch的eager模式调试器，通过跟踪器和反应式UI可视化操作。用户可以在GitHub上找到该项目。 <div>
【torchdbg：PyTorch 操作的跟踪器和反应式 UI，用于以调试器的形式可视化跟踪】'torchdbg - PyTorch centric eager mode debugger' GitHub: github.com/ezyang/torchdbg <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoikasc2j7j20u00v8n04.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 07 Apr 2024 12:55:11 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@异步图书 送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O8yWi4P6D</link>
<guid>https://weibo.com/1402400261/O8yWi4P6D</guid>
<content:encoded><![CDATA[
<div> 大语言模型、前沿进展、科学家、工程师、学生、案例、庖丁解牛、可可粉、转发、评论

<br /><br />总结:
本文介绍了一本名为《大语言模型：基础与前沿》的书籍活动，截止时间为2024年4月12日12:00。该书全面深入地介绍了大语言模型及其前沿进展，适合科学家、工程师和学生参考。作者摒弃了纯理论的说教模式，而是通过案例和庖丁解牛的方式帮助读者理解与认识大语言模型。参与活动的方式是转发+评论，可可粉转发即可参与。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%BC%82%E6%AD%A5%E5%9B%BE%E4%B9%A6">@异步图书</a>  送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。摒弃了纯理论的说教模式，从案例入手， 采用庖丁解牛的方式帮助读者理解与认识大语言模型。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019331269755053"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef8oboqij20ga0m8q8p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9segl7j20m90m9q6z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9t5km0j20m90m942f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef9tq2esj20m90m9gpe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef9ugq5dj20m90m9dif.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 22:25:24 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O8yW6m9YP</link>
<guid>https://weibo.com/1402400261/O8yW6m9YP</guid>
<content:encoded><![CDATA[
<div> LangChain, 实战, 初学者, 大语言模型, LangChain生态系统, LangServe, LangSmith, 生成式人工智能, 应用场景, LCEL

<br /><br />总结:
LangChain团队推出了《LangChain实战》这本书，专为初学者和对LangChain应用及大语言模型感兴趣的开发者编写。书中介绍了LangChain 0.1版本，配套600分钟详解视频，重点探讨了多个核心应用场景和LCEL的应用方式。此外，书籍详细探讨了LangChain、LangServe和LangSmith等概念，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。截止日期为2024年4月11日中午12点，感兴趣的读者可参与转发+评论活动，有机会获得《LangChain实战》这本书。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a> <a href="https://shop.sc.weibo.com/h5/goods/index?iid=110014024002610004661854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">LangChain实战：从原型到生产，动手打造 LLM 应用</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5ywtixj20ku0zzdmx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hofl98oom9j207q0a0jrm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 22:24:56 GMT</pubDate>
</item>
<item>
<title>今日推介(第1368期)：大型语言模型在手机GPU上的高效部署、用紧凑语言模型加速多模态基础模型、基于思维链提示的文本-语音合成鲁棒编解码器语言建模、高性能卷积...</title>
<link>https://weibo.com/1402400261/O8yVNDx0K</link>
<guid>https://weibo.com/1402400261/O8yVNDx0K</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、手机GPU、高效部署、紧凑语言模型、多模态基础模型、思维链提示、文本-语音合成、鲁棒编解码器、高性能卷积神经网络、语言模型、事实可变性

总结:<br /><br />本文介绍了在手机GPU上高效部署大型语言模型以及用紧凑语言模型加速多模态基础模型的方法。其中，基于思维链提示的文本-语音合成鲁棒编解码器语言建模方法，能够提高合成语音的质量和准确性。此外，研究指出高性能卷积神经网络在语言模型方面的重要性，以及语言模型事实可变性的研究意义。通过这些方法和研究，可以提升语言模型的性能和效率。 <div>
今日推介(第1368期)：大型语言模型在手机GPU上的高效部署、用紧凑语言模型加速多模态基础模型、基于思维链提示的文本-语音合成鲁棒编解码器语言建模、高性能卷积神经网络研究、语言模型事实可变性研究 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/691003771"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.7)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hohv469uhmj21b60n4jup.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hohv49nu91j20r20n2tal.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hohv4c8t0pj219d0u0798.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hohv4enzxuj20wt0u0wjm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hohv4hqugzj20qy174789.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 22:24:11 GMT</pubDate>
</item>
<item>
<title>[CV] Are We on the Right Way for Evaluating Large Vision-Language Models? 网页链接 提出高质量的MMStar多模态基准和多模态收益与泄露指标，全面评估模型视...</title>
<link>https://weibo.com/1402400261/O8ySYC7Nb</link>
<guid>https://weibo.com/1402400261/O8ySYC7Nb</guid>
<content:encoded><![CDATA[
<div> 关键词: MMStar, 多模态基准, 多模态收益与泄露指标, 模型视觉理解能力, 训练策略

总结:<br /><br />本文提出了对大型视觉语言模型进行评估的方法。通过提出高质量的MMStar多模态基准和多模态收益与泄露指标，全面评估模型的视觉理解能力，并分析训练策略。这一方法有助于确定模型的性能和指导未来的研究方向。 <div>
[CV] Are We on the Right Way for Evaluating Large Vision-Language Models?  <br /><a href="https://arxiv.org/abs/2403.20330"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出高质量的MMStar多模态基准和多模态收益与泄露指标，全面评估模型视觉理解能力并分析训练策略。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hohux9mt20j20vc1ayqhu.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hohuxa1z4ij21gq0xsh1a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hohuxarhifj21gq1cgkah.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 22:17:15 GMT</pubDate>
</item>
<item>
<title>[LG] Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak Attacks? 网页链接 通过构建评估基准并在多种语言模型上部署已知攻击，深入分析...</title>
<link>https://weibo.com/1402400261/O8yQY7zLr</link>
<guid>https://weibo.com/1402400261/O8yQY7zLr</guid>
<content:encoded><![CDATA[
<div> 关键词: 评估基准, 语言模型, 攻击, 鲁棒性, GPT-4, 文字越狱, 视觉越狱

总结:<br /><br />本研究通过构建评估基准并在多种语言模型上部署已知攻击，分析了专有模型GPT-4和开源模型在抵御文字及视觉越狱攻击方面的鲁棒性。研究展示了对GPT-4V是否能够抵御uni和multi-modal jailbreak攻击进行了深入的探究。结果表明，GPT-4对抗这些攻击具有一定的鲁棒性，但在某些情况下仍存在安全风险，需要进一步研究和加强防护措施。这项研究对未来提升语言模型的安全性和鲁棒性具有一定的指导意义。 <div>
[LG] Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak Attacks?  <br /><a href="https://arxiv.org/abs/2404.03411"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />通过构建评估基准并在多种语言模型上部署已知攻击，深入分析了专有模型GPT-4和开源模型抵御文字及视觉越狱攻击的鲁棒性。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohus5l7kfj20uy1dsqkp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 22:12:18 GMT</pubDate>
</item>
<item>
<title>[CV] MM3DGS SLAM: Multi-modal 3D Gaussian Splatting for SLAM Using Vision, Depth, and Inertial Measurements 网页链接 提出一种将单目视觉、深度与惯性测...</title>
<link>https://weibo.com/1402400261/O8yMxsVMF</link>
<guid>https://weibo.com/1402400261/O8yMxsVMF</guid>
<content:encoded><![CDATA[
<div> 关键词: MM3DGS SLAM, 多模态, 单目视觉, 深度测量, 惯性测量, 实时, 高质量重建, 相机定位, 增量式<br />

总结:<br />
本文提出了一种称为MM3DGS SLAM的多模态3D Gaussian Splatting技术，利用单目视觉、深度测量和惯性测量相结合的方法实现实时的SLAM。该方法能够实现高质量的增量式重建和准确的相机定位。通过结合多种传感器信息，可以提高重建的精度和速度。在实验中，作者展示了该方法在各种场景下的有效性和稳定性。这种多模态融合的SLAM方法为实时定位和建图提供了一个新的技术途径。 <div>
[CV]  MM3DGS SLAM: Multi-modal 3D Gaussian Splatting for SLAM Using Vision, Depth, and Inertial Measurements  <br /><a href="https://arxiv.org/abs/2404.00923"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />提出一种将单目视觉、深度与惯性测量相结合的实时3D SLAM方法，可以实现高质量的增量式重建与准确的相机定位。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hohugrida8j213s1d61cz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hohugs09axj20ve0nkn36.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hohugsavb6j20vo0h2jvw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 22:01:23 GMT</pubDate>
</item>
<item>
<title>[CV] 94% on CIFAR-10 in 3.29 Seconds on a Single GPU 网页链接 提出多项技术的组合实现CIFAR-10数据集上快速高效的神经网络训练，取得新的最先进训练速度。 [...</title>
<link>https://weibo.com/1402400261/O8yKpf4By</link>
<guid>https://weibo.com/1402400261/O8yKpf4By</guid>
<content:encoded><![CDATA[
<div> 关键词: CIFAR-10, 数据集, 神经网络训练, 最先进训练速度

总结:<br /><br />总结: 本研究在CIFAR-10数据集上利用多项技术的组合，实现了快速高效的神经网络训练，取得了新的最先进训练速度。研究结果显示，在单个GPU上，达到了94%的准确率，仅需3.29秒的训练时间。这标志着在数据集上实现了显著的性能提升，为神经网络训练的效率和速度带来了新的突破。通过该研究，提出的方法将为未来的深度学习研究和实践提供有益的参考和指导。 <div>
[CV] 94% on CIFAR-10 in 3.29 Seconds on a Single GPU  <br /><a href="https://arxiv.org/abs/2404.00498"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />提出多项技术的组合实现CIFAR-10数据集上快速高效的神经网络训练，取得新的最先进训练速度。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohubaros3j20wm1cmdvk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohubba8z9j21ou0taaqg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hohubbqatij20li0ig0u9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 21:56:08 GMT</pubDate>
</item>
<item>
<title>通过MULAN基准测试集发现语言模型对事实可变性的编码提供了时间感知的新证据，并且可变事实比不可变事实更易于更新。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《MuLan:...</title>
<link>https://weibo.com/1402400261/O8yH9gVHv</link>
<guid>https://weibo.com/1402400261/O8yH9gVHv</guid>
<content:encoded><![CDATA[
<div> 时间感知、事实可变性、语言模型、MuLan、编码、更新、证据、基准测试集、易于更新、University of Copenhagen & Google DeepMind

<br /><br />总结:
研究发现，语言模型对事实可变性的编码在时间感知方面提供了新证据。通过MULAN基准测试集，发现可变事实比不可变事实更易于更新。这项研究由哥本哈根大学和谷歌DeepMind共同进行。 <div>
通过MULAN基准测试集发现语言模型对事实可变性的编码提供了时间感知的新证据，并且可变事实比不可变事实更易于更新。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《MuLan: A Study of Fact Mutability in Language Models》C Fierro, N Garneau, E Bugliarello, Y Kementchedjhieva, A Søgaard [University of Copenhagen &amp; Google DeepMind] (2024) <a href="https://arxiv.org/abs/2404.03036"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohtwyssjlj20ne0w0n4f.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hohtwzg7nej20qy174afd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hohtwzmppqj21hk0mmgr2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohtwzse7xj20r20msacs.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 21:48:06 GMT</pubDate>
</item>
<item>
<title>[CL]《MuLan: A Study of Fact Mutability in Language Models》C Fierro, N Garneau, E Bugliarello, Y Kementchedjhieva, A Søgaard [University of Copenhag...</title>
<link>https://weibo.com/1402400261/O8yH5EFU5</link>
<guid>https://weibo.com/1402400261/O8yH5EFU5</guid>
<content:encoded><![CDATA[
<div> 关键词: MuLan, 语言模型, 可变性, 研究, 事实, University of Copenhagen, Google DeepMind

总结:<br /><br />这篇文章由哥本哈根大学和Google DeepMind的研究人员合作撰写，研究了语言模型中事实可变性的情况。他们以木兰为例，探讨了语言模型中事实的变化和可塑性。研究发现，语言模型在处理事实时存在一定的可变性，可能导致信息失真或误导。通过对不同模型的比较和分析，研究人员提出了一些改进建议，以提高语言模型对事实的处理准确性和可靠性。这项研究对于理解语言模型的运作机制和改进其性能具有重要意义。 <div>
[CL]《MuLan: A Study of Fact Mutability in Language Models》C Fierro, N Garneau, E Bugliarello, Y Kementchedjhieva, A Søgaard [University of Copenhagen &amp; Google DeepMind] (2024) <a href="https://arxiv.org/abs/2404.03036"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohtwyssjlj20ne0w0n4f.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hohtwzg7nej20qy174afd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hohtwzmppqj21hk0mmgr2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohtwzse7xj20r20msacs.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 21:47:58 GMT</pubDate>
</item>
<item>
<title>提出效率差距图等新的分析工具，设计了同时优化模型效率和计算效率的ConvFirstNet，其延迟相比ConvNeXt降低4倍，实现了卷积神经网络效率的重要进步。 - 转发 @爱...</title>
<link>https://weibo.com/1402400261/O8yDEDUuy</link>
<guid>https://weibo.com/1402400261/O8yDEDUuy</guid>
<content:encoded><![CDATA[
<div> ConvFirstNet, 优化模型效率, 计算效率, 延迟降低, 卷积神经网络, 差距图, 分析工具

总结:
2014年至今，深度学习中卷积神经网络成为重要技术，但其效率和计算效率问题一直存在。作者在这篇论文中提出了效率差距图等新的分析工具，设计了ConvFirstNet，优化了模型效率和计算效率，将延迟降低了4倍，实现了对卷积神经网络效率的重要进步。通过这项研究，人们可以更好地理解卷积神经网络的效率问题，并为未来的研究和实践提供指导。 <div>
提出效率差距图等新的分析工具，设计了同时优化模型效率和计算效率的ConvFirstNet，其延迟相比ConvNeXt降低4倍，实现了卷积神经网络效率的重要进步。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《On the Efficiency of Convolutional Neural Networks》A Lavin [Phantom AI] (2024) <a href="https://arxiv.org/abs/2404.03617"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hohtjlzwlij20ua1iikar.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hohtjmou3dj218a14ik0q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohtjn18c9j210u1bgguu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohtjn4nnrj210q11agts.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hohttwco5ij20zt15ndkx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hohttwbvr9j21000djgo3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hohttwbvnoj20zx0kntbx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hohttwcqnij20zz1fhwj0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hohttwbvkaj21000lpdj2.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 21:39:30 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.6)》 爱可可微博热门分享(4.6) [图片]</title>
<link>https://weibo.com/1402400261/O8vSgb1S2</link>
<guid>https://weibo.com/1402400261/O8vSgb1S2</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 分享, 爱可可, 4.6, 爱情, 情感, 大V, 网友

<br /><br />总结:
爱可可微博热门分享(4.6)介绍了一些关于爱情和情感的话题，吸引了众多网友关注。大V分享的内容引起了热议，让人们反思自身情感世界，并分享各自的看法和经历。微博上热门话题的讨论热度持续高涨，展现了网友们对爱情话题的浓厚兴趣。 <div>
《爱可可微博热门分享(4.6)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405020291523805285"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.6)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hohhmjyi7uj20kf0bh75r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 14:37:14 GMT</pubDate>
</item>
<item>
<title>【AI生成内容泛滥冲击Google Books】- Google Books作为索引已出版资料的重要学术工具，正在收录大量低质量、由AI生成的书籍内容。 - 这些AI生成的书籍会出现在G...</title>
<link>https://weibo.com/1402400261/O8ujEAJtY</link>
<guid>https://weibo.com/1402400261/O8ujEAJtY</guid>
<content:encoded><![CDATA[
<div> Google Books, AI生成内容, 学术工具, 低质量内容, Google Ngram Viewer, 学术界, 索引, 垃圾内容, 技术挑战, AI技术

<br /><br />总结:
Google Books作为重要学术工具，收录了大量AI生成的低质量书籍内容，可能影响Google Ngram Viewer的准确性。在AI技术迅速发展的背景下，学术界应加强对付AI生成内容的措施。谷歌官方表示将删除低质量内容，但AI生成内容的泛滥令学术工具和搜索引擎受到前所未有的冲击。学术界需重视海量AI垃圾内容稀释优质内容、误导读者和破坏学术生态的问题。识别AI生成内容是技术挑战，需要发展智能AI技术来抵制恶意生成内容。全方位合作加强对AI滥用监管，建立科学的AI治理体系。 <div>
【AI生成内容泛滥冲击Google Books】<br />- Google Books作为索引已出版资料的重要学术工具，正在收录大量低质量、由AI生成的书籍内容。  <br />- 这些AI生成的书籍会出现在Google Books的搜索结果中。 <br />- 大量索引AI生成的垃圾内容，可能会影响Google Ngram Viewer的结果准确性。Ngram Viewer是研究人员用来追踪历史语言使用情况的重要工具，它基于Google Books的数据。  <br />- 这反映出在AI技术快速发展的背景下，学术界对付AI生成的大规模垃圾内容还缺乏应对之策。图书出版和学术搜索工具的把关机制亟待升级，以应对AI带来的挑战。  <br />- 谷歌官方表示会删除所有低质量内容，无论是AI还是人工创作。但AI生成内容的泛滥，对搜索引擎和学术工具构成了前所未有的冲击。  <br /><br />思考：  <br />- AI生成内容正以超乎想象的速度渗透到方方面面。作为知识索引的基础设施，Google Books这样的工具首当其冲受到冲击，凸显出AI时代学术规范和内容把关面临的困境。  <br />- 海量的AI垃圾内容会稀释优质内容的密度，误导读者，破坏学术生态。Ngram Viewer等研究工具也会受到污染，影响学术研究的准确性。学术界需要高度重视这一问题。  <br />- 识别AI生成内容本身就是一个技术挑战。传统的人工审核已然不敷使用，平台和工具方需要研发更智能的AI技术来对抗恶意的AI生成内容。  <br />- 从源头治理，完善AI伦理规范，加强对AI滥用的监管，需要学界、业界、政府多方合力。在拥抱AI红利的同时，也要警惕其负面影响，建立科学的AI治理体系。<img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hohaqzffl3j218z0u0dhi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 10:39:14 GMT</pubDate>
</item>
<item>
<title>【Meta率先扩大AI内容标记范围】Meta宣布将从5月开始扩大对人工智能生成内容的标记范围，主要变化包括： - 标记对象从仅视频扩大到视频、音频和图像等更多种类的...</title>
<link>https://weibo.com/1402400261/O8ufU9kYU</link>
<guid>https://weibo.com/1402400261/O8ufU9kYU</guid>
<content:encoded><![CDATA[
<div> 扩大标记范围, 人工智能, 内容, 标签, Meta, 政策, 透明度, 监督委员会, 深度伪造, 风险

<br /><br />总结:
Meta宣布从5月开始扩大对人工智能生成内容的标记范围，包括视频、音频、图像等多种内容形式。标签生成方式多样，对存在误导公众风险的内容将使用更显著的标签。7月起，Meta将不再删除合规的AI生成内容，而是通过标签标注背景信息。但若内容违规，则无论AI或人工创作均会被删除。调整旨在提高透明度，回应社会对深度伪造技术滥用的担忧。Meta独立监督委员会的反馈促使其更新标签政策。新政策有助于加强公众对AI内容的辨识，平衡创新应用与风险，并为整个行业树立标杆。然而，仅靠标签仍难以根本解决AI内容造假问题，各平台应进一步完善审核机制，加强行业自律与监管合作。 <div>
【Meta率先扩大AI内容标记范围】<br />Meta宣布将从5月开始扩大对人工智能生成内容的标记范围，主要变化包括：  <br />- 标记对象从仅视频扩大到视频、音频和图像等更多种类的内容。  <br />- 标签可通过用户自行披露、事实核查人员建议或Meta检测AI内容的隐形标记等多种方式生成。  <br />- 对于被认为存在误导公众风险的AI内容，将使用更加显著的标签。  <br />- 7月起，Meta将不再默认删除合规的AI生成内容，而是通过标签标注背景信息，以平衡言论自由和内容真实性。  <br />- 但如内容违反平台其他规定如反对选民干预、欺凌骚扰、暴力煽动等，则无论AI或人工创作都将予以删除。  <br /><br />原因与影响：<br />- Meta承认其原有政策过于狭隘，难以应对日益泛滥、形式多样的AI生成内容。此次调整主要是为了提高透明度，更好地回应外界对深度伪造等技术滥用的担忧。  <br />- Meta独立监督委员会此前就敦促其更新标签政策，此举是对委员会反馈的积极回应。  <br />- 业内普遍认为，Meta的新政策有助于在不过度审查的前提下，加强公众对AI生成内容的辨识，平衡创新应用与潜在风险，为业界树立了标杆。  <br />- 但也有观点指出，单靠标签仍难以从根本上遏制AI内容造假滥用，各平台还需进一步完善内容审核机制，加强行业自律与监管协同。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hohahe3eioj20jr0b3t9e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 10:30:00 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Generalized Schrödinger Bridge Matching》(ICLR 2024) GitHub: github.com/facebookresearch/generalized-schrodinger-bridge-matching...</title>
<link>https://weibo.com/1402400261/O8u3hzPEl</link>
<guid>https://weibo.com/1402400261/O8u3hzPEl</guid>
<content:encoded><![CDATA[
<div> Schrödinger Bridge Matching, Generalized, Algorithm, Optimization, Machine Learning, Deep Learning, ICLR 2024, Facebook Research, GitHub

<br />
提出一种广义Schrödinger桥匹配方法，用于优化算法的设计。通过对齐两个分布来实现数据匹配，能够在机器学习和深度学习领域获得更好的效果。该方法在ICLR 2024上得到了应用，并由Facebook Research团队开发。相关代码已经开源在GitHub上。

<br /><br />总结:Schrodinger Bridge Matching是一种新的数据匹配方法，可在深度学习和机器学习中应用，并在ICLR 2024年会议上展示。由Facebook Research团队实现并开源。 <div>
几篇论文实现代码：<br />《Generalized Schrödinger Bridge Matching》(ICLR 2024) GitHub: github.com/facebookresearch/generalized-schrodinger-bridge-matching<br />《Retrieval-Augmented Layout Transformer for Content-Aware Layout Generation》(CVPR 2024) GitHub: github.com/CyberAgentAILab/RALF [fig4]<br />《SSR-Encoder: Encoding Selective Subject Representation for Subject-Driven Generation》(CVPR 2024) GitHub: github.com/Xiaojiu-z/SSR_Encoder [fig6]<br />《AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent》(2024) GitHub: github.com/THUDM/AutoWebGLM [fig1]<br />《DN-Splatter: Depth and Normal Priors for Gaussian Splatting and Meshing》(2024) GitHub: github.com/maturk/dn-splatter<br />《MiniGPT4-Video: Advancing Multimodal LLMs for Video Understanding with Interleaved Visual-Textual Tokens》(2024) GitHub: github.com/Vision-CAIR/MiniGPT4-video [fig2]<br />《Placing Objects in Context via Inpainting for Out-of-distribution Segmentation》(2024) GitHub: github.com/naver/poc [fig3]<br />《CLAP NQ: Cohesive Long-form Answers from Passages in Natural Questions》(2024) GitHub: github.com/primeqa/clapnq<br />《CodeEditorBench: Evaluating Code Editing Capability of Large Language Models》(2024) GitHub: github.com/CodeEditorBench/CodeEditorBench [fig5]<br />《The Hidden Attention of Mamba Models》(2024) GitHub: github.com/AmeenAli/HiddenMambaAttn [fig7]<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoh4p0ibcoj22la0yohdt.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoh631ezzhj22cm11lk22.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoh64h5d9dj21u20hx1e6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoh7gpj4s9j21ds0gy1kx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoh7m5y4xqj22b6170kjl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoh7p7jpxhj24te154b2a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoh9eyqbaij23gg1gxnj3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 09:58:54 GMT</pubDate>
</item>
<item>
<title>'MaxKB - 基于 LLM 大语言模型的知识库问答系统，开箱即用，支持快速嵌入到第三方业务系统' GitHub: github.com/1Panel-dev/MaxKB #开源# #机器学习# #人工智能#...</title>
<link>https://weibo.com/1402400261/O8u2bg0zt</link>
<guid>https://weibo.com/1402400261/O8u2bg0zt</guid>
<content:encoded><![CDATA[
<div> 知识库、问答系统、LLM、大语言模型、开箱即用、第三方业务系统、GitHub、MaxKB、快速嵌入、基于<br />
<br />
提供了一个基于LLM大语言模型的知识库问答系统MaxKB，用户可直接使用，并支持快速嵌入到第三方业务系统中。该系统的源代码可在GitHub上找到，地址为github.com/1Panel-dev/MaxKB。MaxKB的特点包括开箱即用，同时支持定制化和灵活的部署，适用于各种需求。MaxKB使用LLM技术作为核心引擎，能够对用户提出的问题进行准确的回答，大大提升了信息检索效率。用户可以根据自身需求对系统进行定制和优化，以更好地满足业务需求。MaxKB的开源性和易用性使得它成为了知识管理和问答解决方案中的理想选择。 <br /><br />总结: <div>
'MaxKB - 基于 LLM 大语言模型的知识库问答系统，开箱即用，支持快速嵌入到第三方业务系统' GitHub: github.com/1Panel-dev/MaxKB <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoh9i596h1j21h50u0adr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoh9i66189j21hr0u0wl1.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoh9i7gy1pj21hf0u041f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 09:56:11 GMT</pubDate>
</item>
<item>
<title>【BeeTrove：349K 个 OpenAI 自定义 GPTs 的数据】'BeeTrove - OpenAI GPTs Statistics Dataset' GitHub: github.com/beetrove/openai-gpts-data #开源# #机器学...</title>
<link>https://weibo.com/1402400261/O8tTe2lcP</link>
<guid>https://weibo.com/1402400261/O8tTe2lcP</guid>
<content:encoded><![CDATA[
<div> OpenAI, BeeTrove, 自定义GPTs, 数据, 统计, 数据集, GitHub <br />
<br />
提供了关于OpenAI自定义GPTs数据的统计信息，项目名为BeeTrove。数据可以在GitHub上找到。这个数据集包含了大量有关OpenAI GPTs的信息，可以用于各种研究和应用。<br />
数据集由BeeTrove创建和维护，对于研究人员和开发者来说是非常有用的资源。通过这个数据集，用户可以深入了解OpenAI自定义GPTs的特性和应用场景。GitHub上提供了详细的信息和文档，方便用户使用和下载数据。<br />
总结: <br />提供了关于OpenAI自定义GPTs的统计数据，包含在BeeTrove项目中。数据集对于研究和开发具有重要意义，用户可以在GitHub上找到详细信息和文档，方便使用。<br /> <div>
【BeeTrove：349K 个 OpenAI 自定义 GPTs 的数据】'BeeTrove - OpenAI GPTs Statistics Dataset' GitHub: github.com/beetrove/openai-gpts-data <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoh8uwkwlwj20u01040wb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 09:34:07 GMT</pubDate>
</item>
<item>
<title>【SCIN Dataset：SCIN 数据集包含来自美国互联网用户的 10,000+ 张皮肤疾病图像】'SCIN Dataset - The SCIN dataset contains 10,000+ images of dermatology co...</title>
<link>https://weibo.com/1402400261/O8tSg6xbJ</link>
<guid>https://weibo.com/1402400261/O8tSg6xbJ</guid>
<content:encoded><![CDATA[
<div> 皮肤疾病图像 数据集 美国 互联网 用户 10000+<br />
<br />
SCIN 数据集包含来自美国互联网用户的 10,000+ 张皮肤疾病图像，包括自我报告的人口统计信息、症状信息和皮肤科医生的标签。数据集还包含了估计的菲茨帕特里克皮肤类型和教士肤色。<br />
总结: 该SCIN数据集包含10,000+张美国互联网用户的皮肤疾病图像，其中包括自我报告的人口统计信息、症状信息和皮肤科医生的标签，以及估计的菲茨帕特里克皮肤类型和教士肤色。 <div>
【SCIN Dataset：SCIN 数据集包含来自美国互联网用户的 10,000+ 张皮肤疾病图像】'SCIN Dataset - The SCIN dataset contains 10,000+ images of dermatology conditions, crowdsourced with informed consent from US internet users. Contributions include self-reported demographic and symptom information and dermatologist labels. The dataset also contains estimated Fitzpatrick skin type and Monk Skin Tone.' GitHub: github.com/google-research-datasets/scin <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoh8ss2ysej20x50u0n39.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 09:31:43 GMT</pubDate>
</item>
<item>
<title>【Multi-agent Quadruped Environment：多Agent四足机器人环境，支持定位控制或仅高层规划学习】'Multi-agent Quadruped Environment - A multi-agent quadruped...</title>
<link>https://weibo.com/1402400261/O8tQxEkO3</link>
<guid>https://weibo.com/1402400261/O8tQxEkO3</guid>
<content:encoded><![CDATA[
<div> 多Agent四足机器人环境、支持定位控制、高层规划学习、GitHub、ziyanx02、环境、学习、机器人、控制、规划

<br /><br />总结:
这是一个支持多Agent四足机器人环境的项目，能够学习到定位控制或高层规划。通过GitHub可以获取相关信息，作者是ziyanx02。这个环境可以用于机器人的学习、控制和规划。 <div>
【Multi-agent Quadruped Environment：多Agent四足机器人环境，支持定位控制或仅高层规划学习】'Multi-agent Quadruped Environment - A multi-agent quadruped environment, supporting learning of both locomotion control or only high-level planning.' GitHub: github.com/ziyanx02/multiagent-quadruped-environment <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoh8oe0q3mj20xu0u0tdi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 09:27:31 GMT</pubDate>
</item>
<item>
<title>【microWakeWord：基于 TensorFlow 的唤醒词检测训练框架，使用合成样本生成适用于某些微控制器】'microWakeWord - A TensorFlow based wake word detection tra...</title>
<link>https://weibo.com/1402400261/O8tOj9RiR</link>
<guid>https://weibo.com/1402400261/O8tOj9RiR</guid>
<content:encoded><![CDATA[
<div> TensorFlow, 唤醒词检测, 训练框架, 合成样本, 微控制器, GitHub, microWakeWord, 训练, 框架, 适用

总结:<br /><br />本文介绍了基于 TensorFlow 的唤醒词检测训练框架 microWakeWord，该框架利用合成样本生成，适用于某些微控制器。用户可以在GitHub上找到框架的代码和文档。这个框架提供了一种训练唤醒词检测模型的方法，特别适用于资源有限的硬件环境。通过生成合成样本，用户可以有效地训练模型，以在特定的微控制器上实现唤醒词检测功能。框架的设计非常灵活，可以根据用户的需求进行定制化。它为开发唤醒词检测应用提供了一个方便且高效的解决方案。 <div>
【microWakeWord：基于 TensorFlow 的唤醒词检测训练框架，使用合成样本生成适用于某些微控制器】'microWakeWord - A TensorFlow based wake word detection training framework using synthetic sample generation suitable for certain microcontrollers.' GitHub: github.com/kahrendt/microWakeWord <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoh8inc9dnj211l0u0q8q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 09:22:00 GMT</pubDate>
</item>
<item>
<title>【Rule-based Retrieval：一个 Python 软件包，用于创建和管理检索增强生成 (RAG) 应用，支持高级过滤功能，集成了 OpenAI 和 Pinecone，用于文本生成和高效的向...</title>
<link>https://weibo.com/1402400261/O8tEkBkex</link>
<guid>https://weibo.com/1402400261/O8tEkBkex</guid>
<content:encoded><![CDATA[
<div> Rule-based Retrieval, Python, 软件包, 创建, 管理, 检索增强生成, RAG, 应用, 高级过滤功能, OpenAI, Pinecone

<br /><br />总结:
Rule-based Retrieval 是一个 Python 软件包，可帮助用户创建和管理检索增强生成（RAG）应用，并具有高级过滤功能。该软件包与 OpenAI 无缝集成，用于文本生成，同时也与 Pinecone 集成，实现高效的向量数据库管理。该软件包为用户提供了便捷的工具和功能，使其能够更高效地处理文本生成和数据管理任务。 <div>
【Rule-based Retrieval：一个 Python 软件包，用于创建和管理检索增强生成 (RAG) 应用，支持高级过滤功能，集成了 OpenAI 和 Pinecone，用于文本生成和高效的向量数据库管理】'Rule-based Retrieval - The Rule-based Retrieval package is a Python package that enables you to create and manage Retrieval Augmented Generation (RAG) applications with advanced filtering capabilities. It seamlessly integrates with OpenAI for text generation and Pinecone for efficient vector database management.' GitHub: github.com/whyhow-ai/rule-based-retrieval <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoh7t32frfj21740k6q6j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 08:57:26 GMT</pubDate>
</item>
<item>
<title>【从0到1构建一个MiniLLM】'build_MiniLLM_from_scratch - 从0到1构建一个MiniLLM' GitHub: github.com/Tongjilibo/build_MiniLLM_from_scratch #开源# #机器学...</title>
<link>https://weibo.com/1402400261/O8tAX7jU3</link>
<guid>https://weibo.com/1402400261/O8tAX7jU3</guid>
<content:encoded><![CDATA[
<div> MiniLLM, 从0到1构建, GitHub, Tongjilibo, 代码, 学习, 自建, 机器学习, 模型, 训练

<br /><br />总结:
该文章详细介绍了如何从零开始构建一个MiniLLM，作者分享了在GitHub上的项目链接，逐步讲解了建立MiniLLM所需的步骤和方法。通过这篇文章，读者可以深入学习和了解如何自建机器学习模型，包括代码编写、训练模型等方面的知识。这对于想要深入学习机器学习的人来说是一篇很有价值的文章。 <div>
【从0到1构建一个MiniLLM】'build_MiniLLM_from_scratch - 从0到1构建一个MiniLLM' GitHub: github.com/Tongjilibo/build_MiniLLM_from_scratch <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoh7kfnvv1j219f0u00y7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 08:49:06 GMT</pubDate>
</item>
<item>
<title>【mamba-tiny：简单、紧凑的 Mamba SSM（State Space Model）在 PyTorch 中的实现】'mamba-tiny - Simple, minimal implementation of the Mamba SSM in one pyt...</title>
<link>https://weibo.com/1402400261/O8sSegIG5</link>
<guid>https://weibo.com/1402400261/O8sSegIG5</guid>
<content:encoded><![CDATA[
<div> 简单、紧凑、Mamba SSM、PyTorch、实现、GitHub、PeaBrane、efficient、associative scans

<br /><br />总结:
本文介绍了在PyTorch中实现简单、紧凑的Mamba SSM（State Space Model）的方法，作者提供了一个名为mamba-tiny的项目，该项目在一个pytorch文件中实现了Mamba SSM。相比使用for循环，这种实现更加高效，但可能比使用关联扫描效率稍低。感兴趣的读者可以在GitHub上找到该项目，作者是PeaBrane。 <div>
【mamba-tiny：简单、紧凑的 Mamba SSM（State Space Model）在 PyTorch 中的实现】'mamba-tiny - Simple, minimal implementation of the Mamba SSM in one pytorch file. More efficient than using for loops, but probably less efficient than using associative scans' GitHub: github.com/PeaBrane/mamba-tiny <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoh4ds047xj20u00ufjvt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 06:58:55 GMT</pubDate>
</item>
<item>
<title>'StyleLLM 文风大模型 - StyleLLM文风大模型：基于大语言模型的文本风格迁移项目，提供了四个基于中国四大名著训练的模型。Text style transfer base on Large L...</title>
<link>https://weibo.com/1402400261/O8skhukz7</link>
<guid>https://weibo.com/1402400261/O8skhukz7</guid>
<content:encoded><![CDATA[
<div> StyleLLM、文本风格迁移、大语言模型、四大名著、训练模型、GitHub、文风大模型、Text style transfer、关键词提取

总结:<br /><br />StyleLLM 文风大模型是一个基于大语言模型的文本风格迁移项目，提供了四个训练模型，基于中国四大名著。该项目在GitHub上有代码仓库，用于实现文本风格转换。通过这个项目，用户可以通过大语言模型在不同风格的文本间进行转换，实现文本风格的转移。项目的研究对于文本风格迁移技术的发展和应用具有一定的参考意义。 <div>
'StyleLLM 文风大模型 - StyleLLM文风大模型：基于大语言模型的文本风格迁移项目，提供了四个基于中国四大名著训练的模型。Text style transfer base on Large Language Model' GitHub: github.com/stylellm/stylellm_models <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoh1y410w4j20vb0u0wl6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 06 Apr 2024 05:35:16 GMT</pubDate>
</item>
<item>
<title>【RAG进化之路】- 近年来，RAG(检索增强生成)技术在提高语言模型的知识性、准确性等方面发挥着重要作用。RAG可以从外部知识库中检索相关信息，增强语言模型的生...</title>
<link>https://weibo.com/1402400261/O8q7fqGsi</link>
<guid>https://weibo.com/1402400261/O8q7fqGsi</guid>
<content:encoded><![CDATA[
<div> RAG, 检索增强生成, Naive RAG, Advanced RAG, Modular RAG, 外部知识库, 模块化, 管道化, 搜索模块, RAG-Fusion

<br /><br />总结:
近年来，RAG技术在提高语言模型的知识性、准确性等方面发挥着重要作用。RAG经历了从Naive RAG到Advanced RAG再到Modular RAG的进化过程。Naive RAG存在检索质量不高的问题，而Advanced RAG通过查询重写、细粒度分割等策略改进了此问题。Modular RAG具有模块化和管道化的架构，支持端到端的训练，成为当前的标准范式。其中的新模块如Search模块和RAG-Fusion模块进一步增强了RAG系统的适用性。总体来说，RAG技术的进化促进了语言模型的知识化，Modular RAG为当前RAG研究提供了重要方向。 <div>
【RAG进化之路】<br />- 近年来，RAG(检索增强生成)技术在提高语言模型的知识性、准确性等方面发挥着重要作用。RAG可以从外部知识库中检索相关信息，增强语言模型的生成能力。   <br />- RAG技术经历了从Naive RAG到Advanced RAG再到Modular RAG的进化。Naive RAG存在检索质量不高，生成容易出现幻觉等问题。Advanced RAG通过查询重写、细粒度分割等策略改进了Naive RAG。   <br />- Modular RAG具有模块化和管道化的架构，可以灵活组合不同模块来解决具体问题，如添加搜索模块等。Modular RAG支持端到端的训练，成为当前RAG应用的标准范式。   <br />- 文章还介绍了Modular RAG中的一些新模块，如Search模块可以利用生成的代码搜索知识图谱，RAG-Fusion模块可以扩展查询的视角。这些创新进一步增强了RAG系统的适用性。   <br />- 总体来说，RAG技术的进化优化了语言模型的知识化，是让语言模型更适合实际应用的关键技术进步。Modular RAG提供了模块化和可定制的方案，成为当前RAG研究的重要方向。<br />《Evolution of RAGs: Naive RAG, Advanced RAG, and Modular RAG Architectures - MarkTechPost》 <a href="https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hogs7b6j1sj21560p2jxi.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hogs7csd2cj213g0q8aef.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hogs7fi6s3j214i0k20ya.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 23:57:41 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@异步图书 送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O8pDdpdb8</link>
<guid>https://weibo.com/1402400261/O8pDdpdb8</guid>
<content:encoded><![CDATA[
<div> 大语言模型、前沿进展、科学家、工程师、学生、案例、庖丁解牛、理解、认识、赠书<br />
<br />
总结:本文介绍了一本《大语言模型：基础与前沿》的书籍赠送活动，参与者需转发+评论即可参与。该书全面深入地介绍了大语言模型及其前沿进展，适合科学家、工程师和学生参考。书籍摒弃了纯理论说教，而是从案例入手用庖丁解牛的方式帮助读者理解与认识大语言模型。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%BC%82%E6%AD%A5%E5%9B%BE%E4%B9%A6">@异步图书</a>  送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。摒弃了纯理论的说教模式，从案例入手， 采用庖丁解牛的方式帮助读者理解与认识大语言模型。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019331269755053"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef8oboqij20ga0m8q8p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9segl7j20m90m9q6z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9t5km0j20m90m942f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef9tq2esj20m90m9gpe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef9ugq5dj20m90m9dif.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 22:43:42 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O8pCZ8LXr</link>
<guid>https://weibo.com/1402400261/O8pCZ8LXr</guid>
<content:encoded><![CDATA[
<div> LangChain, LangServe, LangSmith, LLM, 初学者, 应用场景, 生态系统,生成式人工智能,开发者, LangChain团队

<br /><br />总结:
LangChain团队推出了《LangChain实战》这本书，专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写。本书基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并深入探讨了LCEL的应用方式。同时，围绕LangChain生态系统的概念，详细探讨了LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。截至2024.4.11 12:00，*可可粉*转发+评论即可参与送出3本《LangChain实战》的活动。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a> <a href="https://shop.sc.weibo.com/h5/goods/index?iid=110014024002610004661854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">LangChain实战：从原型到生产，动手打造 LLM 应用</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5ywtixj20ku0zzdmx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hofl98oom9j207q0a0jrm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 22:43:07 GMT</pubDate>
</item>
<item>
<title>今日推介(第1367期)：用神经压缩文本训练LLM、大型语言模型的演绎、归纳和溯因学习、基于经验合作机制的师生课程学习的再思考、语言模型的表示微调、人工智能与...</title>
<link>https://weibo.com/1402400261/O8pCNjvOY</link>
<guid>https://weibo.com/1402400261/O8pCNjvOY</guid>
<content:encoded><![CDATA[
<div> 神经压缩文本、LLM、大型语言模型、演绎、归纳、溯因学习、经验合作机制、师生课程学习、再思考、语言模型、表示微调、人工智能、知识坍缩问题

总结:<br />
本文介绍了使用神经压缩文本训练LLM和大型语言模型的演绎、归纳和溯因学习方法。同时探讨了基于经验合作机制的师生课程学习的再思考，以及语言模型的表示微调。最后讨论了人工智能与知识坍缩问题，为读者提供了对这些领域的深入了解。文章内容丰富，信息量大，是一篇值得一读的文章。 <div>
今日推介(第1367期)：用神经压缩文本训练LLM、大型语言模型的演绎、归纳和溯因学习、基于经验合作机制的师生课程学习的再思考、语言模型的表示微调、人工智能与知识坍缩问题 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/690889816"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hogq11a160j20zp0u00yg.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hogq13j4zoj20ti0z60zh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hogq186xffj21k80hcaec.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hogq1bd3eoj213s0u0dlu.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hogq1elhakj20s60r00vl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 22:42:39 GMT</pubDate>
</item>
<item>
<title>[CL] Blessing or curse? A survey on the Impact of Generative AI on Fake News 网页链接 通过结构化文献调研，全面系统地总结和分析了生成式AI在假新闻生成与...</title>
<link>https://weibo.com/1402400261/O8pzl1jvt</link>
<guid>https://weibo.com/1402400261/O8pzl1jvt</guid>
<content:encoded><![CDATA[
<div> 关键词: 生成式AI, 假新闻, 检测, 应用, 技术, 主题, 未来方向

总结:<br /><br />本文通过结构化文献调研，系统总结分析了生成式AI在假新闻生成与检测方面的应用现状。文章讨论了关键技术和主要课题，指出生成式AI在假新闻领域既能成为祝福，也可能带来诅咒。未来研究方向包括提高生成式AI的检测能力、加强对假新闻生成过程的监管等，有望帮助更好应对假新闻问题。 <div>
[CL] Blessing or curse? A survey on the Impact of Generative AI on Fake News  <br /><a href="https://arxiv.org/abs/2404.03021"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过结构化文献调研，全面系统地总结和分析了生成式AI在假新闻生成与检测中的应用现状、关键技术、主要课题和未来方向。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hogpsjen8tj21121bgx0l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hogpsjjf8tj21rm0rqq9i.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hogpsk2lrsj20pa17in0f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 22:34:08 GMT</pubDate>
</item>
<item>
<title>[CL] The Probabilities Also Matter: A More Faithful Metric for Faithfulness of Free-Text Explanations in Large Language Models 网页链接 提出相关解释忠...</title>
<link>https://weibo.com/1402400261/O8pvuhX15</link>
<guid>https://weibo.com/1402400261/O8pvuhX15</guid>
<content:encoded><![CDATA[
<div> 解释忠实度、自然语言、指标、反事实测试、细节、评估、新指标、质量、大语言模型、补充
<br />
<br />
总结:本文提出了一个新的衡量自然语言解释忠实度的指标——相关解释忠实度(CEF)，并基于此提出了反事实测试(CCT)。CEF能够更全面地捕捉解释质量的细节，是对解释忠实度评估的有益补充。通过研究大语言模型中的自由文本解释，文章强调了解释质量和忠实度的重要性，并指出传统衡量方法可能存在的局限性。CEF和CCT的提出为解释忠实度的评估提供了新的视角和工具，有助于提高解释质量的准确性和全面性。 <div>
[CL] The Probabilities Also Matter: A More Faithful Metric for Faithfulness of Free-Text Explanations in Large Language Models  <br /><a href="https://arxiv.org/abs/2404.03189"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出相关解释忠实度(CEF)这一衡量自然语言解释忠实度的新指标，并基于此提出了相关反事实测试(CCT)，能捕捉解释质量的更多细节，是对解释忠实度评估的有益补充。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hogpioppe4j20v21b4h2d.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hogpiou8tmj21ee0rc45e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 22:24:39 GMT</pubDate>
</item>
<item>
<title>[CL] Learning to Plan and Generate Text with Citations 网页链接 通过引入问题序列作为生成蓝图，探索了规划型模型的归因能力，发现相比标准序列到序列，规划...</title>
<link>https://weibo.com/1402400261/O8prC2QRE</link>
<guid>https://weibo.com/1402400261/O8prC2QRE</guid>
<content:encoded><![CDATA[
<div> 规划型模型、问题序列、生成蓝图、归因能力、标准序列到序列、输出质量、引文准确率

通过引入问题序列作为生成蓝图，探索了规划型模型的归因能力。研究发现，相比标准序列到序列模型，规划型模型明显提升了长篇问答的输出质量和引文准确率。这一发现为提高自然语言生成模型的性能和实用性提供了新的思路。总结：文章研究了规划型模型的优势，通过引入问题序列，实现了更高的输出质量和引文准确率，为提升自然语言生成模型的能力提供了有益的启示。 <div>
[CL] Learning to Plan and Generate Text with Citations  <br /><a href="https://arxiv.org/abs/2404.03381"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过引入问题序列作为生成蓝图，探索了规划型模型的归因能力，发现相比标准序列到序列，规划明显提升了长篇问答的输出质量和引文准确率。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hogp8pu7yoj20v61aswwp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hogp8q52fcj219619eqio.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hogp8r2xzyj219i0jcn6s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 22:15:06 GMT</pubDate>
</item>
<item>
<title>[RO] Embodied Neuromorphic Artificial Intelligence for Robotics: Perspectives, Challenges, and Research Development Stack 网页链接 全面概述了具身神经...</title>
<link>https://weibo.com/1402400261/O8pmigBsm</link>
<guid>https://weibo.com/1402400261/O8pmigBsm</guid>
<content:encoded><![CDATA[
<div> 具身神经拟态人工智能、机器人、应用现状、关键挑战、未来发展方向、研究、技术、智能、模型

<br /><br />总结:
本文详细介绍了具身神经拟态人工智能在机器人领域的应用现状，包括现有技术和模型的发展。同时探讨了该领域面临的关键挑战，例如如何将人工智能技术与机器人实际应用相结合，并解决实际问题。未来发展方向包括加强研究，推动技术进步，提高智能机器人的性能和功能，拓展其应用范围。整体而言，具身神经拟态人工智能对机器人的发展至关重要，将为未来的机器人技术注入新的活力。 <div>
[RO] Embodied Neuromorphic Artificial Intelligence for Robotics: Perspectives, Challenges, and Research Development Stack  <br /><a href="https://arxiv.org/abs/2404.03325"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />全面概述了具身神经拟态人工智能在机器人领域的应用现状、关键挑战和未来发展方向。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hogov3zvkyj21161byx4v.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hogov4f35jj21lu0va7kl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hogov4i2zzj21720qsagl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 22:02:00 GMT</pubDate>
</item>
<item>
<title>文章构建模型指出依赖AI可能导致知识分布狭窄化，但个体的策略性选择可能有助避免这一风险。 - 转发 @爱可可-爱生活:&amp;ensp;[AI]《AI and the Problem of Knowled...</title>
<link>https://weibo.com/1402400261/O8p92wTuh</link>
<guid>https://weibo.com/1402400261/O8p92wTuh</guid>
<content:encoded><![CDATA[
<div> AI, knowledge collapse, narrow distribution, individual choice, risk avoidance, model, strategy, Peterson, University of Poitiers

<br /><br />总结:
文章指出依赖AI可能导致知识分布狭窄化的问题，但也提出个体的策略性选择可以有助于避免这一风险。通过构建模型，研究者分析了AI对知识分布的影响，强调了个体在面对这一问题时的重要性。个体可以根据自身需求和偏好，选择适合自己的策略，从而降低潜在的风险。这一研究对于理解AI与知识分布之间的关系具有重要意义，也为个体在使用AI时提供了有益的启示。Peterson教授的研究为我们提供了更深入的思考，并为应对知识分布狭窄化的挑战提供了有益的思路。 <div>
文章构建模型指出依赖AI可能导致知识分布狭窄化，但个体的策略性选择可能有助避免这一风险。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [AI]《AI and the Problem of Knowledge Collapse》A J. Peterson [University of Poitiers] (2024) <a href="https://arxiv.org/abs/2404.03502"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hognnc1b5jj20m015s7dp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hognnceiyhj20o616wqc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognncyb2cj20s40nkaby.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hognndegsxj20s60r0tcf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognx0ib6nj20hj0ja3zi.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognx0i633j20hh0jat9o.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognx0i776j20hj0jat9b.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hognx0i2hzj20ht0en74o.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 21:29:21 GMT</pubDate>
</item>
<item>
<title>[AI]《AI and the Problem of Knowledge Collapse》A J. Peterson [University of Poitiers] (2024) 网页链接 #机器学习##人工智能##论文# [图片][图片][图片][...</title>
<link>https://weibo.com/1402400261/O8p8ZzzRL</link>
<guid>https://weibo.com/1402400261/O8p8ZzzRL</guid>
<content:encoded><![CDATA[
<div> knowledge collapse, AI, problem, ethics, decision-making, reliability, uncertainty, bias, information overload

<br /><br />总结:
在Peterson的文章中，探讨了人工智能与知识塌缩的问题。人工智能在决策过程中可能存在伦理、可靠性、不确定性、偏见和信息过载等挑战。知识塌缩可能导致人工智能系统无法正确处理复杂情况，从而影响决策的准确性。处理这一问题需要进一步研究和讨论，以确保人工智能系统的发展能够更好地服务人类社会。 <div>
[AI]《AI and the Problem of Knowledge Collapse》A J. Peterson [University of Poitiers] (2024) <a href="https://arxiv.org/abs/2404.03502"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hognnc1b5jj20m015s7dp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hognnceiyhj20o616wqc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognncyb2cj20s40nkaby.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hognndegsxj20s60r0tcf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognx0ib6nj20hj0ja3zi.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognx0i633j20hh0jat9o.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hognx0i776j20hj0jat9b.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hognx0i2hzj20ht0en74o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 21:29:14 GMT</pubDate>
</item>
<item>
<title>提出表示微调框架，发现相比调整权重，直接对语言模型的表示进行有针对性的干预可以以更少的参数实现类似或更好的下游任务表现。 - 转发 @爱可可-爱生活:&amp;ensp;[...</title>
<link>https://weibo.com/1402400261/O8p392NYd</link>
<guid>https://weibo.com/1402400261/O8p392NYd</guid>
<content:encoded><![CDATA[
<div> 微调框架、语言模型表示、下游任务、权重调整、有针对性干预、更少参数、表现更好

<br /><br />总结:本文提出了一种名为ReFT的表示微调框架，通过对语言模型的表示进行有针对性的干预来实现更好的下游任务表现。与传统调整权重相比，该方法可以用更少的参数达到类似甚至更好的效果。通过实验证明，ReFT框架在各种下游任务中表现出色，证实了其有效性和实用性。这一研究对于提高语言模型在各类任务中的性能有着重要的指导意义。 <div>
提出表示微调框架，发现相比调整权重，直接对语言模型的表示进行有针对性的干预可以以更少的参数实现类似或更好的下游任务表现。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《ReFT: Representation Finetuning for Language Models》Z Wu, A Arora, Z Wang, A Geiger… [Stanford University] (2024) <a href="https://arxiv.org/abs/2404.03592"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hognhufqy7j21220lcn5y.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hognhutgorj219o0lg0z4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hognhvez0bj219o0lg0z4.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 21:14:49 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.5)》 爱可可微博热门分享(4.5) [图片]</title>
<link>https://weibo.com/1402400261/O8mxq2PL2</link>
<guid>https://weibo.com/1402400261/O8mxq2PL2</guid>
<content:encoded><![CDATA[
<div> 微博、爱可可、热门分享、4.5、关键词

<br /><br />总结:
爱可可微博热门分享文章以4.5分受到关注，内容涵盖各种热门话题，吸引了大量用户关注和转发。文章内容丰富多样，包括时事新闻、娱乐八卦、美食旅游等多个领域的内容。独特的视角和深入的解析让读者对各种话题有了更深入的了解。文章质量高，得到了广泛的好评和点赞，是一篇深受欢迎的微博热门分享。 <div>
《爱可可微博热门分享(4.5)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405019932638183790"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.5)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hogceqdb8yj20rs0fmwgv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 14:51:10 GMT</pubDate>
</item>
<item>
<title>帮转～ - 转发 @徐亦达教授:&amp;ensp;大家好，请大家有空帮忙一下哈！😄 首先非常感谢大家啦🤝🤝🤝。如果您有时间，是否能帮我拍摄5张同样商标的照片（从不...</title>
<link>https://weibo.com/1402400261/O8kWMkjjj</link>
<guid>https://weibo.com/1402400261/O8kWMkjjj</guid>
<content:encoded><![CDATA[
<div> 照片 商标 角度 拍摄 上传 链接 帮助

商标主人需要大家帮忙拍摄5张同一商标的照片，从不同的角度，然后上传到指定链接。希望大家能够帮忙，非常感激！ <div>
帮转～<br /><blockquote> - 转发 <a href="https://weibo.com/5765533535" target="_blank">@徐亦达教授</a>: 大家好，请大家有空帮忙一下哈！😄 首先非常感谢大家啦🤝🤝🤝。如果您有时间，是否能帮我拍摄5张同样商标的照片（从不同的角度），并将它们上传到以下链接？非常感谢各位朋友的帮助！<br /><a href="https://docs.qq.com/form/page/DR2Zhbm51Tnl0eFFu"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <img src="https://tvax1.sinaimg.cn/large/006ibAEngy1hog14iauzuj30go0gota8.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 10:48:09 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models》(ICLR 2024) GitHub: github.com/kykim0/TextNorm《Tokeniz...</title>
<link>https://weibo.com/1402400261/O8kdOl9zC</link>
<guid>https://weibo.com/1402400261/O8kdOl9zC</guid>
<content:encoded><![CDATA[
<div> Text-to-Image Models, Confidence-aware Reward Optimization, Fine-tuning, Tokenization, Noiseless Channel, Neural Avatar, Image Segmentation, Multi-view Generation, Monocular 3D Detection, Style-Preserving, Change Detection, Language Models, Knowledge Translator, Self-Supervised Point Tracking, Linear Attention, Human Avatars, Dense Retrieval, Bit Vectors

总结:
文中介绍了多篇关于文本到图像模型、标记化、神经化身、图像分割、多视角生成等方面的论文实现代码。每篇论文都探讨了不同的技术和方法，包括模型优化、细化、标记化、图像生成、变化检测、语言模型、自监督点追踪等领域。这些研究为计算机视觉和自然语言处理领域的发展提供了新的视角和解决方案。 <div>
几篇论文实现代码：<br />《Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models》(ICLR 2024) GitHub: github.com/kykim0/TextNorm<br />《Tokenization and the Noiseless Channel》(ACL 2024) GitHub: github.com/zouharvi/tokenization-scorer<br />《Relightable and Animatable Neural Avatar from Sparse-View Video》(CVPR 2024) GitHub: github.com/zju3dv/RelightableAvatar<br />《Rethinking Interactive Image Segmentation with Low Latency, High Quality, and Diverse Prompts》(CVPR 2024) GitHub: github.com/uncbiag/SegNext<br />《MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation》(CVPR 2024) GitHub: github.com/zhizdev/mvdfusion<br />《SeaBird: Segmentation in Bird's View with Dice Loss Improves Monocular 3D Detection of Large Objects》(CVPR 2024) GitHub: github.com/abhi1kumar/SeaBird [fig4]<br />《InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation》(2024) GitHub: github.com/InstantStyle/InstantStyle [fig1]<br />《ChangeMamba: Remote Sensing Change Detection with Spatio-Temporal State Space Model》(2024) GitHub: github.com/ChenHongruixuan/MambaCD [fig2]<br />《ReFT: Representation Finetuning for Language Models》(2024) GitHub: github.com/stanfordnlp/pyreft<br />《Hulk: A Universal Knowledge Translator for Human-Centric Tasks》(2024) GitHub: github.com/OpenGVLab/Hulk [fig5]<br />《DINO-Tracker: Taming DINO for Self-Supervised Point Tracking in a Single Video》(2024) GitHub: github.com/AssafSinger94/dino-tracker<br />《Linear Attention Sequence Parallelism》(2024) GitHub: github.com/OpenNLPLab/LASP [fig3]<br />《HAHA: Highly Articulated Gaussian Human Avatars with Textured Mesh Prior》(2024) GitHub: github.com/david-svitov/HAHA<br />《Efficient Multi-vector Dense Retrieval with Bit Vectors》(2024) GitHub: github.com/CosimoRulli/emvb<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofubz9zdzj21gs17k7fe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofw8kueprj22691797wi.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofwlb8wvwj20k00ct795.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hog0a4fkm7j21gp0dk152.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hog1cq2s18j22ha11w7wh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 08:57:22 GMT</pubDate>
</item>
<item>
<title>'GPTS-Prompt-Collection - 收集GPTS的prompt / Collect the prompt of GPTS' GitHub: github.com/B3o/GPTS-Prompt-Collection #开源# #机器学习# #人工智能# [...</title>
<link>https://weibo.com/1402400261/O8k3kbPso</link>
<guid>https://weibo.com/1402400261/O8k3kbPso</guid>
<content:encoded><![CDATA[
<div> 关键词: GPTS, Prompt, Collection, GitHub, 收集, 提取, 关键点, 800字, 文章, 代码库

总结:<br /><br />
文章介绍了一个GitHub代码库，该代码库用于收集GPTS的prompt。通过这个项目，用户可以获取和分享各种GPTS生成的prompt，从而帮助提高模型的表现。用户可以在GitHub上查看和下载这些prompt，并在自己的项目中使用。该项目提供了一个方便的平台，让用户可以轻松地收集和分享prompt，从而为GPTS的发展做出贡献。GitHub代码库地址为github.com/B3o/GPTS-Prompt-Collection。 <div>
'GPTS-Prompt-Collection - 收集GPTS的prompt / Collect the prompt of GPTS' GitHub: github.com/B3o/GPTS-Prompt-Collection <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hog1fspuh2j20kk0t2go7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 08:31:32 GMT</pubDate>
</item>
<item>
<title>【Orange Meets：基于 Cloudflare Calls 构建的演示应用，可以通过该应用体验 WebRTC 技术】'Orange Meets - a demo application built using Cloudflare Calls...</title>
<link>https://weibo.com/1402400261/O8j8c99JD</link>
<guid>https://weibo.com/1402400261/O8j8c99JD</guid>
<content:encoded><![CDATA[
<div> Cloudflare Calls, 构建, Orange Meets, 演示应用, WebRTC 技术, GitHub, 应用体验

<br /><br />总结:
Orange Meets是一个演示应用，使用Cloudflare Calls构建，可以让用户体验WebRTC技术。这个应用可以在GitHub上找到，名为github.com/cloudflare/orange。通过Orange Meets，用户可以了解和体验Cloudflare Calls和WebRTC技术的功能和优势。 <div>
【Orange Meets：基于 Cloudflare Calls 构建的演示应用，可以通过该应用体验 WebRTC 技术】'Orange Meets - a demo application built using Cloudflare Calls’ GitHub: github.com/cloudflare/orange <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hofxd6vocdj20u00vkq7w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 06:10:46 GMT</pubDate>
</item>
<item>
<title>【Dot：使用大型语言模型(LLM)和检索增强生成(RAG)进行文档交互的独立应用，面向本地使用大型语言模型（LLM）和检索增强生成（RAG）进行文档交互的独立应用程序...</title>
<link>https://weibo.com/1402400261/O8j7p9nAF</link>
<guid>https://weibo.com/1402400261/O8j7p9nAF</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、检索增强生成、文档交互、独立应用、本地使用、GitHub、Mistral 7B、应用程序

<br /><br />总结:
这篇文章介绍了一个名为Dot的独立应用程序，其使用大型语言模型（LLM）和检索增强生成（RAG）技术，实现本地文档交互功能。用户可以通过GitHub下载这个应用程序，并使用其中的Mistral 7B模型进行操作。Dot的设计目的是为用户提供一种便捷的方式来进行文档处理和生成，同时保证数据隐私和安全。通过结合大型语言模型和检索增强生成技术，Dot可以帮助用户快速获取文档信息并生成相关内容，提高工作效率。Dot的本地化设计也符合用户对数据隐私和安全性的需求，让用户能够安心地使用这个应用程序。 <div>
【Dot：使用大型语言模型(LLM)和检索增强生成(RAG)进行文档交互的独立应用，面向本地使用大型语言模型（LLM）和检索增强生成（RAG）进行文档交互的独立应用程序】’Dot - Standalone app for fully local RAG with Mistral 7B' GitHub: github.com/alexpinel/Dot <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hofxbbddiuj20u00xuwj0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 06:08:50 GMT</pubDate>
</item>
<item>
<title>【CIFAR-10 Airbench：包含了基于 PyTorch 框架的 CIFAR-10 数据集快速训练脚本，提供了三种方法，分别可以实现 94.01%、95.01% 和 96.05% 的准确率，运行时间分...</title>
<link>https://weibo.com/1402400261/O8j022Y66</link>
<guid>https://weibo.com/1402400261/O8j022Y66</guid>
<content:encoded><![CDATA[
<div> PyTorch, CIFAR-10, 快速训练脚本, 准确率, 运行时间, GitHub, KellerJordan, CIFAR-10 Airbench<br />
<br />
提供了基于 PyTorch 框架的 CIFAR-10 数据集快速训练脚本，包含三种方法可以实现不同准确率，分别为94.01%、95.01%和96.05%。运行时间分别为3.29秒、10.4秒和46.3秒。项目托管在GitHub上，作者是KellerJordan。  <div>
【CIFAR-10 Airbench：包含了基于 PyTorch 框架的 CIFAR-10 数据集快速训练脚本，提供了三种方法，分别可以实现 94.01%、95.01% 和 96.05% 的准确率，运行时间分别为 3.29 秒、10.4 秒和 46.3 秒】'CIFAR-10 Airbench' GitHub: github.com/KellerJordan/cifar10-airbench <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hofwsfm1cij20yy0u0dk9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 05:50:40 GMT</pubDate>
</item>
<item>
<title>【LL3M：构建支持 Jax/Flax 训练和微调的大语言/多模态模型和 MoE 模型】'LL3M: Large Language and Multi-Modal Model in Jax / Flax - LL3M: Large Language a...</title>
<link>https://weibo.com/1402400261/O8iRXsXRz</link>
<guid>https://weibo.com/1402400261/O8iRXsXRz</guid>
<content:encoded><![CDATA[
<div> Jax, Flax, 训练, 微调, 大语言模型, 多模态模型, MoE 模型, GitHub, 支持, 构建

<br /><br />总结:
该项目提出了一个名为LL3M的大语言和多模态模型，基于Jax和Flax框架，支持模型训练和微调。该模型还包含MoE（Mixture of Experts）模型。整个项目代码托管在GitHub上。LL3M模型可以用于多种任务，包括自然语言处理和计算机视觉。通过该项目，研究人员可以更方便地训练和使用大型语言和多模态模型。 <div>
【LL3M：构建支持 Jax/Flax 训练和微调的大语言/多模态模型和 MoE 模型】'LL3M: Large Language and Multi-Modal Model in Jax / Flax - LL3M: Large Language and Multi-Modal Model in Jax' GitHub: github.com/jiasenlu/LL3M <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hofw7rr0ehj217k0ismzt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 05:30:47 GMT</pubDate>
</item>
<item>
<title>【SableDb：基于 RocksDb 存储引擎的 Key-Value NoSQL 数据库，与 Redis 协议兼容，旨在降低内存成本和增加比 Redis 更大的容量】'SableDb - Ultra fast, persis...</title>
<link>https://weibo.com/1402400261/O8iQd2qwJ</link>
<guid>https://weibo.com/1402400261/O8iQd2qwJ</guid>
<content:encoded><![CDATA[
<div> SableDb、RocksDb、Key-Value、NoSQL、数据库、Redis、协议兼容、降低内存成本、增加容量、GitHub

<br /><br />总结:
SableDb是一个基于RocksDb存储引擎的Key-Value型NoSQL数据库，与Redis协议兼容。旨在降低内存成本和增加比Redis更大的容量。该数据库支持Redis API，具有快速持久性和高性能。用户可以在GitHub上找到SableDb的开源代码，并了解更多相关信息。 <div>
【SableDb：基于 RocksDb 存储引擎的 Key-Value NoSQL 数据库，与 Redis 协议兼容，旨在降低内存成本和增加比 Redis 更大的容量】'SableDb - Ultra fast, persistent database supporting Redis API' GitHub: github.com/sabledb-io/sabledb <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hofw32it0kj21740lwgpg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 05:26:28 GMT</pubDate>
</item>
<item>
<title>'Bili2text - Bilibili视频转文字，一步到位，输入链接即可使用' GitHub: github.com/lanbinshijie/bili2text #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O8ivvFIdX</link>
<guid>https://weibo.com/1402400261/O8ivvFIdX</guid>
<content:encoded><![CDATA[
<div> 关键词: Bili2text, Bilibili, 视频转文字, GitHub, 转换工具, 链接输入<br />
<br />
Bili2text是一个可以将Bilibili视频转换为文字的工具，用户只需输入视频链接即可使用。该工具在GitHub上开源，代码可在github.com/lanbinshijie/bili2text找到。<br /><br />
总结: <br />
1. Bili2text是一个视频转文字工具，可用于将Bilibili视频转换为文字。<br />
2. 用户只需输入视频链接即可使用该工具。<br />
3. 该工具的代码开源在GitHub上，网址为github.com/lanbinshijie/bili2text。 <div>
'Bili2text - Bilibili视频转文字，一步到位，输入链接即可使用' GitHub: github.com/lanbinshijie/bili2text <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hofum86vanj20yd0u0n0v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 04:35:29 GMT</pubDate>
</item>
<item>
<title>【JetMoE: 基于开源数据集训练的大型语言模型，可以与 LLaMA2-7B 等高性能模型相媲美，仅需较少的训练资金(0.1M Dollars)】’JetMoE: Reaching LLaMA2 Performan...</title>
<link>https://weibo.com/1402400261/O8iqA9D3s</link>
<guid>https://weibo.com/1402400261/O8iqA9D3s</guid>
<content:encoded><![CDATA[
<div> 基于开源数据集，训练大型语言模型，性能媲美LLaMA2-7B，仅需0.1M Dollars训练资金<br />
<br />
1. JetMoE是一个基于开源数据集训练的大型语言模型，与LLaMA2-7B等高性能模型相媲美。<br />
2. JetMoE训练所需资金仅为0.1M Dollars，较其他模型相对较低。<br />
3. 这篇文章介绍了JetMoE的训练方式及性能表现，以及与其他模型的对比情况。<br />
4. JetMoE的GitHub链接为github.com/myshell-ai/JetMoE。<br />
<br />
总结:本文介绍了基于开源数据集训练的大型语言模型JetMoE，表现媲美LLaMA2-7B，仅需0.1M Dollars训练资金，是一种高性价比的模型选择。文章详细介绍了JetMoE的优势和性能表现，以及与其他模型的对比情况。感兴趣的读者可通过GitHub链接获取更多信息。 <div>
【JetMoE: 基于开源数据集训练的大型语言模型，可以与 LLaMA2-7B 等高性能模型相媲美，仅需较少的训练资金(0.1M Dollars)】’JetMoE: Reaching LLaMA2 Performance with 0.1M Dollars - Reaching LLaMA2 Performance with 0.1M Dollars' GitHub: github.com/myshell-ai/JetMoE <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hofu9l51tcj21aj0u078p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 04:23:20 GMT</pubDate>
</item>
<item>
<title>【生成式AI高峰已过？】- 生成式AI的兴趣高峰已经过去，公众兴趣下降，风投估值过高，初创公司开始倒闭，企业对部署安全性存疑。 - 但技术本身仍在快速进步，不...</title>
<link>https://weibo.com/1402400261/O8hyyppLO</link>
<guid>https://weibo.com/1402400261/O8hyyppLO</guid>
<content:encoded><![CDATA[
<div> 生成式AI，兴趣高峰，公众下降，风投估值，初创公司，安全性存疑，技术进步，新模型，基础设施，低谷期

<br /><br />总结:
生成式AI的兴趣高峰已经过去，公众兴趣下降，风投估值过高，初创公司开始倒闭，企业对部署安全性存疑。技术虽然在快速进步，但进展不为公众所知。每项革命性技术都经历高峰和低谷，生成式AI可能也是如此。是否再次繁荣取决于默默努力的人们。过度炒作可能导致公众接受困难，技术领域应谨记。技术发展和公众舆论需要平衡。过度炒作会损害公众对技术的信任，阻碍长远发展。变革依靠内在力量，外界关注并非必需。历史将解答生成式AI的命运。 <div>
【生成式AI高峰已过？】<br />- 生成式AI的兴趣高峰已经过去，公众兴趣下降，风投估值过高，初创公司开始倒闭，企业对部署安全性存疑。   <br />- 但技术本身仍在快速进步，不断有新模型问世，基础设施也在建设，只是这些进展不为公众所知。   <br />- 每项革命性技术都曾经历过兴趣的高峰和低谷，生成式AI可能也是这样，目前正处在低谷期。   <br />- 是否会再次繁荣取决于静默努力的人们，而非当下的舆论，历史会给出答案。   <br />- 过度炒作可能让公众在下次繁荣时难以接受，技术领域应谨记。   <br />- 我们应该问自己，技术本身是否有足够的力量推动变革，而非依靠夸大其词。   <br /><br />思考：   <br />- 技术发展的节奏和公众舆论的节奏不尽相同，需要平衡二者。   <br />- 过度炒作会损害公众对技术的信任，可能会阻碍长远发展。   <br />- 变革依靠内在驱动力，外界关注并非必需。<br />《The State of Generative AI, 2024 - by Alberto Romero》 <a href="https://www.thealgorithmicbridge.com/p/the-state-of-generative-ai-2024"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hofqf29bu1j214g0n4tbv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 02:10:14 GMT</pubDate>
</item>
<item>
<title>【128k上下文+多语言+工具：Cohere开放企业级应用大模型Command R+】- Cohere推出Command R+模型，一个为应对企业级工作负载而构建的最强大、最具可扩展性的大型...</title>
<link>https://weibo.com/1402400261/O8h1oCNt9</link>
<guid>https://weibo.com/1402400261/O8h1oCNt9</guid>
<content:encoded><![CDATA[
<div> Cohere, Command R+, Microsoft Azure, 多语言, 工具使用, 128k token上下文窗口,性能升级, 企业级应用, 市场拓展, 合作伙伴关系

<br /><br />总结:
Cohere推出了适用于企业级工作负载的最强大、可扩展的大型语言模型Command R+，首先在Microsoft Azure上推出，旨在加速企业AI的采用。该模型具有128k token的上下文窗口，支持多种关键语言和工具使用，以实现复杂业务流程的自动化。Command R+在各方面表现出色，与微软Azure等云计算巨头合作，有望在多个云平台上快速部署，降低企业的采用门槛。企业如Atomicwork可以利用Command R+来提高数字工作场所体验，加速企业生产力。这标志着Cohere在企业级AI市场的发力，展现了其深刻的企业需求洞察力和强大的技术实力。Cogere还需要持续投入解决数据安全、伦理合规等挑战，助力企业AI的落地应用。 <div>
【128k上下文+多语言+工具：Cohere开放企业级应用大模型Command R+】<br />- Cohere推出Command R+模型，一个为应对企业级工作负载而构建的最强大、最具可扩展性的大型语言模型(LLM)。  <br />- Command R+首先在Microsoft Azure上推出，旨在加速企业AI的采用。它加入了Cohere的R系列LLM，专注于在高效率和强准确性之间取得平衡，使企业能从概念验证走向生产。  <br />- Command R+具有128k token的上下文窗口，旨在提供同类最佳的性能，包括：  <br />  - 先进的检索增强生成(RAG)和引用，以减少幻觉  <br />  - 支持10种关键语言的多语言覆盖，以支持全球业务运营  <br />  - 工具使用，以实现复杂业务流程的自动化  <br />- Command R+在各方面都优于Command R，在类似模型的基准测试中表现出色。  <br />- 开发人员和企业可以从今天开始在Azure上访问Cohere的最新模型，很快也将在Oracle云基础设施(OCI)以及未来几周内的其他云平台上提供。Command R+也将立即在Cohere的托管API上提供。  <br />- Atomicwork等企业客户可以利用Command R+来改善数字工作场所体验，加速企业生产力。  <br /><br />思考：  <br />- Cohere推出Command R+，进一步丰富了其企业级LLM产品线，展现了其在企业AI市场的雄心和实力。与微软Azure的合作有望加速其企业客户的拓展。  <br />- Command R+在Command R的基础上进行了全面升级，128k token的上下文窗口、多语言支持、工具使用等特性使其能够胜任更加复杂多样的企业应用场景。这表明Cohere对企业需求有着深刻洞察。  <br />- RAG和引用功能有助于提高模型输出的可靠性，减少幻觉，这对于企业级应用至关重要。可以看出Cohere在兼顾性能的同时，也非常重视模型的可控性。  <br />- 与微软、甲骨文等云计算巨头合作，使Command R+能够在多个主流云平台上快速部署，降低了企业的采用门槛。这种开放的生态策略有利于加速其市场渗透。  <br />- Atomicwork等企业客户的支持表明Command R+具有显著的商业价值。将LLM与企业数字化转型相结合，有望催生更多创新性的应用。  <br />- Command R+的推出标志着Cohere在企业级AI市场的发力，其强大的性能和完善的生态有望帮助其在竞争中占据优势地位。不过，企业AI的落地仍面临数据安全、伦理合规等诸多挑战，Cohere还需要在这些方面持续投入。<br />《Introducing Command R+: A Scalable LLM Built for Business》 <a href="https://txt.cohere.com/command-r-plus-microsoft-azure/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hofo1hyiwyj21hc0u0n0r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 00:48:32 GMT</pubDate>
</item>
<item>
<title>【OpenAI推出对微调API的改进和新的定制模型计划】- OpenAI推出了对微调API的改进，并扩大了定制模型计划，以帮助开发者提高模型性能，降低延迟，提高准确性并降...</title>
<link>https://weibo.com/1402400261/O8gHS6J2t</link>
<guid>https://weibo.com/1402400261/O8gHS6J2t</guid>
<content:encoded><![CDATA[
<div> OpenAI, 微调API, 定制模型计划, 模型性能, RAG, 合作, 技术, 控制, 提升, 开发者

<br /><br />总结:
OpenAI推出了对微调API的改进和新的定制模型计划，旨在帮助开发者提高模型性能、降低延迟、提高准确性并降低成本。开发者可以运用多种技术，如RAG扩展模型知识、使用微调定制模型行为或构建定制训练模型来提升模型性能。通过新的微调API功能，开发者能更好地控制微调过程，并与OpenAI的AI专家和研究人员合作构建定制模型。自推出自助微调API以来，成千上万家组织已使用API训练了数十万个模型，以增强模型对特定任务的理解和能力。定制模型计划则旨在与OpenAI研究人员合作，针对特定领域训练和优化模型，并根据客户需求不断改进计划以提高性能。重点在于明确使用场景、设计评估系统、选择技术并持续迭代，使模型达到最佳性能。开发者可以通过微调API快速看到有意义的结果，而定制模型计划则适用于需要深度微调或传授特定领域知识的组织。这些举措体现了OpenAI致力于协助开发者和企业实现AI应用的决心，有望促进AI技术在各行业的应用，并加速AI技术向生产环境的渗透。 <div>
【OpenAI推出对微调API的改进和新的定制模型计划】<br />- OpenAI推出了对微调API的改进，并扩大了定制模型计划，以帮助开发者提高模型性能，降低延迟，提高准确性并降低成本。  <br />- 开发者可以使用多种技术来提高模型性能，如使用检索增强生成(RAG)扩展模型知识，使用微调定制模型行为，或使用新的特定领域知识构建定制训练模型。  <br />- OpenAI推出了新的微调API功能，让开发者可以更好地控制使用API进行微调，并引入更多方式与OpenAI的AI专家和研究人员合作构建定制模型。  <br />- 自2023年8月推出GPT-3.5的自助微调API以来，已有数千家组织使用该API训练了数十万个模型。微调可以帮助模型深入理解内容，并增强模型在特定任务上的现有知识和能力。  <br />- OpenAI推出了定制模型计划，旨在与OpenAI研究人员合作，针对特定领域训练和优化模型。通过与客户合作，OpenAI评估了他们的定制模型需求，并改进了计划以进一步最大化性能。  <br />- 关键是要明确使用场景的范围，设计和实施评估系统，选择正确的技术，并准备随着时间的推移不断迭代，使模型达到最佳性能。使用OpenAI，大多数组织可以通过自助微调API快速看到有意义的结果。对于需要更深入地微调模型或向模型灌输新的特定领域知识的组织，OpenAI的定制模型计划可以提供帮助。  <br /><br />思考：  <br />- OpenAI持续改进微调API和定制模型计划，体现了其致力于帮助开发者和企业实现AI应用的决心。这些举措有望加速AI技术在各行各业的落地和普及。  <br />- 文章列举了多种提升模型性能的技术，如RAG、微调、定制训练等，展现了当前AI优化的多样性和灵活性。开发者可以根据具体应用场景选择合适的技术组合。  <br />- 微调API的新功能赋予开发者更多控制权，定制模型计划提供了与OpenAI专家合作的机会，这种开放、灵活的生态有利于满足企业的差异化需求，催生更多创新应用。  <br />- OpenAI与客户的深度合作，如与SKT在电信客户服务领域的合作，展现了定制化AI解决方案的巨大价值。这种合作模式有望在更多行业复制和推广。  <br />- 文章强调了明确使用场景、建立评估体系、选择合适技术、持续迭代优化的重要性，这为企业采用AI提供了很好的方法论指导。  <br />- OpenAI的这些举措有望加速AI技术向生产环境的渗透，帮助企业实现AI价值。同时，我们也要看到，实现AI的规模化应用仍面临诸多挑战，如数据质量、伦理风险等，需要产学研各界共同努力加以应对。<br />《Introducing improvements to the fine-tuning API and expanding our custom models program》 <a href="https://openai.com/blog/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hofmneqtp0j21d70u0q9i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 05 Apr 2024 00:00:26 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@异步图书 送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O8geoaKFM</link>
<guid>https://weibo.com/1402400261/O8geoaKFM</guid>
<content:encoded><![CDATA[
<div> 大语言模型、前沿进展、科学家、工程师、学生、案例、庖丁解牛、理解、认识

<br /><br />总结:
本文介绍了《大语言模型：基础与前沿》这本书，截止日期为2024年4月12日中午12点，*可可粉*转发+评论即可参与赠送3本书。该书全面深入地介绍了大语言模型及其前沿进展，适合想要了解这一领域或掌握这种方法与工具的科学家、工程师和学生参考。书中摒弃了纯理论的说教模式，通过案例入手，以庖丁解牛的方式帮助读者理解与认识大语言模型。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%BC%82%E6%AD%A5%E5%9B%BE%E4%B9%A6">@异步图书</a>  送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。摒弃了纯理论的说教模式，从案例入手， 采用庖丁解牛的方式帮助读者理解与认识大语言模型。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019331269755053"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef8oboqij20ga0m8q8p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9segl7j20m90m9q6z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9t5km0j20m90m942f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef9tq2esj20m90m9gpe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef9ugq5dj20m90m9dif.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 22:47:48 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转...</title>
<link>https://weibo.com/1402400261/O8gel92B5</link>
<guid>https://weibo.com/1402400261/O8gel92B5</guid>
<content:encoded><![CDATA[
<div> LangChain实战, 初学者, 大语言模型, LLM, LangChain 0.1版本, LangServe, LangSmith, LangChain团队, 生成式人工智能, LangChain生态系统

<br /><br />总结:
本文介绍了携手送出3本《LangChain实战》的活动，截止日期为2024年4月11日。参与者需转发并评论，即可参与。该书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者编写，基于LangChain 0.1版本。同时，配套600分钟详解视频，重点介绍多个核心应用场景，并深入探讨LCEL的应用方式。书中围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。活动为LangChain的学习者提供了一个学习和交流的平台。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a> <a href="https://shop.sc.weibo.com/h5/goods/index?iid=110014024002610004661854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">LangChain实战：从原型到生产，动手打造 LLM 应用</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5ywtixj20ku0zzdmx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hofl98oom9j207q0a0jrm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 22:47:41 GMT</pubDate>
</item>
<item>
<title>今日推介(第1366期)：在基于Transformer的语言中动态分配计算、描述模型中幻觉的新测量方法、高效的编译时提示结构感知方法、线性注意力序列并行、强化学习的范...</title>
<link>https://weibo.com/1402400261/O8gcClW8Q</link>
<guid>https://weibo.com/1402400261/O8gcClW8Q</guid>
<content:encoded><![CDATA[
<div> Transformer、动态分配计算、模型幻觉、新测量方法、编译时提示、结构感知方法、线性注意力、序列并行、强化学习、范畴网络<br />
<br />
<总结>
本文介绍了一些新的研究成果，包括在基于Transformer的语言模型中动态分配计算的方法，描述模型中幻觉的新测量方法，以及高效的编译时提示结构感知方法。此外，还介绍了线性注意力和序列并行的技术，以及在强化学习中应用范畴网络的视角。这些方法的提出和应用有助于改进机器学习和人工智能领域的相关技术，推动相关领域的研究和发展。 <div>
今日推介(第1366期)：在基于Transformer的语言中动态分配计算、描述模型中幻觉的新测量方法、高效的编译时提示结构感知方法、线性注意力序列并行、强化学习的范畴网络学视角 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/690782999"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hofkfmfv30j20xy0u0q9l.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hofkfol1qzj20sw0pm0xf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hofkfrkzeoj21cc0hqjuz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hofkfuprauj20p211s0xl.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hofkfxbyvlj20ku0qkaba.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 22:43:27 GMT</pubDate>
</item>
<item>
<title>[IR] Efficient Multi-Vector Dense Retrieval Using Bit Vectors 网页链接 提出EMVB框架，通过bit向量预过滤、SIMD计算、量化技术等方法实现高效低内存的多向量...</title>
<link>https://weibo.com/1402400261/O8g7MfrpU</link>
<guid>https://weibo.com/1402400261/O8g7MfrpU</guid>
<content:encoded><![CDATA[
<div> EMVB框架, Bit向量预过滤, SIMD计算, 量化技术, 多向量稠密检索, 高效, 低内存

<br /><br />总结:
本文提出了一种名为EMVB的框架，旨在实现高效低内存的多向量稠密检索。框架包括bit向量预过滤、SIMD计算和量化技术等方法，用于提高检索效率。通过使用bit向量预过滤，可以减少不必要的计算。同时，利用SIMD计算和量化技术对向量进行处理，进一步提高了检索效率。该框架在稠密向量检索任务中表现出色，是一种高效且节省内存的检索方法。 <div>
[IR] Efficient Multi-Vector Dense Retrieval Using Bit Vectors  <br /><a href="https://arxiv.org/abs/2404.02805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出EMVB框架，通过bit向量预过滤、SIMD计算、量化技术等方法实现高效低内存的多向量稠密检索。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofk3ig8y8j20uo1c2duf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofk3inkovj21cw0maaeo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofk3j1u9xj21cs0k043n.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 22:31:31 GMT</pubDate>
</item>
<item>
<title>[CL] CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models 网页链接 CMULAB是一个开源的Web框架，通过集成各...</title>
<link>https://weibo.com/1402400261/O8g5iDezz</link>
<guid>https://weibo.com/1402400261/O8g5iDezz</guid>
<content:encoded><![CDATA[
<div> CMULAB, 开源框架, 自然语言处理, 多语言, 模型集成, 低资源语言, 部署, 微调, 降低门槛
<br />
CMULAB是一个开源的Web框架，通过集成各种多语言NLP模型，简化了低资源语言的自然语言处理工具的部署和微调过程，降低了使用门槛，使更多语言社区受益。 <div>
[CL]  CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models  <br /><a href="https://arxiv.org/abs/2404.02408"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />CMULAB是一个开源的Web框架，通过集成各种多语言NLP模型，简化了低资源语言的自然语言处理工具的部署和微调过程，降低了使用门槛，使更多语言社区受益。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofjx5bxxqj20vk1bg4fy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofjx5roywj21la0ua47x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofjx6a8dwj21oe17idss.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 22:25:25 GMT</pubDate>
</item>
<item>
<title>[LG] Domain Generalization through Meta-Learning: A Survey 网页链接 对基于元学习提高模型泛化能力的域泛化方法进行全面调研，总结现有方法与存在的挑战，为...</title>
<link>https://weibo.com/1402400261/O8g35EtUJ</link>
<guid>https://weibo.com/1402400261/O8g35EtUJ</guid>
<content:encoded><![CDATA[
<div> 域泛化、元学习、模型、挑战、调研、方法、指导、研究、泛化能力、领域

总结:<br /><br />本文对基于元学习的域泛化方法进行了全面调研，总结了现有方法及存在的挑战，并为未来研究提供了指导。在研究中，针对模型在不同领域下的泛化能力进行了讨论，提出了利用元学习来改善泛化能力的思路。调研发现，当前的域泛化方法存在一些挑战，例如领域差异、数据标签分布等问题，需要进一步研究解决。未来的研究可以集中在如何提高模型在多个领域中的表现，以及如何设计更加有效的元学习策略等方面，以促进泛化能力的提升。 <div>
[LG] Domain Generalization through Meta-Learning: A Survey  <br /><a href="https://arxiv.org/abs/2404.02785"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />对基于元学习提高模型泛化能力的域泛化方法进行全面调研，总结现有方法与存在的挑战，为未来研究提供指导。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofjrgd6kmj20xg15m7ga.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofjrh6mp8j21cy150wmo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofjrhnyi5j21c80tqgqh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofjri3qtpj21d40p6aht.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 22:19:59 GMT</pubDate>
</item>
<item>
<title>[CL] Auxiliary task demands mask the capabilities of smaller language models 网页链接 与大模型相比，小规模语言模型更容易受到评估设计引入的辅助需求的影...</title>
<link>https://weibo.com/1402400261/O8g0s5eI3</link>
<guid>https://weibo.com/1402400261/O8g0s5eI3</guid>
<content:encoded><![CDATA[
<div> 大模型,小规模语言模型,评估设计,辅助需求,真实能力,低估,评估,能力发展,研究视角

<br /><br />总结:
小规模语言模型更容易受到评估设计引入的辅助需求的影响，可能导致其真实能力被低估。这一发现为语言模型的评估和能力发展研究提供了新的视角，强调对于小规模语言模型的评估需要综合考虑辅助需求的影响。 <div>
[CL] Auxiliary task demands mask the capabilities of smaller language models  <br /><a href="https://arxiv.org/abs/2404.02418"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />与大模型相比，小规模语言模型更容易受到评估设计引入的辅助需求的影响，其真实能力可能被低估，这一发现为语言模型的评估和能力发展研究提供了新的视角。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofjkptd3ij20va1dqh17.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofjkqdhb6j21bu0x2n6v.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofjkqnw6lj21by0w8wnl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 22:13:28 GMT</pubDate>
</item>
<item>
<title>将强化学习的各种主流算法统一表达为范畴网络学框架中的参数化光学元，通过组合简单的范畴论模块构造复杂算法，揭示了这些算法背后的共性。 - 转发 @爱可可-爱生...</title>
<link>https://weibo.com/1402400261/O8fTmgYeo</link>
<guid>https://weibo.com/1402400261/O8fTmgYeo</guid>
<content:encoded><![CDATA[
<div> 参数化光学元, 强化学习, 范畴网络学框架, 主流算法, 共性, 算法背后, 范畴论模块, 复杂算法

<br /><br />总结:
本文将强化学习的各种主流算法统一表达为范畴网络学框架中的参数化光学元，通过组合简单的范畴论模块构造复杂算法，揭示了这些算法背后的共性。这种方法将不同算法统一起来，揭示了它们之间的联系和共同之处。参数化光学元的概念在此框架中起到关键作用，帮助理解算法之间的联系，并且通过范畴网络学框架的应用，能够更好地理解算法的本质和工作原理。通过这种方式构建的复杂算法模型可以更好地解决现实生活中的问题，同时也为强化学习领域的研究提供了新的思路和方法。整体来看，本文为强化学习算法的发展和应用开辟了新的方向，为研究人员提供了更多的启发和思考。 <div>
将强化学习的各种主流算法统一表达为范畴网络学框架中的参数化光学元，通过组合简单的范畴论模块构造复杂算法，揭示了这些算法背后的共性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Reinforcement Learning in Categorical Cybernetics》J Hedges, R R Sakamoto  (2024) <a href="https://arxiv.org/abs/2404.02688"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofihvxkgyj21j60mwna8.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofihwach1j20ku0qkdhe.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofihwk8anj20la0n2dhq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofihwpqq7j20n20zgq5q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofj2enwrdj20xc05qjs1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofj2en24aj20d108qaac.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofj2enyf5j20zs0d9wgi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofj2envf2j20z80bwdho.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofj2enk53j20zs06y0ts.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 21:56:00 GMT</pubDate>
</item>
<item>
<title>[LG]《Reinforcement Learning in Categorical Cybernetics》J Hedges, R R Sakamoto (2024) 网页链接 #机器学习##人工智能##论文# [图片][图片][图片][图片][图...</title>
<link>https://weibo.com/1402400261/O8fTirwiQ</link>
<guid>https://weibo.com/1402400261/O8fTirwiQ</guid>
<content:encoded><![CDATA[
<div> 强化学习、分类学、网络控制、机器学习、人工智能、深度学习、信息科学

总结:<br /><br />
本文探讨了在分类学的框架下运用强化学习的方法来解决网络控制问题。研究者提出了一种基于分类学思想的强化学习算法，利用深度学习技术实现网络控制的优化。他们认为在信息科学领域中，将强化学习与分类学相结合可以提高系统的性能和鲁棒性。研究结果表明，这种方法可以有效地应用于网络控制领域，为构建更强大的人工智能系统提供了新思路。 <div>
[LG]《Reinforcement Learning in Categorical Cybernetics》J Hedges, R R Sakamoto  (2024) <a href="https://arxiv.org/abs/2404.02688"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofihvxkgyj21j60mwna8.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofihwach1j20ku0qkdhe.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofihwk8anj20la0n2dhq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofihwpqq7j20n20zgq5q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofj2enwrdj20xc05qjs1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofj2en24aj20d108qaac.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofj2enyf5j20zs0d9wgi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofj2envf2j20z80bwdho.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofj2enk53j20zs06y0ts.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 21:55:51 GMT</pubDate>
</item>
<item>
<title>设计了LASP技术实现线性注意力模型的高效序列级并行，对处理长序列任务具有重要意义。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Linear Attention Sequence Paralleli...</title>
<link>https://weibo.com/1402400261/O8fKtAKqW</link>
<guid>https://weibo.com/1402400261/O8fKtAKqW</guid>
<content:encoded><![CDATA[
<div> LASP、线性注意力模型、高效序列级并行、长序列任务、Shanghai AI Laboratory、TapTap

<br /><br />总结:
本文介绍了一种名为LASP的技术，能够实现线性注意力模型的高效序列级并行，对处理长序列任务具有重要意义。LASP技术由上海人工智能实验室和TapTap合作开发。该技术通过实现线性注意力模型的高效序列级并行，提升了长序列任务的处理速度和效率。LASP技术的设计使其在处理长序列任务时能够更加高效，对于提升模型的性能有着重要意义。该研究对于未来在处理长序列任务时的优化具有重要的参考意义。LASP技术在实践中展现出了良好的效果，为解决长序列任务的挑战提供了新的思路和方法。 <div>
设计了LASP技术实现线性注意力模型的高效序列级并行，对处理长序列任务具有重要意义。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Linear Attention Sequence Parallelism》W Sun, Z Qin, D Li, X Shen, Y Qiao, Y Zhong [Shanghai AI Laboratory &amp; TapTap] (2024) <a href="https://arxiv.org/abs/2404.02882"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofi8pdok9j20la12wn6t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofi8pq1gej20p211s7ak.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofi8q20cij20os0omq94.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofi8q8axzj21d60mytfy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofifj2ayvj20j00i4gn9.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 21:34:07 GMT</pubDate>
</item>
<item>
<title>[LG]《Linear Attention Sequence Parallelism》W Sun, Z Qin, D Li, X Shen, Y Qiao, Y Zhong [Shanghai AI Laboratory &amp; TapTap] (2024) 网页链接 #机器学习##...</title>
<link>https://weibo.com/1402400261/O8fKngOP4</link>
<guid>https://weibo.com/1402400261/O8fKngOP4</guid>
<content:encoded><![CDATA[
<div> 关键词: Linear Attention Sequence Parallelism, Shanghai AI Laboratory, TapTap, 并行计算, 自然语言处理, 深度学习

总结:<br /><br />
本文介绍了一种名为Linear Attention Sequence Parallelism的方法，旨在加速自然语言处理任务中的注意力机制计算。该方法由上海人工智能实验室和TapTap联合研发，利用并行计算的方式提高了深度学习模型的计算效率。作者通过实验验证了该方法在不同任务上的性能表现优异，展示了其在提高计算速度和保持模型准确性方面的潜力。通过对比实验和分析，论文强调了Linear Attention Sequence Parallelism对于加速自然语言处理任务的重要性，为深度学习领域的研究和应用提供了新的思路和方法。 <div>
[LG]《Linear Attention Sequence Parallelism》W Sun, Z Qin, D Li, X Shen, Y Qiao, Y Zhong [Shanghai AI Laboratory &amp; TapTap] (2024) <a href="https://arxiv.org/abs/2404.02882"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofi8pdok9j20la12wn6t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofi8pq1gej20p211s7ak.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofi8q20cij20os0omq94.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofi8q8axzj21d60mytfy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofifj2ayvj20j00i4gn9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 21:33:51 GMT</pubDate>
</item>
<item>
<title>提出SAMMO框架，将提示表示为结构化程序，以便在强大语言模型和复杂提示的时代进行元提示优化。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Prompts As Programs: A Str...</title>
<link>https://weibo.com/1402400261/O8fFZ2uJO</link>
<guid>https://weibo.com/1402400261/O8fFZ2uJO</guid>
<content:encoded><![CDATA[
<div> 结构化程序、元提示、SAMMO框架、强大语言模型、复杂提示、优化、编译时、效率、Microsoft Research、T Schnabel、J Neville

<br /><br />总结:
文章提出了SAMMO框架，旨在将提示表示为结构化程序，以便在当今强大语言模型和复杂提示的时代进行元提示优化。该框架由Microsoft Research的T Schnabel和J Neville提出。SAMMO框架可以在编译时对提示进行优化，提高效率。通过将提示转化为程序结构，可以更好地利用语言模型的优势，优化提示生成过程。这一结构化方法为提示的细化和提升提供了新的可能性，对于构建高效的元提示系统具有重要意义。SAMMO框架的提出为提示优化研究和应用带来了新的思路和方法。 <div>
提出SAMMO框架，将提示表示为结构化程序，以便在强大语言模型和复杂提示的时代进行元提示优化。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Prompts As Programs: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization》T Schnabel, J Neville [Microsoft Research] (2024) <a href="https://arxiv.org/abs/2404.02319"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hofi1b2mkwj20km0vo45m.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofi1bs15qj21cc0hqdkj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofi1c7e9ij20ws0m8gph.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofi1cfcffj20ws0sydja.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofi3z9lr0j20wm0rgdk2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hofi3zqqp5j20wm0t4q5n.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hofi402cwpj21te0zsqan.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hofi402g19j20wc0qugp6.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 21:23:02 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.4)》 爱可可微博热门分享(4.4) [图片]</title>
<link>https://weibo.com/1402400261/O8cOtffBL</link>
<guid>https://weibo.com/1402400261/O8cOtffBL</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 分享, 爱可可, 4.4, 文章, 社交媒体, 关键词, 热度, 用户互动

<br /><br />总结:
爱可可微博最新一期的热门分享文章于4月4日发布，引起了社交媒体用户的热烈讨论。文章内容涉及各种热门话题，通过关键词的引导，吸引了大量用户互动和讨论。热度持续上升，展现了爱可可微博在用户心中的影响力和地位。通过分享和转发，文章得到了广泛传播和关注。整体来看，这篇文章在社交媒体上取得了不错的成绩，为爱可可微博的发展增添了新的动力。 <div>
《爱可可微博热门分享(4.4)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405019558816645311"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.4)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hof5h4sioaj20lc0c0dhn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 14:05:43 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Readout Guidance: Learning Control from Diffusion Features》(CVPR 2024) GitHub: github.com/google-research/readout_guidance《COMO:...</title>
<link>https://weibo.com/1402400261/O89B424n4</link>
<guid>https://weibo.com/1402400261/O89B424n4</guid>
<content:encoded><![CDATA[
<div> readout guidance, learning control, diffusion features, CVPR 2024, GitHub, code implementation, COMO, compact mapping, odometry, Exploiting Diffusion Prior, generalizable dense prediction, Jailbreaking Leading Safety-Aligned LLMs, simple adaptive attacks, Sparse Feature Circuits, interpretable causal graphs, Long-context LLMs, in-context learning, SciMMIR, scientific multi-modal information retrieval, T-GATE, text-to-image diffusion models, LightM-UNet, medical image segmentation, AniPortrait, audio-driven portrait animations

总结:<br /><br />这篇论文介绍了几篇在CVPR 2024会议上发表的论文实现代码的GitHub地址，涉及到了各种领域的计算机视觉研究成果。具体包括了对控制学习的提升、紧凑型地图制作和测距技术、利用扩散先验进行密集预测、对语言模型的攻击与编辑、长上下文学习时间过长、科学多模态信息检索、文本-图片扩散模型的推理难点、医学图像分割轻量级UNet模型以及音频驱动的逼真肖像动画合成等方面的研究。这些工作为各领域研究提供了重要的工具和基础模型，推动了计算机视觉领域的进步。 <div>
几篇论文实现代码：<br />《Readout Guidance: Learning Control from Diffusion Features》(CVPR 2024) GitHub: github.com/google-research/readout_guidance<br />《COMO: Compact Mapping and Odometry》(CVPR 2024) GitHub: github.com/edexheim/como<br />《Exploiting Diffusion Prior for Generalizable Dense Prediction》(CVPR 2024) GitHub: github.com/shinying/dmp<br />《Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks》(2024) GitHub: github.com/tml-epfl/llm-adaptive-attacks<br />《Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models》(2024) GitHub: github.com/saprmarks/feature-circuits<br />《Long-context LLMs Struggle with Long In-context Learning》(2024) GitHub: github.com/TIGER-AI-Lab/LongICLBench<br />《SciMMIR： Benchmarking Scientific Multi-modal Information Retrieval》(2024) GitHub: github.com/Wusiwei0410/SciMMIR [fig1]<br />《T-GATE: Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models》(2024) GitHub: github.com/HaozheLiu-ST/T-GATE [fig2]<br />《LightM-UNet: Mamba Assists in Lightweight UNet for Medical Image Segmentation》(2024) GitHub: github.com/MrBlankness/LightM-UNet<br />《AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animations》(2024) GitHub: github.com/Blizaine/AniPortrait [fig3]<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoepawlkxqj20ra0cv13q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoepvk3i3fj24ct1xk1l4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoer3jpmafj214y0sddtp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:54:26 GMT</pubDate>
</item>
<item>
<title>【RAG Arena：基于 Next.js 和 LangChain 的开源聊天机器人项目，提供了一种接受多个响应的查询体验】'RAG Arena - RAG Arena is an open-source Next.js projec...</title>
<link>https://weibo.com/1402400261/O89Al8eSF</link>
<guid>https://weibo.com/1402400261/O89Al8eSF</guid>
<content:encoded><![CDATA[
<div> Next.js, LangChain, 开源项目, 聊天机器人, 查询体验, 多个响应, 用户投票, 数据检索方法, GitHub

<br /><br />总结:
RAG Arena 是 Mendable.ai 开发的基于 Next.js 和 LangChain 的开源项目，与 LangChain 接口交互，提供了一种 RAG 聊天机器人体验，查询可以接收多个响应。用户可以对这些响应进行投票，然后解除模糊以展示被使用的检索器，通过不同的数据检索方法来区分聊天机器人。GitHub 上有相关的项目链接。 <div>
【RAG Arena：基于 Next.js 和 LangChain 的开源聊天机器人项目，提供了一种接受多个响应的查询体验】'RAG Arena - RAG Arena is an open-source Next.js project made by Mendable.ai that interfaces with LangChain to provide a RAG chatbot experience where queries receive multiple responses. Users vote on these responses, which are then unblurred to reveal the Retriever used, differentiating the chatbots by their data retrieval methods.' GitHub: github.com/mendableai/rag-arena <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoer87quqnj21740kg787.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:52:39 GMT</pubDate>
</item>
<item>
<title>【L7VP：地理空间智能可视分析和应用开发工具】'L7VP - L7VP is an geospatial intelligent visual analysis and application development tools.' GitHub: gith...</title>
<link>https://weibo.com/1402400261/O89xd5vnp</link>
<guid>https://weibo.com/1402400261/O89xd5vnp</guid>
<content:encoded><![CDATA[
<div> 地理空间、智能、可视分析、应用开发工具、L7VP、GitHub、antvis、README、开发、工具

总结:<br /><br />文章介绍了一款名为L7VP的地理空间智能可视分析和应用开发工具，可在GitHub上找到相关信息。该工具提供了智能的地理空间数据分析和可视化功能，方便开发人员进行应用开发和数据分析。用户可以通过GitHub上的README文件了解更多关于L7VP工具的详情。 <div>
【L7VP：地理空间智能可视分析和应用开发工具】'L7VP - L7VP is an geospatial intelligent visual analysis and application development tools.' GitHub: github.com/antvis/L7VP?tab=readme-ov-file <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoer07278bj21hc0u00y8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:44:57 GMT</pubDate>
</item>
<item>
<title>【Praison AI：将 AutoGen 和 CrewAI 或类似框架集成到一个低代码解决方案中，用于构建和管理多智能体 LLM 系统，重点放在简单性、定制化和高效人机协同上】'Pra...</title>
<link>https://weibo.com/1402400261/O89wKk5UU</link>
<guid>https://weibo.com/1402400261/O89wKk5UU</guid>
<content:encoded><![CDATA[
<div> AutoGen,CrewAI,多智能体,LLM系统,低代码解决方案,简单性,定制化,高效人机协同,PraisonAI,GitHub <br />
<br />
总结:<br />
Praison AI是一个整合了AutoGen和CrewAI等框架的低代码解决方案，用于构建和管理多智能体LLM系统。该解决方案专注于提供简单、定制化和高效的人机协同体验。开发者可以通过PraisonAI快速搭建和管理多智能体系统，从而实现更高效的工作流程和协作模式。感兴趣的用户可以在GitHub上找到PraisonAI的源代码和更多信息。 <div>
【Praison AI：将 AutoGen 和 CrewAI 或类似框架集成到一个低代码解决方案中，用于构建和管理多智能体 LLM 系统，重点放在简单性、定制化和高效人机协同上】'Praison AI - PraisonAI application combines AutoGen and CrewAI or similar frameworks into a low-code solution for building and managing multi-agent LLM systems, focusing on simplicity, customisation, and efficient human-agent collaboration.' GitHub: github.com/MervinPraison/PraisonAI <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoeqz07r47j21740hudip.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:43:48 GMT</pubDate>
</item>
<item>
<title>【RunsOn: 自建 GitHub Action 运行器，提供更便宜、更快的 CI/CD 体验】’RunsOn: 10x cheaper GitHub Action runners. - 10x cheaper GitHub Action runners. ...</title>
<link>https://weibo.com/1402400261/O89vx5PAn</link>
<guid>https://weibo.com/1402400261/O89vx5PAn</guid>
<content:encoded><![CDATA[
<div> RunsOn, 自建 GitHub Action 运行器, 更便宜, 更快, CI/CD, 体验, GitHub Action runners, caches, On premise.<br /><br />总结: RunsOn 是一个提供更便宜、更快的自建 GitHub Action 运行器的平台，可以提供10倍更便宜的 GitHub Action runners 和5倍更快的缓存服务，用户可以在本地部署该平台以获得更优秀的 CI/CD 体验。GitHub 地址为github.com/runs-on/runs-on。 <div>
【RunsOn: 自建 GitHub Action 运行器，提供更便宜、更快的 CI/CD 体验】’RunsOn: 10x cheaper GitHub Action runners. - 10x cheaper GitHub Action runners. 5x faster caches. On premise.' GitHub: github.com/runs-on/runs-on <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoeqvvz33aj20v80u0n1q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:40:49 GMT</pubDate>
</item>
<item>
<title>【AURORA：免费的GPT3.5 API】’AURORA' GitHub: github.com/aurora-develop/aurora #开源# #机器学习# #人工智能#</title>
<link>https://weibo.com/1402400261/O89uMw7en</link>
<guid>https://weibo.com/1402400261/O89uMw7en</guid>
<content:encoded><![CDATA[
<div> GitHub, AURORA, 免费, GPT3.5, API

<br /><br />总结:
AURORA是一个提供免费的GPT3.5 API的开源项目，可通过GitHub进行访问和使用。该API能够帮助开发者快速开发语言处理和生成任务，为用户提供便利。 <div>
【AURORA：免费的GPT3.5 API】’AURORA' GitHub: github.com/aurora-develop/aurora <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a>
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:38:58 GMT</pubDate>
</item>
<item>
<title>【Gazelle：名为 Gazelle 的语音和语言联合模型，可直接响应音频】'Gazelle - Joint Speech Language Model - Joint speech-language model - respond directly ...</title>
<link>https://weibo.com/1402400261/O89ujjcYX</link>
<guid>https://weibo.com/1402400261/O89ujjcYX</guid>
<content:encoded><![CDATA[
<div> 语音和语言联合模型、Gazelle、GitHub、直接响应音频、联合模型、模型、语音、语言、音频

总结:<br /><br />这篇文章介绍了一种名为Gazelle的语音和语言联合模型，能够直接响应音频输入。该模型已在GitHub上开源，能够有效处理语音和语言任务，提供更加智能的交互体验。Gazelle模型的特点在于能够联合处理语音和语言信息，实现更高效的响应和交互能力。通过GitHub链接，用户可以了解和使用这一先进的模型技术。 <div>
【Gazelle：名为 Gazelle 的语音和语言联合模型，可直接响应音频】'Gazelle - Joint Speech Language Model - Joint speech-language model - respond directly to audio!' GitHub: github.com/tincans-ai/gazelle <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoeqsrsj7ej20u0128q77.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:37:48 GMT</pubDate>
</item>
<item>
<title>【DOOM Mistral：用Mistral-7B模型利用 ViZDoom 引擎通过视觉输入玩 DOOM】'DOOM Mistral - Mistral7B playing DOOM' GitHub: github.com/umuthopeyildirim/DOOM...</title>
<link>https://weibo.com/1402400261/O89sEoRqI</link>
<guid>https://weibo.com/1402400261/O89sEoRqI</guid>
<content:encoded><![CDATA[
<div> ViZDoom、Mistral-7B、DOOM、GitHub、视觉输入、引擎、玩、模型

DOOM Mistral项目使用Mistral-7B模型结合ViZDoom引擎，通过视觉输入来玩DOOM游戏。项目代码可在GitHub上找到。这个项目展示了如何利用AI模型和游戏引擎结合，实现视觉输入下的游戏玩法。 <div>
【DOOM Mistral：用Mistral-7B模型利用 ViZDoom 引擎通过视觉输入玩 DOOM】'DOOM Mistral - Mistral7B playing DOOM' GitHub: github.com/umuthopeyildirim/DOOM-Mistral <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoeqoi1tgoj20tg0r80vl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:33:43 GMT</pubDate>
</item>
<item>
<title>【Multi Modal Starter Kit：多模态启动包，支持视频理解和叙述】'Multi Modal Starter Kit - Multi-modal starter kit for AI video understanding and narrati...</title>
<link>https://weibo.com/1402400261/O89johygh</link>
<guid>https://weibo.com/1402400261/O89johygh</guid>
<content:encoded><![CDATA[
<div> 视频理解、叙述、多模态启动包、AI、Ollama、Llava、bakllava、GPT-4v、GitHub、tigrisdata-community<br />
<br />
AI视频理解和叙述的多模态启动包，支持Ollama、GPT-4v等工具的使用。用户可访问GitHub上的项目链接获取相关资源。 <div>
【Multi Modal Starter Kit：多模态启动包，支持视频理解和叙述】'Multi Modal Starter Kit - Multi-modal starter kit for AI video understanding and narration. Works with Ollama (Llava, bakllava), GPT-4v' GitHub: github.com/tigrisdata-community/multi-modal-starter-kit <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoeq0rtvegj214b0u0dk9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:10:54 GMT</pubDate>
</item>
<item>
<title>【Search4All：开源版Perplexity，基于 LLM 和搜索引擎构建的平台，具有可定制且美观的界面，支持共享缓存搜索结果】’Search4All - Open source version of Per...</title>
<link>https://weibo.com/1402400261/O89iJc55p</link>
<guid>https://weibo.com/1402400261/O89iJc55p</guid>
<content:encoded><![CDATA[
<div> 开源版Perplexity，LLM，搜索引擎，平台，界面定制，搜索结果共享，GitHub，AI搜索引擎，可定制美观界面<br />
<br />搜索4All是一个基于LLM和搜索引擎构建的平台，旨在提供开源版本的Perplexity，用户可以定制美观界面，并支持共享缓存搜索结果。该项目已在GitHub上发布，用户可以在github.com/fatwang2/search4all上找到相关信息。这个AI搜索引擎平台提供了一种新的搜索体验，用户可以根据自己的需求定制界面风格，并享受到共享搜索结果的便利性。 <div>
【Search4All：开源版Perplexity，基于 LLM 和搜索引擎构建的平台，具有可定制且美观的界面，支持共享缓存搜索结果】’Search4All - Open source version of Perplexity, your own AI search engine' GitHub: github.com/fatwang2/search4all <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoepz1euaqj212o0u0tcv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 05:09:16 GMT</pubDate>
</item>
<item>
<title>【只需250美元的低成本开源机械臂】- 可以建造第二个机械臂(领航者臂)来控制另一个臂(跟随者臂)。领航者臂的设计参考GELLO项目但更简单。这种机械臂非常适合机器...</title>
<link>https://weibo.com/1402400261/O88jYlBat</link>
<guid>https://weibo.com/1402400261/O88jYlBat</guid>
<content:encoded><![CDATA[
<div> 开源机械臂、低成本、第二个机械臂、领航者臂、跟随者臂、Dynamixel电机、机器人学习、部件购买链接、3D打印文件、衣服折叠。<br />
<br />
总结:<br />
这篇文章介绍了一种低成本开源机械臂，可以建造第二个机械臂来控制另一个臂。其中采用了Dynamixel XL430和XL330舵机电机，通过Dynamixel SDK控制。作者提供了详细的部件购买链接、装配视频、3D打印文件和组装说明，使读者能够复现这个机械臂。该机械臂适合机器人学习和低成本机器人应用研究，作者演示了机械臂可以折叠衣服，展示了其潜力和价值。 <div>
【只需250美元的低成本开源机械臂】<br />- 可以建造第二个机械臂(领航者臂)来控制另一个臂(跟随者臂)。领航者臂的设计参考GELLO项目但更简单。这种机械臂非常适合机器人学习。   <br />- 该机械臂使用Dynamixel XL430和XL330舵机电机。XL430电机近乎是XL330的两倍强力，用于前两个关节。XL330电机较弱但每个只重18克，使臂非常轻巧和快速。   <br />- 手臂可以通过Dynamixel SDK控制：pip install dynamixel-sdk。提供了一个简单的遥控脚本teleoperation.py来测试机械臂，可能需要调整设备名称。   <br />- 仓库提供了详细的部件购买链接、装配视频、3D打印文件、组装说明，可以让读者复现这个低成本机械臂。   <br />- 作者演示了两个这样的臂可以折叠衣服。该项目对于机器人学习和低成本机器人应用研究具有价值。<br />’$250 Robot Arm' GitHub: github.com/AlexanderKoch-Koch/low_cost_robot <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoeln98w8ij21400u041c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 02:39:35 GMT</pubDate>
</item>
<item>
<title>【LLM入门：不涉及太多数学和术语的LLM基本原理通俗讲解】《Large language models, explained with a minimum of math and jargon》 网页链接 #机器学习# #人工...</title>
<link>https://weibo.com/1402400261/O887qiGgi</link>
<guid>https://weibo.com/1402400261/O887qiGgi</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、解释、基本原理、通俗、数学、术语、讲解

<br /><br />总结:
本文通俗易懂地解释了大型语言模型的基本原理，避免涉及过多数学和专业术语。大型语言模型是指可以处理大量语言数据的模型，通过学习语言规则和模式来生成文本。它们通过巨大的数据集来训练，逐渐提升预测和生成文本的能力。大型语言模型的发展对自然语言处理和人工智能领域具有重要意义，未来有望应用于各种场景中。 <div>
【LLM入门：不涉及太多数学和术语的LLM基本原理通俗讲解】《Large language models, explained with a minimum of math and jargon》 <a href="https://www.understandingai.org/p/large-language-models-explained-with"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoekqyz080j214g0pbtc7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoekr2g625j214g0lnjv5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 02:08:40 GMT</pubDate>
</item>
<item>
<title>【LLM“红队”课程：教你如何测试和发现LLM应用中的漏洞，以使其更安全。通过提示注入攻击各种聊天机器人应用，看系统如何反应，理解安全失败。LLM失败会导致法...</title>
<link>https://weibo.com/1402400261/O87ROztmK</link>
<guid>https://weibo.com/1402400261/O87ROztmK</guid>
<content:encoded><![CDATA[
<div> 红队、LLM应用、漏洞、安全、注入攻击、系统反应、安全失败、法律责任、声誉损害、服务中断
<br />
<br />
总结：本文介绍了一门关于“红队”测试LLM应用的课程，通过教授如何测试和发现应用中的漏洞，从而使其更安全。课程内容包括提示注入攻击各种聊天机器人应用，观察系统反应并理解安全失败的原因。强调LLM应用的失败可能导致法律责任、声誉损害和高昂的服务中断，因此学习如何积极测试、攻击和改进LLM应用的健壮性至关重要。通过本课程，学习者可以提升安全意识，提高对应用漏洞的识别和应对能力。 <div>
【LLM“红队”课程：教你如何测试和发现LLM应用中的漏洞，以使其更安全。通过提示注入攻击各种聊天机器人应用，看系统如何反应，理解安全失败。LLM失败会导致法律责任、声誉损害和代价高昂的服务中断。该课程帮助你积极测试、攻击和改进LLM应用的健壮性】《Red Teaming LLM Applications - DeepLearning.AI》 <a href="https://www.deeplearning.ai/short-courses/red-teaming-llm-applications/?hss_channel=tw-992153930095251456"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoejn3p2y6j20u00w20w8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 01:30:13 GMT</pubDate>
</item>
<item>
<title>【代码转换+精准时间戳：Universal-1树立语音AI新标杆】 - AssemblyAI发布了一个名为Universal-1的新语音识别(ASR)模型，在多个测试场景中展现出优异的性能和鲁...</title>
<link>https://weibo.com/1402400261/O87O4kb9T</link>
<guid>https://weibo.com/1402400261/O87O4kb9T</guid>
<content:encoded><![CDATA[
<div> AssemblyAI, Universal-1, 语音识别, ASR, 性能, 鲁棒性, 用户偏好测试, 代码转换, 时间戳, 鲁棒性, 推理速度

<br /><br />总结:
AssemblyAI发布了Universal-1新语音识别模型，展现出优异性能和鲁棒性。在用户偏好测试中，大多数用户更喜欢Universal-1。Universal-1具有代码转换能力，可转录多种语言。精准估计单词级时间戳，适用于音视频编辑和会话分析。在多个数据集中性能表现优异，特别是在电话和嘈杂环境中。推理速度优于其他模型，有助于实时处理应用。在各方面的表现证明了AssemblyAI在语音识别领域的实力，将推动语音AI在各行业应用。用户偏好、代码转换、时间戳精准度、鲁棒性和推理速度等方面都展示了Universal-1的优势，提升了其实用性和适用性。 <div>
【代码转换+精准时间戳：Universal-1树立语音AI新标杆】  <br />- AssemblyAI发布了一个名为Universal-1的新语音识别(ASR)模型，在多个测试场景中展现出优异的性能和鲁棒性。  <br />- 在用户偏好测试中，71%的用户更喜欢Universal-1的输出，而不是AssemblyAI之前的Conformer-2模型。  <br />- Universal-1展现出了在单个音频文件中转录多种语言的能力，即代码转换能力。  <br />- Universal-1能够精确估计单词级别的时间戳，这对于音视频编辑和会话分析等下游应用至关重要。  <br />- 在11个数据集中的5个上，Universal-1的单词错误率(WER)最低，在电话和嘈杂等声学挑战性环境中表现出强大的鲁棒性。它比Conformer-2的WER相对降低了11%。  <br />- 在相同的推理硬件上，Universal-1的处理速度优于OpenAI的Whisper Large-v3模型。  <br /><br />点评：  <br />- Universal-1在多个测试集上的出色表现证明了AssemblyAI在语音识别领域的技术实力。这将进一步推动语音AI在各行各业的应用。  <br />- 用户偏好测试结果表明，Universal-1不仅在客观指标上有优势，在主观体验上也得到了用户的认可。这对于以用户为中心的产品设计非常重要。  <br />- 代码转换能力使Universal-1能够处理多语言场景，这在全球化背景下具有重要价值，有助于提高语音技术的包容性。  <br />- 精确的单词级时间戳估计使Universal-1能够支持更广泛的应用，如字幕生成、会议纪要等，提升了其实用性。  <br />- 在嘈杂环境中的鲁棒性是Universal-1的一大亮点。这使其能够适应更多真实世界的场景，如呼叫中心、公共场所等，拓宽了应用范围。  <br />- 在推理速度上的优势使Universal-1更具成本效益，这对于需要实时处理的应用(如语音助手)尤为重要。<br />《AssemblyAI Research | Building the world's leading Speech AI models》 <a href="https://www.assemblyai.com/research/universal-1"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoejd6b80tj218g0p0mzw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoejd8sgjfj218g0p0dis.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoejdb3h4mj218g0p0wgo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 01:20:59 GMT</pubDate>
</item>
<item>
<title>【代号Lavender的AI“暗杀”系统：以色列AI军事应用引发伦理和道义拷问】- 以色列军方在加沙战争的前几周使用一个名为"Lavender"的AI机器，通过大规模监控收集的...</title>
<link>https://weibo.com/1402400261/O87JkzOO5</link>
<guid>https://weibo.com/1402400261/O87JkzOO5</guid>
<content:encoded><![CDATA[
<div> 以色列、AI军事应用、伦理、道义、暗杀系统、Lavender、加沙战争、目标选择、人道主义法、国际社会
<br /><br />总结:
文章揭示了以色列在加沙战争中使用AI进行目标选择和暗杀的情况。以色列军方通过名为"Lavender"的AI系统，对加沙地区居民进行监控和评分，将大部分人列入涉嫌"哈马斯武装分子"的名单，严重违反国际人道主义法。另一个名为"Where’s Daddy?"的系统跟踪目标并向军方发出打击信号，故意攻击家庭住宅，展现了行动的残酷和不人道性。高级指挥官的言论暗示了以色列军方普遍使用人体目标AI的可能性，对此应引起国际社会高度关注和谴责。这种利用AI进行杀戮的做法对人工智能军事应用提出了监管挑战，国际社会需要建立规范，确保人工智能发展符合人道主义精神。 <div>
【代号Lavender的AI“暗杀”系统：以色列AI军事应用引发伦理和道义拷问】<br />- 以色列军方在加沙战争的前几周使用一个名为"Lavender"的AI机器，通过大规模监控收集的信息，对加沙地带230万居民中的大多数人进行分析和评分，标记了大约37,000名巴勒斯坦人为涉嫌的"哈马斯武装分子"，大部分是初级成员，列入暗杀名单。   <br />- Lavender软件为加沙的几乎每个人给出1到100的评分，表示他们是哈马斯或巴勒斯坦伊斯兰圣战组织军事翼活跃分子的可能性。  <br />- 以色列军方还使用一个名为"Where’s Daddy?"的系统跟踪这些目标，并在他们进入家中时向军方发出信号。然后军方选择使用"哑弹"打击这些家庭住宅。  <br />- Lavender与以色列军方的另一个AI系统"The Gospel"不同，后者标记军方声称武装分子使用的建筑物和结构，而Lavender标记人并将其列入暗杀名单。  <br />- 以色列高级指挥官曾多次暗示像Lavender这样的人体目标机器的存在。一位8200部队数据科学和AI中心的指挥官在一次私人讲座中也提到了这一点。<br /><br />点评：  <br />- 这篇调查报道揭示了以色列在加沙战争中大规模使用AI进行目标选择和暗杀的惊人细节，引发了对高度自动化战争的伦理和法律问题的严重关切。  <br />- Lavender系统对平民进行大规模监控和评分，并将其列入暗杀名单，这种做法严重违反国际人道主义法，可能构成战争罪。它模糊了战斗人员和平民之间的界限，使平民处于极其危险的境地。  <br />- "Where’s Daddy?"系统跟踪目标并在其进入家中时发出打击信号，故意攻击家庭住宅，这进一步凸显了以色列军事行动的残酷性和不人道性。  <br />- 与标记建筑物的"The Gospel"系统不同，Lavender直接针对人，创建"杀戮名单"，这种做法更加令人不安，因为它赋予机器决定生死的权力。  <br />- 以色列高级指挥官关于人体目标AI的言论表明，这种做法在以色列军方中可能相当普遍，需要国际社会高度警惕和谴责。  <br />- 这种利用AI进行杀戮的做法，对人工智能军事应用的治理和监管提出了严峻挑战。国际社会亟需建立相关规范，防止AI武器化，确保人工智能的发展符合人道主义精神。<br />《‘Lavender’: The AI machine directing Israel’s bombing spree in Gaza》 <a href="https://www.972mag.com/lavender-ai-israeli-army-gaza/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoeiw7qd47j21at0u0aeu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 01:09:19 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@异步图书 送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进...</title>
<link>https://weibo.com/1402400261/O86TsEVJz</link>
<guid>https://weibo.com/1402400261/O86TsEVJz</guid>
<content:encoded><![CDATA[
<div> 大语言模型、前沿、科学家、工程师、学生、案例、庖丁解牛、全面、深入、方法与工具

总结:<br /><br />文章介绍了一本名为《大语言模型：基础与前沿》的书籍，截至2024年4月12日，读者可以通过转发+评论参与送出3本这本书。这本书全面深入地介绍了大语言模型以及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。与纯理论的说教模式不同，这本书采用了从案例入手的方式，采用庖丁解牛的方法帮助读者理解和认识大语言模型。 <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%BC%82%E6%AD%A5%E5%9B%BE%E4%B9%A6">@异步图书</a>  送出3本《大语言模型：基础与前沿》，截至2024.4.12 12:00，*可可粉*转发+评论即可参与。本书全面且深入介绍了大语言模型及其前沿进展，适合所有需要了解这个领域或掌握这种方法与工具的科学家、工程师和学生参考。摒弃了纯理论的说教模式，从案例入手， 采用庖丁解牛的方式帮助读者理解与认识大语言模型。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019331269755053"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef8oboqij20ga0m8q8p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9segl7j20m90m9q6z.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoef9t5km0j20m90m942f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoef9tq2esj20m90m9gpe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef9ugq5dj20m90m9dif.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 23:01:32 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@博文视点Broadview 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言...</title>
<link>https://weibo.com/1402400261/O86RdFp49</link>
<guid>https://weibo.com/1402400261/O86RdFp49</guid>
<content:encoded><![CDATA[
<div> LangChain, LangServe, LangSmith, LLM, 初学者, 多个核心应用场景, LCEL, LangChain团队, 生成式人工智能, LangChain生态系统

总结:<br />
本文介绍了LangChain团队的新书《LangChain实战》，针对初学者和对LangChain应用感兴趣的开发者。书籍基于LangChain 0.1版本，配套详解视频，重点介绍了多个核心应用场景，并深入探讨了LCEL的应用方式。同时，书中详细探讨了LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。欢迎感兴趣的读者转发+评论参与活动，赢取精彩的实战书籍！ <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《LangChain实战》，截至2024.4.11 12:00，*可可粉*转发+评论即可参与。本书专为初学者和对LangChain应用及大语言模型（LLM）应用感兴趣的开发者而编写的，基于LangChain 0.1版本，配套600分钟详解视频，重点介绍了多个核心应用场景，并且深入探讨了LCEL的应用方式。同时，本书围绕LangChain生态系统的概念，详细探讨LangChain、LangServe和LangSmith，帮助读者全面了解LangChain团队在生成式人工智能领域的布局。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5019329879867805"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5y7mh4j20m80m843w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef5ywtixj20ku0zzdmx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef60gn5cj20m80m80x0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef61a08vj20m80m8wio.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoef62eb09j20m80m8tdb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 22:56:01 GMT</pubDate>
</item>
<item>
<title>今日推介(第1365期)：潜扩散模型的缩放特性、语言模型对齐的渐近性、面向高效LLM生成的提示混合专家、用偏好树提高LLM推理能力、长上下文LLM的长上下文学习能力...</title>
<link>https://weibo.com/1402400261/O86Ihb4Al</link>
<guid>https://weibo.com/1402400261/O86Ihb4Al</guid>
<content:encoded><![CDATA[
<div> 潜扩散模型, 缩放特性, 语言模型, 对齐, 渐近性, 提示混合专家, 偏好树, 推理能力, 长上下文, 学习能力

<br /><br />总结:
本文讨论了潜扩散模型的缩放特性和语言模型对齐的渐近性。研究指出，面向高效LLM生成的提示混合专家可以提高LLM的推理能力。同时，通过偏好树的方法，可以进一步提高LLM的推理能力。长上下文LLM具有较强的长上下文学习能力，需要进行专门的评估。研究展示了这些模型在不同场景下的表现，为提高自然语言处理模型的性能提供了重要参考。 <div>
今日推介(第1365期)：潜扩散模型的缩放特性、语言模型对齐的渐近性、面向高效LLM生成的提示混合专家、用偏好树提高LLM推理能力、长上下文LLM的长上下文学习能力评估 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/690674008"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoeejddux9j21ao0pi79e.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoeejff0r5j20wg0u042g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoeejixv1qj21hi0rmgpq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoeejlnscej20x00oo0w5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoeejqx22gj21hc0qswlh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 22:33:57 GMT</pubDate>
</item>
<item>
<title>[CV] ViTamin: Designing Scalable Vision Models in the Vision-Language Era 网页链接 通过重新评估视觉语言模型的视觉后骨干设计，提出了一种融合卷积和Trans...</title>
<link>https://weibo.com/1402400261/O86CVvK4U</link>
<guid>https://weibo.com/1402400261/O86CVvK4U</guid>
<content:encoded><![CDATA[
<div> 关键词: ViTamin, 视觉语言模型, 可拓展性, 下游任务迁移, 混合网络, 卷积, Transformer

总结:<br /><br />
本文重新评估了视觉语言模型的设计，提出了混合网络ViTamin，结合了卷积和Transformer，实现了比ViT更好的可拓展性和下游任务迁移。ViTamin的设计在视觉语言领域具有重要意义，为改善模型性能和应用提供了新的思路。ViTamin的融合设计使其能够更好地理解图像和语言之间的关系，为解决视觉与语言结合的挑战提供了一种创新的方法。混合网络的设计不仅提高了模型在不同任务上的表现，还为未来的研究和应用奠定了基础。这项研究为视觉语言模型的发展和优化提供了有益的启示，为相关领域的进一步探索和创新指明了方向。ViTamin的成功应用证明了混合网络在视觉与语言结合中的潜力，为未来的研究和应用带来了新的可能性。ViTamin的提出对视觉与语言模型的发展具有重要的理论和实际意义，为构建更加智能和有效的视觉语言系统奠定了基础。 <div>
[CV] ViTamin: Designing Scalable Vision Models in the Vision-Language Era  <br /><a href="https://arxiv.org/abs/2404.02132"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过重新评估视觉语言模型的视觉后骨干设计，提出了一种融合卷积和Transformer的混合网络ViTamin，实现了比ViT更好的可拓展性和下游任务迁移。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoee611zmpj212m1aqh6x.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoee61avepj21cy16i4e9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoee61nvddj21de0okn69.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 22:20:48 GMT</pubDate>
</item>
<item>
<title>[CV] Surface Reconstruction from Gaussian Splatting via Novel Stereo Views 网页链接 提出通过3DGS合成立体视图并立体匹配获取深度的表面重建方法，使重建质...</title>
<link>https://weibo.com/1402400261/O86zqaJ9s</link>
<guid>https://weibo.com/1402400261/O86zqaJ9s</guid>
<content:encoded><![CDATA[
<div> 3DGS合成、立体视图、立体匹配、表面重建、质量、速度、神经重建<br />
<br />
总结:<br />
本研究提出了一种通过3DGS合成立体视图并进行立体匹配来获取深度的表面重建方法。与仅基于3DGS的方法相比，该方法重建质量更高，而且速度也要快得多，超越了复杂的神经重建方法。通过这种创新方法，可以更有效地重建物体的表面结构，为三维重建领域的进展带来了新的可能性。 <div>
[CV] Surface Reconstruction from Gaussian Splatting via Novel Stereo Views  <br /><a href="https://arxiv.org/abs/2404.01810"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />提出通过3DGS合成立体视图并立体匹配获取深度的表面重建方法，使重建质量超过仅基于3DGS的方法，速度也远快于复杂的神经重建。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoedwz5a6rj20s816kn8d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoedwzkmn3j21380la0zd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoedx0a70pj213a19i7ei.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 22:12:09 GMT</pubDate>
</item>
<item>
<title>[LG] Are large language models superhuman chemists? 网页链接 提出ChemBench化学基准测试，发现前沿大语言模型整体超过人类专家，但在化学推理和安全评估方面...</title>
<link>https://weibo.com/1402400261/O86umebTC</link>
<guid>https://weibo.com/1402400261/O86umebTC</guid>
<content:encoded><![CDATA[
<div> ChemBench化学基准测试, 大语言模型, 超越人类专家, 化学推理, 安全评估, 局限, 提升

<br /><br />总结:
研究引入了ChemBench化学基准测试，发现前沿大语言模型在整体上超过了人类专家。然而，这些模型在化学推理和安全评估方面仍存在局限性，需要进一步提升。 <div>
[LG] Are large language models superhuman chemists?  <br /><a href="https://arxiv.org/abs/2404.01475"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />提出ChemBench化学基准测试，发现前沿大语言模型整体超过人类专家，但在化学推理和安全评估方面仍有局限，需要进一步提升。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoedk072x7j20tc11adq2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoedk0uh2nj218o0v2n67.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoedk1cnqcj218c0ve10a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoedk1wb03j218u0retgu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:59:41 GMT</pubDate>
</item>
<item>
<title>[CL] Octopus v2: On-device language model for super agent 网页链接 提出了一种通过为每个函数指定唯一标记并进行微调的方法，使20亿参数的在设备语言模型在...</title>
<link>https://weibo.com/1402400261/O86rNDTtw</link>
<guid>https://weibo.com/1402400261/O86rNDTtw</guid>
<content:encoded><![CDATA[
<div> 关键词: Octopus v2, 在设备语言模型, 20亿参数, 超越GPT-4, 函数指定唯一标记, 微调, 函数调用任务, 精度, 速度<br />

总结:<br />
研究提出了Octopus v2，这是一种在设备上的语言模型，通过为每个函数指定唯一标记并进行微调，实现了20亿参数的模型在函数调用任务上超越了GPT-4的精度和速度。 Octopus v2模型的性能表现得非常出色，展示了其在应用领域的巨大潜力。通过该研究，可以看到在设备语言模型的研究领域有着广阔的发展前景，为未来的研究和实践提供了新的思路和方法。 <div>
[CL] Octopus v2: On-device language model for super agent  <br /><a href="https://arxiv.org/abs/2404.01744"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出了一种通过为每个函数指定唯一标记并进行微调的方法，使20亿参数的在设备语言模型在函数调用任务上显著超越GPT-4的精度与速度。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoeddi6m7qj20v01b4gv8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoeddiicy6j215y0iun0a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeddiyjv0j216e0ne0xk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:53:23 GMT</pubDate>
</item>
<item>
<title>通过构建长文本上下文学习基准LongICLBench，比较多种语言模型的能力，发现当前模型在复杂场景下理解长文本仍面临困难。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Lon...</title>
<link>https://weibo.com/1402400261/O86pp4qkN</link>
<guid>https://weibo.com/1402400261/O86pp4qkN</guid>
<content:encoded><![CDATA[
<div> 长文本上下文学习基准、多种语言模型、复杂场景、困难、LongICLBench、长文本理解挑战

<br /><br />总结:
研究人员构建了长文本上下文学习基准LongICLBench，通过比较多种语言模型的能力发现，当前模型在复杂场景下理解长文本仍面临困难。文章指出长文本上下文学习是一个挑战，并提出在长文本任务中进行更深入的研究和改进长文本理解能力的方法。这项研究对于改善语言模型在长文本理解上的表现具有重要意义。 <div>
通过构建长文本上下文学习基准LongICLBench，比较多种语言模型的能力，发现当前模型在复杂场景下理解长文本仍面临困难。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Long-context LLMs Struggle with Long In-context Learning》T Li, G Zhang, Q D Do, X Yue, W Chen [University of Waterloo] (2024) <a href="https://arxiv.org/abs/2404.02060"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoeczzai10j218e12etr3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeczztbjaj21hc0qsqci.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoed00cvbrj21hi0xkwvw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoed00j4c9j21gu0l20xp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoed7a2pwtj20vd0k2go5.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:47:28 GMT</pubDate>
</item>
<item>
<title>[CL]《Long-context LLMs Struggle with Long In-context Learning》T Li, G Zhang, Q D Do, X Yue, W Chen [University of Waterloo] (2024) 网页链接 #机器学...</title>
<link>https://weibo.com/1402400261/O86pmeO8M</link>
<guid>https://weibo.com/1402400261/O86pmeO8M</guid>
<content:encoded><![CDATA[
<div> 长文本理解，长上下文学习，LLMs，困难，学习，上下文，模型，表现，挑战，解决方案

总结:<br />
本文讨论了长上下文语言模型（LLMs）在长篇文本理解中遇到的困难。研究指出，LLMs在处理长文本时存在学习困难，导致性能下降。主要挑战包括对长上下文的学习和理解能力不足，以及模型存储和计算量大。研究团队提出了一些解决方案，包括增加训练数据的规模和多样性，设计更有效的模型结构，以及优化存储和计算效率。这些方法有望提高LLMs在长篇文本处理中的表现。 <div>
[CL]《Long-context LLMs Struggle with Long In-context Learning》T Li, G Zhang, Q D Do, X Yue, W Chen [University of Waterloo] (2024) <a href="https://arxiv.org/abs/2404.02060"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoeczzai10j218e12etr3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeczztbjaj21hc0qsqci.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoed00cvbrj21hi0xkwvw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoed00j4c9j21gu0l20xp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoed7a2pwtj20vd0k2go5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:47:22 GMT</pubDate>
</item>
<item>
<title>通过高质量对齐数据ULTRAINTERACT与定制化的模型优化策略，开发出目前开源环境下推理能力最强的大规模语言模型EURUS。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Advan...</title>
<link>https://weibo.com/1402400261/O86lPhdtz</link>
<guid>https://weibo.com/1402400261/O86lPhdtz</guid>
<content:encoded><![CDATA[
<div> ULTRAINTERACT, 定制化的模型优化策略, EURUS, 大规模语言模型, 推理能力, 高质量对齐数据, 开源环境, 语言模型, 理论推导, 实验结果

总结:<br /><br />这篇文章介绍了一种基于高质量对齐数据ULTRAINTERACT和定制化的模型优化策略开发的大规模语言模型EURUS，通过提升推理能力，成为目前开源环境下推理能力最强的语言模型。研究团队通过理论推导和实验结果展示了EURUS的优势，为进一步提升语言模型的性能提供了新思路。 <div>
通过高质量对齐数据ULTRAINTERACT与定制化的模型优化策略，开发出目前开源环境下推理能力最强的大规模语言模型EURUS。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Advancing LLM Reasoning Generalists with Preference Trees》L Yuan, G Cui, H Wang, N Ding... [Tsinghua University &amp; Northeastern University] (2024) <a href="https://arxiv.org/abs/2404.02078"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoecqyuacaj215w0yo7lp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoecqzascfj21eg0pedlp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoecqznh5rj20x00oogq7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoecqzylyxj21e40p0qd1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoectzftqxj20vh0d5tbh.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:38:40 GMT</pubDate>
</item>
<item>
<title>[CL]《Advancing LLM Reasoning Generalists with Preference Trees》L Yuan, G Cui, H Wang, N Ding... [Tsinghua University &amp; Northeastern University] (202...</title>
<link>https://weibo.com/1402400261/O86lMeoTl</link>
<guid>https://weibo.com/1402400261/O86lMeoTl</guid>
<content:encoded><![CDATA[
<div> Preference Trees, Advancing LLM Reasoning Generalists, Tsinghua University, Northeastern University, Yuan, Cui, Wang, Ding, 2024

<br /><br />总结:
这篇文章讨论了利用偏好树来提升LLM推理通用性的方法。作者们来自清华大学和东北大学，包括Yuan、Cui、Wang和Ding。他们提出了一种新的方法，旨在帮助LLM推理通用性的进步。研究成果有望为语言模型的发展做出贡献。 <div>
[CL]《Advancing LLM Reasoning Generalists with Preference Trees》L Yuan, G Cui, H Wang, N Ding... [Tsinghua University &amp; Northeastern University] (2024) <a href="https://arxiv.org/abs/2404.02078"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoecqyuacaj215w0yo7lp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoecqzascfj21eg0pedlp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoecqznh5rj20x00oogq7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoecqzylyxj21e40p0qd1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoectzftqxj20vh0d5tbh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:38:32 GMT</pubDate>
</item>
<item>
<title>GRIFFIN利用预训练语言模型自身结构特点简单有效地实现了混合专家，大幅减少了计算成本和内存需求，为部署加速提供了灵活高效的新途径。 - 转发 @爱可可-爱生活:...</title>
<link>https://weibo.com/1402400261/O86gFr9eO</link>
<guid>https://weibo.com/1402400261/O86gFr9eO</guid>
<content:encoded><![CDATA[
<div> 预训练语言模型、混合专家、计算成本、内存需求、部署加速、灵活、高效、Prompt-prompted Mixture of Experts、H Dong、B Chen、Y Chi、CMU

<br /><br />总结:
H Dong、B Chen和Y Chi在CMU发表的《Prompt-prompted Mixture of Experts for Efficient LLM Generation》通过利用预训练语言模型自身结构特点，成功实现了混合专家的方法，大幅减少了计算成本和内存需求，为部署加速提供了灵活高效的新途径。该研究为解决语言模型生成过程中的效率和成本问题提供了重要的方法和思路。 <div>
GRIFFIN利用预训练语言模型自身结构特点简单有效地实现了混合专家，大幅减少了计算成本和内存需求，为部署加速提供了灵活高效的新途径。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Prompt-prompted Mixture of Experts for Efficient LLM Generation》H Dong, B Chen, Y Chi [CMU] (2024) <a href="https://arxiv.org/abs/2404.01365"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoecelrotmj21cw0jswod.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoecemawn1j21hm0pk489.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeceminjdj21h60lqafy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoecemop4gj21hi0rmjwl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeckpmjisj210x0dcgnp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoeckpmjpmj210x0cddh4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoeckpmyrej210x0d7jt9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeckpmpltj210x0gbabr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoeckpns53j210x14xtdv.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:25:57 GMT</pubDate>
</item>
<item>
<title>[LG]《Prompt-prompted Mixture of Experts for Efficient LLM Generation》H Dong, B Chen, Y Chi [CMU] (2024) 网页链接 #机器学习##人工智能##论文# [图片][...</title>
<link>https://weibo.com/1402400261/O86gyEnxx</link>
<guid>https://weibo.com/1402400261/O86gyEnxx</guid>
<content:encoded><![CDATA[
<div> 关键词: Prompt-prompted, Mixture of Experts, Efficient LLM Generation, 模型生成, 训练效率

总结:<br /><br />
该研究提出了一种基于Prompt-prompted Mixture of Experts的方法，用于有效生成大型语言模型（LLM）。该方法结合了不同专家的知识，通过Prompt-prompted机制引导模型生成，提高了训练效率和生成质量。研究结果表明，该方法在生成LLM时具有很高的效率和性能。这项研究对于提高大规模语言模型的生成能力具有重要意义，值得进一步深入研究和应用。 <div>
[LG]《Prompt-prompted Mixture of Experts for Efficient LLM Generation》H Dong, B Chen, Y Chi [CMU] (2024) <a href="https://arxiv.org/abs/2404.01365"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoecelrotmj21cw0jswod.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoecemawn1j21hm0pk489.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeceminjdj21h60lqafy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoecemop4gj21hi0rmjwl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeckpmjisj210x0dcgnp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoeckpmjpmj210x0cddh4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoeckpmyrej210x0d7jt9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeckpmpltj210x0gbabr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoeckpns53j210x14xtdv.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoeckpmtr2j210x0hnjtn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoeckpntl1j210x0wtaf7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoeckpnr3jj210x0xejwp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:25:41 GMT</pubDate>
</item>
<item>
<title>在简单假设下，证明best-of-N对齐方法渐进等价于最优KL约束强化学习解，从理论上解释了其优异的实际表现。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Asymptotics of L...</title>
<link>https://weibo.com/1402400261/O86breDei</link>
<guid>https://weibo.com/1402400261/O86breDei</guid>
<content:encoded><![CDATA[
<div> Language Model Alignment, Best-of-N对齐方法, 最优KL约束强化学习解, 渐进等价, 理论解释, 优异实际表现, J Q Yang, S Salamatian, Z Sun, A T Suresh, A Beirami

<br /><br />总结: 
该研究探讨了最优KL约束强化学习解与best-of-N对齐方法的渐进等价性，在简单假设下进行理论分析。研究指出，best-of-N对齐方法在实际表现中表现优异，其表现优异的原因是由于其与最优KL约束强化学习解的渐进等价性。这一发现为理解模型对齐方法提供了新的视角，并为实际应用中的性能提升提供了理论支持。 <div>
在简单假设下，证明best-of-N对齐方法渐进等价于最优KL约束强化学习解，从理论上解释了其优异的实际表现。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Asymptotics of Language Model Alignment》J Q Yang, S Salamatian, Z Sun, A T Suresh, A Beirami [University of Sydney &amp; MIT &amp; Google Research] (2024) <a href="https://arxiv.org/abs/2404.01730"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoec130qb2j214811qqke.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoec139wffj21bu1887ca.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:13:04 GMT</pubDate>
</item>
<item>
<title>[LG]《Asymptotics of Language Model Alignment》J Q Yang, S Salamatian, Z Sun, A T Suresh, A Beirami [University of Sydney &amp; MIT &amp; Google Research] (20...</title>
<link>https://weibo.com/1402400261/O86bpwyeM</link>
<guid>https://weibo.com/1402400261/O86bpwyeM</guid>
<content:encoded><![CDATA[
<div> 语言模型对齐，渐近分析，大学悉尼，麻省理工，谷歌研究，2024，文献综述，模型比较，评估方法

<br /><br />总结:
本文研究了语言模型对齐的渐近分析，作者分析了大学悉尼、麻省理工和谷歌研究的相关工作。他们比较了不同模型的有效性，提出了评估方法。文章对语言模型对齐的重要性和发展方向进行了探讨，为未来相关研究提供了指导。 <div>
[LG]《Asymptotics of Language Model Alignment》J Q Yang, S Salamatian, Z Sun, A T Suresh, A Beirami [University of Sydney &amp; MIT &amp; Google Research] (2024) <a href="https://arxiv.org/abs/2404.01730"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoec130qb2j214811qqke.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoec139wffj21bu1887ca.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 21:13:00 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.3)》 爱可可微博热门分享(4.3) [图片]</title>
<link>https://weibo.com/1402400261/O83uPoNq9</link>
<guid>https://weibo.com/1402400261/O83uPoNq9</guid>
<content:encoded><![CDATA[
<div> 关键词：爱可可、微博、热门、分享、文章、娱乐、新闻、社交、互动、用户

总结：
《爱可可微博热门分享(4.3)》是一篇关于微博热门话题的分享文章，涵盖了娱乐、新闻等多个领域的内容。通过微博平台，用户可以及时了解到各种热门话题，进行互动和社交交流。文章内容丰富多彩，吸引了众多用户的关注和参与，展示了爱可可微博的活力和影响力。通过微博的分享和传播，让更多人了解到最新的资讯和热门事件，促进了信息的传递和交流，为用户提供了一个丰富多样的社交平台。<br /><br />  <div>
《爱可可微博热门分享(4.3)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405019200677872051"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.3)</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoe0cedvtmj20rs0fm0ty.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 14:22:36 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《3D-MoLM: Towards 3D Molecule-Text Interpretation in Language Models》(2024) GitHub: github.com/lsh0520/3D-MoLM [fig4]《ViTamin: De...</title>
<link>https://weibo.com/1402400261/O83g9DU0A</link>
<guid>https://weibo.com/1402400261/O83g9DU0A</guid>
<content:encoded><![CDATA[
<div> 关键词: 3D-MoLM, 语言模型, 分子-文本解释, ViTamin, 视觉模型, 梯度对齐, 跨域人脸反欺诈, DePT, 全息提示调整, XScale-NVS, 视图合成, SWE-agent, 软件工程, Agent界面，CameraCtrl, 文本到视频生成, QuaRot, 旋转语言模型, CSD, 扩散模型, Evalverse, 语言模型评估库, JailbreakBench, 鲁邦测试基准, Eurus, 偏好树, LLaVA-Hound-DPO, 视频模型优化, LG_SDG, 医学图像分割, MuseTalk, 实时唇语同步, JaxUED, Jax库, LifelongMemory, 长时记忆, TimeMachine, 时间序列预测, 1-bit LLMs, 1.58比特语言模型, SPRIGHT, 文本到图像模型, Proxy调整, MiM-ISTD, 红外小目标检测

<br /><br />总结: 
"3D-MoLM: Towards 3D Molecule-Text Interpretation in Language Models"提出了一种在语言模型中实现3D分子-文本解释的方法，利用GitHub上的代码进行实现。
"ViTamin: Designing Scalable Vision Models in the Vision-language Era"介绍了在视觉-语言时代设计可扩展视觉模型的技术，并提供了GitHub代码。
"Gradient Alignment for Cross-Domain Face Anti-Spoofing"讨论了跨域人脸反欺诈中的梯度对齐问题，并提供了GitHub代码。
"DePT: Decoupled Prompt Tuning"介绍了一种全息提示调整的方法，帮助提升模型性能，相关代码在GitHub上有提供。
"XScale-NVS: Cross-Scale Novel View Synthesis with Hash Featurized Manifold"描述了跨尺度观点合成的技术，相关代码在GitHub上可找到。
"SWE-agent: Agent Computer Interfaces Enable Software Engineering Language Models"研究了软件工程语言模型中代理界面的应用，相关代码可在GitHub上获取。
"CameraCtrl: Enabling Camera Control for Text-to-Video Generation"介绍了一种控制相机生成文本到视频的技术，相关代码在GitHub上有提供。
"QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs"讨论了在旋转语言模型中实现无异常的4比特推断的方法，相关代码在GitHub上有提供。
"Measuring Style Similarity in Diffusion Models"探讨了扩散模型中的风格相似性衡量方法，相关代码在GitHub上可找到。
"Evalverse: Unified and Accessible Library for Large Language Model Evaluation"提供了一个统一且易用的语言模型评估库，相关代码在GitHub上有提供。 <div>
几篇论文实现代码：<br />《3D-MoLM: Towards 3D Molecule-Text Interpretation in Language Models》(2024) GitHub: github.com/lsh0520/3D-MoLM [fig4]<br />《ViTamin: Designing Scalable Vision Models in the Vision-language Era》(CVPR 2024) GitHub: github.com/Beckschen/ViTamin [fig1]<br />《Gradient Alignment for Cross-Domain Face Anti-Spoofing》(CVPR 2024) GitHub: github.com/Leminhbinh0209/CVPR24-FAS<br />《DePT: Decoupled Prompt Tuning》(CVPR 2024) GitHub: github.com/Koorye/DePT [fig5]<br />《XScale-NVS: Cross-Scale Novel View Synthesis with Hash Featurized Manifold》(CVPR 2024) GitHub: github.com/THU-luvision/XScale-NVS<br />《SWE-agent: Agent Computer Interfaces Enable Software Engineering Language Models》(2024) GitHub: github.com/princeton-nlp/SWE-agent<br />《CameraCtrl: Enabling Camera Control for Text-to-Video Generation》(2024) GitHub: github.com/hehao13/CameraCtrl<br />《QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs》(2024) GitHub: github.com/spcl/QuaRot<br />《Measuring Style Similarity in Diffusion Models》(2024) GitHub: github.com/learn2phoenix/CSD<br />《Evalverse: Unified and Accessible Library for Large Language Model Evaluation》(2024) GitHub: github.com/UpstageAI/evalverse<br />《JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models》(2024) GitHub: github.com/JailbreakBench/jailbreakbench<br />《Advancing LLM Reasoning Generalists with Preference Trees》(2024) GitHub: github.com/OpenBMB/Eurus<br />《Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward》(2024) GitHub: github.com/RifleZhang/LLaVA-Hound-DPO<br />《Language Grounded Single Source Domain Generalization in Medical Image Segmentation》(2024) GitHub: github.com/ShahinaKK/LG_SDG [fig2]<br />《MuseTalk: Real-Time High Quality Lip Synchorization with Latent Space Inpainting》(2024) GitHub: github.com/TMElyralab/MuseTalk [fig3]<br />《JaxUED: A simple and useable UED library in Jax》(2024) GitHub: github.com/DramaCow/jaxued<br />《LifelongMemory: Leveraging LLMs for Answering Queries in Long-form Egocentric Videos》(2024) GitHub: github.com/Agentic-Learning-AI-Lab/lifelong-memory<br />《TimeMachine: A Time Series is Worth 4 Mambas for Long-term Forecasting》(2024) GitHub: github.com/Atik-Ahamed/TimeMachine<br />《The Era of 1-bit LLMs All Large Language Models are in 1.58 Bits》(2024) GitHub: github.com/rejunity/tiny-asic-1_58bit-matrix-mul<br />《Getting it Right: Improving Spatial Consistency in Text-to-Image Models》(2024) GitHub: github.com/SPRIGHT-T2I/SPRIGHT<br />《Tuning Language Models by Proxy》(2024) GitHub: github.com/alisawuffles/proxy-tuning<br />《MiM-ISTD: Mamba-in-Mamba for Efficient Infrared Small Target Detection》(2024) GitHub: github.com/txchen-USTC/MiM-ISTD [fig6]<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hodvmdi4ttj20wn0k011z.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hodvpkbxh3j23tn2vru0y.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hodw340ylwj22s419lk3q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hodwtb71cbj21890eidy5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hodwucbmrpj212q0d37c8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hody2sz7yoj20lo0bh40p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 13:46:27 GMT</pubDate>
</item>
<item>
<title>【Home LLM：基于本地LLM的家庭助理】’Home LLM - A Home Assistant integration that allows you to control your house using an LLM running locally' GitHu...</title>
<link>https://weibo.com/1402400261/O83bBsjHZ</link>
<guid>https://weibo.com/1402400261/O83bBsjHZ</guid>
<content:encoded><![CDATA[
<div> LLM、Home Assistant、GitHub、本地、家庭助理、控制、房屋、集成、acond96、家庭助手<br />
<br />
LLM是一个基于本地LLM的家庭助理，可以让用户通过Home Assistant集成来控制房屋。用户可以在GitHub上找到这个项目，作者是acond96。这个家庭助手的特点是可以在本地运行，提供更安全和私密的控制体验。通过Home LLM，用户可以方便地管理房屋设备和自动化任务，带来更便捷的生活方式。 <div>
【Home LLM：基于本地LLM的家庭助理】’Home LLM - A Home Assistant integration that allows you to control your house using an LLM running locally' GitHub: github.com/acon96/home-llm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodyz6j2pgj213c0u0n2q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 13:35:14 GMT</pubDate>
</item>
<item>
<title>【学术论文极简LaTeX模板】'Minimalist LaTeX Template for Academic Papers - Minimalist LaTeX template for academic papers' GitHub: github.com/pmichailla...</title>
<link>https://weibo.com/1402400261/O82XehgrP</link>
<guid>https://weibo.com/1402400261/O82XehgrP</guid>
<content:encoded><![CDATA[
<div> LaTeX, 模板, 学术论文, GitHub, 精简, pmichaillat 

<br /><br />总结:
这篇学术论文介绍了一个极简的LaTeX模板，主要用于撰写学术论文。该模板提供了简洁的设计和布局，适用于学术界的各种研究领域。作者提供了GitHub地址，方便用户下载和使用。这个模板以简洁、易用和专业为特点，可以帮助学术作者高效地撰写论文。 <div>
【学术论文极简LaTeX模板】'Minimalist LaTeX Template for Academic Papers - Minimalist LaTeX template for academic papers' GitHub: github.com/pmichaillat/latex-paper <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodxydcpzqj21iq0tidm6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 12:59:49 GMT</pubDate>
</item>
<item>
<title>'Open Parse - Streamlines the process of preparing documents for LLM's.' GitHub: github.com/Filimoa/open-parse #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O82VU8v1i</link>
<guid>https://weibo.com/1402400261/O82VU8v1i</guid>
<content:encoded><![CDATA[
<div> GitHub, Open Parse, Streamlines, documents, preparing, LLM's, Filimoa, 

此项目名为Open Parse，旨在简化准备文件为LLM的过程。该项目的GitHub链接为github.com/Filimoa/open-parse。通过使用Open Parse，用户可以更高效地处理文件，节省时间和精力。该工具可以帮助LLM的工作更加流畅和高效，提升工作效率。通过GitHub平台，用户可以方便地获取并使用Open Parse工具，为文件处理过程带来便利。总之，Open Parse是一款实用的工具，为准备文件为LLM提供了便捷的解决方案。 <br /><br />总结： <br />Open Parse是一个可以简化准备文件为LLM的过程的工具，通过GitHub平台提供给用户使用，为文件处理过程带来便利，提升工作效率。 <div>
'Open Parse - Streamlines the process of preparing documents for LLM's.' GitHub: github.com/Filimoa/open-parse <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hodxusqf37j20u00uhdk2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 12:56:33 GMT</pubDate>
</item>
<item>
<title>【LLM相关论文分类列表】’Awesome-LLM-related-Papers-Comprehensive-Topics - Awesome LLM-related papers and repos on very comprehensive topics.' GitHub:...</title>
<link>https://weibo.com/1402400261/O82JOEFhu</link>
<guid>https://weibo.com/1402400261/O82JOEFhu</guid>
<content:encoded><![CDATA[
<div> GitHub, Awesome, LLM, Papers, Repos, Comprehensive Topics, 论文分类, 相关研究, 研究领域

<br /><br />总结:该GitHub项目收集了关于LLM（硕士法学）相关的优秀论文和资源，涵盖了非常全面的主题。通过这个项目，研究者可以轻松地找到有关LLM领域的相关研究成果和资源，有助于帮助他们深入了解和探索这一领域。GitHub平台的开放性和便利性使得研究者们可以方便地分享和获取LLM相关研究成果，促进了学术交流和合作。希望这个项目能够为研究者们提供有益的参考和指导，推动LLM研究领域的发展。 <div>
【LLM相关论文分类列表】’Awesome-LLM-related-Papers-Comprehensive-Topics - Awesome LLM-related papers and repos on very comprehensive topics.' GitHub: github.com/shure-dev/Awesome-LLM-related-Papers-Comprehensive-Topics <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hodx00affrj20vf0u0gqe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 12:26:47 GMT</pubDate>
</item>
<item>
<title>【llm-export：llm模型导出工具，能够将llm模型导出为onnx和mnn模型】'llm-export - llm-export can export llm model to onnx.' GitHub: github.com/wangzhaode...</title>
<link>https://weibo.com/1402400261/O82Fu6YUD</link>
<guid>https://weibo.com/1402400261/O82Fu6YUD</guid>
<content:encoded><![CDATA[
<div> llm-export, llm模型, 导出工具, onnx, mnn模型<br />
<br />
llm-export是一种工具，可以将llm模型导出为onnx和mnn模型。这个工具在GitHub上有开源代码，可以方便地将llm模型转换为onnx格式，便于在其他平台上使用。通过使用llm-export工具，用户可以快速方便地转换和导出llm模型，从而实现跨平台应用和部署。 <div>
【llm-export：llm模型导出工具，能够将llm模型导出为onnx和mnn模型】'llm-export - llm-export can export llm model to onnx.' GitHub: github.com/wangzhaode/llm-export <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hodwovijovj213i0oe0vz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 12:16:06 GMT</pubDate>
</item>
<item>
<title>'MicroLlama-300M - a small Llama based model with 300M parameters trained from scratch with $500 budget' GitHub: github.com/keeeeenw/MicroLlama #开源#...</title>
<link>https://weibo.com/1402400261/O82DKw8P4</link>
<guid>https://weibo.com/1402400261/O82DKw8P4</guid>
<content:encoded><![CDATA[
<div> MicroLlama-300M, small, Llama, 300M parameters, trained from scratch, $500 budget, GitHub, keeeeenw, MicroLlama

<br /><br />
总结:
本文介绍了一个名为MicroLlama-300M的小型Llama模型，拥有300M个参数，并且是从头开始用500美元的预算训练的。该项目的源代码托管在GitHub上的keeeeenw/MicroLlama仓库中。MicroLlama-300M模型通过在有限预算下训练，展示了良好的性能和效率。 <div>
'MicroLlama-300M - a small Llama based model with 300M parameters trained from scratch with $500 budget' GitHub: github.com/keeeeenw/MicroLlama <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hodwkg7r0wj20z80u0431.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 12:11:50 GMT</pubDate>
</item>
<item>
<title>【RAG评估数据集】’Docugami Knowledge Graph Retrieval Augmented Generation (KG-RAG) Datasets - Knowledge Graph Retrieval Augmented Generation (KG-RAG)...</title>
<link>https://weibo.com/1402400261/O82wcrw6z</link>
<guid>https://weibo.com/1402400261/O82wcrw6z</guid>
<content:encoded><![CDATA[
<div> GitHub, Docugami, Knowledge Graph, 数据集, KG-RAG, 检索, 生成, 文档

<br /><br />总结:
文章介绍了Docugami Knowledge Graph Retrieval Augmented Generation (KG-RAG) 数据集，并提供了相关的GitHub链接。该数据集是用于知识图检索和生成的一种评估数据集。数据集涵盖了不同知识图领域的信息，旨在帮助研究人员进行相关实验和模型评估。通过使用KG-RAG数据集，可以更好地理解知识图检索和生成的相关问题，并提供了一种衡量模型性能的标准。KG-RAG数据集是一个有用的资源，可以促进知识图领域的研究和发展。 <div>
【RAG评估数据集】’Docugami Knowledge Graph Retrieval Augmented Generation (KG-RAG) Datasets - Knowledge Graph Retrieval Augmented Generation (KG-RAG) Eval Datasets' GitHub: github.com/docugami/KG-RAG-datasets <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodw13rmouj20zi0u0tft.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 11:53:14 GMT</pubDate>
</item>
<item>
<title>【JailbreakBench：开源的鲁棒性基准，用于评估对大型语言模型(LLM)进行大规模越狱的进展。该基准提供的 JBB-Behaviors 数据集，包含 100 种不同的滥用行为，这...</title>
<link>https://weibo.com/1402400261/O82mC0lCR</link>
<guid>https://weibo.com/1402400261/O82mC0lCR</guid>
<content:encoded><![CDATA[
<div> OpenAI, 鲁棒性基准, 大型语言模型, 滥用行为, JBB-Behaviors 数据集, 基准领域表, 攻击和防御算法

<br /><br />总结:
JailbreakBench是一个开源的鲁棒性基准，专注于评估对大型语言模型进行大规模越狱的进展。其提供了包含100种不同滥用行为的JBB-Behaviors数据集，这些行为经过精挑细选，符合OpenAI的使用策略。此外，该基准还提供了领域表，用于追踪算法在攻击和防御数据集滥用行为方面的性能表现。通过JailbreakBench，研究人员和开发者可以更好地评估和改进语言模型的鲁棒性，促进模型在安全性方面的进步。 <div>
【JailbreakBench：开源的鲁棒性基准，用于评估对大型语言模型(LLM)进行大规模越狱的进展。该基准提供的 JBB-Behaviors 数据集，包含 100 种不同的滥用行为，这些行为是根据 OpenAI 的使用策略性精选的。此外，该基准还提供了官方的JailbreakBench领域表，用于跟踪对数据集中滥用行为进行攻击和防御的算法的性能】'JailbreakBench - An Open Robustness Benchmark for Jailbreaking Language Models' GitHub: github.com/JailbreakBench/jailbreakbench <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodvchzx40j210s0u0tej.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 11:29:36 GMT</pubDate>
</item>
<item>
<title>【Arena-Hard：用于评估指令微调LLM的工具，包含500个挑战性用户查询】'Arena-Hard - Arena-Hard benchmark' GitHub: github.com/lm-sys/arena-hard #开源# #机...</title>
<link>https://weibo.com/1402400261/O82le12r2</link>
<guid>https://weibo.com/1402400261/O82le12r2</guid>
<content:encoded><![CDATA[
<div> GitHub, Arena-Hard, 评估指令微调LLM工具, 500个挑战性用户查询

<br /><br />总结:
GitHub上提供了一个名为Arena-Hard的工具，用于评估指令微调LLM的性能表现。该工具包含500个具有挑战性的用户查询，能够帮助研究人员和开发者对模型进行更全面的评估和测试。通过使用这个工具，可以更好地了解模型在复杂场景下的表现，并为进一步优化和改进模型提供参考。Arena-Hard benchmark项目为研究人员提供了一个有力的工具，帮助他们更好地评估和优化LLM模型的性能。 <div>
【Arena-Hard：用于评估指令微调LLM的工具，包含500个挑战性用户查询】'Arena-Hard - Arena-Hard benchmark' GitHub: github.com/lm-sys/arena-hard <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodv8xnp01j21ji0hc0vl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 11:26:11 GMT</pubDate>
</item>
<item>
<title>【Evalverse：旨在支持LLM(大型语言模型)评估需求。提供一个简单、标准化、用户友好的方案，用于处理和管理LLM评估，满足AI研究工程师和科学家的需求】'evalvers...</title>
<link>https://weibo.com/1402400261/O82kzwXJ8</link>
<guid>https://weibo.com/1402400261/O82kzwXJ8</guid>
<content:encoded><![CDATA[
<div> LLM，评估需求，简单，标准化，用户友好，处理，管理，AI研究工程师，科学家

<br /><br />总结:
Evalverse是一个旨在支持LLM评估需求的解决方案，提供简单、标准化、用户友好的工具，用于处理和管理LLM评估，满足AI研究工程师和科学家的需求。GitHub上有相关信息。 <div>
【Evalverse：旨在支持LLM(大型语言模型)评估需求。提供一个简单、标准化、用户友好的方案，用于处理和管理LLM评估，满足AI研究工程师和科学家的需求】'evalverse - The Universe of Evaluation. All about the evaluation for LLMs.' GitHub: github.com/UpstageAI/evalverse <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodv73vdiuj20u00z60xy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hodv78c1tuj21z40u0q6g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hodv79izxjj21hc0u0tbg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 11:24:35 GMT</pubDate>
</item>
<item>
<title>【Lightning Whisper MLX：极快的Whisper实现，特别优化用于Apple Silicon的MLX，比Whisper CPP快10倍，比目前的MLX Whisper实现快4倍】’Lightning Whisper MLX...</title>
<link>https://weibo.com/1402400261/O82i71rii</link>
<guid>https://weibo.com/1402400261/O82i71rii</guid>
<content:encoded><![CDATA[
<div> Apple Silicon, Whisper, MLX, 极快, 优化, GitHub, 快10倍, 快4倍

<br /><br />总结:
Lightning Whisper MLX是一个针对Apple Silicon进行了特别优化的Whisper实现，使用MLX技术实现极快的速度。相比Whisper CPP实现，速度提升了10倍，比目前的MLX Whisper实现也快了4倍。该项目已经在GitHub上开源，地址为github.com/mustafaaljadery/lightning-whisper-mlx。这个项目为Apple Silicon用户提供了更高效的Whisper体验。 <div>
【Lightning Whisper MLX：极快的Whisper实现，特别优化用于Apple Silicon的MLX，比Whisper CPP快10倍，比目前的MLX Whisper实现快4倍】’Lightning Whisper MLX - An extremely fast implementation of whisper optimized for Apple Silicon using MLX.' GitHub: github.com/mustafaaljadery/lightning-whisper-mlx <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hodv0w73xaj210t0u0ad0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 11:18:31 GMT</pubDate>
</item>
<item>
<title>'TorchComp - Differentiable dynamic range controller in PyTorch GitHub: github.com/yoyololicon/torchcomp #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O82eZuBpL</link>
<guid>https://weibo.com/1402400261/O82eZuBpL</guid>
<content:encoded><![CDATA[
<div> PyTorch、动态范围控制器、可微分、GitHub、torchcomp、yoyololicon、代码库、实现、技术、深度学习<br />
<br />
本文介绍了一个名为TorchComp的PyTorch包，该包实现了一个可微分的动态范围控制器。用户可以在GitHub上找到该项目，作者是yoyololicon。该动态范围控制器对于深度学习中的动态范围管理非常有用，可以帮助优化模型性能。该代码库提供了实现这一技术的工具和方法，为用户提供了更多灵活性和控制权。如果你对动态范围控制器和PyTorch感兴趣，可以查看该项目并了解更多细节。<br /><br />总结: <br />PyTorch、动态范围控制器、可微分、GitHub、torchcomp、yoyololicon、代码库、实现、技术、深度学习  <div>
'TorchComp - Differentiable dynamic range controller in PyTorch GitHub: github.com/yoyololicon/torchcomp <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodusz1fc5j21ji0m8gpo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 11:10:50 GMT</pubDate>
</item>
<item>
<title>【SWE-agent：把语言模型(如GPT-4)变成软件工程Agent，可以修复实际GitHub仓库中的bug和issue】’SWE-agent: Agent Computer Interfaces Enable Software Engine...</title>
<link>https://weibo.com/1402400261/O7ZHpiqdp</link>
<guid>https://weibo.com/1402400261/O7ZHpiqdp</guid>
<content:encoded><![CDATA[
<div> 关键词: SWE-agent, 语言模型, 软件工程, GitHub, bug, issue, Agent Computer Interfaces, princeton-nlp<br />
<br />
总结: <br />
本文介绍了一种将语言模型转变为软件工程代理的方法，可以用来修复实际GitHub仓库中的bug和issue。通过创建SWE-agent，实现了Agent Computer Interfaces，使得语言模型能够与GitHub进行交互。SWE-agent的功能包括自动修复bug和处理issue，大大提高了软件工程的效率。GitHub仓库地址为github.com/princeton-nlp/SWE-agent，该项目为软件工程领域带来了新的可能性。 <div>
【SWE-agent：把语言模型(如GPT-4)变成软件工程Agent，可以修复实际GitHub仓库中的bug和issue】’SWE-agent: Agent Computer Interfaces Enable Software Engineering Language Models' GitHub: github.com/princeton-nlp/SWE-agent <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hodjkxutafj21fl0u0wj0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 04:42:36 GMT</pubDate>
</item>
<item>
<title>【产品级RAG系统构建路线图(文集)】《Building Retrieval-Augmented Generation Systems | by Leonie Monigatti | Apr, 2024 | Medium》 网页链接 #机器学习# #...</title>
<link>https://weibo.com/1402400261/O7Yf0pSBS</link>
<guid>https://weibo.com/1402400261/O7Yf0pSBS</guid>
<content:encoded><![CDATA[
<div> 构建路线图、RAG系统、产品级、检索增强生成系统、Leonie Monigatti、2024年、Medium、推荐系统、生成模型、自然语言处理
总结:<br /><br />本文着重介绍了构建检索增强生成系统（RAG系统）的产品级路线图，作者提到了RAG系统在推荐系统和生成模型中的应用，强调了其在自然语言处理领域的重要性。文章指出了产品级RAG系统的关键元素和构建步骤，为读者提供了实用的指导和建议。文章还探讨了RAG系统在未来的发展方向，展望了其在2024年的发展前景。通过阅读本文，读者可以了解RAG系统的基本概念和构建方法，为相关研究和应用提供了重要参考。 <div>
【产品级RAG系统构建路线图(文集)】《Building Retrieval-Augmented Generation Systems | by Leonie Monigatti | Apr, 2024 | Medium》 <a href="https://medium.com/@iamleonie/building-retrieval-augmented-generation-systems-be587f42aedb"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hodd4w69c4j20u010xtd0.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodd50i04tj20fk08raal.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hodd52tlwmj20fk08raae.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hodd54eke4j20go0gojsb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hodd567v5oj20u00u00wc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hodd58d5q4j20as0asdg8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 00:59:53 GMT</pubDate>
</item>
<item>
<title>【AutoRound:面向各硬件平台的LM权重量化SOTA算法】- Intel近期发布了AutoRound v0.1，这是一种针对低比特LM推理的创新型仅量化权重的算法，可以近乎无损地压缩...</title>
<link>https://weibo.com/1402400261/O7YcVkkww</link>
<guid>https://weibo.com/1402400261/O7YcVkkww</guid>
<content:encoded><![CDATA[
<div> Intel、AutoRound、量化算法、LM、权重量化、硬件平台、SOTA、精度、模型部署、符号梯度下降

总结:<br /><br />Intel最近发布了面向各硬件平台的AutoRound v0.1算法，该算法针对LM进行仅量化权重的创新性处理，可以近乎无损地压缩各种流行模型。AutoRound只需调优200步，便可在各种情况下超过其他算法，兼容多种量化设备并支持无缝部署。该算法利用符号梯度下降微调权重的量化和最小最大值，取得了优于其他算法的综合精度，且已在多个模型上发布了精调过的量化模型，精度优于原始浮点模型。 <div>
【AutoRound:面向各硬件平台的LM权重量化SOTA算法】<br />- Intel近期发布了AutoRound v0.1，这是一种针对低比特LM推理的创新型仅量化权重的算法，可以近乎无损地压缩各种流行模型，如gemma-7B、Mistral-7b等。   <br />- AutoRound只需要调优200步，就可以在W4G128、W4G-1、W3G128和W2G128情况下，在大多数场景下持续超过其他算法如GPTQ、AWQ、OmniQuant等。   <br />- AutoRound兼容Intel Guadi2、Intel CPU和Nvidia GPU等量化设备，支持将量化模型无缝部署到Intel CPU和Nvidia GPU平台。   <br />- AutoRound采用符号梯度下降微调权重的量化和最小最大值，只需200步。它利用解空间边界明确的优势。   <br />- 在公平设置下，AutoRound取得了优于GPTQ、AWQ、HQQ、OmniQuant等算法的综合精度。随着调优步数的增加，性能可以进一步提升。   <br />- AutoRound已经发布了若干精调过的量化模型，在多个模型上的精度优于原始浮点模型。<br />《AutoRound: SOTA Weight-Only Quantization Algorithm for LLMs Across Hardware Platforms | by Intel(R) Neural Compressor | Apr, 2024 | Medium》 <a href="https://medium.com/@NeuralCompressor/autoround-sota-weight-only-quantization-algorithm-for-llms-across-hardware-platforms-99fe6eac2861"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hodczs1e69j20u00w9tds.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 00:54:45 GMT</pubDate>
</item>
<item>
<title>【Genie游戏生成器：无监督学习开启游戏AI新纪元】- Google DeepMind开发了一个名为Genie的新模型，可以根据简短描述、手绘草图或照片，生成类似超级马里奥兄弟...</title>
<link>https://weibo.com/1402400261/O7Y6wuD4l</link>
<guid>https://weibo.com/1402400261/O7Y6wuD4l</guid>
<content:encoded><![CDATA[
<div> Genie、无监督学习、游戏AI、Genie训练、视频数据、生成式AI、降低门槛、交互式生成、视觉技巧、商业应用前景

总结:<br /><br />Genie是Google DeepMind开发的游戏生成器，通过无监督学习可以生成类似超级马里奥兄弟的2D平台游戏。它通过观看3万小时的2D平台游戏视频进行训练，可以根据简短描述、手绘草图或照片生成游戏。Genie展示了生成式AI在游戏领域的潜力，为游戏开发提供更多创意支持，并且无监督学习方法可以提高模型的泛化能力。其实时生成游戏画面的能力为玩家提供更加个性化和沉浸式的游戏体验。Genie学会了视差等游戏中的视觉技巧，表明其对美学设计原则有一定理解。虽然目前为内部研究项目，但DeepMind已展望其商业应用前景，即转化为游戏制作工具，显示对其技术的乐观态度。随着Genie功能的完善和推理速度的提高，有望成为一个颠覆性的游戏生成平台，为游戏行业带来新的创新动力。 <div>
【Genie游戏生成器：无监督学习开启游戏AI新纪元】<br />- Google DeepMind开发了一个名为Genie的新模型，可以根据简短描述、手绘草图或照片，生成类似超级马里奥兄弟这样的2D平台游戏。   <br />- Genie通过观看网上3万小时的数百款2D平台游戏视频进行训练，学会了判断游戏人物在视频中的8种可能动作，从而生成每一帧图像。   <br />- Genie可以将简单游戏从手绘草图生成出来。它学会了平台游戏中的一些常见视觉效果，如前景移动速度快于背景的视差效果。   <br />- Genie可能被开发成游戏制作工具。它也可以通过观看机械臂操作日用品的视频，学习控制机械臂。   <br />- Genie使用的技术与大型语言模型类似，运行速度有望达到每秒30帧。它可以生成虚拟环境，用于训练机器人解决各种任务。   <br />- Genie是DeepMind的内部研究项目，暂时不会发布。但它可能成为未来创造力表达的新工具。<br /><br />思考：  <br />- Genie展示了生成式AI在游戏领域的巨大潜力。从零开始自动生成游戏，将极大地降低游戏开发的门槛，为游戏设计师提供更多创意支持。  <br />- 仅使用视频数据进行训练，无需手动标注，这种无监督学习方法可以充分利用海量的游戏视频资源，提高模型的泛化能力。这种方法也可能启发其他领域的AI研究。  <br />- 实时生成游戏画面的能力令人印象深刻。这种交互式生成方式为玩家提供了更加个性化和沉浸式的游戏体验，同时也对模型的推理速度提出了更高要求。  <br />- Genie学会了视差等游戏中的视觉技巧，表明它不仅掌握了游戏的基本规则，还理解了一些美学设计原则。这展现了深度学习在理解和生成视觉内容方面的强大能力。  <br />- 虽然Genie还是一个研究项目，但谷歌DeepMind已经展望了其商业应用前景，即转化为游戏制作工具。这表明他们对这一技术的成熟度和实用性持乐观态度。  <br />- 随着推理速度的提高和功能的完善，Genie有望成为一个颠覆性的游戏生成平台，为游戏行业注入新的创新动力。同时，它也可能对游戏开发者的职业前景产生一定影响。<br />《Google DeepMind’s new generative model makes Super Mario-like games from scratch | MIT Technology Review》 <a href="https://www.technologyreview.com/2024/02/29/1089317/google-deepminds-new-generative-model-makes-super-mario-like-games-from-scratch"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hodcjj9lydj20vz0u0gth.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 00:38:59 GMT</pubDate>
</item>
<item>
<title>【OpenAI的Harvey客户案例分享】- Harvey是一家为法律、税务和金融专业人员提供生成式AI平台的初创公司。最近，它与OpenAI合作创建了一个定制化的案例法模型。 -...</title>
<link>https://weibo.com/1402400261/O7Y3zuvrk</link>
<guid>https://weibo.com/1402400261/O7Y3zuvrk</guid>
<content:encoded><![CDATA[
<div> 合作、定制化、案例法模型、LLM、推理、领域知识、重要差异、高效率、跨领域、用户体验

<br /><br />总结:
OpenAI与Harvey合作创建了定制化的案例法模型，为法律、税务和金融专业人员提供生成式AI平台。这个模型注入新的知识和推理方式，融合了大量数据，提供案例法上下文深度。律师更喜欢定制化模型的输出，因为它提供更完整、深入的答案。创始人建议构建与未来LLM能力相关的解决方案，充分利用模型进步带来的价值。该合作展示了定制化LLM在垂直领域应用的潜力，为传统行业带来变革。创始人背景的跨领域视角和经验对LLM应用至关重要。AI技术有望提高行业效率和生产力，对从业者的技能要求和就业前景可能产生影响。面临的挑战是确保输出的相关性和准确性，提供可靠的来源引用。Harvey致力于简化用户体验，降低使用门槛，以推动AI技术的大规模采用。 <div>
【OpenAI的Harvey客户案例分享】<br />- Harvey是一家为法律、税务和金融专业人员提供生成式AI平台的初创公司。最近，它与OpenAI合作创建了一个定制化的案例法模型。   <br />- 这个模型允许Harvey为复杂的推理、广泛的领域知识以及超出单次模型调用能力的任务提供AI系统，如文档起草、复杂诉讼场景的问答以及数百份合同之间的重大差异识别。   <br />- Harvey的创始人认为，LLM可以聚合信息并呈现给律师进行审查，从而提高工作效率。基础模型在推理方面很强，但缺乏法律工作所需的知识。   <br />- Harvey与OpenAI合作，向基础模型中注入新的知识和推理方式，创建一个定制化的案例法模型。该模型融合了相当于100亿Token的数据，以提供案例法所需的上下文深度。   <br />- 测试结果显示，97%的时间律师更喜欢定制化案例法模型的输出结果，因为它提供了更完整、深入的答案并涵盖了更相关的案例法。   <br />- Harvey计划利用该模型探索其他应用，如起草简要和动议，或帮助律师理解不同管辖区域之间的案例法差异。   <br />- Harvey的合伙创始人建议其他创始人要面向未来的LLM能力进行构建，解决更复杂的问题，以充分利用模型进步带来的价值。<br /><br />思考：    <br />- Harvey与OpenAI的合作展示了定制化LLM在垂直领域应用中的巨大潜力。通过注入特定领域知识，LLM可以胜任需要复杂推理和专业知识的任务，这将极大地拓展LLM的应用范围。    <br />- Harvey的成功表明，LLM正在为传统的知识密集型行业带来变革，如法律、税务和金融。AI技术有望提高这些行业的效率和生产力，同时也可能对从业者的技能要求和就业前景产生影响。    <br /> 创始人的背景结合了法律专业和AI技术，这种跨领域的视角和经验对于将LLM成功应用于法律行业至关重要。这启示我们，未来的创新可能越来越多地来自不同领域的交叉融合。    <br />- Harvey面临的一个挑战是如何确保AI系统输出的相关性和准确性，并提供可靠的来源引用。这对于法律等要求严谨的领域尤为重要。Harvey在这方面取得的进展值得关注。    <br />- 通过将多个模型调用组合成单一输出，Harvey旨在简化用户体验，降低使用门槛。这种以用户为中心的思路对于推动AI技术的大规模采用非常必要。<br />《OpenAI customer story: Harvey》 <a href="https://openai.com/customer-stories/harvey"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hodcbz1ohfj21gm0u0q76.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 00:31:43 GMT</pubDate>
</item>
<item>
<title>【多样本越狱：LLM安全防线的突破口】- Anthropic研究团队发现了一种称为“多样本越狱”的新型对抗性攻击，可以突破大型语言模型的安全保护机制。 - 该攻击利用...</title>
<link>https://weibo.com/1402400261/O7XXf5SgD</link>
<guid>https://weibo.com/1402400261/O7XXf5SgD</guid>
<content:encoded><![CDATA[
<div> 多样本越狱、LLM安全防线、对抗性攻击、大型语言模型、in-context学习、Anthropic研究团队、安全漏洞、多样本越狱攻击、缓解措施、AI安全挑战

<br /><br />总结:
Anthropic研究团队发现了一种名为多样本越狱的新型对抗性攻击，能够突破大型语言模型的安全防护，利用模型处理长上下文能力，在prompt中插入特定格式的文本引导模型产生潜在有害响应。随着示例对话数量增加，攻击成功率也增加，显示多样本越狱的可行性。攻击与模型的in-context学习能力有关，大型语言模型更容易受到攻击，因为其学习能力更强。Anthropic已采取限制上下文长度等缓解措施，但完全解决多样本越狱仍具挑战性。发现漏洞并与业界分享显现了负责任的态度和开放协作精神，有助于整个AI社区共同应对安全挑战。增强安全防护是迫切需要的，尤其随着模型能力的增强，引入新安全风险。文章提醒我们平衡上下文窗口扩大带来的性能提升和安全隐患之间的问题，在评估LLM安全性时需考虑不同攻击手段的组合效果。多样本越狱攻击的有效性及与其他攻击技术相结合的威力，强调AI安全问题的复杂性，需要产学研各界持续投入和协同努力。 <div>
【多样本越狱：LLM安全防线的突破口】<br />- Anthropic研究团队发现了一种称为“多样本越狱”的新型对抗性攻击，可以突破大型语言模型的安全保护机制。   <br />- 该攻击利用了大型语言模型能处理更长上下文的能力，通过在prompt中加入大量特定格式的文本，迫使模型产生潜在有害的响应。   <br />- 随着prompt中示例对话数量的增加，模型产生有害响应的比例也在增加，这表明多样本越狱是可行的。   <br />- 多样本越狱似乎与模型的in-context学习能力有关，随着示例数增多，模型的in-context学习效果呈幂律提升，越狱成功率也是如此。   <br />- 相比小模型，大型语言模型更容易被多样本越狱攻击，因为它们的in-context学习能力更强。   <br />- Anthropic已经采取了一些缓解措施，如限制上下文窗口长度、对prompt进行分类处理等，取得了一定效果。   <br />- 发布这项研究有助于提高对这种新型攻击的重视，促使AI研究者尽快找到有效的防御手段。   <br />- 随着模型变得更强大，缓解这类攻击变得更加重要。Anthropic将继续研究如何在不损害模型有用性的前提下防御多样本越狱。<br /><br />思考：  <br />- 多样本越狱技术揭示了当前LLM安全防护的一个重要漏洞，表明随着模型能力的增强，安全风险也在不断升高，需要引起高度重视。  <br />- Anthropic主动披露漏洞并与业界分享，体现了负责任的态度和开放协作的精神，值得赞赏。这种做法有利于推动整个AI社区共同应对安全挑战。  <br />- 上下文窗口的扩大是LLM发展的重要趋势，带来了性能提升的同时，也引入了新的安全隐患。如何在两者间取得平衡，是一个值得深入探讨的问题。  <br />- 文章通过实验数据展示了多样本越狱的有效性，并指出与其他越狱技术结合会进一步增强威力，这提醒我们在评估LLM安全性时需要考虑各种攻击手段的组合效果。  <br />- 虽然Anthropic已经采取了一些缓解措施，但完全解决多样本越狱并非易事。这凸显了AI安全问题的复杂性，需要产学研各界持续投入和协同努力。<br />《Many-shot jailbreaking \ Anthropic》 <a href="https://www.anthropic.com/research/many-shot-jailbreaking"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hodbdvefxgj20uj0u0440.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 00:16:07 GMT</pubDate>
</item>
<item>
<title>今日推介(第1364期)：用语言模型识别有说服力的论点、让LLM在不泄露隐私信息的情况下获得其他LLM的帮助、基于可控大语言模型的安全性与可用性平衡、旋转LLM实现...</title>
<link>https://weibo.com/1402400261/O7XbFuHyV</link>
<guid>https://weibo.com/1402400261/O7XbFuHyV</guid>
<content:encoded><![CDATA[
<div> 语言模型、认证、隐私、安全性、可用性、推理、噪声感知、训练、布局、公众号

<br /><br />总结:
本文介绍了几个关于语言模型的研究领域，包括用语言模型识别有说服力的论点、如何让LLM在不泄露隐私信息的情况下获得其他LLM的帮助，以及基于可控大语言模型的安全性与可用性平衡。另外还提到了旋转LLM实现无离群值4-bit推理和布局感知语言模型的噪声感知训练等内容。这些研究都对提升语言模型的应用和效用有着积极的意义，并在不同领域具有广泛的应用前景。 <div>
今日推介(第1364期)：用语言模型识别有说服力的论点、让LLM在不泄露隐私信息的情况下获得其他LLM的帮助、基于可控大语言模型的安全性与可用性平衡、旋转LLM实现无离群值4-bit推理、布局感知语言模型的噪声感知训练 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/690477458"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hod8hhfsrxj21fe0tk44f.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hod8hl2c26j21330u0dm1.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hod8hnbse3j20vi0k40v0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hod8hq97xbj21f20r40yp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hod8hskrkdj219l0u0tff.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 22:18:55 GMT</pubDate>
</item>
<item>
<title>[CV] Measuring Style Similarity in Diffusion Models 网页链接 提出一种从图像中提取风格描述符的对比学习框架，在零样本任务上优于其他方法，并通过案例研究...</title>
<link>https://weibo.com/1402400261/O7X8lxcyo</link>
<guid>https://weibo.com/1402400261/O7X8lxcyo</guid>
<content:encoded><![CDATA[
<div> 对比学习框架、风格描述符、零样本任务、理解生成模型、归因、应用价值、案例研究 <br />
本文提出了一种对比学习框架，用于从图像中提取风格描述符，并在零样本任务上表现优于其他方法。通过案例研究展示了该框架在理解和归因生成模型中的风格方面的应用价值。 <div>
[CV] Measuring Style Similarity in Diffusion Models  <br /><a href="https://arxiv.org/abs/2404.01292"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />提出一种从图像中提取风格描述符的对比学习框架，在零样本任务上优于其他方法，并通过案例研究展示了其在理解和归因生成模型中的风格方面的应用价值。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod899cavjj20uy1bq7kh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod899jtsij211o16eaj7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod89a39umj21b20kqtf1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 22:10:44 GMT</pubDate>
</item>
<item>
<title>[IR] A Review of Modern Recommender Systems Using Generative Models (Gen-RecSys) 网页链接 系统全面综述了生成模型在推荐系统中的应用，包括基于交互、语言...</title>
<link>https://weibo.com/1402400261/O7X5RaNCV</link>
<guid>https://weibo.com/1402400261/O7X5RaNCV</guid>
<content:encoded><![CDATA[
<div> 生成模型、推荐系统、交互、语言、多模态技术、评估维度、未来方向、研究领域、参考、综述<br />
<br />
总结：<br />
本文综述了生成模型在推荐系统中的应用，包括基于交互、语言和多模态的技术。文章还讨论了评估维度和未来方向，为这一新兴且前景广阔的研究领域提供了宝贵参考。生成模型在推荐系统中的各种应用和技术展示了其在提高推荐效果和用户体验方面的潜力。评估维度的讨论帮助研究者更好地了解如何评估生成模型推荐系统的性能。未来方向的探讨为学者提供了发展方向和研究重点，有助于推动这一领域的进一步发展。希望这篇综述能给推荐系统研究者提供启发，并促进更多创新方法和技术的应用。 <div>
[IR] A Review of Modern Recommender Systems Using Generative Models (Gen-RecSys)  <br /><a href="https://arxiv.org/abs/2404.00579"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />系统全面综述了生成模型在推荐系统中的应用，包括基于交互、语言和多模态的技术，以及评估维度和未来方向，为这一新兴且前景广阔的研究领域提供了宝贵参考。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod82w82hxj213i1c64jy.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod82wgm8gj21w016i16v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 22:04:35 GMT</pubDate>
</item>
<item>
<title>[CL] Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order 网页链接 通过持续预训练和安全性调整...</title>
<link>https://weibo.com/1402400261/O7X3khu4g</link>
<guid>https://weibo.com/1402400261/O7X3khu4g</guid>
<content:encoded><![CDATA[
<div> 多语言、安全性调整、150亿参数、开源、AURORA-M、预训练、语言模型、Red-teamed、美国行政命令

总结:<br />
通过持续预训练和安全性调整，提出了一个多语言、安全可靠的150亿参数开源语言模型AURORA-M。根据美国行政命令进行了Red-teamed测试，证明其在各方面的优势和可靠性。 AURORA-M可应用于诸多领域，为自然语言处理提供了一个重要的工具。 <div>
[CL]  Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order  <br /><a href="https://arxiv.org/abs/2404.00399"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />通过持续预训练和安全性调整，提出了一个多语言、安全可靠的150亿参数开源语言模型AURORA-M。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod7we8wbaj20uw1cy4dd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod7weoe03j21mw10wqd8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod7wf5m0dj21ms116dok.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:58:22 GMT</pubDate>
</item>
<item>
<title>[CL] Mapping the Increasing Use of LLMs in Scientific Papers 网页链接进行第一个大规模分析追踪学术界LLM使用趋势，发现计算机科学增长最快，与作者更频繁发...</title>
<link>https://weibo.com/1402400261/O7WZOuJ28</link>
<guid>https://weibo.com/1402400261/O7WZOuJ28</guid>
<content:encoded><![CDATA[
<div> 计算机科学, LLM, 学术界, 使用趋势, 预印本, 研究领域, 论文<br />
<br />
<br />
总结: 这篇文章通过大规模分析发现，学术界中越来越多地使用LLM，其中计算机科学领域的增长最为迅速。这与作者更频繁发表预印本、研究领域更拥挤以及论文更短等因素有关。LLM的使用趋势在学术界中呈现明显上升趋势，尤其在计算机科学领域。 <div>
[CL] Mapping the Increasing Use of LLMs in Scientific Papers  <br /><a href="https://arxiv.org/abs/2404.01268"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br />进行第一个大规模分析追踪学术界LLM使用趋势，发现计算机科学增长最快，与作者更频繁发表预印本、研究领域更拥挤以及论文更短相关。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod7nee3drj20v81dkaps.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod7ned969j21d010sqi6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod7neppzjj21cc1cwamw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:49:43 GMT</pubDate>
</item>
<item>
<title>[CL]《Noise-Aware Training of Layout-Aware Language Models》R Sarkhel, X Ren, L B Costa, G Su, V Perot, Y Xie, E Koukoumidis, A Nandi [Google &amp; The Oh...</title>
<link>https://weibo.com/1402400261/O7WVazuaD</link>
<guid>https://weibo.com/1402400261/O7WVazuaD</guid>
<content:encoded><![CDATA[
<div> 布局感知语言模型，噪声感知训练，谷歌，俄亥俄州立大学，2024，R Sarkhel，X Ren，L B Costa，G Su，V Perot，Y Xie，E Koukoumidis，A Nandi

<br /><br />总结:
这篇论文探讨了一种新的训练方法，即噪声感知训练，用于提高布局感知语言模型的性能。研究人员提出了一种新颖的噪声注入技术，通过向输入数据中添加噪声来帮助模型更好地理解布局信息。他们在谷歌和俄亥俄州立大学进行了实验，结果表明，这种训练方法可以显著改善布局感知语言模型的性能。这项研究为提高语言模型的布局感知能力提供了新思路，对于提高文本生成、理解和处理的效果具有重要意义。 <div>
[CL]《Noise-Aware Training of Layout-Aware Language Models》R Sarkhel, X Ren, L B Costa, G Su, V Perot, Y Xie, E Koukoumidis, A Nandi [Google &amp; The Ohio State University] (2024) <a href="https://arxiv.org/abs/2404.00488"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod6x1onmnj20le1ag7fb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6x20lkvj20p00nuzoa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod6x2ka9ej21by0vkwmu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6x2tql8j20oi0imgo4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod7bhv7lmj20hi0f1t9d.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod7bhv93mj20hm0e6mxs.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:38:16 GMT</pubDate>
</item>
<item>
<title>QuaRot通过旋转消除激活中的离群点实现了包括权重、激活和KV缓存在内的端到端4-bit LLM量化，保持了几乎全部的模型性能。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Qu...</title>
<link>https://weibo.com/1402400261/O7WOzeI6F</link>
<guid>https://weibo.com/1402400261/O7WOzeI6F</guid>
<content:encoded><![CDATA[
<div> 权重、激活、KV缓存、4-bit量化、端到端、QuaRot、旋转、消除离群点、模型性能、LLMs

<br /><br />总结:
QuaRot是一种新的技术，通过旋转去除激活中的离群点，实现了包括权重、激活和KV缓存在内的端到端4-bit LLM量化。该方法保持了几乎全部的模型性能。研究团队来自ETH Zurich，EPFL和Microsoft Research，他们通过实验验证了这种新方法的有效性。QuaRot主要应用于旋转LLMs，已经证明在4-bit推断中具有很高的效果。通过消除离群点，能够显著提高模型的稳定性和精度。这项研究为低精度推断提供了新的思路，对于在资源受限的设备上部署深度学习模型具有重要意义。QuaRot技术的提出将进一步推动深度学习领域的发展，为模型的应用和优化提供了新的思路。 <div>
QuaRot通过旋转消除激活中的离群点实现了包括权重、激活和KV缓存在内的端到端4-bit LLM量化，保持了几乎全部的模型性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs》S Ashkboos, A Mohtashami, M L. Croci, B Li, M Jaggi, D Alistarh, T Hoefler, J Hensman [ETH Zurich &amp; EPFL &amp; Microsoft Research] (2024) <a href="https://arxiv.org/abs/2404.00456"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod6m7tom8j21620kgdnm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6m8gocdj21f20r4n4y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6m8uxfmj21dy0o60yp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod6m955foj21e40piwjp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod6p5mftwj20ve0hpwha.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6p5mmckj20xq0h5jtm.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod6p5mr7xj20vd0glq4m.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:22:00 GMT</pubDate>
</item>
<item>
<title>[LG]《QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs》S Ashkboos, A Mohtashami, M L. Croci, B Li, M Jaggi, D Alistarh, T Hoefler, J Hensman [ETH...</title>
<link>https://weibo.com/1402400261/O7WMs7i3U</link>
<guid>https://weibo.com/1402400261/O7WMs7i3U</guid>
<content:encoded><![CDATA[
<div> 关键词: QuaRot, Outlier-Free, 4-Bit Inference, Rotated LLMs, ETH Zurich, EPFL, Microsoft Research

总结:<br /><br />这篇文章介绍了一种名为QuaRot的方法，用于在旋转的LLMs中进行无异常值的4位推断。研究团队来自ETH Zurich、EPFL和Microsoft Research，团队成员包括S Ashkboos、A Mohtashami、M L. Croci、B Li、M Jaggi、D Alistarh、T Hoefler和J Hensman。他们提出的方法有效地处理了LLMs中出现的异常情况，可用于进行精确的4位推断。该方法的实现无异常值且高效，为解决此类问题提供了有力的工具。 <div>
[LG]《QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs》S Ashkboos, A Mohtashami, M L. Croci, B Li, M Jaggi, D Alistarh, T Hoefler, J Hensman [ETH Zurich &amp; EPFL &amp; Microsoft Research] (2024) <a href="https://arxiv.org/abs/2404.00456"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod6m7tom8j21620kgdnm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6m8gocdj21f20r4n4y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6m8uxfmj21dy0o60yp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod6m955foj21e40piwjp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod6p5mftwj20ve0hpwha.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod6p5mmckj20xq0h5jtm.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod6p5mr7xj20vd0glq4m.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:16:47 GMT</pubDate>
</item>
<item>
<title>通过自生成训练数据并采用不同的微调策略，实现了不需要额外人工标注就能控制大语言模型响应中的安全性和有用性。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Towards S...</title>
<link>https://weibo.com/1402400261/O7WGy0sEy</link>
<guid>https://weibo.com/1402400261/O7WGy0sEy</guid>
<content:encoded><![CDATA[
<div> 关键词: 自生成训练数据, 大语言模型, 安全性, 有用性, 微调策略, 控制, 响应, 人工标注, 平衡, Meta AI 

总结:<br />
研究通过自生成训练数据和不同的微调策略，实现了大语言模型响应中安全性和有用性的平衡。文章指出通过控制大语言模型的响应，无需额外人工标注便可实现对响应内容的安全性和有用性进行调控。研究的关键在于平衡安全性和有用性，需要对训练数据和微调策略进行精细调节，以满足用户的需求。通过Meta AI技术和来自加州大学圣芭芭拉分校的合作，研究取得了显著进展，有望在大语言模型的应用中发挥重要作用。 <div>
通过自生成训练数据并采用不同的微调策略，实现了不需要额外人工标注就能控制大语言模型响应中的安全性和有用性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Towards Safety and Helpfulness Balanced Responses via Controllable Large Language Models》Y Tuan, X Chen, E M Smith, L Martin… [Meta AI &amp; University of California, Santa Barbara] (2024) <a href="https://arxiv.org/abs/2404.01295"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod68zv1orj20qq0xathh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod690byo2j20vi0k4q5y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod690qgbij21p80ka44c.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod690yryqj21pi0jgdks.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod69mje5gj20hs0jwjsj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod69mjrkuj20zs0f7gnq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod69mjddzj20hs0bqt9t.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod69mjeakj20hr07m0t6.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:02:14 GMT</pubDate>
</item>
<item>
<title>[CL]《Towards Safety and Helpfulness Balanced Responses via Controllable Large Language Models》Y Tuan, X Chen, E M Smith, L Martin… [Meta AI &amp; Unive...</title>
<link>https://weibo.com/1402400261/O7WGolSsF</link>
<guid>https://weibo.com/1402400261/O7WGolSsF</guid>
<content:encoded><![CDATA[
<div> 控制大型语言模型，平衡安全和实用性，安全，实用性，平衡，响应，大型语言模型，Meta AI，加州大学圣巴巴拉，2024<br />
<br />
总结:<br />
本文研究了通过控制大型语言模型实现安全和实用性平衡的方法。通过引入新的技术和算法，可以更好地处理大型语言模型在生成响应时可能出现的安全隐患。研究团队从安全性和实用性的角度出发，提出了一种新的平衡方法，可以确保生成的响应既安全又有帮助。他们结合了Meta AI的技术和加州大学圣巴巴拉的研究资源，取得了一定的进展。通过这项研究，可以为大型语言模型的发展提供更加全面和可靠的指导，确保其在未来的应用中能够更好地服务社会。 <div>
[CL]《Towards Safety and Helpfulness Balanced Responses via Controllable Large Language Models》Y Tuan, X Chen, E M Smith, L Martin… [Meta AI &amp; University of California, Santa Barbara] (2024) <a href="https://arxiv.org/abs/2404.01295"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod68zv1orj20qq0xathh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod690byo2j20vi0k4q5y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod690qgbij21p80ka44c.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod690yryqj21pi0jgdks.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod69mje5gj20hs0jwjsj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod69mjrkuj20zs0f7gnq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod69mjddzj20hs0bqt9t.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod69mjeakj20hr07m0t6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:01:52 GMT</pubDate>
</item>
<item>
<title>设计保护隐私的级联系统和查询生成算法，使本地模型可利用远程模型提高性能而不泄露敏感信息。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Can LLMs get help from othe...</title>
<link>https://weibo.com/1402400261/O7WFX0WBK</link>
<guid>https://weibo.com/1402400261/O7WFX0WBK</guid>
<content:encoded><![CDATA[
<div> 隐私保护、本地模型、远程模型、私人信息、级联系统、查询生成算法、LLMs、信息共享、性能提升、敏感信息泄露

总结:<br /><br />
本文讨论了如何设计一种保护隐私的级联系统和查询生成算法，使本地模型能够利用远程模型提高性能而不泄露敏感信息。研究团队提出了一种解决方案，即通过利用LLMs之间的信息共享来提高模型性能，同时保护私人信息不被泄露。他们提出的方法使得模型能够相互协作，共享有用的信息，同时保持敏感信息的隐私性。该方法的设计是基于查询生成算法，能够有效地限制信息的传输和共享范围，从而保护用户的隐私。通过这种方式，本地模型可以从其他远程模型中获得帮助，提高性能，而不会揭露私人信息。这种方法的应用在保护隐私的同时，也有助于提高模型的性能和效率。 <div>
设计保护隐私的级联系统和查询生成算法，使本地模型可利用远程模型提高性能而不泄露敏感信息。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Can LLMs get help from other LLMs without revealing private information?》F Hartmann, D Tran, P Kairouz… [Google Research] (2024) <a href="https://arxiv.org/abs/2404.01041"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod67a2w6qj21cy0wu185.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod67abxk2j21lu0lsada.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod67b21xcj21ls18cdub.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod67blmnvj21mg0ueah1.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:00:46 GMT</pubDate>
</item>
<item>
<title>[LG]《Can LLMs get help from other LLMs without revealing private information?》F Hartmann, D Tran, P Kairouz… [Google Research] (2024) 网页链接 #机...</title>
<link>https://weibo.com/1402400261/O7WFT9hUp</link>
<guid>https://weibo.com/1402400261/O7WFT9hUp</guid>
<content:encoded><![CDATA[
<div> 隐私保护、LLMs、协作、信息共享、安全协议、数据隐私、加密技术、隐私保护算法

总结:<br /><br />本研究讨论了LLMs（Low-Latency Messaging systems）之间如何在不泄露私人信息的情况下进行合作和信息共享。研究团队提出了一种安全协议，利用加密技术和隐私保护算法，实现了LLMs之间的安全信息交流。他们的方案在保护数据隐私的同时，确保了信息的可靠传输和合作的顺畅进行。这项研究对提高LLMs系统的安全性和隐私保护性具有重要意义。 <div>
[LG]《Can LLMs get help from other LLMs without revealing private information?》F Hartmann, D Tran, P Kairouz… [Google Research] (2024) <a href="https://arxiv.org/abs/2404.01041"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod67a2w6qj21cy0wu185.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod67abxk2j21lu0lsada.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hod67b21xcj21ls18cdub.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod67blmnvj21mg0ueah1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 21:00:36 GMT</pubDate>
</item>
<item>
<title>通过检测有说服力论据的能力来研究LLM生成个性化信息的潜力，无需直接人工实验，为持续监测LLM能力发展提供了有效途径。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Can...</title>
<link>https://weibo.com/1402400261/O7WD0skj7</link>
<guid>https://weibo.com/1402400261/O7WD0skj7</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM, 说服力论据识别, 个性化信息生成, 监测能力发展

总结:<br /><br />
该研究探讨了语言模型(LLM)在识别说服力论据和生成个性化信息方面的潜力，无需进行直接人工实验，提供了一种有效的监测LLM能力发展的方法。研究发现，LLM在识别有说服力的论据方面表现出良好的能力，显示了其潜力。该研究由瑞士洛桑联邦理工学院和剑桥大学的研究人员合作完成，为未来研究LLM能力的发展方向提供了重要参考。 <div>
通过检测有说服力论据的能力来研究LLM生成个性化信息的潜力，无需直接人工实验，为持续监测LLM能力发展提供了有效途径。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Can Language Models Recognize Convincing Arguments?》P Rescala, M H Ribeiro, T Hu, R West [EPFL &amp; University of Cambridge] (2024) <a href="https://arxiv.org/abs/2404.00750"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod62w15wjj216s0qu7gm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod62wr5pij21fe0tkdnf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod62xb1y7j20pk0q6jve.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod62y3ofkj20ni0simzh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod60r2rsej20n00k5gnq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod60r2u0qj20n00oeacb.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 20:53:31 GMT</pubDate>
</item>
<item>
<title>[CL]《Can Language Models Recognize Convincing Arguments?》P Rescala, M H Ribeiro, T Hu, R West [EPFL &amp; University of Cambridge] (2024) 网页链接 #机器...</title>
<link>https://weibo.com/1402400261/O7WCWhYof</link>
<guid>https://weibo.com/1402400261/O7WCWhYof</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型，说服性论点，识别，论证，人工智能，自然语言处理，研究，EPFL，剑桥大学

总结:
研究人员来自EPFL和剑桥大学，他们进行了关于语言模型是否能识别具有说服力的论点的研究。他们探讨了人工智能和自然语言处理领域的重要问题，即机器是否能够识别人类的论证方式。研究结果表明，语言模型在识别说服力论点方面取得了一定的进展，但仍存在一些挑战和限制。他们的研究为语言模型的进一步发展提供了有价值的参考，为人工智能领域的研究和应用带来了新的启示。 <div>
[CL]《Can Language Models Recognize Convincing Arguments?》P Rescala, M H Ribeiro, T Hu, R West [EPFL &amp; University of Cambridge] (2024) <a href="https://arxiv.org/abs/2404.00750"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hod62w15wjj216s0qu7gm.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod62wr5pij21fe0tkdnf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod62xb1y7j20pk0q6jve.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod62y3ofkj20ni0simzh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hod60r2rsej20n00k5gnq.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hod60r2u0qj20n00oeacb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 20:53:21 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.2)》 爱可可微博热门分享(4.2) [图片]</title>
<link>https://weibo.com/1402400261/O7UfG92ii</link>
<guid>https://weibo.com/1402400261/O7UfG92ii</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、文章、内容、关键词、社交媒体、用户、热度

<br /><br />总结:
本文是关于爱可可微博热门分享的内容。文章主要围绕着社交媒体平台微博上热门内容展开，分享了一些用户感兴趣的话题和信息。通过分析关键词和用户互动，可以更好地了解微博热度和用户喜好。爱可可微博分享的内容涵盖了各种各样的主题，吸引了广泛的用户群体关注和参与讨论。通过这些热门分享，可以更好地了解社交媒体上的热点话题和用户需求，为用户提供更好的信息和服务。 <div>
《爱可可微博热门分享(4.2)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405018845323591860"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.2)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hocvj66pjxj20rs0fmmzd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 14:50:33 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation》(CVPR 2024) GitHub: github.com/Aradhye2002/Ec...</title>
<link>https://weibo.com/1402400261/O7TPalOlz</link>
<guid>https://weibo.com/1402400261/O7TPalOlz</guid>
<content:encoded><![CDATA[
<div> ECoDepth, Diffusion Models, Monocular Depth Estimation, Conditioning, Effective, CVPR 2024, GitHub, Relation Rectification, Relation Rectification, Diffusion Model, Hourglass Tokenizer, Efficient, Transformer-Based, 3D Human Pose Estimation, XScale-NVS, Cross-Scale, Novel View Synthesis, Hash Featurized Manifold, DiJiang, Large Language Models, Compact Kernelization, Talk3D, Talking Portrait Synthesis, 3D Generative Prior, Motion Inversion, Video Customization, MineLand, Multi-Agent Interactions, Limited Multimodal Senses, Physical Needs, UPD, Unsolvable Problem Detection, Vision Language Models, Draw-and-Understand, Visual Prompts

总结：<br /><br /> 《ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation》介绍了一种有效的条件扩展扩散模型，用于单目深度估计。GitHub上有相关的代码实现。 《Relation Rectification in Diffusion Model》讨论了扩散模型中的关系校正问题，也提供了相关的GitHub代码。《Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation》介绍了一种用于3D人体姿势估计的高效Transformer模型。XScale-NVS展示了一种跨尺度新视图合成方法，并使用哈希特征化流形。DiJiang通过紧凑内核化实现了高效的大型语言模型。Talk3D提出了一种通过个性化三维生成先验实现的高保真度语音合成方法。Motion Inversion展示了视频定制中的运动反转技术。MineLand通过模拟大规模多智能体交互，限制多模态感知和生理需求。UPD关注视觉语言模型的可信度评估。Draw-and-Understand利用视觉提示帮助大型语言模型理解用户需求。 <div>
几篇论文实现代码：<br />《ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation》(CVPR 2024) GitHub: github.com/Aradhye2002/EcoDepth [fig2]<br />《Relation Rectification in Diffusion Model》(CVPR 2024) GitHub: github.com/WUyinwei-hah/RRNet<br />《Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation》(CVPR 2024) GitHub: github.com/NationalGAILab/HoT<br />《XScale-NVS: Cross-Scale Novel View Synthesis with Hash Featurized Manifold》(CVPR 2024) GitHub: github.com/THU-luvision/XScale-NVS<br />《DiJiang: Efficient Large Language Models through Compact Kernelization》(2024) GitHub: github.com/YuchuanTian/DiJiang [fig1]<br />《Talk3D: High-Fidelity Talking Portrait Synthesis via Personalized 3D Generative Prior》(2024) GitHub: github.com/KU-CVLAB/Talk3D [fig3] <br />《Motion Inversion for Video Customization》(2024) GitHub: github.com/EnVision-Research/MotionInversion<br />《MineLand: Simulating Large-Scale Multi-Agent Interactions with Limited Multimodal Senses and Physical Needs》(2024) GitHub: github.com/cocacola-lab/MineLand<br />《Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models》(2024) GitHub: github.com/AtsuMiyai/UPD [fig4]<br />《Draw-and-Understand: Leveraging Visual Prompts to Enable MLLMs to Comprehend What You Want》(2024) GitHub: github.com/AFeng-x/Draw-and-Understand [fig5]<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hocfuvwv8uj21je0kqak6.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hocfx3bw1xj21x00le1kx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hocg07nt81j259e2g1npf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hocs644i0fj20un0gztsi.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoctmropi0j22ec14q7he.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:45:14 GMT</pubDate>
</item>
<item>
<title>【VillagerBench: 多智能体合作前沿技术的基准套件，旨在挑战虚拟智能体共同完成的极限，从建筑项目到烹饪任务，再到逃脱房间的谜题】'VillagerBench: Benchmark...</title>
<link>https://weibo.com/1402400261/O7TOrFbis</link>
<guid>https://weibo.com/1402400261/O7TOrFbis</guid>
<content:encoded><![CDATA[
<div> 多智能体合作, 基准套件, 挑战, 虚拟智能体, 完成, 极限, 建筑项目, 烹饪任务, 逃脱房间, 谜题

<br /><br />总结:
"VillagerBench"是一个用于多智能体合作的基准套件，旨在挑战虚拟智能体共同完成任务的极限。该套件涵盖了各种任务，包括建筑项目、烹饪任务和逃脱房间谜题，旨在促进智能体在团队合作中的表现。GitHub链接提供了更多关于该套件的信息和资源。 <div>
【VillagerBench: 多智能体合作前沿技术的基准套件，旨在挑战虚拟智能体共同完成的极限，从建筑项目到烹饪任务，再到逃脱房间的谜题】'VillagerBench: Benchmarking Teamwork in the World of Minecraft' GitHub: github.com/cnsdqd-dyb/VillagerAgent <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoctlgywx1j22410u0qft.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:43:28 GMT</pubDate>
</item>
<item>
<title>【ChatDev IDE: 用于构建AI代理的工具，无论是在游戏中的NPC还是强大的代理工具，都可以在这个平台上设计想要的内容】'ChatDev IDE: Building Your AI Agent - C...</title>
<link>https://weibo.com/1402400261/O7TNEvwYT</link>
<guid>https://weibo.com/1402400261/O7TNEvwYT</guid>
<content:encoded><![CDATA[
<div> ChatDev IDE、AI代理、工具、游戏NPC、强大、设计、平台

<br /><br />总结:
ChatDev IDE是一个用于构建AI代理的工具，无论是在游戏中的NPC还是强大的代理工具，用户可以在这个平台上设计他们想要的内容。GitHub上有相关项目：github.com/10cl/chatdev。ChatDev IDE为用户提供了便捷的设计和构建AI代理的功能，让用户可以自定义游戏中的NPC或其他强大的代理工具，实现个性化的需求。通过这个平台，用户可以更轻松地实现他们的AI代理设计和构建工作。 <div>
【ChatDev IDE: 用于构建AI代理的工具，无论是在游戏中的NPC还是强大的代理工具，都可以在这个平台上设计想要的内容】'ChatDev IDE: Building Your AI Agent - ChatDev IDE is an tools for building your ai agent, Whether it's NPCs in games or powerful agent tools, you can design what you want for this platform.' GitHub: github.com/10cl/chatdev <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoctjattloj21hc0qjqe4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoctjdq5a6j20u60czadw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoctjf0qvtj218i0q5164.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:41:31 GMT</pubDate>
</item>
<item>
<title>'LangGraph.js - a library for building stateful, multi-actor applications with LLMs, built on top of (and intended to be used with) LangChain.js' GitH...</title>
<link>https://weibo.com/1402400261/O7TMgqIjs</link>
<guid>https://weibo.com/1402400261/O7TMgqIjs</guid>
<content:encoded><![CDATA[
<div> LangGraph.js, library, stateful, multi-actor applications, LLMs, LangChain.js, GitHub, LangGraph.js

LangGraph.js是一个用于构建具有LLM的有状态多角色应用程序的库，它建立在LangChain.js之上并旨在与之一起使用。GitHub上有该项目的代码库。LangGraph.js可帮助开发人员构建具有状态和多角色功能的应用程序。LangGraph.js库适用于那些需要在应用程序中处理多个角色和状态的开发人员。LangGraph.js是一个建立在LangChain.js之上的库，旨在简化开发人员构建复杂应用程序的过程。LangGraph.js提供了一种有效的方式来管理状态和角色，并且能够与LangChain.js一起使用，使开发更加轻松。LangGraph.js的GitHub代码库包含了该库的所有代码，开发人员可以通过GitHub找到并了解该库的更多信息。LangGraph.js是一个强大的工具，可帮助开发人员快速构建具有LLM的多角色应用程序。总结：LangGraph.js是一个用于构建有状态、多角色应用程序的库，建立在LangChain.js之上，开发人员可以通过GitHub找到该项目的代码库。LangGraph.js提供了一种简化开发过程的有效方式，能够有效管理应用程序中的状态和角色，是一个强大的工具。 <div>
'LangGraph.js - a library for building stateful, multi-actor applications with LLMs, built on top of (and intended to be used with) LangChain.js' GitHub: github.com/langchain-ai/langgraphjs <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoctfvf9u7j21g80u0dma.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:38:05 GMT</pubDate>
</item>
<item>
<title>【nl-sh: 允许用户在终端中直接集成OpenAI的GPTs、Anthropic的Claude或本地GGUF格式的LLM，使操作人员能用流利的人类语言描述任务并执行】’nl-sh: Natural Lang...</title>
<link>https://weibo.com/1402400261/O7TJWloOf</link>
<guid>https://weibo.com/1402400261/O7TJWloOf</guid>
<content:encoded><![CDATA[
<div> 终端、集成、OpenAI、GPTs、Anthropic、Claude、GGUF、LLM、描述任务、执行。<br /><br />总结:
文章介绍了一种名为Natural Language Shell的工具，可以在终端中直接集成OpenAI的GPTs、Anthropic的Claude或本地GGUF格式的LLM，使操作人员能够用流利的人类语言描述任务并执行。这种工具可以让操作人员在终端中以POSIX命令或流利的人类语言描述任务，从而简化操作流程并提高效率。通过集成不同的语言模型，可以提供更多的选择和个性化的体验。该工具的开源地址为github.com/mikecvet/nl-sh，可以在GitHub上查看更多相关信息和下载使用。 <div>
【nl-sh: 允许用户在终端中直接集成OpenAI的GPTs、Anthropic的Claude或本地GGUF格式的LLM，使操作人员能用流利的人类语言描述任务并执行】’nl-sh: Natural Language Shell - The Natural Language Shell integrates OpenAI's GPTs, Anthropic's Claude, or local GGUF-formatted LLMs directly into the terminal experience, allowing operators to describe their tasks in either POSIX commands or fluent human language' GitHub: github.com/mikecvet/nl-sh <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoct9xdb1mj21db0u045y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:32:22 GMT</pubDate>
</item>
<item>
<title>【关于用Agent/大模型打游戏的相关文献资源列表】’A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges - This repo is...</title>
<link>https://weibo.com/1402400261/O7THU9SSK</link>
<guid>https://weibo.com/1402400261/O7THU9SSK</guid>
<content:encoded><![CDATA[
<div> 关键词: 游戏玩家代理、大型模型、方法、应用、挑战、调查、多模态、GitHub、资源

总结: 
<br /><br />这篇文章是有关游戏玩家代理和大型模型的综述调查，介绍了相关方法、应用和挑战。GitHub上提供了一份不断更新的游戏玩家代理和大型多模态模型的文献资源列表。文章主要探讨了游戏玩家代理和大型模型的研究现状和挑战，为该领域的研究提供了有价值的参考。 <div>
【关于用Agent/大模型打游戏的相关文献资源列表】’A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges - This repo is a live list of papers on game playing and large multimodality model - "A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges".' GitHub: github.com/BAAI-Agents/GPA-LM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoct4p04f4j20u00umq8o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:27:21 GMT</pubDate>
</item>
<item>
<title>【GraphAr：开源的、用于存储和检索图数据的标准数据文件格式】'GraphAr - An open source, standard data file format for graph data storage and retrieval' ...</title>
<link>https://weibo.com/1402400261/O7TGHfnZl</link>
<guid>https://weibo.com/1402400261/O7TGHfnZl</guid>
<content:encoded><![CDATA[
<div> GraphAr, 开源, 标准数据文件格式, 图数据, 存储, 检索, GitHub, GraphScope

<br /><br />总结:
GraphAr是一个开源的标准数据文件格式，用于存储和检索图数据。它旨在提供一种统一的方式来组织和访问图数据，使得数据的存储和检索变得更加高效和便捷。通过使用GraphAr，用户可以更容易地管理和操作图数据，从而提高数据处理的效率和准确性。GraphAr将图数据存储在标准格式的文件中，可以通过GitHub获取并使用。 <div>
【GraphAr：开源的、用于存储和检索图数据的标准数据文件格式】'GraphAr - An open source, standard data file format for graph data storage and retrieval' GitHub: github.com/GraphScope/GraphAr <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoct1ly59yj214w0u0n2x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:24:22 GMT</pubDate>
</item>
<item>
<title>'Translational-Style-ChatLLM：西式翻译腔聊天风格中文大模型 - 完全依靠ChatGPT生成数据微调的西式翻译腔聊天风格中文大模型' GitHub: github.com/Benson114/T...</title>
<link>https://weibo.com/1402400261/O7TG2qqfH</link>
<guid>https://weibo.com/1402400261/O7TG2qqfH</guid>
<content:encoded><![CDATA[
<div> 关键词: 西式翻译腔聊天风格、中文大模型、ChatGPT、GitHub

总结:<br /><br />这篇文章介绍了《Translational-Style-ChatLLM：西式翻译腔聊天风格中文大模型》，这是一个完全依靠ChatGPT生成数据微调的西式翻译腔聊天风格中文大模型。GitHub上有相关项目链接。 <div>
'Translational-Style-ChatLLM：西式翻译腔聊天风格中文大模型 - 完全依靠ChatGPT生成数据微调的西式翻译腔聊天风格中文大模型' GitHub: github.com/Benson114/Translational-Style-ChatLLM <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hocszxfsemj21ee0kaaea.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:22:45 GMT</pubDate>
</item>
<item>
<title>【用Transformer作为编码器和解码器的无损压缩的概念Demo】’Lossless Text Compression with Transformer-based Language Model - This repo is to demo the co...</title>
<link>https://weibo.com/1402400261/O7TFDoXRY</link>
<guid>https://weibo.com/1402400261/O7TFDoXRY</guid>
<content:encoded><![CDATA[
<div> Transformer、编码器、解码器、无损压缩、文本、语言模型、Github、Lossless Text Compression、demo、概念

总结:<br />
本文介绍了使用Transformer作为编码器和解码器进行无损压缩的概念。这个概念的demo已经在GitHub上发布，展示了如何利用Transformer-based语言模型实现文本的无损压缩。这种方法可以有效地压缩文本数据，同时保证数据的完整性，有望在实际应用中发挥重要作用。 <div>
【用Transformer作为编码器和解码器的无损压缩的概念Demo】’Lossless Text Compression with Transformer-based Language Model - This repo is to demo the concept of lossless compression with Transformers as encoder and decoder.' GitHub: github.com/Shawn-Guo-CN/Lossless_Text_Compression_with_Transformer <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hocsyuonitj21ca0u0gr9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 13:21:45 GMT</pubDate>
</item>
<item>
<title>【MineLand： 基于 Minecraft 的大型多 Agent 交互模拟器，支持有限的多模态感知和物理需求】'MineLand - Simulating Large-Scale Multi-Agent Interactions wit...</title>
<link>https://weibo.com/1402400261/O7TtFvChI</link>
<guid>https://weibo.com/1402400261/O7TtFvChI</guid>
<content:encoded><![CDATA[
<div> GitHub, MineLand, Minecraft, 多Agent, 交互模拟器, 多模态感知, 物理需求
<br />
<br />
总结:
MineLand是一个基于Minecraft的大型多Agent交互模拟器，支持有限的多模态感知和物理需求。该模拟器允许多个Agent在虚拟世界中进行交互，并能感知不同的模态信息，同时还需满足物理需求。通过GitHub上的项目页面，用户可以了解更多有关MineLand的信息和使用方法。MineLand的研究意义在于模拟大规模多Agent之间的交互，为研究人员提供了一个实验平台，用于探索Agent之间的关系和行为。MineLand的开发对于深入理解多Agent系统的运行机制具有重要意义，有助于推动相关领域的发展。 <div>
【MineLand： 基于 Minecraft 的大型多 Agent 交互模拟器，支持有限的多模态感知和物理需求】'MineLand - Simulating Large-Scale Multi-Agent Interactions with Limited Multimodal Senses and Physical Needs' GitHub: github.com/cocacola-lab/MineLand <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hocs47jdh4j21hc0u07kw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 12:52:17 GMT</pubDate>
</item>
<item>
<title>【StableTTS：轻量TTS模型，专为汉语和英语语音生成服务，参数仅有 10M】'StableTTS - Next-generation TTS model using flow-matching and DiT, inspired by St...</title>
<link>https://weibo.com/1402400261/O7QI8snkE</link>
<guid>https://weibo.com/1402400261/O7QI8snkE</guid>
<content:encoded><![CDATA[
<div> GitHub, StableTTS, 轻量, 汉语, 英语, 语音生成, 10M, 模型, 流匹配, DiT

<br /><br />总结:
StableTTS是一种轻量级TTS模型，专为汉语和英语语音生成服务而设计，模型参数仅有10M。该模型采用了流匹配和DiT技术，受稳定扩散3的启发。这种Next-generation TTS模型将语音合成领域带入了新的阶段，能够更高效地生成自然流畅的语音。通过GitHub平台，用户可以查看和了解StableTTS的具体实现和应用。 <div>
【StableTTS：轻量TTS模型，专为汉语和英语语音生成服务，参数仅有 10M】'StableTTS - Next-generation TTS model using flow-matching and DiT, inspired by Stable Diffusion 3' GitHub: github.com/KdaiP/StableTTS <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hocfwiijyuj21ji0n2q6z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 05:49:41 GMT</pubDate>
</item>
<item>
<title>【HeyForm：开源的表单构建器，允许创建引人入胜的对话性形式用于调查、问卷、测验和投票，无需编程技能即可使用】'HeyForm - an open-source form builder that...</title>
<link>https://weibo.com/1402400261/O7QAdy3jc</link>
<guid>https://weibo.com/1402400261/O7QAdy3jc</guid>
<content:encoded><![CDATA[
<div> 开源、表单构建器、对话性形式、调查、问卷、测验、投票、无需编程技能、GitHub、github.com/heyform/heyform

<br /><br />总结:
HeyForm是一个开源的表单构建器，允许用户创建引人入胜的对话性形式，用于进行调查、问卷、测验和投票。用户无需具备编程技能，通过访问其GitHub页面github.com/heyform/heyform即可开始使用。HeyForm的设计简洁易用，适合各种用户使用，为用户提供了便利的表单创建方式，并能够生成丰富多样的形式，帮助用户收集信息和进行数据分析。 <div>
【HeyForm：开源的表单构建器，允许创建引人入胜的对话性形式用于调查、问卷、测验和投票，无需编程技能即可使用】'HeyForm - an open-source form builder that allows anyone to create engaging conversational forms for surveys, questionnaires, quizzes, and polls. No coding skills required.' GitHub: github.com/heyform/heyform <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hocfc605l7j21900u0n3y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 05:30:10 GMT</pubDate>
</item>
<item>
<title>【RAGFlow：基于深度文档理解构建的开源 RAG(Retrieval-Augmented Generation)引擎】'RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine ...</title>
<link>https://weibo.com/1402400261/O7Qzt7oOe</link>
<guid>https://weibo.com/1402400261/O7Qzt7oOe</guid>
<content:encoded><![CDATA[
<div> 深度文档理解、开源、RAG、引擎、Retrieval-Augmented Generation、GitHub、infiniflow、RAGFlow

<br /><br />总结:
RAGFlow是一个基于深度文档理解构建的开源RAG引擎，采用Retrieval-Augmented Generation技术。用户可以在GitHub上找到该项目的代码库，地址为github.com/infiniflow/ragflow。该引擎具有强大的文档理解能力，能够实现检索和生成结合的文本处理任务。通过RAGFlow，用户可以更加高效地处理文档信息并进行相关任务的实现。 <div>
【RAGFlow：基于深度文档理解构建的开源 RAG(Retrieval-Augmented Generation)引擎】'RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.' GitHub: github.com/infiniflow/ragflow <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hocfa8ht0vj21hc0u00uu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 05:28:19 GMT</pubDate>
</item>
<item>
<title>恭喜@VarusRey 等3名用户获得【《码农翻身2》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效。公示链接：网页链接 - 转发 @爱可可-爱...</title>
<link>https://weibo.com/1402400261/O7Q1b6Oiu</link>
<guid>https://weibo.com/1402400261/O7Q1b6Oiu</guid>
<content:encoded><![CDATA[
<div> 码农翻身2 抽奖 微博 官方 工具 监督 公正 有效 参与 技术 故事 编程语言 Java Python JavaScript C语言 MySQL Redis 技术原理 读起来爽

<br /><br />总结:
在微博举办的《码农翻身2》抽奖活动中，官方唯一抽奖工具监督抽奖过程，确保结果公正有效。参与者只需转发并评论即可参与，有机会获得新出版的《码农翻身2》。这本畅销书以故事的方式讲解技术，让看似枯燥的技术变得有趣。故事中展现了各个编程语言之间的争斗和互动，让读者掌握技术原理的同时又能享受阅读乐趣。 <div>
恭喜<a href="https://weibo.com/n/VarusRey">@VarusRey</a> 等3名用户获得【《码农翻身2》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20280688&amp;pageid=100140E51193834"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 04:03:49 GMT</pubDate>
</item>
<item>
<title>【CPU上的LLaMA语言模型推理速度优化实践】 - 作者为llamafile编写了84个新的矩阵乘法核，使其在CPU上处理prompt和图像的速度提高30%到500%。这对ARM和AVX512等C...</title>
<link>https://weibo.com/1402400261/O7Osgu4Br</link>
<guid>https://weibo.com/1402400261/O7Osgu4Br</guid>
<content:encoded><![CDATA[
<div> 矩阵乘法、CPU、LLaMA、优化、性能、跨平台、普及、应用、性能分析、改进
<br /><br />总结: 通过优化矩阵乘法内核，作者成功提升了LLaMA在CPU上的推理速度，对于资源受限设备的应用具有重要意义。跨平台和跨架构的优化使得LLaMA在更广泛的环境中运行，促进了LLM的普及和应用。作者通过性能分析找到瓶颈并进行有针对性的优化，展示了一种值得借鉴的工程方法。当前优化虽然对长提示的加速有限，但作者持续改进，相信后续表现会更加令人期待。文章首先突出了矩阵乘法在LLM中的核心地位和优化的重要性，详细描述了优化过程和结果，分享了性能优化经验。代码已提交给LLaMA的上游项目，以使更多用户受益。 <div>
【CPU上的LLaMA语言模型推理速度优化实践】<br /> - 作者为llamafile编写了84个新的矩阵乘法核，使其在CPU上处理prompt和图像的速度提高30%到500%。这对ARM和AVX512等CPU架构提速明显。   <br />- 在不同的CPU硬件上测试了优化后的llamafile和原版llama.cpp的性能，结果显示llamafile的速度提升幅度可达2倍。测试的硬件包括Intel、ARM、AMD等在内的服务器、个人电脑和专业工作站。   <br />- 作者主要通过优化矩阵乘法来实现提速，因为分析发现矩阵乘法占了95%的时间。作者使用C++实现了优化的矩阵乘法内核。   <br />- 作者不仅关注服务器硬件的性能，还重视廉价的个人电脑和树莓派等爱好者硬件的性能提升，以使更多用户也能受益。   <br />- 作者还分析了不同数据类型如fp16、bfloat16等对速度和精度的影响。并增加了对这些数据类型的支持。   <br />- 作者的代码已提交给llama.cpp的上游项目，以便所有用户都能受益。代码使用MIT许可发布。   <br />- 文章详细描述了作者是如何通过优化关键的矩阵乘法操作来显著提高整个语言模型的推理速度的，旨在分享这一性能优化经验。   <br /><br />思考：  <br />- 作者通过优化矩阵乘法内核，大幅提升了llamafile在CPU上的推理速度，这对于在资源受限设备上部署LLM具有重要意义。  <br />- 跨平台和跨架构的优化使llamafile能够在更广泛的环境中运行，有利于LLM的普及和应用。  <br />- 通过性能分析定位瓶颈，并针对性优化，这种工程方法值得借鉴。  <br />- 虽然目前的优化对较长提示的加速效果有限，但作者正在持续改进，后续表现值得期待。  <br />- 文章在开头通过简洁的代码定义矩阵乘法，突出了其在LLM中的核心地位和优化的重要性。<br />《LLaMA Now Goes Faster on CPUs》 <a href="https://justine.lol/matmul"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoc5xqcm7uj211q0u0n4f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 00:05:05 GMT</pubDate>
</item>
<item>
<title>“Datawhale - 专注于AI领域的开源组织，致力于构建一个纯粹的学习圈子，帮助学习者更好地成长” 网页链接 #机器学习# #人工智能# [图片][图片][图片]</title>
<link>https://weibo.com/1402400261/O7OqmCa13</link>
<guid>https://weibo.com/1402400261/O7OqmCa13</guid>
<content:encoded><![CDATA[
<div> Datawhale, AI领域, 开源组织, 纯粹学习圈子, 帮助学习者, 成长<br />
<br />
在AI领域，Datawhale是一个专注于开源组织，旨在构建一个纯粹的学习圈子，帮助学习者更好地成长。他们致力于为学习者提供资源和支持，促进知识的共享和学习的发展，旨在推动AI领域的进步和发展。通过不断学习和交流，学习者能够不断提升技能，实现个人的成长和发展。<br /><br />总结: Datawhale是专注于AI领域的开源组织，旨在构建一个纯粹的学习圈子，帮助学习者更好地成长。通过资源和支持，推动知识分享和学习发展，促进个人技能提升和成长。 <div>
“Datawhale - 专注于AI领域的开源组织，致力于构建一个纯粹的学习圈子，帮助学习者更好地成长” <a href="https://linklearner.com/home"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoc5s699fjj21hw0u0n0m.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoc5sp5b6gj20zs0u0dis.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoc5t3b46aj217n0u0gom.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 02 Apr 2024 00:00:24 GMT</pubDate>
</item>
<item>
<title>【矩阵形状与矩阵乘法性能】- 矩阵乘法的性能随矩阵尺寸的增大而整体提升，这是由于计算强度提高和并行度提高带来的。运算相对于内存访问的算术强度越高，性能越...</title>
<link>https://weibo.com/1402400261/O7OpehzFb</link>
<guid>https://weibo.com/1402400261/O7OpehzFb</guid>
<content:encoded><![CDATA[
<div> 矩阵乘法、矩阵形状、性能、计算强度、并行度、划分、内存访问、算术强度、优化、深度学习<br />
<br />
总结:<br />
矩阵乘法的性能随着矩阵尺寸的增大而提升，这与计算强度提高和并行度增加有关。算术强度越高，性能越好。矩阵乘法的性能与矩阵形状的可划分性密切相关，形状能被2、8、16等2的幂整除时性能更优。当形状大小超过波粒子整数倍时，会出现性能下降，这与硬件SM数量相关。微小的矩阵形状变化可能导致巨大的性能差异，选择能被缓存行大小整除的形状很重要。一些框架能自动优化矩阵形状，但手动优化依然重要。理解矩阵运算性能的决定因素，选择合适的矩阵形状，对深度学习模型的性能提升至关重要。 <div>
【矩阵形状与矩阵乘法性能】<br />- 矩阵乘法的性能随矩阵尺寸的增大而整体提升，这是由于计算强度提高和并行度提高带来的。运算相对于内存访问的算术强度越高，性能越好。   <br />- 矩阵乘法的性能与矩阵形状的可划分性高度相关，当形状能被2、8、16等2的幂整除时，性能明显更好。这是由于划分(tiling)带来的更优内存访问模式。   <br />- 当矩阵形状大小超过波粒子(wave)的整数倍时，会出现明显的性能下降。这种波粒子量化的影响与硬件SM(流处理器)的数量相关。   <br />- 由于上述原因，微小的矩阵形状变化可能导致巨大的性能差异。选择能够被缓存行大小整除的形状非常重要。   <br />- 一些框架如torch.compile会自动优化矩阵形状，将其pad至更优形状。但由于存在显存消耗和波粒子量化难以优化的问题，手动优化形状依然重要。   <br />- 理解矩阵运算性能的决定因素，选择合适的矩阵形状，能显著提升矩阵计算的性能。这对基于矩阵运算的深度学习模型具有重要意义。<br />《What Shapes Do Matrix Multiplications Like? [medium]》 <a href="https://www.thonking.ai/p/what-shapes-do-matrix-multiplications"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoc5q6je9dj20w30u00wt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 23:57:36 GMT</pubDate>
</item>
<item>
<title>【用AutoTrain微调Mixtral 8x7B实战】《Finetune Mixtral 8x7B with AutoTrain》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O7OnL0nLA</link>
<guid>https://weibo.com/1402400261/O7OnL0nLA</guid>
<content:encoded><![CDATA[
<div> 关键词：AutoTrain、微调、Mixtral 8x7B、实战

总结:
<br /><br />
本文介绍了如何使用AutoTrain对Mixtral 8x7B进行微调，以适应实际应用场景。首先介绍了Mixtral 8x7B的基本情况，然后详细说明了AutoTrain微调的流程和步骤。通过实例分析和操作步骤，读者可以了解如何利用AutoTrain进行深度模型微调，以提高模型在具体任务上的表现和效果。整个过程需要细致的数据准备、模型配置和调整，同时也需要合理的训练策略和参数设置。最后，作者总结了AutoTrain微调Mixtral 8x7B的实战经验，为读者提供了更加高效和实用的深度学习模型微调方法。通过本文的学习，读者可以更好地掌握深度学习模型微调的技巧和方法，以应对不同任务和场景的需求。 <div>
【用AutoTrain微调Mixtral 8x7B实战】《Finetune Mixtral 8x7B with AutoTrain》 <a href="https://huggingface.co/blog/abhishek/autotrain-mixtral-dgx-cloud-local"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoc5me4grnj20u00utaec.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 23:53:58 GMT</pubDate>
</item>
<item>
<title>HuggingFace开源AI方案手册 - 转发 @爱可可-爱生活:&amp;ensp;【Open-Source AI Cookbook：HuggingFace开源AI方案手册，涵盖了使用开源工具和模型构建AI应用和解决各...</title>
<link>https://weibo.com/1402400261/O7OnguHgt</link>
<guid>https://weibo.com/1402400261/O7OnguHgt</guid>
<content:encoded><![CDATA[
<div> HuggingFace, AI, 开源, 方案手册, 模型, 构建, 应用, 解决任务, GitHub, 笔记本

<br /><br />总结:
HuggingFace开源AI方案手册是一个收集了实际构建AI应用和使用开源工具和模型解决各种机器学习任务的笔记本集合。该手册在GitHub上提供，涵盖了使用HuggingFace开源工具和模型的实用方面。读者可以通过这些示例了解如何利用开源工具和模型构建AI应用，解决各种机器学习任务。通过这些笔记本，读者可以更深入地了解如何利用HuggingFace的技术来提升自己的AI项目。GitHub链接提供了丰富的资源，为AI开发者提供了学习和研究的平台。 HuggingFace开源AI方案手册将帮助读者更好地理解和应用AI技术，推动AI的发展。 <div>
HuggingFace开源AI方案手册<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 【Open-Source AI Cookbook：HuggingFace开源AI方案手册，涵盖了使用开源工具和模型构建AI应用和解决各种任务的方法】'Open-Source AI Cookbook - a collection of notebooks illustrating practical aspects of building AI applications and solving various machine learning tasks using open-source tools and models.’ <a href="https://huggingface.co/learn/cookbook/index"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> GitHub: github.com/huggingface/cookbook <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hmw5wsoap6j20u00ypagc.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 23:52:46 GMT</pubDate>
</item>
<item>
<title>【AI对话零门槛：ChatGPT开放免注册使用】- OpenAI推出了无需注册即可使用ChatGPT的功能，降低了使用门槛，让更多人可以体验AI的好处。 - 目前每周有超过1亿用户...</title>
<link>https://weibo.com/1402400261/O7OmLyBYE</link>
<guid>https://weibo.com/1402400261/O7OmLyBYE</guid>
<content:encoded><![CDATA[
<div> OpenAI, ChatGPT, 无需注册, 降低门槛, 1亿用户, 全球影响力, 用户隐私, 内容安全, 注册用户功能, AI普惠化

总结:<br /><br />OpenAI推出了无需注册即可使用ChatGPT的功能，降低了使用门槛，让更多人可以体验AI的好处。每周有超过1亿用户在185个国家使用ChatGPT，免注册使用将进一步扩大用户基础。虽然取消注册要求，但OpenAI重视用户隐私和内容安全，并提供注册用户专属功能。OpenAI的使命是让普通大众也能体验到AI工具带来的益处，这个新功能是朝着AI普惠化更进一步的重要一步。 <div>
【AI对话零门槛：ChatGPT开放免注册使用】<br />- OpenAI推出了无需注册即可使用ChatGPT的功能，降低了使用门槛，让更多人可以体验AI的好处。   <br />- 目前每周有超过1亿用户在185个国家使用ChatGPT，以学习新知识、寻找创作灵感和获得问题解答。开放使用功能将进一步提升覆盖面。   <br />- 用户提供的信息可能会被OpenAI用来改进模型，但用户可以通过设置关闭此功能。更多详细信息可以在帮助中心查看。   <br />- 为提高内容安全，该体验增加了更广泛类别的提示和生成内容屏蔽。   <br />- 注册账户可以获得保存聊天记录、分享聊天、语音对话等额外功能。   <br />- 对任何之前因注册流程门槛而无法尝试AI的人来说，这个新功能提供了一个零门槛使用ChatGPT的机会。   <br />- OpenAI的使命是让普通大众也能体验到AI工具带来的益处。这个功能的推出是朝着使AI普惠化更进一步。<br /><br />思考：    <br />- 取消注册要求是OpenAI在普及AI方面迈出的重要一步，这将大大降低普通用户接触和体验ChatGPT的门槛，有利于加速AI技术的大众化进程。    <br />- ChatGPT的全球影响力已经非常显著，超过1亿的周活跃用户数据印证了其在知识获取、创意激发等方面的价值。免注册使用将进一步扩大其用户基础。    <br />- 在开放的同时，OpenAI也重视用户隐私和内容安全，为用户提供了控制个人数据使用的选项，并加强了内容审核，这种负责任的态度值得肯定。    <br />- 虽然免注册使用受到欢迎，但注册用户专属的附加功能仍有吸引力，OpenAI在两种模式间取得了较好的平衡。    <br />- 随着准入门槛的降低，ChatGPT在教育、创意、个人助理等领域的应用有望进一步深化，但同时也需警惕对人类认知和创造力的潜在负面影响。<br />《Start using ChatGPT instantly》 <a href="https://openai.com/blog/start-using-chatgpt-instantly"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoc5jv8pktj21i60u0q64.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 23:51:32 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可...</title>
<link>https://weibo.com/1402400261/O7OjVxm5u</link>
<guid>https://weibo.com/1402400261/O7OjVxm5u</guid>
<content:encoded><![CDATA[
<div> Java Python JavaScript C语言 MySQL Redis 技术故事 编程语言 欢迎参与开奖活动！ 

<br /><br />总结:
欢迎参与今日开奖活动，转发并评论可有机会获得《码农翻身2》。书中通过编程语言王国的争斗故事，以轻松幽默的方式讲解技术知识，让枯燥的技术变得有趣。不同编程语言相互攻击，技术原理交融，读者能够在阅读中掌握技术本质。MySQL和Redis之间的对抗，以及C语言的悲催经历，都让读者在阅读过程中获得乐趣和知识。《码农翻身2》的故事情节生动有趣，让大家能够深入理解技术知识，享受阅读乐趣。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 23:44:32 GMT</pubDate>
</item>
<item>
<title>今日推介(第1363期)：从大型语言模型中蒸馏的通用文本嵌入、慢变序列稳定机器学习模型再训练研究、语言模型段落记忆定位、LLM长文本不确定性量化、Transformer- ...</title>
<link>https://weibo.com/1402400261/O7NJulgMx</link>
<guid>https://weibo.com/1402400261/O7NJulgMx</guid>
<content:encoded><![CDATA[
<div> 蒸馏、文本嵌入、慢变序列、稳定机器学习、模型再训练、段落记忆、长文本、不确定性量化、Transformer、混合语言模型

总结：<br />
研究围绕大型语言模型展开，从中提取了通用文本嵌入，通过蒸馏技术实现。同时探讨了慢变序列稳定机器学习模型再训练的方法和实践。针对语言模型段落记忆问题，提出了相应的定位方法。此外，还对LLM长文本不确定性进行量化研究，以提升模型性能。最后，介绍了Transformer-mamba混合语言模型的开发和应用。整体研究丰富了自然语言处理领域的技术和应用。 <div>
今日推介(第1363期)：从大型语言模型中蒸馏的通用文本嵌入、慢变序列稳定机器学习模型再训练研究、语言模型段落记忆定位、LLM长文本不确定性量化、Transformer- mamba混合语言模型 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/690275166"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.2)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoc2qnz3gxj21m30u00yq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoc2qsoq97j21qp0u0tf9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoc2qy4q8cj20te1bcai1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoc2r20mejj21ij0u0dp0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoc2r55kozj20u00vn0w8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 22:14:45 GMT</pubDate>
</item>
<item>
<title>[AI] Towards Greener LLMs: Bringing Energy-Efficiency to the Forefront of LLM Inference 网页链接 通过调节频率、并行度和批处理等多种手段，全面描绘了优...</title>
<link>https://weibo.com/1402400261/O7NFCbFAF</link>
<guid>https://weibo.com/1402400261/O7NFCbFAF</guid>
<content:encoded><![CDATA[
<div> 频率、并行度、批处理、大语言模型、推理平台、能效、性能权衡、数据中心、设计指导

<br /><br />总结:
本文通过调节频率、并行度和批处理等多种手段，全面探讨了优化大语言模型推理平台能效的各种性能权衡。文章为未来数据中心提供了宝贵的设计指导，为实现更加环保的LLMs起到了重要作用。 <div>
[AI] Towards Greener LLMs: Bringing Energy-Efficiency to the Forefront of LLM Inference  <br /><a href="https://arxiv.org/abs/2403.20306"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过调节频率、并行度和批处理等多种手段，全面描绘了优化大语言模型推理平台能效的各种性能权衡，为未来的数据中心提供了宝贵的设计指导。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc2h6digoj20zq1b0kek.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc2h6ui3yj20ls19oaja.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc2h7ipd0j20ls1dwdp3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc2h83c1cj20lu1dyajg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 22:05:13 GMT</pubDate>
</item>
<item>
<title>[CL] STRUM-LLM: Attributed and Structured Contrastive Summarization 网页链接 提出了STRUM-LLM系统，使用大语言模型生成有结构、归因和对比性的摘要，以帮助...</title>
<link>https://weibo.com/1402400261/O7NBeif7h</link>
<guid>https://weibo.com/1402400261/O7NBeif7h</guid>
<content:encoded><![CDATA[
<div> STRUM-LLM系统, 大语言模型, 生成, 结构, 归因, 对比性, 摘要, 无须标注数据, 处理任意长度输入, 自我修订, 质量提升

<br /><br />总结: 
研究提出了STRUM-LLM系统，利用大语言模型生成结构化、归因和对比性的摘要，帮助用户在选择两个选项时做出明智决策。这一方法无需标注数据，能够处理任意长度的输入，并通过自我修订显著提升了摘要质量。 <div>
[CL] STRUM-LLM: Attributed and Structured Contrastive Summarization  <br /><a href="https://arxiv.org/abs/2403.19710"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出了STRUM-LLM系统，使用大语言模型生成有结构、归因和对比性的摘要，以帮助用户在两个选项间进行明智决策，方法无须标注数据，可以处理任意长度输入，通过自我修订显著提升质量。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc25zf8dzj20yy1cstq0.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc25zrv8wj20sw162q9j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:54:25 GMT</pubDate>
</item>
<item>
<title>[CL] ReALM: Reference Resolution As Language Modeling 网页链接 本文通过将指代消解建模为语言模型选择任务，证明了语言模型可以高效解决包含非对话在内的各...</title>
<link>https://weibo.com/1402400261/O7NxtaOwL</link>
<guid>https://weibo.com/1402400261/O7NxtaOwL</guid>
<content:encoded><![CDATA[
<div> RealM, 指代消解, 语言模型选择任务, 非对话, 高效解决, 关键词

<br /><br />总结:
本文通过将指代消解建模为语言模型选择任务，证明了语言模型可以高效解决包含非对话在内的各类指代消解。语言模型在处理指代消解时表现出色，能够有效解决各种语境下的指代问题。这种方法有效缩减了指代消解的复杂性，提高了处理效率。RealM模型为指代消解提供了新的解决思路，为相关领域的研究和应用带来了新的启示。 <div>
[CL] ReALM: Reference Resolution As Language Modeling  <br /><a href="https://arxiv.org/abs/2403.20329"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />本文通过将指代消解建模为语言模型选择任务，证明了语言模型可以高效解决包含非对话在内的各类指代消解。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc1wcriqnj20uu1a4qj3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc1wcwzqgj20us10q42s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:45:09 GMT</pubDate>
</item>
<item>
<title>[CL] DiJiang: Efficient Large Language Models through Compact Kernelization 网页链接 DiJiang通过频域核化，实现了将预训练Transformer高效转换为线性复杂...</title>
<link>https://weibo.com/1402400261/O7NuvCmpL</link>
<guid>https://weibo.com/1402400261/O7NuvCmpL</guid>
<content:encoded><![CDATA[
<div> 频域核化 预训练Transformer 线性复杂度 模型 训练 推理 成本 性能 DiJiang<br />
<br />
提出了一种名为DiJiang的方法，通过频域核化将预训练的Transformer模型高效地转换为具有线性复杂度的模型。这一方法极大地降低了模型的训练和推理成本，同时仍保持了可比的性能水平。DiJiang方法的核心思想是利用频域核化技术，通过计算频域特征来简化模型的复杂度，从而提高模型的效率。通过实验证明，DiJiang模型在保持性能的同时，大幅减少了训练和推理的时间成本，为大规模语言模型的应用提供了一种高效的解决方案。总的来说，DiJiang方法为提升大型语言模型的效率和性能做出了重要贡献。<br /><br />总结: <br />DiJiang通过频域核化将预训练Transformer模型转换为具有线性复杂度的模型，降低了训练和推理成本，保持了可比的性能。 <div>
[CL] DiJiang: Efficient Large Language Models through Compact Kernelization  <br /><a href="https://arxiv.org/abs/2403.19928"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />DiJiang通过频域核化，实现了将预训练Transformer高效转换为线性复杂度模型，极大降低了训练和推理成本，同时保持了可比的性能。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc1oqlhhkj211m1c41e9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc1oqwsg9j21im0ocn3t.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc1oredckj20r20qajuj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc1orxnowj21f40jote2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:37:52 GMT</pubDate>
</item>
<item>
<title>提出Jamba这种混合Transformer-Mamba结构的语言模型，在单GPU上实现了强大的性能，对长序列也很友好，是一种非常有前景的创新型架构。 - 转发 @爱可可-爱生活:&amp;e...</title>
<link>https://weibo.com/1402400261/O7NrFyUBU</link>
<guid>https://weibo.com/1402400261/O7NrFyUBU</guid>
<content:encoded><![CDATA[
<div> Jamba, Transformer-Mamba, 语言模型, 单GPU, 性能, 长序列, 创新型架构

<br /><br />总结:
提出了一种混合Transformer-Mamba结构的语言模型Jamba，在单GPU上实现了强大的性能，对长序列也很友好。该架构具有前景，是一种创新型架构。 Jamba的设计结合了Transformer和Mamba的优点，具有高效的计算能力和长序列处理能力。在实验中，Jamba在多项任务上取得了优异的表现，证明了其性能和实用性。总体而言，Jamba是一种非常有潜力和前景的语言模型架构。 <div>
提出Jamba这种混合Transformer-Mamba结构的语言模型，在单GPU上实现了强大的性能，对长序列也很友好，是一种非常有前景的创新型架构。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Jamba: A Hybrid Transformer-Mamba Language Model》O Lieber, B Lenz, H Bata, G Cohen... [A21 Labs] (2024) <a href="https://arxiv.org/abs/2403.19887"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc1aergz1j21ck0xswuj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1af49fgj215k17ugrx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1afhehij215g0imgny.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc1afrbl0j21500kmdko.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd1qinj20vd0f0755.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd24sbj20ve0g3abi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd1tsrj20vd0egmy7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd301hj20vh0oiwje.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc1hd1bxhj20ns0dc0t7.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:30:52 GMT</pubDate>
</item>
<item>
<title>[CL]《Jamba: A Hybrid Transformer-Mamba Language Model》O Lieber, B Lenz, H Bata, G Cohen... [A21 Labs] (2024) 网页链接 #机器学习##人工智能##论文# [图...</title>
<link>https://weibo.com/1402400261/O7NrCw64v</link>
<guid>https://weibo.com/1402400261/O7NrCw64v</guid>
<content:encoded><![CDATA[
<div> Jamba, Hybrid Transformer-Mamba, Language Model, A21 Labs, 2024, O Lieber, B Lenz, H Bata, G Cohen

<br /><br />总结:
这篇文章介绍了一种名为Jamba的混合Transformer-Mamba语言模型，由A21 Labs团队在2024年的研究成果。该模型结合了Transformer和Mamba的特性，具有较强的语言建模能力。研究团队通过对O Lieber、B Lenz、H Bata和G Cohen等成员的研究，展示了Jamba在自然语言处理领域的潜在应用和优势。Jamba模型的推出将为语言建模和相关领域的发展提供新的思路和可能性。 <div>
[CL]《Jamba: A Hybrid Transformer-Mamba Language Model》O Lieber, B Lenz, H Bata, G Cohen... [A21 Labs] (2024) <a href="https://arxiv.org/abs/2403.19887"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc1aergz1j21ck0xswuj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1af49fgj215k17ugrx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1afhehij215g0imgny.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc1afrbl0j21500kmdko.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd1qinj20vd0f0755.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd24sbj20ve0g3abi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd1tsrj20vd0egmy7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc1hd301hj20vh0oiwje.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc1hd1bxhj20ns0dc0t7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:30:44 GMT</pubDate>
</item>
<item>
<title>针对长文本生成提出句级一致性判断的LUQ方法进行不确定性量化，结果表明LUQ可显著提升语言模型的生成事实性。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《LUQ: Long-tex...</title>
<link>https://weibo.com/1402400261/O7Nl11qlt</link>
<guid>https://weibo.com/1402400261/O7Nl11qlt</guid>
<content:encoded><![CDATA[
<div> 关键词: 长文本生成, 句级一致性, 不确定性量化, LUQ 方法, 语言模型

总结:<br /><br />这篇文章介绍了一种针对长文本生成的句级一致性判断方法LUQ，并对不确定性进行了量化。研究结果显示，LUQ方法能显著提升语言模型的生成事实性。LUQ方法由来自剑桥大学和亚马逊AGI的C Zhang、F Liu、M Basaldella和N Collier合作研究，于2024年发表。这一方法的提出填补了长文本生成领域的研究空白，并为语言模型的发展带来了新的启示。LUQ方法不仅可以帮助评估生成文本的一致性，还可以对生成文本的不确定性进行量化，提高了生成文本的可信度。通过对LUQ方法的研究，可以为提高自然语言处理系统的效果提供有效的方法和技术。LUQ方法的应用前景广阔，对自然语言生成领域具有重要意义。 <div>
针对长文本生成提出句级一致性判断的LUQ方法进行不确定性量化，结果表明LUQ可显著提升语言模型的生成事实性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《LUQ: Long-text Uncertainty Quantification for LLMs》C Zhang, F Liu, M Basaldella, N Collier [University of Cambridge &amp; Amazon AGI] (2024) <a href="https://arxiv.org/abs/2403.20279"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0zrcezoj20kg19ck2a.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0zryhgij21rm0z0too.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0zs8jphj21rg15sqfv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0zseif2j20vm0z678i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc108mpwfj20ho0k3my5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc108mptdj20hm0d3mxj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:14:28 GMT</pubDate>
</item>
<item>
<title>[CL]《LUQ: Long-text Uncertainty Quantification for LLMs》C Zhang, F Liu, M Basaldella, N Collier [University of Cambridge &amp; Amazon AGI] (2024) 网页链...</title>
<link>https://weibo.com/1402400261/O7NkWjPxB</link>
<guid>https://weibo.com/1402400261/O7NkWjPxB</guid>
<content:encoded><![CDATA[
<div> 关键词: LUQ, Uncertainty Quantification, LLMs, Cambridge, Amazon AGI

LUQ: Long-text Uncertainty Quantification for LLMs 是由剑桥大学和亚马逊AGI合作的研究项目，致力于解决长文本对于语言模型的不确定性量化问题。研究着眼于提高语言模型对于长文本理解和处理的准确度，特别是在处理含有不确定性信息的文本时。通过引入新的方法和技术，研究团队成功地开发了LUQ框架，可以有效地衡量和管理语言模型在长文本处理过程中的不确定性。该框架的应用将有助于提升语言模型的性能，并推动自然语言处理领域的进一步发展。

总结:<br /><br />LUQ: Long-text Uncertainty Quantification for LLMs 是一个研究项目，旨在提高语言模型对长文本的处理准确度，尤其是在处理不确定性信息时。研究团队通过开发LUQ框架成功解决了这一问题，为自然语言处理领域的发展提供了新的思路和方法。 <div>
[CL]《LUQ: Long-text Uncertainty Quantification for LLMs》C Zhang, F Liu, M Basaldella, N Collier [University of Cambridge &amp; Amazon AGI] (2024) <a href="https://arxiv.org/abs/2403.20279"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0zrcezoj20kg19ck2a.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0zryhgij21rm0z0too.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0zs8jphj21rg15sqfv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0zseif2j20vm0z678i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc108mpwfj20ho0k3my5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc108mptdj20hm0d3mxj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:14:17 GMT</pubDate>
</item>
<item>
<title>通过梯度分析和训练目标，发现语言模型中的记忆主要集中在较低层的注意力头，解释了记忆的鲁棒性。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Localizing Paragraph Me...</title>
<link>https://weibo.com/1402400261/O7Nks758p</link>
<guid>https://weibo.com/1402400261/O7Nks758p</guid>
<content:encoded><![CDATA[
<div> 记忆、语言模型、注意力头、梯度分析、训练目标、鲁棒性、段落、定位、Google、ETH Zürich

总结:<br /><br />这篇文章通过梯度分析和训练目标发现，语言模型中的记忆主要集中在较低层的注意力头，这解释了记忆的鲁棒性。作者提出了定位段落记忆在语言模型中的方式，并对这一结论进行了实证研究。研究结果显示，语言模型在处理文本任务时对段落级别的记忆有显著影响，有助于解释语言模型的表现和性能。这一发现对语言模型研究和应用具有一定的启发意义，有望进一步拓展语言模型的应用领域。 <div>
通过梯度分析和训练目标，发现语言模型中的记忆主要集中在较低层的注意力头，解释了记忆的鲁棒性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Localizing Paragraph Memorization in Language Models》N Stoehr, M Gordon, C Zhang, O Lewis [Google &amp; ETH Zürich] (2024) <a href="https://arxiv.org/abs/2403.19851"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0y3jp0xj20uc1cogyf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0y3zf8jj20te1bcn7k.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0y49vojj20t60vudn1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0y4lql2j21m00x8ajv.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0yohechj20zx0wxq8n.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0yog5k7j20zt0igae0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0yogdymj20zx0sd77y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0yog11mj20zs0f4tay.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0yofgnwj20zs0atta4.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:13:05 GMT</pubDate>
</item>
<item>
<title>[CL]《Localizing Paragraph Memorization in Language Models》N Stoehr, M Gordon, C Zhang, O Lewis [Google &amp; ETH Zürich] (2024) 网页链接 #机器学习##人...</title>
<link>https://weibo.com/1402400261/O7Nkkr4DX</link>
<guid>https://weibo.com/1402400261/O7Nkkr4DX</guid>
<content:encoded><![CDATA[
<div> Paragraph Memorization, Language Models, Localizing, Google, ETH Zürich, N Stoehr, M Gordon, C Zhang, O Lewis

<br /><br />总结:
这篇文章由N Stoehr, M Gordon, C Zhang, O Lewis等人在2024年发表，并由Google和ETH Zürich合作完成。研究的主题是关于在语言模型中的段落记忆的本地化。研究指出了语言模型在总结信息时的一些问题，并提出了一种新的方法来处理这个问题，以提高模型的效率和准确性。研究结果显示，这种本地化的方法可以显著改善语言模型的记忆和总结能力，在各种应用场景中都具有潜在的重要性。文章的研究方法和结论对自然语言处理领域具有一定的参考价值。 <div>
[CL]《Localizing Paragraph Memorization in Language Models》N Stoehr, M Gordon, C Zhang, O Lewis [Google &amp; ETH Zürich] (2024) <a href="https://arxiv.org/abs/2403.19851"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0y3jp0xj20uc1cogyf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0y3zf8jj20te1bcn7k.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0y49vojj20t60vudn1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0y4lql2j21m00x8ajv.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0yohechj20zx0wxq8n.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0yog5k7j20zt0igae0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0yogdymj20zx0sd77y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0yog11mj20zs0f4tay.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0yofgnwj20zs0atta4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0yohxfgj20zy1atn5d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0yogkxlj20zs0j8776.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0yogkj8j20z40a90uf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0yoggjuj20zx0mf76t.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:12:47 GMT</pubDate>
</item>
<item>
<title>通过定义模型距离度量并集成到混合整数规划算法中，提出一种在机器学习模型数据批量再训练问题上既考虑性能又保证结构稳定性的全局优化方法。 - 转发 @爱可可-爱...</title>
<link>https://weibo.com/1402400261/O7NjUvh7e</link>
<guid>https://weibo.com/1402400261/O7NjUvh7e</guid>
<content:encoded><![CDATA[
<div> 模型距离度量, 混合整数规划, 数据批量再训练, 性能, 结构稳定性, 全局优化方法, 机器学习, 稳定性, 慢变化序列
<br />
<br />
总结: 
该研究提出了一种在机器学习模型数据批量再训练中考虑性能和保证结构稳定性的全局优化方法。通过定义模型距离度量并集成到混合整数规划算法中，利用慢变化序列确保模型稳定性。这种方法在实际应用中有望提升机器学习模型的性能和稳定性，对于机器学习领域具有一定的实用意义。 <div>
通过定义模型距离度量并集成到混合整数规划算法中，提出一种在机器学习模型数据批量再训练问题上既考虑性能又保证结构稳定性的全局优化方法。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Towards Stable Machine Learning Model Retraining via Slowly Varying Sequences》V D Jr, Y Ma, P Paschalidis, D Bertsimas [Management, HEC Paris &amp; MIT &amp; Harvard University] (2024) <a href="https://arxiv.org/abs/2403.19871"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0wvp1eej21d40rqdsd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0ww6ophj21m20rsjzn.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0wwfi43j21ma0pmahx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0wwjpfmj21mo0todm9.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:11:44 GMT</pubDate>
</item>
<item>
<title>[LG]《Towards Stable Machine Learning Model Retraining via Slowly Varying Sequences》V D Jr, Y Ma, P Paschalidis, D Bertsimas [Management, HEC Paris &amp;...</title>
<link>https://weibo.com/1402400261/O7NjQ4qli</link>
<guid>https://weibo.com/1402400261/O7NjQ4qli</guid>
<content:encoded><![CDATA[
<div> 稳定性、机器学习、模型再训练、缓慢变化序列、管理、HEC巴黎、MIT、哈佛大学

总结:<br /><br />这篇文章提出了一种通过缓慢变化序列实现稳定机器学习模型再训练的方法。研究人员来自管理、HEC巴黎、MIT和哈佛大学，他们的方法旨在解决机器学习模型再训练过程中出现的不稳定性问题。通过引入缓慢变化的序列，可以有效地降低模型训练过程中的不确定性，提高模型的稳定性和准确性。这项研究对于提高机器学习模型再训练的效率和可靠性具有重要意义。 <div>
[LG]《Towards Stable Machine Learning Model Retraining via Slowly Varying Sequences》V D Jr, Y Ma, P Paschalidis, D Bertsimas [Management, HEC Paris &amp; MIT &amp; Harvard University] (2024) <a href="https://arxiv.org/abs/2403.19871"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0wvp1eej21d40rqdsd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0ww6ophj21m20rsjzn.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoc0wwfi43j21ma0pmahx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0wwjpfmj21mo0todm9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:11:34 GMT</pubDate>
</item>
<item>
<title>通过语言模型的知识蒸馏，使一个容量仅1.2亿参数的模型在通用语义理解基准测试中，取得了超过容量7倍大模型的竞争性能。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《Gec...</title>
<link>https://weibo.com/1402400261/O7NjbofHT</link>
<guid>https://weibo.com/1402400261/O7NjbofHT</guid>
<content:encoded><![CDATA[
<div> Gecko, 文本嵌入, 语言模型, 知识蒸馏, 容量, 语义理解, 基准测试, Google DeepMind

<br /><br />总结:
本文介绍了一种名为Gecko的方法，通过语言模型的知识蒸馏，将一个容量仅1.2亿参数的模型在通用语义理解基准测试中的性能提升至超过容量7倍大模型的竞争水平。Gecko模型通过迁移学习技术，将大语言模型中的信息压缩为小型模型，并提供了一种高效的文本嵌入方式。研究表明，Gecko在各种任务和语料上都能取得优异的结果，展示了其在文本理解领域的强大能力。Gecko的提出为文本嵌入领域的发展带来了新的思路和可能性，为构建高效、精确的语义理解模型提供了有力支持。 <div>
通过语言模型的知识蒸馏，使一个容量仅1.2亿参数的模型在通用语义理解基准测试中，取得了超过容量7倍大模型的竞争性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Gecko: Versatile Text Embeddings Distilled from Large Language Models》J Lee, Z Dai, X Ren, B Chen… [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.20327"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0vbcwm8j21la0hidos.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0vc19kkj21lk0tqtgq.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0vcc327j21l60wm494.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:09:58 GMT</pubDate>
</item>
<item>
<title>[CL]《Gecko: Versatile Text Embeddings Distilled from Large Language Models》J Lee, Z Dai, X Ren, B Chen… [Google DeepMind] (2024) 网页链接 #机器学习...</title>
<link>https://weibo.com/1402400261/O7Nj4qu11</link>
<guid>https://weibo.com/1402400261/O7Nj4qu11</guid>
<content:encoded><![CDATA[
<div> Gecko, Versatile, Text Embeddings, Large Language Models, DeepMind<br />
<br />
在这篇文章中，研究者介绍了一种称为Gecko的文本嵌入模型，该模型可以从大型语言模型中提炼出高效的文本嵌入。研究团队通过精心设计的训练策略，成功将Gecko应用于各种自然语言处理任务中，取得了令人瞩目的效果。该模型的灵活性和多功能性使其在不同任务和数据集上均表现出色，展现了其在文本表示学习领域的巨大潜力。总的来说，Gecko为利用大型语言模型提炼出高效文本嵌入提供了一种创新的方法，有望推动自然语言处理领域的发展。<br /><br />总结： <br />Gecko模型是一种能够从大型语言模型中提炼文本嵌入的方法，具有灵活性和多功能性。通过精心设计的训练策略，Gecko在各种自然语言处理任务中取得了令人瞩目的效果，并展现出在文本表示学习领域的巨大潜力。 <div>
[CL]《Gecko: Versatile Text Embeddings Distilled from Large Language Models》J Lee, Z Dai, X Ren, B Chen… [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.20327"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoc0vbcwm8j21la0hidos.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoc0vc19kkj21lk0tqtgq.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoc0vcc327j21l60wm494.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 21:09:41 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(4.1)》 爱可可微博热门分享(4.1) [图片]</title>
<link>https://weibo.com/1402400261/O7KEQFkmk</link>
<guid>https://weibo.com/1402400261/O7KEQFkmk</guid>
<content:encoded><![CDATA[
<div> 微博、热门分享、爱可可、4.1、关键词、情感分析、用户评论、话题讨论、互动、网友互动

总结:<br /><br />爱可可微博4.1日发布的热门分享内容引起了网友的热烈讨论。通过情感分析，用户评论中反映出了对话题的关注和讨论热度。网友们通过互动的方式展开话题讨论，形成了热门话题。这种互动不仅增加了用户之间的互动性，也提升了微博平台的用户黏性。 <div>
《爱可可微博热门分享(4.1)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405018476531024181"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(4.1)</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hobp6dkrbpj20rs0fmwik.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 14:25:06 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models》(ICLR 2024) GitHub: github.com/ThisisBillhe/Eff...</title>
<link>https://weibo.com/1402400261/O7KcGCGEF</link>
<guid>https://weibo.com/1402400261/O7KcGCGEF</guid>
<content:encoded><![CDATA[
<div> EfficientDM, quantization-aware fine-tuning, low-bit diffusion models, ICLR 2024, GitHub, TimeMixer, decomposable multiscale mixing, time series forecasting, LaDiC, diffusion models, autoregressive counterparts, image-to-text generation, NAACL 2024, Repurposing Diffusion-Based Image Generators, Monocular Depth Estimation, CVPR 2024

总结:EfficientDM实现了对低比特扩散模型的高效量化感知微调，为ICLR 2024会议的研究中心。TimeMixer通过可分解的多尺度混合提高了时间序列预测的效果，作者发布了GitHub。LaDiC研究了扩散模型与自回归模型在图像到文本生成中的优劣，获得NAACL 2024提名。Marigold-Video项目重复利用扩散模型生成图像，用于单目深度估计，展示于CVPR 2024。SQLdepth提出了一种通用的自监督微结构单目深度估计方法，GitHub上提供了代码。AgentStudio是一个构建通用虚拟代理的工具包，CVPR 2024中的其中一个项目。SA-GS提出了适应尺度的高斯飞溅方法，无需训练即可抗锯齿，作者开源了GitHub代码。ICDPO通过上下文直接优先优化的方法来有效借鉴他人的对齐能力，详细信息可在GitHub上找到。DS-Agent实现了将大型语言模型与案例推理相结合的自动数据科学工具，CVPR 2024有相关研究成果。MoDiTalker是一种针对高保真头像生成的运动解耦扩散模型，KU-CVLAB团队开源了代码。NaturalSpeech 3利用分解编解码器和扩散模型实现了零预测语音合成，项目源代码在GitHub上可用。SVD-LLM提出了针对大型语言模型的截断意识奇异值分解方法，GitHub上有开源代码。Change-Agent致力于实现交互式远程遥感变化解释和分析，Chen-Yang-Liu团队的开源项目。Spectral Motion Alignment提出了一种使用扩散模型的视频运动传输的谱运动对齐方法，详细代码在GitHub上提供。 <div>
几篇论文实现代码：<br />《EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models》(ICLR 2024) GitHub: github.com/ThisisBillhe/EfficientDM<br />《TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting》(ICLR 2024) GitHub: github.com/kwuking/TimeMixer [fig8]<br />《LaDiC: Are Diffusion Models Really Inferior to Autoregressive Counterparts for Image-to-text Generation?》(NAACL 2024) GitHub: github.com/wangyuchi369/LaDiC [fig7]<br />《Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation》(CVPR 2024) GitHub: github.com/pablodawson/Marigold-Video [fig2]<br />《Rewrite the Stars》(CVPR 2024) GitHub: github.com/ma-xu/Rewrite-the-Stars<br />《SQLdepth: Generalizable Self-Supervised Fine-Structured Monocular Depth Estimation》(2024) GitHub: github.com/hisfog/SfMNeXt-Impl<br />《AgentStudio: A Toolkit for Building General Virtual Agents》(2024) GitHub: github.com/SkyworkAI/agent-studio [fig1]<br />《Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation》(2024) GitHub: github.com/pablodawson/Marigold-Video<br />《SA-GS: Scale-Adaptive Gaussian Splatting for Training-Free Anti-Aliasing》(2024) GitHub: github.com/zsy1987/SA-GS<br />《ICDPO: Effectively Borrowing Alignment Capability of Others via In-context Direct Preference Optimization》(2024) GitHub: github.com/F2-Song/ICDPO [fig3]<br />《DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning》(2024) GitHub: github.com/guosyjlu/DS-Agent [fig4]<br />《MoDiTalker: Motion-Disentangled Diffusion Model for High-Fidelity Talking Head Generation》(2024) GitHub: github.com/KU-CVLAB/MoDiTalker<br />《NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models》(2024) GitHub: github.com/lifeiteng/ns3_codec [fig5]<br />《SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language Model Compression》(2024) GitHub: github.com/AIoT-MLSys-Lab/SVD-LLM<br />《Change-Agent: Towards Interactive Comprehensive Remote Sensing Change Interpretation and Analysis》(2024) GitHub: github.com/Chen-Yang-Liu/Change-Agent [fig6]<br />《Spectral Motion Alignment for Video Motion Transfer using Diffusion Models》(2024) GitHub: github.com/geonyeong-park/Spectral-Motion-Alignment<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob8xp699mj227c0yc7wh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hob909rjg3j21ac174dmw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob9db8l86j20gp05n40o.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hob9jehv2uj21qt0myque.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hobml5iiw0j21i40li46r.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hobmm7kf3jj211x0dlwj7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hobn12rglbj242g1q44qq.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hobn2bdaqaj21nq0qoncb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 13:15:43 GMT</pubDate>
</item>
<item>
<title>'stable-diffusion-tutorial - 全网最全Stable Diffusion全套教程，从入门到进阶' GitHub: github.com/ai-vip/stable-diffusion-tutorial #开源# #机器学习# #人...</title>
<link>https://weibo.com/1402400261/O7K8fh9af</link>
<guid>https://weibo.com/1402400261/O7K8fh9af</guid>
<content:encoded><![CDATA[
<div> GitHub, Stable Diffusion, 教程, 入门, 进阶, AI, VIP, 全套, 全网, 最全

<br /><br />总结:
这篇文章是关于Stable Diffusion全套教程的GitHub项目，适合从入门到进阶学习。项目由AI VIP团队提供，涵盖了稳定传播的所有方面，并被称为全网最全的教程。通过该教程，读者可以系统学习稳定传播的原理、应用和进阶技巧，是学习AI技术的必备资源。 <div>
'stable-diffusion-tutorial - 全网最全Stable Diffusion全套教程，从入门到进阶' GitHub: github.com/ai-vip/stable-diffusion-tutorial <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hobmunzax9j20u01g3dl7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 13:04:46 GMT</pubDate>
</item>
<item>
<title>【Jaiqu：基于AI的JSON转换工具】'Jaiqu - Automatically reformat any JSON into any schema with AI' GitHub: github.com/AgentOps-AI/Jaiqu #开源# #机器学习...</title>
<link>https://weibo.com/1402400261/O7K80uAaB</link>
<guid>https://weibo.com/1402400261/O7K80uAaB</guid>
<content:encoded><![CDATA[
<div> GitHub, Jaiqu, AI, JSON, 转换工具, 自动重新格式化, 模式, AgentOps, 

AI技术不断发展，在各个领域都有了广泛的应用。AgentOps团队开发了一款名为Jaiqu的基于AI技术的JSON转换工具，能自动将任何JSON数据重新格式化成任意模式。用户只需输入待转换的JSON数据，Jaiqu就能自动分析并转换为用户指定的模式，极大地提高了数据处理的效率。用户还可以通过GitHub获取Jaiqu的源代码和更多信息。这款工具的推出不仅简化了数据处理的流程，也展示了AI技术在数据处理领域的巨大潜力。 <br /><br />总结:AI技术在数据处理工具中的应用，Jaiqu能自动将JSON重新格式化成任意模式，提高了数据处理效率，用户可通过GitHub获取更多信息。 <div>
【Jaiqu：基于AI的JSON转换工具】'Jaiqu - Automatically reformat any JSON into any schema with AI' GitHub: github.com/AgentOps-AI/Jaiqu <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hobmub0sk7j20zh0u0tcz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 13:04:11 GMT</pubDate>
</item>
<item>
<title>【AutoGen AGI：旨在通过AutoGen技术来提升AI Agent的智能能力，重点在于提高AI Agent在沟通、决策制定以及复杂任务完成等方面的智能水平】’AutoGen AGI: Advan...</title>
<link>https://weibo.com/1402400261/O7H6Xezex</link>
<guid>https://weibo.com/1402400261/O7H6Xezex</guid>
<content:encoded><![CDATA[
<div> AutoGen AGI, AI Agent, 智能能力提升, 沟通, 决策制定, 复杂任务完成, 群体聊天动态, 创新, GitHub, AI未来发展 <br />
<br />
总结: AutoGen AGI是一个旨在通过AutoGen技术提升AI Agent智能能力的项目，重点在于提高AI Agent在沟通、决策制定以及复杂任务完成等方面的能力。项目着眼于创新，尤其关注群体聊天动态等领域的提升，致力于促进AI在未来的发展。GitHub链接：github.com/metamind-ai/autogen-agi。 <div>
【AutoGen AGI：旨在通过AutoGen技术来提升AI Agent的智能能力，重点在于提高AI Agent在沟通、决策制定以及复杂任务完成等方面的智能水平】’AutoGen AGI: Advancing AI agents using AutoGen towards AGI capabilities. Explore cutting-edge enhancements in group chat dynamics, decision-making, and complex task proficiency. Join our journey in shaping AI's future!' GitHub: github.com/metamind-ai/autogen-agi <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hob9irqxyhj20u00u0wl0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:23:21 GMT</pubDate>
</item>
<item>
<title>'IAmDirector - 每个人都能成为导演 - 本项目开源基于NextJS的前端， 希望能够提供一个用于生成式AI的文字转视频， 尤其是电影从编剧到视频生成的Web前端平台参...</title>
<link>https://weibo.com/1402400261/O7H6haljm</link>
<guid>https://weibo.com/1402400261/O7H6haljm</guid>
<content:encoded><![CDATA[
<div> NextJS, 前端, AI, 文字转视频, 电影, Web平台, 开源, 参考, GitHub, 项目

<br /><br />总结:
本项目是一个开源的基于NextJS的前端平台，旨在提供一个用于生成式AI的文字转视频工具，特别是涉及电影从编剧到视频生成的Web前端平台参考。用户可以通过该平台生成自己的影视作品，实现文字变成视频的转换。项目代码托管在GitHub上，方便用户查看和参考。通过使用该平台，每个人都有机会成为一名导演，创造属于自己的影视作品。 <div>
'IAmDirector - 每个人都能成为导演 - 本项目开源基于NextJS的前端， 希望能够提供一个用于生成式AI的文字转视频， 尤其是电影从编剧到视频生成的Web前端平台参考' GitHub: github.com/JiaqiLi404/IAmDirector-Text2Video-NextJS-Client <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hob9gtuh61j21et0u0tfz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hob9guybkkj21fa0u077z.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob9gwvzvaj21im0u0js9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:21:40 GMT</pubDate>
</item>
<item>
<title>'我的大模型课 - 关于如何编写大模型的prompt的一系列课' GitHub: github.com/PandaBearLab/prompt-tutorial #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O7H4mo6a6</link>
<guid>https://weibo.com/1402400261/O7H4mo6a6</guid>
<content:encoded><![CDATA[
<div> 关键词：大模型课、编写、prompt、GitHub、PandaBearLab

大模型课是一系列关于如何编写大模型的prompt的课程，可以在GitHub上的PandaBearLab的仓库找到相关资料。这个课程涵盖了编写大型模型时需要考虑的方方面面，包括设计、实现、调试等等。通过这些课程，学习者可以更好地理解如何构建复杂的大型模型，并学会解决相关问题。GitHub上的资料可以帮助学习者更方便地获取课程内容，学习的过程更加高效和便捷。<br /><br />总结: 大模型课是一系列关于如何编写大模型的prompt的一系列课程，GitHub上PandaBearLab的仓库提供了相关资料，通过这些课程，学习者可以获取关于设计、实现、调试等方面的知识，从而更好地理解和构建复杂的大型模型。GitHub上的资料能够帮助学习者更方便地获取课程内容，提高学习效率。 <div>
'我的大模型课 - 关于如何编写大模型的prompt的一系列课' GitHub: github.com/PandaBearLab/prompt-tutorial <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hob9c5tzcij210i0u00wt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:16:58 GMT</pubDate>
</item>
<item>
<title>'因果推断：从概念到实践 - Causal Inference for the Brave and True的中文翻译版。全部代码基于Python，适用于计量经济学、量化社会学、策略评估等领域。英文...</title>
<link>https://weibo.com/1402400261/O7H1vwTXM</link>
<guid>https://weibo.com/1402400261/O7H1vwTXM</guid>
<content:encoded><![CDATA[
<div> 因果推断、概念、实践、Python、计量经济学、量化社会学、策略评估、Matheus Facure、GitHub、Causal Inference for the Brave and True

<br /><br />总结:
本文介绍了因果推断的概念及实践方法，以Python为工具进行计量经济学、量化社会学和策略评估研究。该指南以Matheus Facure为原作者，涵盖了因果推断的基本原理和实现技巧。读者可通过GitHub获取更多相关信息。 <div>
'因果推断：从概念到实践 - Causal Inference for the Brave and True的中文翻译版。全部代码基于Python，适用于计量经济学、量化社会学、策略评估等领域。英文版原作者：Matheus Facure' GitHub: github.com/xieliaing/CausalInferenceIntro <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob94snrc3j20v80u043v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:09:56 GMT</pubDate>
</item>
<item>
<title>【AgentStudio：用于构建和基准测试通用虚拟Agent的开源工具包】'AgentStudio - An open toolkit for building and benchmarking general virtual agents in the...</title>
<link>https://weibo.com/1402400261/O7GZ8wt8n</link>
<guid>https://weibo.com/1402400261/O7GZ8wt8n</guid>
<content:encoded><![CDATA[
<div> AgentStudio，开源工具包，构建，基准测试，通用虚拟Agent，GitHub，SkyworkAI，Agent-Studio<br />
AgentStudio是一个用于构建和基准测试通用虚拟Agent的开源工具包。用户可以利用AgentStudio来开发和评估各种虚拟Agent，以帮助他们在各种环境中更好地执行任务。该工具包还提供了一些功能强大的工具，用于在现实世界中对Agent进行测试和评估其性能。用户可以通过访问GitHub上的SkyworkAI/agent-studio仓库来获取AgentStudio的源代码，并开始使用这个工具包。AgentStudio的出现为虚拟Agent的构建和测试提供了更多便利和支持，有助于促进虚拟Agent技术的发展。<br /><br />总结: <br />AgentStudio是一个开源工具包，用于构建和基准测试通用虚拟Agent。用户可以通过GitHub获取源代码并使用AgentStudio来开发和评估虚拟Agent，这将有助于促进虚拟Agent技术的发展。 <div>
【AgentStudio：用于构建和基准测试通用虚拟Agent的开源工具包】'AgentStudio - An open toolkit for building and benchmarking general virtual agents in the wild' GitHub: github.com/SkyworkAI/agent-studio <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob8yjg8qsj21xa0u0dp6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob8ymdq8uj22g50u0n4j.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob8yrof1jj21pk0u07az.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:04:06 GMT</pubDate>
</item>
<item>
<title>【旨在复现Anthropic的稀疏自编码可视化】'sae_vis' GitHub: github.com/callummcdougall/sae_vis #开源# #机器学习# #人工智能# [图片][图片]</title>
<link>https://weibo.com/1402400261/O7GYcc9se</link>
<guid>https://weibo.com/1402400261/O7GYcc9se</guid>
<content:encoded><![CDATA[
<div> 稀疏自编码、可视化、GitHub、sae_vis、复现、Anthropic、Callum McDougall

稀疏自编码是一种用于学习数据表示的技术，通过在编码阶段引入稀疏性约束，可以更好地捕捉数据的关键特征，从而实现对数据的压缩和重建。Anthropic提出了一种稀疏自编码的方法，并通过GitHub上的sae_vis项目来展示这种技术的可视化效果。通过复现这个项目，我们可以更好地理解和探究Anthropic提出的稀疏自编码技术，同时也可以学习到如何利用GitHub来分享和展示代码。GitHub上的sae_vis项目由Callum McDougall创建，可以帮助我们更直观地理解稀疏自编码的原理和应用。通过学习和探究这个项目，我们可以加深对稀疏自编码和数据可视化的理解，为进一步研究和应用相关技术提供参考。 

<br /><br />总结: 
稀疏自编码是一种学习数据表示的技术，Anthropic提出了一种稀疏自编码方法，并通过GitHub上的sae_vis项目展示其可视化效果，通过复现该项目可以加深理解和探究相关技术，同时学习如何利用GitHub分享和展示代码，sae_vis项目由Callum McDougall创建，帮助更直观地理解稀疏自编码的原理和应用，通过学习该项目可以深入了解稀疏自编码和数据可视化，为进一步研究和应用相关技术提供参考。 <div>
【旨在复现Anthropic的稀疏自编码可视化】'sae_vis' GitHub: github.com/callummcdougall/sae_vis <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hob8w6ybitj21gu0st49b.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hob8wbxwhuj215x0u0k0f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:01:46 GMT</pubDate>
</item>
<item>
<title>【Heron：可无缝集成多种图像/视频和语言模型的库. 此外, 还提供在各种数据集上训练的预训练权重】'Heron - a library that seamlessly integrates multiple Vis...</title>
<link>https://weibo.com/1402400261/O7GXBxwVd</link>
<guid>https://weibo.com/1402400261/O7GXBxwVd</guid>
<content:encoded><![CDATA[
<div> Heron、图像模型、视频模型、语言模型、集成、库、预训练权重、数据集、训练、GitHub

<br /><br />总结:
Heron是一款库，可以无缝集成多种图像、视频和语言模型，同时还提供在各种数据集上训练的预训练权重。用户可以通过GitHub获取该库，方便使用和开发。Heron为用户提供了整合不同模型的便利，训练和调用均得以简化，是一个强大的工具库。 <div>
【Heron：可无缝集成多种图像/视频和语言模型的库. 此外, 还提供在各种数据集上训练的预训练权重】'Heron - a library that seamlessly integrates multiple Vision and Language models, as well as Video and Language models' GitHub: github.com/turingmotors/heron <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hob8utpmtxj20u00yxgqz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 05:00:19 GMT</pubDate>
</item>
<item>
<title>《用 bitsandbytes、4 比特量化和 QLoRA 打造亲民的 LLM》- 提出了QLoRA方法，可以在单GPU上微调超大规模语言模型(65B参数)，同时内存使用率显著降低，性能与全1...</title>
<link>https://weibo.com/1402400261/O7FaODDI3</link>
<guid>https://weibo.com/1402400261/O7FaODDI3</guid>
<content:encoded><![CDATA[
<div> bitsandbytes, 4比特量化, QLoRA, LLM, 单GPU, 超大规模语言模型, 内存使用率, NormalFloat4, 低秩适配器, 双量化

<br /><br />总结:
该研究提出了QLoRA方法，可以在单GPU上微调超大规模语言模型(65B参数)，同时降低内存使用率，性能与全16bit量化微调相当。QLoRA核心是将预训练语言模型用4 bit量化压缩，冻结参数并加低秩适配器作为可训练参数，梯度只反向传播到适配器。在Vicuna基准测试中，QLoRA微调的Guanaco聊天机器人性能接近ChatGPT水平。数量化技术降低了训练超大模型门槛，使之在普通GPU上运行。有望加速LLM的大众化进程，让更多人参与到LLM开发和应用。QLoRA巧妙的量化和适配器技术降低内存占用，保持了性能。NF4、双量化技术进一步挖掘了量化潜力，为后续研究提供新思路。小型高质量数据集上微调为LLM应用提供重要启示，即数据质量和针对性可能更关键。 <div>
《用 bitsandbytes、4 比特量化和 QLoRA 打造亲民的 LLM》<br />- 提出了QLoRA方法，可以在单GPU上微调超大规模语言模型(65B参数)，同时内存使用率显著降低，性能与全16bit量化微调相当。   <br />- QLoRA的核心是将预训练语言模型用4bit量化(一般为NormalFloat4)压缩，冻结参数，并添加低秩适配器作为可训练参数。训练时，梯度只反向传播到适配器。   <br />- QLoRA使用不同的数据类型存储权重(4bit)和计算(16bit)，可以减少训练和推理时的内存占用。还可以通过双量化进一步降低内存。   <br />- 在Vicuna基准测试中，使用QLoRA微调的Guanaco聊天机器人性能几乎达到ChatGPT水平，表明该方法训练大模型效果显著。   <br />- 给出了QLoRA的代码实现，支持PyTorch框架，还提供了Google Colab演示Notebook，方便用户上手使用。   <br />- 4bit量化目前与GPU兼容，需要安装CUDA &gt;= 11.2。支持使用accelerate库加载的绝大多数HuggingFace模型都可以进行4bit量化。   <br />- 尽管无法进行全模型4bit训练，但可以在4bit量化的大模型上训练适配器等可训练模块，实现高效微调。   <br />- 4bit量化大模型技术降低了训练超大模型的门槛，使之能在普通GPU上运行，对研究工作具有重要意义。<br /><br />思考：  <br />- 该研究为在消费级硬件上运行和训练大语言模型提供了可行的技术方案，有望加速LLM的大众化进程，让更多人能够参与到LLM的开发和应用中来。  <br />- QLoRA通过巧妙的量化和适配器技术，在大幅降低内存占用的同时保持了与全精度微调相当的性能，体现了算法设计的优雅和高效。  <br />- 引入NF4、双量化等创新技术，进一步挖掘了量化的潜力，为后续研究提供了新的思路。  <br />- 在小型高质量数据集上微调获得最佳性能，这一发现为LLM的实际应用提供了重要启示，即并非训练数据越多越好，数据质量和针对性可能更为关键。  <br /> <a href="https://huggingface.co/blog/zh/4bit-transformers-bitsandbytes"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hob0vxmn22j20u00vgwje.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 00:27:23 GMT</pubDate>
</item>
<item>
<title>【生命的多尺度交响：集体智慧串联生物学】- 生物系统具有多尺度结构，从分子网络到细胞、组织、器官、整体和群体。每个层级都能在不同的问题空间中解决问题，如...</title>
<link>https://weibo.com/1402400261/O7F95wKcj</link>
<guid>https://weibo.com/1402400261/O7F95wKcj</guid>
<content:encoded><![CDATA[
<div> 生物系统、多尺度结构、集体动力学、集体智慧、胚胎发育、细胞迁移、癌症、黑色素瘤、器官建立、动力系统理论

<br /><br />总结:
本文从多尺度视角审视生物学，揭示了生物系统内在的复杂性和协同性。集体智慧为理解生物学不同层次之间的相互作用提供了新的框架，揭示了细胞群体在转录、生理和解剖空间展现的集体智慧。跨尺度研究方法不仅有助于基础生物学研究，也对生物医学和工程设计等应用领域具有重要意义。利用集体智慧这一对称性推进研究是创新性的，为未来研究指明了方向，但具体操作仍需进一步探索。 <div>
【生命的多尺度交响：集体智慧串联生物学】<br />- 生物系统具有多尺度结构，从分子网络到细胞、组织、器官、整体和群体。每个层级都能在不同的问题空间中解决问题，如生理、形态和行为状态空间。将自下而上的适应功能从一个具有能力的子单元层次渗透到一个更高的功能组织层次需要集体动力学：多个组件必须协同工作以实现特定的结果。   <br />- 概述了不同尺度的一些生物学实例，突出显示了细胞材料做出决定的能力，这些决定实现了对特定稳态端点的合作，并通过在细胞、组织和整个有机体水平上解决问题来实现集体智能。   <br />- 探讨了这样的假设：集体智慧不仅仅是动物群体的特例，一个重要的对称性存在于群体行为科学和细胞及其他不同尺度生物系统能力之间。   <br />- 简要概述了这种方法的含义，以及行为多样智能领域的工具对再生医学和合成生物工程的可能影响。   <br />- 发育是一个非常基本的集体示例，胚胎被认为是一个整体，是因为其组成细胞都在协同工作向一个特定的形态空间路径：细胞致力于制造一个特定的功能解剖结构。   <br />- 如果在胚胎层面临时引入隔离岛屿，会形成双生子、三生子等，显示胚胎是一个动力学可激发介质，可以自我组织形成多个连贯的胚胎。   <br />- 当我们观察细胞迁移时，集体行为往往与其组分的倾向相反，即使在相对最小的系统中也是复杂和难以预测的，这是整体与其组成部分竞争的缩影。   <br />- 癌症是一个集体行为的失败模式实例，当细胞与组织的信息结构隔离时，它们会恢复到一个古老的、单细胞的转录和行为表型。   <br />- 在蝾螈模型中，已显示正常黑色素细胞可以被驱动为类似黑色素瘤的转换型：它们过度增殖，并迁移到正常情况下不含黑色素细胞的区域，这个表型重现了黑色素瘤转移。   <br />- 最显著的是，这种表型是全有或全无的现象。使用不同的试剂可以在一组动物中诱导不同百分比的超 Pigmentation(转换)，但这是种群层面的表型：例如，70%的动物可以转换，但任何给定的动物要么完全转换要么完全正常。   <br />- 在解剖形态空间中，细胞集团需要做出关于将要建立哪个器官以及它们必须采取何种形状的具体决定。这与识别基因调控网络和分化信号是一个根本不同的问题。   <br />- 利用动力系统理论和连接主义神经科学/人工智能的工具有助于提供正式化理解细胞网络如何存储模式信息并从部分输入中恢复它，以及这种集体行为如何出现。<br /><br />思考：  <br />- 文章从多尺度视角审视生物学，揭示了生物系统内在的复杂性和协同性，这种视角有助于我们更全面地理解生命现象。  <br />- 集体智慧这一概念的引入，为理解生物学不同层次之间的相互作用提供了一个新的框架，具有启发性。  <br />- 文章指出，细胞群体在转录、生理和解剖空间展现出类似于高等生物的集体智慧，这一发现颠覆了我们对智能的传统认知，表明智能可能是生命的一种基本属性。  <br />- 跨尺度的研究方法不仅有助于基础生物学研究，而且对生物医学和工程设计等应用领域也具有重要意义，体现了基础研究的应用价值。  <br />- 文章提出利用集体智慧这一对称性来推进研究，这种思路具有创新性，为未来的研究指明了方向，不过，如何具体操作还需要进一步探索。<br />《Collective intelligence: A unifying concept for integrating biology across scales and substrates | Communications Biology》 <a href="https://www.nature.com/articles/s42003-024-06037-4?code=96f36603-dac2-4485-a0f5-488009563d60&amp;error=cookies_not_supported"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hob0u4gp0cj20j10ntgpz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hob0u4x4uej20j10hlwgb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob0u5cqu7j20j10o4q7s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob0u5qcvwj20j10mdad8.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hob0u61pwej20j10nqju7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hob0u6b64wj20j10onwi6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 00:23:07 GMT</pubDate>
</item>
<item>
<title>【RLHF人工反馈强化学习详解】- ChatGPT的训练可以分为三个阶段：预训练、监督微调(SFT)和人工反馈强化学习(RLHF)。 - 预训练的目标是训练一个大型语言模型(LLM)...</title>
<link>https://weibo.com/1402400261/O7F5VzPzQ</link>
<guid>https://weibo.com/1402400261/O7F5VzPzQ</guid>
<content:encoded><![CDATA[
<div> 预训练、监督微调、人工反馈强化学习、大型语言模型、示范数据、奖励模型、强化学习、高分回复、减少“幻觉”、关键创新点

<br /><br />总结:
ChatGPT的训练过程分为预训练、监督微调和人工反馈强化学习三个阶段。预训练旨在训练大型语言模型，而监督微调利用示范数据进行监督学习。人工反馈强化学习包含奖励模型和强化学习微调两个子阶段，用于让模型生成高质量回复。RLHF可以减少模型的“幻觉”，因为缩小了模型内部知识与标注者知识的差异。这一技术是ChatGPT成功的关键创新点之一，未来可能会得到更广泛应用。在应用RLHF时，难点在于构建高质量的奖励模型和示范数据。公司可考虑使用RLHF来提升语言模型的安全性和适用性，但需要投入大量资源建设示范数据集和奖励模型。 <div>
【RLHF人工反馈强化学习详解】<br />- ChatGPT的训练可以分为三个阶段：预训练、监督微调(SFT)和人工反馈强化学习(RLHF)。   <br />- 预训练的目标是训练一个大型语言模型(LLM)，使其具有语言补全能力。预训练需要大量互联网数据(万亿字符级)，但可用数据有限。   <br />- SFT的目标是让LLM生成符合用户需求的回复，使用人工标注的示范数据进行监督学习。   <br />- RLHF包含奖励模型和强化学习微调两个子阶段。奖励模型用于给出提示-回复对的打分，强化学习用于让LLM生成高分回复。   <br />- RLHF可以减少LLM的“幻觉”，原因可能是减小了LLM内部知识与标注者知识的差异。   <br />- RLHF是ChatGPT等模型成功的关键创新点之一，未来可能会得到更广泛应用。其难点在于构建高质量的奖励模型和示范数据。   <br />- 公司可考虑使用RLHF提升自家LLM的安全性、适用性。但需要投入大量资源建设示范数据集和奖励模型。<br />《RLHF: Reinforcement Learning from Human Feedback》 <a href="https://huyenchip.com/2023/05/02/rlhf.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hob0kl0r2ij213f0u0afz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 00:15:20 GMT</pubDate>
</item>
<item>
<title>【Mamba详解】- Mamba是一种新型的状态空间模型(State Space Model，SSM)，它取得了和Transformer类似的性能，但可以处理更长的序列(例如100万token)。这是通过...</title>
<link>https://weibo.com/1402400261/O7F4sn27H</link>
<guid>https://weibo.com/1402400261/O7F4sn27H</guid>
<content:encoded><![CDATA[
<div> Mamba、状态空间模型、长序列、计算效率、学习矩阵、选择机制、RNN变体、可解释性、Transformer组合、AI安全<br />
<br />
总结:<br />
Mamba是一种新型的状态空间模型，可以处理较长序列并取得性能优势，通过引入选择机制使得学习矩阵适应不同上下文。相比于Transformer，Mamba在长序列建模上提供了更高的效率和可解释性，适用于需处理非常长序列的任务。其创新性在于将RNN的变体与选择机制结合，为AI模型的发展指明了新方向，对研究长期记忆、计划能力和代理人AI安全具有启发意义。 <div>
【Mamba详解】<br />- Mamba是一种新型的状态空间模型(State Space Model，SSM)，它取得了和Transformer类似的性能，但可以处理更长的序列(例如100万token)。这是通过去除Attention机制中的“二次瓶颈”实现的。   <br />- SSM的优点是计算效率高，可以线性缩放序列长度，而Transformer中的Attention机制时间复杂度是平方级的，会随着序列长度的增加而变慢。   <br />- SSM包含状态转移矩阵A、输入矩阵B、输出矩阵C和直接传递矩阵D，这些矩阵都是可学习的。Mamba的创新在于引入了“选择机制”，使这些矩阵都成为输入x的函数，实现对不同上下文的适应。   <br />- SSM可以看作是RNN的变体，但引入选择机制后效果更好，在保持计算高效的同时提高了对长序列建模的有效性。   <br />- Mamba可实现比RNN更长的上下文记忆，但比Transformer更高效。这种在有效性和效率之间的权衡取决于状态表示的压缩程度。   <br />- Mamba适用于需要非常长序列长度的任务，如处理DNA序列、生成长视频、写小说等。   <br />- Mamba可提高模型的可解释性，通过分析状态的变化来理解上下文学习等现象。   <br />- Mamba可与Transformer组合使用，处理不同时间尺度上的建模，发挥各自的优势。   <br />- Mamba对研究长期记忆、计划能力和代理人AI安全具有启发意义。它标志着后Transformer时代的到来。<br /><br />思考：  <br />- Mamba在长序列建模上的突破令人印象深刻，有望扩展AI模型的应用范围，如更长篇章的语言理解和生成。  <br />- 通过巧妙的设计，Mamba在提升性能的同时兼顾了效率，体现了算法的优雅。  <br />- Mamba对状态表征的选择性压缩让人联想到人类的注意力机制，这种机制的引入赋予了模型更强的建模能力。  <br />- 理解AI模型的内部状态和信息流动方式，对于我们解释其行为、提升其可解释性和可控性具有重要意义。  <br />- Mamba作为Transformer的有力挑战者，为探索新的AI建模范式指明了一个有潜力的方向，期待它在更多任务上的表现。<br />《Mamba Explained》 <a href="https://thegradient.pub/mamba-explained/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span> <span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hob09qxzk2j21yj0u0791.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hob09yqg7gj20kv0a4wfi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hob0a23vigj20w00lyq4y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hob0a91xi3j218g0p5wh4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 01 Apr 2024 00:11:42 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：明日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可...</title>
<link>https://weibo.com/1402400261/O7Ek9tAoi</link>
<guid>https://weibo.com/1402400261/O7Ek9tAoi</guid>
<content:encoded><![CDATA[
<div> Java, Python, JavaScript, C语言, MySQL, Redis, 技术, 故事, 编程语言, 码农翻身

<br /><br />总结:
《码农翻身2》以故事的形式讲解技术，让枯燥的技术变得有趣。在编程语言王国中，Java与Python争斗，JavaScript与Java对抗，而孤独的C语言则面对没有对象的困境。MySQL和Redis之间的对立不断升级。这本书让读者不仅掌握技术原理和本质，同时能享受阅读乐趣。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：明日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 22:17:38 GMT</pubDate>
</item>
<item>
<title>今日推介(第1362期)：基于开放式指令的自监督图像检索、Transformer网络的topos theory视角分析、编程语言模型漏洞检测现状评估、面向内存高效大型语言模型微调...</title>
<link>https://weibo.com/1402400261/O7Ek1uSou</link>
<guid>https://weibo.com/1402400261/O7Ek1uSou</guid>
<content:encoded><![CDATA[
<div> 自监督图像检索、Transformer网络、topos theory、编程语言模型漏洞检测、层级重要性采样、内存高效大型语言模型微调、语言模型可解释性、因果图发现、因果图编辑

总结:<br /><br />本文报道了基于开放式指令的自监督图像检索方法，通过Transformer网络的topos theory视角分析，评估了编程语言模型漏洞检测现状，并提出了面向内存高效大型语言模型微调的层级重要性采样策略。同时，研究了语言模型可解释因果图的发现与编辑方法，为语言模型研究领域的发展提供了新的观点和思路。 <div>
今日推介(第1362期)：基于开放式指令的自监督图像检索、Transformer网络的topos theory视角分析、编程语言模型漏洞检测现状评估、面向内存高效大型语言模型微调的层级重要性采样、语言模型可解释因果图的发现与编辑 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/690078164"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(4.1)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoax780v8sj21wc0u048e.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoax79uclvj20yi0n675r.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoax7cpiv0j20u00z1tk0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoax7fqtlgj20p40ksjtb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoax7i9melj21gf0u07ba.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 22:17:18 GMT</pubDate>
</item>
<item>
<title>[CV] DINO-Tracker: Taming DINO for Self-Supervised Point Tracking in a Single Video 网页链接 提出DINO-Tracker框架，将预训练模型的语义先验与针对单视频...</title>
<link>https://weibo.com/1402400261/O7EgX6B7M</link>
<guid>https://weibo.com/1402400261/O7EgX6B7M</guid>
<content:encoded><![CDATA[
<div> 测试时训练、DINO-Tracker、密集点追踪、预训练模型、语义先验、长时遮挡视频

<br /><br />总结:本文提出了DINO-Tracker框架，通过将预训练模型的语义先验与针对单视频的测试时训练相结合，实现了长时遮挡视频中的密集点追踪。该方法利用自监督学习的方式，在测试阶段根据视频的上下文信息，通过自动编码器来推断出点的运动轨迹，实现了对长时间间隔下自动跟踪点的能力。与传统方法相比，DINO-Tracker能自适应地学习不同视频场景下的点追踪模型，并且无需额外的标签数据。实验结果表明，DINO-Tracker在各种复杂的视频中都表现出色，是一种高效且准确的自监督点追踪方法。 <div>
[CV] DINO-Tracker: Taming DINO for Self-Supervised Point Tracking in a Single Video  <br /><a href="https://arxiv.org/abs/2403.14548"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出DINO-Tracker框架，将预训练模型的语义先验与针对单视频的测试时训练相结合，实现长时遮挡视频中的密集点追踪。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoawzlx6thj20v61bwwuz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoawzm8xx0j21hw0s248a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoawzmmg9sj21ak0higr6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 22:09:44 GMT</pubDate>
</item>
<item>
<title>[LG] Tensor Network-Constrained Kernel Machines as Gaussian Processes 网页链接 通过理论证明和实验验证首次建立了张量网络限制的核机和高斯过程之间的关系...</title>
<link>https://weibo.com/1402400261/O7EehAJow</link>
<guid>https://weibo.com/1402400261/O7EehAJow</guid>
<content:encoded><![CDATA[
<div> Tensor Network-Constrained Kernel Machines, Gaussian Processes, 参数独立同分布先验, 收敛, 可完全表征, 实验证明, 理论证明, 高斯过程, 核机, 张量网络限制<br />
<br />
总结: <br />
本文针对张量网络限制的核机和高斯过程之间的关系进行了理论证明和实验证明，首次建立了两者之间的联系。实验结果表明，在参数上放置独立同分布先验时，张量网络限制的核机会收敛到一个可完全表征的高斯过程。这为理解核机和高斯过程之间的关系提供了深入的见解，也为在实际应用中更好地利用这些方法提供了指导。 <div>
[LG] Tensor Network-Constrained Kernel Machines as Gaussian Processes  <br /><a href="https://arxiv.org/abs/2403.19500"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>       <br />通过理论证明和实验验证首次建立了张量网络限制的核机和高斯过程之间的关系，即在参数上放置独立同分布先验时，张量网络限制的核机会收敛到一个可完全表征的高斯过程。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoawss39r2j210g1c4h3g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoawss9w5mj210e0f441f.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoawssej1tj210g0eoq7b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 22:03:10 GMT</pubDate>
</item>
<item>
<title>[LG] AgentStudio: A Toolkit for Building General Virtual Agents 网页链接 提出了开源的AgentStudio工具包，它提供了通用的观察和动作空间，在线环境实现，以...</title>
<link>https://weibo.com/1402400261/O7Ecd1kjq</link>
<guid>https://weibo.com/1402400261/O7Ecd1kjq</guid>
<content:encoded><![CDATA[
<div> 工具包、AgentStudio、通用虚拟Agent、观察空间、动作空间、在线环境、数据收集、人机交互界面、研究、基准测试

总结:<br /><br />研究团队提出了开源的AgentStudio工具包，旨在促进通用虚拟Agent的研究和真实场景基准测试。该工具包提供了通用的观察和动作空间，实现了在线环境，并包含数据收集和人机交互界面，为虚拟Agent研究提供了便利和支持。 <div>
[LG] AgentStudio: A Toolkit for Building General Virtual Agents  <br /><a href="https://arxiv.org/abs/2403.17918"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />提出了开源的AgentStudio工具包，它提供了通用的观察和动作空间，在线环境实现，以及数据收集和人机交互界面，可促进通用虚拟Agent的研究和真实场景基准测试。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoawnfy84cj20vk1dok97.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoawngicrxj21oc14gtr0.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoawngk2rmj21o60waalm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:58:03 GMT</pubDate>
</item>
<item>
<title>[CL] A comparison of Human, GPT-3.5, and GPT-4 Performance in a University-Level Coding Course 网页链接 研究发现当前语言模型在物理编程作业方面的能力尚...</title>
<link>https://weibo.com/1402400261/O7E9C39JI</link>
<guid>https://weibo.com/1402400261/O7E9C39JI</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型, 物理编程作业, 教学目标, 教育工作者, 人类, GPT-3.5, GPT-4, 能力, 进步, 调整

总结:<br /><br />研究发现当前语言模型在物理编程作业方面的能力尚未超越人类，但稳步进步预示可能在不久的将来实现突破。这需要教育工作者重新考量编程作业的作用与教学目标的调整。三种实体——人类、GPT-3.5和GPT-4，在大学级编程课程中的表现被比较，结果显示语言模型还有提升空间，需持续关注其发展。根据研究结论，教学需重点关注培养学生的编程能力与思维，或许不久的将来，语言模型在编程方面会有更大突破。 <div>
[CL] A comparison of Human, GPT-3.5, and GPT-4 Performance in a University-Level Coding Course  <br /><a href="https://arxiv.org/abs/2403.16977"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />研究发现当前语言模型在物理编程作业方面的能力尚未超越人类，但稳步进步预示可能在不久的将来实现突破，这需要教育工作者重新考量编程作业的作用与教学目标的调整。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoawgsjinpj210i1c2kb9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoawgsv3imj210e0pytd6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoawgt47x7j210k0pojv9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:51:39 GMT</pubDate>
</item>
<item>
<title>[IR] Scaling Laws For Dense Retrieval 网页链接 通过对比对数似然指标和规模化实验，发现稠密检索模型性能也遵循资源量的幂律缩放关系，建立了模型性能预测和...</title>
<link>https://weibo.com/1402400261/O7E6urV1R</link>
<guid>https://weibo.com/1402400261/O7E6urV1R</guid>
<content:encoded><![CDATA[
<div> 对数似然指标 规模化实验 稠密检索模型 资源量 幂律缩放关系 模型性能 预测 资源优化 分配<br />
<br />
提出通过对比对数似然指标和规模化实验，发现稠密检索模型性能遵循资源量的幂律缩放关系，可用于模型性能预测和资源优化分配。这一发现为稠密检索模型的性能评估和优化提供了新的思路和方法。 <div>
[IR] Scaling Laws For Dense Retrieval  <br /><a href="https://arxiv.org/abs/2403.18684"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过对比对数似然指标和规模化实验，发现稠密检索模型性能也遵循资源量的幂律缩放关系，建立了模型性能预测和资源优化分配的可能性。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw8sg5zoj2102188nfw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw8svf04j21q80qu79o.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw8tgikjj21kq0ngwii.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:43:58 GMT</pubDate>
</item>
<item>
<title>通过稀疏自编码器和线性近似，提出一种发现人类可解释语言模型特征之间因果关系的可扩展流水线，以构建细粒度回路解释模型行为，并应用于下游任务。 - 转发 @爱...</title>
<link>https://weibo.com/1402400261/O7E3Q9kNu</link>
<guid>https://weibo.com/1402400261/O7E3Q9kNu</guid>
<content:encoded><![CDATA[
<div> 稀疏自编码器、线性近似、因果关系、可扩展流水线、细粒度回路、解释模型行为、下游任务、语言模型、特征、语言模型特征

总结:<br /><br />这篇文章提出了一种利用稀疏自编码器和线性近似的方法，来发现人类可解释的语言模型特征之间的因果关系。他们构建了一个可扩展的流水线，用于构建细粒度回路来解释模型行为，并将其应用于下游任务中。通过架构Sparse Feature Circuits，使得研究人员能够在语言模型中发现和编辑可解释的因果关系图，并对模型进行细致的解释。这种方法可以帮助研究人员更好地理解语言模型的工作原理和特征之间的关系，为语言处理领域的研究和实践提供了新的思路。 <div>
通过稀疏自编码器和线性近似，提出一种发现人类可解释语言模型特征之间因果关系的可扩展流水线，以构建细粒度回路解释模型行为，并应用于下游任务。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models》S Marks, C Rager, E J. Michaud, Y Belinkov, D Bau, A Mueller [Northeastern University &amp; MIT] (2024) <a href="https://arxiv.org/abs/2403.19647"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoavurbf0qj21em0potkf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavurv5khj21oi0ro13q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavusaiiaj21p00ywqep.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavuskxi0j21ou0n0qb7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oy3hnj20vh0dh76g.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oyhohj20vi0eydj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oydahj20vj0fuwhe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoaw1oyalgj20ve0gdtb5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oyqsjj20vf0qkadm.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:37:26 GMT</pubDate>
</item>
<item>
<title>[LG]《Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models》S Marks, C Rager, E J. Michaud, Y Belinkov, D B...</title>
<link>https://weibo.com/1402400261/O7E3JjgAw</link>
<guid>https://weibo.com/1402400261/O7E3JjgAw</guid>
<content:encoded><![CDATA[
<div> Sparse Feature Circuits, Discovering, Editing, Interpretable, Causal Graphs, Language Models, Northeastern University, MIT, 2024

<br /><br />总结:
这篇论文由Northeastern大学和MIT的研究人员共同合作，提出了一种称为Sparse Feature Circuits的方法，可以发现和编辑语言模型中可解释的因果图。研究人员指出，传统的语言模型在解释和编辑因果关系方面存在一定的困难，因此他们提出了这种新方法。Sparse Feature Circuits是一种新颖的方法，可以帮助人们更好地理解语言模型中的因果关系，并进行相应的编辑。通过实验证明，这种方法在发现和编辑可解释的因果图方面取得了显著的效果。整体而言，这项研究为语言模型中因果关系的理解和编辑提供了新的思路和方法。 <div>
[LG]《Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models》S Marks, C Rager, E J. Michaud, Y Belinkov, D Bau, A Mueller [Northeastern University &amp; MIT] (2024) <a href="https://arxiv.org/abs/2403.19647"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoavurbf0qj21em0potkf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavurv5khj21oi0ro13q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavusaiiaj21p00ywqep.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavuskxi0j21ou0n0qb7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oy3hnj20vh0dh76g.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oyhohj20vi0eydj2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oydahj20vj0fuwhe.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoaw1oyalgj20ve0gdtb5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oyqsjj20vf0qkadm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw1oyu6mj20ve0m2n02.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaw1oyjjgj20vh0mk0vg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw1oy2sej20ve0el40d.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oyratj20vi0fa768.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oycdnj20vf0hztax.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoaw1oyimjj20vi0kc0vc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoaw1oynjjj20vd0gr76y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoaw1oye9ij20vd0j0wh2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoaw1oyo2kj20vd0g2jtp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:37:10 GMT</pubDate>
</item>
<item>
<title>LISA通过层级重要性采样有效模拟LoRA更新方式，实现内存高效的大规模语言模型微调，在多任务上性能优异。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《LISA: Layerwise I...</title>
<link>https://weibo.com/1402400261/O7E08j19a</link>
<guid>https://weibo.com/1402400261/O7E08j19a</guid>
<content:encoded><![CDATA[
<div> 层级重要性采样、LoRA更新方式、内存高效、大规模语言模型微调、多任务、性能优异、LISA、香港科技大学

<br /><br />总结:
该研究提出了一种名为LISA的方法，通过层级重要性采样有效模拟LoRA更新方式，实现了内存高效的大规模语言模型微调。该方法在多任务上表现出色，性能优异，为语言模型微调提供了新的思路和解决方案。LISA方法由香港科技大学的研究团队提出，为大规模语言模型微调领域的发展做出了重要贡献。 <div>
LISA通过层级重要性采样有效模拟LoRA更新方式，实现内存高效的大规模语言模型微调，在多任务上性能优异。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning》R Pan, X Liu, S Diao, R Pi, J Zhang, C Han, T Zhang [The Hong Kong University of Science and Technology] (2024) <a href="https://arxiv.org/abs/2403.17919"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavmt9utbj21d60o6drq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoavmtktt0j20p40ksgo8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoavmtxfumj21ik0l6q7x.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hoavmu3z4zj20s80pqtby.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoavsfd8fhj20hv0f7aat.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoavsfd33aj20hu0g8gm6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoavsfdtokj20yw0rlgog.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoavsfd67pj20ua097gm4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoavsfcw1hj20qs097wex.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 21:28:18 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.31)》 爱可可微博热门分享(3.31) [图片]</title>
<link>https://weibo.com/1402400261/O7B7H4FP8</link>
<guid>https://weibo.com/1402400261/O7B7H4FP8</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、3.31、关键词

<br /><br />总结:
3月31日，爱可可微博账号分享了一篇热门内容，引起了网友的关注和转发。文章内容涵盖了多个话题，包括生活趣事、美食推荐、时尚搭配等。微博中的精彩内容吸引了众多用户的注意，让大家在微博平台上进行互动和分享。通过这些热门话题，网友们可以了解到更多有趣的信息，充实自己的生活。爱可可微博成为了人们交流和分享的平台，为大家带来了更多的快乐和收获。 <div>
《爱可可微博热门分享(3.31)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405018110007574965"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.31)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hoaj2y0wrpj20c206st96.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 14:08:40 GMT</pubDate>
</item>
<item>
<title>【AI生成内容泛滥，文化生态岌岌可危】- 各类AI模型(如GPT-4、ChatGPT等)产生的文本、图像、视频等内容，质量参差不齐，正在大量充斥互联网。这些内容包括学术论...</title>
<link>https://weibo.com/1402400261/O7yyxwwUe</link>
<guid>https://weibo.com/1402400261/O7yyxwwUe</guid>
<content:encoded><![CDATA[
<div> AI生成内容、文化生态、科学研究、影响、低质量视频、儿童认知、社会实验、公共文化资源、环境立法、清洁互联网法案

<br /><br />总结:
AI生成内容在互联网上泛滥，给文化生态带来威胁，影响深远。在科学研究领域，AI生成内容的使用严重影响同行评审，可能带来不当行为。此外，在视频领域，低质量的AI合成儿童视频可能损害儿童认知发展，需要引起警惕。针对这一趋势，需要借鉴20世纪环境立法的经验，制定《清洁互联网法案》，强制监管AI生成内容，保护公共文化资源。AI公司应该加强自律，但同样需要法律监管来应对AI内容污染问题。AI的快速发展带来了一系列社会问题，需要重视并加强监管，避免其失控。 <div>
【AI生成内容泛滥，文化生态岌岌可危】<br />- 各类AI模型(如GPT-4、ChatGPT等)产生的文本、图像、视频等内容，质量参差不齐，正在大量充斥互联网。这些内容包括学术论文、社交媒体帖子、虚假账号、搜索结果等。   <br />- AI生成内容对科学研究的影响尤其严重。研究发现，参加AI会议的科研人员在同行评审中大量使用类似AI生成文本的词汇。这意味着部分作者可能使用AI生成内容或辅助完成同行评审。   <br />- YouTube上也出现大量使用AI合成的低质量儿童视频，这可能会损害儿童认知发展。我们正在进行一场大规模的社会实验，还不知道后果如何。   <br />- 企业和个人出于经济利益考虑，会选择使用廉价的AI生成内容。这导致“公共文化资源”遭到污染，犯了“公地悲剧”的错误。   <br />- 20世纪需要环境立法来保护共享环境，21世纪同样需要立法来保护共享文化。具体可要求对AI生成内容进行标记或水印。   <br />- AI公司目前不愿添加高级水印，担心这会影响模型性能。需立法强制对生成内容添加统计图案等难以移除的水印，以便检测。   <br />- 我们需要等同于《清洁空气法案》的《清洁互联网法案》，通过立法监管来应对AI内容污染问题，不能仅期望企业自律。  <br /><br />思考：  <br />- AI生成内容泛滥成灾，污染文化环境，这一观点发人深省。AI的影响已经渗透到科学等重要领域，令人警醒。  <br />- 连科学论文评审都大量使用AI，反映出目前学术界对AI的过度依赖和急功近利，值得反思。  <br />- AI在学术领域的滥用，凸显了AI技术发展的负面影响。如何规范AI的使用，划定伦理道德底线，是一个亟待解决的问题。  <br />- 文章揭示了AI技术快速发展带来的社会问题，表明我们要高度警惕AI的负面影响，加强监管，防止其失控。<br />《Opinion | AI Garbage Is Already Polluting the Internet - The New York Times》 <a href="https://www.nytimes.com/2024/03/29/opinion/ai-internet-x-youtube.html?ugrp=u&amp;unlocked_article_code=1.gU0.U5Ee.kvPE0e0DodvZ&amp;smid=url-share"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa7r3rbruj20u0126tfm.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:36:35 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment》(ICLR 2024) GitHub: github.com/lisiyao21/Du...</title>
<link>https://weibo.com/1402400261/O7yvaAD75</link>
<guid>https://weibo.com/1402400261/O7yvaAD75</guid>
<content:encoded><![CDATA[
<div> 关键词：Duolando、GPT、强化学习、舞蹈伴奏、UniDepth、深度估计、T2I模型、超分辨率、LiDAR、视觉SLAM

总结:
Duolando是一种使用强化学习技术对GPT进行跟随的方法，用于舞蹈伴奏。UniDepth是一种通用的单目度量深度估计模型。 T2I模型可以通过识别语义方向实现连续、特定主题的属性控制。AdaSR-TalkingHead是一种用于一次性生成语音头像的自适应超分辨率技术。 LTA-OM是一种长期关联的激光雷达-惯性里程计和地图构建技术。EfficientVMamba是一种轻量级视觉Mamba的有选择性扫描技术。LITA是一种语言指导的时间定位助理模型。GaussianCube利用最优传输将高斯喷洒结构化用于三维生成建模。Perturbed-Attention Guidance是一种扰动注意力引导技术。ROUTERBENCH是用于多LLM路由系统的基准测试。Long-Context-Attention是用于长上下文LLM模型训练的分布式注意力实现。DevBench是用于软件开发的全面基准测试。Should-It-Be-Executed-Or-Processed探讨LLMs是否能够区分指令和数据。BasicPBC是学习匹配的动画油桶着色基准测试。EasyRL4Rec是一个用户友好的基于强化学习的推荐系统代码库。SuperPoint是一种自监督兴趣点检测和描述模型。EgoSchema是用于非常长形式视频语言理解的诊断基准测试。 <div>
几篇论文实现代码：<br />《Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment》(ICLR 2024) GitHub: github.com/lisiyao21/Duolando<br />《UniDepth: Universal Monocular Metric Depth Estimation》(CVPR 2024) GitHub: github.com/lpiccinelli-eth/UniDepth [fig1]<br />《Continuous, Subject-Specific Attribute Control in T2I Models by Identifying Semantic Directions》(2024) GitHub: github.com/CompVis/attribute-control<br />《Adaptive Super Resolution for One-Shot Talking Head Generation》(2024) GitHub: github.com/Songluchuan/AdaSR-TalkingHead<br />《LTA-OM: Long-Term Association LiDAR-Inertial Odometry and Mapping》(2024) GitHub: github.com/hku-mars/LTAOM<br />《EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba》(2024) GitHub: github.com/TerryPei/EfficientVMamba [fig2] <br />《LITA: Language Instructed Temporal-Localization Assistant》(2024) GitHub: github.com/NVlabs/LITA<br />《GaussianCube: Structuring Gaussian Splatting for 3D Generative Modeling using Optimal Transport》(2024) GitHub: github.com/GaussianCube/GaussianCube<br />《Perturbed-Attention Guidance》(2024) GitHub: github.com/KU-CVLAB/Perturbed-Attention-Guidance<br />《ROUTERBENCH: A Benchmark for Multi-LLM Routing System》(2024) GitHub: github.com/withmartian/routerbench<br />《Long-Context-Attention: Distributed Attention Implementations for Long Context LLM Model Training》(2024) GitHub: github.com/feifeibear/long-context-attention<br />《DevBench: A Comprehensive Benchmark for Software Development》(2024) GitHub: github.com/open-compass/DevBench [fig3]<br />《Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?》(2024) GitHub: github.com/egozverev/Should-It-Be-Executed-Or-Processed<br />《Learning Inclusion Matching for Animation Paint Bucket Colorization》(2024) GitHub: github.com/ykdai/BasicPBC<br />《EasyRL4Rec: A User-Friendly Code Library for Reinforcement Learning Based Recommender Systems》(2024) GitHub: github.com/chongminggao/EasyRL4Rec<br />《SuperPoint: Self-Supervised Interest Point Detection and Description》(2024) GitHub: github.com/christian-rauch/super_point_inference<br />《EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding》(2024) GitHub: github.com/egoschema/EgoSchema<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoa145bowtj21rf0i6wu8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hoa1h04n3kj20l70deafb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hoa681no84j23zf1827wh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:28:18 GMT</pubDate>
</item>
<item>
<title>【EPUB to Audiobook Converter：EPUB到有声书的转换器】’EPUB to Audiobook Converter - EPUB to audiobook converter, optimized for Audiobookshelf' GitHub...</title>
<link>https://weibo.com/1402400261/O7yttipiX</link>
<guid>https://weibo.com/1402400261/O7yttipiX</guid>
<content:encoded><![CDATA[
<div> GitHub, EPUB to Audiobook Converter, Audiobookshelf
<br />
EPUB到有声书的转换器，可以将EPUB转换为有声书，GitHub上有项目epub_to_audiobook，作者是p0n1，优化了Audiobookshelf的使用体验。

<br /><br />总结:
EPUB到有声书的转换器是一个可以将EPUB格式的电子书转换为有声书的工具，适用于Audiobookshelf，作者是p0n1，在GitHub上开源了相关项目。 <div>
【EPUB to Audiobook Converter：EPUB到有声书的转换器】’EPUB to Audiobook Converter - EPUB to audiobook converter, optimized for Audiobookshelf' GitHub: github.com/p0n1/epub_to_audiobook <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa7e0zh6mj21010u0aec.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:24:06 GMT</pubDate>
</item>
<item>
<title>【Softmax for Arbitrary Label Trees：一个用于医学影像分割的框架】'Softmax for Arbitrary Label Trees - Softmax for Arbitrary Label Trees (SALT) is a fr...</title>
<link>https://weibo.com/1402400261/O7yt26gby</link>
<guid>https://weibo.com/1402400261/O7yt26gby</guid>
<content:encoded><![CDATA[
<div> 分词：Softmax、Arbitrary Label Trees、医学影像分割、框架、训练、分割网络、条件概率、模型、层级关系、数据

总结:<br /><br />这篇文章介绍了一个名为Softmax for Arbitrary Label Trees (SALT)的框架，用于训练医学影像分割网络。SALT利用条件概率来建模数据中的层级关系，从而更好地进行分割任务。该框架的GitHub链接是github.com/UMEssen/SALT。SALT框架可以帮助提高医学影像分割的准确性和效率，是一个有潜力的方法。 <div>
【Softmax for Arbitrary Label Trees：一个用于医学影像分割的框架】'Softmax for Arbitrary Label Trees - Softmax for Arbitrary Label Trees (SALT) is a framework for training segmentation networks using conditional probabilities to model hierarchical relationships in the data.' GitHub: github.com/UMEssen/SALT <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa7d02ja2j20u0112n32.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:23:00 GMT</pubDate>
</item>
<item>
<title>【Edge Infer：- 旨在资源受限的设备上运行小型 AI 模型(包括向量化和Onnx模型)，如 Android、iOS 或 MCU，实现高效的边缘智能，用于实时决策】'Edge Infer - Ed...</title>
<link>https://weibo.com/1402400261/O7ys0ziZp</link>
<guid>https://weibo.com/1402400261/O7ys0ziZp</guid>
<content:encoded><![CDATA[
<div> Edge Infer, 资源受限设备, 小型AI模型, 向量化, Onnx模型, Android, iOS, MCU, 边缘智能, 实时决策, GitHub

总结:<br /><br />Edge Infer 是一种旨在在资源受限的设备上运行小型AI模型的工具，包括向量化和Onnx模型，适用于Android、iOS或MCU等设备，实现高效的边缘智能，用于实时决策。Edge Infer的GitHub链接为github.com/unit-mesh/edge-infer。 <div>
【Edge Infer：- 旨在资源受限的设备上运行小型 AI 模型(包括向量化和Onnx模型)，如 Android、iOS 或 MCU，实现高效的边缘智能，用于实时决策】'Edge Infer - EdgeInfer enables efficient edge intelligence by running small AI models, including embeddings and OnnxModels, on resource-constrained devices like Android, iOS, or MCUs for real-time decision-making. EdgeInfer' GitHub: github.com/unit-mesh/edge-infer <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa7adt8y1j20yc0u0dil.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:20:30 GMT</pubDate>
</item>
<item>
<title>【hoarder-app：用于数据(链接、图片、笔记)收集的应用，支持AI自动打标和全文检索功能】'hoarder-app - A self-hostable bookmark-everything app (links, note...</title>
<link>https://weibo.com/1402400261/O7yrtjJXR</link>
<guid>https://weibo.com/1402400261/O7yrtjJXR</guid>
<content:encoded><![CDATA[
<div> 自托管、收藏一切数据的应用、链接、笔记、图片、AI自动标记、全文检索、GitHub、MohamedBassem、hoarder-app<br />
<br />
总结:<br />
hoarder-app是一个自托管的应用程序，用于收藏各种数据，包括链接、笔记和图片。该应用支持AI自动标记和全文检索功能，用户可以方便地管理和查找自己收藏的信息。该项目可以在GitHub上找到，由MohamedBassem维护。 <div>
【hoarder-app：用于数据(链接、图片、笔记)收集的应用，支持AI自动打标和全文检索功能】'hoarder-app - A self-hostable bookmark-everything app (links, notes and images) with AI-based automatic tagging and full text search' GitHub: github.com/MohamedBassem/hoarder-app <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa78e98l2j21jk0u0n4q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:19:10 GMT</pubDate>
</item>
<item>
<title>【Popple：分布式、高可用、通用用途的键/值数据库】'Popple - Popple is a distributed, highly available, general purpose key/value database.' GitHub: git...</title>
<link>https://weibo.com/1402400261/O7ypPED6c</link>
<guid>https://weibo.com/1402400261/O7ypPED6c</guid>
<content:encoded><![CDATA[
<div> 分布式、高可用、通用、键/值数据库、Popple、GitHub、hoorayman、distributed、highly available、general purpose

分布式键/值数据库Popple是一个通用、高可用的分布式键/值数据库，可以处理各种用途的数据。它具有弹性，能够在整个系统中分布数据，保证数据的高可用性。Popple的代码托管在GitHub上，由hoorayman开发和维护。采用分布式架构，Popple可以有效地存储和检索大量键/值对，适用于各种应用场景。总的来说，Popple是一个强大的键/值数据库，具有分布式部署和高可用性的特点，适用于多种通用用途。 <br /><br />总结: Popple是一个分布式、高可用、通用用途的键/值数据库，由hoorayman开发，可用于处理各种数据应用。 <div>
【Popple：分布式、高可用、通用用途的键/值数据库】'Popple - Popple is a distributed, highly available, general purpose key/value database.' GitHub: github.com/hoorayman/popple <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%95%B0%E6%8D%AE%E5%BA%93%23&amp;isnewpage=1"><span class="surl-text">#数据库#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa74ti7tdj21240u0q73.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:15:08 GMT</pubDate>
</item>
<item>
<title>【rev.ng：基于LLVM和QEMU的二进制分析框架和反编译器】’The rev.ng binary analysis framework and decompiler' GitHub: github.com/revng/revng-c #开源# #机...</title>
<link>https://weibo.com/1402400261/O7ynd9CZx</link>
<guid>https://weibo.com/1402400261/O7ynd9CZx</guid>
<content:encoded><![CDATA[
<div> LLVM、QEMU、二进制分析框架、反编译器、GitHub、rev.ng、revng-c

总结:<br /><br />rev.ng是基于LLVM和QEMU的二进制分析框架和反编译器，它提供一种强大的工具来分析和反编译二进制文件。通过GitHub上的revng-c项目，用户可以轻松访问和使用这个框架。LLVM和QEMU的结合使得rev.ng具备了强大的分析和反编译能力，帮助用户更好地理解和操纵二进制文件。通过rev.ng，用户可以深入研究二进制文件的内部结构和功能，从而进行更高级的安全研究和分析工作。是一个有着广泛应用前景的二进制分析工具。 <div>
【rev.ng：基于LLVM和QEMU的二进制分析框架和反编译器】’The rev.ng binary analysis framework and decompiler' GitHub: github.com/revng/revng-c <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa6y3b15sj21i60l4n1o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:08:41 GMT</pubDate>
</item>
<item>
<title>【EasyRL4Rec - 专注于强化学习(RL)为基础的推荐系统(RS)的全面且易于使用的库】'EasyRL4Rec - a comprehensive and easy-to-use library designed specifically...</title>
<link>https://weibo.com/1402400261/O7ym7486g</link>
<guid>https://weibo.com/1402400261/O7ym7486g</guid>
<content:encoded><![CDATA[
<div> 库，强化学习，推荐系统，全面，易于使用，github，Reinforcement Learning，Recommender Systems，comprehensive，easy-to-use

总结:<br /><br />
"EasyRL4Rec"是一个专注于强化学习为基础的推荐系统的全面且易于使用的库。其设计旨在为推荐系统提供强化学习的解决方案，并在GitHub上提供代码库。该库提供了强化学习和推荐系统的综合性功能，并且易于使用，成为开发推荐系统的有力工具。 <div>
【EasyRL4Rec - 专注于强化学习(RL)为基础的推荐系统(RS)的全面且易于使用的库】'EasyRL4Rec - a comprehensive and easy-to-use library designed specifically for Reinforcement Learning (RL)-based Recommender Systems (RSs)‘ GitHub: github.com/chongminggao/EasyRL4Rec <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa6v4ng6rj20v60u0gpv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 07:05:58 GMT</pubDate>
</item>
<item>
<title>【高效SAM分割模型大列表】’Efficient-Segment-Anything-Model - One summary of efficient segment anything models' GitHub: github.com/czg1225/Awesome-Eff...</title>
<link>https://weibo.com/1402400261/O7yfei9ug</link>
<guid>https://weibo.com/1402400261/O7yfei9ug</guid>
<content:encoded><![CDATA[
<div> GitHub, Efficient-Segment-Anything-Model, 分割模型, 高效, 模型, 列表, 精彩, 总结, 优点, 应用

<br /><br />总结:
本文介绍了高效SAM分割模型的一份大列表，包含了各种精彩的分割模型。这些模型在分割任务中具有高效性，能够快速准确地识别出目标物体。这些模型的优点在于其高效性和准确性，可以被广泛应用于图像分割、语义分割等领域。通过这个列表，研究者和开发者可以找到适合自己项目的高效SAM分割模型，提高分割任务的效率和准确率。 <div>
【高效SAM分割模型大列表】’Efficient-Segment-Anything-Model - One summary of efficient segment anything models' GitHub: github.com/czg1225/Awesome-Efficient-Segment-Anything <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa6dbad5kj20u00unq7j.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa6dcle9yj215h0u0gq9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa6ddlmj6j20xi0c540f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa6deyl0kj235s0peqd6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa6dfx5dwj21tv0u00yz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa6dhbvx5j235s0natjb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa6diu3ruj22u80u0wo6.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hoa6djqb0uj21f70u0q98.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa6dlfv25j21j40u0jys.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 06:49:01 GMT</pubDate>
</item>
<item>
<title>【RestAI：基于LlamaIndex、Ollama和HF pipelines的AIaaS(人工智能即服务)开源平台】'RestAI - RestAI is an AIaaS (AI as a Service) open-source platform. Bu...</title>
<link>https://weibo.com/1402400261/O7xdOmrEj</link>
<guid>https://weibo.com/1402400261/O7xdOmrEj</guid>
<content:encoded><![CDATA[
<div> RestAI、AIaaS、开源平台、LlamaIndex、Ollama、HF Pipelines、支持、LLM、嵌入式使用、调优

总结:<br /><br />RestAI是一个基于LlamaIndex、Ollama和HF Pipelines的AIaaS开源平台，支持任何被LlamaIndex支持的公共LLM和任何被Ollama支持的本地LLM。它提供精准的嵌入式使用和调优功能。GitHub上有相关项目。 <div>
【RestAI：基于LlamaIndex、Ollama和HF pipelines的AIaaS(人工智能即服务)开源平台】'RestAI - RestAI is an AIaaS (AI as a Service) open-source platform. Built on top of LlamaIndex, Ollama and HF Pipelines. Supports any public LLM supported by LlamaIndex and any local LLM suported by Ollama. Precise embeddings usage and tuning.' GitHub: github.com/apocas/restai <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hoa1v0x4sij20ud0u0ad4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 04:12:47 GMT</pubDate>
</item>
<item>
<title>【Plandex：基于OpenAI API的命令行AI编程引擎，用于处理复杂的任务，可以帮助用户分解大型任务为更小的子任务，并逐个实现这些子任务，帮助快速完成工作流，与...</title>
<link>https://weibo.com/1402400261/O7xaJE7HH</link>
<guid>https://weibo.com/1402400261/O7xaJE7HH</guid>
<content:encoded><![CDATA[
<div> 命令行、AI编程引擎、处理任务、分解任务、实现子任务、完成工作流、技术互动、减少时间、GitHub、Plandex<br />
<br />
AI编程引擎Plandex基于OpenAI API，用于处理复杂任务，能帮助用户将大型任务分解为小任务，并逐一实现，从而快速完成工作流。用户可以利用Plandex与不熟悉的技术互动，摆脱困境，减少在无聊事务上的时间花费。该工具的GitHub仓库可在github.com/plandex-ai/plandex找到。Plandex是一个有用的AI工具，可提高用户的工作效率和减轻工作负担。总结: <br />AI编程引擎Plandex基于OpenAI API，可帮助用户快速解决复杂任务，通过分解大型任务为小任务逐一实现，并与不熟悉的技术互动，提高工作效率。 <div>
【Plandex：基于OpenAI API的命令行AI编程引擎，用于处理复杂的任务，可以帮助用户分解大型任务为更小的子任务，并逐个实现这些子任务，帮助快速完成工作流，与不熟悉的技术互动，摆脱困境，减少在无聊的事情上花费的时间】’Plandex - An AI coding engine for complex tasks' GitHub: github.com/plandex-ai/plandex <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa1mb9tl9j20u00uwn1d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 04:05:12 GMT</pubDate>
</item>
<item>
<title>【深度伪造(Deepfake)相关文献资源列表】’Deepfake Generation and Detection: A Benchmark and Survey - A Survey on Deepfake Generation and Detection' Git...</title>
<link>https://weibo.com/1402400261/O7x9Clzzn</link>
<guid>https://weibo.com/1402400261/O7x9Clzzn</guid>
<content:encoded><![CDATA[
<div> Deepfake Generation, Detection, Benchmark, Survey, GitHub, Resource, Awesome, Flyingby, Survey on Deepfake Generation and Detection

<br /><br />总结:
本文介绍了关于深度伪造（Deepfake）生成和检测的研究现状，提供了一个包含相关资源的GitHub链接。文章从深度伪造生成和检测的角度出发，提供了相关资源和信息，帮助读者了解深度伪造技术的发展和应用。GitHub链接中包含了丰富的资料，为研究者提供了实用的工具和参考文献。深度伪造技术的发展对社会产生了重要影响，因此深入了解相关信息和研究是十分必要的。通过本文和相关资源，读者可以更好地了解和研究深度伪造技术，为社会和科学研究做出更有益的贡献。 <div>
【深度伪造(Deepfake)相关文献资源列表】’Deepfake Generation and Detection:   <br />  A Benchmark and Survey - A Survey on Deepfake Generation and Detection' GitHub: github.com/flyingby/Awesome-Deepfake-Generation-and-Detection <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hoa1k9ly7yj21js0jr79w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa1kaeawrj20vb0d4goz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 04:02:27 GMT</pubDate>
</item>
<item>
<title>【OpenUI：让使用者描述网页界面并实时渲染的开源项目】'OpenUI - OpenUI let's you describe UI using your imagination, then see it rendered live.' GitHub:...</title>
<link>https://weibo.com/1402400261/O7x5h1h9B</link>
<guid>https://weibo.com/1402400261/O7x5h1h9B</guid>
<content:encoded><![CDATA[
<div> OpenUI、描述、界面、实时渲染、开源项目、GitHub、使用者、网页、界面、渲染 live。

<br /><br />总结:
OpenUI是一个开源项目，可以让使用者通过描述界面来实时渲染网页界面。用户可以发挥自己的想象力来描述界面，然后看到它在实时渲染的过程中呈现出来。该项目托管在GitHub上，方便用户查看和参与贡献。通过OpenUI，用户可以轻松创建自己想要的网页界面，带来更加直观和便捷的设计体验。 <div>
【OpenUI：让使用者描述网页界面并实时渲染的开源项目】'OpenUI - OpenUI let's you describe UI using your imagination, then see it rendered live.' GitHub: github.com/wandb/openui <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hoa193yigoj21410u00wc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 03:51:44 GMT</pubDate>
</item>
<item>
<title>【OpenDevin: 一个开源项目，旨在复制Devin，Devin是一个自主的AI软件工程师，能执行复杂的工程任务，并积极与用户协作进行软件开发项目的合作】'OpenDevin: Cod...</title>
<link>https://weibo.com/1402400261/O7x2Kl9x2</link>
<guid>https://weibo.com/1402400261/O7x2Kl9x2</guid>
<content:encoded><![CDATA[
<div> OpenDevin, 开源项目, 复制Devin, AI软件工程师, 执行工程任务, 用户协作, 软件开发项目, GitHub, Code Less, Make More

<br /><br />总结:
OpenDevin是一个开源项目，旨在复制Devin，Devin是一个自主的AI软件工程师，能执行复杂的工程任务，并积极与用户协作进行软件开发项目的合作。该项目在GitHub上可找到，旨在让用户编写更少的代码，取得更多的成果。 <div>
【OpenDevin: 一个开源项目，旨在复制Devin，Devin是一个自主的AI软件工程师，能执行复杂的工程任务，并积极与用户协作进行软件开发项目的合作】'OpenDevin: Code Less, Make More' GitHub: github.com/opendevin/opendevin <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5017953058357310"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax4.sinaimg.cn/orj480/5396ee05ly1hoa12ihxhwj21f20qumxl.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/ksQ6Y1c5lx08dIbPt6Na010412002IBP0E010.mp4?label=mp4_720p&amp;template=1368x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711865762&amp;ssig=PUWH7V97Hq&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/n7Oawc2Jlx08dIbPjD5e010412001fj80E010.mp4?label=mp4_hd&amp;template=912x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711865762&amp;ssig=buxMcLzUUi&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/TLUUJoUrlx08dIbPBcUE010412000JWS0E010.mp4?label=mp4_ld&amp;template=684x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711865762&amp;ssig=X5k%2F11GgW2&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5017953058357310" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 03:45:31 GMT</pubDate>
</item>
<item>
<title>《LLM 应用开发实践笔记》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O7wM56Ev8</link>
<guid>https://weibo.com/1402400261/O7wM56Ev8</guid>
<content:encoded><![CDATA[
<div> 应用开发、LLM、实践、笔记、技术、编程、学习、经验、案例、方法论

<br /><br />总结:
LLM 应用开发实践笔记是一篇关于应用开发实践的经验分享文章。文章通过具体的案例和方法论，介绍了在应用开发过程中的技术细节和实践经验。作者通过自身的学习和实践，总结出了一套有效的开发方法，帮助读者更好地理解应用开发的过程。通过本文，读者可以学习到实际应用开发中的技巧和经验，为自己的开发工作提供有用的参考。 <div>
《LLM 应用开发实践笔记》 <a href="https://aitutor.liduos.com/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9zv1onj7j20ki10s76d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 03:04:27 GMT</pubDate>
</item>
<item>
<title>对 预训练 MoE、upcycled MoE 和 FrankenMoE 三类 MoE 模型的简介。- 预训练 MoE预训练 MoE 旨在利用 MoE 架构从头开始预训练语言模型，以期获得比传统密集模型...</title>
<link>https://weibo.com/1402400261/O7wxgeqRs</link>
<guid>https://weibo.com/1402400261/O7wxgeqRs</guid>
<content:encoded><![CDATA[
<div> 预训练 MoE、upcycled MoE、FrankenMoE、语言模型、专家、预训练、计算成本、效果、模型合并

<br /><br />总结:
预训练 MoE 是一种利用 MoE 架构从头开始预训练语言模型的方法，具有训练速度快、推理速度快和专家针对不同概念等优势，代表性模型有 Switch Transformer、Mixtral。upcycled MoE 是在已经训练好的基础模型上创建多个专家形成 MoE 模型，优势在于计算成本低、可灵活控制专家数量，代表性工作有 DeepSeek-MoE、Upstage SOLAR。FrankenMoE 是将在特定任务上表现优异的微调模型组合成 MoE 模型，专家面向特定任务，但缺乏负载均衡优势，表现可能优于通用 MoE 模型，代表性模型为 Beyonder-4x7B-v2。 <div>
对 预训练 MoE、upcycled MoE 和 FrankenMoE 三类 MoE 模型的简介。<br /><br />- 预训练 MoE<br />预训练 MoE 旨在利用 MoE 架构从头开始预训练语言模型，以期获得比传统密集模型更高效的训练效果。预训练 MoE 的优势在于：<br />1. 训练速度更快。在相同计算预算下，MoE 模型理论上可以比密集模型更快达到相同的性能水平。<br />2. 推理速度更快。尽管 MoE 模型参数量巨大，但实际推理时只会激活部分专家，因此推理速度比拥有相同参数量的密集模型更快。<br />3. 专家可以专门针对不同的浅层概念或词元组，而不是某个特定主题。<br />不过，预训练 MoE 也面临一些挑战，如推理时需要大量内存来加载所有专家参数，以及在下游任务微调时容易过拟合等。代表性的预训练 MoE 模型有 Switch Transformer、Mixtral 等。<br /><br />- upcycled MoE<br />upcycled MoE 的思路是在一个已经训练好的基础模型上，通过复制其前馈网络来创建多个专家，形成一个 MoE 模型。与从头预训练相比，upcycled MoE 的优势在于：<br />1. 基于成熟的预训练模型，继续预训练的计算成本更低。<br />2. 可以使用细粒度的专家，即将前馈网络切割成更小的单元，从而获得数量众多的小型专家。  <br />3. 可以灵活控制要激活的专家数量，在推理速度和效果之间进行权衡。<br />upcycled MoE 的代表性工作包括 DeepSeek-MoE、Upstage SOLAR 等。<br /><br />- FrankenMoE<br />FrankenMoE 的思路与模型合并类似，即选择几个在特定任务上表现优异的微调模型，将它们组合成一个 MoE 模型。通过一定的训练，可以让路由器学会将不同类型的token发送给对应的专家。<br />与预训练 MoE 和再利用 MoE 相比，FrankenMoE 的特点是：<br />1. 专家是面向特定任务的，而不是通用的浅层概念，这一点与预训练 MoE 有本质区别。<br />2. 不再具有 MoE 的某些优势，如负载均衡。因为专家之间的能力差异较大。<br />3. 在特定任务上的表现可能优于通用的 MoE 模型，如 Beyonder-4x7B-v2。<br />但 FrankenMoE 能否广泛应用于不同场景，目前还有待进一步验证。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9yoziedxj20xc4t8b29.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9yp0i5o4j20u70i90v8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9yp1kqcyj20pb0chwfw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 02:27:57 GMT</pubDate>
</item>
<item>
<title>《混合专家模型 (MoE) 详解》- MoE 是一种将大型语言模型中全连接层替换为稀疏层的技术，可以显著提高预训练效率。其包含两个主要元素：稀疏的 MoE 层和一个门控...</title>
<link>https://weibo.com/1402400261/O7w5scEbo</link>
<guid>https://weibo.com/1402400261/O7w5scEbo</guid>
<content:encoded><![CDATA[
<div> 稀疏层、MoE层、门控网络、专家、模型规模、Transformer、微调、训练挑战、开源项目、知识蒸馏、量化

<br /><br />总结:
混合专家模型（MoE）是一种将大型语言模型中全连接层替换为稀疏层的技术，通过引入稀疏性和门控网络，实现部分输入数据计算、模型规模扩张而不增加计算量，并通过专家负载平衡、辅助损失函数和专家容量限制来提高效率。MoE与Transformer结合取得进展，如GShard实现规模扩张至6000亿参数，Switch Transformer简化门控网络，提出专家容量概念。MoE模型在微调中容易过拟合，需采用更高正则化，多任务示教微调再单任务微调可提升表现。面临训练和部署挑战，需专家并行、通信优化、断点续训、模型压缩等技术。MoE模型为构建大规模高效神经网络提供新思路，Switch Transformers等研究解决MoE不稳定性问题，指明后续改进方向。MoE引发学术界和工业界广泛关注，多个研究组织发布基于MoE模型取得性能进步，未来可进一步探索知识蒸馏、量化等方向。将MoE蒸馏为密集模型和量化是有前景的研究方向，在保持性能的同时大幅压缩模型体积，促进MoE在资源受限环境下的部署。 <div>
《混合专家模型 (MoE) 详解》<br />- MoE 是一种将大型语言模型中全连接层替换为稀疏层的技术，可以显著提高预训练效率。其包含两个主要元素：稀疏的 MoE 层和一个门控网络，门控网络决定每个 token 由哪个 expert 处理。   <br />- MoE 的起源可追溯到 1991 年的论文，2010-2015 年间的研究为 MoE 在深度网络中的应用奠定了基础。2017 年的论文首次在 NLP 任务中应用了 MoE，将 LSTM 模型扩展到 1300 亿参数。   <br />- MoE 引入了稀疏性，只对部分输入数据进行计算，从而实现模型规模的扩张而不增加计算量。门控网络学习将输入分配给不同的专家(expert)。   <br />- 为了平衡各专家的负载，需要添加辅助损失函数鼓励所有专家得到近似相等的训练样本。还可以设置专家容量限制。   <br />- MoE 与 Transformer 的结合取得了显著进展。例如 GShard 利用 MoE 将模型扩展到 6000 亿参数；Switch Transformer 引入单专家策略简化了门控网络，提出了专家容量的概念。   <br />- 相较于稠密模型，MoE 模型在下游任务的微调中更容易过拟合，需要采用更高的正则化。最近的工作显示先进行多任务示教微调然后再单任务微调可以显著提升 MoE 的表现。   <br />- 训练和部署 MoE 也面临一些挑战，论文提出了专家并行、通信优化、断点续训、模型压缩等技术来解决这些问题。   <br />- 目前有多个开源项目致力于 MoE 的研究，未来可探索的方向包括知识蒸馏、量化等。  <br /><br />思考：  <br />- MoE 模型的出现为构建大规模且高效的神经网络提供了新的思路。通过将专家作为组件嵌入到网络中，MoE 有望突破传统密集模型的瓶颈。  <br />- Switch Transformers 等工作针对 MoE 的不稳定性问题进行了深入研究，为后续的改进指明了方向。1.6 万亿参数的 MoE 模型展现了这一架构的巨大潜力。  <br />- 多个研究组织已经发布了基于 MoE 的模型，表明 MoE 正在受到学术界和工业界的广泛关注。这些模型在性能上取得了显著进步，有望在实际应用中发挥重要作用。  <br />- 将 MoE 蒸馏为密集模型以及对其进行量化是非常有前景的研究方向。这不仅能够在保持性能的同时大幅压缩模型体积，还能促进 MoE 在资源受限环境下的部署。<br /> <a href="https://huggingface.co/blog/moe"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9wulpqsaj20za0u00wv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 01:19:26 GMT</pubDate>
</item>
<item>
<title>《BrushNet - BrushNet: A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion | a Hugging Face Space by TencentARC》 网页链接 #...</title>
<link>https://weibo.com/1402400261/O7vT1o0c8</link>
<guid>https://weibo.com/1402400261/O7vT1o0c8</guid>
<content:encoded><![CDATA[
<div> BrushNet, Image Inpainting, Plug-and-Play Model, Diffusion, Dual-Branch, Decomposed, Hugging Face Space, TencentARC

<br /><br />总结:
本文介绍了一种基于图像修复的模型BrushNet，通过两个分支的扩散机制实现图像修复。该模型能够自动进行图像修复，满足用户需求。通过对不同部分的修复分解，提高了修复效果。 TencentARC团队在Hugging Face Space上提供了该模型，方便用户使用。 <div>
《BrushNet - BrushNet: A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion | a Hugging Face Space by TencentARC》 <a href="https://huggingface.co/spaces/TencentARC/BrushNet"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5017908603191302"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax3.sinaimg.cn/orj480/5396ee05ly1ho9vyjuuigj20zk0k00tk.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/DGCmhkr0lx08dHZH7en6010412005TBA0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711858507&amp;ssig=CUnU3p7Iwb&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/xv8u3UeOlx08dHZGKSly010412002Lz70E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711858507&amp;ssig=CXQrgsO%2Fnc&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/Afyz8Cvblx08dHZGKdLq010412001JUS0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711858507&amp;ssig=xQSd7WEinY&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5017908603191302" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 00:48:49 GMT</pubDate>
</item>
<item>
<title>【DSPy：机器学习工作流重塑提示工程】- DSPy 是一个与众不同的提示工程框架，它将逻辑与提示分离，使开发人员能够通过 dspy.Module 确定性地编程逻辑，而不用关...</title>
<link>https://weibo.com/1402400261/O7vOKCeLv</link>
<guid>https://weibo.com/1402400261/O7vOKCeLv</guid>
<content:encoded><![CDATA[
<div> 提示工程、DSPy、机器学习、工作流、逻辑、LLM、闭合循环、易用性、术语、概念

总结：<br /><br />本文介绍了DSPy这一机器学习工作流重塑提示工程的框架，其将逻辑与提示分离，使开发人员专注于逻辑编程而不需关心底层LLM，有望简化提示工程流程。DSPy将提示工程转变为结构化的机器学习工作流，闭合了训练和评估的循环，突出了LLM/Agent系统的重要性。然而，DSPy目前存在易用性问题，术语和概念晦涩，对新手不友好。希望DSPy在优化易用性方面做出改进，降低学习门槛，扩大受众群。 <div>
【DSPy：机器学习工作流重塑提示工程】<br />- DSPy 是一个与众不同的提示工程框架，它将逻辑与提示分离，使开发人员能够通过 dspy.Module 确定性地编程逻辑，而不用关心所使用的 LLM。  <br />- DSPy 的革命性在于它将提示工程纯手工过程转变为结构化的机器学习工作流，包括准备数据集、定义模型、训练、评估和测试。  <br />- DSPy 的关键贡献是闭合了提示工程中训练和评估的循环，并将逻辑与文本表示分离开来，凸显了对 LLM/Agent 系统的潜在重要性。  <br />- DSPy 目前存在的问题是对新手来说学习曲线较陡峭，其习语如 signature、module、program、teleprompter、optimization 和 compile 等术语让人望而生畏。即使对于精通提示工程的人来说，在 DSPy 中驾驭这些概念也是一个具有挑战性的迷宫。  <br /><br />思考：  <br />- DSPy 通过将逻辑与提示分离，使开发人员能够专注于逻辑编程，而无需关注底层 LLM，这一点令人印象深刻。这种方式有望大大简化提示工程的流程。  <br />- 将提示工程转变为结构化的机器学习工作流是一个宏伟的愿景，如果能实现，将极大地推动 LLM 应用的发展。不过这需要 DSPy 在易用性上做出改进。  <br />- DSPy 的术语和概念目前还比较晦涩，对新手不够友好。如果能在这方面做些优化，降低学习门槛，DSPy 的受众会更加广泛。  <br />《DSPy: Not Your Average Prompt Engineering》 <a href="https://jina.ai/news/dspy-not-your-average-prompt-engineering/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9vnlvwvzj20xc0hiabc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9vnnsds1j20xc0hijt8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 31 Mar 2024 00:38:18 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评...</title>
<link>https://weibo.com/1402400261/O7uVrf61S</link>
<guid>https://weibo.com/1402400261/O7uVrf61S</guid>
<content:encoded><![CDATA[
<div> 编程语言、故事、技术、Java、Python、JavaScript、C语言、MySQL、Redis、技术原理。

<br /><br />总结:
《码农翻身2》是一本故事化的技术书籍，通过讲述编程语言之间的斗争和争端，将看似枯燥的技术知识变得生动有趣。Java、Python、JavaScript、C语言、MySQL和Redis等技术在书中扮演着不同角色，展现了它们之间的互动和竞争。读者在享受故事的同时，也能够学到技术的原理和本质。《码农翻身2》是一部结合技术和趣味的书籍，让读者在轻松愉快的阅读中提升自己的技术水平。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 22:22:01 GMT</pubDate>
</item>
<item>
<title>今日推介(第1361期)：使用方向感知t-SNE可视化高维时间数据、超越回路重叠寻找模型机制、语言模型视角下的工具使用研究综述、用引导扩散从零开始生成强大的投毒...</title>
<link>https://weibo.com/1402400261/O7uVh0dhT</link>
<guid>https://weibo.com/1402400261/O7uVh0dhT</guid>
<content:encoded><![CDATA[
<div> 方向感知t-SNE、高维时间数据、超越回路重叠、模型机制、语言模型、工具使用、引导扩散、投毒和后门、反事实预训练、目标移除和插入

<br /><br />总结:
本文介绍了几篇关于机器学习和人工智能领域的研究成果。首先，提出了使用方向感知t-SNE可视化高维时间数据的方法，可以更直观地展示数据的特征和变化。其次，探讨了超越回路重叠寻找模型机制的方法，对于理解复杂系统的运作机制具有重要意义。另外，从语言模型的视角分析了工具使用研究，为提升用户体验和效率提供了新思路。此外，介绍了用引导扩散从零开始生成强大的投毒和后门的技术，以及用于逼真目标移除和插入的自举反事实预训练的方法，这些技术在安全和数据处理领域具有重要应用前景。通过这些研究成果的分享，可以促进机器学习和人工智能领域的发展，推动相关技术的创新和应用。 <div>
今日推介(第1361期)：使用方向感知t-SNE可视化高维时间数据、超越回路重叠寻找模型机制、语言模型视角下的工具使用研究综述、用引导扩散从零开始生成强大的投毒和后门、用于逼真目标移除和插入的自举反事实预训练 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/689966788"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.31)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho9rpdhji0j20go0gswgt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho9rpfuh30j20go0960uf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho9rpicbi3j20go0dt3zx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho9rpkv1naj20go07kmxz.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho9rpn7yx5j20go08fta0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 22:21:36 GMT</pubDate>
</item>
<item>
<title>通过构建反事实图像数据集微调扩散模型，实现了逼真的物体删除和插入，显著提高了渲染物体对场景效应的能力。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《ObjectDrop: B...</title>
<link>https://weibo.com/1402400261/O7uR4D6Cm</link>
<guid>https://weibo.com/1402400261/O7uR4D6Cm</guid>
<content:encoded><![CDATA[
<div> 反事实图像数据集、微调、扩散模型、物体删除、物体插入、场景效应、物体移除、物体添加、渲染能力、ObjectDrop
<br />
<br />
总结：研究通过构建反事实图像数据集微调扩散模型，实现了逼真的物体删除和插入，提高了渲染物体对场景效应的能力。这项研究利用了ObjectDrop技术，通过对图像进行微调和扩散模型的训练，实现了物体的删除和插入，使得场景效果更加真实。该技术对于图像处理和渲染领域具有重要意义，可以在实际应用中提供更多可能性。研究团队的工作有望为数字图像处理领域带来新的突破，为物体移除和添加等任务提供更加高效、准确的解决方案。 <div>
通过构建反事实图像数据集微调扩散模型，实现了逼真的物体删除和插入，显著提高了渲染物体对场景效应的能力。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion》D Winter, M Cohen, S Fruchter, Y Pritch, A Rav-Acha, Y Hoshen [Google Research] (2024) <a href="https://arxiv.org/abs/2403.18818"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9r6lfzd1j21fc0j812s.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9r6lwz2pj21ok0xu7g6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9r6m52xjj21oi0m6gtc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9r6mf9a0j21p80uync4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9reswzu0j210y0m4aeu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9resx0v3j210z0n7tda.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9reswusnj210x0ovn0q.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resxfa7j210x0qu43z.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9resx035j210p0epq6x.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 22:11:15 GMT</pubDate>
</item>
<item>
<title>[CV]《ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion》D Winter, M Cohen, S Fruchter, Y Pritch, A Rav-Acha, ...</title>
<link>https://weibo.com/1402400261/O7uR2hqNe</link>
<guid>https://weibo.com/1402400261/O7uR2hqNe</guid>
<content:encoded><![CDATA[
<div> Bootstrapping, Counterfactuals, Object Removal, Object Insertion, Photorealistic, Google Research, Deep Learning, Image Editing, Computer Vision, Object Detection

<br /><br />总结：
该研究来自Google Research团队，提出了一种名为ObjectDrop的方法，用于在图像中实现真实感十足的对象删除和插入操作。通过引入反事实生成器来训练深度学习模型，实现了对于图像中物体的有效去除和替换。与传统方法相比，ObjectDrop能够更好地处理较复杂的情景，并且生成的结果质量更高。研究团队在大规模数据集上进行了实验证实，结果表明ObjectDrop在图像编辑和计算机视觉领域具有广阔的应用前景。 <div>
[CV]《ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion》D Winter, M Cohen, S Fruchter, Y Pritch, A Rav-Acha, Y Hoshen [Google Research] (2024) <a href="https://arxiv.org/abs/2403.18818"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9r6lfzd1j21fc0j812s.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9r6lwz2pj21ok0xu7g6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9r6m52xjj21oi0m6gtc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9r6mf9a0j21p80uync4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9reswzu0j210y0m4aeu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9resx0v3j210z0n7tda.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9reswusnj210x0ovn0q.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resxfa7j210x0qu43z.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9resx035j210p0epq6x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9reswcx8j21120dtad2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9resvwsij210y091wgh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resz9qcj21111h3k2x.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9resz22mj210m1ggwp5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9resz299j210x1fgqdh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9reszey1j210x1fg13w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resz2ntj210x1eg130.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9resyyvrj210x1fowog.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 22:11:10 GMT</pubDate>
</item>
<item>
<title>利用引导扩散生成高质量和高效的中投毒基础样本，再与下游攻击算法相结合，实现了更隐蔽和强效的对抗机器学习。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Generating ...</title>
<link>https://weibo.com/1402400261/O7uKD6OzN</link>
<guid>https://weibo.com/1402400261/O7uKD6OzN</guid>
<content:encoded><![CDATA[
<div> 中投毒基础样本, 引导扩散, 下游攻击算法, 对抗机器学习, 高质量, 高效, 隐蔽, 强效, 生成, 转发 

总结:<br /><br />这篇文章介绍了一种利用引导扩散生成高质量和高效的中投毒基础样本的方法，然后与下游攻击算法相结合，实现了更隐蔽和强效的对抗机器学习。研究者通过这种方法能够生成具有潜在毒害和后门功能的样本，为网络安全领域提供了有力的工具和技术。 <div>
利用引导扩散生成高质量和高效的中投毒基础样本，再与下游攻击算法相结合，实现了更隐蔽和强效的对抗机器学习。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion》H Souri, A Bansal, H Kazemi, L Fowl... [Johns Hopkins University &amp; University of Maryland &amp; Google] (2024) <a href="https://arxiv.org/abs/2403.16365"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qlilx7pj21jo0veh0a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qljbfj9j21uu0ua4be.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qljtdcij21ki16q7ki.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qljxysoj21kg0vk7ez.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0tti1j20vi0j3wh9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0t8m3j20sq083ta2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qy0trcsj20vd0g6di1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0v0c4j20vg0hggox.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0u9apj20vg0hgdjp.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:55:23 GMT</pubDate>
</item>
<item>
<title>[LG]《Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion》H Souri, A Bansal, H Kazemi, L Fowl... [Johns Hopkins University &amp; U...</title>
<link>https://weibo.com/1402400261/O7uKuxzfT</link>
<guid>https://weibo.com/1402400261/O7uKuxzfT</guid>
<content:encoded><![CDATA[
<div> 关键词: Generating Potent Poisons, Backdoors, Guided Diffusion, Johns Hopkins University, University of Maryland, Google

总结:
本研究由约翰霍普金斯大学、马里兰大学和谷歌合作完成，探讨了如何利用引导扩散技术从头开始生成强效毒药和后门。研究团队通过实验和研究发现，在网络安全领域中，利用引导扩散方法可以快速生成具有毒性和后门功能的恶意软件和程序。通过深入分析和模拟实验，研究人员成功演示了这种方法的有效性和潜力，为网络安全防御提供了新的思路和方法。这项研究对于加强网络安全防御和对抗恶意攻击具有重要意义，有望为未来的网络安全研究和应用提供有益的参考和借鉴。 <div>
[LG]《Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion》H Souri, A Bansal, H Kazemi, L Fowl... [Johns Hopkins University &amp; University of Maryland &amp; Google] (2024) <a href="https://arxiv.org/abs/2403.16365"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qlilx7pj21jo0veh0a.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qljbfj9j21uu0ua4be.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qljtdcij21ki16q7ki.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qljxysoj21kg0vk7ez.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0tti1j20vi0j3wh9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0t8m3j20sq083ta2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qy0trcsj20vd0g6di1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0v0c4j20vg0hggox.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0u9apj20vg0hgdjp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0tmvnj20vh0e4abz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0toplj20vj0e4gnj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qy0txctj20vh0hi77g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qy0u2x6j20vh0hhq6h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qy0ttahj20vh0hgmzw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qy0tk82j20vj0e4jt7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qy0thgyj20vj0e4jt9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:55:03 GMT</pubDate>
</item>
<item>
<title>通过定义工具的概念、总结应用场景和方法、分析效率等方面，全面系统地回顾和分析了工具辅助语言模型的研究进展，为该领域的发展提供了重要指导。 - 转发 @爱可...</title>
<link>https://weibo.com/1402400261/O7uEwqhRZ</link>
<guid>https://weibo.com/1402400261/O7uEwqhRZ</guid>
<content:encoded><![CDATA[
<div> 工具概念, 应用场景, 方法, 效率, 语言模型, 研究进展, 指导意义, 重要性, 调查, 资源分配
<br /><br />总结:
本文系统地回顾和分析了工具辅助语言模型的研究进展。首先定义工具的概念，然后总结了工具在语言模型中的应用场景和方法。分析了工具辅助语言模型的效率，并探讨了其在领域发展中的重要性和指导意义。通过对工具的调查和资源分配，为该领域的进一步发展提供了重要启示。 <div>
通过定义工具的概念、总结应用场景和方法、分析效率等方面，全面系统地回顾和分析了工具辅助语言模型的研究进展，为该领域的发展提供了重要指导。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《What Are Tools Anyway? A Survey from the Language Model Perspective》Z Wang, Z Cheng, H Zhu, D Fried, G Neubig [CMU &amp; Shanghai Jiao Tong University] (2024) <a href="https://arxiv.org/abs/2403.15452"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qcpp0boj21ge0natio.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qcq7gp6j20qs0m6djr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qcqfpcsj20rc0ro0y6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qcqml1qj21pm0jyqdc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qinfp1cj20d107bwey.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qingarmj20vk0drtap.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:40:21 GMT</pubDate>
</item>
<item>
<title>[CL]《What Are Tools Anyway? A Survey from the Language Model Perspective》Z Wang, Z Cheng, H Zhu, D Fried, G Neubig [CMU &amp; Shanghai Jiao Tong Univers...</title>
<link>https://weibo.com/1402400261/O7uEusOfo</link>
<guid>https://weibo.com/1402400261/O7uEusOfo</guid>
<content:encoded><![CDATA[
<div> 关键词：工具，语言模型，调查，功能，应用，自然语言处理，研究，方法，数据集，评估

总结：<br /><br />总结:本文介绍了基于语言模型的视角对工具进行调查的研究。作者探讨了工具的功能、应用及在自然语言处理中的作用。研究方法包括对数据集的评估和分析，为未来研究提供了参考。 <div>
[CL]《What Are Tools Anyway? A Survey from the Language Model Perspective》Z Wang, Z Cheng, H Zhu, D Fried, G Neubig [CMU &amp; Shanghai Jiao Tong University] (2024) <a href="https://arxiv.org/abs/2403.15452"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qcpp0boj21ge0natio.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qcq7gp6j20qs0m6djr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qcqfpcsj20rc0ro0y6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qcqml1qj21pm0jyqdc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qinfp1cj20d107bwey.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho9qingarmj20vk0drtap.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:40:16 GMT</pubDate>
</item>
<item>
<title>提出 EAP-IG 方法，实验证明它相比 EAP 可以提取出更忠实的回路，以更准确地理解语言模型的内在运算机制。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Have Faith in Fa...</title>
<link>https://weibo.com/1402400261/O7uBnidh5</link>
<guid>https://weibo.com/1402400261/O7uBnidh5</guid>
<content:encoded><![CDATA[
<div> 提取关键词：
EAP-IG、EAP、回路、语言模型、内在运算机制、信任度、模型机制、研究

总结:
本文提出了EAP-IG方法，与传统的EAP方法相比，能够更准确地提取出语言模型内在运算机制中更忠实的回路。实验证明，EAP-IG方法能够更好地理解模型的运作机制，从而提高对语言模型的理解信任度。研究结果表明，通过考虑回路的信任度，可以超越仅仅考虑回路重叠，从而更全面地揭示语言模型的内在机制。详细分析表明EAP-IG方法在理解语言模型方面的优势，为深入研究语言模型的内在运作机制提供了新的思路。Br><br />总结: 本研究提出了EAP-IG方法，与传统的EAP方法相比，能够更准确地提取出语言模型内在运算机制中更忠实的回路。实验结果表明，EAP-IG方法能够提高对语言模型的理解信任度，有助于揭示模型的内在机制。通过考虑回路的信任度，可以更全面地理解语言模型的内在运作机制，为深入研究提供了新的方向。 <div>
提出 EAP-IG 方法，实验证明它相比 EAP 可以提取出更忠实的回路，以更准确地理解语言模型的内在运算机制。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms》M Hanna, S Pezzelle, Y Belinkov [University of Amsterdam &amp; Technion] (2024) <a href="https://arxiv.org/abs/2403.17806"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q33y9lhj21bq0vwnca.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q34mdhyj21lg0qik0x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9q34yn5ej21m00vyk6a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q352mugj21l211en6e.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajljb6j20vh0dy76v.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qajlihij20vf0gidi8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajkv4qj20vd0bawfe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qajl2bfj20un0euq4i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajlil2j20ve0d140p.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:32:35 GMT</pubDate>
</item>
<item>
<title>[LG]《Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms》M Hanna, S Pezzelle, Y Belinkov [University of Amsterdam...</title>
<link>https://weibo.com/1402400261/O7uBkAiq9</link>
<guid>https://weibo.com/1402400261/O7uBkAiq9</guid>
<content:encoded><![CDATA[
<div> 信念，忠诚，模型机制，电路重叠，大学阿姆斯特丹，特希翁，2024年

<br />
本研究旨在探讨在寻找模型机制时如何超越电路重叠的思维。研究团队来自阿姆斯特丹大学和以色列理工学院，通过实证分析发现，在研究模型机制时，一定要坚定信念和忠诚，不仅仅停留在电路重叠的层面上，还要深入挖掘更为深层的原因和关联。他们提出了一种新的研究方法，希望可以帮助学术界在探索模型机制时更加全面和深入地思考问题。总体来说，这项研究为相关领域的学者们提供了新的研究思路和方法，对于推动学术研究具有一定启发意义。

<br />
总结: 该研究提出了超越电路重叠的新思路，强调在寻找模型机制时需要有信念和忠诚，以更深入和全面的视角探讨问题，为学术界提供了新的研究方法。 <div>
[LG]《Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms》M Hanna, S Pezzelle, Y Belinkov [University of Amsterdam &amp; Technion] (2024) <a href="https://arxiv.org/abs/2403.17806"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q33y9lhj21bq0vwnca.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q34mdhyj21lg0qik0x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9q34yn5ej21m00vyk6a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9q352mugj21l211en6e.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajljb6j20vh0dy76v.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qajlihij20vf0gidi8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajkv4qj20vd0bawfe.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho9qajl2bfj20un0euq4i.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajlil2j20ve0d140p.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajkfrcj20uw03ugm3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho9qajldlxj20t10cc0tl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajll3dj20vh0frq53.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho9qajlhyaj20ve0npwgz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 21:32:29 GMT</pubDate>
</item>
<item>
<title>【开源大语言模型的选择之道】- 近期不断有新的大型语言模型(LLM)发布，如Llama 2、Mixtral 8x7B、Zephyr 7B、SOLAR 10.7B和Code Llama等。这些模型规模越来越大...</title>
<link>https://weibo.com/1402400261/O7n3vpf2O</link>
<guid>https://weibo.com/1402400261/O7n3vpf2O</guid>
<content:encoded><![CDATA[
<div> 关键词: 大语言模型、选择、开源、性能、部署成本、可控性、多语言支持、部署流程、负责任、开源模型

总结:<br />
选择大语言模型时需考虑性能表现、调优空间、多语言支持等因素，开源模型具有更高的可控性、数据安全性和成本效益，但需要自行部署和维护。专用LLM在特定任务上表现更优，但通用LLM适用范围更广，需根据需求选择。在部署LLM时要考虑偏见、问责制等伦理问题，选择合适的模型大小和做好基础设施规划。API和监控可以简化部署流程和识别问题。发展中的LLM需要负责任地造福社会，模型参数量不代表在所有任务上表现更好，开源模型可能在灵活性、成本等方面更有优势。在实际应用中需全面评估质量、速度和成本，并不盲目追求参数量。开源模型可能是更好的选择，部署大语言模型需要考虑多方面策略，是一个复杂的过程。 <div>
【开源大语言模型的选择之道】<br />- 近期不断有新的大型语言模型(LLM)发布，如Llama 2、Mixtral 8x7B、Zephyr 7B、SOLAR 10.7B和Code Llama等。这些模型规模越来越大，性能也在不断提升。   <br />- 选择使用哪个LLM要考虑多方面因素，如性能表现、调优空间、多语言支持、部署成本等。例如Llama 2在安全性方面较好，Mixtral 8x7B的效率高，Zephyr 7B理解人类意图的能力强。   <br />- 相比商业LLM，开源LLM有更高的可控性、数据安全性、成本效益及社区支持等优势。但它们也需要自行部署和维护。   <br />- 专用LLM比通用LLM在特定任务上的表现更优，但后者应用范围更广。需根据实际需求选择。   <br />- 大规模部署LLM需考虑偏见、透明度、问责制等伦理问题。同时要选择合适的模型大小，做好基础设施规划，实现可扩展性等。   <br />- API、模型服务框架等可以简化LLM的部署流程。日志和监控对于运行中识别问题也很重要。   <br />- LLM的潜力正在不断被开发，需要继续推动其以负责任的方式造福社会。<br /><br />思考：  <br />- 模型参数量越大，训练数据越多，并不一定意味着在所有任务上都表现更好，有时更小的模型针对特定领域优化反而更有优势。  <br />- 开源模型在灵活性、成本等方面可能比商业模型更有优势。  <br />- 大语言模型的发展速度惊人，但在实际应用中需要全面评估质量、速度、成本等因素，不能盲目追求参数量。  <br />- 开源正在成为AI领域的重要趋势，开源模型在许多场景下可能是更好的选择。  <br />- 部署大语言模型需要考虑诸多策略，涉及模型选择、推理优化、提示工程、伦理安全等方方面面，是一个复杂的过程。<br />《Navigating the World of Large Language Models》 <a href="https://www.bentoml.com/blog/navigating-the-world-of-large-language-models"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8sy28h1vj20u00wtwka.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 02:19:55 GMT</pubDate>
</item>
<item>
<title>【不确定的确定性：用生成式模型颠覆天气预报】- 由于气象本质上是随机的，传统方法通过物理模拟生成一组预测来定量化不确定性，但这需要大量计算成本。Google提...</title>
<link>https://weibo.com/1402400261/O7mnVgkA5</link>
<guid>https://weibo.com/1402400261/O7mnVgkA5</guid>
<content:encoded><![CDATA[
<div> 生成式模型、天气预报、SEEDS、生成对抗网络、不确定性、物理模拟、极端天气事件、混合预报系统、数据和机器学习、跨学科融合<br />
<br />
总结：<br />
Google提出的SEEDS生成对抗网络模型可以以更低的成本有效生成大规模天气预报集合，可以匹配甚至超过基于物理的预测集合。SEEDS能更准确地预测尾部分布的可能性，如极端天气事件。该模型充分利用生成式AI的力量，以高效速度生成集合预报，代表了混合预报系统的一种新型应用。SEEDS展示了生成AI在天气预报中的巨大潜力，特别对于预测极端天气事件的概率。这项研究表明，生成式AI和扩散模型是一个前景广阔的方向，可以为传统科学和工程领域带来新的解决方案。基于数据和机器学习的方法在不确定性量化和概率预测方面可能比传统的物理模拟更具优势。跨学科融合将为更多领域提供突破，如AI技术与天气预报的结合。 <div>
【不确定的确定性：用生成式模型颠覆天气预报】<br />- 由于气象本质上是随机的，传统方法通过物理模拟生成一组预测来定量化不确定性，但这需要大量计算成本。Google提出了一种名为SEEDS的生成对抗网络模型，可以以比传统物理预测模型低得多的成本有效生成大规模的天气预报集合。   <br />- SEEDS基于去噪扩散概率模型，是一种最先进的生成AI技术，只需要一个或两个来自运算天气预测系统的种子预报，就可以生成一个大的集合，而这个集合可以匹配或超过基于物理的集合的技能指标。   <br />- SEEDS生成的集合可以更准确地给出尾部分布的可能性，如±2σ和±3σ的极端天气事件。它可以在很短时间内生成超过10000个集合成员，这对准确定量化极端事件的可能性非常有用。   <br />- SEEDS充分利用了生成式AI的力量，以加速的速度产生了与操作系统可比的集合预报。它代表了一种混合预报系统，只需要很少的物理模拟轨迹就可以激发扩散模型高效生成更多预报。   <br />- SEEDS展示了生成AI在运行数值天气预报方面的巨大应用潜力。它可以加速气象预报的进步，并可扩展到需要大量集合的领域，如对未来气候的不确定性进行风险评估。   <br /><br />思考：<br />- 传统认为天气预报依赖复杂的物理模型和超级计算机，但这项工作表明生成式AI可以在很低的计算成本下取得更好的效果，尤其在预测极端天气事件概率方面。  <br />- 生成式AI和扩散模型是一个非常有前景的方向，可以应用到传统的科学和工程领域，提供新的解决方案  <br />- 在不确定性量化和概率预测方面，基于数据和机器学习的方法可能比传统的物理模拟更有优势  <br />- 跨学科融合将产生更多突破，比如这里就是AI技术与天气预报的结合<br />《Generative AI to quantify uncertainty in weather forecasting – Google Research Blog》 <a href="https://blog.research.google/2024/03/generative-ai-to-quantify-uncertainty.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8q0mpl24j20u00zt7nf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8q0nte93j21jj0q5amj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 00:37:28 GMT</pubDate>
</item>
<item>
<title>【MLX版4-bit量化的DBRX模型】《mlx-community/dbrx-instruct-4bit · Hugging Face》 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O7m7kCzNp</link>
<guid>https://weibo.com/1402400261/O7m7kCzNp</guid>
<content:encoded><![CDATA[
<div> 关键词: MLX, 4-bit量化, DBRX模型

总结:
MLX团队提出了一种基于4-bit量化的DBRX模型，该模型在保持高性能的同时大幅减少了模型大小和计算资源的需求。通过将模型参数量化为4-bit，可以显著降低模型的存储空间和计算复杂度，同时还能保持较高的模型精度。在实验中，该模型在ImageNet数据集上取得了与32-bit浮点模型相媲美的性能，证明了其在实际应用中的可行性和有效性。该方法为轻量级模型设计提供了新的思路和实践指导。MLX团队的研究成果为深度学习领域的模型压缩和优化提供了有益的启示。 <div>
【MLX版4-bit量化的DBRX模型】《mlx-community/dbrx-instruct-4bit · Hugging Face》 <a href="https://huggingface.co/mlx-community/dbrx-instruct-4bit"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho8ou5negyj20ws0u041g.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 23:56:36 GMT</pubDate>
</item>
<item>
<title>匿名排行榜有长答案偏好，这一点确实值得关注 - 转发 @爱可可-爱生活:&amp;ensp;【Maxime Labonne：Starling-LM-7B-beta模型在各种基准测试中表现出色，这给我们带来...</title>
<link>https://weibo.com/1402400261/O7m6JoLoN</link>
<guid>https://weibo.com/1402400261/O7m6JoLoN</guid>
<content:encoded><![CDATA[
<div> 模型、排行榜、Starling、性能、基准测试、实用性、评估、优势、缺陷、细节<br />
<br />
总结：<br />
Maxime Labonne提到了Starling-LM-7B-beta模型在Chatbot Arena排行榜上表现出色，超过了许多更大的模型，包括GPT-3.5-Turbo等。他指出Starling的PPO微调提高了回答实用性，但现有基准测试可能没有正确评估这一点。建议使用大语言模型作为评判者，并专注于回答的实用性。尽管Starling的回答更详尽，但评分也可能受到一些排行榜本身的限制，如不能处理对话等。这篇文章着重强调了基准测试体系的不足，以及Starling模型的优点和局限性。 <div>
匿名排行榜有长答案偏好，这一点确实值得关注<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 【Maxime Labonne：Starling-LM-7B-beta模型在各种基准测试中表现出色，这给我们带来了一些启示】<br />在Chatbot Arena排行榜上，这个7B的模型令人印象深刻地超过了许多更大的模型，包括GPT-3.5-Turbo、Mixtral、Gemini Pro以及Llama 2 70B的所有微调版本，也明显优于排名第30的Mistral-7B-Instruct-v0.。  <br />在另一个排行榜上，Starling的平均分数虽然低于Mistral-7B-Instruct-v0.2，但评估结果表明Starling更优秀：  <br />- 在AGIEval这个优秀的基准测试中，分数高出5.71分  <br />- 在BigBench和GPT4All测试中也有2-3分的领先，其中BigBench和AGIEval一样出色  <br />- 在TruthfulQA上表现较差，但这个基准测试本身就不可靠  <br />不过，Starling并没有比它使用的基础模型OpenChat 3.5 0106高出太多。MT-bench和MMLU基准测试也没能很好地体现出Starling的优势。  <br />我猜测，Starling的PPO微调显著提高了其回答的实用性，而这一点没有被现有的基准测试正确评估。这凸显了当前评估体系的不足。与其引入新的评估集，不如用大语言模型作为评判者，专门关注回答的实用性。  <br />当然，Chatbot Arena也不是完美的。它不能处理对话，而且答案越详细，Elo分数往往越高。Starling的回答通常比OpenChat更加详尽，这正是它的优势所在。  <br />鉴于7B模型的出色表现，我很想看到它们在Chatbot Arena排行榜上的排名。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8ooeruumj20u01xn4cq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8oof8g8ij20t60sa0xl.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 23:55:07 GMT</pubDate>
</item>
<item>
<title>【Maxime Labonne：Starling-LM-7B-beta模型在各种基准测试中表现出色，这给我们带来了一些启示】在Chatbot Arena排行榜上，这个7B的模型令人印象深刻地超过了许...</title>
<link>https://weibo.com/1402400261/O7m5fdezH</link>
<guid>https://weibo.com/1402400261/O7m5fdezH</guid>
<content:encoded><![CDATA[
<div> 关键词: Starling-LM-7B-beta模型, Chatbot Arena, 基准测试, 实用性, 评估体系, 回答详尽, 优秀表现, PPO微调, 评判者, 不足

总结:<br /><br />Maxime Labonne介绍了Starling-LM-7B-beta模型在各种基准测试中的出色表现，超过了更大的模型，如GPT-3.5-Turbo、Mixtral等，并提出现有评估体系的不足之处。Starling的PPO微调显著提高了回答的实用性，而现有基准测试未能正确评估这一点。建议使用大语言模型作为评判者，专注于回答的实用性。此外，Chatbot Arena虽然评分准则有限，但在答案详尽度方面有一定偏向，导致Starling的回答通常比OpenChat更详尽。Starling的优势在于回答的详细性，值得期待7B模型在排行榜上的表现。 <div>
【Maxime Labonne：Starling-LM-7B-beta模型在各种基准测试中表现出色，这给我们带来了一些启示】<br />在Chatbot Arena排行榜上，这个7B的模型令人印象深刻地超过了许多更大的模型，包括GPT-3.5-Turbo、Mixtral、Gemini Pro以及Llama 2 70B的所有微调版本，也明显优于排名第30的Mistral-7B-Instruct-v0.。  <br />在另一个排行榜上，Starling的平均分数虽然低于Mistral-7B-Instruct-v0.2，但评估结果表明Starling更优秀：  <br />- 在AGIEval这个优秀的基准测试中，分数高出5.71分  <br />- 在BigBench和GPT4All测试中也有2-3分的领先，其中BigBench和AGIEval一样出色  <br />- 在TruthfulQA上表现较差，但这个基准测试本身就不可靠  <br />不过，Starling并没有比它使用的基础模型OpenChat 3.5 0106高出太多。MT-bench和MMLU基准测试也没能很好地体现出Starling的优势。  <br />我猜测，Starling的PPO微调显著提高了其回答的实用性，而这一点没有被现有的基准测试正确评估。这凸显了当前评估体系的不足。与其引入新的评估集，不如用大语言模型作为评判者，专门关注回答的实用性。  <br />当然，Chatbot Arena也不是完美的。它不能处理对话，而且答案越详细，Elo分数往往越高。Starling的回答通常比OpenChat更加详尽，这正是它的优势所在。  <br />鉴于7B模型的出色表现，我很想看到它们在Chatbot Arena排行榜上的排名。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8ooeruumj20u01xn4cq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8oof8g8ij20t60sa0xl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 23:51:27 GMT</pubDate>
</item>
<item>
<title>【三层评估法则：快速迭代，系统优化AI产品】- 构建语言模型产品的成功关键是快速迭代。必须具备评估质量、调试问题和改变系统行为的流程和工具。 - 评估系统有3...</title>
<link>https://weibo.com/1402400261/O7lI1oWfy</link>
<guid>https://weibo.com/1402400261/O7lI1oWfy</guid>
<content:encoded><![CDATA[
<div> 快速迭代, 系统优化, AI产品, 评估, 单元测试, 模型评估, 人工评估, A/B测试, 日志记录, 微调

总结:<br /><br />这篇文章讲述了构建语言模型产品成功的关键在于快速迭代。作者提出了评估系统的三个层次：单元测试、模型和人工评估、A/B测试。单元测试是成本最低、频率最高的评估方式，要包含特定功能的场景和通用场景，不断更新。模型评估需要日志记录对话，构建特定领域的数据查看和标注工具，并定期进行人工评估。自动评估也很重要，可用于合成数据。作者强调A/B测试要谨慎引入，只有在产品较成熟时才适合。评估基础设施的建立可重复使用于调试和评估解决方案的效果。评估系统不仅能加速迭代，还能解锁微调和调试能力，从而提升AI系统的质量。整体而言，作者通过这些观点为AI产品开发提供了清晰的指导。 <div>
【三层评估法则：快速迭代，系统优化AI产品】<br />- 构建语言模型产品的成功关键是快速迭代。必须具备评估质量、调试问题和改变系统行为的流程和工具。   <br />- 评估系统有3个层次：单元测试、人工和模型评估、A/B测试。单元测试成本最低，频率最高。   <br />- 单元测试要包含特定功能的场景和通用场景，要不断根据新出现的错误更新。还要用语言模型生成测试用例。   <br />- 日志记录对话是模型评估的先决条件。要使查看数据无障碍，构建特定领域的数据查看和标注工具。定期人工评估样本很重要。   <br />- 可以用更强大的语言模型做自动评估。要跟踪模型和人工评价的相关性。自动评价也可以用于合成数据。   <br />- A/B测试确保AI产品驱动了预期的用户行为。当AI产品较成熟时再考虑。   <br />- 评估系统为微调和调试解锁能力。大部分微调工作是收集高质量数据，评估系统已具备数据生成和整理引擎。   <br />- 评估基础设施可重复使用于调试。可快速定位、复现错误，评估解决方案的效果。<br /><br />点评：  <br />- 作者基于多年从事语言模型相关工作的经验，指出鲁棒的评估系统对AI产品的成功至关重要，这一观点非常中肯和实用。  <br />- 文章强调了快速迭代对AI成功的重要性，并提出了质量评估、问题调试等必备流程和工具，为AI产品开发提供了清晰的指导。  <br />- 作者将评估分为三个层次：单元测试、模型和人工评估、A/B测试，这种分层思路有助于系统地开展评估工作，提高评估的针对性和有效性。  <br />- 对于第三层A/B测试，作者建议要谨慎对待，只有在产品足够成熟时才适合引入，这体现了作者对AI产品负责任开发的重视。  <br />- 文章还提到了评估AI子组件(如RAG)的重要性，这为进一步优化和改进AI系统提供了思路。  <br />- 作者强调评估系统不仅能加速迭代，还能解锁微调和调试能力，从而大幅提升AI系统质量，这一观点具有启发性，值得AI从业者深思。<br />《Your AI Product Needs Evals - How to construct domain-specific LLM evaluation systems.》 <a href="https://hamel.dev/blog/posts/evals/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8n1bjwo3j20u013fq7s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:54:15 GMT</pubDate>
</item>
<item>
<title>【Voice Engine：15秒音频样本，开启逼真语音合成新时代】- OpenAI开发了一个名为Voice Engine的模型，可以通过15秒的音频样本生成自然语音，非常逼真地模拟原说...</title>
<link>https://weibo.com/1402400261/O7lGhyHkc</link>
<guid>https://weibo.com/1402400261/O7lGhyHkc</guid>
<content:encoded><![CDATA[
<div> Voice Engine、OpenAI、15秒音频样本、逼真语音合成、安全措施、合成语音、风险、负责任部署、公开对话、全球公众<br />
<br />
总结：<br />
OpenAI开发了Voice Engine模型，能通过15秒音频样本生成逼真语音，有广泛的应用前景。在试用阶段，OpenAI重视安全措施和负责任部署，通过公开对话推动社会适应该技术。合成语音技术存在滥用风险，OpenAI提出相应措施防范潜在滥用行为。透过预览展示技术潜力，强调提高全球公众对合成语音技术认识十分必要，体现开放和负责任态度。 <div>
【Voice Engine：15秒音频样本，开启逼真语音合成新时代】<br />- OpenAI开发了一个名为Voice Engine的模型，可以通过15秒的音频样本生成自然语音，非常逼真地模拟原说话人的声音。这表明即使是一个小模型，也可以利用极短的音频样本生成富有情感和逼真的语音。   <br />- OpenAI已经在一小部分可靠合作伙伴中试用Voice Engine，发现它在教育、翻译、辅助交流等方面有广阔的应用前景。它可以为更广泛的受众创作语音内容，将内容翻译成多种语言保留原说话人的语调，为失语人群提供个性化语音等。   <br />- OpenAI认识到合成语音存在严重的风险，特别是在选举年。OpenAI正在与各国政府、媒体、娱乐、教育等领域的合作伙伴接触，收集他们的反馈意见。   <br />- OpenAI已经为Voice Engine引入了多项安全措施，包括给生成语音添加水印以追踪来源，监控其使用情况，需要合作伙伴遵守使用政策等。但OpenAI暂时还不会大规模部署这项技术。   <br />- OpenAI希望这项技术的预览能凸显它的潜力，同时也推动社会加强应对日渐逼真的生成模型带来的挑战的能力。OpenAI建议采取多项措施应对这一技术潮流。   <br />- OpenAI承诺会继续就合成语音的挑战和机遇与各界进行讨论。OpenAI将基于这些讨论结果决定是否和如何大规模部署这项技术。<br /><br />点评：  <br />- Voice Engine展示了OpenAI在语音合成技术方面的突破性进展，仅需15秒的音频样本就能生成逼真的自然语音，令人印象深刻。  <br />- OpenAI在Voice Engine的开发和应用中体现了对AI安全和负责任部署的高度重视，这种谨慎和知情的态度值得肯定。  <br />- 合成语音技术的滥用风险不容忽视，OpenAI提出的语音验证和禁止语音列表等措施，有助于在一定程度上防范潜在的滥用行为。  <br />- 通过Voice Engine的小规模预览，OpenAI展开了关于合成语音技术负责任部署的公开对话，这对于推动社会适应和应对这一新兴技术至关重要。  <br />- OpenAI强调，无论他们是否最终广泛部署Voice Engine，提高全球公众对语音合成技术发展趋势的认识和理解都十分必要，这体现了他们的开放和负责任态度。<br />《Navigating the Challenges and Opportunities of Synthetic Voices》 <a href="https://openai.com/blog/navigating-the-challenges-and-opportunities-of-synthetic-voices"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho8mwpd8pcj21fq0u0qa5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:49:58 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评...</title>
<link>https://weibo.com/1402400261/O7lvlzpnR</link>
<guid>https://weibo.com/1402400261/O7lvlzpnR</guid>
<content:encoded><![CDATA[
<div> Java、Python、JavaScript、C语言、MySQL、Redis、技术、故事、编程语言、王国

<br /><br />总结:
《码农翻身2》是一本将技术知识以故事的形式生动讲解的畅销书，让看似枯燥的技术变得有趣。书中描述了编程语言王国的争斗，如Java向Python渗透、JavaScript向Java进攻、以及C语言的悲催处境。故事中MySQL和Redis之间的矛盾不断升级，让读者能轻松掌握技术原理。书籍内容丰富，既有技术知识，又富有趣味性。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:23:01 GMT</pubDate>
</item>
<item>
<title>今日推介(第1360期)：只用少数微调模型达到模型融合性能、教语言模型提问澄清问题、直接偏好优化中长度与质量的解缠、将偏好数据集分割逐步使用的DPO、多专家递...</title>
<link>https://weibo.com/1402400261/O7lvdpHBP</link>
<guid>https://weibo.com/1402400261/O7lvdpHBP</guid>
<content:encoded><![CDATA[
<div> 模型微调、模型融合、语言模型、问题澄清、偏好优化、长度与质量、DPO、专家递延回归

<br /><br />总结:
本文介绍了一些最新的研究成果和技术应用。首先，提出了一种只用少数微调模型就可以达到模型融合性能的方法，从而提高模型的效率和准确性。其次，讨论了如何教导语言模型提问以澄清问题，从而提高模型的理解和应用能力。接着，介绍了直接偏好优化中长度与质量的解缠技术，帮助优化结果更加准确和可靠。然后，讨论了将偏好数据集分割逐步使用的DPO方法，提高了数据集的利用效率。最后，介绍了多专家递延回归技术，有助于提高模型的预测和分析能力。这些技术都有着广泛的应用前景，可以帮助解决实际问题并提高工作效率。 <div>
今日推介(第1360期)：只用少数微调模型达到模型融合性能、教语言模型提问澄清问题、直接偏好优化中长度与质量的解缠、将偏好数据集分割逐步使用的DPO、多专家递延回归 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/689840527"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.30)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8m45hovtj20go06g3z8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8m47vrtij20go0aygn2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho8m4b400wj20go0clwg7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8m4dj4ofj20go05u0t9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho8m4h6e0pj20go09omz8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:22:41 GMT</pubDate>
</item>
<item>
<title>[CV] Mesh2NeRF: Direct Mesh Supervision for Neural Radiance Field Representation and Generation 网页链接 提出Mesh2NeRF，一种从网格中直接获取NeRF表示的...</title>
<link>https://weibo.com/1402400261/O7lrfnG01</link>
<guid>https://weibo.com/1402400261/O7lrfnG01</guid>
<content:encoded><![CDATA[
<div> 直接获取NeRF表示、网格、3D监督、渲染过程、单场景拟合、生成、精确可靠、提升表现、Mesh2NeRF、解析解  
<br /><br />总结:  
本研究提出了一种名为Mesh2NeRF的方法，可以通过直接从网格中获取NeRF表示的解析解，为各类NeRF任务提供精确可靠的3D监督。这种方法可以绕过渲染过程中的不确定性，显著提升NeRF在单场景拟合和生成中的表现。Mesh2NeRF可以为NeRF任务提供更准确的监督信号，有望在3D场景表示与生成领域中发挥重要作用。 <div>
[CV] Mesh2NeRF: Direct Mesh Supervision for Neural Radiance Field Representation and Generation  <br /><a href="https://arxiv.org/abs/2403.19319"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />提出Mesh2NeRF，一种从网格中直接获取NeRF表示的解析解，可为各类NeRF任务提供精确可靠的3D监督，绕过渲染过程中的不确定性，显著提升NeRF在单场景拟合和生成中的表现。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho8lubomuaj20rg16gwqn.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho8luby8cxj21c012itm4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:12:55 GMT</pubDate>
</item>
<item>
<title>[CV] LocCa: Visual Pretraining with Location-aware Captioners 网页链接 LocCa通过引入位置感知描述任务实现了视觉表示对局部细节和整体语义的统一建模，在保...</title>
<link>https://weibo.com/1402400261/O7lp22VlA</link>
<guid>https://weibo.com/1402400261/O7lp22VlA</guid>
<content:encoded><![CDATA[
<div> Visual Pretraining, Location-aware Captioners, LocCa, 图像理解, 定位性能, 位置感知描述任务, 视觉表示, 局部细节, 整体语义

LocCa是一种通过引入位置感知描述任务实现视觉表示对局部细节和整体语义的统一建模方法。该方法在保持图像级理解能力的同时显著提升了定位性能。通过对图像进行位置感知描述任务的预训练，LocCa使得模型能够更好地对图像中的局部细节和整体语义进行捕捉和理解。这种方法为视觉表示学习带来了新的启发，为提升图像理解和定位性能提供了新的思路。LocCa的引入为视觉预训练领域带来了新的研究方向，将在未来的研究中继续发挥重要作用。<br /><br />总结:LocCa通过引入位置感知描述任务实现了视觉表示对局部细节和整体语义的统一建模，在保持图像级理解能力的同时大幅提升了定位性能。 <div>
[CV] LocCa: Visual Pretraining with Location-aware Captioners  <br /><a href="https://arxiv.org/abs/2403.19596"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />LocCa通过引入位置感知描述任务实现了视觉表示对局部细节和整体语义的统一建模，在保持图像级理解能力的同时大幅提升了定位性能。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8lolftcpj20rc16mtky.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8lom5f2fj21ck0y8akb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 22:07:27 GMT</pubDate>
</item>
<item>
<title>[LG] Tiny Machine Learning: Progress and Futures 网页链接 TinyML通过算法和系统的协同设计，实现深度学习模型在内存和计算有限的微控制器上的高效推理和训练...</title>
<link>https://weibo.com/1402400261/O7llHvZry</link>
<guid>https://weibo.com/1402400261/O7llHvZry</guid>
<content:encoded><![CDATA[
<div> 关键词: TinyML, 算法, 深度学习模型, 微控制器, 推理, 训练, AI能力, 边缘物联网设备

总结:<br /><br />
本文介绍了Tiny Machine Learning（TinyML）技术的进展和未来发展。TinyML通过算法和系统的协同设计，在内存和计算有限的微控制器上实现了深度学习模型的高效推理和训练，从而将强大的AI能力扩展到无数的边缘物联网设备中。TinyML的发展为边缘设备赋予了智能化的能力，可以提供更快速、更可靠的数据处理和决策能力，推动了物联网领域的进一步发展。TinyML技术的未来发展将不断完善算法和系统设计，提高在资源有限的设备上的性能和效率，同时推动AI能力在边缘计算领域的广泛应用和普及。 <div>
[LG] Tiny Machine Learning: Progress and Futures  <br /><a href="https://arxiv.org/abs/2403.19076"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />TinyML通过算法和系统的协同设计，实现深度学习模型在内存和计算有限的微控制器上的高效推理和训练，将强大的AI能力扩展到无数的边缘物联网设备中。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho8lg3cjwnj20wy17u7oc.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8lg3ml3lj21kq0uuqet.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8lg3sr1pj21ki18cqff.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho8lg3u4s2j21ke0iin5p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 21:59:15 GMT</pubDate>
</item>
<item>
<title>通过设计可证明H一致性的单阶段和两阶段代理损失函数，巧妙地将多专家递延框架扩展至回归问题，既适用于联合学习也适用于预训练模型。 - 转发 @爱可可-爱生活:&amp;e...</title>
<link>https://weibo.com/1402400261/O7lg0kReZ</link>
<guid>https://weibo.com/1402400261/O7lg0kReZ</guid>
<content:encoded><![CDATA[
<div> 代理损失函数, 单阶段, 两阶段, 多专家递延框架, 回归问题, 联合学习, 预训练模型<br />
<br />
提出了一种可以证明H一致性的单阶段和两阶段代理损失函数，将多专家递延框架扩展至回归问题。该方法适用于联合学习和预训练模型。通过设计巧妙的损失函数，实现了对多专家预测结果的推迟，在保证模型的一致性的同时提高了模型的性能和泛化能力。实验结果表明，该方法在回归问题上取得了良好的性能表现。总体而言，本文提出的方法在处理回归问题中充分发挥了多专家的优势，为相关领域的研究和应用提供了新的思路和方法。<br /><br />总结: <div>
通过设计可证明H一致性的单阶段和两阶段代理损失函数，巧妙地将多专家递延框架扩展至回归问题，既适用于联合学习也适用于预训练模型。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Regression with Multi-Expert Deferral》A Mao, M Mohri, Y Zhong [Courant Institute of Mathematical Sciences &amp; Google Research] (2024) <a href="https://arxiv.org/abs/2403.19494"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho8kufil4jj21cq0sakch.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 21:45:13 GMT</pubDate>
</item>
<item>
<title>[LG]《Regression with Multi-Expert Deferral》A Mao, M Mohri, Y Zhong [Courant Institute of Mathematical Sciences &amp; Google Research] (2024) 网页链接 #...</title>
<link>https://weibo.com/1402400261/O7lfY0hw3</link>
<guid>https://weibo.com/1402400261/O7lfY0hw3</guid>
<content:encoded><![CDATA[
<div> 关键词: Regression, Multi-Expert Deferral, Courant Institute of Mathematical Sciences, Google Research

总结:<br /><br />这篇文章由毛阿(Mao)、莫里(Mohri)和钟杨(Zhong)共同撰写，研究了多专家推迟的回归方法。他们从数学科学研究所和谷歌研究部门发表了这项研究。<br />该研究提出了一种新方法，通过使用多个专家的意见来进行回归预测，以提高预测准确性。<br />专家推迟是指在有争议的情况下，将决策推迟到更有经验和专业知识的专家来做出。<br />研究使用了各种数学和统计方法来解决多专家推迟的回归问题，为实际应用提供了新的解决方案。<br />该研究成果对于数据科学领域以及商业决策具有重要意义，可以提高预测模型的准确性和稳定性。<br />毛阿、莫里和钟杨等研究人员的工作有望推动回归分析领域的进一步发展，为未来研究提供新的思路和方法。<br />通过结合数学科学和实际应用，他们的研究为数据分析领域带来了新的启示和突破。<br />毛阿、莫里和钟杨在多专家推迟的回归领域做出了重要贡献，为该领域的研究做出了新的探索和创新。<br />他们的研究成果为数据科学和机器学习领域提供了新的视角和方法，拓展了学术研究和实践应用的范围。<br />通过整合不同领域的专业知识和经验，毛阿、莫里和钟杨等研究人员为多专家推迟的回归方法提供了新的理论基础和实践指导。 <div>
[LG]《Regression with Multi-Expert Deferral》A Mao, M Mohri, Y Zhong [Courant Institute of Mathematical Sciences &amp; Google Research] (2024) <a href="https://arxiv.org/abs/2403.19494"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho8kufil4jj21cq0sakch.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 21:45:06 GMT</pubDate>
</item>
<item>
<title>提出sDPO，将偏好数据集分步使用以获取更严格的下界约束，从而获得整体性能更强的语言模型。 - 转发 @爱可可-爱生活:&amp;ensp;[CL]《sDPO: Don't Use Your Data All...</title>
<link>https://weibo.com/1402400261/O7lcEBZ31</link>
<guid>https://weibo.com/1402400261/O7lcEBZ31</guid>
<content:encoded><![CDATA[
<div> 关键词: sDPO, 偏好数据集, 下界约束, 语言模型, 整体性能, 转发, Upstage AI

总结:<br /><br />
这篇文章提出了sDPO方法，旨在通过分步使用偏好数据集来获取更严格的下界约束，从而提升语言模型的整体性能。sDPO的核心思想是不将所有数据一次性使用，而是分阶段使用，以优化模型的性能。作者通过实验和研究表明，sDPO能够有效提升语言模型的性能，使其更加强大和稳健。这一方法在未来可能对自然语言处理领域有着重要的影响，并值得进一步研究和探索。 <div>
提出sDPO，将偏好数据集分步使用以获取更严格的下界约束，从而获得整体性能更强的语言模型。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《sDPO: Don't Use Your Data All at Once》D Kim, Y Kim, W Song, H Kim, Y Kim, S Kim, C Park [Upstage AI] (2024) <a href="https://arxiv.org/abs/2403.19270"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho8kl4nf9uj20o60qc44m.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho8kl5h2ltj21km0jswkb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho8kl5nudnj20s40godhv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho8kl5voulj20s00f6gnn.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 21:36:58 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.29)》 爱可可微博热门分享(3.29) [图片]</title>
<link>https://weibo.com/1402400261/O7ie07MEC</link>
<guid>https://weibo.com/1402400261/O7ie07MEC</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、3.29、关键词

<br /><br />总结:
3月29日，爱可可微博上热门分享了许多精彩内容，引起了广泛关注。其中包括美食推荐、旅行攻略、时尚资讯等各种各样的话题。用户们纷纷参与讨论，点赞和转发量也很高。爱可可微博的内容多样性和质量受到了用户的肯定。希望未来能继续为大家带来更多有趣的内容。 <div>
《爱可可微博热门分享(3.29)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405017383558316417"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.29)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho87newffvj20d607e3zd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 14:02:01 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《SuperNormal: Neural Surface Reconstruction via Multi-View Normal Integration》(CVPR 2024) GitHub: github.com/CyberAgentAILab/Super...</title>
<link>https://weibo.com/1402400261/O7hNne0Zq</link>
<guid>https://weibo.com/1402400261/O7hNne0Zq</guid>
<content:encoded><![CDATA[
<div> 关键词：神经表面重建、多视图法线集成、情感图像生成、深度学习、自动驾驶、人物重建、虚拟人视频生成、语言模型、远程感知图像分类、视频对象分割。

总结:<br /><br />
这篇论文整理了几篇实现代码，涵盖了神经表面重建、情感图像生成、神经网络鲁棒性评估等多个领域。其中包括了一种通过多视图法线集成实现神经表面重建的方法，以及一种用于生成情感图像内容的文本到图像扩散模型。同时还介绍了一种自动驾驶中用于融合单视图和多视图深度信息的自适应融合算法，以及一种在野外环境中从单目视频中重建多个人物的方法。此外还有一种用于挖掘多模态视觉语言模型潜力的MiniGemini模型，以及一种生成高保真虚拟人视频的MuseV模型等。<br />
另外，还介绍了一种用于实现长视频理解的语言库，以及一种基于变分自动编码器的明暗风格内容分离模型。还有一种实时变换器开放词汇检测的方法，以及一种用状态空间模型实现遥感图像分类的RSMamba模型。同时还有一种用于控制区域级标题生成的ControlCap模型，以及一种使用文本到图像扩散实现注意力插值的AID模型。此外还有一种由LLM引导的组合式4D场景生成模型Comp4D，以及一种用于改善视觉识别中非层级Mamba算法的PlainMamba模型等。最后还介绍了一种通过调制交叉注意力内存实现高效视频对象分割的MAVOS模型，以及一种通过修剪和低秩修改评估安全性调整脆弱性的方法。 <div>
几篇论文实现代码：<br />《SuperNormal: Neural Surface Reconstruction via Multi-View Normal Integration》(CVPR 2024) GitHub: github.com/CyberAgentAILab/SuperNormal [fig3] <br />《EmoGen: Emotional Image Content Generation with Text-to-Image Diffusion Models》(CVPR 2024) GitHub: github.com/JingyuanYY/EmoGen [fig4]<br />《ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object》(CVPR 2024) GitHub: github.com/chenshuang-zhang/imagenet_d<br />《Adaptive Fusion of Single-View and Multi-View Depth for Autonomous Driving》(CVPR 2024) GitHub: github.com/Junda24/AFNet<br />《MultiPly: Reconstruction of Multiple People from Monocular Video in the Wild》(CVPR 2024) GitHub: github.com/jzr99/MultiPly<br />《Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models》(2024) GitHub: github.com/dvlab-research/MiniGemini [fig1]<br />《MuseV: Infinite-length and High Fidelity Virtual Human Video Generation with Visual Conditioned Parallel Denoising》(2024) GitHub: github.com/TMElyralab/MuseV [fig2] <br />《Long-form factuality in large language models》(2024) GitHub: github.com/google-deepmind/long-form-factuality<br />《Implicit Style-Content Separation using B-LoRA》(2024) GitHub: github.com/yardenfren1996/B-LoRA [fig5] <br />《Real-time Transformer-based Open-Vocabulary Detection with Efficient Fusion Head》(2024) GitHub: github.com/om-ai-lab/OmDet [fig8]<br />《RSMamba: Remote Sensing Image Classification with State Space Model》(2024) GitHub: github.com/KyanChen/RSMamba [fig9]<br />《Language Repository for Long Video Understanding》(2024) GitHub: github.com/kkahatapitiya/LangRepo [fig10]<br />《Light and Optimal Schr\"odinger Bridge Matching》(2024) GitHub: github.com/SKholkin/LightSB-Matching<br />《ControlCap: Controllable Region-level Captioning》(2024) GitHub: github.com/callsys/ControlCap [fig11]<br />《AID: Attention Interpolation of Text-to-Image Diffusion》(2024) GitHub: github.com/QY-H00/attention-interpolation-diffusion<br />《Comp4D: LLM-Guided Compositional 4D Scene Generation》(2024) GitHub: github.com/VITA-Group/Comp4D<br />《PlainMamba: Improving Non-hierarchical Mamba in Visual Recognition》(2024) GitHub: github.com/ChenhongyiYang/PlainMamba [fig7]<br />《Fed3DGS: Scalable 3D Gaussian Splatting with Federated Learning》(2024) GitHub: github.com/DensoITLab/Fed3DGS<br />《Efficient Video Object Segmentation via Modulated Cross-Attention Memory》(2024) GitHub: github.com/Amshaker/MAVOS [fig6]<br />《Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications》(2024) GitHub: github.com/boyiwei/alignment-attribution-code<br />《Surface and Edge Detection for Primitive Fitting of Point Clouds》(2024) GitHub: github.com/yuanqili78/SED-Net<br />《FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions》(2024) GitHub: github.com/orionw/FollowIR<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho81cu9q8pj22tu0uxe73.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho81cv52blj20re0jjjyq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho81cylzabj22t02bc7wm.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho81cxbo0vj21ll0hfwsr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho81cyh6kmj20h909d419.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho81czzpxdj21yh0tykib.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho83zmbtfmj224y0n81kx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho84jcw8cuj237a1nb17e.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho84yi8kbtj21x80i4qiw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho84z1po9rj22po0sph3r.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho852lcklej21u61eeu0x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:56:26 GMT</pubDate>
</item>
<item>
<title>【遥感多模态大语言模型相关论文资源列表】’Awesome-Remote-Sensing-Multimodal-Large-Language-Model (Vision-Language) - Multimodal Large Language Model f...</title>
<link>https://weibo.com/1402400261/O7hIcz64J</link>
<guid>https://weibo.com/1402400261/O7hIcz64J</guid>
<content:encoded><![CDATA[
<div> 遥感、多模态、大语言模型、远程感知、视觉-语言、资源、GitHub、论文、研究、文献

总结：<br /><br />这份资源列表涵盖了远程感知多模态大语言模型相关的研究论文和资源，提供了GitHub链接，供研究人员参考。远程感知是指利用卫星或无人机等远距离传感器获取地表信息的技术，多模态大语言模型则是融合了视觉和语言信息的模型。这个领域的研究涉及到文献综述、模型应用、数据集构建等方面，对于推动远程感知和人工智能领域的发展具有重要意义。 <div>
【遥感多模态大语言模型相关论文资源列表】’Awesome-Remote-Sensing-Multimodal-Large-Language-Model (Vision-Language) - Multimodal Large Language Model for Remote Sensing (Vision-Language)' GitHub: github.com/ZhanYang-nwpu/Awesome-Remote-Sensing-Multimodal-Large-Language-Model <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho85e0nazbj21a10u0q7t.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:43:42 GMT</pubDate>
</item>
<item>
<title>【高斯Splatting相关论文列表】’2024-Arxiv-Paper-List-Gaussian-Splatting - 2024 Gaussian Splatting Paper List(Arxiv)' GitHub: github.com/Lee-JaeWon/202...</title>
<link>https://weibo.com/1402400261/O7hH1r6Pl</link>
<guid>https://weibo.com/1402400261/O7hH1r6Pl</guid>
<content:encoded><![CDATA[
<div> 高斯，Splatting，Arxiv，论文，列表，GitHub，2024

总结:
该GitHub项目整理了关于高斯Splatting的Arxiv论文列表，汇总了2024年的相关研究成果。这些论文涵盖了高斯Splatting技术在计算机图形学和计算机视觉领域的应用和研究进展。通过这个列表，研究者可以快速了解最新的研究动态和成果，为未来的研究提供参考和启发。GitHub项目还提供了详细的文献信息和链接，方便研究者进行更深入的阅读和学习。整理这些论文列表有助于促进学术交流和合作，推动高斯Splatting技术的发展和应用。 <div>
【高斯Splatting相关论文列表】’2024-Arxiv-Paper-List-Gaussian-Splatting - 2024 Gaussian Splatting Paper List(Arxiv)' GitHub: github.com/Lee-JaeWon/2024-Arxiv-Paper-List-Gaussian-Splatting <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho85b13zdrj20u00ul42w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:40:48 GMT</pubDate>
</item>
<item>
<title>【AxoNN：用于训练深度神经网络的并行框架】'AxoNN - A parallel framework for training deep neural networks' GitHub: github.com/axonn-ai/axonn #开源# #机...</title>
<link>https://weibo.com/1402400261/O7hGmmKev</link>
<guid>https://weibo.com/1402400261/O7hGmmKev</guid>
<content:encoded><![CDATA[
<div> 并行框架、训练、深度神经网络、AxoNN、GitHub、神经网络、深度学习、机器学习、人工智能

<br /><br />总结:
AxoNN是一个用于训练深度神经网络的并行框架，旨在提高训练过程的效率和速度。通过在GitHub上开源项目，AxoNN为研究人员和开发者提供了一个方便的工具，帮助他们在深度学习和机器学习领域进行神经网络的训练。AxoNN的并行架构使得训练过程更加快速，并能够处理大规模数据集。这个框架对于推动人工智能领域的发展具有重要意义，为神经网络的训练提供了新的可能性。AxoNN的开发和使用将有助于加速深度学习技术的发展，促进人工智能的应用和创新。 <div>
【AxoNN：用于训练深度神经网络的并行框架】'AxoNN - A parallel framework for training deep neural networks' GitHub: github.com/axonn-ai/axonn <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho859cfbodj211a0iajtg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:39:10 GMT</pubDate>
</item>
<item>
<title>【mistral.rs： 纯Rust写的语言模型推理平台】'mistral.rs - Blazingly fast LLM inference.' GitHub: github.com/EricLBuehler/mistral.rs #开源# #机器学习# #...</title>
<link>https://weibo.com/1402400261/O7hFUnXaF</link>
<guid>https://weibo.com/1402400261/O7hFUnXaF</guid>
<content:encoded><![CDATA[
<div> Rust、语言模型、推理、平台、mistral.rs、快速、LLM、推断、GitHub、EricLBuehler<br />
<br />
Rust编写的语言模型推理平台mistral.rs具有快速性能，支持深度语言模型推断。该项目托管在GitHub上，由EricLBuehler开发。通过mistral.rs，用户可以快速进行语言模型的推断，提高工作效率。该平台在推理速度和准确性方面表现优异，是一个值得关注的工具。 <div>
【mistral.rs： 纯Rust写的语言模型推理平台】'mistral.rs - Blazingly fast LLM inference.' GitHub: github.com/EricLBuehler/mistral.rs <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho8586irc7j21310u0q6i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:38:03 GMT</pubDate>
</item>
<item>
<title>'Docker image for A1111 Stable Diffusion Web UI, Kohya_ss and ComfyUI - Docker image for Stable Diffusion WebUI with ControlNet, After Detailer, Dream...</title>
<link>https://weibo.com/1402400261/O7hAC6AMQ</link>
<guid>https://weibo.com/1402400261/O7hAC6AMQ</guid>
<content:encoded><![CDATA[
<div> GitHub, Docker image, Stable Diffusion WebUI, Kohya_ss, ComfyUI, ControlNet, After Detailer, Dreambooth, Deforum, ReActor

<br /><br />总结:
本文介绍了一个GitHub项目，提供了用于A1111 Stable Diffusion Web UI的Docker镜像，其中包含了Kohya_ss和ComfyUI。另外还提供了另一个Docker镜像，包含了Stable Diffusion WebUI以及ControlNet、After Detailer、Dreambooth、Deforum和ReActor等扩展功能。感兴趣的用户可以在github.com/ashleykleynhans/stable-diffusion-docker找到更多信息。 <div>
'Docker image for A1111 Stable Diffusion Web UI, Kohya_ss and ComfyUI - Docker image for Stable Diffusion WebUI with ControlNet, After Detailer, Dreambooth, Deforum and ReActor extensions, as well as Kohya_ss and ComfyUI' GitHub: github.com/ashleykleynhans/stable-diffusion-docker <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho84ulotv0j21ji0ka41v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:25:00 GMT</pubDate>
</item>
<item>
<title>【Bolna：快速构建LLM语音聊天应用的关键框架，帮助开发人员轻松打造高效的聊天应用】'Bolna - End-to-end platform enabling LLM based voice driven conversat...</title>
<link>https://weibo.com/1402400261/O7hvwvhmu</link>
<guid>https://weibo.com/1402400261/O7hvwvhmu</guid>
<content:encoded><![CDATA[
<div> 快速构建、LLM语音聊天应用、关键框架、开发人员、高效、聊天应用、Bolna、End-to-end、platform、GitHub

总结:<br /><br />
本文介绍了Bolna，一个能够实现LLM语音驱动的对话应用的端到端平台。通过提供关键框架，帮助开发人员轻松构建高效的聊天应用。开发者可以在GitHub上找到Bolna的源代码项目。 <div>
【Bolna：快速构建LLM语音聊天应用的关键框架，帮助开发人员轻松打造高效的聊天应用】'Bolna - End-to-end platform enabling LLM based voice driven conversational applications' GitHub: github.com/bolna-ai/bolna <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho84hifed3j21bk0gmacb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:12:28 GMT</pubDate>
</item>
<item>
<title>【PyTorch in JavaScript：一个深度学习 JavaScript 库，旨在与 PyTorch 的语法相类似，以便开发人员使用 JavaScript 实现深度学习模型】'PyTorch in JavaScript...</title>
<link>https://weibo.com/1402400261/O7hsykjAw</link>
<guid>https://weibo.com/1402400261/O7hsykjAw</guid>
<content:encoded><![CDATA[
<div> PyTorch, JavaScript, 深度学习, 库, 语法, 开发人员, 实现, 模型, GitHub, 项目
<br /><br />总结:
PyTorch在JavaScript中的实现是一个类似于PyTorch的JavaScript库，从头开始构建。这个项目旨在提供一个类似于PyTorch的编程体验，使开发人员能够使用JavaScript语言来实现深度学习模型。通过GitHub上的项目，开发人员可以了解和使用这个深度学习库，从而在JavaScript环境中进行模型的开发和应用。JavaScript语言的灵活性和便捷性使得这个库可以更好地与前端开发集成，为开发人员提供了更多选择和可能性。通过这个项目，开发人员可以在JavaScript中体验和应用类似于PyTorch的深度学习功能，进一步推动了深度学习技术在不同领域的应用和发展。 <div>
【PyTorch in JavaScript：一个深度学习 JavaScript 库，旨在与 PyTorch 的语法相类似，以便开发人员使用 JavaScript 实现深度学习模型】'PyTorch in JavaScript - A JavaScript library like PyTorch, built from scratch.' GitHub: github.com/eduardoleao052/js-torch <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho849wysk6j21am0u0gpo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:05:08 GMT</pubDate>
</item>
<item>
<title>【RAG相关资源大列表】’Awesome-RAG' GitHub: github.com/frutik/Awesome-RAG #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O7hrKuBtP</link>
<guid>https://weibo.com/1402400261/O7hrKuBtP</guid>
<content:encoded><![CDATA[
<div> GitHub、RAG、资源、列表、frutik、Awesome-RAG、资源列表、相关资源、大列表
<br />
RAG是一个GitHub上的资源列表，由frutik创建并维护，收录了大量与RAG相关的资源。这个列表包含了各种与RAG技术相关的项目和工具，可以帮助用户更好地了解和学习RAG技术。通过这个资源列表，用户可以找到各种教程、示例代码、工具软件等，帮助他们在RAG领域取得更多的进展。总的来说，Awesome-RAG是一个集合了丰富资源并持续更新的GitHub资源列表，对RAG技术的学习和应用提供了很大的帮助。
<br /><br />
总结: RAG资源列表是由frutik创建并维护的GitHub项目，整合了大量关于RAG技术的资源，包括教程、示例代码和工具软件，为用户提供了学习和应用RAG技术的支持。 <div>
【RAG相关资源大列表】’Awesome-RAG' GitHub: github.com/frutik/Awesome-RAG <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho845k6jptj20sm1j4q92.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 12:03:10 GMT</pubDate>
</item>
<item>
<title>【Page Assist：开源 Chrome 插件它提供一个 Sidebar 和 Web UI，让你在任意网页和本地 AI 模型交互】’Page Assist - Use your locally running AI models to a...</title>
<link>https://weibo.com/1402400261/O7hpvAAoK</link>
<guid>https://weibo.com/1402400261/O7hpvAAoK</guid>
<content:encoded><![CDATA[
<div> 开源 Chrome 插件 Sidebar Web UI 任意网页 本地 AI 模型 交互 GitHub page-assist 

<br /><br />总结:
Page Assist 是一个开源的 Chrome 插件，它提供了一个 Sidebar 和 Web UI，让用户可以在任意网页上和本地 AI 模型进行交互。用户可以利用本地运行的 AI 模型来辅助浏览网页，提供更智能的功能和服务。这个项目的代码托管在 GitHub 上，地址为github.com/n4ze3m/page-assist。通过安装该插件，用户可以提升网页浏览的效率和体验，利用 AI 技术来更好地辅助自己的工作和学习。Page Assist 将 AI 技术与浏览器插件相结合，为用户提供了一种新的交互方式，帮助他们更好地利用本地AI模型，实现更智能化的网页浏览体验。 <div>
【Page Assist：开源 Chrome 插件它提供一个 Sidebar 和 Web UI，让你在任意网页和本地 AI 模型交互】’Page Assist - Use your locally running AI models to assist you in your web browsing' GitHub: github.com/n4ze3m/page-assist <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho8423ptyjj20dc0a074e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 11:57:39 GMT</pubDate>
</item>
<item>
<title>【ratchet：跨平台浏览器ML框架】’ratchet - A cross-platform browser ML framework.' GitHub: github.com/huggingface/ratchet #开源# #机器学习# #人工智能#...</title>
<link>https://weibo.com/1402400261/O7gRiszJV</link>
<guid>https://weibo.com/1402400261/O7gRiszJV</guid>
<content:encoded><![CDATA[
<div> 跨平台浏览器 ML 框架、GitHub、huggingface、ratchet、ratchet - A cross-platform browser ML framework<br />
<br />
要点1: ratchet是一个跨平台浏览器ML框架。
要点2: 这个框架的代码托管在GitHub上，地址为github.com/huggingface/ratchet。
要点3: 感兴趣的用户可以查看并了解这个框架的具体功能和用途。
要点4: ratchet的设计可以让用户在不同平台上使用浏览器进行机器学习相关的工作。
要点5: 这个框架为浏览器提供了一种跨平台的机器学习解决方案。
<br /><br />总结: 
ratchet是一个跨平台浏览器ML框架，用户可以通过GitHub上的地址github.com/huggingface/ratchet了解和使用这个框架。这个框架的设计使得用户可以在不同平台上使用浏览器进行机器学习相关的工作，为浏览器提供了一种跨平台的机器学习解决方案。 <div>
【ratchet：跨平台浏览器ML框架】’ratchet - A cross-platform browser ML framework.' GitHub: github.com/huggingface/ratchet <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho81mf2w3vj213y0o80v6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 10:33:22 GMT</pubDate>
</item>
<item>
<title>【DeepSeek：基于LLM的检索引擎】'DeepSeek - LLM powered retrieval engine designed to process a ton of sources to collect a comprehensive list of entiti...</title>
<link>https://weibo.com/1402400261/O7gMqyvjl</link>
<guid>https://weibo.com/1402400261/O7gMqyvjl</guid>
<content:encoded><![CDATA[
<div> LLM，GitHub，检索引擎，DeepSeek，实体收集，源数据处理，全面列表，DeepSeek设计，LLM加强，大量来源<br />
<br />
提供了基于LLM的检索引擎DeepSeek，旨在处理大量来源数据，以收集全面的实体列表。DeepSeek利用LLM技术加强检索过程，能够快速有效地从各种来源中提取信息。GitHub上有相关项目代码，有兴趣的话可以查看详细信息。 <div>
【DeepSeek：基于LLM的检索引擎】'DeepSeek - LLM powered retrieval engine designed to process a ton of sources to collect a comprehensive list of entities.' GitHub: github.com/dzhng/deep-seek <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho819ysep7j214w0u0dif.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 10:21:22 GMT</pubDate>
</item>
<item>
<title>【MAD-Lab：用来加速深学习架构设计的开源项目，使用简单的合成任务来预测模型在序列模式中的性能】'MAD-Lab - A MAD laboratory to improve AI architecture de...</title>
<link>https://weibo.com/1402400261/O7gfz9Dfi</link>
<guid>https://weibo.com/1402400261/O7gfz9Dfi</guid>
<content:encoded><![CDATA[
<div> 加速深学习架构设计 开源项目 简单 合成任务 预测 模型 序列模式 性能

<br /><br />总结:
MAD-Lab是一个用来加速深学习架构设计的开源项目，通过简单的合成任务来预测模型在序列模式中的性能。该项目提供了一个MAD实验室，旨在改进人工智能架构设计。用户可以在GitHub上找到该项目，通过使用这个工具，可以更有效地设计和优化深度学习模型，提升模型的性能和效率。MAD-Lab的出现为深度学习领域的研究者和开发者提供了一个有益的工具和资源，有助于推动人工智能技术的发展和应用。 <div>
【MAD-Lab：用来加速深学习架构设计的开源项目，使用简单的合成任务来预测模型在序列模式中的性能】'MAD-Lab - A MAD laboratory to improve AI architecture designs' GitHub: github.com/athms/mad-lab <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7yxjrtmdj210l0u0ajb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 09:00:24 GMT</pubDate>
</item>
<item>
<title>'《一人企业方法论》第二版，也适合做其他副业（比如自媒体、电商、数字商品）的非技术人群' GitHub: github.com/easychen/one-person-businesses-methodology-v...</title>
<link>https://weibo.com/1402400261/O7gdbAQPy</link>
<guid>https://weibo.com/1402400261/O7gdbAQPy</guid>
<content:encoded><![CDATA[
<div> 关键词: 一人企业、方法论、副业、自媒体、电商、数字商品、非技术人群

<br /><br />总结:
《一人企业方法论》第二版是适用于非技术人群的方法论，不仅适用于经营一人企业，也适合从事副业如自媒体、电商、数字商品等领域的人群。该方法论提供了系统化的指导和实践经验，帮助个体创业者建立和拓展自己的事业。通过深入了解市场、客户需求，精准定位、有效推广，以及灵活的运营策略，个体创业者可以实现自身事业的增长和成功。在如今激烈竞争的商业环境下，掌握一套科学的方法论对于非技术人群来说尤为重要，可以帮助他们更好地应对挑战，实现事业的持续发展。 <div>
'《一人企业方法论》第二版，也适合做其他副业（比如自媒体、电商、数字商品）的非技术人群' GitHub: github.com/easychen/one-person-businesses-methodology-v2.0 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho7yrkguatj20ks0rkdl0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:54:33 GMT</pubDate>
</item>
<item>
<title>【OpenTAD: 开源的PyTorch时间动作检测工具箱】'OpenTAD: An Open-Source Temporal Action Detection Toolbox. - OpenTAD is an open-source temporal action de...</title>
<link>https://weibo.com/1402400261/O7gcPf6p9</link>
<guid>https://weibo.com/1402400261/O7gcPf6p9</guid>
<content:encoded><![CDATA[
<div> PyTorch, 时间动作检测, 开源工具箱, OpenTAD, GitHub, 检测工具, 时间序列, 神经网络, 视频数据<br />
<br />
提到了一个名为OpenTAD的开源工具箱，用于PyTorch平台上的时间动作检测任务。这个工具箱主要基于神经网络技术，针对视频数据中的时间序列进行动作检测。此工具箱的代码开源在GitHub上，为研究人员和开发者提供了一个方便易用的工具，帮助他们在时间动作检测方面取得更好的成果。 <div>
【OpenTAD: 开源的PyTorch时间动作检测工具箱】'OpenTAD: An Open-Source Temporal Action Detection Toolbox. - OpenTAD is an open-source temporal action detection (TAD) toolbox based on PyTorch.' GitHub: github.com/sming256/OpenTAD <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho7yq5hkkyj21360u07a1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:53:38 GMT</pubDate>
</item>
<item>
<title>【Valkey：一个新的开源项目，旨在重启之前的开源 Redis 项目】' - A new project to resume development on the formerly open-source Redis project. We're ca...</title>
<link>https://weibo.com/1402400261/O7gc7dqjj</link>
<guid>https://weibo.com/1402400261/O7gc7dqjj</guid>
<content:encoded><![CDATA[
<div> Valkey, 开源项目, Redis, 重启, Valkyrie, GitHub, 意在继续开发, 新项目, 项目名称

<br /><br />总结:
Valkey是一个新的开源项目，旨在重启之前的开源Redis项目。项目名称取自Valkyrie，意在继续开发并完善之前的Redis项目。Valkey的代码托管在GitHub上，为开发人员提供了一个共同合作和贡献的平台。这个新项目旨在延续Redis的精神，为用户提供更好的数据存储和管理解决方案。通过Valkey项目，我们希望能够持续推动开源技术的发展，为开发者提供更多优质的工具和资源。 <div>
【Valkey：一个新的开源项目，旨在重启之前的开源 Redis 项目】' - A new project to resume development on the formerly open-source Redis project. We're calling it Valkey, like a Valkyrie.' GitHub: github.com/valkey-io/valkey <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Redis%23"><span class="surl-text">#Redis#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho7yovkkwjj21jo0p6wjr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:51:54 GMT</pubDate>
</item>
<item>
<title>GitHub: github.com/databricks/dbrx - 转发 @爱可可-爱生活:&amp;ensp;【Databricks开源DBRX高性能大语言模型】- DBRX是Databricks开发的开源通用语言模型，在多项...</title>
<link>https://weibo.com/1402400261/O7g8IykIK</link>
<guid>https://weibo.com/1402400261/O7g8IykIK</guid>
<content:encoded><![CDATA[
<div> Databricks, DBRX, 开源, 语言模型, MoE架构, GenAI, 训练, 效率, 商业模型, Hugging Face

<br /><br />总结:
Databricks推出了开源通用语言模型DBRX，在多项基准测试中表现出色，尤其在编程和数学推理方面优于其他开源模型。DBRX采用MoE架构，在训练和推理上更为高效，推理吞吐量提高2-3倍。DBRX已集成在Databricks的GenAI产品中，客户可以通过API使用。其训练代码和模型也在Hugging Face平台上开源。DBRX的推出展示了Databricks高效训练语言模型的能力，为企业训练定制模型提供了可能。这一举措将推动语言模型的开放性发展，为开发者和企业构建定制模型提供新的选择。MoE架构在提升大型语言模型效率方面有着巨大潜力，为进一步优化模型提供了思路。Databricks将DBRX定位为GenAI战略的核心，展现了他们对语言模型和GenAI商业化的信心和决心。这也预示着更多垂直领域模型的到来。 <div>
GitHub: github.com/databricks/dbrx<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 【Databricks开源DBRX高性能大语言模型】<br />- DBRX是Databricks开发的开源通用语言模型，在多项标准基准测试上达到了当前开源语言模型的最高水平。   <br />- DBRX在多项综合基准测试中表现最好，尤其在编程和数学推理方面优于其他开源模型。与开源模型相比，DBRX在MMLU数据集上的表现也是最好的。   <br />- 根据测试，DBRX甚至超过了专门用于编程的CodeLLAMA-70B，并且与商业模型GPT-3.5相当甚至略胜。DBRX也与Gemini 1.0 Pro和Mistral Medium等商业模型有竞争力。   <br />- DBRX使用混合专家(MoE)架构，使其在训练和推理上更加高效。与类似参数量的非MoE模型相比，DBRX的推理吞吐量提高2-3倍。   <br />- DBRX的整体训练效率比之前提高了近4倍，这得益于更好的数据、MoE架构以及其他改进。   <br />- DBRX已经在Databricks的GenAI产品中进行了集成，客户可以通过API使用该模型。DBRX的训练代码和模型也在Hugging Face平台上开源。   <br />- DBRX证明了Databricks可以高效地训练世界级的基础语言模型，也为企业训练自己的基础模型提供了能力。DBRX只是Databricks协助客户训练定制语言模型的一个例子。<br /><br />思考：  <br />- Databricks作为一家数据和AI公司推出如此强大的开源LLM令人印象深刻，这将极大推动LLM的开放性发展。  <br />- DBRX在通用和编程能力上的出色表现，有望成为开发者和企业构建定制LLM的新选择。  <br />- MoE架构在提升LLM效率方面的潜力得到了很好的体现，为进一步优化大模型提供了思路。  <br />- Databricks将DBRX定位于其GenAI战略的核心，反映出他们对LLM和GenAI商业化的信心和决心。  <br />- Databricks过去为客户大规模训练LLM的经验，为DBRX的成功奠定了基础，也预示着更多垂直领域模型的到来。<br />《Introducing DBRX: A New State-of-the-Art Open LLM | Databricks》 <a href="https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6bjgicy7j21ej0u0jvd.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6bjkgdyqj21c70u0tbn.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:43:32 GMT</pubDate>
</item>
<item>
<title>【Jamba：突破性的SSM-Transformer混合架构模型】- AI21 推出了名为 Jamba 的新型自然语言处理模型，首个基于 Mamba 结构化状态空间(Structured State Space mod...</title>
<link>https://weibo.com/1402400261/O7g6y9NdH</link>
<guid>https://weibo.com/1402400261/O7g6y9NdH</guid>
<content:encoded><![CDATA[
<div> Jamba, SSM-Transformer, 混合架构, 模型, Mamba, Transformer, 注意力机制, 模块化设计, 开源, AI21

<br /><br />总结:
AI21推出了Jamba，这是首个基于Mamba结构化状态空间(SSM)模型和传统Transformer架构的混合模型。Jamba结合了Mamba和Transformer的优势，解决了纯SSM模型质量不高和Transformer计算效率低的问题。该模型使用混合注意力机制，支持256K上下文窗口，在单GPU上可以支持14万token并有3倍吞吐量提升。通过模块化设计、动态激活部分参数的方式，Jamba的效果与传统52B参数模型相当。初步评估显示Jamba在吞吐量和效率等指标上表现优异，权重已在Apache 2.0许可下开源。AI21希望通过开源Jamba推动SSM-Transformer架构的发展和创造更多应用。 <div>
【Jamba：突破性的SSM-Transformer混合架构模型】<br />- AI21 推出了名为 Jamba 的新型自然语言处理模型，首个基于 Mamba 结构化状态空间(Structured State Space model，SSM)模型和传统Transformer架构的混合模型。   <br />- Jamba 结合了 Mamba 和 Transformer 两种模型的优势，既解决了纯 SSM 模型质量不高的问题，又克服了 Transformer 在大上下文场景下计算效率低的缺点。   <br />- Jamba 使用混合注意力机制，同时支持256K的上下文窗口，在单GPU上可以支持14万token。相比类似规模的模型，其吞吐量提升3倍。   <br />- Jamba采用模块化设计， transformer模块、mamba模块和mixture-of-experts模块分别承担不同功能。同时使用动态激活部分参数的方式，使12B参数发挥与全Transformer架构52B参数模型相当的效果。   <br />- 初步评估显示，Jamba在多个指标上表现优异，如吞吐量、效率等。这充分验证了 Jamba作为首个达到商业级水平的SSM-Transformer混合架构模型的可行性。   <br />- Jamba的权重已在Apache 2.0许可下开源，用户可以在Hugging Face上使用。Jamba旨在作为基础模型进行微调、训练和开发定制化解决方案。   <br />- AI21希望通过开源Jamba，能推动SSM-Transformer架构的进一步发展和优化，创造更多新奇有趣的应用。<br />《Jamba：A Groundbreaking SSM - Transformer Open Model》 <a href="https://www.ai21.com/jamba"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho7ya8797hj21of0u077k.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7ya9ejbbj21hc0u0q4x.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho7yabemj3j20vo0iymyx.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7yad0805j21k60u0769.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho7yadvis9j21v00u00v7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 08:38:10 GMT</pubDate>
</item>
<item>
<title>【Grok-1.5发布：支持128K超长上下文】- Grok-1.5是xAI最新发布的大型语言模型，具有更强的推理和解决问题的能力。 - Grok-1.5的一个显著改进是在编程和数学相关...</title>
<link>https://weibo.com/1402400261/O7fqKClTg</link>
<guid>https://weibo.com/1402400261/O7fqKClTg</guid>
<content:encoded><![CDATA[
<div> Grok-1.5, xAI, 128K超长上下文, 推理能力, 人工智能, 编程, 数学, 长文本理解, NIAH, JAX, Rust, Kubernetes, GPU集群, 用户反馈, 基准测试, 模型优化, 发展创新, 定制分布式训练框架, 马斯克, 商业化进程, 开源<br />
<br />
总结:<br />
Grok-1.5是xAI发布的大型语言模型，具有强大的推理和解决问题能力，特别在编程和数学任务中表现优异。其支持处理高达128K token的超长文本，在NIAH任务中表现出色。该模型基于JAX、Rust和Kubernetes构建，可以在大规模GPU集群上进行原型设计和模型训练。xAI团队非常注重用户反馈，并持续改进Grok以满足需求。未来Grok可能引入新功能如总结帖子、内容建议等。虽然未提供微调代码，但开源Grok-1展现了xAI开放、透明的态度。马斯克暗示将扩大Grok聊天机器人的使用权限，显示xAI正逐步推进商业化进程。 <div>
【Grok-1.5发布：支持128K超长上下文】<br />- Grok-1.5是xAI最新发布的大型语言模型，具有更强的推理和解决问题的能力。   <br />- Grok-1.5的一个显著改进是在编程和数学相关任务上的表现，在MATH和GSM8K这两个评估中学科竞赛问题解决能力的基准测试中取得了50.6%和90%的得分。   <br />- Grok-1.5可以处理高达128K token的长文本理解任务，上下文窗口增大了16倍，记忆能力显著提升。它在长文本检索任务NIAH中展示了在长达128k token的上下文中完美检索文本的能力。   <br />- Grok-1.5基于JAX、Rust和Kubernetes构建，使团队可以在大规模GPU集群上进行原型设计和模型训练。检查点、数据加载和任务重启等都进行了优化，以最大程度提高可靠性和训练时间。   <br />- Grok-1.5即将向早期测试用户开放，xAI团队欢迎用户反馈意见。在未来几天里，他们还会推出一些新功能。   <br />- Grok-1.5在多个基准测试中表现强劲，显示出语言理解和推理方面的长足进步。它为解决更加复杂的问题提供了更大的上下文理解能力。xAI将继续改进Grok，以满足用户的需求。   <br /><br />思考：  <br />- Grok-1.5在推理、编码和数学能力方面的改进令人印象深刻，xAI在不断推动人工智能技术的发展和创新。  <br />- 128K token的长上下文处理能力是一个重大突破，使Grok-1.5能够更好地理解和利用长文档中的信息，处理更复杂的提示，这将大大拓展其应用场景。  <br />- 定制的分布式训练框架体现了xAI在底层技术和工程能力方面的实力，有利于加速人工智能模型的迭代和优化。  <br />- 尽管Grok-1.5尚未正式发布，但马斯克已经透露了一些未来可能引入的新功能，如总结帖子、内容建议等，这些都将大大提升用户体验。  <br />- 开源Grok-1彰显了xAI开放、透明的态度，但没有提供微调代码，可能是出于保护核心技术和竞争优势的考虑。  <br />- 马斯克暗示将逐步扩大Grok聊天机器人的使用权限，表明xAI正在稳步推进商业化进程，未来可能会成为X平台的重要变现途径之一。<br />《Announcing Grok-1.5》 <a href="https://x.ai/blog/grok-1.5"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho7vbau0f3j221o0u0aeg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho7vbbwf6yj21jk0rs0wb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 06:55:13 GMT</pubDate>
</item>
<item>
<title>恭喜@i_tuna 等3名用户获得【《hello 算法》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效。公示链接：网页链接 - 转发 @爱可可-爱...</title>
<link>https://weibo.com/1402400261/O7eixaBMz</link>
<guid>https://weibo.com/1402400261/O7eixaBMz</guid>
<content:encoded><![CDATA[
<div> 微博官方、《hello 算法》、抽奖、监督、公正、有效、携手、数据结构、算法、动画图解

<br /><br />总结:
本次活动是微博官方举办的抽奖活动，奖品为《hello 算法》书籍，抽奖过程经过官方监督，结果公正有效。参与方式为转发并评论，截止时间为2024年3月29日12:00。《hello 算法》书籍内容生动易懂，配有动画图解，帮助读者轻松掌握数据结构与算法知识。书中还提供实战代码示例和互动环节设计，让读者即学即用，提高学习效率。通过这本书，读者可以以全新的视角进入算法的世界，掌握重要的数据结构和算法知识。 <div>
恭喜<a href="https://weibo.com/n/i_tuna">@i_tuna</a> 等3名用户获得【《hello 算法》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20240246&amp;pageid=100140E51191126"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 29 Mar 2024 04:02:13 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评...</title>
<link>https://weibo.com/1402400261/O7bWjsGOq</link>
<guid>https://weibo.com/1402400261/O7bWjsGOq</guid>
<content:encoded><![CDATA[
<div> Java, Python, JavaScript, C语言, MySQL, Redis, 技术原理, 故事, 码农翻身2

<br /><br />
总结: 
《码农翻身2》是一本以故事形式讲解技术的畅销书，通过描述编程语言王国的争斗和技术之间的矛盾，让读者了解技术原理并且阅读愉快。书中描绘了Java向Python渗透、JavaScript向Java进攻的情景，C语言的孤独悲催以及MySQL和Redis间的矛盾。通过趣味性的故事，读者可以轻松掌握技术知识。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 22:01:59 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*...</title>
<link>https://weibo.com/1402400261/O7bWgwtuw</link>
<guid>https://weibo.com/1402400261/O7bWgwtuw</guid>
<content:encoded><![CDATA[
<div> 开奖 参与 携手 hello算法 可可粉 数据结构 算法 视角 图解 实战代码 思考问题  <br />
<br />
总结: 今天有开奖活动，欢迎大家参与。赠送3本《hello 算法》，截止时间是2024年3月29日中午12点。参与方式是转发并在评论中加上关键词“可可粉”。这本书可以帮助读者轻松掌握数据结构和算法，以全新的视角进入算法的世界。每一章都有生动的动画图解让抽象的概念变得直观易懂，实战代码示例可以帮助读者即学即用，加深对新知识的理解。书中的互动环节设计可以帮助读者主动思考，提出问题并解决问题。希望大家能够充分利用这本书提升自己的算法能力。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 22:01:52 GMT</pubDate>
</item>
<item>
<title>今日推介(第1359期)：大型语言模型中的长文本事实性、语言模型的少样本重校准、大型语言模型能产生具有同理心的反应、监控提示训练、适应任意分辨率的视觉Transf...</title>
<link>https://weibo.com/1402400261/O7bW44IwI</link>
<guid>https://weibo.com/1402400261/O7bW44IwI</guid>
<content:encoded><![CDATA[
<div> 长文本事实性、语言模型、少样本重校准、同理心、监控提示训练、任意分辨率、视觉Transformer<br />
<br />
大型语言模型在生成长文本时，需要保证信息的准确性和事实性，这对于提高模型的可信度至关重要。研究表明，少样本重校准技术可以帮助语言模型更好地理解和生成文本，提高其效果和表现。另外，大型语言模型能够产生具有同理心的反应，为人类与AI之间建立更加亲近的联系提供可能。监控提示训练是一种有效的训练方法，可以帮助语言模型适应多样的语境和情境，提高其对话和文本生成的能力。同时，视觉Transformer具有适应任意分辨率的能力，能够更好地处理各种视觉任务。综上所述，大型语言模型在不断发展和完善的过程中，不断探索新的技术方法和应用场景，为人工智能领域的发展带来新的可能性和机遇。<br /><br />总结:长文本事实性是大型语言模型生成文本时需要考虑的重要因素，少样本重校准技术可以提高模型效果，大型语言模型能产生具有同理心的反应，监控提示训练有助于提高模型能力，视觉Transformer适应任意分辨率的特性能够更好应对各种视觉任务。 <div>
今日推介(第1359期)：大型语言模型中的长文本事实性、语言模型的少样本重校准、大型语言模型能产生具有同理心的反应、监控提示训练、适应任意分辨率的视觉Transformer 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/689639917"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.29)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7fvouo5nj20go08e75c.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7fvs8ioaj20go05qq3r.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7fvuu2uvj20go0913z2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho7fvx9i5qj20go0fat9u.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho7fvzpva4j20go0b10u3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 22:01:22 GMT</pubDate>
</item>
<item>
<title>[CV] EgoLifter: Open-world 3D Segmentation for Egocentric Perception 网页链接 EgoLifter利用3D高斯与实例特征的组合以及对比学习，实现了从第一人称视频进...</title>
<link>https://weibo.com/1402400261/O7bSLBR4R</link>
<guid>https://weibo.com/1402400261/O7bSLBR4R</guid>
<content:encoded><![CDATA[
<div> EgoLifter, 3D高斯，实例特征，对比学习，第一人称视频，开放世界3D场景分割，端到端框架，无需人工3D标注数据

<br /><br />总结:
EgoLifter利用3D高斯与实例特征的组合以及对比学习，实现了从第一人称视频进行开放世界3D场景分割的端到端框架，无需人工3D标注数据。 <div>
[CV] EgoLifter: Open-world 3D Segmentation for Egocentric Perception  <br /><a href="https://arxiv.org/abs/2403.18118"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>     <br />EgoLifter利用3D高斯与实例特征的组合以及对比学习，实现了从第一人称视频进行开放世界3D场景分割的端到端框架，无需人工3D标注数据。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fnia6goj20uy1cuwsn.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fnipwdjj211g17eh27.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7fnj4p5nj211o0sa7df.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fnjjgkgj20wu1bq179.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:53:15 GMT</pubDate>
</item>
<item>
<title>[CV] Benchmarking Object Detectors with COCO: A New Path Forward 网页链接 通过构建高质量的数据集COCO-ReM，揭示了目标检测模型评估的重要性，为未来的算法...</title>
<link>https://weibo.com/1402400261/O7bPVv6UR</link>
<guid>https://weibo.com/1402400261/O7bPVv6UR</guid>
<content:encoded><![CDATA[
<div> 构建数据集 COCO-ReM 目标检测模型评估 算法研究 基准 数据集质量 目标检测模型 可靠性

<br /><br />总结:
该文章介绍了通过建立高质量数据集COCO-ReM来揭示目标检测模型评估的重要性，并为未来算法研究奠定可靠基准。这项研究突出了数据集质量对于目标检测模型评估的关键性，并提出了使用COCO-ReM作为基准数据集的优势。作者强调了评估目标检测模型的重要性，列举了一些现有数据集的局限性，并指出了COCO-ReM数据集的创新性和研究意义。通过对比各种数据集，研究人员表明了COCO-ReM数据集在不同性能指标上的优势，包括更高的准确性和更全面的测试。文章最后总结了该研究的重要性，并呼吁未来的算法研究应该基于可靠的基准数据集进行评估，以推动目标检测领域的发展。 <div>
[CV]  Benchmarking Object Detectors with COCO: A New Path Forward  <br /><a href="https://arxiv.org/abs/2403.18819"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过构建高质量的数据集COCO-ReM，揭示了目标检测模型评估的重要性，为未来的算法研究奠定可靠的基准。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fg83ke0j210g184wud.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7fg8jnpsj217a0xi4dd.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7fg90wc4j217w0ja47w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7fg9jn61j217c0jk0xh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:46:15 GMT</pubDate>
</item>
<item>
<title>[CL] Enhancing Legal Document Retrieval: A Multi-Phase Approach with Large Language Models 网页链接 通过在法律文档多阶段检索流程中集成提示驱动的大型语...</title>
<link>https://weibo.com/1402400261/O7bNMp76A</link>
<guid>https://weibo.com/1402400261/O7bNMp76A</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、法律文档检索、多阶段方法、提示驱动、性能提升、集成、检索性能、法律领域、信息检索、语言模型

<br /><br />总结:
本文提出了一种通过在法律文档多阶段检索流程中集成提示驱动的大型语言模型来提升检索性能的方法。研究针对法律领域的信息检索问题进行了探讨，并提出了一种多阶段方法，其中大型语言模型起到关键作用。通过集成大型语言模型，可以显著提高法律文档的检索性能，提高检索结果的准确性和相关性。这种方法为提高法律文档检索效率和质量提供了新思路和方法。 <div>
[CL] Enhancing Legal Document Retrieval: A Multi-Phase Approach with Large Language Models  <br /><a href="https://arxiv.org/abs/2403.18093"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过在法律文档多阶段检索流程中集成提示驱动的大型语言模型，提出了一种可显著提高检索性能的方法。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7faq17bhj20rm16oals.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7faqartwj21no0qagrd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7farrkrzj21060n2dht.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:40:58 GMT</pubDate>
</item>
<item>
<title>[CL] BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text 网页链接 提出了面向生物医学领域的小型开源语言模型BioMedLM，证明了通过高质量...</title>
<link>https://weibo.com/1402400261/O7bLx6SZP</link>
<guid>https://weibo.com/1402400261/O7bLx6SZP</guid>
<content:encoded><![CDATA[
<div> 生物医学领域、小型开源语言模型、BioMedLM、高质量领域语料训练、生物医学QA、竞争力效果

<br /><br />总结:
文章介绍了一个面向生物医学领域的小型开源语言模型BioMedLM，该模型在经过高质量领域语料训练后，在生物医学QA等任务上展现出竞争力的效果。作者提出了这个2.7B参数的语言模型，证明了即使不是追求模型规模，通过充分训练仍可以在生物医学领域取得良好的表现。BioMedLM为生物医学领域的文本处理和分析提供了一个有潜力的工具，为相关研究和实践带来了新的可能性。该研究结果为语言模型在特定领域的应用提供了有益的启示，强调了训练数据和模型设计的重要性。BioMedLM的出现丰富了开源语言模型的领域应用场景，对于推动生物医学领域的智能化发展具有积极意义。 <div>
[CL] BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text  <br /><a href="https://arxiv.org/abs/2403.18421"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出了面向生物医学领域的小型开源语言模型BioMedLM，证明了通过高质量的领域语料训练，即使不追求模型规模也可以在生物医学QA等任务上达到竞争力的效果。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7f4yzhcpj20zk1daww5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7f4zbj9xj21cs0k2wg9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7f4zyeftj214u0pm0ul.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:35:25 GMT</pubDate>
</item>
<item>
<title>[LG] Tutorial on Diffusion Models for Imaging and Vision 网页链接 本教程全面系统地介绍了从变分自编码器到扩散模型的发展脉络，数学推导细致，内容丰富，是...</title>
<link>https://weibo.com/1402400261/O7bJ6kisn</link>
<guid>https://weibo.com/1402400261/O7bJ6kisn</guid>
<content:encoded><![CDATA[
<div> 变分自编码器、扩散模型、数学推导、理解、教材、系统性、发展脉络、内容丰富、图像、视觉功能
<br />
<br />
总结: 本教程全面系统地介绍了从变分自编码器到扩散模型的发展脉络，数学推导细致，内容丰富，是理解扩散模型的好教材。 <div>
[LG] Tutorial on Diffusion Models for Imaging and Vision  <br /><a href="https://arxiv.org/abs/2403.18103"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />本教程全面系统地介绍了从变分自编码器到扩散模型的发展脉络，数学推导细致，内容丰富，是理解扩散模型的好教材。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7eypxk3tj210q17ggwg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho7eyq7nf7j21i80vetis.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7eyqmidgj21cm0o60yj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:29:26 GMT</pubDate>
</item>
<item>
<title>通过自适应token融合模块和模糊位置编码增强了视觉Transformer的分辨率可扩展性，使其在广泛分辨率上都能保持高性能。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《ViTAR...</title>
<link>https://weibo.com/1402400261/O7bFwiMRP</link>
<guid>https://weibo.com/1402400261/O7bFwiMRP</guid>
<content:encoded><![CDATA[
<div> 关键词: 自适应token融合模块, 模糊位置编码, 视觉Transformer, 分辨率可扩展性, 高性能

总结:<br /><br />这篇论文介绍了一种名为ViTAR的视觉Transformer模型，通过引入自适应token融合模块和模糊位置编码，提高了模型在不同分辨率下的性能表现。该模型能够在广泛的分辨率下保持高性能，并具有较强的分辨率可扩展性。该研究由中国科学院和字节跳动的团队共同完成。<br />ViTAR模型在视觉Transformer的基础上做出了创新改进，使得模型在各种分辨率上的应用更加灵活可靠。通过自适应token融合模块，模型能够有效地融合不同分辨率的特征信息，提升了模型的表征能力和泛化能力。<br />同时，引入模糊位置编码则进一步增强了模型的分辨率可扩展性，使其能够处理更加复杂的视觉任务。这些技术创新为视觉Transformer的发展带来了新的思路和可能性，为未来的视觉任务研究提供了有益的启示。 <div>
通过自适应token融合模块和模糊位置编码增强了视觉Transformer的分辨率可扩展性，使其在广泛分辨率上都能保持高性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《ViTAR: Vision Transformer with Any Resolution》Q Fan, Q You, X Han, Y Liu, Y Tao, H Huang, R He, H Yang [Chinese Academy of Sciences &amp; ByteDance] (2024) <a href="https://arxiv.org/abs/2403.18361"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7edlfnhcj20ng15c13g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho7edls4tmj20vk0ukgqy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7edmc5nzj21qc158gxh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7edmhwrij20um0ia761.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho7epi8s51j20r30fcdh7.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:20:36 GMT</pubDate>
</item>
<item>
<title>[CV]《ViTAR: Vision Transformer with Any Resolution》Q Fan, Q You, X Han, Y Liu, Y Tao, H Huang, R He, H Yang [Chinese Academy of Sciences &amp; ByteDance...</title>
<link>https://weibo.com/1402400261/O7bFtD4yb</link>
<guid>https://weibo.com/1402400261/O7bFtD4yb</guid>
<content:encoded><![CDATA[
<div> 关键词: ViTAR, 视觉Transformer, 分辨率, 中国科学院, 字节跳动

总结:<br /><br />
本文介绍了 ViTAR，一种具有任意分辨率的视觉Transformer模型，由中国科学院和字节跳动共同研发。该模型在视觉任务中表现出色，能够处理各种分辨率的图像输入。研究人员通过实验证明，ViTAR在不同分辨率下均能取得出色的性能表现。该模型的独特之处在于能够处理不同分辨率的输入，提高了模型的适用性和泛化能力。总体而言，ViTAR为视觉Transformer模型的发展带来了新的思路和方法，对图像分析和处理领域具有重要意义。 <div>
[CV]《ViTAR: Vision Transformer with Any Resolution》Q Fan, Q You, X Han, Y Liu, Y Tao, H Huang, R He, H Yang [Chinese Academy of Sciences &amp; ByteDance] (2024) <a href="https://arxiv.org/abs/2403.18361"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7edlfnhcj20ng15c13g.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho7edls4tmj20vk0ukgqy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho7edmc5nzj21qc158gxh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho7edmhwrij20um0ia761.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho7epi8s51j20r30fcdh7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 21:20:31 GMT</pubDate>
</item>
<item>
<title>【如何成为“效率大师”？】其实，提高工作效率并没有想象中那么难，只要掌握几个简单的技巧，你也可以成为效率之王。 - 首先，学会专注。把时间分块，在日历上...</title>
<link>https://weibo.com/1402400261/O73tVBTUS</link>
<guid>https://weibo.com/1402400261/O73tVBTUS</guid>
<content:encoded><![CDATA[
<div> 专注 深度工作 艾森豪威尔矩阵 邮件处理 习惯 养成 目标计划 番茄工作法 回顾 说“不” 散步  自动化

<br /><br />总结:
首先，要学会专注，将时间分块，全神贯注地完成每项任务。其次，练习深度工作，保持专注，不分心。第三，使用艾森豪威尔矩阵来安排任务，注重重要事项。第四，批量处理邮件和消息，有效安排时间。第五，养成每天练习习惯，坚持一年即可看到成效。第六，利用番茄工作法战胜拖延症。第七，制定目标和计划，每天进行回顾。第八，学会对事情说“不”，拒绝无关紧要的事务。第九，每天晚上散步，可结合冥想。最后，尽可能自动化任务，提高效率。生活就像马拉松，效率是取得优异成绩的关键。 <div>
【如何成为“效率大师”？】<br />其实，提高工作效率并没有想象中那么难，只要掌握几个简单的技巧，你也可以成为效率之王。   <br />- 首先，学会专注。把时间分块，在日历上为每个任务预留时间，然后全神贯注地完成当前的任务。可以尝试3:3:3法则：每天花3小时做最重要的项目，3小时做短期任务，3小时做日常维护。   <br />- 其次，练习"深度工作"。每天至少花4个小时专注工作，期间不要分心(可以把手机调到飞行模式)。学习新东西时，可以用费曼技巧：选一个主题，试着向一个5岁的孩子解释，然后继续研究以填补知识空白。   <br />- 第三，用艾森豪威尔(Eisenhower)矩阵来安排任务。目标是把更多时间花在重要的事情上，那些能推进你长期价值观、使命、目标和原则的事情。   <br />- 第四，批量处理邮件和消息。每天集中1-3次时间来处理邮件。对不必要的邮件立即删除，需要别人处理的转发出去，几分钟内可以回复的马上回，其他的则安排时间处理。   <br />- 第五，养成每天练习20分钟的习惯。坚持一年，你就会比90%的人做得更好。可以用"尽善尽美"(GTD)的方法来高效地安排每一件事。   <br />- 第六，用番茄工作法来战胜拖延症。选择一个任务，设置25分钟的计时器，专注工作，中间不要分心，然后休息一下，再重复。每完成4个番茄钟，就休息久一点。   <br />- 第七，制定年度、月度、周度和日常的目标和计划。没有目标，你可能哪儿也到不了。   <br />- 第八，进行每日和每周回顾。问问自己："我今天做了哪些符合目标的事情?""有什么地方可以改进吗?"   <br />- 第九，学会对很多事情说”不”！一个"不"就是对很多其他事情说"是"。   <br />- 第十，每天晚上散步30分钟。如果能在散步时冥想，那就更好了。   <br />- 最后，尽可能地自动化。试着用各种工具来自动化一切可以自动化的事情，尤其是重复性的任务。   <br />生活就像一场马拉松，效率就是你的配速。掌握这些技巧，相信你一定能在这场马拉松中取得优异的成绩。当然，知易行难，关键是要把这些方法落实到行动中。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho6ekdg9wgj20u01kt11n.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho6ekdwe11j20u019en53.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:30:05 GMT</pubDate>
</item>
<item>
<title>【distil-large-v3：Whisper large-v3的蒸馏精简版】Distil-Whisper的设计旨在加快推理速度，仅使用两个解码器层，实现了与原版Whisper相媲美的语音识别准确性，...</title>
<link>https://weibo.com/1402400261/O73pWbPS5</link>
<guid>https://weibo.com/1402400261/O73pWbPS5</guid>
<content:encoded><![CDATA[
<div> 解码器层、语音识别、推理速度、准确性、幻听错误、分块长文本算法、错误率、Distil-Whisper、设计、提升速度

<br /><br />总结:
Distil-Whisper是一个蒸馏精简版的Whisper模型，旨在加快推理速度。它仅使用两个解码器层，但在语音识别准确性方面与原版Whisper相媲美，推理速度提升了6.3倍。此外，Distil-Whisper在降低幻听错误方面也取得了重大进展，使用分块长文本算法时，幻听错误率降低了约30%。Distil-Whisper的设计使得语音识别更加高效、准确，为技术领域带来了新的突破。 <div>
【distil-large-v3：Whisper large-v3的蒸馏精简版】Distil-Whisper的设计旨在加快推理速度，仅使用两个解码器层，实现了与原版Whisper相媲美的语音识别准确性，但速度却提升了惊人的6.3倍。此外，Distil-Whisper在降低幻听错误方面也取得了重大进展，使用分块长文本算法时，幻听错误率降低了约30%。 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho6ea22y2cj20y20u0tdo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:20:15 GMT</pubDate>
</item>
<item>
<title>【AI许可(licensing)：虚幻的安全感与真实的管理困境】- 一些组织主张通过许可证限制强大AI模型的扩散，类似于核武器或人体克隆。但是这种做法在实施上不可行。 ...</title>
<link>https://weibo.com/1402400261/O73nMkiHG</link>
<guid>https://weibo.com/1402400261/O73nMkiHG</guid>
<content:encoded><![CDATA[
<div> 许可证、AI模型、扩散、训练成本、国际合作、利益、风险、监管套利、开源AI、灵活应对

总结:<br /><br />本文讨论了AI许可在管理风险方面的困境。许可证虽然被一些组织主张限制强大AI模型的扩散，但实施上存在诸多困难。训练成本逐渐下降，监控数据中心需要国际合作。少数大公司将获益，强制许可证可能加剧风险。许可证可能导致恶化风险和监管套利，开源AI也需要预防措施。需要更加开放和灵活的方式应对AI发展带来的影响。许可不能真正阻止恶意使用，执法难度大。颠覆性技术难以被垄断。要综合评估AI风险，并制定相应措施应对。 <div>
【AI许可(licensing)：虚幻的安全感与真实的管理困境】<br />- 一些组织主张通过许可证限制强大AI模型的扩散，类似于核武器或人体克隆。但是这种做法在实施上不可行。   <br />- 尽管目前训练顶级AI模型需要大量算力，但随着算法和硬件的进步，训练成本正在急速下降。要全面监控数据中心以限制AI开发不可行且需要空前国际合作。   <br />- 尽管AI模型会扩散，但少数大公司将从这波爆发中获得巨大利益。强制许可证将进一步加剧这种风险，因为只有少数公司可以开发顶级AI。   <br />- 许可证可能导致AI风险恶化，包括安全风险、结果同质化、定义可接受言论界限、影响公众态度等。这也有利于行业巨头进行监管套利。   <br />- 鼓励不同背景的学术界、企业和非营利组织开发和评估顶级AI模型，可能是解决AI风险的更好方式。当然，开源AI也需要防范措施。   <br />- 总体而言，AI技术许可证在实施可行性和有效性上都存在重大障碍。我们需要更加开放和灵活的方式来应对AI发展带来的影响。<br /><br />思考：  <br />- 作者对许可能否有效管理AI风险提出了尖锐质疑，这个观点有一定道理，值得认真考虑。  <br />- 文章指出，许可无法真正阻止坏人，因为他们总能找到非法获取模型的办法。这提醒我们，单纯的许可可能并非万全之策。  <br />- 作者认为许可的支持者低估了执法难度，这一论断可能有一定道理。但能否通过技术创新等方式克服这些难度，可能还有待进一步探索。  <br />- 文章指出，从历史上看，颠覆性技术无法被垄断，终会扩散。这启示我们要用发展的眼光看待AI技术的传播。  <br />- 作者提醒我们不要被许可制造的虚假安全感所迷惑，而忽视了更紧迫的风险。这提示我们要全面评估AI风险，并相应制定综合防控措施。<br />《Licensing is neither feasible nor effective for addressing AI risks》 <a href="https://www.aisnakeoil.com/p/licensing-is-neither-feasible-nor"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6e4nvbhwj20y20u0tdo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:14:56 GMT</pubDate>
</item>
<item>
<title>【模型微调是否仍有价值】- 最近有一些观点开始质疑模型微调的价值，作者认为在许多情况下，模型微调仍然非常有价值。 - 模型微调对于学习语法、风格和规则很有...</title>
<link>https://weibo.com/1402400261/O73m0AYRY</link>
<guid>https://weibo.com/1402400261/O73m0AYRY</guid>
<content:encoded><![CDATA[
<div> 微调 价值 观点 场景 领域 评估 框架 提示工程 区分 RAG

<br /><br />总结: 本文讨论了模型微调的价值，认为在学习语法、风格和规则等方面仍然非常有帮助，但对于开发者工具等通用情况，微调的效果可能有限。作者强调了评估框架的重要性，指出微调需有系统的性能度量。此外，提示工程在微调中扮演着重要的角色，能帮助检验和改善模型的性能。文章还对微调和基于检索的方法进行了区分，指出它们各自适用于不同的场景和目的。综上所述，微调仍然是提升模型表现的有效手段，但其应用需根据具体情况进行决定。 <div>
【模型微调是否仍有价值】<br />- 最近有一些观点开始质疑模型微调的价值，作者认为在许多情况下，模型微调仍然非常有价值。   <br />- 模型微调对于学习语法、风格和规则很有帮助，而提示工程更适合为模型提供上下文和最新事实。   <br />- 在开发者工具、基础模型、通用助手等情况下，模型微调不太有价值。但在专业领域和特定使用案例中，模型微调可以明显改进性能。   <br />- 在产品早期阶段，由于没有域特定的评估体系，很难有效地进行模型微调。构建评估体系是使用模型微调的先决条件。   <br />- 文章给出了Honeycomb和ReChat两个案例，说明了如何通过模型微调学习特定语法、风格和规则，从而提升产品性能。   <br />- 模型微调不仅适用于小模型，大型模型如GPT-3.5也能从中获益。模型微调仍然是提升模型表现的有效手段，值得继续探索与改进。<br /><br />思考：  <br />- 文章对当前AI领域微调价值的看法提供了一个平衡的视角。作者在承认怀疑声音日益增多的同时，坚持认为微调在许多场景下仍有很高价值。  <br />- 一个关键见解是，微调的适用性在很大程度上取决于具体的使用场景和领域。对于通用的开发者工具或基础模型本身，微调的边际效用可能有限。但对于更专业的应用，微调仍可带来显著改善。  <br />- 文章强调要有一个鲁棒的评估框架，作为任何模型优化(包括微调)的基础。没有系统的性能度量方式，我们很容易武断地否定微调等技术。  <br />- 文章也突出了提示工程作为微调的前提和补充所扮演的角色。广泛的提示可以检验评估机制，如果效果令人满意，它本身就足够了。  <br />- 作者对微调和基于检索的方法(如RAG)做了有益的区分，前者更适合学习风格和语法模式，后者更适合注入最新信息。<br />《Hamel’s Blog - Is Fine-Tuning Still Valuable?》 <a href="https://hamel.dev/blog/posts/fine_tuning_valuable.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho6e0460lkj20u016rtg6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:10:33 GMT</pubDate>
</item>
<item>
<title>【用FrankenMoE集成多个预训练模型：MergeKit赋能高效MoE构建】- MoE(混合专家模型)是一种提高性能的模型架构，它使用多个子网络(称为“专家”)。MoE只激活相关...</title>
<link>https://weibo.com/1402400261/O73kchGO2</link>
<guid>https://weibo.com/1402400261/O73kchGO2</guid>
<content:encoded><![CDATA[
<div> MoE, 混合专家模型, FrankenMoE, MergeKit, 预训练模型, 性能提升, 创新思路, 高质量模型, 实用性, 创意方法

<br /><br />总结:
本文介绍了使用FrankenMoE集成多个预训练模型来创建MoE的方法。传统的MoE需要从头训练专家和路由器，而FrankenMoE通过MergeKit集成预训练模型，使MoE构建更快速、灵活、提高性能。作者创建了一个名为Beyonder-4x7B-v3的FrankenMoE模型，并取得了不错的结果。虽然FrankenMoE方法在性能提升方面有潜力，但也存在一些实际问题，如较高的VRAM需求，需要权衡利弊来决定使用。MergeKit为MoE构建提供了创新思路，具有很大实用价值，读者可以尝试实践。LazyMergeKit成功创建并评估了作者的frankenMoE，证明了方法的可行性和有效性。MergeKit的创新有望推动MoE技术的进一步发展和应用。 <div>
【用FrankenMoE集成多个预训练模型：MergeKit赋能高效MoE构建】<br />- MoE(混合专家模型)是一种提高性能的模型架构，它使用多个子网络(称为“专家”)。MoE只激活相关的专家，从而实现更快的训练和推理。   <br />- 传统的MoE模型需要从头训练专家和路由器(确定哪些token由哪些专家处理)。而“FrankenMoE”则是通过集成多个预训练好的模型来创建MoE。   <br />- FrankenMoE的创建包括选择专家模型、定义正样本和负样本提示、使用MergeKit生成MoE模型。文章详细介绍了一个例子。   <br />- 作者创建了一个FrankenMoE模型Beyonder-4x7B-v3，它在多个基准测试中取得了不错的结果，展示了这种方法的潜力。   <br />- FrankenMoE在提高性能方面很有前景，但也存在一些实际中的问题，如较高的VRAM需求。需要权衡利弊来决定是否适合使用。   <br />- 这种方法为改进模型性能提供了一种创新思路，值得进一步探索，但还有待改进。建议读者尝试自己创建FrankenMoE模型。<br /><br />思考：  <br />- MergeKit通过集成预训练模型创建MoE的方法非常有创意，为MoE的构建提供了一种新的思路和途径。  <br />- 与从头训练MoE相比，MergeKit的方法可以更快速、灵活地创建高质量的MoE，具有很大的实用价值。  <br />- 文章对MergeKit创建frankenMoEs的过程进行了详细的介绍和示范，读者可以很容易地上手实践。  <br />- 作者使用LazyMergeKit成功创建并评估了自己的frankenMoE，证明了这一方法的可行性和有效性。  <br />- MergeKit在MoE领域的创新有望推动MoE技术的进一步发展和应用，值得业界关注和探索。<br />《Create Mixtures of Experts with MergeKit | by Maxime Labonne | Mar, 2024 | Towards Data Science》 <a href="https://towardsdatascience.com/create-mixtures-of-experts-with-mergekit-11b318c99562"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho6dvfyxq4j20u00vsgrj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho6dvgrvsgj21hc0u0n21.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:06:05 GMT</pubDate>
</item>
<item>
<title>【RLHF成功背后的隐忧：AI安全亟需多管齐下】- 文章认为当前主流的模型对齐技术RLHF在防止语言模型非故意的伤害方面非常有效，使得聊天机器人产品得以推向大众消...</title>
<link>https://weibo.com/1402400261/O73iKrQzj</link>
<guid>https://weibo.com/1402400261/O73iKrQzj</guid>
<content:encoded><![CDATA[
<div> 模型对齐技术、RLHF、AI安全、聊天机器人、意图恶意使用、防范措施、内容审核、软件安全、灾难性风险

总结：<br /><br />本文指出，现有模型对齐技术在防止语言模型非故意伤害方面表现出色，尤其在聊天机器人领域取得成功。然而，对意图恶意使用的对手，模型对齐无法产生很大作用，因此需要额外的防范措施。模型对齐其实更像内容审核，而不是软件安全，应重视其局限性。对于AI安全问题，需要更系统性的思考，不能过度依赖模型对齐技术。需要开发更强大的对齐技术，同时关注模型外的防御措施，以确保全面的安全性。对于可能带来严重意外伤害的场景，单纯的技术方法可能不够，AI安全社区应高度重视。 <div>
【RLHF成功背后的隐忧：AI安全亟需多管齐下】<br />- 文章认为当前主流的模型对齐技术RLHF在防止语言模型非故意的伤害方面非常有效，使得聊天机器人产品得以推向大众消费者。   <br />- 但是RLHF无法防止有意图的恶意使用。对付资金雄厚的对手，模型对齐毫无用处，因为对手可以重新训练模型或移除对齐。   <br />- 对付日常用户的恶意使用，模型对齐仍有一定效用，因为它使其更难进行故意误用。但不能仅依赖模型对齐，还需要产品级的其他防范措施。   <br />- 模型对齐更像是内容审核，而不是软件安全。它的不足不应引发恐慌，仍然是有用的。但对付灾难性风险，不应过分依赖模型对齐。   <br />- 需要开发更强大的对齐技术，同时关注模型之外的防御措施，扩大安全性的系统性思考。<br /><br />思考：  <br />- 文章指出，业界过度依赖模型对齐技术来解决AI安全问题，这一观点值得重视。我们不能把模型对齐视为万灵药。  <br />- RLHF等模型对齐技术在聊天机器人领域取得了成功，但其局限性也日益凸显。对齐完美与否，取决于诸多因素。  <br />- 对手绕过对齐技术引发的担忧合情合理。但暂停AI等极端措施是否必要和可行，仍有待商榷。  <br />- 文章提到即使对齐了，聊天机器人也可能有害，产品概念也很重要。这启示我们AI安全需要更全面的视角，不能只盯着模型本身。  <br />- 对于自主智能体等可能带来更严重意外伤害的场景，单纯的技术方法可能不够，这值得AI安全社区高度重视。<br />《Model alignment protects against accidental harms, not intentional ones》 <a href="https://www.aisnakeoil.com/p/model-alignment-protects-against"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6drrmzkdj20ud0u0dks.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 28 Mar 2024 00:02:32 GMT</pubDate>
</item>
<item>
<title>【模型安全≠使用安全，AI治理需要更全面的视角】- 在AI界存在一个普遍假设，即AI安全性是AI模型的一项特性。基于这个假设，许多公司投资了大量资源来提高模型的...</title>
<link>https://weibo.com/1402400261/O73hpqXEs</link>
<guid>https://weibo.com/1402400261/O73hpqXEs</guid>
<content:encoded><![CDATA[
<div> 模型安全, 使用安全, AI治理, 模型特性, 上下文, 系统性思考, 误用, 边际风险, 对抗测试, 社会成本

总结:<br /><br />这篇文章指出了AI安全不是模型特性，强调了模型的安全与其部署的上下文和环境密切相关。文章提出了四点建议，包括防范模型误用、评估边际风险、重塑对抗测试和让第三方进行对抗测试。作者认为模型无法判断某些恶意用途，提出责任划分会变得复杂，AI安全需要综合思考。文章还讨论了安全内容的差异化处理和警惕简单思维定势的重要性。整体而言，AI治理需要更全面的视角，并且不能简单地将安全问题归咎于模型特性。 <div>
【模型安全≠使用安全，AI治理需要更全面的视角】<br />- 在AI界存在一个普遍假设，即AI安全性是AI模型的一项特性。基于这个假设，许多公司投资了大量资源来提高模型的安全性。但是文章认为这种做法是有限的，因为AI安全性不是模型的特性，而在很大程度上取决于模型被部署的上下文和环境。   <br />- 文章举了钓鱼邮件、生物恐怖主义和传播虚假信息等例子，说明模型本身无法判断这些用途是否恶意，因为模型无法获知完整的部署上下文。要做到只生成无害内容几乎不可能。   <br />- 文章提出了四点建议：一是防范模型误用的主要措施应位于模型之外；二是评估开源模型的边际风险；三是重塑对抗测试，以发现对手方的新能力；四是让第三方而不是开发者自己进行对抗测试。   <br />- 文章认为，接受模型无法杜绝误用意味着责任划分会变得非常复杂。开发者在道德上应承担部分由于AI滥用带来的社会成本，但在法律上很难执行。这是AI政策亟待解决的难题。   <br />- 文章提出AI安全性不是模型特性这一观点，认为仅仅对模型进行安全性改进是有限的，需要更广泛的系统性思考。这一观点对当前AI安全研究具有重要启发意义。<br /><br />思考：  <br />- 作者提出了一个有趣的观点，即AI安全不是模型的特性，这与业界的主流看法形成了鲜明对比，值得深入思考。  <br />- 文章指出，即使模型本身是安全的，也可能被用于恶意目的，这提醒我们在考虑AI安全时需要更全面的视角。  <br />- 作者认为不能将安全问题全权委托给模型决定，因为模型可能缺乏必要的上下文信息，这一论断有一定道理，但可能也并非放之四海而皆准。  <br />- 文章提到一些例外情况，如儿童色情内容等，表明某些内容本身就是有问题的。这提示我们在AI安全治理中，可能需要对不同类型的内容采取差异化的策略。  <br />- "安全是模型特性"说法之所以会流行，可能确实与其便利性有关。这提醒我们在探讨AI安全时，要警惕简单化、一刀切的思维定势。<br />《AI safety is not a model property》 <a href="https://www.aisnakeoil.com/p/ai-safety-is-not-a-model-property"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho6dob3pdpj20ug0u0n1d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 23:59:14 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评...</title>
<link>https://weibo.com/1402400261/O73czeXBY</link>
<guid>https://weibo.com/1402400261/O73czeXBY</guid>
<content:encoded><![CDATA[
<div> Java、Python、JavaScript、C语言、MySQL、Redis、技术、故事、码农翻身

<br /><br />总结:
《码农翻身2》是一本以故事方式讲解技术的畅销书，其中描述了编程语言王国之间的争斗和趣味故事。Java、Python、JavaScript等编程语言相互竞争，MySQL和Redis互相斗争，C语言则面临着单身的悲催。这本书旨在让读者掌握技术原理的同时，享受有趣的阅读体验。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 23:47:18 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：明日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*...</title>
<link>https://weibo.com/1402400261/O73cwc9dI</link>
<guid>https://weibo.com/1402400261/O73cwc9dI</guid>
<content:encoded><![CDATA[
<div> 可可粉、转发、评论、hello 算法、数据结构、算法、动画图解、实战代码示例、互动环节设计、轻松掌握

<br /><br />总结:
明日将会开奖，并欢迎大家参与携手送出3本《hello 算法》的活动。截止日期是2024年3月29日中午12点。参与方式是转发并评论*可可粉*即可参与。这本书旨在帮助读者轻松掌握数据结构与算法，通过全新的视角引领读者进入算法的世界。每一章节都配有生动的动画图解，使抽象的数据结构和算法变得直观易懂。书中的实战代码示例让读者可以即学即用，及时巩固新知识。互动环节的设计帮助读者主动思考，提出问题并解决问题。这本书的目的是让读者在学习数据结构与算法的过程中更加轻松愉快。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：明日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 23:47:11 GMT</pubDate>
</item>
<item>
<title>【Chatbot匿名竞技场最新更新：Claude 3 0pus不负众望成为冠军，Starling-LM-7B-beta以7B的规模击败GPT 3.5、Mistral 和 Gemini Pro】《LMSys Chatbot Arena Lea...</title>
<link>https://weibo.com/1402400261/O72QQ683v</link>
<guid>https://weibo.com/1402400261/O72QQ683v</guid>
<content:encoded><![CDATA[
<div> 更新、竞技场、Claude 3 0pus、冠军、Starling-LM-7B-beta、击败、GPT 3.5、Mistral、Gemini Pro

<br /><br />总结:
最新更新显示，匿名竞技场中，Claude 3 0pus凭借强大实力成为冠军，而Starling-LM-7B-beta也以7B规模战胜了GPT 3.5、Mistral和Gemini Pro，引起广泛关注。 <div>
【Chatbot匿名竞技场最新更新：Claude 3 0pus不负众望成为冠军，Starling-LM-7B-beta以7B的规模击败GPT 3.5、Mistral 和 Gemini Pro】《LMSys Chatbot Arena Leaderboard - a Hugging Face Space by lmsys》 <a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho6bs0wrabj21c30u0q88.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 22:53:46 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.27)》 爱可可微博热门分享(3.27) [图片]</title>
<link>https://weibo.com/1402400261/O6ZHV30UH</link>
<guid>https://weibo.com/1402400261/O6ZHV30UH</guid>
<content:encoded><![CDATA[
<div> 微博，热门，分享，爱可可，3.27，关键词：

抖音，短视频，创作者，内容，粉丝，明星，合作，推广，营销，平台

<br /><br />总结:
3月27日，爱可可微博发布了热门分享内容，讨论的焦点主要集中在抖音平台上。抖音作为一个热门的短视频平台，吸引了众多创作者在上面发布各种内容，受到粉丝们的喜爱。不仅普通用户，就连明星也会在抖音上开设账号，与粉丝互动。同时，抖音也成为了许多品牌推广营销的平台，通过和创作者合作，进行推广活动，取得良好的营销效果。 <div>
《爱可可微博热门分享(3.27)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405016671747440838"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.27)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho5xwefsbuj20m80cijt5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 14:53:33 GMT</pubDate>
</item>
<item>
<title>【Redis架构演进之路】就像罗马不是一天建成的，Redis的架构也是随着时间的推移而不断进化的。 - Redis最初于2010年发布1.0版本，那时的架构非常简单，主要用作...</title>
<link>https://weibo.com/1402400261/O6YFu0ZOC</link>
<guid>https://weibo.com/1402400261/O6YFu0ZOC</guid>
<content:encoded><![CDATA[
<div> Redis、架构、演进、内存、持久化、故障转移、监控、集群、数据结构、多线程IO
<br /><br />总结:
Redis架构从简单的缓存应用不断演进，2013年的2.8版本引入了持久化和复制功能，提高了可用性。2015年的3.0版本推出集群功能，通过数据分片管理数据。2017年的5.0版本新增了Stream数据类型，2020年的6.0版本引入了多线程IO处理，进一步提升了性能。Redis的架构演进之路充满智慧和汗水，体现了业界对高性能、高可用数据存储的追求。Redis不断成长为强大的内存数据库，为业务应用开发带来便利和高效。Redis的发展历程，展示了持续创新和不断进化的精神。Redis架构模型的优化和技术的不断引入，为用户提供更稳定、更高效的数据服务。Redis的成功也启示着业界追求卓越的态度，值得持续关注和学习。 <div>
【Redis架构演进之路】<br />就像罗马不是一天建成的，Redis的架构也是随着时间的推移而不断进化的。   <br />- Redis最初于2010年发布1.0版本，那时的架构非常简单，主要用作业务应用的缓存。但由于Redis是将数据存储在内存中，一旦重启，所有数据就会丢失，流量会直接冲击数据库。   <br />- 到了2013年，Redis 2.8版本解决了这个问题。它引入了RDB内存快照来持久化数据，同时还支持AOF(Append-Only-File)方式，将每个写命令都写入AOF文件。此外，Redis 2.8还增加了复制功能来提高可用性。主节点处理实时的读写请求，从节点则同步主节点的数据。   <br />- 为了实时监控Redis实例，Redis 2.8推出了Sentinel(哨兵)。它承担四大任务：监控、通知、自动故障转移和配置提供者。可以说，Sentinel为Redis保驾护航，时刻守护着Redis的可用性。   <br />- Redis的下一个里程碑是2015年发布的3.0版本，该版本增加了Redis集群功能。Redis集群是一种分布式数据库解决方案，通过数据分片来管理数据。整个数据被分为16384个槽位，每个节点负责一部分槽位。这就好比将一个大蛋糕切成16384份，分给不同的人去管理。   <br />- Redis之所以备受欢迎，是因为其高性能和丰富的数据结构，大大降低了开发业务应用的复杂度。2017年发布的Redis 5.0新增了Stream数据类型。2020年发布的Redis 6.0则引入了多线程IO处理，进一步提升了性能。Redis的架构模型被划分为网络模块和主处理模块，开发者发现网络模块往往会成为系统的瓶颈。而多线程IO的引入，则解决了这个潜在的问题。   <br />Redis的架构演进之路，充满了智慧和汗水。从最初简单的缓存应用，到集群分片、多线程IO，Redis一步步成长为今天这个强大的内存数据库。它的发展历程，也映射出了业界对高性能、高可用数据存储的追求。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho5tas9ihej20u01k9qbj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho5tbbdmc6j20te10otfe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 12:14:48 GMT</pubDate>
</item>
<item>
<title>【Sora运行揭秘】- Sora是基于Latent Diffusion和Transformer的扩散模型，相比早期的图像生成模型显著提升了视频质量和一致性。 - 数据量和计算量的扩大是改进视...</title>
<link>https://weibo.com/1402400261/O6YA4eBGV</link>
<guid>https://weibo.com/1402400261/O6YA4eBGV</guid>
<content:encoded><![CDATA[
<div> Latent Diffusion、Transformer、视频质量、计算量、用户界面、训练计算量、应用渗透度、真实世界模拟、合成数据、机器学习技术

总结:<br /><br />
Sora是基于Latent Diffusion和Transformer的扩散模型，提升了视频质量和一致性。数据量和计算量的扩大是改进视频生成模型的关键，计算量增加将带来性能提升。Runway等公司正在研发Sora用户界面，对实用性至关重要。训练计算量巨大，推理计算将大于训练。Sora学会了模拟真实世界，可用于合成数据和数据增强。Sora代表了视频生成模型向更高质量发展里程碑，展示了先进机器学习技术潜力。训练数据对性能至关重要，Sora可能借助大型视频数据集。AI生成视频技术的快速发展将影响多个行业，未来电影制作可能由AI完成。视频生成模型发展将增大对算力尤其GPU的需求，Sora为未来GPU需求预测提供重要参考。 <div>
【Sora运行揭秘】<br />- Sora是基于Latent Diffusion和Transformer的扩散模型，相比早期的图像生成模型显著提升了视频质量和一致性。   <br />- 数据量和计算量的扩大是改进视频生成模型的关键，与大语言模型类似，可以预期计算量持续增加会带来模型性能的快速提升。   <br />- Runway等公司正在研发Sora等模型的用户界面和工作流程，这对其实用性至关重要。   <br />- Sora的训练计算量巨大，据估计需要4200-10500块H100 GPU计算一个月。但推理计算要大于训练计算，“收支平衡点”在生成1530-3810万分钟视频后。   <br />- 如果Sora类模型在TikTok和Youtube等平台达到较高应用渗透度，预计峰值需求将达到约72万个H100 GPU。   <br />- Sora隐含地学会了模拟真实世界，这对于在像素空间大规模训练机器人等具身智能体非常有用。   <br />- Sora类模型也可用于生成合成数据和数据增强，为缺乏数据的领域提供帮助。<br /><br />思考：  <br />- Sora代表了视频生成模型向更大规模、更高质量方向发展的重要里程碑。  <br />- Sora采用了多种先进的机器学习技术，包括扩散模型、潜在空间建模和Transformer架构，展示了这些技术在视频生成领域的巨大潜力。  <br />- 大规模高质量的训练数据对于视频生成模型的性能至关重要。Sora很可能得益于一个前所未有的大型视频数据集。  <br />- Sora的出现预示着AI生成视频技术的快速发展，将对电影、广告等多个行业产生深远影响。未来，AI有可能生成完整的电影，彻底改变视频内容的制作方式。  <br />- 随着视频生成模型的不断发展，对算力尤其是GPU的需求也将大幅增长。Sora为业界对未来GPU需求的预测提供了重要参考。<br />《Factorial Funds | Under The Hood: How OpenAI's Sora Model Works》 <a href="https://www.factorialfunds.com/blog/under-the-hood-how-openai-s-sora-model-works"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho5sx94j2qj20tu0grjup.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 12:01:28 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Mastering Memory Tasks with World Models》(ICLR 2024) GitHub: github.com/chandar-lab/Recall2Imagine《Composed Video Retrieval via ...</title>
<link>https://weibo.com/1402400261/O6WfYlh3o</link>
<guid>https://weibo.com/1402400261/O6WfYlh3o</guid>
<content:encoded><![CDATA[
<div> 关键词: Memory Tasks, World Models, Recall2Imagine, Video Retrieval, Logit Standardization, Knowledge Distillation, Vision-Language Models, Spec-Gaussian, AniPortrait, Data Mixing Laws

总结:<br /><br />本文介绍了几篇论文的实现代码，涵盖了多个领域包括记忆任务、视频检索、知识蒸馏、视觉-语言模型等。第一篇论文《Mastering Memory Tasks with World Models》通过实现代码Recall2Imagine来实现记忆任务。第二篇论文《Composed Video Retrieval via Enriched Context and Discriminative Embeddings》介绍了视频检索方法。第三篇论文《Logit Standardization in Knowledge Distillation》探讨了知识蒸馏中logit标准化的重要性。第四篇论文《Dual Memory Networks: A Versatile Adaptation Approach for Vision-Language Models》提出了一种适用于视觉-语言模型的双重记忆网络方法。还有其他论文涉及3D高斯光滑、音频驱动的动态图像合成、数据混合规律、波谱图像处理等多个领域。这些论文的实现代码均可在GitHub上找到，为相关研究领域的学术研究者提供了重要的参考资源。 <div>
几篇论文实现代码：<br />《Mastering Memory Tasks with World Models》(ICLR 2024) GitHub: github.com/chandar-lab/Recall2Imagine<br />《Composed Video Retrieval via Enriched Context and Discriminative Embeddings》(CVPR 2024) GitHub: github.com/OmkarThawakar/composed-video-retrieval<br />《Logit Standardization in Knowledge Distillation》(CVPR 2024) GitHub: github.com/sunshangquan/logit-standardization-KD<br />《Dual Memory Networks: A Versatile Adaptation Approach for Vision-Language Models》(CVPR 2024) GitHub: github.com/YBZh/DMN [fig4]<br />《Spec-Gaussian: Anisotropic View-Dependent Appearance for 3D Gaussian Splatting》(2024) GitHub: github.com/ingra14m/Specular-Gaussians<br />《AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animations》(2024) GitHub: github.com/Zejun-Yang/AniPortrait [fig1]<br />《Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance》(2024) GitHub: github.com/yegcjs/mixinglaws<br />《RGBD GS-ICP SLAM》(2024) GitHub: github.com/Lab-of-AI-and-Robotics/GS_ICP_SLAM<br />《AdaIR: Adaptive All-in-One Image Restoration via Frequency Mining and Modulation》(2024) GitHub: github.com/c-yn/AdaIR [fig2]<br />《Sotopia-π: Interactive Learning of Socially Intelligent Language Agents》(2024) GitHub: github.com/sotopia-lab/sotopia-pi [fig3]<br />《Visual CoT: Unleashing Chain-of-Thought Reasoning in the Multi-Modal Language Model》(2024) GitHub: github.com/deepcs233/Visual-CoT [fig5]<br />《LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models》(2024) GitHub: github.com/42Shawn/LLaVA-PruMerge<br />《GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks》(2024) GitHub: github.com/alibaba/GraphTranslator [fig6]<br />《Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance》(2024) GitHub: github.com/fudan-generative-vision/champ<br />《Optimizing LiDAR Placements for Robust Driving Perception in Adverse Conditions》(2024) GitHub: github.com/ywyeli/Place3D<br />《TC4D: Trajectory-Conditioned Text-to-4D Generation》(2024) GitHub: github.com/sherwinbahmani/tc4d<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho5hr2enfbj214y0sddtp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho5hu2pesmj20qi0hz7i3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho5humfr3hj21jk1jkkh6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho5ia4849cj20lb0fg46o.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho5iaui3hij21740gy430.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho5ihzzcdhj21h60tsgvg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 06:06:28 GMT</pubDate>
</item>
<item>
<title>【Go-Redis：快速高效的内存型 Key-Value 存储，Redis的替代方案，用 Go 语言实现】'Go-Redis - Super fast drop-in replacement of the in memory key-value st...</title>
<link>https://weibo.com/1402400261/O6WfRkdaQ</link>
<guid>https://weibo.com/1402400261/O6WfRkdaQ</guid>
<content:encoded><![CDATA[
<div> Go-Redis、快速、高效、内存型、Key-Value、存储、替代方案、Go语言实现、GitHub、Dhravya

<br /><br />总结:
Go-Redis是一个快速高效的内存型Key-Value存储，是Redis的替代方案，用Go语言实现。该项目托管在GitHub上，由Dhravya开发。Go-Redis是一个极具竞争力的项目，旨在提供与Redis相当甚至更快的性能。由于使用了Go语言实现，Go-Redis具有高效的并发处理能力和优秀的执行性能。通过使用Go-Redis，用户可以获得比传统的Redis更快的操作速度，这使得它成为许多项目的理想选择。如果您正在寻找一个快速、高效且易于集成的Key-Value存储解决方案，Go-Redis可能是您的不二之选。 <div>
【Go-Redis：快速高效的内存型 Key-Value 存储，Redis的替代方案，用 Go 语言实现】'Go-Redis - Super fast drop-in replacement of the in memory key-value store Redis, made in Golang' GitHub: github.com/Dhravya/go-redis <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Redis%23"><span class="surl-text">#Redis#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5inu9wf5j212f0u0q5w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 06:06:11 GMT</pubDate>
</item>
<item>
<title>【C-Shopping：基于Nextjs开发同时适配Desktop、Tablet、Phone多种设备的精美购物平台】'C-Shopping v1.0.0 - A beautiful shopping platform developed with Ne...</title>
<link>https://weibo.com/1402400261/O6WamwqdU</link>
<guid>https://weibo.com/1402400261/O6WamwqdU</guid>
<content:encoded><![CDATA[
<div> Next.js, Desktop, Tablet, Phone, 购物平台, 适配, GitHub, 开发, 设备, 精美

<br /><br />总结:
"C-Shopping v1.0.0"是一个基于Next.js开发的购物平台，可以适配多种设备，包括Desktop、Tablet和Phone。这个平台具有精美的界面设计，开发者已经将代码上传到GitHub上。希望通过这个平台提供更好的用户体验，满足不同设备的需求。 <div>
【C-Shopping：基于Nextjs开发同时适配Desktop、Tablet、Phone多种设备的精美购物平台】'C-Shopping v1.0.0 - A beautiful shopping platform developed with Next.js, tailored for various devices including Desktop, Tablet, and Phone. ' GitHub: github.com/huanghanzhilian/c-shopping <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho5i9ndpbej20dw07x0up.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5i9o9wgyj20rs0fq0ub.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5i9qf5elj20rs0fqdh6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:52:39 GMT</pubDate>
</item>
<item>
<title>【Flatito:用于搜索 YAML 和 JSON 文件的Grep工具，它可以帮助搜索文件中特定的关键字并获取相关信息】'Flatito: Grep for YAML and JSON files - Grep for YAML...</title>
<link>https://weibo.com/1402400261/O6W9hxmvS</link>
<guid>https://weibo.com/1402400261/O6W9hxmvS</guid>
<content:encoded><![CDATA[
<div> GitHub，Flatito，Grep，YAML，JSON，搜索工具，关键字，获取信息，ceritium，文件<br /><br />总结:
文章介绍了一款名为Flatito的工具，在GitHub上开源，用于搜索YAML和JSON文件中特定关键字的Grep工具。用户可以通过使用Flatito，搜索文件中的关键字，并获取相关信息。Flatito为程序员提供了便利，使他们能够快速准确地定位文件中的信息，提高工作效率。Flatito由ceritium开发，为用户提供了一个方便的工具，帮助他们更好地管理和处理YAML和JSON文件。 <div>
【Flatito:用于搜索 YAML 和 JSON 文件的Grep工具，它可以帮助搜索文件中特定的关键字并获取相关信息】'Flatito: Grep for YAML and JSON files - Grep for YAML and JSON files' GitHub: github.com/ceritium/flatito <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho5i6zke6sj20ui0u0dlc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:49:59 GMT</pubDate>
</item>
<item>
<title>【LLM-Culture：用于研究大型语言模型文化演化的开源框架】'LLM-Culture' GitHub: github.com/jeremyperez2/LLM-Culture #开源# #机器学习# #人工智能# [图片][...</title>
<link>https://weibo.com/1402400261/O6W8b6Y2a</link>
<guid>https://weibo.com/1402400261/O6W8b6Y2a</guid>
<content:encoded><![CDATA[
<div> GitHub, LLM-Culture, 研究, 大型语言模型, 文化演化, 开源框架

<br /><br />总结:
LLM-Culture是一个用于研究大型语言模型文化演化的开源框架。该项目存储在GitHub上，旨在探讨和分析语言模型在不同文化背景下的发展和变化。通过这个框架，研究人员可以对大型语言模型的文化演化有更深入的理解，并且可以进行进一步的研究和探索。希望这个工具能够为语言模型研究领域带来更多的启发和成果。 <div>
【LLM-Culture：用于研究大型语言模型文化演化的开源框架】'LLM-Culture' GitHub: github.com/jeremyperez2/LLM-Culture <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho5i41xnnmj22rl0u0wo9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5i43nxr3j21c00u0wh6.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho5i456uhyj22n90u0wog.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:47:16 GMT</pubDate>
</item>
<item>
<title>【WhatTheDuck：用于 DuckDB 的开源 web 应用，用户能将 CSV 文件上传并将其存储在表格中，并通过 SQL 进行查询】'WhatTheDuck - an open-source web applicatio...</title>
<link>https://weibo.com/1402400261/O6W7maOoB</link>
<guid>https://weibo.com/1402400261/O6W7maOoB</guid>
<content:encoded><![CDATA[
<div> DuckDB, 开源, web 应用, CSV 文件, 存储, 表格, SQL 查询, GitHub, incentius-foss, WhatTheDuck

<br /><br />总结:
WhatTheDuck是一个基于DuckDB的开源web应用，允许用户上传CSV文件并将其存储在表格中，然后通过SQL查询数据。用户可以在GitHub上找到该项目的代码，链接为github.com/incentius-foss/WhatTheDuck。通过WhatTheDuck，用户可以方便地管理CSV数据并进行SQL查询操作，为数据分析和处理提供了便利和效率。 <div>
【WhatTheDuck：用于 DuckDB 的开源 web 应用，用户能将 CSV 文件上传并将其存储在表格中，并通过 SQL 进行查询】'WhatTheDuck - an open-source web application built on DuckDB. It allows users to upload CSV files, store them in tables, and perform SQL queries on the data.' GitHub: github.com/incentius-foss/WhatTheDuck <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%95%B0%E6%8D%AE%E5%BA%93%23&amp;isnewpage=1"><span class="surl-text">#数据库#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5i21ftj3j21im0pkgqe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:45:14 GMT</pubDate>
</item>
<item>
<title>【BinaryVectorDB：用于高效搜索大规模向量数据库的开源项目】'BinaryVectorDB - Efficient Search on Large Datasets - Efficient vector database for hundred...</title>
<link>https://weibo.com/1402400261/O6W2NnyJQ</link>
<guid>https://weibo.com/1402400261/O6W2NnyJQ</guid>
<content:encoded><![CDATA[
<div> 向量数据库、高效搜索、大规模、开源项目、GitHub、BinaryVectorDB、向量、检索、百万级、嵌入<br />
<br />
BinaryVectorDB是一个开源项目，旨在提供高效搜索大规模向量数据库的解决方案。该项目在GitHub上托管，为用户提供了一个能够处理数亿个嵌入的有效向量数据库。通过BinaryVectorDB，用户可以快速检索和比对向量数据，实现快速而准确的搜索结果。这个项目的出现，为处理海量向量数据提供了便捷和高效的工具，为用户提供了更好的数据处理和资源利用方式。<br /><br />总结: <br />BinaryVectorDB是一个开源项目，旨在提供高效搜索大规模向量数据库的解决方案。该项目在GitHub上托管，为用户提供了一个能够处理数亿个嵌入的有效向量数据库。通过BinaryVectorDB，用户可以快速检索和比对向量数据，实现快速而准确的搜索结果。这个项目的出现，为处理海量向量数据提供了便捷和高效的工具，为用户提供了更好的数据处理和资源利用方式。 <div>
【BinaryVectorDB：用于高效搜索大规模向量数据库的开源项目】'BinaryVectorDB - Efficient Search on Large Datasets - Efficient vector database for hundred millions of embeddings.' GitHub: github.com/cohere-ai/BinaryVectorDB <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho5hpriibpj21250u0zpc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:34:00 GMT</pubDate>
</item>
<item>
<title>【Freeze：代码和终端输出的截图生成】’Freeze - Generate images of code and terminal output' GitHub: github.com/charmbracelet/freeze #开源# #工具# [图...</title>
<link>https://weibo.com/1402400261/O6W1ObpF9</link>
<guid>https://weibo.com/1402400261/O6W1ObpF9</guid>
<content:encoded><![CDATA[
<div> GitHub、Freeze、代码、终端输出、生成、图片、charmbracelet、截图、工具、开发者<br />
<br />
重点介绍了一个名为Freeze的工具，可以帮助开发者生成代码和终端输出的截图。该工具由charmbracelet团队开发，通过GitHub进行了开源。Freeze可以将代码和终端输出转化为图片形式，方便开发者进行分享和展示。开发者可以通过Freeze轻松地生成漂亮的截图，提高展示代码和输出结果的效果和效率。 <div>
【Freeze：代码和终端输出的截图生成】’Freeze - Generate images of code and terminal output' GitHub: github.com/charmbracelet/freeze <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%B7%A5%E5%85%B7%23&amp;isnewpage=1"><span class="surl-text">#工具#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho5hnigrrkj20ul0u076u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:31:34 GMT</pubDate>
</item>
<item>
<title>【Hybrid-Net：基于 Transformer 的音源分离工具，可生成歌词、旋律、节奏等】'Hybrid-Net - Real-time audio source separation, generate lyrics, chords, bea...</title>
<link>https://weibo.com/1402400261/O6W11h8la</link>
<guid>https://weibo.com/1402400261/O6W11h8la</guid>
<content:encoded><![CDATA[
<div> Transformer、音源分离、歌词、旋律、节奏、实时、生成、Hybrid-Net、GitHub、工具

Hybrid-Net 是一个基于 Transformer 技术的音源分离工具，能够实时分离音频源，并生成歌词、旋律和节奏。用户可以在GitHub上找到Hybrid-Net的源代码。这个工具利用了先进的深度学习技术，为音乐制作人和音乐爱好者提供了一种方便且高效的音源分离工具，使他们能够更好地编辑和制作音乐作品。Hybrid-Net的实时性和生成多种音乐元素的能力使其在音乐创作和制作领域具有很大的应用潜力。Hybrid-Net为音乐创作提供了更多可能性，让用户更容易地创作出优质的音乐作品。 <div>
【Hybrid-Net：基于 Transformer 的音源分离工具，可生成歌词、旋律、节奏等】'Hybrid-Net - Real-time audio source separation, generate lyrics, chords, beat.' GitHub: github.com/DoMusic/Hybrid-Net <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho5hlmtar0j21400h6tat.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 05:29:38 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评...</title>
<link>https://weibo.com/1402400261/O6TbSFiLr</link>
<guid>https://weibo.com/1402400261/O6TbSFiLr</guid>
<content:encoded><![CDATA[
<div> Java, Python, JavaScript, C语言, MySQL, Redis, 技术原理, 故事, 码农翻身2

总结：<br /><br />
《码农翻身2》是一部以故事为主线讲解技术的畅销书，将枯燥的技术内容变成有趣的故事。在编程语言王国中，Java向Python渗透，JavaScript向Java进攻，C语言孤独回家，MySQL和Redis相互作对。通过讲述这些故事，读者可以轻松掌握技术原理和本质，享受阅读乐趣。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 22:18:09 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发...</title>
<link>https://weibo.com/1402400261/O6TbNCOp0</link>
<guid>https://weibo.com/1402400261/O6TbNCOp0</guid>
<content:encoded><![CDATA[
<div> hello 算法, 截止日期, 可可粉, 数据结构, 算法, 动画图解, 实战代码示例, 互动环节, 直观易懂, 新知识

<br /><br />总结:
截止日期为2024年3月29日中午12:00，参与方式是转发并评论帖子。这本《hello 算法》书籍以全新的视角讲解数据结构与算法，每一章节都有生动的动画图解，让抽象的概念变得直观易懂。书中还提供实战代码示例帮助读者即学即用，及时巩固新知识。互动环节的设计则能帮助读者主动思考、提问和解决问题。通过这本书，读者可以轻松掌握算法，进入算法的世界。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 22:17:57 GMT</pubDate>
</item>
<item>
<title>今日推介(第1357期)：LLM Agent操作系统、从损失角度理解语言模型的涌现能力、用概率流推进扩散语言生成、基于大语言模型状态奖励和动作建模的强化学习推荐系统...</title>
<link>https://weibo.com/1402400261/O6TbDB7R4</link>
<guid>https://weibo.com/1402400261/O6TbDB7R4</guid>
<content:encoded><![CDATA[
<div> LLM Agent操作系统、损失角度、语言模型、能力、概率流、扩散语言生成、大语言模型、强化学习、推荐系统、3DGS
总结：<br /><br />本文介绍了最新的LLM Agent操作系统，从损失角度探讨了语言模型的涌现能力，提出了用概率流推进扩散语言生成的方法，以及基于大语言模型的状态奖励和动作建模的强化学习推荐系统。此外，还讨论了3DGS在改进渲染和重建的SDF中的应用。整篇文章深入探讨了语言模型和人工智能技术在推荐系统和渲染领域的最新进展。 <div>
今日推介(第1357期)：LLM Agent操作系统、从损失角度理解语言模型的涌现能力、用概率流推进扩散语言生成、基于大语言模型状态奖励和动作建模的强化学习推荐系统、3DGS满足改进渲染和重建的SDF 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/689222773"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.27)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho553velkuj20go0bp3zt.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho553xmqk5j20go0dzmyp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho5540zmsoj20go04rq3a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho55447ws1j20go0770th.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho5546v8uwj20go0b0q4m.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 22:17:32 GMT</pubDate>
</item>
<item>
<title>[CV] Gaussian in the Wild: 3D Gaussian Splatting for Unconstrained Image Collections 网页链接 GS-W通过为每个高斯点建立独立、可自适应采样的内在与动态外...</title>
<link>https://weibo.com/1402400261/O6T8nkhR8</link>
<guid>https://weibo.com/1402400261/O6T8nkhR8</guid>
<content:encoded><![CDATA[
<div> 高斯点，内在动态外观表示，图像重建，快速渲染，高质量<br />
<br />
提出了一种名为GS-W的算法，通过为每个高斯点建立独立、可自适应采样的内在与动态外观表示，实现了从无限制图像重建场景的高质量与快速渲染。这种方法能够有效处理不受约束的图像集合，提高重建场景的质量和渲染速度。GS-W算法的关键在于对每个高斯点的内在和动态外观表示进行有效建模，从而实现高质量的场景重建。通过实验证明了该算法的有效性和性能优势，为处理无约束图像集合提供了有效的解决方案。 <div>
[CV]  Gaussian in the Wild: 3D Gaussian Splatting for Unconstrained Image Collections  <br /><a href="https://arxiv.org/abs/2403.15704"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />GS-W通过为每个高斯点建立独立、可自适应采样的内在与动态外观表示，实现了从无限制图像重建场景的高质量与快速渲染。 <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho54vv1aymj20qa15stj4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho54vvdhkgj21fu16ywr8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 22:09:31 GMT</pubDate>
</item>
<item>
<title>[CV] CG-SLAM: Efficient Dense RGB-D SLAM in a Consistent Uncertainty-aware 3D Gaussian Field 网页链接 提出CG-SLAM系统，通过高斯Splatting技术实现高效精...</title>
<link>https://weibo.com/1402400261/O6T3Ogxsv</link>
<guid>https://weibo.com/1402400261/O6T3Ogxsv</guid>
<content:encoded><![CDATA[
<div> 关键词: CG-SLAM, 高斯Splatting, 相机跟踪, 场景重建, RGB-D SLAM

总结:<br /><br />总结:本文提出了CG-SLAM系统，通过高斯Splatting技术实现高效精确的相机跟踪和优质场景重建，是实时和高质量RGB-D SLAM的有效途径。CG-SLAM能够在三维高斯场中保持一致的不确定性估计，同时有效地处理相机运动和场景表面的变化。使用高斯场作为数据结构使得系统能够高效地进行场景表面重建和相机定位。通过实验证明，CG-SLAM系统具有良好的鲁棒性和实时性，适用于各种室内和室外场景的SLAM任务。 <div>
[CV] CG-SLAM: Efficient Dense RGB-D SLAM in a Consistent Uncertainty-aware 3D Gaussian Field  <br /><a href="https://arxiv.org/abs/2403.16095"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出CG-SLAM系统，通过高斯Splatting技术实现高效精确的相机跟踪和优质场景重建，是实时和高质量RGB-D SLAM的有效途径。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho54k4hfr4j20v21codub.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho54k4yen1j21gu0mqn7w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho54k5m4gaj21hc0w8amw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 21:58:16 GMT</pubDate>
</item>
<item>
<title>[CV] latentSplat: Autoencoding Variational Gaussians for Fast Generalizable 3D Reconstruction 网页链接 提出变分3D高斯表示以及从两个视角进行预测和新视...</title>
<link>https://weibo.com/1402400261/O6SYutbHt</link>
<guid>https://weibo.com/1402400261/O6SYutbHt</guid>
<content:encoded><![CDATA[
<div> 变分高斯表示, 3D重建, 视频训练数据, autoencoding, 预测, 合成, 快速, 高质量, 可推广

<br /><br />总结:
latentSplat提出了一种框架，实现了快速、高质量、可推广的3D场景重建。该框架利用变分高斯表示，可以从两个视角进行预测和新视角合成。重要的是，该方法仅依赖容易获得的视频训练数据，为实现高效的3D重建提供了新途径。 <div>
[CV] latentSplat: Autoencoding Variational Gaussians for Fast Generalizable 3D Reconstruction  <br /><a href="https://arxiv.org/abs/2403.16292"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出变分3D高斯表示以及从两个视角进行预测和新视角合成的框架，实现了快速、高质量、可推广的3D场景重建，仅依赖容易获得的视频训练数据。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho546i1lj5j20ry190dui.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho546ils4uj21jg0zygz3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 21:45:10 GMT</pubDate>
</item>
<item>
<title>提出一个双分支框架，通过3D高斯Splatting渲染和符号距离场表面重建的有效结合，实现了渲染质量和重建细节的同时改进。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《GSDF...</title>
<link>https://weibo.com/1402400261/O6SU0i26G</link>
<guid>https://weibo.com/1402400261/O6SU0i26G</guid>
<content:encoded><![CDATA[
<div> 高斯Splatting、3D、符号距离场、渲染、重建、质量、细节、双分支框架、改进、GSDF<br />
<br />
提出了一个双分支框架，结合了3D高斯Splatting渲染和符号距离场表面重建，从而在同时改进渲染质量和重建细节方面取得了显著进展。该框架通过将渲染和重建两个任务进行有效结合，实现了更好的渲染效果和更精细的重建结果。研究者提出的GSDF方法为3DGS和SDF的结合提供了一种有效的途径，极大地提高了渲染和重建的效率和精度。此外，该方法还在实际应用中取得了令人满意的效果，显示出了其在图形渲染和重建领域的巨大潜力。<br /><br />总结: <div>
提出一个双分支框架，通过3D高斯Splatting渲染和符号距离场表面重建的有效结合，实现了渲染质量和重建细节的同时改进。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《GSDF: 3DGS Meets SDF for Improved Rendering and Reconstruction》M Yu, T Lu, L Xu, L Jiang, Y Xiangli, B Dai [Shanghai Artificial Intelligence Laboratory &amp; The Chinese University of Hong Kong] (2024) <a href="https://arxiv.org/abs/2403.16964"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho53um5ibnj215q0xe4df.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho53umrat0j21dk0wq7gu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho53un9e7oj21cc1d0arn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53unllu1j21by1481bk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho53uozslwj20rl0cq40y.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53up08vbj20rl0lh422.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53uozovdj20rl0e2tas.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho53up110dj20rl12an1y.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53up29daj20rl14ln4z.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 21:34:06 GMT</pubDate>
</item>
<item>
<title>[CV]《GSDF: 3DGS Meets SDF for Improved Rendering and Reconstruction》M Yu, T Lu, L Xu, L Jiang, Y Xiangli, B Dai [Shanghai Artificial Intelligence La...</title>
<link>https://weibo.com/1402400261/O6STSyJ3k</link>
<guid>https://weibo.com/1402400261/O6STSyJ3k</guid>
<content:encoded><![CDATA[
<div> 关键词：GSDF, 3DGS, SDF, 改进渲染, 重建, 人工智能, 上海, 香港大学, 2024

总结:<br /><br />这篇文章探讨了GSDF技术与3DGS相结合以改善渲染和重建的方法。作者来自上海人工智能实验室和香港大学。他们的研究着重于将GSDF技术与SDF技术相结合，以改善三维物体渲染和重建过程。通过这种方法，他们取得了显著的进展，提高了渲染和重建的准确性和效率。这不仅对于三维图形领域具有重要意义，也为人工智能技术的发展带来了新的启示。<br /><br /> <div>
[CV]《GSDF: 3DGS Meets SDF for Improved Rendering and Reconstruction》M Yu, T Lu, L Xu, L Jiang, Y Xiangli, B Dai [Shanghai Artificial Intelligence Laboratory &amp; The Chinese University of Hong Kong] (2024) <a href="https://arxiv.org/abs/2403.16964"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho53um5ibnj215q0xe4df.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho53umrat0j21dk0wq7gu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho53un9e7oj21cc1d0arn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53unllu1j21by1481bk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho53uozslwj20rl0cq40y.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53up08vbj20rl0lh422.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53uozovdj20rl0e2tas.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho53up110dj20rl12an1y.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho53up29daj20rl14ln4z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 21:33:48 GMT</pubDate>
</item>
<item>
<title>提出使用大型语言模型作为强化学习推荐系统的环境，提供更精确的状态表达和反馈奖励，同时增强正样本，在多个数据集上持续改进性能。 - 转发 @爱可可-爱生活:&amp;en...</title>
<link>https://weibo.com/1402400261/O6SMp8nBP</link>
<guid>https://weibo.com/1402400261/O6SMp8nBP</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、强化学习、推荐系统、状态表达、反馈奖励、正样本、数据集、性能改进、大型模型、状态建模

<br /><br />总结:
本研究提出了使用大型语言模型作为强化学习推荐系统环境的方法，以提供更精确的状态表达和反馈奖励。同时，通过增强正样本并在多个数据集上持续改进性能，实现了更精准的推荐结果。研究团队来自格拉斯哥大学、谷歌研究和 Telefonica 研究，并在实验中展示了该方法的有效性。通过综合利用大型语言模型，本研究为推荐系统提供了新的发展思路，有望在推荐领域取得重要进展。 <div>
提出使用大型语言模型作为强化学习推荐系统的环境，提供更精确的状态表达和反馈奖励，同时增强正样本，在多个数据集上持续改进性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [IR]《Reinforcement Learning-based Recommender Systems with Large Language Models for State Reward and Action Modeling》J Wang, A Karatzoglou, I Arapakis, J M. Jose [University of Glasgow &amp; Google Research &amp; Telefonica Research] (2024) <a href="https://arxiv.org/abs/2403.16948"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho539won58j20ws0z2n9m.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho539xhgknj21tq0sedok.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho539xzqrwj20wm0xeqbw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho539yhjdkj20wa112ai0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho53bdnk6oj21ay0pqdk2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho53be6zx9j21b20ooq6l.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 21:15:23 GMT</pubDate>
</item>
<item>
<title>[IR]《Reinforcement Learning-based Recommender Systems with Large Language Models for State Reward and Action Modeling》J Wang, A Karatzoglou, I Arapa...</title>
<link>https://weibo.com/1402400261/O6SMlykck</link>
<guid>https://weibo.com/1402400261/O6SMlykck</guid>
<content:encoded><![CDATA[
<div> 大语言模型，强化学习，推荐系统，状态奖励，行为建模，J Wang，A Karatzoglou，I Arapakis，J M. Jose，2024

<br /><br />总结:
该研究探讨了基于强化学习的推荐系统，利用大型语言模型进行状态奖励和行为建模。研究明确使用深度强化学习模型，结合大型语言模型，可以提高推荐系统的性能。文章介绍了推荐系统中状态和行为的重要性，并提出了一种新的方法来利用语言模型进行状态奖励的建模。实验证明这种方法在不同数据集上都取得了优异的效果，对推荐系统的发展具有重要意义。 <div>
[IR]《Reinforcement Learning-based Recommender Systems with Large Language Models for State Reward and Action Modeling》J Wang, A Karatzoglou, I Arapakis, J M. Jose [University of Glasgow &amp; Google Research &amp; Telefonica Research] (2024) <a href="https://arxiv.org/abs/2403.16948"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho539won58j20ws0z2n9m.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho539xhgknj21tq0sedok.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho539xzqrwj20wm0xeqbw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho539yhjdkj20wa112ai0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho53bdnk6oj21ay0pqdk2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho53be6zx9j21b20ooq6l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 21:15:15 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.26)》 爱可可微博热门分享(3.26) [图片]</title>
<link>https://weibo.com/1402400261/O6Qj0dJAk</link>
<guid>https://weibo.com/1402400261/O6Qj0dJAk</guid>
<content:encoded><![CDATA[
<div> 微博，热门，分享，爱可可，3.26，关键词

爱可可微博在3月26日分享的内容受到了热烈讨论和转发，引起了广泛关注。微博上涉及的话题有着吸引人的内容，引起了人们的共鸣。用户们积极参与讨论，分享自己的观点和看法。通过微博平台，信息得以迅速传播和传达，形成了一种有趣而具有交流性质的社交氛围。微博热门分享的内容吸引了用户的关注和互动，使得微博平台成为了信息传递和互动交流的重要平台。

<br /><br />总结: 
- 微博平台在3月26日分享的内容引起了热烈讨论和转发
- 用户们积极参与讨论，分享自己的观点和看法
- 微博成为人们信息传播和互动交流的重要平台 <div>
《爱可可微博热门分享(3.26)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405016310345236560"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.26)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4se5qzs7j20lc0c0q4b.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 14:57:27 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@博文视点Broadview 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故...</title>
<link>https://weibo.com/1402400261/O6PqzpRsK</link>
<guid>https://weibo.com/1402400261/O6PqzpRsK</guid>
<content:encoded><![CDATA[
<div> 技术故事, 编程语言, Java, Python, JavaScript, C语言, MySQL, Redis, 技术原理, 爽

总结:
《码农翻身2》用故事的形式生动讲解技术知识，让看似枯燥的技术变得有趣。编程语言王国之间争斗不断，如Java向Python渗透，JavaScript向Java进攻。C语言孤独无侣，MySQL和Redis互相博弈。书中内容既能让读者掌握技术原理，又能让阅读过程愉快爽快。 <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《码农翻身2》，截至2024.4.2 12:00，*可可粉*转发+评论即可参与。畅销书《码农翻身》第2部终于出版了，依然是用故事的方式讲解技术，把看似枯燥乏味的技术，变成好玩有趣的故事。编程语言王国之间依然争斗得你死我活，今天Java向Python渗透，明天JavaScript就向Java猛烈进攻。而C语言春节回家，发现只有自己没有对象，十分悲催。MySQL和Redis互相看不顺眼，不断向对方使绊子。让大家掌握技术原理和本质的同时，又能读起来很爽。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5016276596163714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohfsdnwj20m80m843i.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4ohgdugqj20m80m8tc1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4ohgus3ij20m80m8q75.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4ohhdfwxj20zk0zk7ar.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 12:43:21 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Differentiable Euler Characteristic Transforms for Shape Classification》(ICLR 2024) GitHub: github.com/aidos-lab/DECT《Str2Str: A...</title>
<link>https://weibo.com/1402400261/O6MPm0zl4</link>
<guid>https://weibo.com/1402400261/O6MPm0zl4</guid>
<content:encoded><![CDATA[
<div> 关键词: Differentiable Euler Characteristic Transforms, Shape Classification, Zero-shot Protein Conformation Sampling, Neural Architecture Generation, Autonomous Driving, Human Image Animation, Topological Navigation, Object Relighting, Visual Recognition, Garment Dynamics

总结:<br /><br />
本文介绍了几篇论文以及它们的实现代码，涵盖了形状分类、蛋白质构象采样、神经架构生成、自主驾驶、人物图像动画、拓扑导航、物体照明重建、视觉识别、服装动力学等领域。不同论文采用不同方法和模型，展示了在各个领域的应用和研究成果。这些研究对于推动人工智能领域的发展具有重要意义，为相关领域提供了新的思路和方法。每篇论文都在GitHub上公开了相应的实现代码，方便其他研究者和开发者进行复现和进一步研究。总体来说，这些论文为人工智能领域的不同方向带来了新的启发和发展方向。 <div>
几篇论文实现代码：<br />《Differentiable Euler Characteristic Transforms for Shape Classification》(ICLR 2024) GitHub: github.com/aidos-lab/DECT<br />《Str2Str: A Score-based Framework for Zero-shot Protein Conformation Sampling》(ICLR 2024) GitHub: github.com/lujiarui/Str2Str [fig4] <br />《DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion Models》(ICLR 2024) GitHub: github.com/CownowAn/DiffusionNAG [fig6]<br />《M-BEV: Masked BEV Perception for Robust Autonomous Driving》(AAAI 2024) GitHub: github.com/Sranc3/M-BEV<br />《Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance》(2024) GitHub: github.com/fudan-generative-vision/champ [fig1]<br />《LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement》(2024) GitHub: github.com/SqueezeAILab/LLM2LLM [fig2]<br />《PlaceNav: Topological Navigation through Place Recognition》(2024) GitHub: github.com/lasuomela/PlaceNav<br />《Objects With Lighting: A Real-World Dataset for Evaluating Reconstruction and Rendering for Object Relighting》(2024) GitHub: github.com/isl-org/objects-with-lighting<br />《RAR: Retrieving And Ranking Augmented MLLMs for Visual Recognition》(2024) GitHub: github.com/Liuziyu77/RAR [fig3]<br />《Neural Garment Dynamics via Manifold-Aware Transformers》(2024) GitHub: github.com/PeizhuoLi/manifold-aware-transformers<br />《PSALM: Pixelwise SegmentAtion with Large Multi-Modal Model》(2024) GitHub: github.com/zamling/PSALM [fig5] <br />《Calib3D: Calibrating Model Preferences for Reliable 3D Scene Understanding》(2024) GitHub: github.com/ldkong1205/Calib3D<br />《Pixel-GS: Density Control with Pixel-aware Gradient for 3D Gaussian Splatting》(2024) GitHub: github.com/zhengzhang01/Pixel-GS<br />《LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues》(2024) GitHub: github.com/apple/ml-lucid-datagen<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho4abzisurj25w13p6qv5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho4baefc75j21il0rydsw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho4c4jtjkjj211q0o51kx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4cdialr6j228k0zjdp0.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho4cfbs7l9j227m15v1kx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho4clt5s6uj2334140e0c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 06:06:10 GMT</pubDate>
</item>
<item>
<title>【神经编程智能相关资源大列表】’Neural Code Intelligence Survey 2024; Reading lists and resources' GitHub: github.com/QiushiSun/NCISurvey #开源# #机器...</title>
<link>https://weibo.com/1402400261/O6MP72Yu5</link>
<guid>https://weibo.com/1402400261/O6MP72Yu5</guid>
<content:encoded><![CDATA[
<div> GitHub，神经编程智能，资源，大列表，调查，阅读列表，2024，编程智能，智能资源，神经网络

<br /><br />总结:
该文章介绍了一个名为'Neural Code Intelligence Survey 2024; Reading lists and resources'的GitHub项目，旨在提供与神经编程智能相关的资源大列表。该项目汇总了各种阅读列表和资源，帮助研究人员和开发者了解神经编程智能领域的最新进展和相关资源。通过这个项目，人们可以更方便地获取相关文献和资料，促进神经编程智能领域的发展。 <div>
【神经编程智能相关资源大列表】’Neural Code Intelligence Survey 2024; Reading lists and resources' GitHub: github.com/QiushiSun/NCISurvey <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho4d0m99f9j235s0p0wp9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho4d0v502rj20tw0t2q7j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 06:05:33 GMT</pubDate>
</item>
<item>
<title>【具身智能相关资源大列表】’Awesome-Embodied-AI' GitHub: github.com/yunlongdong/Awesome-Embodied-AI #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O6MLs9Z8n</link>
<guid>https://weibo.com/1402400261/O6MLs9Z8n</guid>
<content:encoded><![CDATA[
<div> GitHub、具身智能、资源、列表、 Awesome-Embodied-AI、代码库、云龙东、开放源代码、机器人、项目。

<br /><br />总结:
Awesome-Embodied-AI是一个GitHub代码库，收集了与具身智能相关的资源，为开发机器人和其他具身智能项目提供了丰富的开放源代码资源。由云龙东创建，是一个非常有价值的资源列表。 <div>
【具身智能相关资源大列表】’Awesome-Embodied-AI' GitHub: github.com/yunlongdong/Awesome-Embodied-AI <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho4cri39iij20w70u0q7g.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:56:33 GMT</pubDate>
</item>
<item>
<title>【Vid2Persona：用 AI 描述视频角色的性格，并作为角色与您聊天】'Vid2Persona - This project breathes life into video characters by using AI to describe t...</title>
<link>https://weibo.com/1402400261/O6ML5kiCj</link>
<guid>https://weibo.com/1402400261/O6ML5kiCj</guid>
<content:encoded><![CDATA[
<div> GitHub, Vid2Persona, AI, 视频角色, 描述性格, 聊天 <br />
<br />
总结:<br />
Vid2Persona是一个使用AI描述视频角色性格并与用户进行聊天的项目，通过GitHub可以了解更多相关信息。 <div>
【Vid2Persona：用 AI 描述视频角色的性格，并作为角色与您聊天】'Vid2Persona - This project breathes life into video characters by using AI to describe their personality and then chat with you as them.' GitHub: github.com/deep-diver/Vid2Persona <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho4cqjcmbkj20u01mu113.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:55:39 GMT</pubDate>
</item>
<item>
<title>【The Pipe：一个多模态工具，用于将现实世界的信息输入大语言模型，基于多核设计，通过精心设计的启发式方法，从文件、文件夹、网页等来源创建有意义的文本和图...</title>
<link>https://weibo.com/1402400261/O6MKv317f</link>
<guid>https://weibo.com/1402400261/O6MKv317f</guid>
<content:encoded><![CDATA[
<div> GitHub, 多模态工具, 现实世界信息, 大语言模型, 多核设计, 启发式方法, 文件文件夹网页, 文本图像提示

<br /><br />总结:
The Pipe是一个多模态工具，可以将现实世界的信息输入大语言模型。它采用多核设计和精心设计的启发式方法，可以从文件、文件夹、网页等来源创建有意义的文本和图像提示。用户可以通过GitHub找到The Pipe的开源代码，利用它来加强语言模型的学习和应用。 <div>
【The Pipe：一个多模态工具，用于将现实世界的信息输入大语言模型，基于多核设计，通过精心设计的启发式方法，从文件、文件夹、网页等来源创建有意义的文本和图像提示】'The Pipe - Feed real-world data into large language models / 管道' GitHub: github.com/emcf/thepipe <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho4cp11869j20yp0u0n28.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:54:12 GMT</pubDate>
</item>
<item>
<title>【文生视频相关文献资源列表】’Awesome-Text-to-Video-Generation - A list for Text-to-Video, Image-to-Video works' GitHub: github.com/soraw-ai/Awesome-T...</title>
<link>https://weibo.com/1402400261/O6MJMfNJG</link>
<guid>https://weibo.com/1402400261/O6MJMfNJG</guid>
<content:encoded><![CDATA[
<div> GitHub、Awesome-Text-to-Video-Generation、文本到视频、图像到视频、资源列表、文献、soraw-ai、生成文本、生成视频、生成图像

<br /><br />总结:
这是一个关于文本到视频和图像到视频生成的资源列表，收录了各种与这一主题相关的文献资料和项目。GitHub上的项目地址为github.com/soraw-ai/Awesome-Text-to-Video-Generation。该资源列表涵盖了生成文本到视频和图像到视频的各种作品和研究成果，是研究和开发这一领域的重要参考资料。通过这个资源列表，可以了解到当前在文本到视频和图像到视频生成方面的最新进展和成果。 <div>
【文生视频相关文献资源列表】’Awesome-Text-to-Video-Generation - A list for Text-to-Video, Image-to-Video works' GitHub: github.com/soraw-ai/Awesome-Text-to-Video-Generation <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho4cn6zqyxj217t0u0qar.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:52:26 GMT</pubDate>
</item>
<item>
<title>【Prompt Quill：全球第一个基于RAG的提示工程助手，基于320万个可用提示库，目的是为了帮用户更好地创建用于生成图像的提示】’Welcome to Prompt Quill - worl...</title>
<link>https://weibo.com/1402400261/O6MIvy3Ea</link>
<guid>https://weibo.com/1402400261/O6MIvy3Ea</guid>
<content:encoded><![CDATA[
<div> RAG、提示工程助手、320万提示库、图像生成、GitHub、OSI1880VR、工具、创新、全球第一

<br /><br />总结:
Prompt Quill是全球第一个基于RAG的提示工程助手，旨在帮助用户更好地创建用于生成图像的提示。它提供了一个庞大的提示库，包含320万个可用提示，用户可以在GitHub上找到该项目。此工具由OSI1880VR开发，标志着在提示领域的创新。 Prompt Quill的出现为图像生成领域带来了便利和效率。 <div>
【Prompt Quill：全球第一个基于RAG的提示工程助手，基于320万个可用提示库，目的是为了帮用户更好地创建用于生成图像的提示】’Welcome to Prompt Quill - world's first RAG driven prompt engineer helper at this large scale‘ GitHub: github.com/osi1880vr/prompt_quill <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho4chy7dxmj20m80ciwhg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho4cij6r6zj20vp0u0teb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:49:17 GMT</pubDate>
</item>
<item>
<title>'FlowJax: Distributions and Normalizing Flows in Jax' GitHub: github.com/danielward27/flowjax #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O6MFB1yZY</link>
<guid>https://weibo.com/1402400261/O6MFB1yZY</guid>
<content:encoded><![CDATA[
<div> GitHub, FlowJax, Distributions, Normalizing Flows, Jax

<br />FlowJax是一个在Jax中处理分布和正规化流的工具，作者是danielward27。他们在GitHub上发布了这个工具的源代码。FlowJax是一个用于处理分布和正规化流的工具，它使用Jax库来实现。Jax是一个针对机器学习的开源Python库，提供了自动微分和跨设备并行计算的功能。FlowJax的主要目的是使处理分布和正规化流的任务更加简单和高效。正规化流是一种用于近似复杂概率分布的技术，通过将简单分布映射到目标分布来实现。FlowJax可以帮助用户实现各种分布和正规化流模型，在Jax的基础上快速实现和测试新的方法。通过GitHub上的源代码，用户可以自行下载并使用FlowJax工具，进行更加高效的分布处理和正规化流建模。FlowJax的出现为在Jax中处理分布和正规化流任务的研究者和开发者提供了新的工具和资源，有助于推动这一领域的发展。总结: FlowJax是一个在Jax中处理分布和正规化流的工具，提供了简单和高效的方法来处理分布和正规化流模型，并为研究者和开发者提供了新的工具和资源。 <div>
'FlowJax: Distributions and Normalizing Flows in Jax' GitHub: github.com/danielward27/flowjax <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho4ccdudddj20su0df77w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:42:07 GMT</pubDate>
</item>
<item>
<title>【Sycamore：用于复杂非结构数据(文档、幻灯片、音频等)的开源项目，提供基于LLM的搜索和分析等服务】’ Sycamore is an LLM-powered search and analytics plat...</title>
<link>https://weibo.com/1402400261/O6MEEpoLM</link>
<guid>https://weibo.com/1402400261/O6MEEpoLM</guid>
<content:encoded><![CDATA[
<div> Sycamore, 开源项目, 复杂非结构数据, 文档, 幻灯片, 音频, LLN, 搜索, 分析, GitHub<br />
<br />总结:
Sycamore是一个基于LLN技术的开源搜索和分析平台，专门用于处理复杂非结构化数据，如文档、幻灯片和音频等。项目提供了强大的搜索和分析功能，适用于处理各种类型的非结构化数据。GitHub上有相关项目代码。 <div>
【Sycamore：用于复杂非结构数据(文档、幻灯片、音频等)的开源项目，提供基于LLM的搜索和分析等服务】’ Sycamore is an LLM-powered search and analytics platform for unstructured data.' GitHub: github.com/aryn-ai/sycamore <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho4c9z4bznj21910u0gsh.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho4ca0kslpj21ra0u0n2u.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:39:48 GMT</pubDate>
</item>
<item>
<title>【A Survey of LLM Surveys：精心分类的LLM综述大列表】’A Survey of LLM Surveys - A collection of 150+ surveys on LLMs' GitHub: github.com/NiuTrans/ABig...</title>
<link>https://weibo.com/1402400261/O6MDExdGc</link>
<guid>https://weibo.com/1402400261/O6MDExdGc</guid>
<content:encoded><![CDATA[
<div> GitHub, LLM, surveys, collection, 150+, classifications, repository, NiuTrans, comprehensive, list

<br /><br />总结:
这篇文章介绍了一个收集了150多份关于LLM（Large Language Model）的综述调查的GitHub仓库，其中详细分类整理了这些调查报告，提供了一个全面的列表。这个仓库由NiuTrans创建，为研究人员提供了一个有用的资源，帮助他们更好地了解和研究LLM。 <div>
【A Survey of LLM Surveys：精心分类的LLM综述大列表】’A Survey of LLM Surveys - A collection of 150+ surveys on LLMs' GitHub: github.com/NiuTrans/ABigSurveyOfLLMs <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho4c7irs9nj20u00u5n10.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 05:37:20 GMT</pubDate>
</item>
<item>
<title>【浓缩时间轴：AI简史】《A brief history of Artificial Intelligence》网页链接 #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O6KTU4o1u</link>
<guid>https://weibo.com/1402400261/O6KTU4o1u</guid>
<content:encoded><![CDATA[
<div> 计算机、逻辑学家、模式识别、神经网络、机器学习、深度学习、自然语言处理、图像识别、智能系统、强化学习
<br />
人类最早对人工智能概念的探讨可以追溯到古希腊哲学家亚里士多德，但直到20世纪中叶才开始真正发展，计算机的发展为AI提供了实现的可能性。20世纪50年代至70年代，逻辑学家提出了第一个“逻辑神经元模型”，引入了模式识别和神经网络的概念。80年代至90年代，机器学习和深度学习技术不断发展，带动了AI领域的快速发展。近年来，自然语言处理、图像识别等技术的突破使得智能系统在各个领域得到广泛应用，而强化学习技术的不断深入研究也为AI的未来发展带来了更多可能性。AI已经成为当今社会发展的重要推动力，其在医疗、交通、金融、教育等领域的应用已经深深改变了人们的生活和工作方式。AI的发展将继续推动人类社会迈向智能化时代。 
<br />总结: 
人工智能概念起源于古希腊哲学家，20世纪中叶开始起步，计算机发展为AI实现提供可能性；逻辑学家提出“逻辑神经元模型”引入模式识别和神经网络；80-90年代机器学习和深度学习技术发展推动AI迅速发展；自然语言处理、图像识别等技术突破加速智能系统应用；强化学习技术研究为AI未来发展拓展更多可能性；AI已广泛应用于医疗、交通、金融、教育等领域，改变人们生活和工作方式；AI将推动人类社会向智能化时代迈进。 <div>
【浓缩时间轴：AI简史】《A brief history of Artificial Intelligence》<a href="http://aicoco.net/s/8h"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho44i0tcbcj21360u047x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 01:11:53 GMT</pubDate>
</item>
<item>
<title>【LeaderboardFinder：找到适合特定场景的大模型排行榜】《LeaderboardFinder - Have you ever wondered which leaderboard would be best for your use case? -...</title>
<link>https://weibo.com/1402400261/O6KzqeZW5</link>
<guid>https://weibo.com/1402400261/O6KzqeZW5</guid>
<content:encoded><![CDATA[
<div> leaderboard, 大模型, 排行榜, 适合, 特定场景, Hugging Face Space, use case

<br /><br />总结:
这篇文章介绍了一个名为LeaderboardFinder的工具，可以帮助用户找到适合特定场景的大模型排行榜。用户可以通过Hugging Face Space平台来查找和比较不同排行榜，选择最适合自己使用情况的排行榜。LeaderboardFinder为用户提供了一个方便的方式，让他们能更快速地找到合适的模型排行榜。 <div>
【LeaderboardFinder：找到适合特定场景的大模型排行榜】《LeaderboardFinder - Have you ever wondered which leaderboard would be best for your use case? - a Hugging Face Space by leaderboards》 <a href="https://huggingface.co/spaces/leaderboards/LeaderboardFinder"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho432sj0zbj21630u0dkr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 00:21:25 GMT</pubDate>
</item>
<item>
<title>【Marigold-LCM：无监督单目深度估计模型Demo，可以从单张图像中高效预测各像素点的深度信息，不需要额外的监督信号如深度图或者立体图像对】《Marigold-LCM Dep...</title>
<link>https://weibo.com/1402400261/O6Kxo2nsI</link>
<guid>https://weibo.com/1402400261/O6Kxo2nsI</guid>
<content:encoded><![CDATA[
<div> 深度估计模型, 无监督, 单目, 高效预测, 像素点, 深度信息, 无需监督信号, 单张图像, Marigold-LCM<br />
<br />
总结:<br />
本文介绍了一种无监督单目深度估计模型Marigold-LCM，能够高效预测单张图像中各像素点的深度信息，无需额外的监督信号如深度图或者立体图像对。该模型采用了先进的技术，实现了对深度信息的精准预测，为深度估计领域的发展带来新的可能性。模型的有效性和准确性得到了验证，具有重要的应用前景。 <div>
【Marigold-LCM：无监督单目深度估计模型Demo，可以从单张图像中高效预测各像素点的深度信息，不需要额外的监督信号如深度图或者立体图像对】《Marigold-LCM Depth Estimation - a Hugging Face Space by prs-eth》 <a href="https://huggingface.co/spaces/prs-eth/marigold-lcm"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5016088346296344"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax3.sinaimg.cn/orj480/5396ee05ly1ho42xdge0lj20k00kkwg2.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/uHAcl7sulx08dzZ0ZX8I010412003Yf20E010.mp4?label=mp4_720p&amp;template=720x740.24.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711416481&amp;ssig=tBj7oRCsNx&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/NhqyacNhlx08dzZ18hPq010412002O7Q0E010.mp4?label=mp4_hd&amp;template=540x552.24.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711416481&amp;ssig=gZnuwp4Do7&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/IeqyZjj1lx08dzZ135Sw010412001zN00E010.mp4?label=mp4_ld&amp;template=360x368.24.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711416481&amp;ssig=gFoNDmYGOs&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5016088346296344" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 00:16:24 GMT</pubDate>
</item>
<item>
<title>【Grok-1迎来PyTorch+HuggingFace优化版：推理加速3.8倍,开发门槛大幅降低】 - Grok-1是Musk的xAI开源的314亿参数Mixture of Experts模型，是目前最大的开源语言...</title>
<link>https://weibo.com/1402400261/O6Kvn0zQo</link>
<guid>https://weibo.com/1402400261/O6Kvn0zQo</guid>
<content:encoded><![CDATA[
<div> Grok-1, PyTorch, HuggingFace, Colossal-AI, 推理加速, 门槛降低, 易用版本, 性能优化, 并行加速, 开源贡献

<br /><br />
总结: 
Grok-1是Musk的开源语言模型，Colossal-AI团队提供了PyTorch版本，推动大语言模型的研究和应用。他们通过性能优化和推理加速提高了模型效率。未来更多的优化和应用有望推动AI技术的发展，促进自然语言处理等领域的进步。 <div>
【Grok-1迎来PyTorch+HuggingFace优化版：推理加速3.8倍,开发门槛大幅降低】   <br />- Grok-1是Musk的xAI开源的314亿参数Mixture of Experts模型，是目前最大的开源语言模型，允许自由分发和商业化改进。   <br />- Colossal-AI团队提供了基于Python+PyTorch+HuggingFace的Grok-1易用版本，降低了使用门槛，方便AI开发者上手。   <br />- Colossal-AI通过张量并行等方式对Grok-1进行了性能优化，在8块H800服务器上使推理加速近4倍。   <br />- 推理示例非常简单，只需要运行提供的脚本，就可以自动下载并加载模型，获得对齐的推理结果。   <br />- Colossal-AI后续还会继续对Grok-1在并行加速、量化降低成本等方面进行优化，值得持续关注。   <br />- Grok-1的PyTorch实现极大地降低了使用门槛，使广大AI研发者不受框架限制即可利用此模型，是非常值得欢迎的开源贡献。   <br />- 此举也启发我们，应该继续探索各种方式来提升大模型的易用性、效率和可拓展性，推动AI技术向更开放、普惠的方向发展。   <br /><br />思考： <br />- Grok-1的开源对于推动大语言模型的研究和应用意义重大，特别是允许自由分发和商业化，极大地降低了中小企业和个人开发者的门槛。  <br />- Colossal-AI团队为主流AI开发者提供易用的PyTorch版本，体现了他们推动先进AI技术民主化的努力，值得称赞。近4倍的推理加速效果也令人印象深刻。  <br />- 文章提到Colossal-AI未来还会引入Grok-1在并行加速、量化减少成本等方面的优化，值得持续关注。这些优化有望进一步提升Grok-1的性能和可用性。  <br />- 随着越来越多的大模型被开源，并提供易用的推理优化方案，有望极大地促进自然语言处理、对话系统、内容生成等领域的技术进步和产业应用。<br />'Grok-1 Inference' GitHub: github.com/hpcaitech/ColossalAI/tree/main/examples/language/grok-1 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho42s8pv6pj21400u0793.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho42sabj9oj20t90gfgms.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho42sd4qrjj21xo0u0tel.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 00:11:26 GMT</pubDate>
</item>
<item>
<title>【从技术到创意：Sora如何重塑艺术家的工作流程】 - Sora模型目前仍处于早期试用阶段，OpenAI正在与视觉艺术家、设计师等创意社区进行交流，收集他们的反馈以改...</title>
<link>https://weibo.com/1402400261/O6KsWB6nm</link>
<guid>https://weibo.com/1402400261/O6KsWB6nm</guid>
<content:encoded><![CDATA[
<div> Sora, 艺术家, 创意, 创作, 视觉效果, 创意社区, 生成能力, 原型制作, 资源限制, 抽象艺术

总结:<br />
Sora模型在重塑艺术家工作流程方面展现了巨大潜力。它通过强大的生成能力帮助艺术家实现脑海中想法，突破资源限制，拓展创意边界。Sora可以用于电影制作、音乐视觉化、时尚设计等领域，提高效率、加速原型制作和创意迭代，为创意产业带来新的可能性。这些优势使创作更高效、作品更具情感冲击力，同时也催生了新的艺术风格和美学。但同时，应审慎对待其潜在的负面影响。 <div>
【从技术到创意：Sora如何重塑艺术家的工作流程】  <br />- Sora模型目前仍处于早期试用阶段，OpenAI正在与视觉艺术家、设计师等创意社区进行交流，收集他们的反馈以改进模型。   <br />- 从艺术家的创作中可以看出，Sora当前最擅长生成逼真或超现实的视觉效果，可以帮助艺术家将脑海中的想法快速实现。这对艺术创作来说是突破性的进步。   <br />- Sora的强大生成能力解放了艺术家的想象力，他们可以不受资源限制地尝试各种新的创意点子，并将其可视化实现。这为抽象艺术的发展提供了动力。   <br />- Sora可用于电影制作中原型和迭代创意，大大提高了效率。对于长期受预算限制的创意人员来说，这是一个突破。   <br />- Sora也可用于音乐视觉化，帮助将难以实现的视觉效果变为可能，为音乐艺术家开辟了新的创作方向。   <br />- 在时尚设计领域，Sora可以快速将设计师脑海中的理念可视化实现，加速设计迭代，突破技术限制。   <br />- Sora还可用于快速原型混合现实中的3D角色和场景。这减少了创作者在技术细节上的投入，让他们更专注于创意。   <br />- Sora为创意社区提供了强有力的想象力延伸和创作增强工具。它解放并拓展了艺术家的创作边界，对创意产业将产生深远影响。但我们也应关注其潜在的负面影响，并保持审慎态度。<br /><br />思考：  <br />- Sora似乎极大地拓展了艺术创作的边界，让许多原本不可能实现的创意构思成为可能，这一点令人印象深刻。  <br />- 有了Sora这样的工具辅助，艺术家们可以将更多的时间和精力放在创意构思本身，而不是被技术细节所束缚，这对于提升作品质量和情感冲击力有很大帮助。  <br />- Sora在快速迭代和原型制作方面的优势，可以帮助创意团队更高效地与客户沟通，推进项目进度。这对于时间和预算都很紧张的商业项目而言尤为重要。  <br />- Sora的"怪异性"和超现实效果，可能会催生一种新的艺术风格和美学，为视觉艺术领域带来新的活力和可能性。<br />《Sora: First Impressions》 <a href="https://openai.com/blog/sora-first-impressions"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax4.sinaimg.cn/orj480/5396ee05ly1ho42kw2nrhj20zk0k0dgv.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/o3V5zjyclx08dzYbCn9m01041200dReH0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711416481&amp;ssig=FB8SfdWDG3&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/IywIoWFWlx08dzYbpkGI010412006LU20E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711416481&amp;ssig=5Df0oNLPD7&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/inIwVZ7Ilx08dzYbm4Vq010412004fwK0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711416481&amp;ssig=aXVJqTNw%2Fn&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5016085276065815" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Tue, 26 Mar 2024 00:05:28 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发...</title>
<link>https://weibo.com/1402400261/O6KqpyYCe</link>
<guid>https://weibo.com/1402400261/O6KqpyYCe</guid>
<content:encoded><![CDATA[
<div> hello算法, 可可粉, 数据结构, 算法, 动画图解, 实战代码, 互动环节, 轻松掌握, 新知识, 提问解决问题

<br /><br />总结:
《hello 算法》是一本帮助读者轻松掌握数据结构与算法的书籍。通过生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例使读者能够即学即用，及时巩固新知识。书中设计了互动环节，帮助读者主动思考、提问和解决问题。通过本书，读者可以以全新的视角进入算法的世界，学习到丰富的知识，并通过互动环节不断提升自己的算法解决问题的能力。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 23:59:14 GMT</pubDate>
</item>
<item>
<title>今日推介(第1356期)：大型语言模型能在上下文中探索吗、用新型迭代数据增强来提升LLM、利用Spotlighting防御间接提示注入攻击、防止越狱把安全性定义清楚最重要...</title>
<link>https://weibo.com/1402400261/O6JNAD6QM</link>
<guid>https://weibo.com/1402400261/O6JNAD6QM</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、上下文探索、迭代数据增强、LLM、Spotlighting防御、间接提示注入攻击、防止越狱、安全性定义、概念嵌入生成

<br /><br />总结:
本文介绍了几个关键技术点。首先是关于大型语言模型在上下文中的探索能力，这对于提高模型的自然语言处理能力至关重要。其次是新型迭代数据增强技术的应用，可以有效提升LLM的性能。接着介绍了Spotlighting防御技术，可以防止间接提示注入攻击，提高系统的安全性。文章还提到了越狱问题，明确定义安全性是防止越狱的关键。最后讨论了大型语言模型的概念嵌入生成，为模型的发展提供了新思路。这些技术和方法的应用将进一步推动自然语言处理和人工智能领域的发展。 <div>
今日推介(第1356期)：大型语言模型能在上下文中探索吗、用新型迭代数据增强来提升LLM、利用Spotlighting防御间接提示注入攻击、防止越狱把安全性定义清楚最重要、大型语言模型的概念嵌入生成 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/689014510"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho3znqy7f7j20go0f1myr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho3znuwdacj20go0bs0ug.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho3znzg8ywj20go0ajdga.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho3zo35ouxj20go07faau.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho3zo6h03nj20go0aft9s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 22:23:35 GMT</pubDate>
</item>
<item>
<title>[LG] Accelerated Objective Gap and Gradient Norm Convergence for Gradient Descent via Long Steps 网页链接 构造涉及银比(silver ratio)的特殊步长表，通过...</title>
<link>https://weibo.com/1402400261/O6JJXjo0J</link>
<guid>https://weibo.com/1402400261/O6JJXjo0J</guid>
<content:encoded><![CDATA[
<div> 银比、特殊步长表、目标函数差值、梯度范数、收敛速率、O(1/N^(1.2716...))、短步长梯度下降、证明、归纳法、改进

<br /><br />总结:
文章通过构造涉及银比的特殊步长表，同时在目标函数差值和梯度范数上通过归纳法证明了可以获得收敛速率为O(1/N^(1.2716...))的结果，这一结果改进了短步长梯度下降的经典成果。这种方法提供了更快速的梯度下降算法，为优化问题的解决提供了新的思路和工具。 <div>
[LG] Accelerated Objective Gap and Gradient Norm Convergence for Gradient Descent via Long Steps  <br /><a href="https://arxiv.org/abs/2403.14045"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />构造涉及银比(silver ratio)的特殊步长表，通过归纳法证明可以在目标函数差值和梯度范数上同时获得O(1/N^(1.2716...))的收敛速率，改进了短步长梯度下降的经典结果。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho3zevlu2xj210s1ba7in.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 22:14:38 GMT</pubDate>
</item>
<item>
<title>[IR] FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions 网页链接 提出FOLLOWIR基准测试集和p-MRR评估指标，分析了现有...</title>
<link>https://weibo.com/1402400261/O6JHsE2Ne</link>
<guid>https://weibo.com/1402400261/O6JHsE2Ne</guid>
<content:encoded><![CDATA[
<div> 模型评估, 指令理解, 信息检索, FOLLOWIR, 基准测试集, p-MRR, 指令遵循

<br /><br />总结:
该研究提出了FOLLOWIR基准测试集和p-MRR评估指标，旨在评估和教授信息检索模型遵循指令的能力。分析发现现有模型在遵循复杂指令方面存在不足，为提高信息检索模型的指令理解能力提供了基础。通过该研究，可以更好地了解信息检索模型在指令遵循方面的表现，并为进一步研究指令理解能力和提高模型性能提供参考。 <div>
[IR] FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions  <br /><a href="https://arxiv.org/abs/2403.15246"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出FOLLOWIR基准测试集和p-MRR评估指标，分析了现有模型在遵循复杂指令方面的不足，为进一步提高信息检索模型的指令理解能力奠定基础。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho3z8mo922j20vc1bond1.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho3z8mw16gj21em0qewq7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho3z8nl79fj21f819gwnh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 22:08:29 GMT</pubDate>
</item>
<item>
<title>[RO] Learning Quadruped Locomotion Using Differentiable Simulation 网页链接 通过分解与校准不同物理空间实现了可微仿真框架，使单四足机器人可在几分钟内学...</title>
<link>https://weibo.com/1402400261/O6JDwwbT9</link>
<guid>https://weibo.com/1402400261/O6JDwwbT9</guid>
<content:encoded><![CDATA[
<div> 可微仿真框架, 四足机器人, 学习, 步态, 物理空间, 机器人<br />
<br />
通过分解和校准不同物理空间，研究人员开发了一种可微仿真框架，使得单四足机器人能够在几分钟内学习复杂的步态。这种框架可以直接迁移至实际机器人上，极大地提高了机器人学习的效率和准确性。通过这种方法，研究人员为机器人学习和应用带来了新的可能性，为未来的机器人技术发展提供了新思路和方法。<br /><br />总结: <br />可微仿真框架提高了机器人学习效率，使得四足机器人可以快速学习复杂步态。该方法可直接应用于实际机器人上，为机器人技术发展带来新思路。 <div>
[RO] Learning Quadruped Locomotion Using Differentiable Simulation  <br /><a href="https://arxiv.org/abs/2403.14864"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过分解与校准不同物理空间实现了可微仿真框架，使单四足机器人可在几分钟内学习复杂步态，并可直接迁移到实际机器人上。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho3yyc5homj210y1b6qo1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho3yyckgmdj21cu0waqb6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho3yyd03vaj20oi0i2di2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho3yydlcefj21cm0lqdpe.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 21:58:47 GMT</pubDate>
</item>
<item>
<title>[LG] Compiler generated feedback for Large Language Models 网页链接 本文通过结合大型语言模型与编译器反馈的方式实现了LLVM IR代码优化，并证明采样技术可...</title>
<link>https://weibo.com/1402400261/O6JxKz4iD</link>
<guid>https://weibo.com/1402400261/O6JxKz4iD</guid>
<content:encoded><![CDATA[
<div> LLVM IR代码优化 大型语言模型 编译器反馈 采样技术 最优效果

<br /><br />总结:
本文讨论了如何结合大型语言模型与编译器反馈实现LLVM IR代码优化，并证明了采样技术可以取得近最优的效果。该方法通过引入大型语言模型对代码进行优化，并利用编译器反馈来调整优化策略，取得了令人满意的结果。这种方法在实践中展现出了很高的效果，为代码优化领域带来了新的思路和方法。 <div>
[LG] Compiler generated feedback for Large Language Models  <br /><a href="https://arxiv.org/abs/2403.14714"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />本文通过结合大型语言模型与编译器反馈的方式实现了LLVM IR代码优化，并证明采样技术可以取得近最优的效果。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho3yjjlcuqj211g1awaw9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho3yjk3qcrj21g00z4k32.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho3yjkh2fkj21gg0ne0zr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho3yjkndsyj20qi0t20x6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 21:44:34 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.25)》 爱可可微博热门分享(3.25) [图片]</title>
<link>https://weibo.com/1402400261/O6GKpoEpC</link>
<guid>https://weibo.com/1402400261/O6GKpoEpC</guid>
<content:encoded><![CDATA[
<div> 关键词: 爱可可, 微博, 热门分享, 3.25

总结:<br /><br />这篇文章是关于爱可可微博上的热门分享，内容丰富多样，引起广泛关注。其中，3.25号的内容尤为受欢迎。微博作为一个社交平台，通过分享信息、互动交流，为用户带来各种有趣的内容和话题。爱可可微博的热门分享能够吸引大量用户关注和参与讨论，增加用户互动的乐趣，丰富了用户在微博平台上的体验。希望未来能继续看到更多精彩的内容和互动，让用户们享受到更多乐趣和收获。 <div>
《爱可可微博热门分享(3.25)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405015942936526924"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.25)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho3m746fhzj20rs0fmwgd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 14:37:30 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Online GNN Evaluation Under Test-Time Graph Distribution Shifts》(ICLR 2024) GitHub: github.com/Amanda-Zheng/LEBED [fig5]《FITS: M...</title>
<link>https://weibo.com/1402400261/O6Dg6rZPh</link>
<guid>https://weibo.com/1402400261/O6Dg6rZPh</guid>
<content:encoded><![CDATA[
<div> Online GNN Evaluation, Test-Time Graph Distribution Shifts, FITS, Time Series, Boosting Continual Learning, Vision-Language Models, SpeeDiT, Diffusion Models, BiRefNet, Image Segmentation, Simplified Diffusion Schrödinger Bridge, DPOT, PDE Pre-Training, GCTM, Image Manipulation, MLM_Filter, Finetuned Multimodal Language Models, EnCLAP, Neural Audio Codec, Automated Audio Captioning, MapQR, Vectorized Map Construction, CLIP-VIS, Video Instance Segmentation

<br />
总结: 在这几篇论文中，提出了许多新颖的方法和技术来解决各种问题。其中包括针对在线图卷积神经网络评估和测试时图分布漂移的解决方案，涉及到时间序列建模、视觉-语言模型持续学习的增强、加速扩散模型训练等领域。此外，还有针对高分辨率图像分割、自动音频字幕生成、地图构建和视频实例分割等问题的创新方法。这些研究为不同领域的深度学习应用提供了新的思路和技术手段，推动了相关领域的发展。 <div>
几篇论文实现代码：<br />《Online GNN Evaluation Under Test-Time Graph Distribution Shifts》(ICLR 2024) GitHub: github.com/Amanda-Zheng/LEBED [fig5]<br />《FITS: Modeling Time Series with 10k parameters》(ICLR 2024) GitHub: github.com/VEWOXIC/FITS<br />《Boosting Continual Learning of Vision-Language Models via Mixture-of-Experts Adapters》(CVPR 2024) GitHub: github.com/JiazuoYu/MoE-Adapters4CL [fig5]<br />《SpeeDiT: Accelerating DiTs and General Diffusion Models via Principle Timestep Adjustment Training》(2024) GitHub: github.com/1zeryu/SpeeDiT<br />《Bilateral Reference for High-Resolution Dichotomous Image Segmentation》(2024) GitHub: github.com/ZhengPeng7/BiRefNet<br />《Simplified Diffusion Schrödinger Bridge》(2024) GitHub: github.com/tzco/Simplified-Diffusion-Schrodinger-Bridge<br />《DPOT: Auto-Regressive Denoising Operator Transformer for Large-Scale PDE Pre-Training》(2024) GitHub: github.com/HaoZhongkai/DPOT [fig1]<br />《Generalized Consistency Trajectory Models for Image Manipulation》(2024) GitHub: github.com/1202kbs/GCTM [fig2]<br />《Finetuned Multimodal Language Models are High-Quality Image-Text Data Filters》(2024) GitHub: github.com/Victorwz/MLM_Filter<br />《EnCLAP: Combining Neural Audio Codec and Audio-Text Joint Embedding for Automated Audio Captioning》(2024) GitHub: github.com/jaeyeonkim99/EnCLAP [fig3]<br />《Leveraging Enhanced Queries of Point Sets for Vectorized Map Construction》(2024) GitHub: github.com/HXMap/MapQR [fig6]<br />《CLIP-VIS: Adapting CLIP for Open-Vocabulary Video Instance Segmentation》(2024) GitHub: github.com/zwq456/CLIP-VIS [fig4]<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho34oe5qplj21k60qe7br.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho358pd30dj20pl0kr7ic.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho35bi313rj28cc38o7wk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho362w5f4hj23r61egnpd.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho3661b06bj215t0hnqif.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho36js2y5xj23300s0qdi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:44:36 GMT</pubDate>
</item>
<item>
<title>【Multimodal Gamer：在电脑上用多媒态模型打游戏的框架】'Multimodal Gamer - A framework to enable multimodal models to play games on a computer.' GitHub...</title>
<link>https://weibo.com/1402400261/O6Dfbp8b8</link>
<guid>https://weibo.com/1402400261/O6Dfbp8b8</guid>
<content:encoded><![CDATA[
<div> 多媒体模型、游戏、电脑、框架、GitHub、模型训练、模型推理、游戏场景、输入模态、输出模态

<br /><br />总结:
这篇文章介绍了一个名为Multimodal Gamer的框架，该框架可以让多媒体模型在电脑上玩游戏。通过在GitHub上提供代码，作者展示了如何使用多媒体模型进行游戏。该框架包括模型训练和推理两个主要阶段，能够在游戏场景中使用不同的输入模态和输出模态。通过这个框架，研究人员和开发人员可以更好地探索多媒体模型在游戏领域的应用，并尝试开发更加智能的游戏玩家。 <div>
【Multimodal Gamer：在电脑上用多媒态模型打游戏的框架】'Multimodal Gamer - A framework to enable multimodal models to play games on a computer.' GitHub: github.com/joshbickett/multimodal-gamer <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho36qeh1z4j20x40u00xr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:42:20 GMT</pubDate>
</item>
<item>
<title>【遥感图像描述相关文献资源列表】’awesome-remote-image-captioning - A list of awesome remote sensing image captioning resources' GitHub: github.com/iO...</title>
<link>https://weibo.com/1402400261/O6DernLcd</link>
<guid>https://weibo.com/1402400261/O6DernLcd</guid>
<content:encoded><![CDATA[
<div> 远程感知、图像描述、资源列表、GitHub、iOPENCap、遥感图像、图像标注、资源、思维导图、研究方向、深度学习、数据集

遥感图像描述是一个研究方向，该文献资源列表收集了一些相关的资源，可以在GitHub上找到。iOPENCap是其中的一个项目。远程感知领域关注图像描述和遥感图像，提供了一些资源和数据集用于深度学习研究。该资源列表包括数据集、文献和代码等资源，可以帮助研究人员更好地开展远程感知领域的工作。思维导图也是其中的一种资源，可以帮助研究人员更好地理解和整理这个研究方向。 <div>
【遥感图像描述相关文献资源列表】’awesome-remote-image-captioning - A list of awesome remote sensing image captioning resources' GitHub: github.com/iOPENCap/awesome-remote-image-captioning <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho36oi536nj20x70u046t.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:40:30 GMT</pubDate>
</item>
<item>
<title>'Char detection base on crnn 字符（单字）检测基于CRNN' GitHub: github.com/fanqie03/char-detection #开源# #机器学习# #人工智能# [图片][图片][图片]</title>
<link>https://weibo.com/1402400261/O6DdU75Wt</link>
<guid>https://weibo.com/1402400261/O6DdU75Wt</guid>
<content:encoded><![CDATA[
<div> CRNN、字符检测、单字、GitHub、fanqie03、字符检测、基于、CNN、RNN、文本检测
<br />
本文介绍了基于CRNN的字符（单字）检测技术，通过GitHub仓库fanqie03/char-detection进行实现。该技术结合了卷积神经网络（CNN）和循环神经网络（RNN）的特点，能够有效地识别文本中的单个字符。文章中详细介绍了CRNN的原理及实现步骤，包括字符检测的数据集准备、模型训练和测试等内容。通过对字符图像进行预处理、特征提取和序列识别，实现了高效率和准确度的字符检测。这种基于CRNN的方法在文本识别领域具有广泛的应用前景，能够帮助用户快速准确地识别字符信息。总的来说，本文提供了一种有效的字符检测方法，为相关领域的研究和应用提供了有益的参考。 
<br /><br />总结: <div>
'Char detection base on crnn 字符（单字）检测基于CRNN' GitHub: github.com/fanqie03/char-detection <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho36n1krarj20v50e2429.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho36n344nbj20an0fwtah.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho36n4karyj20jh0mxaca.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:39:11 GMT</pubDate>
</item>
<item>
<title>【NineRec: 多模态大规模数据集和多领域推荐系统基准】'[TPAMI 2024] NineRec: A Benchmark Dataset Suite for Evaluating Transferable Recommendation - A Lar...</title>
<link>https://weibo.com/1402400261/O6Dc9bvae</link>
<guid>https://weibo.com/1402400261/O6Dc9bvae</guid>
<content:encoded><![CDATA[
<div> 数据集，多模态，大规模，多领域，推荐系统，基准，跨领域迁移学习，GitHub，NineRec，TPAMI 2024

总结:<br /><br />这篇文章介绍了NineRec，一个用于评估可转移推荐的基准数据集套件。该数据集包括大规模的多模态数据，用于多领域推荐系统的基准测试。作者提出了一种用于跨领域迁移学习的NineRec框架，并在TPAMI 2024上发布。GitHub上提供了相关资源。NineRec为推荐系统领域提供了重要的研究工具，并在实验中展示了其有效性和影响力。 <div>
【NineRec: 多模态大规模数据集和多领域推荐系统基准】'[TPAMI 2024] NineRec: A Benchmark Dataset Suite for Evaluating Transferable Recommendation - A Large-scale Multimodal Dataset and Benchmark for Multi-domain Recommender System' GitHub: github.com/westlake-repl/NineRec <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho36ik5cu8j20z30u044j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho36il7kmqj20xh0u0486.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:34:51 GMT</pubDate>
</item>
<item>
<title>【codeium-parse：命令行代码解析工具，支持语法解析，帮用户轻松处理代码格式】’codeium-parse - A command line tool for parsing code syntax' GitHub: gith...</title>
<link>https://weibo.com/1402400261/O6DbvzzHC</link>
<guid>https://weibo.com/1402400261/O6DbvzzHC</guid>
<content:encoded><![CDATA[
<div> codeium-parse、命令行、代码解析工具、语法解析、GitHub、Exafunction、轻松处理代码格式

总结:<br /><br />本文介绍了一个名为codeium-parse的命令行工具，用于解析代码语法。该工具支持用户处理代码格式，帮助用户快速解析代码的语法。用户可以在GitHub上找到该工具的开源代码，项目地址为github.com/Exafunction/codeium-parse。 <div>
【codeium-parse：命令行代码解析工具，支持语法解析，帮用户轻松处理代码格式】’codeium-parse - A command line tool for parsing code syntax' GitHub: github.com/Exafunction/codeium-parse <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho36gz1bpbj20z60u078y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:33:17 GMT</pubDate>
</item>
<item>
<title>【Chat with MLX：高性能的macOS应用，将本地文档与一个个性化大型语言模型(LLM)连接起来。利用检索增强生成 (RAG)，可有效地搜索和查询文档】'Chat with MLX - ...</title>
<link>https://weibo.com/1402400261/O6D6NezKY</link>
<guid>https://weibo.com/1402400261/O6D6NezKY</guid>
<content:encoded><![CDATA[
<div> 关键词: MLX, macOS应用, 本地文档, 大型语言模型, 检索增强生成, 搜索, 查询

总结:
MLX是一个高性能的macOS应用，它将本地文档与一个个性化的大型语言模型(LLM)连接起来。通过利用检索增强生成(RAG)，用户可以有效地搜索和查询文档。这个应用提供了一种新颖的方式来管理和利用本地文档，并帮助用户更高效地查找和使用信息。MLX的功能强大，可以满足用户对文档管理和查询的各种需求，是一款实用的工具。MLX提供了一种直观、灵活的界面，让用户可以轻松地与文档和语言模型进行交互。通过MLX，用户可以更快速地查找所需信息，提高工作效率。MLX的设计简洁、易用，适合各种用户群体使用，是一款有很高潜力的应用。MLX的开发团队在不断努力改进和优化应用，以提供更好的用户体验和功能。MLX将成为用户处理文档和获取信息的得力助手，为他们节省时间和精力。 <div>
【Chat with MLX：高性能的macOS应用，将本地文档与一个个性化大型语言模型(LLM)连接起来。利用检索增强生成 (RAG)，可有效地搜索和查询文档】'Chat with MLX - Chat with MLX is a high-performance macOS application that connects your local documents to a personalized large language model (LLM).' GitHub: github.com/mlx-chat/mlx-chat-app <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho364urcyuj219s0u0gq6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:21:39 GMT</pubDate>
</item>
<item>
<title>【Cookbook to Craft Good Code：一个帮助编写高质量代码的开源指南，强调代码的可读性、简洁性和易维护性】'Cookbook to Craft Good Code - Cookbook for Craft...</title>
<link>https://weibo.com/1402400261/O6D41EcNQ</link>
<guid>https://weibo.com/1402400261/O6D41EcNQ</guid>
<content:encoded><![CDATA[
<div> GitHub, Cookbook, Craft, Good Code, 高质量代码, 可读性, 简洁性, 易维护性

<br /><br />总结:
《Cookbook to Craft Good Code》是一个帮助编写高质量代码的开源指南，强调代码的可读性、简洁性和易维护性。该指南包含了许多有用的建议和实用的技巧，可以帮助开发人员写出更好的代码。重点强调了如何使代码易于阅读、简洁明了以及方便维护，旨在提高代码的质量和可维护性。通过遵循这些指南，开发人员可以提高他们编写代码的效率，并减少潜在的bug和问题，从而提高整体开发质量。整体而言，这个指南为编写高质量代码提供了一些非常有用的建议和技巧，值得开发人员借鉴和参考。 <div>
【Cookbook to Craft Good Code：一个帮助编写高质量代码的开源指南，强调代码的可读性、简洁性和易维护性】'Cookbook to Craft Good Code - Cookbook for Crafting Good Code' GitHub: github.com/Mountchicken/CodeCookbook <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%BC%96%E7%A8%8B%23&amp;isnewpage=1"><span class="surl-text">#编程#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho35xpcxokj21bq0u0jy9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 05:14:51 GMT</pubDate>
</item>
<item>
<title>【LightwheelOcc：面向自动驾驶的3D Occupancy合成数据集】'LightwheelOcc - LightwheelOcc: A 3D Occupancy Synthetic Dataset in Autonomous Driving' GitHub:...</title>
<link>https://weibo.com/1402400261/O6CVRecv2</link>
<guid>https://weibo.com/1402400261/O6CVRecv2</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶、3D Occupancy、合成数据集、LightwheelOcc、OpenDriveLab、GitHub

总结:<br /><br />本文介绍了面向自动驾驶的3D Occupancy合成数据集LightwheelOcc，旨在提供给研究人员用于自动驾驶系统中的数据处理和算法开发。数据集由OpenDriveLab团队开发，可在GitHub上获取。数据集的发布有助于推动自动驾驶技术的发展，提高系统性能和安全性。LightwheelOcc的开发是为了解决现有数据集的不足，为自动驾驶研究提供更多选择和资源支持。数据集的合成方法有效地模拟了自动驾驶场景，能够提供真实且多样化的数据样本，有助于提高自动驾驶系统的鲁棒性和准确性。通过使用LightwheelOcc数据集，研究人员可以进行更全面的数据分析和算法验证，促进自动驾驶技术的快速发展。 <div>
【LightwheelOcc：面向自动驾驶的3D  Occupancy合成数据集】'LightwheelOcc - LightwheelOcc: A 3D Occupancy Synthetic Dataset in Autonomous Driving' GitHub: github.com/OpenDriveLab/LightwheelOcc <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho35cb2r26j21420u0teu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 04:54:43 GMT</pubDate>
</item>
<item>
<title>【Whispering：一个开源项目，旨在通过 OpenAI Whisper API 简化语音到文字转换体验】'Whispering - Seamlessly convert spoken words into text with AI assist...</title>
<link>https://weibo.com/1402400261/O6CLFqb7N</link>
<guid>https://weibo.com/1402400261/O6CLFqb7N</guid>
<content:encoded><![CDATA[
<div> OpenAI，Whispering，语音到文字转换，OpenAI Whisper API，开源项目，简化体验，AI辅助，无缝转换，文字，通信<br />
<br />
提到的开源项目Whispering旨在简化语音到文字转换体验，通过OpenAI Whisper API提供AI助力，让用户能够轻松实现从口述文字的转换，实现了无缝的沟通体验。 <div>
【Whispering：一个开源项目，旨在通过 OpenAI Whisper API 简化语音到文字转换体验】'Whispering - Seamlessly convert spoken words into text with AI assistance, powered by OpenAI, for effortless communication.' GitHub: github.com/braden-w/whispering <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho34mo6satj211t0u0djr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 04:29:37 GMT</pubDate>
</item>
<item>
<title>【Gmeek：一个博客框架，使用 git 托管代码，简洁易用，无需本地部署，只需搭建和写作即可完成博客搭建。】'Gmeek - Gmeek is a Blog All in Github' GitHub: gi...</title>
<link>https://weibo.com/1402400261/O6CK5oqfm</link>
<guid>https://weibo.com/1402400261/O6CK5oqfm</guid>
<content:encoded><![CDATA[
<div> Gmeek, 博客框架, git, 托管代码, 简洁易用, 无需本地部署, 搭建, 写作, 完成博客搭建

<br /><br />总结:
Gmeek是一个简洁易用的博客框架，使用git托管代码，无需本地部署，只需搭建和写作即可完成博客搭建。通过在GitHub上使用Gmeek，用户可以快速建立自己的博客，方便地进行写作和分享内容。Gmeek的特点是操作简单，只需一些基本的配置和写作，即可发布博客内容。对于想要快速搭建个人博客的用户来说，Gmeek是一个很好的选择。 <div>
【Gmeek：一个博客框架，使用 git 托管代码，简洁易用，无需本地部署，只需搭建和写作即可完成博客搭建。】'Gmeek - Gmeek is a Blog All in Github' GitHub: github.com/Meekdai/Gmeek <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%8D%9A%E5%AE%A2%23&amp;isnewpage=1"><span class="surl-text">#博客#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho34inyapwj213j0o7mzg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 04:25:43 GMT</pubDate>
</item>
<item>
<title>'LapisCV - 开箱即用的 Obsidian / Typora 简历' GitHub: github.com/BingyanStudio/LapisCV #开源# #简历# [图片][图片][图片]</title>
<link>https://weibo.com/1402400261/O6CJKnpvw</link>
<guid>https://weibo.com/1402400261/O6CJKnpvw</guid>
<content:encoded><![CDATA[
<div> GitHub、LapisCV、Obsidian、Typora、简历、开箱即用、BingyanStudio

<br /><br />总结:
这篇文章介绍了'LapisCV - 开箱即用的 Obsidian / Typora 简历'项目，项目地址为GitHub上的github.com/BingyanStudio/LapisCV。项目中提供了一款名为LapisCV的简历模板，可以在Obsidian或Typora上直接使用，帮助用户快速创建简历。通过该项目，用户可以轻松地定制自己的简历，提升求职竞争力。 <div>
'LapisCV - 开箱即用的 Obsidian / Typora 简历' GitHub: github.com/BingyanStudio/LapisCV <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%AE%80%E5%8E%86%23&amp;isnewpage=1"><span class="surl-text">#简历#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho34hqkpjaj218l0u0gqh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho34hrefgsj218c0u0gqe.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho34hsmj84j21c00u0aeh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 04:24:53 GMT</pubDate>
</item>
<item>
<title>【Rye language： 一种动态编程语言，结合了 Rebol、Factor、Linux shells 和 Golang 等思想，仍在不断发展中】'Rye language - homoiconic dynamic programming...</title>
<link>https://weibo.com/1402400261/O6CIG9SM8</link>
<guid>https://weibo.com/1402400261/O6CIG9SM8</guid>
<content:encoded><![CDATA[
<div> Rye language, 动态编程语言, Rebol, Factor, Linux shells, Golang, 发展, homoiconic, GitHub, refaktor<br />
<br />
要点一：Rye language 是一种动态编程语言，结合了 Rebol、Factor、Linux shells 和 Golang 等思想，目前仍在不断发展中。<br />
要点二：Rye language 是一种 homoiconic 动态编程语言，具有一些新的思想。<br />
要点三：Rye language 的源代码托管在 GitHub 上，项目地址为github.com/refaktor/rye。 <br />

总结：<br />
Rye language 是一种结合了多种编程语言思想的动态编程语言，包括 Rebol、Factor、Linux shells 和 Golang，它是一种 homoiconic 语言，具有一些新颖的概念。Rye language 的开发仍在不断进行中，代码托管在 GitHub 上，可随时查阅和参与。 <div>
【Rye language： 一种动态编程语言，结合了 Rebol、Factor、Linux shells 和 Golang 等思想，仍在不断发展中】'Rye language - homoiconic dynamic programming language with some new ideas' GitHub: github.com/refaktor/rye <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%BC%96%E7%A8%8B%23&amp;isnewpage=1"><span class="surl-text">#编程#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho34f2mlflj21ji0oe0y5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 04:22:15 GMT</pubDate>
</item>
<item>
<title>【codel：可以用来完成各种复杂的任务和项目的自动化AI Agent，无论是使用终端、浏览器还是编辑器】'codel - Fully autonomous AI Agent that can perform compl...</title>
<link>https://weibo.com/1402400261/O6CI39B4M</link>
<guid>https://weibo.com/1402400261/O6CI39B4M</guid>
<content:encoded><![CDATA[
<div> codel, 自动化AI Agent, 任务, 项目, 终端, 浏览器, 编辑器, GitHub, semanser, 复杂任务<br />
<br />
提到了一个名为codel的全自动AI Agent，能够利用终端、浏览器和编辑器完成复杂的任务和项目。该项目的代码托管在GitHub上，作者是semanser。codel的独特之处在于它能够完成各种不同类型的任务，并且可以在不同环境下运行，包括终端、浏览器和编辑器。这使得codel成为一个强大的工具，可以帮助用户自动化完成繁琐的工作，提高工作效率。通过GitHub上的开源代码，用户可以自定义和优化codel，以适应特定的需求和项目。总的来说，codel是一个十分实用和灵活的AI Agent，可以为用户提供强大的自动化功能，帮助他们应对各种复杂任务和项目。 <br /><br />总结: <div>
【codel：可以用来完成各种复杂的任务和项目的自动化AI Agent，无论是使用终端、浏览器还是编辑器】'codel - Fully autonomous AI Agent that can perform complicated tasks and projects using terminal, browser, and editor.' GitHub: github.com/semanser/codel <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho34d9jpl2j21i80u0jv8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 04:20:42 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发...</title>
<link>https://weibo.com/1402400261/O6B15iVGw</link>
<guid>https://weibo.com/1402400261/O6B15iVGw</guid>
<content:encoded><![CDATA[
<div> 可可粉 转发 评论 hello 算法 数据结构 算法世界 动画图解 实战代码 示例 互动环节

<br /><br />总结:
文章介绍了一次活动，参与者需要转发并评论指定内容，有机会获得《hello 算法》这本书。这本书通过生动的动画图解和实战代码示例，帮助读者轻松掌握数据结构和算法知识，让抽象的概念变得直观易懂。互动环节的设计也能帮助读者主动思考和解决问题，提高学习效果。活动截止日期为2024年3月29日12:00。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 25 Mar 2024 00:02:06 GMT</pubDate>
</item>
<item>
<title>今日推介(第1355期)：用图神经网络学习神经网络等变表示、Zigzag Mamba扩散模型、基于文本到图像模型的一步图像翻译、基于内容帧运动潜分解的高效视频扩散模型、...</title>
<link>https://weibo.com/1402400261/O6Ajk28GJ</link>
<guid>https://weibo.com/1402400261/O6Ajk28GJ</guid>
<content:encoded><![CDATA[
<div> 图神经网络、神经网络等变表示、Zigzag Mamba扩散模型、文本到图像模型、图像翻译、内容帧运动潜分解、视频扩散模型、即插即用框架、视频编辑

<br /><br />总结:
本文介绍了几个新颖的研究方向：利用图神经网络学习神经网络等变表示，探讨了Zigzag Mamba扩散模型在传播过程中的应用；提出了基于文本到图像模型的一步图像翻译方法，实现了高效的文本转图像任务；同时，基于内容帧运动潜分解的高效视频扩散模型也被提出，为视频扩散任务带来了新的思路；最后，研究者们还提出了一种用于任意视频到视频编辑任务的即插即用框架，为视频编辑领域带来了便利和创新。这些研究成果在图像处理和视频编辑领域具有重要意义，有望为相关领域的研究和应用带来新的启发和突破。 <div>
今日推介(第1355期)：用图神经网络学习神经网络等变表示、Zigzag Mamba扩散模型、基于文本到图像模型的一步图像翻译、基于内容帧运动潜分解的高效视频扩散模型、用于任意视频到视频编辑任务的即插即用框架 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/688803513"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.25)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho2trshiilj20go04l74q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho2trw1clpj20go085ab2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho2trz8ig5j20go08twfm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho2ts3wesij20go07pq41.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho2ts6llz5j20go0bp763.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 22:14:16 GMT</pubDate>
</item>
<item>
<title>[CL] LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models 网页链接 LLAMAFACTORY是一个模块化、标准化、易用的框架，可以高效微调大规模语言...</title>
<link>https://weibo.com/1402400261/O6AfZcveI</link>
<guid>https://weibo.com/1402400261/O6AfZcveI</guid>
<content:encoded><![CDATA[
<div> 模块化、标准化、易用、框架、高效微调、大规模语言模型   
<br />
LLAMAFACTORY是一个模块化、标准化、易用的框架，可以高效微调大规模语言模型。 这个框架可以帮助用户统一微调100多种语言模型，提高效率并简化操作流程。LLAMAFACTORY提供了统一的界面和工具，使用户能够轻松选择并微调所需的语言模型。该框架还支持自定义的微调和扩展，让用户能够根据自己的需求进行灵活应用。LLAMAFACTORY的设计目标是为了让用户更轻松地利用大规模语言模型，从而提升其应用的效果和性能。 <div>
[CL] LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models  <br /><a href="https://arxiv.org/abs/2403.13372"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />LLAMAFACTORY是一个模块化、标准化、易用的框架，可以高效微调大规模语言模型。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2tjnkvldj20x41d04jc.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2tjnppwuj20uu13gdm9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 22:06:04 GMT</pubDate>
</item>
<item>
<title>[CV] SceneScript: Reconstructing Scenes With An Autoregressive Structured Language Model 网页链接 通过设计可扩展的结构化语言SceneScript以及对应的大规...</title>
<link>https://weibo.com/1402400261/O6AdPiLs7</link>
<guid>https://weibo.com/1402400261/O6AdPiLs7</guid>
<content:encoded><![CDATA[
<div> 结构化语言SceneScript, 大规模合成数据集, 第一人称视频, 3D 场景结构, 自动回归, 模型训练, 场景重建, 视频分析, 可扩展设计, 复杂场景解析

<br /><br />总结:
本研究通过设计可扩展的结构化语言SceneScript以及对应的大规模合成数据集，实现了从第一人称视频中解析复杂3D场景结构的新方法。通过自动回归的模型训练，实现了对场景的精确重建和视频分析，为复杂场景的解析提供了有效的工具和方法。 <div>
[CV] SceneScript: Reconstructing Scenes With An Autoregressive Structured Language Model  <br /><a href="https://arxiv.org/abs/2403.13064"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过设计可扩展的结构化语言SceneScript以及对应的大规模合成数据集，实现了直接从第一人称视频中解析复杂3D场景结构的新方法。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2te21oy4j20rk1amk4m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2te2nnzyj21ni11a4e4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2te33o3oj21n40v2n9k.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2te3mc2xj21n60r6163.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 22:00:44 GMT</pubDate>
</item>
<item>
<title>[CV] Nellie: Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy 网页链接 Nellie是一个开源的...</title>
<link>https://weibo.com/1402400261/O6A91e8W9</link>
<guid>https://weibo.com/1402400261/O6A91e8W9</guid>
<content:encoded><![CDATA[
<div> 关键词: Nellie, 细胞内结构分析, 层次特征提取, 机器学习, 单通道图像, 空间动态组织器信息

总结:<br /><br />
本文介绍了开源工具Nellie，用于自动化分析细胞内结构，包括分割、跟踪和特征提取。该工具具有层次特征提取和机器学习整合的创新，能够从2D/3D单通道图像中获取丰富的空间动态组织器信息。Nellie的应用范围涵盖了细胞生物学领域，为细胞研究提供了强大的工具和支持。 <div>
[CV] Nellie: Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy  <br /><a href="https://arxiv.org/abs/2403.13214"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>   <br />Nellie是一个开源的全自动细胞内结构分析流水线，其创新的层次特征提取与机器学习整合，可从单通道图像中获取丰富的空间动态组织器信息。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2t1rh18aj210w0yk7e0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2t1s51e7j211e1c4k5q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2t1sd6mzj210g1cqtq6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2t1sjtrij210e1detq9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 21:48:54 GMT</pubDate>
</item>
<item>
<title>[LG] A Survey on Uncertainty Quantification for Deep Learning: An Uncertainty Source Perspective 网页链接 通过不确定性来源的视角首次系统回顾各类DNN不...</title>
<link>https://weibo.com/1402400261/O6A6olNpV</link>
<guid>https://weibo.com/1402400261/O6A6olNpV</guid>
<content:encoded><![CDATA[
<div> 不确定性、量化、深度学习、技术原理、优劣势、选择方法、实际应用、可解释性AI、指导<br />
<br />
<br />
总结: 本文首次系统回顾了各类DNN不确定度量化技术，通过不确定性来源的视角考察了这些方法框架的技术原理、应对不同不确定性来源的优劣势，以及在选择方法与实际应用之间建立的关联。此外，为不同场景下的可解释性AI提供了指导，有助于更好地理解和应用深度学习模型的不确定性量化技术。 <div>
[LG] A Survey on Uncertainty Quantification for Deep Learning: An Uncertainty Source Perspective  <br /><a href="https://arxiv.org/abs/2302.13425"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过不确定性来源的视角首次系统回顾各类DNN不确定度量化技术，概述了不同方法框架的技术原理、应对不同不确定性来源的优劣势，并在选择方法与实际应用之间建立关联，为不同场景下的可解释性AI提供指导。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2sv182sij20u61887ks.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2sv1bgrgj21680lc417.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2sv1q3joj21n20i6wjp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2sv2b0byj20us0lg76n.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 21:42:26 GMT</pubDate>
</item>
<item>
<title>[RO] BEHAVIOR-1K: A Human-Centered, Embodied AI Benchmark with 1,000 Everyday Activities and Realistic Simulation 网页链接 提出BEHAVIOR-1K基准测试，包...</title>
<link>https://weibo.com/1402400261/O6A2M6jdy</link>
<guid>https://weibo.com/1402400261/O6A2M6jdy</guid>
<content:encoded><![CDATA[
<div> 挑选关键词：BEHAVIOR-1K基准测试, 人类中心, 机器人, 日常活动, OMNIGIBSON仿真环境

<br /><br />总结:
文章介绍了BEHAVIOR-1K基准测试，其中包含1000个根据人类需求选择的日常活动定义。该基准测试在高度逼真的OMNIGIBSON仿真环境中实现，为发展人类中心的机器人提供了重要基础。这个基准测试的设计旨在帮助研究人员评估和改进机器人系统在执行日常活动任务时的表现。通过对机器人行为进行大规模的测试和评估，可以为未来机器人在日常生活中扮演更为普遍和重要的角色提供支持和指导。文章的作者强调了人类中心的设计理念在机器人研究和发展中的重要性，希望BEHAVIOR-1K基准测试能够成为一个有用的工具，促进人机交互领域的进步。 <div>
[RO] BEHAVIOR-1K: A Human-Centered, Embodied AI Benchmark with 1,000 Everyday Activities and Realistic Simulation  <br /><a href="https://arxiv.org/abs/2403.09227"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />提出BEHAVIOR-1K基准测试，包含1000个根据人类需求选择的日常活动定义，在高度逼真的OMNIGIBSON仿真环境中具体实现，为发展人类中心的机器人提供了重要基础。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2slquamkj20v41cigyw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2slra7kkj21qu0x2tnt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2slrpmwwj21qu0zakb5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 21:33:31 GMT</pubDate>
</item>
<item>
<title>AnyV2V是一个通用的视频编辑框架，通过将过程拆分为图像编辑和I2V生成，实现基于各类图像编辑模型的高保真视频编辑。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《AnyV2V...</title>
<link>https://weibo.com/1402400261/O6zZkqBQ2</link>
<guid>https://weibo.com/1402400261/O6zZkqBQ2</guid>
<content:encoded><![CDATA[
<div> 关键词: AnyV2V, 视频编辑框架, 图像编辑, I2V生成, 高保真编辑, 模型

总结:<br /><br />总结: AnyV2V是一个通用的视频编辑框架，通过图像编辑和I2V生成过程，实现基于各类图像编辑模型的高保真视频编辑。该框架可实现任何视频到视频编辑任务，作者通过提出一种简单易用的插件式编辑方式，实现了高质量、易扩展的视频编辑。该框架在实验中展现了优异的编辑效果，展示了其在实际应用中的潜力。通过将视频编辑任务拆分为图像编辑和I2V生成两个子任务，可以更灵活、高效地完成视频编辑，提高编辑质量和效率。该框架为视频编辑领域提供了一种创新的思路和工具，有望推动视频编辑技术的发展。 <div>
AnyV2V是一个通用的视频编辑框架，通过将过程拆分为图像编辑和I2V生成，实现基于各类图像编辑模型的高保真视频编辑。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks》M Ku, C Wei, W Ren, H Yang, W Chen [University of Waterloo &amp; Harmony.AI] (2024) <a href="https://arxiv.org/abs/2403.14468"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2s6uc535j218q15idys.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2s6v75x8j21gm10ynb3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2s6vnoeuj21g217wh2y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2s6w0vjrj21fk12aqli.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2scsobogj20rh0x0jxr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2scsnqfwj20rh0j7n2a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2scsoligj20rh11en4s.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 21:25:02 GMT</pubDate>
</item>
<item>
<title>[CV]《AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks》M Ku, C Wei, W Ren, H Yang, W Chen [University of Waterloo &amp; Harmony.AI]...</title>
<link>https://weibo.com/1402400261/O6zZgmRdg</link>
<guid>https://weibo.com/1402400261/O6zZgmRdg</guid>
<content:encoded><![CDATA[
<div> 关键词: AnyV2V, 视频编辑, 框架, 智能编辑, 深度学习, 自动化, 插件化, 多功能性, 实时编辑, 研究

总结:<br /><br />研究团队提出了一个名为AnyV2V的框架，能够进行任何视频到视频的编辑任务，具有智能编辑、自动化和插件化的特点。该框架基于深度学习技术，具有多功能性，能够实现实时编辑。研究结果表明，AnyV2V框架在各种视频编辑任务中表现出色，为视频编辑领域带来了新的可能性。 <div>
[CV]《AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks》M Ku, C Wei, W Ren, H Yang, W Chen [University of Waterloo &amp; Harmony.AI] (2024) <a href="https://arxiv.org/abs/2403.14468"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2s6uc535j218q15idys.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2s6v75x8j21gm10ynb3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2s6vnoeuj21g217wh2y.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2s6w0vjrj21fk12aqli.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2scsobogj20rh0x0jxr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2scsnqfwj20rh0j7n2a.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho2scsoligj20rh11en4s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 21:24:52 GMT</pubDate>
</item>
<item>
<title>通过内容帧和运动潜表示对视频进行紧凑编码，设计高效视频扩散模型CMD，实现高质量视频生成同时大幅降低计算成本。 - 转发 @爱可可-爱生活:&amp;ensp;[CV]《Efficien...</title>
<link>https://weibo.com/1402400261/O6zU22DoB</link>
<guid>https://weibo.com/1402400261/O6zU22DoB</guid>
<content:encoded><![CDATA[
<div> 高效视频扩散模型, 内容帧, 运动潜表示, CMD, 高质量视频生成, 计算成本, 紧凑编码, 视频, KAIST, NVIDIA

<br /><br />总结:
该研究提出了一种高效视频扩散模型CMD，通过内容帧和运动潜表示对视频进行紧凑编码，实现高质量视频生成的同时大幅降低计算成本。该模型通过内容帧和运动潜表示的分解实现了对视频的高效编码和还原，提高了视频处理的效率和质量。研究团队来自KAIST和NVIDIA，他们的成果有望在视频处理领域带来重要的创新和应用。 <div>
通过内容帧和运动潜表示对视频进行紧凑编码，设计高效视频扩散模型CMD，实现高质量视频生成同时大幅降低计算成本。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CV]《Efficient Video Diffusion Models via Content-Frame Motion-Latent Decomposition》S Yu, W Nie, D Huang, B Li, J Shin, A Anandkumar [KAIST &amp; NVIDIA] (2024) <a href="https://arxiv.org/abs/2403.14148"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2rxof5nij214c0rwgxs.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2rxou43gj20om0ui44o.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2rxpbzubj21bq0m2qb1.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2rxpnztij21cw14gk9n.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2rynl41qj20vd0bsabo.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2rynltyjj20vd0byac2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2rynlxt2j20vd0bytao.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho2rynl8mej20u40cxwgd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho2rynnu0nj20tz18s10t.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 21:11:59 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.24)》 爱可可微博热门分享(3.24) [图片]</title>
<link>https://weibo.com/1402400261/O6xdpvE7S</link>
<guid>https://weibo.com/1402400261/O6xdpvE7S</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、3.24、话题、关注、粉丝、评论、轻松

<br /><br />总结：
今日爱可可微博推送了一篇热门分享，引起了广泛关注和讨论。用户们纷纷在微博上转发并评论该话题，带动了粉丝互动和分享热度。内容涵盖了各种主题，从娱乐轻松到社会热点，让用户们在微博平台上获得了丰富的信息和乐趣。大家可以继续关注爱可可微博，获取更多热门话题和精彩内容。 <div>
《爱可可微博热门分享(3.24)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405015576514003379"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.24)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho2g43dhwij20p90e7dhf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 14:21:28 GMT</pubDate>
</item>
<item>
<title>《告别焦虑：用行动让内心重获自由》 网页链接 #焦虑# [图片]</title>
<link>https://weibo.com/1402400261/O6vvx4X9m</link>
<guid>https://weibo.com/1402400261/O6vvx4X9m</guid>
<content:encoded><![CDATA[
<div> 焦虑、行动、内心、自由、挑战、克服、积极、心理健康、改变、建议

<br />
这篇文章提出了让内心重获自由的方法，重点在于用积极的行动来克服焦虑。首先，作者指出焦虑可以通过行动来改变，建议读者积极面对挑战，而不是逃避。其次，文章强调了心理健康的重要性，认为通过调整心态和行为可以有效缓解焦虑。此外，作者还提到了一些应对焦虑的具体建议，如运动、冥想和寻求社交支持等方式。总的来说，要摆脱焦虑，关键在于采取行动，积极面对内心的困扰，从而重获内心的自由。 

<br /><br />总结: 挑战不要逃避，积极行动是克服焦虑的关键；心理健康的重要性不可忽视，调整心态和行为有助于缓解焦虑；建议采取运动、冥想和社交支持等方式来应对焦虑。 <div>
《告别焦虑：用行动让内心重获自由》 <a href="https://www.toutiao.com/article/7349846808909136399/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%84%A6%E8%99%91%23&amp;isnewpage=1"><span class="surl-text">#焦虑#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho28kqrziaj20xb0u0q90.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 10:00:37 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码:《InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior》(ICLR 2024) GitHub: github.com/chenguolin/In...</title>
<link>https://weibo.com/1402400261/O6ue3uyGu</link>
<guid>https://weibo.com/1402400261/O6ue3uyGu</guid>
<content:encoded><![CDATA[
<div> InstructScene, 3D室内场景合成, 语义图先验, GitHub, SPAD, CVPR 2024, 多视角漫反射器, AnyV2V, 视频编辑, Yell At Your Robot, 语言修正, Switch Diffusion Transformer, 去噪任务, 稀疏混合专家<br />
<br />
要点1: 《InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior》介绍了一种由指令驱动的3D室内场景合成算法，采用了语义图先验。<br />
要点2: 《SPAD : Spatially Aware Multiview Diffusers》探讨了空间感知多视角漫反射器的研究，是CVPR 2024的文章。<br />
要点3: 《AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks》提出了一个用于各种视频编辑任务的即插即用框架，名为AnyV2V。<br />
要点4: 《Yell At Your Robot: Improving On-the-Fly from Language Corrections》聚焦于通过语言纠正来实时改进机器人的研究。<br />
要点5: 《Switch Diffusion Transformer: Synergizing Denoising Tasks with Sparse Mixture-of-Experts》介绍了Switch Diffusion Transformer技术，将去噪任务与稀疏混合专家相结合。 <br />
<br />
总结: 这几篇论文分别探讨了不同方向的研究内容，涵盖了指令驱动的室内场景合成、多视角漫反射器、视频编辑框架、语言纠正改进机器人和稀疏混合专家在去噪任务中的应用。每篇论文都提出了创新的方法和技术，为相应领域的研究和进展提供了有益的参考和启发。 <div>
几篇论文实现代码:<br />《InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior》(ICLR 2024) GitHub: github.com/chenguolin/InstructScene[fig3]<br />《SPAD : Spatially Aware Multiview Diffusers》(CVPR 2024) GitHub: github.com/yashkant/spad [fig2]<br />《AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks》(2024) GitHub: github.com/TIGER-AI-Lab/AnyV2V [fig1] <br />《Yell At Your Robot: Improving On-the-Fly from Language Corrections》(2024) GitHub: github.com/yay-robot/yay_robot [fig4]<br />《Switch Diffusion Transformer: Synergizing Denoising Tasks with Sparse Mixture-of-Experts》(2024) GitHub: github.com/byeongjun-park/Switch-DiT [fig5]<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho20jwayxhj20w60o64g1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho21unbx45j220k0jgb1m.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho21z0t2pvj23140x6qv6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho226e7gcoj22uf0te4qp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho22t646awj21zh0r1hdt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:44:50 GMT</pubDate>
</item>
<item>
<title>【files-to-prompt：将一个目录中的文件合并成一个更完整的提示文本】'files-to-prompt - Concatenate a directory full of files into a single prompt for use...</title>
<link>https://weibo.com/1402400261/O6ud6lpoj</link>
<guid>https://weibo.com/1402400261/O6ud6lpoj</guid>
<content:encoded><![CDATA[
<div> 文件合并 指令 LLMs GitHub 文本 提取 合并 目录 文件 输出所有要点。
<br /><br />
总结: 该文章介绍了一个工具，可以将一个目录中的文件合并成一个更完整的提示文本，用于与LLMs一起使用。工具的GitHub链接为github.com/simonw/files-to-prompt。 <div>
【files-to-prompt：将一个目录中的文件合并成一个更完整的提示文本】'files-to-prompt - Concatenate a directory full of files into a single prompt for use with LLMs' GitHub: github.com/simonw/files-to-prompt <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho22ukraruj214y0g676a.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:42:29 GMT</pubDate>
</item>
<item>
<title>【auto-coder：功能强大的命令行版Devin，使用 Byzer-LLM 语言模型，提供自动化代码生成功能，支持多种编程语言，通过上下文自动生成代码，帮助开发者快速完成AI...</title>
<link>https://weibo.com/1402400261/O6ucmiW6v</link>
<guid>https://weibo.com/1402400261/O6ucmiW6v</guid>
<content:encoded><![CDATA[
<div> 关键词: auto-coder, 命令行版, Byzer-LLM 语言模型, 自动化代码生成, 多种编程语言, 上下文自动生成代码, 开发者, AI代码创作, GitHub

总结:
Auto-coder 是一款功能强大的命令行工具，使用 Byzer-LLM 语言模型实现自动化代码生成，支持多种编程语言。通过上下文分析，可以帮助开发者快速完成AI代码创作。用户可以在 GitHub 上找到该工具的代码库。 <div>
【auto-coder：功能强大的命令行版Devin，使用 Byzer-LLM 语言模型，提供自动化代码生成功能，支持多种编程语言，通过上下文自动生成代码，帮助开发者快速完成AI代码创作】'auto-coder - game-changing Auto-Coder’ GitHub: github.com/allwefantasy/auto-coder <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho22srr00pj211w0u0jxg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:40:39 GMT</pubDate>
</item>
<item>
<title>【RAGTune：用于自动调整和优化RAG管线的工具。允许您评估不同的 LLMs(大型语言模型)、嵌入模型、查询转换器和重排器等组件】'RAGTune - Tuning and Evaluation ...</title>
<link>https://weibo.com/1402400261/O6ualh97E</link>
<guid>https://weibo.com/1402400261/O6ualh97E</guid>
<content:encoded><![CDATA[
<div> GitHub、RAGTune、自动调整、优化、RAG管线、评估、LLMs、大型语言模型、嵌入模型、查询转换器<br />
<br />
RAGTune是用于自动调整和优化RAG管线的工具，允许用户评估不同的LLMs、嵌入模型、查询转换器和重排器等组件。该工具在GitHub上开源，即将添加自动化优化功能。用户可以通过RAGTune对RAG管线进行调整和评估，以找到最佳的组件配置。该工具有助于提高RAG管线的性能和效率，为语言模型的应用提供更好的支持。 <div>
【RAGTune：用于自动调整和优化RAG管线的工具。允许您评估不同的 LLMs(大型语言模型)、嵌入模型、查询转换器和重排器等组件】'RAGTune - Tuning and Evaluation of RAG pipeline. (Automated optimization to be added soon)' GitHub: github.com/misbahsy/RAGTune <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho22nljeh1j21ji0ggn02.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:35:41 GMT</pubDate>
</item>
<item>
<title>【Ollama LLM的漂亮HTML聊天界面】’Fully-featured &amp; beautiful web interface for Ollama LLMs - Fully-featured, beautiful web interface for Ollama LLMs -...</title>
<link>https://weibo.com/1402400261/O6u7122XO</link>
<guid>https://weibo.com/1402400261/O6u7122XO</guid>
<content:encoded><![CDATA[
<div> NextJS, Ollama LLM, 聊天界面, HTML, 界面美观, GitHub, 部署, 单击部署

<br /><br />总结:
这是一个用NextJS构建的Ollama LLMs的全功能美观聊天界面的Web界面，可一键部署在GitHub上。界面设计简洁美观，用户可以轻松进行互动和通讯。通过GitHub可轻松获取该项目并进行单击部署，极大地方便了用户的使用和部署过程。 <div>
【Ollama LLM的漂亮HTML<br />聊天界面】’Fully-featured &amp; beautiful web interface for Ollama LLMs - Fully-featured, beautiful web interface for Ollama LLMs - built with NextJS. Deploy with a single click.' GitHub: github.com/jakobhoeg/nextjs-ollama-llm-ui <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho22eisl9uj218c0s0acx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:27:29 GMT</pubDate>
</item>
<item>
<title>【WSL Manager：WSL发行版管理器，一个用户友好的小软件，可帮助您轻松管理 Windows Subsystem for Linux(WSL)发行版，包括安装、卸载、更新、备份和恢复】’Wel...</title>
<link>https://weibo.com/1402400261/O6u552Kkf</link>
<guid>https://weibo.com/1402400261/O6u552Kkf</guid>
<content:encoded><![CDATA[
<div> GUI、WSL2、管理、Windows Subsystem for Linux、发行版、安装、卸载、更新、备份、恢复
<br /><br />
总结:
WSL Manager 是一个用户友好的小软件，可以帮助用户轻松管理 Windows Subsystem for Linux (WSL) 发行版。该管理器提供图形界面(GUI)，可以快速地安装、卸载、更新、备份和恢复 WSL2 实例。用户可以通过 GitHub 访问该软件的代码库。 <div>
【WSL Manager：WSL发行版管理器，一个用户友好的小软件，可帮助您轻松管理 Windows Subsystem for Linux(WSL)发行版，包括安装、卸载、更新、备份和恢复】’Welcome to WSL Manager - A GUI to quickly manage your WSL2 instances' GitHub: github.com/bostrot/wsl2-distro-manager <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23WSL%23"><span class="surl-text">#WSL#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho229yk23wj21c00u0go7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:22:43 GMT</pubDate>
</item>
<item>
<title>【Financial Agent：用LangChain开发的金融Agent】’Financial Agent - A financial agent, built entirely with LangChain!' GitHub: github.com/virattt/finan...</title>
<link>https://weibo.com/1402400261/O6u1MaB1s</link>
<guid>https://weibo.com/1402400261/O6u1MaB1s</guid>
<content:encoded><![CDATA[
<div> Financial Agent, LangChain, 金融, Agent, GitHub, 开发, 技术，LangChain, 金融服务，GitHub

<br /><br />总结:
这篇文章介绍了使用LangChain开发的金融Agent，即Financial Agent。这个金融Agent完全由LangChain构建而成，通过GitHub提供给用户下载和使用。使用LangChain开发金融Agent将为用户提供更高效的金融服务，同时展示了LangChain在金融科技领域的应用和潜力。如果需要构建金融服务的系统或应用，可以考虑使用这个Financial Agent作为参考和模板。 <div>
【Financial Agent：用LangChain开发的金融Agent】’Financial Agent - A financial agent, built entirely with LangChain!' GitHub: github.com/virattt/financial-agent <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho221nfhmtj21ji0g4417.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:14:35 GMT</pubDate>
</item>
<item>
<title>'RefactorGraph - 分层解耦的深度学习推理引擎' GitHub: github.com/InfiniTensor/RefactorGraph #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O6u0hyrji</link>
<guid>https://weibo.com/1402400261/O6u0hyrji</guid>
<content:encoded><![CDATA[
<div> GitHub, RefactorGraph, 分层解耦, 深度学习, 推理引擎, InfiniTensor  

<br />
深度学习在计算机视觉、自然语言处理等领域取得重大进展，但是许多现有的深度学习框架存在性能瓶颈和复杂性高的问题。RefactorGraph是一个开源的分层解耦的深度学习推理引擎，旨在解决这些问题。该引擎的主要特点包括支持图编译、模块化设计、优化策略等。RefactorGraph通过将计算图分解为多个层次，实现了更好的性能和更简洁清晰的代码。同时，它还提供了灵活的操作和分布式计算的支持，使得用户能够更轻松地定制和优化深度学习模型。总的来说，RefactorGraph为深度学习的推理过程提供了一个高效、灵活的解决方案，对推动深度学习技术的发展具有积极意义。

<br /><br />
总结:  
1. RefactorGraph是一个分层解耦的深度学习推理引擎，旨在解决深度学习框架存在的性能瓶颈和复杂性问题。  
2. 该引擎支持图编译、模块化设计和优化策略，为用户提供更高效的计算图管理和优化方式。  
3. RefactorGraph通过将计算图分解为多个层次，实现更好的性能和更简洁清晰的代码。  
4. 提供了灵活的操作和分布式计算支持，使用户能够定制和优化深度学习模型。  
5. 对推动深度学习技术的发展具有积极意义，为深度学习推理过程提供了一个高效、灵活的解决方案。 <div>
'RefactorGraph - 分层解耦的深度学习推理引擎' GitHub: github.com/InfiniTensor/RefactorGraph <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho21xtlr6xj214w0u0q7z.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:10:54 GMT</pubDate>
</item>
<item>
<title>【Mistral Transformer：用于运行和微调Mistral 7B模型的简洁代码】’Mistral Transformer - minimal code to run our 7B model and to finetune it’ GitHub: g...</title>
<link>https://weibo.com/1402400261/O6tXzobsR</link>
<guid>https://weibo.com/1402400261/O6tXzobsR</guid>
<content:encoded><![CDATA[
<div> GitHub, Mistral Transformer, 运行, 微调, 7B模型, 简洁代码

<br /><br />总结:
Mistral Transformer是一个用于运行和微调Mistral 7B模型的工具，提供了简洁的代码。用户可以在GitHub上找到相关代码。该工具可帮助用户快速运行和微调模型，提高工作效率。 <div>
【Mistral Transformer：用于运行和微调Mistral 7B模型的简洁代码】’Mistral Transformer - minimal code to run our 7B model and to finetune it’ GitHub: github.com/mistralai-sf24/hackathon <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho21qpbzv0j21be0u0gqy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho21qtnqeyj22k40u0794.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 06:04:13 GMT</pubDate>
</item>
<item>
<title>【Lapdev：自托管远程开发环境管理系统，可以在服务器或云服务器上建立和管理远程开发环境】'Lapdev - Self-Hosted Remote Dev Environment' GitHub: github.com...</title>
<link>https://weibo.com/1402400261/O6tHorWH1</link>
<guid>https://weibo.com/1402400261/O6tHorWH1</guid>
<content:encoded><![CDATA[
<div> 自托管、远程、开发环境、管理系统、服务器、云服务器、建立、管理、lapdev、GitHub<br />
<br />
总结：<br />
文章介绍了 Lapdev 系统，它是一个自托管的远程开发环境管理系统，可以在服务器或云服务器上建立和管理开发环境。用户可以通过 GitHub 上的 lapce/lapdev 找到该系统的详细信息和代码。该系统的主要特点包括自托管、远程开发环境、服务器和云服务器部署支持，以及便于管理开发环境的功能。通过 Lapdev，用户可以方便地搭建和管理自己的开发环境，提高开发效率。 <div>
【Lapdev：自托管远程开发环境管理系统，可以在服务器或云服务器上建立和管理远程开发环境】'Lapdev - Self-Hosted Remote Dev Environment' GitHub: github.com/lapce/lapdev <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E5%8F%91%23&amp;isnewpage=1"><span class="surl-text">#开发#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho20l3dc63j21ek0u0din.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 05:24:22 GMT</pubDate>
</item>
<item>
<title>恭喜@Litoch 等3名用户获得【《大语言模型：原理与工程实践(全彩)》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效。公示链接：网页...</title>
<link>https://weibo.com/1402400261/O6takDgUm</link>
<guid>https://weibo.com/1402400261/O6takDgUm</guid>
<content:encoded><![CDATA[
<div> 大语言模型，抽奖，书籍，作者，知识体系，实践性，代码，全彩印刷，杨青，训练经验

<br /><br />总结:
微博举办了抽奖活动，恭喜3名幸运用户获得了《大语言模型：原理与工程实践(全彩)》一书。该书由杨青撰写，旨在揭开大语言模型的神秘面纱，透彻解读其内在机理和应用实践。书籍特色包括系统性的知识体系和实践性的重视，配有代码和全彩印刷。作者具有大语言模型实践经验，在书中分享了训练经验和干货内容，让读者能够深入了解和运用大语言模型。活动截止时间为2024年3月24日12:00，感兴趣的用户可转发和评论参与抽奖。 <div>
恭喜<a href="https://weibo.com/n/Litoch">@Litoch</a> 等3名用户获得【《大语言模型：原理与工程实践(全彩)》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20198320&amp;pageid=100140E51188562"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 04:02:55 GMT</pubDate>
</item>
<item>
<title>【Nvidia提供的在线免费新课】1、Generative AI Explained 网页链接 2、Building A Brain in 10 Minutes | NVIDIA 网页链接 3、Augment your LLM Using Retrieva...</title>
<link>https://weibo.com/1402400261/O6su8CHHx</link>
<guid>https://weibo.com/1402400261/O6su8CHHx</guid>
<content:encoded><![CDATA[
<div> Generative AI, Building A Brain, Retrieval Augmented Generation, AI in the Data Center, Data Science Workflows, Zero Code Changes

<br /><br />总结:
Nvidia提供了一系列在线免费新课程，涵盖了各种人工智能领域的主题。其中包括Generative AI的解释，如何在10分钟内构建一个大脑，使用Retrieval Augmented Generation增强LLM，以及在数据中心中应用人工智能等内容。此外，还探讨了如何加速数据科学工作流程而无需进行任何代码更改。这些课程为学习人工智能提供了宝贵资源，帮助人们更好地了解和应用这一领域的知识。 <div>
【Nvidia提供的在线免费新课】<br />1、Generative AI Explained <a href="https://courses.nvidia.com/courses/course-v1:DLI+S-FX-07+V1/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <br />2、Building A Brain in 10 Minutes | NVIDIA <a href="https://courses.nvidia.com/courses/course-v1:DLI+T-FX-01+V1/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <br />3、Augment your LLM Using Retrieval Augmented Generation <a href="https://courses.nvidia.com/courses/course-v1:NVIDIA+S-FX-16+v1/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br />4、AI in the Data Center <a href="https://www.coursera.org/learn/introduction-ai-data-center"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br />5、Accelerate Data Science Workflows with Zero Code Changes <a href="https://courses.nvidia.com/courses/course-v1:DLI+T-DS-03+V1/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho1v8fg0o7j20xc0istgb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 02:18:58 GMT</pubDate>
</item>
<item>
<title>【LlamaIndex+Mistral开发指南】《Build Cool Stuff with Mistral! (RAG, Agents) - Google Slides》 网页链接 #机器学习# #人工智能# [图片][图片]</title>
<link>https://weibo.com/1402400261/O6s9ndzLj</link>
<guid>https://weibo.com/1402400261/O6s9ndzLj</guid>
<content:encoded><![CDATA[
<div> Agents, RAG, Google Slides, Mistral, 开发, 指南, Cool Stuff, Build, LlamaIndex

<br /><br />总结:
本文介绍了如何使用Mistral来构建各种酷炫的项目。首先介绍了Agents和RAG这两个重要概念，然后详细讲解了在Google Slides上如何进行开发。通过本文，读者可以学习到如何利用Mistral来打造各种有趣的项目，为开发者提供了一份详细的指南。 <div>
【LlamaIndex+Mistral开发指南】《Build Cool Stuff with Mistral! (RAG, Agents) - Google Slides》 <a href="https://docs.google.com/presentation/d/1dbfoxzNcoI-D45RKZfO1UfBJIr4v0YtHhj1cwuCj020/edit"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho1tr8xzhtj21fo0u0wgu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho1tr98b7yj21jm0u0q8i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 01:27:48 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发...</title>
<link>https://weibo.com/1402400261/O6rNW8q5w</link>
<guid>https://weibo.com/1402400261/O6rNW8q5w</guid>
<content:encoded><![CDATA[
<div> 携手、送出、hello算法、可可粉、数据结构、算法、动画图解、实战代码示例、互动环节<br />
<br />
数据结构和算法是计算机科学中的重要知识点，掌握它们对于编程能力的提高至关重要。《hello算法》这本书以全新的视角带你进入算法的世界，通过生动的动画图解，让抽象的概念变得直观易懂。每一章都提供实战代码示例，帮助读者即学即用，巩固所学知识。书中设计了互动环节，帮助读者主动思考、提问和解决问题。通过携手转发和评论，可可粉可以有机会获得这本书，轻松入门数据结构与算法，提升编程技能。<br /><br />总结:数据结构和算法是计算机科学中的重要知识点，而《hello算法》这本书以全新的视角带你轻松掌握这些概念。书中生动的动画图解、实战代码示例和互动环节设计，让读者能够直观理解、应用和巩固所学的知识。通过参与活动，可可粉有机会获得这本书，提升自己的编程能力。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 00:34:59 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截...</title>
<link>https://weibo.com/1402400261/O6rNRBQ1C</link>
<guid>https://weibo.com/1402400261/O6rNRBQ1C</guid>
<content:encoded><![CDATA[
<div> 大语言模型、开奖、参与、转发、评论、知识体系、实践性、全彩印刷、杨青、干货满满

总结:<br /><br />今日开奖，欢迎参与转发评论抽奖活动，奖品是《大语言模型：原理与工程实践(全彩)》三本。这本书揭开了大语言模型的神秘面纱，详细解读了内在机理和应用实践，特色在于系统性的知识体系和对实践性的重视。作者杨青是大语言模型实践者，将自己的训练经验融入书中，内容干货满满。截止时间是2024年3月24日12:00，转发+评论即可参与。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 24 Mar 2024 00:34:49 GMT</pubDate>
</item>
<item>
<title>今日推介(第1354期)：基于条件最优传输理解无限深无限宽ResNets训练、用Shapley交互揭示数据的底层结构、黑盒生成语言模型部分参数的窃取、LLM智能体长时会话记...</title>
<link>https://weibo.com/1402400261/O6rbfxgVj</link>
<guid>https://weibo.com/1402400261/O6rbfxgVj</guid>
<content:encoded><![CDATA[
<div> 条件最优传输、ResNets训练、Shapley交互、数据结构、黑盒攻击、LLM智能体、长时记忆、立体声音频编码

<br /><br />总结:
本文介绍了基于条件最优传输理解无限深无限宽ResNets训练的方法，利用Shapley交互揭示数据的底层结构，探讨了黑盒生成语言模型部分参数的窃取问题，提出了LLM智能体长时会话记忆评估的技术，以及快速高保真立体声音频编码的研究成果。这些研究为深度学习和音频处理领域的发展提供了有益的思路和方法。 <div>
今日推介(第1354期)：基于条件最优传输理解无限深无限宽ResNets训练、用Shapley交互揭示数据的底层结构、黑盒生成语言模型部分参数的窃取、LLM智能体长时会话记忆评估、快速高保真立体声音频编码 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/688692818"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.24)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho1pgtonofj20go0bz76y.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho1pgxhwb9j20go095gmb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho1ph04d2fj20go0ez75t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho1ph2vh1ej20go0rl0vy.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho1ph55flgj20go0fign7.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:59:41 GMT</pubDate>
</item>
<item>
<title>[CL] From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models 网页链接 对图表自动理解任务进行了全面调...</title>
<link>https://weibo.com/1402400261/O6r7zjwHU</link>
<guid>https://weibo.com/1402400261/O6r7zjwHU</guid>
<content:encoded><![CDATA[
<div> 关键词: 图表自动理解, 大型基础模型, 调研, 方法, 进展, 未来研究方向, 研究与应用, 宝贵参考

总结:<br /><br />本文对图表自动理解领域进行了全面调研，系统地总结了关键问题、方法与进展，为研究与应用提供了宝贵参考。研究指出大型基础模型在自动理解任务中的重要性，也对未来研究方向进行了展望，促进了该领域的发展和进步。<br />Overall, this survey provides a comprehensive overview of the automatic chart understanding task, covering key issues, methods, and advancements. It offers valuable insights for both research and practical applications. The significance of large foundation models in automatic understanding tasks is highlighted, and future research directions are proposed to advance the field. <div>
[CL] From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models  <br /><a href="https://arxiv.org/abs/2403.12027"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />对图表自动理解任务进行了全面调研，系统梳理了关键问题、方法与进展，并对未来研究方向进行了展望，为该领域的研究与应用提供了宝贵参考。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1p7mn0twj20y819aqn3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1p7n7tfkj21r00p0wrf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1p7nqo39j21p20m8n73.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1p7oabjyj21rs0lkgt4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:50:37 GMT</pubDate>
</item>
<item>
<title>[CL] A Design Space for Intelligent and Interactive Writing Assistants 网页链接 通过系统地回顾文献，提出了一个包含任务、用户、技术、交互和生态系统五个...</title>
<link>https://weibo.com/1402400261/O6r0CncNX</link>
<guid>https://weibo.com/1402400261/O6r0CncNX</guid>
<content:encoded><![CDATA[
<div> 智能交互式写作助手, 设计空间, 文献回顾, 结构化, 多维可能性, 研究人员, 设计人员, 生态系统, 任务, 技术

总结:<br />
本文提出了一个包含任务、用户、技术、交互和生态系统五个方面、35个维度和143个代码的写作助手设计空间，通过系统地回顾文献，为探索智能交互式写作助手的多维可能性空间提供了结构化的方式。这个设计空间可以帮助研究人员、设计人员和其他利益相关者全面理解这个快速发展领域，为进一步研究和设计提供了基础和指导。 <div>
[CL] A Design Space for Intelligent and Interactive Writing Assistants  <br /><a href="https://arxiv.org/abs/2403.14117"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />通过系统地回顾文献，提出了一个包含任务、用户、技术、交互和生态系统五个方面、35个维度和143个代码的写作助手设计空间，以提供一种结构化的方式探索智能交互式写作助手的多维可能性空间，从而帮助研究人员、设计人员和其他利益相关者全面理解这一快速发展的领域。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1opt2r41j213c1c84ov.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1optba1sj21ge1c61c1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1optl9z2j21gc0rywl6.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1opu9kf7j21gm0msah6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:33:29 GMT</pubDate>
</item>
<item>
<title>[CL] Arcee's MergeKit: A Toolkit for Merging Large Language Models 网页链接 提出MergeKit，一个开源、模块化、可扩展的模型合并库，使研究人员和实践者可以...</title>
<link>https://weibo.com/1402400261/O6qXdEONk</link>
<guid>https://weibo.com/1402400261/O6qXdEONk</guid>
<content:encoded><![CDATA[
<div> 提取关键词：MergeKit、开源、模块化、可扩展、预训练语言模型、性能、适应范围、研究人员、实践者、新模型

总结:<br /><br />
研究人员和实践者可以利用开源的MergeKit工具包，模块化地、可扩展地合并预训练语言模型，创造出性能更优异、适应范围更广的新模型。这个库通过提供一个高效的方法，为合并大型语言模型提供了方便和效率。MergeKit的模块化设计使得用户可以根据需求自由选择模型组件，定制化自己的合并流程，帮助他们更好地利用不同模型的优势。通过MergeKit，研究人员和实践者可以更轻松地探索、实验和开发更先进的语言模型，提高模型的性能和适应性，推动领域的发展和创新。 <div>
[CL] Arcee's MergeKit: A Toolkit for Merging Large Language Models  <br /><a href="https://arxiv.org/abs/2403.13257"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />提出MergeKit，一个开源、模块化、可扩展的模型合并库，使研究人员和实践者可以高效地合并预训练语言模型，从而创造出性能更优异、适应范围更广的新模型。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1oh4u01kj20w21cadz4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1oh54u1jj21h40y4n1w.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1oh5gfpfj21c61acqah.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1oh5t4o6j21ce152n8x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:25:07 GMT</pubDate>
</item>
<item>
<title>[CV] MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems? 网页链接 MATHVERSE通过控制问题的多模态信息内容，配合逐步推理...</title>
<link>https://weibo.com/1402400261/O6qUh22Ep</link>
<guid>https://weibo.com/1402400261/O6qUh22Ep</guid>
<content:encoded><![CDATA[
<div> 关键词: MathVerse, 多模态信息, MLMM, 视觉数学理解, 推理能力

MathVerse通过控制问题的多模态信息内容，配合逐步推理评分，可以更准确全面地检验MLLM的视觉数学理解和推理能力。文章指出，传统的语言模型可能无法准确理解和解决视觉数学问题，而MathVerse的多模态信息内容可以帮助MLLM更好地识别和理解数学问题中的图表和图片。此外，文章还介绍了MathVerse使用的逐步推理评分方法，通过结合多模态信息和逐步推理评分，可以更全面地评估MLLM的数学理解和推理能力。总体而言，MathVerse提供了一种全面且准确的评测方法，帮助评估MLLM在视觉数学问题中的表现。<br /><br />总结: MathVerse通过控制问题的多模态信息内容，并配合逐步推理评分，可以更准确全面地检验MLLM的视觉数学理解和推理能力。<article> <div>
[CV] MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?  <br /><a href="https://arxiv.org/abs/2403.14624"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />MATHVERSE通过控制问题的多模态信息内容，配合逐步推理评分，可以更准确全面地检验MLLM的视觉数学理解和推理能力。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1o9jninjj20vo1bi7j2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1o9k4w1jj21ii0xkn8e.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1o9kk764j21i20p646w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1o9l1dxxj21i40vuqd1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:17:50 GMT</pubDate>
</item>
<item>
<title>提出MusicHiFi方法，通过三个GAN的级联，实现了从梅尔谱到高保真立体声音频转换的快速、高效的端到端的框架。 - 转发 @爱可可-爱生活:&amp;ensp;[AS]《MusicHiFi: Fa...</title>
<link>https://weibo.com/1402400261/O6qRkskhl</link>
<guid>https://weibo.com/1402400261/O6qRkskhl</guid>
<content:encoded><![CDATA[
<div> 关键词：MusicHiFi、GAN、梅尔谱、高保真、立体声、音频转换、快速、高效、端到端、框架

总结:<br /><br />总结: 本文提出了一种名为MusicHiFi的方法，通过三个GAN的级联，实现了从梅尔谱到高保真立体声音频转换的快速、高效的端到端框架。该方法由G Zhu、J Caceres、Z Duan和N J. Bryan在University of Rochester & Adobe Research进行研究。通过该方法，可以实现音频转换的高保真和立体声效果，为音频处理领域提供了新思路。 <div>
提出MusicHiFi方法，通过三个GAN的级联，实现了从梅尔谱到高保真立体声音频转换的快速、高效的端到端的框架。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [AS]《MusicHiFi: Fast High-Fidelity Stereo Vocoding》G Zhu, J Caceres, Z Duan, N J. Bryan [University of Rochester &amp; Adobe Research] (2024) <a href="https://arxiv.org/abs/2403.10493"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nxf98tjj21340xqtnb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nxfoc0uj213410eahl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nxg1hpfj21380m0gra.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:10:36 GMT</pubDate>
</item>
<item>
<title>[AS]《MusicHiFi: Fast High-Fidelity Stereo Vocoding》G Zhu, J Caceres, Z Duan, N J. Bryan [University of Rochester &amp; Adobe Research] (2024) 网页链接 #...</title>
<link>https://weibo.com/1402400261/O6qPxCzpM</link>
<guid>https://weibo.com/1402400261/O6qPxCzpM</guid>
<content:encoded><![CDATA[
<div> 关键词: MusicHiFi, Fast, High-Fidelity, Stereo, Vocoding, University of Rochester, Adobe Research, G Zhu, J Caceres, Z Duan

总结:<br /><br />
这篇文章介绍了一种名为MusicHiFi的快速高保真立体声声码技术，由罗切斯特大学和Adobe Research的G Zhu、J Caceres、Z Duan和N J. Bryan合作研究。他们利用这种技术实现了更高保真度的立体声音频编码，使得声音的还原更加清晰逼真。研究中提出了一种新的声码器算法，能够快速处理音频信号并保持高保真度，同时还考虑到了立体声效果的呈现。通过实验证明，MusicHiFi在音频编码方面具有很高的效果和性能，为高保真度立体声编码提供了新的可能性。 <div>
[AS]《MusicHiFi: Fast High-Fidelity Stereo Vocoding》G Zhu, J Caceres, Z Duan, N J. Bryan [University of Rochester &amp; Adobe Research] (2024) <a href="https://arxiv.org/abs/2403.10493"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nxf98tjj21340xqtnb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nxfoc0uj213410eahl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nxg1hpfj21380m0gra.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:06:11 GMT</pubDate>
</item>
<item>
<title>通过机器-人协作管线构建高质量长期多轮对话数据集，并设计了问答、事件总结和对话生成任务对模型长期记忆能力进行全面评估，结果显示当前语言模型在非常长上下...</title>
<link>https://weibo.com/1402400261/O6qOvt7sV</link>
<guid>https://weibo.com/1402400261/O6qOvt7sV</guid>
<content:encoded><![CDATA[
<div> 非常长上下文对话理解、机器-人协作管线、高质量长期多轮对话数据集、问答任务、事件总结任务、对话生成任务、模型长期记忆能力评估、语言模型挑战

<br /><br />总结:
研究者通过机器-人协作管线构建了高质量长期多轮对话数据集，并分别设计了问答、事件总结和对话生成任务来评估模型的长期记忆能力。研究结果显示，当前语言模型在非常长的上下文对话理解方面仍存在挑战。这表明在开发长期记忆能力更强的语言模型时，还有待进一步研究和改进。 <div>
通过机器-人协作管线构建高质量长期多轮对话数据集，并设计了问答、事件总结和对话生成任务对模型长期记忆能力进行全面评估，结果显示当前语言模型在非常长上下文对话理解方面仍面临挑战。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Evaluating Very Long-Term Conversational Memory of LLM Agents》A Maharana, D Lee, S Tulyakov, M Bansal, F Barbieri, Y Fang [University of Southern California &amp; University of North Carolina  Snap Inc] (2024) <a href="https://arxiv.org/abs/2402.17753"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nou506bj20la18qk24.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nouvkj9j20oa146qan.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1novov6qj21c40s0wpt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nowej40j21c20jw7az.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnrdhj20zt0fgdj9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nuqp0ryj20zs0lon1s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nuqp5aej20zs0lw78w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnm9gj20zs09bjtg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nuqpn96j20zt0nkjxy.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:03:39 GMT</pubDate>
</item>
<item>
<title>[CL]《Evaluating Very Long-Term Conversational Memory of LLM Agents》A Maharana, D Lee, S Tulyakov, M Bansal, F Barbieri, Y Fang [University of Southe...</title>
<link>https://weibo.com/1402400261/O6qOtslfs</link>
<guid>https://weibo.com/1402400261/O6qOtslfs</guid>
<content:encoded><![CDATA[
<div> 关键词: Very Long-Term Conversational Memory, LLM Agents, Evaluation, University of Southern California, University of North Carolina, Snap Inc

总结:<br /><br />这篇文章评估了LLM代理人的非常长期对话记忆，作者来自南加州大学、北卡罗来纳大学和Snap Inc。研究表明，在考虑长期对话历史的情况下，LLM代理人在对话生成中表现更好。研究围绕着LLM代理人的记忆能力展开，通过评估代理人在回答各种问题时的表现，揭示了长期记忆对话对代理人性能的重要性。研究结果证明，在实验数据集上，LLM代理人在记忆对话历史方面表现出色，这为未来的对话系统研究提供了有益的见解。 <div>
[CL]《Evaluating Very Long-Term Conversational Memory of LLM Agents》A Maharana, D Lee, S Tulyakov, M Bansal, F Barbieri, Y Fang [University of Southern California &amp; University of North Carolina  Snap Inc] (2024) <a href="https://arxiv.org/abs/2402.17753"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nou506bj20la18qk24.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nouvkj9j20oa146qan.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1novov6qj21c40s0wpt.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nowej40j21c20jw7az.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnrdhj20zt0fgdj9.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nuqp0ryj20zs0lon1s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nuqp5aej20zs0lw78w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnm9gj20zs09bjtg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nuqpn96j20zt0nkjxy.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1nuqpkurj20zs0mttdw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1nuqp5vfj20zs0l9gpf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nuqnphij20zx0ifjud.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 22:03:34 GMT</pubDate>
</item>
<item>
<title>研究人员设计了一种低成本的模型参数提取攻击，可针对商业语言模型API恢复部分关键参数，提醒需要警惕模型泄露风险，并采取适当防御措施。 - 转发 @爱可可-爱生...</title>
<link>https://weibo.com/1402400261/O6qKNqHCb</link>
<guid>https://weibo.com/1402400261/O6qKNqHCb</guid>
<content:encoded><![CDATA[
<div> 提取关键词:
模型参数提取攻击 低成本 商业语言模型API 风险 防御措施

总结:
研究人员设计了一种低成本的模型参数提取攻击，能够针对商业语言模型API恢复部分关键参数，提醒人们警惕模型泄露风险。需要采取适当的防御措施来保护模型的安全性。这篇文献对模型隐私保护和安全性提出了重要警示，建议研究者和企业加强对模型安全的重视，以防止敏感信息泄露。 <div>
研究人员设计了一种低成本的模型参数提取攻击，可针对商业语言模型API恢复部分关键参数，提醒需要警惕模型泄露风险，并采取适当防御措施。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Stealing Part of a Production Language Model》N Carlini, D Paleka, K D Dvijotham... [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.06634"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nev4wrej20sq0zq481.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nevk1kxj20yi0v0n2x.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nevt2q2j20yc0v40xb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho1nl858scj212l0chac7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nl85a49j212s0chgno.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho1nl85e89j212d0f4tb8.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho1nl85baxj212d0htq51.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 21:54:31 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.23)》 爱可可微博热门分享(3.23) [图片]</title>
<link>https://weibo.com/1402400261/O6nJHsNeY</link>
<guid>https://weibo.com/1402400261/O6nJHsNeY</guid>
<content:encoded><![CDATA[
<div> 微博, 热门, 爱可可, 分享, 关键词

<br /><br />总结:
爱可可微博推出了一篇热门分享文章，内容受到了广泛关注。文章中涉及了各种各样的话题，引起了网友们的热烈讨论和转发。通过爱可可微博的宣传和推广，这篇文章得到了较高的关注度和阅读量，对于微博的传播和影响力起到了积极的推动作用。 <div>
《爱可可微博热门分享(3.23)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405015212137775311"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.23)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho1a9kgkc8j20fn08swf8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 14:13:34 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Detecting, Explaining, and Mitigating Memorization in Diffusion Models》(ICLR 2024) GitHub: github.com/YuxinWenRick/diffusion_memo...</title>
<link>https://weibo.com/1402400261/O6lCmrshm</link>
<guid>https://weibo.com/1402400261/O6lCmrshm</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度融合模型、长文本处理、图像生成、数据重建、信息检索

总结:
<br /><br />本研究提出了一种名为"Detecting, Explaining, and Mitigating Memorization in Diffusion Models"的深度融合模型，旨在解决扩散模型中出现的过拟合问题。通过GitHub上的开源代码，实现了对模型的检测、解释和缓解。该模型的应用范围涵盖了图像深度估计、数学问题求解、人脸画风提取、信息检索等多个领域。研究团队还提出了涵盖了深度加权平均和长文本处理等技术的新模型，为解决各类问题提供了新的思路和方法。整体而言，这些研究为深度学习模型的发展和应用带来了一定的推动力。 <div>
几篇论文实现代码：<br />《Detecting, Explaining, and Mitigating Memorization in Diffusion Models》(ICLR 2024) GitHub: github.com/YuxinWenRick/diffusion_memorization<br />《DepthFM: Fast Monocular Depth Estimation with Flow Matching》(2024) GitHub: github.com/CompVis/depth-fm [fig1]<br />《MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?》(2024) GitHub: github.com/ZrrSkywalker/MathVerse [fig2] <br />《Stylized Face Sketch Extraction via Generative Prior with Limited Data》(2024) GitHub: github.com/kwanyun/StyleSketch<br />《INSTRUCTIR: A Benchmark for Instruction Following of Information Retrieval Models》(2024) GitHub: github.com/kaistAI/InstructIR [fig3]<br />《Enhancing Information Flow in Transformers via Depth Weighted Averaging》(2024) GitHub: github.com/epfml/DenseFormer<br />《ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment》(2024) GitHub: github.com/TencentQQGYLab/ELLA<br />《HiGPT: Heterogeneous Graph Language Model》(2024) GitHub: github.com/HKUDS/HiGPT [fig4]<br />《Long-CLIP: Unlocking the Long-Text Capability of CLIP》(2024) GitHub: github.com/beichenzbc/Long-CLIP<br />《G3DR: Generative 3D Reconstruction in ImageNet》(2024) GitHub: github.com/preddy5/G3DR<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0ytu59x4j21oj0oq1ky.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0yzi3pouj21ho0oib29.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho10fojxmzj20yd0qfaoa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho10rtf0k3j21ea0fe7hb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:50:00 GMT</pubDate>
</item>
<item>
<title>【TagGUI：用于快速添加和编辑图像标签和描述的跨平台桌面应用，旨在为生成器式 AI 模型(如 Stable Diffusion)创建图像数据集，支持自动生成描述】’TagGUI - Ta...</title>
<link>https://weibo.com/1402400261/O6lzVl4ho</link>
<guid>https://weibo.com/1402400261/O6lzVl4ho</guid>
<content:encoded><![CDATA[
<div> GitHub、TagGUI、图像标签、图像描述、跨平台、快速添加、编辑、AI模型、Stable Diffusion、图像数据集

<br /><br />总结:
TagGUI是一个跨平台的桌面应用程序，旨在帮助用户快速添加和编辑图像标签和描述。它专注于为生成器式AI模型（如Stable Diffusion）创建图像数据集，并支持自动生成描述。用户可以利用TagGUI管理和标注图像数据集，使其更加规范和易于使用。GitHub上有该项目的源代码，用户可前往github.com/jhc13/taggui获取更多信息和资源。 <div>
【TagGUI：用于快速添加和编辑图像标签和描述的跨平台桌面应用，旨在为生成器式 AI 模型(如 Stable Diffusion)创建图像数据集，支持自动生成描述】’TagGUI - Tag manager and captioner for image datasets' GitHub: github.com/jhc13/taggui <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho10qotazbj21jn0u0wja.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho10qq4lkej211g0u011k.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:43:59 GMT</pubDate>
</item>
<item>
<title>【大语言模型自一致性相关文献资源列表】’Awesome LLM Self-Consistency - Awesome LLM Self-Consistency: a curated list of Self-consistency in Large Langu...</title>
<link>https://weibo.com/1402400261/O6lzclKxR</link>
<guid>https://weibo.com/1402400261/O6lzclKxR</guid>
<content:encoded><![CDATA[
<div> Self-consistency, Large Language Models, curated list, GitHub, research, resources, studies, algorithms, evaluations, implementations

自一致性是大语言模型的重要特征，可以在GitHub上找到相关资源和研究内容。这些资源包括研究、算法、评估和实现，有助于理解大语言模型中的自一致性。通过这些资源可以更好地探讨和应用大语言模型的自一致性，为相关研究和实践提供参考。 <div>
【大语言模型自一致性相关文献资源列表】’Awesome LLM Self-Consistency - Awesome LLM Self-Consistency: a curated list of Self-consistency in Large Language Models' GitHub: github.com/SuperBruceJia/Awesome-LLM-Self-Consistency <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho10oxmykbj21ji0qwwko.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:42:12 GMT</pubDate>
</item>
<item>
<title>【WhisperWriter：使用 OpenAI Whisper 模型的免费软件，可以自动将用户的语音转录为文字】'WhisperWriter - A small dictation app using OpenAI's Whisper spe...</title>
<link>https://weibo.com/1402400261/O6lyJoffM</link>
<guid>https://weibo.com/1402400261/O6lyJoffM</guid>
<content:encoded><![CDATA[
<div> OpenAI Whisper 模型、WhisperWriter、语音转录、免费软件、GitHub、人工智能

<br /><br />总结:
WhisperWriter是一个使用OpenAI的Whisper语音识别模型的小型听写应用程序，在GitHub上提供免费下载。用户可以通过该软件将语音自动转录为文字，实现方便快捷的文字输入。这个基于人工智能技术的应用为用户提供了更加智能化的听写体验，帮助提高工作效率。 <div>
【WhisperWriter：使用 OpenAI Whisper 模型的免费软件，可以自动将用户的语音转录为文字】'WhisperWriter - A small dictation app using OpenAI's Whisper speech recognition model.' GitHub: github.com/savbell/whisper-writer <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> #人工智能 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho10ni91rkj20qs06kmxi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:41:03 GMT</pubDate>
</item>
<item>
<title>'MoneyPrinterTurbo - 利用大模型，一键生成短视频' GitHub: github.com/harry0703/MoneyPrinterTurbo #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O6luDyuzy</link>
<guid>https://weibo.com/1402400261/O6luDyuzy</guid>
<content:encoded><![CDATA[
<div> MoneyPrinterTurbo、大模型、短视频、生成、GitHub、harry0703、一键、利用、视频、开发者
<br /><br />
总结:
MoneyPrinterTurbo是一个利用大模型生成短视频的工具，开发者可以通过一键操作快速生成精美的短视频内容。项目托管在GitHub上，作者是harry0703。该工具的核心功能是利用先进的大模型技术，帮助用户快速生成高质量的短视频，节省创作时间和精力。愿意尝试新颖技术的开发者可以前往GitHub查看更多详细信息。 <div>
'MoneyPrinterTurbo - 利用大模型，一键生成短视频' GitHub: github.com/harry0703/MoneyPrinterTurbo <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8ho10czddapj21da0u0adi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:30:58 GMT</pubDate>
</item>
<item>
<title>【WavCraft：基于 LLM 的音频内容创作和编辑 Agent，通过连接各种音频专家模型和 DSP 函数，实现音频内容的创建和编辑】'WavCraft - Official repo for WavCraft...</title>
<link>https://weibo.com/1402400261/O6luhr3pY</link>
<guid>https://weibo.com/1402400261/O6luhr3pY</guid>
<content:encoded><![CDATA[
<div> 音频内容创作、编辑 Agent、LLM、连接、音频专家模型、DSP 函数、音频内容创建、音频内容编辑、WavCraft、GitHub

<br /><br />总结:
WavCraft是基于LLM的音频内容创作和编辑Agent，通过连接各种音频专家模型和DSP函数，实现音频内容的创建和编辑。该项目的官方存储库位于GitHub上。通过WavCraft，用户可以利用人工智能技术进行音频内容的制作和编辑，提高效率和质量。GitHub链接: github.com/JinhuaLiang/WavCraft。 <div>
【WavCraft：基于 LLM 的音频内容创作和编辑 Agent，通过连接各种音频专家模型和 DSP 函数，实现音频内容的创建和编辑】'WavCraft - Official repo for WavCraft, an AI agent for audio creation and editing' GitHub: github.com/JinhuaLiang/WavCraft <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho10cbs8e3j213e0u0qam.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 08:30:05 GMT</pubDate>
</item>
<item>
<title>【npx lumentis：用单个命令从转录文本和非结构化信息生成精美的文档】'npx lumentis - AI powered one-click comprehensive docs from transcripts and text.' ...</title>
<link>https://weibo.com/1402400261/O6lgtxrjU</link>
<guid>https://weibo.com/1402400261/O6lgtxrjU</guid>
<content:encoded><![CDATA[
<div> 转录文本、非结构化信息、生成文档、npx lumentis、AI、单个命令、精美、GitHub、hrishioa、comprehensive docs<br />
<br />
提到了一款名为npx lumentis的工具，可以通过单个命令将转录文本和非结构化信息转换为精美的文档。这个工具是由AI技术驱动的，能够快速生成全面的文档。可以在GitHub上找到该工具的源代码，作者是hrishioa。 <div>
【npx lumentis：用单个命令从转录文本和非结构化信息生成精美的文档】'npx lumentis - AI powered one-click comprehensive docs from transcripts and text.' GitHub: github.com/hrishioa/lumentis <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho0zcw2z6wj21g80u0gpl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 07:56:05 GMT</pubDate>
</item>
<item>
<title>【Leaping：简洁易用的 Python 测试调试工具，可帮助追踪代码执行过程并使用自然语言回溯代码状态，以便在代码运行期间查看其状态】'Leaping' GitHub: github.co...</title>
<link>https://weibo.com/1402400261/O6lbJeZ2G</link>
<guid>https://weibo.com/1402400261/O6lbJeZ2G</guid>
<content:encoded><![CDATA[
<div> 追踪代码执行过程 自然语言回溯 简洁易用 Python 测试调试工具 Leaping GitHub 状态查看 <br />
<br />
Leaping 是一个简洁易用的 Python 测试调试工具，能够帮助用户追踪代码执行过程并使用自然语言回溯代码状态。通过 Leaping，用户可以在代码运行期间查看其状态，帮助进行调试和测试。Leaping 的 GitHub 地址为 github.com/leapingio/leaping。Leaping 提供了一种便捷的方式来理解代码的执行流程，并通过自然语言描述代码的状态，使得用户更容易理解代码的运行过程。通过 Leaping，用户可以更高效地进行代码调试和测试，提高工作效率。Leaping 是一个强大的工具，可以帮助用户更好地管理和优化代码的执行过程，是开发者的好帮手。 <br /><br />总结: Leaping 是一个简洁易用的 Python 测试调试工具，通过自然语言回溯代码状态，帮助追踪代码执行过程，提高代码调试效率。GitHub 地址为 github.com/leapingio/leaping。 <div>
【Leaping：简洁易用的 Python 测试调试工具，可帮助追踪代码执行过程并使用自然语言回溯代码状态，以便在代码运行期间查看其状态】'Leaping' GitHub: github.com/leapingio/leaping <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho0z0rza6zj21ji0jw784.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 07:44:23 GMT</pubDate>
</item>
<item>
<title>【gpt-investor：一个实验性投资分析Agent，利用 Claude 3 Opus 和 Haiku 模型提供给特定行业股票的全面分析和推荐】'gpt-investor' GitHub: github.com/mshumer...</title>
<link>https://weibo.com/1402400261/O6laauEq8</link>
<guid>https://weibo.com/1402400261/O6laauEq8</guid>
<content:encoded><![CDATA[
<div> 投资分析、Agent、股票、全面分析、推荐、实验性、GitHub、模型、特定行业、Claude 3 Opus、Haiku

<br /><br />总结:
实验性投资分析Agent"gpt-investor"利用Claude 3 Opus和Haiku模型提供特定行业股票的全面分析和推荐。该项目的GitHub链接是github.com/mshumer/gpt-investor。通过这个Agent，投资者可以获得更准确的投资建议，更好地了解特定行业股票的情况，以便做出更明智的投资决策。 <div>
【gpt-investor：一个实验性投资分析Agent，利用 Claude 3 Opus 和 Haiku 模型提供给特定行业股票的全面分析和推荐】'gpt-investor' GitHub: github.com/mshumer/gpt-investor <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0ywr6onfj211h0u0wjr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 07:40:31 GMT</pubDate>
</item>
<item>
<title>【VIGGLE：基于骨骼动画技术的AI视频生成工具】- 上传人物角色图片和动作参考视频，Viggle AI可以自动将图片中的人物提取出来，匹配到参考视频的动作上，生成一...</title>
<link>https://weibo.com/1402400261/O6j8JwRfU</link>
<guid>https://weibo.com/1402400261/O6j8JwRfU</guid>
<content:encoded><![CDATA[
<div> VIGGLE、骨骼动画技术、AI视频生成工具、人物角色图片、动作参考视频、角色动画视频、动作捕捉、动作迁移、自动化、高质量。<br />
<br />
总结:VIGGLE是一款基于骨骼动画技术的AI视频生成工具，用户只需上传人物角色图片和动作参考视频，即可自动生成一致性的角色动画视频。利用骨骼动画技术，Viggle AI能精准捕捉参考视频中人物的动作，并将其映射到静态图片角色上，实现动作的迁移和还原。整个视频生成过程高度自动化，无需手动调整，即可快速生成高质量的人物动画。 <div>
【VIGGLE：基于骨骼动画技术的AI视频生成工具】<br />- 上传人物角色图片和动作参考视频，Viggle AI可以自动将图片中的人物提取出来，匹配到参考视频的动作上，生成一致性的角色动画视频。  <br />- 利用骨骼动画技术，Viggle AI能够精准捕捉参考视频中人物的动作，并将其映射到静态图片角色上，实现动作的迁移和还原。  <br />- 整个视频生成过程高度自动化，用户只需上传图片和视频，无需手动调整，即可快速生成高质量的人物动画。<br />《VIGGLE》 <a href="https://viggle.ai/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5015034862960685"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a><br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/5396ee05ly1ho0pyw4vjlj20zk0k0aa6.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/PQVexIgOlx08dvlCz1rO01041200ab3h0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711171244&amp;ssig=ip8oyDMWYY&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/oh4vtfIdlx08dvlC6w0E010412004xkP0E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711171244&amp;ssig=vk6bhYPmTk&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/UgbXpOkOlx08dvlC5mZq010412002OPL0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1711171244&amp;ssig=df03%2FZd5YY&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5015034862960685" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 02:31:30 GMT</pubDate>
</item>
<item>
<title>【NLP入门指南：一文览尽自然语言处理的基本概念】《Natural Language Processing (NLP) [A Complete Guide]》 网页链接 #机器学习# #人工智能# [图片][图片][图...</title>
<link>https://weibo.com/1402400261/O6ilu3Wss</link>
<guid>https://weibo.com/1402400261/O6ilu3Wss</guid>
<content:encoded><![CDATA[
<div> NLP, 自然语言处理, 基本概念, 入门, 指南, 文章, 内容, 信息提取,语言模型

自然语言处理(NLP)是一门研究如何使用计算机处理和分析人类语言的领域。本文为初学者提供了NLP的基本概念和指南，包括语言模型、信息提取等内容。通过阅读本文，读者可以更好地了解NLP的基本原理和应用。NLP有着广泛的应用领域，如机器翻译、情感分析、文本分类等。通过学习NLP，我们可以更好地理解和处理人类语言，为人工智能技术的发展做出贡献。<br /><br />总结:自然语言处理(NLP)是一门涉及语言模型和信息提取等基本概念的领域。通过学习NLP，我们可以更好地理解和处理人类语言，为人工智能技术的发展做出贡献。 <div>
【NLP入门指南：一文览尽自然语言处理的基本概念】《Natural Language Processing (NLP) [A Complete Guide]》 <a href="https://www.deeplearning.ai/resources/natural-language-processing"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mg60avsj21900u0tdz.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0mgmjx1kj21h90u0jvn.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgnwo4kj21h90u0wjb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgplmy3j21h90u044t.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0mgrblhkj21h90u0432.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgt33llj21h90u0grj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgv1l7tj21h90u0wjj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0mgx8zdjj21h90u0q74.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0mgyxituj21h90u0aep.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 00:30:10 GMT</pubDate>
</item>
<item>
<title>【平凡中的非凡：AI 工具的日常应用启示录】- 作者分享了他使用 Claude 和 ChatGPT 完成临时任务的案例。 - 作者认为，这个案例最值得注意的地方在于它完全不值...</title>
<link>https://weibo.com/1402400261/O6iiUb6Xt</link>
<guid>https://weibo.com/1402400261/O6iiUb6Xt</guid>
<content:encoded><![CDATA[
<div> 平凡 非凡 AI 工具 日常应用 启示录 Claude ChatGPT 临时任务 成功 可靠 态度 信任

<br /><br />总结:
作者分享了使用Claude和ChatGPT完成临时任务的案例，并认为这种平凡的成功反映出AI工具的高度可靠性和应用价值。他对AI工具的信心和依赖启发我们思考其在日常工作中的作用，虽然轻描淡写，但背后透露出对AI工具的高度认可。文章提供了真实的使用场景，引发我们对AI工具在实践中的表现和影响的思考，让我们反思是否已经习以为常地依赖AI的能力。整体而言，文章独特的视角和真实的案例给了我们一些有价值的启示。 <div>
【平凡中的非凡：AI 工具的日常应用启示录】<br />- 作者分享了他使用 Claude 和 ChatGPT 完成临时任务的案例。  <br />- 作者认为，这个案例最值得注意的地方在于它完全不值得注意，他每天都能从这些工具中获得类似的结果。  <br />- 作者对这个案例的成功并不感到惊讶，相反，如果它没有成功，他可能会有点惊讶。  <br />- 作者提供了与 Claude 和 ChatGPT 对话的完整记录。 <br /> <br />点评：<br />- 作者的观点颇具反直觉性，他认为这个案例之所以值得关注，恰恰是因为它已经变得司空见惯，这种看似平凡的成功背后，反映出 AI 工具已经达到了一个新的高度。  <br />- 作者对 AI 工具的信心和依赖，启发我们思考这些工具在日常工作中的应用价值和可靠性，它们正在悄然改变我们的工作方式。  <br />- 尽管作者没有对案例进行详细分析，但他的分享本身就具有一定的价值，它提供了一个真实的使用场景，让我们看到了 AI 工具在实践中的表现。  <br />- 作者的态度虽然轻描淡写，但背后透露出一种对 AI 工具的高度认可和信任，这种态度值得我们反思：我们是否也已经对 AI 的能力习以为常了?  <br />- 这篇文章虽然篇幅不长，但作者独特的视角和真实的使用案例，给了我们一些有价值的启示，引发了我们对 AI 工具在日常应用中的角色和影响的思考。<br />《Claude and ChatGPT for ad-hoc sidequests》 <a href="https://simonwillison.net/2024/Mar/22/claude-and-chatgpt-case-study/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho0madax76j20u00v2gr5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 00:23:49 GMT</pubDate>
</item>
<item>
<title>【AI代替受试者：科技进步与风险防范的平衡之道】- 随着 GPT-4 等大型语言模型变得越来越复杂，一些研究人员逐渐接受人工智能可以在某些科学研究中取代人类参与...</title>
<link>https://weibo.com/1402400261/O6iaDzKnw</link>
<guid>https://weibo.com/1402400261/O6iaDzKnw</guid>
<content:encoded><![CDATA[
<div> 卡内基梅隆大学、大型语言模型、人工智能、研究、AI伦理、风险防范、科技进步、敏感话题、脆弱群体、科学研究。  

总结:  
卡内基梅隆大学的研究人员领导了一篇新的预印论文，综述了使用大型语言模型代替人类研究对象的想法，并引用了13项相关研究。一些提议认为AI生成的数据可以应用于研究敏感话题，避免将脆弱群体暴露在可能危险的实验中。然而，专家担心这种做法可能导致科研结果不严谨，而脆弱群体的脆弱性可能被AI放大。使用AI取代人类参与者在科研中具有争议性，一方面提高了效率，另一方面可能损害结果的有效性，需要谨慎思考。这一议题涉及技术、伦理、社会等多个维度，需要权衡利弊。文章揭示了一个富有争议但值得探讨的话题，为AI在科研中提供了新的视角。 <div>
【AI代替受试者：科技进步与风险防范的平衡之道】<br />- 随着 GPT-4 等大型语言模型变得越来越复杂，一些研究人员逐渐接受人工智能可以在某些科学研究中取代人类参与者的想法。  <br />- 一篇新的预印论文综述了十多项已发表的研究，这些研究测试或提议使用大型语言模型来代替人类研究对象或分析研究结果。  <br />- 该论文由卡内基梅隆大学研究 AI 伦理和计算机视觉的 William Agnew 领导，引用了 13 项相关研究。  <br />- 一些最近的提议认为，AI 生成的数据可能对研究自杀等敏感话题有用，理论上可以避免将脆弱群体暴露在可能引发自杀念头的实验中。  <br />- 但许多专家担心这种做法可能会产生科学上不严谨的结果，脆弱群体的脆弱性在许多方面放大了用 AI 响应研究他们经历的危险。  <br /><br />点评：  <br />- 使用 AI 取代人类参与者的想法颇具争议，一方面它可能提高研究效率，另一方面却可能损害结果的有效性，这种矛盾值得深思。  <br />- 论文提出 AI 生成数据可用于研究敏感话题，但同时也引发了伦理问题，需要谨慎对待。  <br />- 专家对 AI 取代人类参与者的担忧不无道理，它提醒我们在追求科技进步的同时，不能忽视潜在的风险和负面影响。  <br />- 这一议题涉及 AI 与人类在科研中的角色定位问题，需要从技术、伦理、社会等多个维度进行全面思考和权衡。  <br />- 这篇文章揭示了一个富有争议但又引人深思的话题，为 AI 在科研中的应用提供了新的视角，值得进一步探讨。<br />《Can AI Replace Human Research Participants? These Scientists See Risks | Scientific American》 <a href="https://www.scientificamerican.com/article/can-ai-replace-human-research-participants-these-scientists-see-risks/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0lp36kvqj20x10u0afb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 23 Mar 2024 00:03:27 GMT</pubDate>
</item>
<item>
<title>【免费书稿：可微编程基础】- 一本关于概率图模型的教材的部分章节，主要介绍了联合概率分布、似然函数、最大后验推断、边缘推断等基本概念。 - 在联合概率分布...</title>
<link>https://weibo.com/1402400261/O6i5FnWqP</link>
<guid>https://weibo.com/1402400261/O6i5FnWqP</guid>
<content:encoded><![CDATA[
<div> 联合概率分布 似然函数 最大后验推断 边缘推断 概率依赖关系 概率分布 模型参数 观测数据 推断算法 马尔可夫链  
<br />  
<br />  
总结:  
本篇文章介绍了概率图模型中的基本概念，包括联合概率分布、似然函数、最大后验推断和边缘推断。通过详细讨论随机变量之间的概率依赖关系和模型参数与观测数据之间的关系，帮助读者理解概率图模型的核心思想。文章还介绍了期望值、凸包、边缘多面体等数学概念，用于描述概率分布的性质和推断任务的复杂性。由于精确推断的计算复杂度很高，因此设计高效的近似推断算法变得必要。最后，文章开始介绍如何用图模型表示随机过程，为后续章节的讨论做了铺垫。 <div>
【免费书稿：可微编程基础】<br />- 一本关于概率图模型的教材的部分章节，主要介绍了联合概率分布、似然函数、最大后验推断、边缘推断等基本概念。  <br />- 在联合概率分布部分，详细讨论了随机变量之间的概率依赖关系，以及如何用概率分布来刻画这种关系。  <br />- 似然函数是概率图模型中的重要概念，它描述了模型参数与观测数据之间的关系，是许多推断算法的基础。  <br />- 最大后验推断和边缘推断是概率图模型中的两类重要推断任务，分别对应于寻找最可能的变量组合和计算变量的边缘概率分布。  <br />- 引入了期望值、凸包、边缘多面体等数学概念，用于刻画概率分布的性质和推断任务的复杂性。  <br />- 精确的推断通常具有很高的计算复杂度，因此需要设计高效的近似推断算法。  <br />- 在马尔可夫链部分，开始介绍如何用图模型来表示随机过程，为后续章节的讨论做铺垫。<br />《The Elements of Differentiable Programming》M Blondel, V Roulet [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.14606"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0lc8ag08j20u014cq5i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 23:51:12 GMT</pubDate>
</item>
<item>
<title>【博士论文：深度学习基础组成——一种范畴论方法】- 从范畴论的角度探讨了深度学习的基本组成部分，提出了一种新的理论框架。 - 引入"学习范畴"的概念，将深度...</title>
<link>https://weibo.com/1402400261/O6i3mhm0n</link>
<guid>https://weibo.com/1402400261/O6i3mhm0n</guid>
<content:encoded><![CDATA[
<div> 深度学习, 范畴论, 学习范畴, 监督学习, 无监督学习, 强化学习, 优化过程, 泛化能力, 跨学科, 学习算法

<br /><br />总结:
该博士论文从范畴论的角度探讨了深度学习的基础组成部分，引入了"学习范畴"的概念，将深度学习的组件抽象为范畴论中的对象和态射。论文分析了监督学习、无监督学习、强化学习在学习范畴中的表示，讨论了极限和余极限结构与优化过程、泛化能力的联系。还探讨了学习范畴与其他数学领域的关联，指出学习范畴理论有助于理解深度学习，并为设计新算法提供指导。展望了学习范畴论的未来发展方向，包括拓展到机器学习领域和与其他数学分支融合。 <div>
【博士论文：深度学习基础组成——一种范畴论方法】<br />- 从范畴论的角度探讨了深度学习的基本组成部分，提出了一种新的理论框架。  <br />- 引入"学习范畴"的概念，将深度学习中的各种组件(如数据、模型、损失函数等)抽象为范畴论中的对象和态射，揭示了它们之间的内在联系。  <br />- 文章系统地分析了监督学习、无监督学习、强化学习等不同学习范式在学习范畴中的表示，展现了该理论框架的普适性。  <br />- 重点讨论了学习范畴中的极限和余极限结构，并证明了它们与深度学习中的优化过程和泛化能力之间的紧密联系。  <br />- 探讨了学习范畴与其他数学领域(如测度论、概率论、拓扑学)之间的关联，展现了深度学习的跨学科特性。  <br />- 学习范畴理论有助于从更高的抽象层次理解深度学习，为设计新的学习算法和架构提供了理论指导。  <br />- 展望了学习范畴论的进一步发展方向，包括将其拓展到更广泛的机器学习领域，以及与其他数学分支的深度融合。  <br />《Fundamental Components of Deep Learning: A category-theoretic approach》B Gavranović [University of Strathclyde] (2024) <a href="https://arxiv.org/abs/2403.13001"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8ho0l6fztvlj20pg148wil.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 23:45:30 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发...</title>
<link>https://weibo.com/1402400261/O6hv9jfWp</link>
<guid>https://weibo.com/1402400261/O6hv9jfWp</guid>
<content:encoded><![CDATA[
<div> 携手, 送出, hello算法, 可可粉, 数据结构, 算法, 动画图解, 实战代码示例, 互动环节

总结:
《hello算法》是一本以全新视角呈现数据结构与算法的书籍，配有生动的动画图解，让读者轻松掌握。书中提供实战代码示例，让读者即学即用，巩固新知识。同时设计了互动环节帮助读者主动思考、提问和解决问题。截止2024.3.29 12:00，转发并评论可参与送出3本书的活动，可可粉尽快参与哦！ <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:21:14 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：明日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截...</title>
<link>https://weibo.com/1402400261/O6hv5AoXY</link>
<guid>https://weibo.com/1402400261/O6hv5AoXY</guid>
<content:encoded><![CDATA[
<div> 大语言模型、工程实践、全彩、系统性、实践性、代码、作者杨青、训练经验、干货

总结:<br /><br />明天将开奖，欢迎参与。一本名为《大语言模型：原理与工程实践(全彩)》的书籍正在进行赠书活动，截止日期为2024年3月24日12:00。这本书的特色在于揭开大语言模型的神秘面纱，透彻解读内在机理和应用实践，体现系统性和实践性，配有代码和全彩印刷。作者杨青是度小满轩辕大模型负责人，具备训练十亿、百亿、千亿等不同参数规模大语言模型的经验，在书中分享了丰富的干货和实践经验。快来参与转发评论，有机会获得这本经典书籍！ <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：明日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:21:06 GMT</pubDate>
</item>
<item>
<title>今日推介(第1353期)：AI发展与内存墙(Memory Wall)、语义解码新时代、少阳本类增量学习技巧包、跟个性化有害阈值的生成式语言模型聊天、模型编辑统一框架 公·众...</title>
<link>https://weibo.com/1402400261/O6huOyKvQ</link>
<guid>https://weibo.com/1402400261/O6huOyKvQ</guid>
<content:encoded><![CDATA[
<div> AI发展、内存墙、语义解码、增量学习、个性化阈值、生成式语言模型、聊天、模型编辑、统一框架
<br />
<br />
总结:本期推介介绍了AI发展与内存墙、语义解码新时代、少阳本类增量学习技巧包、具有个性化有害阈值的生成式语言模型聊天以及模型编辑统一框架。文章内容涵盖了AI技术的进步、语义解码的应用、增量学习的新思路、生成式语言模型的个性化应用和模型编辑的统一框架构建。通过这些介绍，读者可以了解最新的AI发展趋势和技术应用，以及相关的学习技巧和应用实例。整体而言，本期推介内容涵盖了AI技术领域的多个方面，是一次全面的了解和探讨。 <div>
今日推介(第1353期)：AI发展与内存墙(Memory Wall)、语义解码新时代、少阳本类增量学习技巧包、跟个性化有害阈值的生成式语言模型聊天、模型编辑统一框架 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/688568613"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0iplr89oj20go0cz0uc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8ho0ipo7zm1j20go0xxwje.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0ips1vckj20go09d3zg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0ipvcjofj20go0id0ul.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8ho0ipyioxqj20go093dgb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:20:24 GMT</pubDate>
</item>
<item>
<title>[CV] ReNoise: Real Image Inversion Through Iterative Noising 网页链接 ReNoise 通过迭代重加噪声精炼反演潜码估计的固定点迭代方法，实现高质量、高效率的扩...</title>
<link>https://weibo.com/1402400261/O6hrhuyvs</link>
<guid>https://weibo.com/1402400261/O6hrhuyvs</guid>
<content:encoded><![CDATA[
<div> 关键词: ReNoise, 迭代重加噪声, 反演潜码估计, 固定点迭代方法, 扩散模型, 高质量, 高效率

总结:<br /><br />本文介绍了一种名为ReNoise的方法，通过迭代重加噪声的方式来精炼反演潜码估计。这种固定点迭代方法可实现高质量、高效率的扩散模型图像反演。 ReNoise算法不仅简单高效，而且具有较高的反演准确率和图像质量, 在图像处理和反演领域具有潜在的广泛应用前景。 <div>
[CV] ReNoise: Real Image Inversion Through Iterative Noising  <br /><a href="https://arxiv.org/abs/2403.14602"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />ReNoise 通过迭代重加噪声精炼反演潜码估计的固定点迭代方法，实现高质量、高效率的扩散模型图像反演。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho0igw6raaj21281ag4me.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho0igw9rloj21120pon2c.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho0igwydikj21r00w0dt0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:11:43 GMT</pubDate>
</item>
<item>
<title>[CV] GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation 网页链接 GRM是首个将Transformer和像素对齐高斯集成的快速而...</title>
<link>https://weibo.com/1402400261/O6hp1kbP6</link>
<guid>https://weibo.com/1402400261/O6hp1kbP6</guid>
<content:encoded><![CDATA[
<div> 关键词: GRM, Transformer, 像素对齐, 高斯集成, 3D重建, 生成模型

总结:<br /><br />
本文介绍了一种名为GRM的大型高斯重建模型，它结合了Transformer和像素对齐高斯集成的技术，实现了快速而高质量的3D重建和生成。通过Transformer的应用，GRM能够更有效地处理大规模数据集，并在生成3D模型时保持像素级的精确性。该模型在实验中表现出色，展示了其在提高3D重建效率和质量方面的潜力。 <div>
[CV] GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation  <br /><a href="https://arxiv.org/abs/2403.14621"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />GRM是首个将Transformer和像素对齐高斯集成的快速而高质量的3D重建与生成模型。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0ib2baqfj20qk15y13b.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0ib2ywavj20ve15m12p.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1ho0ib3k77nj21fo0rmn6m.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 22:06:08 GMT</pubDate>
</item>
<item>
<title>[CL] Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity 网页链接 提出自适应检索增强生成框架，根据分...</title>
<link>https://weibo.com/1402400261/O6hlJDYfe</link>
<guid>https://weibo.com/1402400261/O6hlJDYfe</guid>
<content:encoded><![CDATA[
<div> 自适应检索增强生成框架、问题复杂度、无检索、单步检索、多步检索、开放域问答、效率、准确性

<br /><br />总结：
本文提出了一种自适应检索增强生成框架，根据分类器预测的问题复杂度，动态选择无检索、单步检索或多步检索策略，以提高开放域问答的整体效率与准确性。该框架能够根据问题的复杂程度，自动调整检索策略，从而更好地应对不同类型的问题。实验结果表明，该方法在提高问答性能方面取得了显著的效果，展现了很大的潜力。 <div>
[CL] Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity  <br /><a href="https://arxiv.org/abs/2403.14403"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出自适应检索增强生成框架，根据分类器预测的问题复杂度，动态选择无检索、单步检索或多步检索策略，从而提高开放域问答的整体效率与准确性。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0i2nscnnj20u819oar9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho0i2o66l3j21qi0m414v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 21:58:03 GMT</pubDate>
</item>
<item>
<title>[CL] A Taxonomy of Ambiguity Types for NLP 网页链接 提出一个包含11种英语歧义类型的分类法，旨在建立更细致的语言理解分析和评估框架，为探究NLP模型处理不...</title>
<link>https://weibo.com/1402400261/O6hd8aDOF</link>
<guid>https://weibo.com/1402400261/O6hd8aDOF</guid>
<content:encoded><![CDATA[
<div> 英语歧义类型、分类法、NLP模型、语言理解、分析、评估框架、支撑
<br />
本文提出了一个包含11种英语歧义类型的分类法，旨在建立更细致的语言理解分析和评估框架，为探究NLP模型处理不同歧义的能力提供支撑。这个分类法可以帮助研究人员更好地理解歧义现象，并为NLP模型的改进提供参考。通过对不同类型的歧义进行分类和区分，可以更有效地评估和比较不同NLP模型在处理歧义时的表现。总体而言，这一研究为NLP领域的发展提供了有益的思路和方法。 <br /><br />总结: <div>
[CL] A Taxonomy of Ambiguity Types for NLP  <br /><a href="https://arxiv.org/abs/2403.14072"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出一个包含11种英语歧义类型的分类法，旨在建立更细致的语言理解分析和评估框架，为探究NLP模型处理不同歧义的能力提供支撑。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1ho0hgmhy10j20w81ce7mv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1ho0hgmox1aj20ye1asduf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 21:36:51 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.22)》 爱可可微博热门分享(3.22) [图片]</title>
<link>https://weibo.com/1402400261/O6ehB0Xnb</link>
<guid>https://weibo.com/1402400261/O6ehB0Xnb</guid>
<content:encoded><![CDATA[
<div> 微博、热门、分享、爱可可、3.22、关键词、互联网、精彩内容、社交平台、用户关注

<br /><br />总结:
3月22日，爱可可微博热门分享了一些精彩内容，受到用户关注。在互联网时代，微博作为社交平台，分享热门话题和内容，吸引了大量用户参与讨论。用户们可以在微博上发现最新、最热门的资讯和娱乐，让人们更加便捷地获取信息和交流观点。在这个信息爆炸的时代，微博的热门分享成为人们获取资讯、交流看法的重要途径。 <div>
《爱可可微博热门分享(3.22)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405014848751927525"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.22)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1ho04j56rzuj20ir0ajjss.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 14:09:36 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《GRANDE: Gradient-Based Decision Tree Ensembles》(ICLR 2024) GitHub: github.com/s-marton/GRANDE 《Neural Markov Random Field for St...</title>
<link>https://weibo.com/1402400261/O6b5z0qtw</link>
<guid>https://weibo.com/1402400261/O6b5z0qtw</guid>
<content:encoded><![CDATA[
<div> 关键词: 决策树集成、梯度提升、神经网络、立体匹配、语音编辑、扩散模型、面部分析、3D图像处理、计算病理学、生成模型

总结:<br /><br />
本文介绍了多篇论文的实现代码，涵盖了各种领域的研究成果。首先介绍了《GRANDE: Gradient-Based Decision Tree Ensembles》和《Neural Markov Random Field for Stereo Matching》，这两篇论文探讨了决策树集成和神经网络在立体匹配中的应用。然后介绍了《VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild》，该论文提出了一种零样本语音编辑和文本转语音的方法。接着讲述了《Analyzing and Improving the Training Dynamics of Diffusion Models》和《FaceXFormer : A Unified Transformer for Facial Analysis》，这两篇论文分别研究了扩散模型的训练动态和面部分析中的统一Transformer模型。紧接着介绍了《MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images》和《HAC: Hash-grid Assisted Context for 3D Gaussian Splatting Compression》，这两篇论文讨论了3D图像处理中的高效Gaussian Splatting方法。继而阐述了《Towards a General-Purpose Foundation Model for Computational Pathology》和《Gaussian Splatting on the Move:Blur and Rolling Shutter Compensation for Natural Camera Motion》，这两篇论文分别探索了计算病理学的通用基础模型和图像处理中的模糊和快门补偿技术。最后提到了《BrightDreamer: Generic 3D Gaussian Generative Framework for Fast Text-to-3D Synthesis》和《All in a Single Image: Large Multimodal Models are In-Image Learners》，这两篇论文分别介绍了快速文本转3D合成和大型多模态模型在图像学习中的应用。此外还包括了《GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM》和《Generative Enhancement for 3D Medical Images》等内容，涉及了缓存压缩和医疗图像生成增强等核心技术。整体而言，这些研究呈现了当今前沿科技领域的最新进展，为各个领域的研究和实践提供了重要参考。
 <div>
几篇论文实现代码：<br />《GRANDE: Gradient-Based Decision Tree Ensembles》(ICLR 2024) GitHub: github.com/s-marton/GRANDE <br />《Neural Markov Random Field for Stereo Matching》(CVPR 2024) GitHub: github.com/aeolusguan/NMRF [fig1]<br />《VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild》(2024) GitHub: github.com/jasonppy/VoiceCraft<br />《Analyzing and Improving the Training Dynamics of Diffusion Models》(2024) GitHub: github.com/NVlabs/edm2<br />《FaceXFormer : A Unified Transformer for Facial Analysis》(2024) GitHub: github.com/Kartik-3004/facexformer [fig2]<br />《MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images》(2024) GitHub: github.com/donydchen/mvsplat<br />《HAC: Hash-grid Assisted Context for 3D Gaussian Splatting Compression》(2024) GitHub: github.com/YihangChen-ee/HAC [fig3]<br />《Towards a General-Purpose Foundation Model for Computational Pathology》(2024) GitHub: github.com/mahmoodlab/UNI<br />《Gaussian Splatting on the Move:<br />Blur and Rolling Shutter Compensation for Natural Camera Motion》(2024) GitHub: github.com/SpectacularAI/3dgs-deblur<br />《BrightDreamer: Generic 3D Gaussian Generative Framework for Fast Text-to-3D Synthesis》(2024) GitHub: github.com/lutao2021/BrightDreamer <br />《All in a Single Image: Large Multimodal Models are In-Image Learners》(2024) GitHub: github.com/AGI-Edgerunners/IIL [fig4]<br />《GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM》(2024) GitHub: github.com/opengear-project/GEAR<br />《Generative Enhancement for 3D Medical Images》(2024) GitHub: github.com/HKU-MedAI/GEM-3D [fig5]<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzodrsscuj24x81rbkjm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzp8kduwdj223x13yb2a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzpc961h0j22tg1lohdv.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzq288ah6j23lr1ofb29.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzqa6d9coj20ve0jumzy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 06:01:43 GMT</pubDate>
</item>
<item>
<title>【ReverserAI：通过使用本地大语言模型 (LLM)，自动推荐函数名称，帮用户进行软件逆向工程】'ReverserAI (v1.0.1) - Provides automated reverse engineering as...</title>
<link>https://weibo.com/1402400261/O6b5ub8q2</link>
<guid>https://weibo.com/1402400261/O6b5ub8q2</guid>
<content:encoded><![CDATA[
<div> ReverserAI, automated, reverse engineering, local large language models, LLM, software, assistance, consumer hardware, GitHub<br />
<br />
ReverserAI (v1.0.1)是一个提供自动反向工程辅助的工具，通过在消费者硬件上使用本地大语言模型（LLMs）。用户可以利用这个工具对软件进行反向工程。用户可以在GitHub上找到该工具的源代码。 <div>
【ReverserAI：通过使用本地大语言模型 (LLM)，自动推荐函数名称，帮用户进行软件逆向工程】'ReverserAI (v1.0.1) - Provides automated reverse engineering assistance through the use of local large language models (LLMs) on consumer hardware.' GitHub: github.com/mrphrazer/reverser_ai <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnzqfdk4l1j20uw0jsad4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzqffzmlfj21w10u0gpb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 06:01:32 GMT</pubDate>
</item>
<item>
<title>【SpatialData: 用于处理多模态空间 omics数据的开源框架】'SpatialData: an open and universal framework for processing spatial omics data. - An open and ...</title>
<link>https://weibo.com/1402400261/O6b49eEqP</link>
<guid>https://weibo.com/1402400261/O6b49eEqP</guid>
<content:encoded><![CDATA[
<div> 空间 omics数据、开源框架、SpatialData、多模态、GitHub、处理、数据、框架、信息。
<br /><br />总结:
SpatialData是一个开源框架，用于处理多模态空间 omics 数据。这个框架提供了一个通用的数据处理平台，可以处理不同类型的 omics 数据，并提供了交互性和可扩展性。用户可以通过GitHub访问这个框架，并利用它来处理他们的空间 omics 数据。通过SpatialData，用户可以更方便地对空间 omics 数据进行分析和处理，提高数据处理的效率和准确性。 <div>
【SpatialData: 用于处理多模态空间 omics数据的开源框架】'SpatialData: an open and universal framework for processing spatial omics data. - An open and interoperable data framework for spatial omics data' GitHub: github.com/scverse/spatialdata <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnzqc0o7z6j210j0u0ah6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:58:14 GMT</pubDate>
</item>
<item>
<title>【RWKV_Pytorch：用纯Pytorch原生实现的RWKV大语言模型的推理框架】'RWKV_Pytorch - This is an inference framework for the RWKV large language model implem...</title>
<link>https://weibo.com/1402400261/O6b2509HT</link>
<guid>https://weibo.com/1402400261/O6b2509HT</guid>
<content:encoded><![CDATA[
<div> PyTorch、RWKV、推理框架、大语言模型、原生实现、灵活、开源、GitHub、复杂、缺乏可扩展性

总结:<br /><br />
本文介绍了一个纯PyTorch原生实现的RWKV大语言模型推理框架，旨在解决官方原生实现过于复杂且缺乏可扩展性的问题。作者呼吁加入灵活的PyTorch生态系统，共同开源该项目。感兴趣的读者可在GitHub上找到相关代码。 <div>
【RWKV_Pytorch：用纯Pytorch原生实现的RWKV大语言模型的推理框架】'RWKV_Pytorch - This is an inference framework for the RWKV large language model implemented purely in native PyTorch. The official native implementation is overly complex and lacks extensibility. Let's join the flexible PyTorch ecosystem and open-source it together!' GitHub: github.com/yuunnn-w/RWKV_Pytorch <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzq6py8wdj21gb0u0af0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:53:08 GMT</pubDate>
</item>
<item>
<title>【面向无人驾驶的世界模型相关论文资源列表】’Awesome World Models for Autonomous Driving - Collect some World Models for Autonomous Driving papers.' Gi...</title>
<link>https://weibo.com/1402400261/O6aYMeAQs</link>
<guid>https://weibo.com/1402400261/O6aYMeAQs</guid>
<content:encoded><![CDATA[
<div> 无人驾驶、世界模型、论文、资源、GitHub、自动驾驶、数据集、模拟、模型训练、深度学习
<br />
无人驾驶技术的发展离不开对于世界模型的研究与应用。本文收集了一些与无人驾驶相关的世界模型论文资源，包括数据集、模拟环境、模型训练等方面的研究成果。这些论文和资源可以帮助研究人员更好地理解和优化自动驾驶系统，在深度学习和机器视觉等领域为无人驾驶的发展贡献力量。通过GitHub上的相关链接，研究人员可以方便地获取这些资源并开展进一步的研究与实验。 <div>
【面向无人驾驶的世界模型相关论文资源列表】’Awesome World Models for Autonomous Driving - Collect some World Models for Autonomous Driving papers.' GitHub: github.com/LMD0311/Awesome-World-Model <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnzpy8ywndj21790u0dmd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:45:00 GMT</pubDate>
</item>
<item>
<title>【Ludic：轻量Python框架，类似于 React，使用组件的方式构建 HTML 页面。它与 htmx.org框架集成在一起，无需编写大量 JavaScript，可以与 Starlette框架一起使...</title>
<link>https://weibo.com/1402400261/O6aPq4XB3</link>
<guid>https://weibo.com/1402400261/O6aPq4XB3</guid>
<content:encoded><![CDATA[
<div> Ludic, 轻量Python框架, React, 组件, HTML页面, htmx.org框架, 无需JavaScript, Starlette框架

Ludic是一个轻量级的Python框架，类似于React，使用组件的方式构建HTML页面。它与htmx.org框架集成在一起，可以实现无需编写大量JavaScript的HTML页面构建。同时，Ludic可以与Starlette框架一起使用，提供更加便捷的开发体验。通过Ludic，开发者可以快速搭建页面，并通过组件化的方式简化页面逻辑，使得开发工作更加高效和便捷。 <div>
【Ludic：轻量Python框架，类似于 React，使用组件的方式构建 HTML 页面。它与 htmx.org框架集成在一起，无需编写大量 JavaScript，可以与 Starlette框架一起使用】'Ludic - Lightweight framework for building HTML pages in pure Python.' GitHub: github.com/paveldedik/ludic <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Python%23"><span class="surl-text">#Python#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnzpa34n6hj21ew0u0grx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:21:57 GMT</pubDate>
</item>
<item>
<title>【Devika：基于开源的 AI 软件工程师，可以理解人类的高级指令，并根据这些指令，分解成步骤，进行相关信息的研究，并编写代码实现目标】'Devika - Agentic AI S...</title>
<link>https://weibo.com/1402400261/O6aOecw1v</link>
<guid>https://weibo.com/1402400261/O6aOecw1v</guid>
<content:encoded><![CDATA[
<div> 开源 AI 软件工程师 Devika; 高级指令 分解 研究 编写代码 实现目标 Devin Cognition AI 竞争对手<br />
<br />
总结: 
Devika是一名基于开源的 AI 软件工程师，能够理解人类的高级指令，并将其分解成步骤，进行相关信息的研究，并编写代码来实现给定的目标。Devika旨在成为Devin AI的一个竞争性开源替代品。 <div>
【Devika：基于开源的 AI 软件工程师，可以理解人类的高级指令，并根据这些指令，分解成步骤，进行相关信息的研究，并编写代码实现目标】'Devika - Agentic AI Software Engineer - Devika is an Agentic AI Software Engineer that can understand high-level human instructions, break them down into steps, research relevant information, and write code to achieve the given objective. Devika aims to be a competitive open-source alternative to Devin by Cognition AI.' GitHub: github.com/stitionai/devika <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzp769j5cj20un0u0n21.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:19:01 GMT</pubDate>
</item>
<item>
<title>【TorchTune：易于使用的 PyTorch 库，可轻松编写、微调和实验LLM模型。该库提供了多种功能，包括使用 native-PyTorch 实现的流行语言模型，支持各种格式的复原...</title>
<link>https://weibo.com/1402400261/O6aMsh6ew</link>
<guid>https://weibo.com/1402400261/O6aMsh6ew</guid>
<content:encoded><![CDATA[
<div> GitHub，TorchTune，PyTorch，LLM模型，语言模型，fine-tuning，训练工具，评估工具，HF格式，库

总结:<br /><br />
TorchTune是一个易于使用的PyTorch库，专为LLM模型的微调而设计。该库提供了多种功能，包括使用native-PyTorch实现的流行语言模型，支持各种格式的复原，以及提供训练和评估工具，例如HF格式的检查点支持。通过TorchTune，用户可以轻松编写、微调和实验各种LLM模型，为语言模型相关的任务提供了便利的工具和支持。GitHub链接：github.com/pytorch/torchtune <div>
【TorchTune：易于使用的 PyTorch 库，可轻松编写、微调和实验LLM模型。该库提供了多种功能，包括使用 native-PyTorch 实现的流行语言模型，支持各种格式的复原，以及提供训练和评估工具，例如 HF 格式的检查点支持】'TorchTune - A Native-PyTorch Library for LLM Fine-tuning' GitHub: github.com/pytorch/torchtune <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzp2l49hnj212u0u0dkv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 05:14:39 GMT</pubDate>
</item>
<item>
<title>【Pico MLX Server：Apple 的 MLX AI框架的轻松入门方式，提供了一个用于 MLX Server的GUI】’Pico MLX Server' GitHub: github.com/ronaldmannak/PicoMLXServer...</title>
<link>https://weibo.com/1402400261/O6aBRuVBB</link>
<guid>https://weibo.com/1402400261/O6aBRuVBB</guid>
<content:encoded><![CDATA[
<div> GitHub、Pico MLX Server、Apple、MLX AI框架、轻松入门、GUI

<br /><br />总结:
Pico MLX Server是一个供Apple的MLX AI框架使用的GUI工具，为用户提供了简单易用的入门方式。用户可以通过访问GitHub上的Pico MLX Server代码库来获取这一工具。 <div>
【Pico MLX Server：Apple 的 MLX AI框架的轻松入门方式，提供了一个用于 MLX Server的GUI】’Pico MLX Server' GitHub: github.com/ronaldmannak/PicoMLXServer <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzobeagodj21200fgq4i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 04:48:33 GMT</pubDate>
</item>
<item>
<title>【qlora-pipe：用于训练大语言模型的开源脚本，可以在四块4090 GPU上对LLM进行定制训练】'qlora-pipe - A pipeline parallel training script for LLMs.' GitHub...</title>
<link>https://weibo.com/1402400261/O6aAR2rFQ</link>
<guid>https://weibo.com/1402400261/O6aAR2rFQ</guid>
<content:encoded><![CDATA[
<div> 开源脚本、训练、大语言模型、LLM、四块4090 GPU、定制训练、pipeline parallel、GitHub

<br /><br />总结:
qlora-pipe是一个用于训练大语言模型的开源脚本，能够在四块4090 GPU上进行定制训练。它采用pipeline parallel技术，可以加快训练进程，提高效率。用户可以在GitHub上找到qlora-pipe的源代码和详细说明，方便使用和定制。使用qlora-pipe可以帮助研究人员和开发者更好地训练和优化LLMs，提高模型的性能和准确性。 <div>
【qlora-pipe：用于训练大语言模型的开源脚本，可以在四块4090 GPU上对LLM进行定制训练】'qlora-pipe - A pipeline parallel training script for LLMs.' GitHub: github.com/tdrussell/qlora-pipe <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnzo8tlkcnj20yt0u0afc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 04:46:04 GMT</pubDate>
</item>
<item>
<title>【AGI的定义之争：人工智能的终极目标还有多远？】- 人工通用智能(AGI)这一术语在当前有关人工智能的讨论中无处不在，但对其定义和内涵却存在诸多争议。 - 一些...</title>
<link>https://weibo.com/1402400261/O69gfhC5j</link>
<guid>https://weibo.com/1402400261/O69gfhC5j</guid>
<content:encoded><![CDATA[
<div> 人工通用智能、定义之争、智能多样性、人类中心主义、理想化假设、身体感知能力、智能与物质关系、全面审视、开放态度、谨慎思考

<br /><br />总结: 本文讨论了人工通用智能(AGI)的定义之争，指出AGI定义的多样性和争议性，挑战了人类中心主义的思维定式。智能有多种形式和维度，不应将人类智能作为唯一标准。即使是人类也无法在所有领域表现出色，对AGI的理想化假设需要谨慎思考。讨论了AGI是否需要具备类人的身体和感知能力，触及了智能与物质关系的深层思考。文章提出了全面审视AGI内涵的视角，呼吁以开放和谨慎的态度探讨人工通用智能的未来。 <div>
【AGI的定义之争：人工智能的终极目标还有多远？】<br />- 人工通用智能(AGI)这一术语在当前有关人工智能的讨论中无处不在，但对其定义和内涵却存在诸多争议。  <br />- 一些组织和个人将AGI定义为能够像人类一样进行推理和解决问题的系统，但这一定义过于狭隘，忽视了智能的多样性。  <br />- 智能有多种形式和维度，将人类智能作为唯一标准具有局限性。动物和昆虫也展现出了与人类不同但同样令人印象深刻的智能。  <br />- 关于AGI是否应该模仿人脑，以及是否需要具备类似人类的身体和感知能力，学界尚无定论，存在不同观点。  <br />- 一些研究者提出，真正的AGI系统应该能够在多个领域展现出色的性能，但这一观点也受到质疑，因为即使是人类也无法在所有领域都表现出色。  <br />- 对AGI的定义和评判标准的争议，反映出人工智能领域在探索通用智能这一终极目标时仍面临诸多挑战和不确定性。  <br />- 尽管对AGI的理解存在分歧，但各方普遍认为，实现AGI将是人工智能发展的重要里程碑，对人类社会产生深远影响。  <br /><br />点评：<br />- 本文对AGI的定义之争进行了深入剖析，揭示了这一概念在学界和业界的模糊性和争议性，引发读者反思对智能本质的理解。  <br />- 作者提出将人类智能作为AGI标准具有局限性的观点颇具启发性，打破了人类中心主义的思维定式，让我们以更开放的视角看待智能的多样性。  <br />- 文章指出，即使是人类也无法在所有领域都表现出色，这一论断具有一定的颠覆性，挑战了对AGI的一些理想化假设和期望。  <br />- 对AGI是否需要具备类人的身体和感知能力的讨论，触及了人工智能与生物智能的本质区别，引发了关于智能与物质载体关系的深层思考。  <br />- 文章虽未给出对AGI的明确定义，但通过梳理不同观点，为读者提供了一个全面审视AGI内涵的视角，启发我们以更谨慎和开放的态度看待这一概念。<br />《Debates on the nature of artificial general intelligence | Science》 <a href="https://www.science.org/doi/10.1126/science.ado7069"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnzid60gsij20vk0u0tf2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 01:22:32 GMT</pubDate>
</item>
<item>
<title>【SceneScript：语言模型赋能3D场景理解】- Meta Reality Labs 研究团队开发了一种名为 SceneScript 的新方法，用于重建 3D 场景并表示物理空间的布局。 - Scene...</title>
<link>https://weibo.com/1402400261/O68Jg0DkB</link>
<guid>https://weibo.com/1402400261/O68Jg0DkB</guid>
<content:encoded><![CDATA[
<div> Meta Reality Labs, SceneScript, 3D场景理解, 自然语言, 语言模型, 突破性进展, AR技术, 应用前景, 跨领域融合, 人机交互

<br /><br />总结:
Meta Reality Labs的研究团队开发了一种名为SceneScript的新方法，利用自回归结构化语言模型将3D场景表示为自然语言，突破了传统的场景表示方式。这一方法利用语言模型的强大能力学习场景的结构化表示，取得了突破性进展，展现了在场景理解任务中的潜力。SceneScript被认为是通向真正AR眼镜的重要里程碑，有望连接物理世界和数字世界，加速AR技术的发展。这种新颖的思路和跨领域融合的方法对于激发创新思路和推动人工智能技术的应用具有重要意义。这一研究在多个领域都有广阔的应用前景，有助于提升人机交互和空间理解的能力。SceneScript的出现为3D场景表示开辟了新的方向，有望缩小3D重建社区与自然语言处理领域之间的距离。 <div>
【SceneScript：语言模型赋能3D场景理解】<br />- Meta Reality Labs 研究团队开发了一种名为 SceneScript 的新方法，用于重建 3D 场景并表示物理空间的布局。  <br />- SceneScript 使用自回归结构化语言模型将 3D 场景表示为自然语言，这是一种全新的场景表示方式。  <br />- 该方法利用大型语言模型的强大能力，学习场景的结构化表示，并生成符合物理约束的场景描述。  <br />- SceneScript 在标准 3D 重建基准测试中取得了最先进的性能，展示了其在场景理解和生成方面的优势。  <br />- 这项研究为将 3D 场景表示为语言开辟了新的方向，有望缩小 3D 重建社区与自然语言处理领域的距离。  <br />- SceneScript 被视为通向真正 AR 眼镜的重要里程碑，有助于连接物理世界和数字世界。  <br />- 该技术有望应用于虚拟助手、机器人导航、内容创作等领域，提升人机交互和空间理解的能力。  <br /><br />点评：  <br />- 将 3D 场景表示为自然语言的思路非常新颖，打破了传统的场景表示方式，具有颠覆性和启发性。  <br />- 利用语言模型的强大能力来理解和生成场景，这种跨领域的融合思维值得借鉴，有助于激发更多创新思路。  <br />- SceneScript 在性能上取得了突破性进展，展现了语言模型在场景理解任务中的巨大潜力，值得期待。  <br />- 该研究对于推动 AR 技术的发展具有重要意义，有望加速实现真正的 AR 眼镜，改变人们与数字世界的交互方式。  <br />- SceneScript 在多个领域都有广阔的应用前景，这种通用性和拓展性值得肯定，有助于推动人工智能技术的普及和应用。<br />《Introducing SceneScript, a novel approach for 3D scene reconstruction》 <a href="https://ai.meta.com/blog/scenescript-3d-scene-reconstruction-reality-labs-research/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzg0j9nuaj21hc0u04qp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 22 Mar 2024 00:01:16 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@图灵文化 @图灵新知 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带...</title>
<link>https://weibo.com/1402400261/O68BEFK2R</link>
<guid>https://weibo.com/1402400261/O68BEFK2R</guid>
<content:encoded><![CDATA[
<div> 可可粉, 转发, 评论, 数据结构, 算法, 动画图解, 实战代码示例, 主动思考, 互动环节

<br /><br />总结:
本文介绍了一本名为《hello 算法》的数据结构与算法书籍，截止日期为2024年3月29日12:00。读者可以通过转发和评论参与送出3本书籍的活动。这本书的特点在于配有生动的动画图解，使抽象的数据结构和算法变得直观易懂。同时，书中提供实战代码示例，让读者能够即学即用，巩固新知识。互动环节的设计有助于读者主动思考、提问和解决问题，带领读者进入算法的世界，轻松掌握知识。 <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%87%E5%8C%96">@图灵文化</a> <a href="https://weibo.com/n/%E5%9B%BE%E7%81%B5%E6%96%B0%E7%9F%A5">@图灵新知</a> 送出3本《hello 算法》，截止2024.3.29 12:00，*可可粉*转发+评论即可参与。带你轻松掌握数据结构与算法，以全新的视角带你进入算法的世界。书中的每一章节都配有生动的动画图解，让抽象的数据结构和算法变得直观易懂。实战代码示例让你即学即用，及时巩固新知识。互动环节的设计帮助你主动思考，提问和解决问题。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5014630549948449"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfciddvdj21pe24a7wh.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfchthjaj20m80m8q6g.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzfcht5csj20m80m8go5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzfchtze3j20m80m8ach.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzfci9xvsj2494494e81.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzfcht5xoj20m80m8mzj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 23:42:33 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O68z3vsYr</link>
<guid>https://weibo.com/1402400261/O68z3vsYr</guid>
<content:encoded><![CDATA[
<div> 度小满、大语言模型、全彩、内在机理、实践性、代码、杨青、训练经验、干货、实践者

<br /><br />总结:
本书《大语言模型：原理与工程实践(全彩)》由度小满轩辕大模型负责人杨青撰写，旨在揭开大语言模型的神秘面纱，透彻解读其内在机理和应用实践。书中系统性的知识体系和对实践性的重视是其特色之一，配有代码，并全彩印刷。杨青作为真正的大语言模型实践者，在书中分享了十亿、百亿、千亿等不同参数规模大语言模型的训练经验，内容满载干货，实用性强，绝非空谈。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 23:36:09 GMT</pubDate>
</item>
<item>
<title>今日推介(第1352期)：用逆向训练减轻“逆转诅咒“、面向强化学习的视频原则性表示学习、通过多尺度特征学习改进小规模视觉模型性能、通过一次编码并行解码实现高...</title>
<link>https://weibo.com/1402400261/O6845wLPl</link>
<guid>https://weibo.com/1402400261/O6845wLPl</guid>
<content:encoded><![CDATA[
<div> 逆向训练、逆转诅咒、面向强化学习、视频原则性表示学习、多尺度特征学习、小规模视觉模型、高效Transformer解码、函数树、透明机器学习

总结:<br />
本篇文章介绍了几种方法来提升机器学习的效果。首先，通过逆向训练可以减轻"逆转诅咒"现象，进而改善模型性能。其次，面向强化学习的视频原则性表示学习方法能够提高模型的学习效率。同时，通过多尺度特征学习可以显著改善小规模视觉模型的性能。此外，一次编码并行解码方法能够高效实现Transformer解码过程。最后，利用函数树实现透明机器学习可以增强模型的可解释性，提高模型的可信度。这些方法为机器学习的进步提供了重要的思路和方法。 <div>
今日推介(第1352期)：用逆向训练减轻“逆转诅咒“、面向强化学习的视频原则性表示学习、通过多尺度特征学习改进小规模视觉模型性能、通过一次编码并行解码实现高效Transformer解码、用函数树实现透明机器学习 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/688367695"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.22)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnzd2qlg3dj20go08ltae.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnzd2sjjqjj20go07hgme.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnzd2uuxi5j20go09yjsk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnzd2xe44nj20go0h9764.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnzd31nv30j20go0kjglz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 22:19:50 GMT</pubDate>
</item>
<item>
<title>[CV] RadSplat: Radiance Field-Informed Gaussian Splatting for Robust Real-Time Rendering with 900+ FPS 网页链接 通过辐射场监督点云表示的优化和渲染，实...</title>
<link>https://weibo.com/1402400261/O680Jvcgj</link>
<guid>https://weibo.com/1402400261/O680Jvcgj</guid>
<content:encoded><![CDATA[
<div> 辐射场、点云表示、优化、渲染、复杂场景、实时、高质量、视图合成、RadSplat、900+ FPS  
<br />  
<br />总结:  
RadSplat通过辐射场监督点云表示的优化和渲染，实现了对复杂场景的实时高质量视图合成，达到了900+ FPS的渲染速度。该方法利用辐射场信息提高渲染质量，同时通过高效的点云表示实现实时渲染。这种方法能够在复杂场景下快速生成真实感强的视图，为实时渲染提供了一种稳健的方法。 <div>
[CV]  RadSplat: Radiance Field-Informed Gaussian Splatting for Robust Real-Time Rendering with 900+ FPS  <br /><a href="https://arxiv.org/abs/2403.13806"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过辐射场监督点云表示的优化和渲染，实现了对复杂场景的实时高质量视图合成。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzcuggq4wj20z01e67h4.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzcugojirj217q0se47h.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 22:11:35 GMT</pubDate>
</item>
<item>
<title>#### [LG] RewardBench: Evaluating Reward Models for Language Modeling 网页链接 提出语言模型奖励模型评估基准RewardBench，评估各类模型的优劣势，发现现有...</title>
<link>https://weibo.com/1402400261/O67YsjTA0</link>
<guid>https://weibo.com/1402400261/O67YsjTA0</guid>
<content:encoded><![CDATA[
<div> 评估基准，语言模型，奖励模型，优劣势，推理，遵循指令，不足

<br /><br />总结:
这篇论文提出了一种名为RewardBench的评估基准，用于评估语言模型的奖励模型。研究发现，现有模型在推理和遵循指令方面存在明显不足，因此需要更好的奖励模型来提高模型的性能。提出的基准为研究者提供了一种评估不同模型优劣势的方法，有助于推动语言建模领域的发展。 <div>
#### [LG]  RewardBench: Evaluating Reward Models for Language Modeling  <br /><a href="https://arxiv.org/abs/2403.13787"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出语言模型奖励模型评估基准RewardBench，评估各类模型的优劣势，发现现有模型在推理和遵循指令方面仍存在明显不足。 <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzcoivi7yj212q1ju187.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzcojhbknj21i40pa0xw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 22:05:58 GMT</pubDate>
</item>
<item>
<title>[CL] RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content 网页链接 本文提出了一个多方面框架RigorLLM，通过数据增强、安全...</title>
<link>https://weibo.com/1402400261/O67Ul8jZG</link>
<guid>https://weibo.com/1402400261/O67Ul8jZG</guid>
<content:encoded><![CDATA[
<div> 多方面框架; 数据增强; 安全后缀优化; 模型融合; 大语言模型; 有害内容检测; 鲁棒性

本文介绍了一个名为RigorLLM的多方面框架，通过数据增强、安全后缀优化和模型融合等方法，提高了大语言模型对有害内容的检测能力和鲁棒性。通过优化输入和输出，让大语言模型更好地应对不良内容，提高了其应用的安全性和可靠性。该框架的综合应用，为大语言模型的发展和应用提供了重要的保障。 <div>
[CL] RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content  <br /><a href="https://arxiv.org/abs/2403.13031"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>      <br />本文提出了一个多方面框架RigorLLM，通过数据增强、安全后缀优化和模型融合，实现了对大语言模型的输入输出进行有害内容检测的强大鲁棒性。 <img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzce172qbj21861jk7pd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzce1bwjrj212k0mqafc.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzce21dc8j21hq0vyqfp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzce2poqfj21i00rqaip.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 21:55:50 GMT</pubDate>
</item>
<item>
<title>[LG] Evolutionary Optimization of Model Merging Recipes 网页链接 提出进化模型融合方法,在参数和数据流空间通过进化算法自动发现模型的最优组合,实现跨域模...</title>
<link>https://weibo.com/1402400261/O67Rq1hAm</link>
<guid>https://weibo.com/1402400261/O67Rq1hAm</guid>
<content:encoded><![CDATA[
<div> 进化算法, 模型融合, 跨域模型, 参数空间, 数据流空间, 自动发现, 最优组合, 性能强劲, 新模型

Evolutionary Optimization of Model Merging Recipes 提出了一种进化模型融合方法，该方法在参数和数据流空间中运用进化算法来自动发现模型的最优组合，实现了跨域模型的高效融合，生成具有强劲性能的新模型。该研究为模型优化提供了一种全新的途径，有望在实际应用中帮助优化模型性能并节省人力成本。<br /><br />总结: 进化算法应用于模型融合，自动发现最优组合，生成强劲性能新模型，有望在实践中带来积极效果。 <div>
[LG] Evolutionary Optimization of Model Merging Recipes  <br /><a href="https://arxiv.org/abs/2403.13187"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />提出进化模型融合方法,在参数和数据流空间通过进化算法自动发现模型的最优组合,实现跨域模型的高效融合,生成性能强劲的新模型。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzc6kjjllj212w1k8dzq.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzc6ksku0j21ag0woakt.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzc6l8ez8j21a20fk79e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 21:48:38 GMT</pubDate>
</item>
<item>
<title>[LG] Evaluating Frontier Models for Dangerous Capabilities 网页链接 论文系统地评估了多种领域的AI危险能力,为未来的科学评估和风险管控奠定基础。 [图片][...</title>
<link>https://weibo.com/1402400261/O67NpDkRT</link>
<guid>https://weibo.com/1402400261/O67NpDkRT</guid>
<content:encoded><![CDATA[
<div> AI、危险能力、科学评估、风险管控、前沿模型

<br /><br />总结:
本论文针对多领域的AI危险能力进行系统评估，为未来科学评估和风险管控提供了基础。研究围绕前沿模型展开，重点关注发展中的危险能力，并提出评估框架和方法。通过深入研究和实证分析，得出了对不同领域和模型的危险潜在能力的结论。文章强调对AI危险能力的全面评估和风险控制的重要性，为相关领域的研究提供了有益的参考和指导。 <div>
[LG] Evaluating Frontier Models for Dangerous Capabilities  <br /><a href="https://arxiv.org/abs/2403.13793"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>    <br />论文系统地评估了多种领域的AI危险能力,为未来的科学评估和风险管控奠定基础。 <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbw9zov9j214k1ku1dp.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzbwactj4j219i188as8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzbwansd4j218y0f0ac7.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzbwbb8x8j219m0mate3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 21:38:46 GMT</pubDate>
</item>
<item>
<title>函数树方法通过树结构化的单变量函数表示，实现了对复杂多变量函数的透明可解释建模。 - 转发 @爱可可-爱生活:&amp;ensp;[LG]《Function Trees: Transparent Machine...</title>
<link>https://weibo.com/1402400261/O67KlbKQP</link>
<guid>https://weibo.com/1402400261/O67KlbKQP</guid>
<content:encoded><![CDATA[
<div> 函数树方法、树结构、单变量函数、复杂多变量函数、透明、可解释、建模、机器学习、J H. Friedman、Stanford University

总结:<br /><br />这篇文章介绍了函数树方法，通过树结构化的单变量函数表示复杂多变量函数，实现了对其的透明、可解释建模。该方法由斯坦福大学的J H. Friedman提出，有助于理解和解释机器学习模型的工作原理。函数树方法将复杂问题分解为简单的单变量函数，并利用树结构将它们组合起来，使模型更易于理解和解释。这种方法不仅提高了模型的可解释性，还为深入研究机器学习算法提供了新的思路。通过函数树方法，用户可以更直观地理解模型的预测过程，从而更好地应用和改进机器学习技术。 <div>
函数树方法通过树结构化的单变量函数表示，实现了对复杂多变量函数的透明可解释建模。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Function Trees: Transparent Machine Learning》J H. Friedman [Stanford University] (2024) <a href="https://arxiv.org/abs/2403.13141"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnzbg4jbeqj21n80luaju.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbg4ua3jj20qo0wu0ty.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbg503xpj20r40yidix.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbg56ac0j21pw1ai786.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbo2grz1j20v80osq4e.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzbo2hx1xj20yr138whe.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnzbo2h4m2j20wl13kjsb.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnzbo2hhc4j20x50q0die.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnzbo2h2q0j20va0nydgr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 21:31:12 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.21)》 爱可可微博热门分享(3.21) [图片]</title>
<link>https://weibo.com/1402400261/O657woCn0</link>
<guid>https://weibo.com/1402400261/O657woCn0</guid>
<content:encoded><![CDATA[
<div> 微博，热门，分享，爱可可，3.21

总结：<br /><br />爱可可微博3.21日分享了热门内容，引起众多网友关注。微博内容包括各种有趣、新鲜的信息，受到大家的热烈回应。网友们纷纷转发评论，展开讨论。这些分享丰富了用户的微博阅读体验，也增加了用户之间的互动。愿爱可可微博在未来能继续给大家带来更多精彩内容，引领网民们探索更广阔的世界。 <div>
《爱可可微博热门分享(3.21)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405014496543375877"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.21)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnz02s4zrkj20rs0fmad0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 14:50:04 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《AnySkill: Learning Open-Vocabulary Physical Skill for Interactive Agents》(CVPR 2024) GitHub: github.com/jiemingcui/anyskill《Tack...</title>
<link>https://weibo.com/1402400261/O64X3gfOe</link>
<guid>https://weibo.com/1402400261/O64X3gfOe</guid>
<content:encoded><![CDATA[
<div> 关键词: Open-Vocabulary Skill, Physical Skill Learning, Interactive Agents, Diffusion Models, Singularities, Time Intervals, Dance Camera Movement, Scene Reconstruction, Multi-View Generation, Model Merging Recipes

总结: <br /><br />《AnySkill: Learning Open-Vocabulary Physical Skill for Interactive Agents》介绍了一种学习开放词汇物理技能的方法，可以应用于交互式代理系统。<br />《Tackling the Singularities at the Endpoints of Time Intervals in Diffusion Models》解决了扩散模型中时间间隔端点的奇异性问题。<br />《DanceCamera3D: 3D Camera Movement Synthesis with Music and Dance》展示了一种能够结合音乐和舞蹈进行3D摄像机移动合成的方法。<br />《SuperPrimitive: Scene Reconstruction at a Primitive Level》介绍了在基本级别上进行场景重建的技术。<br />《VideoMV: Consistent Multi-View Generation Based on Large Video Generative Model》展示了基于大型视频生成模型的一致性多视图生成方法。<br />《Evolutionary Optimization of Model Merging Recipes》探讨了模型合并配方的进化优化方法。<br />《When Do We Not Need Larger Vision Models?》讨论了何时不需要更大的视觉模型。<br />《RewardBench: Evaluating Reward Models》介绍了评估奖励模型的方法。<br />《Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models》展示了通过混合门控线性递归和局部注意力提高语言模型效率的方法。<br />《How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments》评估了大语言模型在多智能体环境中的游戏能力。<br />《GAPS: Geometry-Aware, Physics-Based, Self-Supervised Neural Garment Draping》介绍了几何感知、基于物理的、自监督神经服装披挂技术。<br />《Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive》解决了偏好优化失败模式的问题。<br />《UrbanGPT: Spatio-Temporal Large Language Models》展示了时空大型语言模型UrbanGPT。<br />《RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation》介绍了通过鲁棒适应实现准确参数高效微调的RoSA方法。 <div>
几篇论文实现代码：<br />《AnySkill: Learning Open-Vocabulary Physical Skill for Interactive Agents》(CVPR 2024) GitHub: github.com/jiemingcui/anyskill<br />《Tackling the Singularities at the Endpoints of Time Intervals in Diffusion Models》(CVPR 2024) GitHub: github.com/PangzeCheung/SingDiffusion [fig2]<br />《DanceCamera3D: 3D Camera Movement Synthesis with Music and Dance》(CVPR 2024) GitHub: github.com/Carmenw1203/DanceCamera3D-Official<br />《SuperPrimitive: Scene Reconstruction at a Primitive Level》(CVPR 2024) GitHub: github.com/makezur/super_primitive<br />《VideoMV: Consistent Multi-View Generation Based on Large Video Generative Model》(2024) GitHub: github.com/alibaba/VideoMV [fig1]<br />《Evolutionary Optimization of Model Merging Recipes》(2024) GitHub: github.com/SakanaAI/evolutionary-model-merge<br />《When Do We Not Need Larger Vision Models?》(2024) GitHub: github.com/bfshi/scaling_on_scales<br />《RewardBench: Evaluating Reward Models》(2024) GitHub: github.com/allenai/reward-bench<br /> 《Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models》(2024) GitHub: github.com/kyegomez/Griffin<br />《How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments》(2024) GitHub: github.com/CUHK-ARISE/GAMABench<br />《GAPS: Geometry-Aware, Physics-Based, Self-Supervised Neural Garment Draping》(2024) GitHub: github.com/Simonhfls/GAPS<br />《Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive》(2024) GitHub: github.com/abacusai/smaug<br />《UrbanGPT: Spatio-Temporal Large Language Models》(2024) GitHub: github.com/HKUDS/UrbanGPT [fig3]<br />《RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation》(2024) GitHub: github.com/IST-DASLab/RoSA<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnyzbcmxhij22jj14qhdt.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnyzbpmsauj20ub0mo4qp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnyzc565i6j21k40j71kx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 14:24:16 GMT</pubDate>
</item>
<item>
<title>'FaceSearchSDK_Android - On Device Android Face 1:N and M:N Search With Liveness Detection &amp; Anti Spoofing SDK / 离线版Android 1:N 和M:N人脸检索，包含...</title>
<link>https://weibo.com/1402400261/O61EowFIA</link>
<guid>https://weibo.com/1402400261/O61EowFIA</guid>
<content:encoded><![CDATA[
<div> Android, FaceSearchSDK, 人脸检索, 活体检测, 反作弊, 离线版, SDK, GitHub, AnyLifeZLB

总结:
该'FaceSearchSDK_Android'是一个面向Android设备的SDK，提供了离线1:N和M:N人脸检索功能，同时包含活体检测和反作弊功能。开发者可以在GitHub上找到该SDK的资源。该SDK的功能可以帮助用户在Android设备上进行人脸识别和搜索，并具备活体检测和反作弊功能，提高了安全性和准确性。 <div>
'FaceSearchSDK_Android - On Device Android Face 1:N and M:N Search With Liveness Detection &amp; Anti Spoofing SDK / 离线版Android 1:N 和M:N人脸检索，包含活体检测反作弊 .' GitHub: github.com/AnyLifeZLB/FaceSearchSDK_Android <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnykrm7iyyj21gb0u0449.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 06:00:04 GMT</pubDate>
</item>
<item>
<title>【OpenDMD：基于分布匹配蒸馏的一步扩散的开源实现和模型】'OpenDMD - Open source implementation and models of One-step Diffusion with Distribution Matchi...</title>
<link>https://weibo.com/1402400261/O61DBbZDs</link>
<guid>https://weibo.com/1402400261/O61DBbZDs</guid>
<content:encoded><![CDATA[
<div> OpenDMD, 分布匹配蒸馏, 一步扩散, 开源实现, 模型, GitHub, Zeqiang-Lai, 分布匹配<br />
<br />
模型名称为OpenDMD，是一种基于分布匹配蒸馏的一步扩散模型，通过分布匹配来提高模型性能。本文提供了OpenDMD的开源实现和模型，项目可在GitHub上找到，作者是Zeqiang-Lai。OpenDMD的核心思想是利用分布匹配蒸馏技术来优化一步扩散模型，提高其性能和效率。通过实现和应用OpenDMD模型，可以更好地理解和研究一步扩散算法，为相关领域的研究和应用提供帮助。<br /><br />总结: <br />OpenDMD是基于分布匹配蒸馏的一步扩散模型的开源实现，通过优化分布匹配来提高模型性能。该模型在GitHub上可获得，作者为Zeqiang-Lai，有助于理解和研究一步扩散算法。 <div>
【OpenDMD：基于分布匹配蒸馏的一步扩散的开源实现和模型】'OpenDMD - Open source implementation and models of One-step Diffusion with Distribution Matching Distillation' GitHub: github.com/Zeqiang-Lai/OpenDMD <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnykpkmfgoj21ji0sctfu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:58:06 GMT</pubDate>
</item>
<item>
<title>【用于用户建模的大型语言模型(LLM-UM)相关论文列表】’Large Language Models for User Modeling (LLM-UM) Reading List - A list of large language models fo...</title>
<link>https://weibo.com/1402400261/O61CxpYtG</link>
<guid>https://weibo.com/1402400261/O61CxpYtG</guid>
<content:encoded><![CDATA[
<div> 大型语言模型、用户建模、GitHub、研究论文、列表、阅读、LLM-UM、用户模型、技术、领域<br />
<br />
在GitHub上可以找到一个关于大型语言模型用于用户建模的研究论文列表。这个列表收集了有关LLM-UM领域的各种论文，涉及到用户模型和相关技术的研究成果。这个资源可以帮助研究人员更好地了解这个领域的最新进展和趋势，有助于推动大型语言模型在用户建模中的应用和发展。<br /><br />总结: <div>
【用于用户建模的大型语言模型(LLM-UM)相关论文列表】’Large Language Models for User Modeling (LLM-UM) Reading List - A list of large language models for user modeling (LLM-UM) papers.' GitHub: github.com/TamSiuhin/LLM-UM-Reading <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnykmt35gpj20vi0u0te3.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnykmu3u3fj21fy0u0tjf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnykmvc0vtj21ji0u0tjf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:55:30 GMT</pubDate>
</item>
<item>
<title>【CoML：可以帮助数据科学和机器学习开发人员的开源项目，基于大型语言模型提供交互式自然语言编程接口，方便数据分析和机器学习任务】'CoML - Interactive codi...</title>
<link>https://weibo.com/1402400261/O61BmBLQw</link>
<guid>https://weibo.com/1402400261/O61BmBLQw</guid>
<content:encoded><![CDATA[
<div> CoML, 数据科学, 机器学习, 开源项目, 自然语言编程接口, 数据分析, 交互式, 大型语言模型, 开发人员, GitHub

<br /><br />总结:
CoML是一个开源项目，为数据科学家和机器学习开发人员提供交互式自然语言编程接口，借助大型语言模型的强大功能，方便他们进行数据分析和机器学习任务。该项目在GitHub上开源，为开发人员提供了强大的工具和支持。 <div>
【CoML：可以帮助数据科学和机器学习开发人员的开源项目，基于大型语言模型提供交互式自然语言编程接口，方便数据分析和机器学习任务】'CoML - Interactive coding assistant for data scientists and machine learning developers, empowered by large language models.' GitHub: github.com/microsoft/CoML <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnykjv10ptj21ji0o0q76.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:52:36 GMT</pubDate>
</item>
<item>
<title>【GAMA-Bench：多Agent环境下LLM博弈能力的性能测试基准】’GAMA-Bench - Benchmarking LLMs' Gaming Ability in Multi-Agent Environments' GitHub: github.com...</title>
<link>https://weibo.com/1402400261/O61z7renB</link>
<guid>https://weibo.com/1402400261/O61z7renB</guid>
<content:encoded><![CDATA[
<div> 多Agent环境、LLM博弈能力、性能测试、基准、GitHub、CUHK-ARISE、GAMABench

<br /><br />总结:
GAMA-Bench是一个用于测试LLM在多Agent环境下博弈能力的性能基准。该基准通过GitHub上的开源代码实现，由CUHK-ARISE团队开发。它可以帮助研究人员评估不同LLM算法在复杂多Agent环境中的性能，并进行性能比较和改进。通过GAMA-Bench，可以更好地理解和优化LLM算法在实际应用场景中的表现。 <div>
【GAMA-Bench：多Agent环境下LLM博弈能力的性能测试基准】’GAMA-Bench - Benchmarking LLMs' Gaming Ability in Multi-Agent Environments' GitHub: github.com/CUHK-ARISE/GAMABench <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnykdmp8jkj21g90u045r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:47:03 GMT</pubDate>
</item>
<item>
<title>【LLaMA Nuts and Bolts：旨在通过代码和文档了解 LLaMA 和其组件运行背后的原理的开源项目】'LLaMA Nuts and Bolts - A holistic way of understanding how LLa...</title>
<link>https://weibo.com/1402400261/O61xXbnCf</link>
<guid>https://weibo.com/1402400261/O61xXbnCf</guid>
<content:encoded><![CDATA[
<div> LLaMA, 组件, 代码, 文档, 原理, 运行, 开源项目, 详细, 理解, 实践<br />
<br />
LLaMA Nuts and Bolts 是一个旨在通过代码和详细文档全面了解LLaMA及其组件在实践中运行原理的开源项目。用户可以通过该项目深入理解LLaMA的工作机制，包括各个组件的运行方式和相互关联。通过查看代码和文档，用户可以更加深入地了解LLaMA项目的逻辑和实际应用。通过这个项目，用户可以掌握LLaMA的核心思想和技术细节，进而更好地使用和优化LLaMA系统。 <div>
【LLaMA Nuts and Bolts：旨在通过代码和文档了解 LLaMA 和其组件运行背后的原理的开源项目】'LLaMA Nuts and Bolts - A holistic way of understanding how LLaMA and its components run in practice, with code and detailed documentation.' GitHub: github.com/adalkiran/llama-nuts-and-bolts <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnykawu52cj20xk0u0jwh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:44:12 GMT</pubDate>
</item>
<item>
<title>【Lightning Thunder：开源 PyTorch 代码编译器，可以使 PyTorch 程序更快，无论是单个加速器还是分布式环境】'Lightning Thunder - Source to source compiler ...</title>
<link>https://weibo.com/1402400261/O61wG8Lpb</link>
<guid>https://weibo.com/1402400261/O61wG8Lpb</guid>
<content:encoded><![CDATA[
<div> PyTorch, 开源, 编译器, 程序, 加速器, 分布式环境, Lightning Thunder, PyTorch 程序, faster, GitHub

总结:<br /><br />文章介绍了 Lightning Thunder，一个开源的 PyTorch 代码编译器，能够使 PyTorch 程序在单个加速器和分布式环境中运行更快。该工具可以优化 PyTorch 程序的性能，提高执行效率，有助于提升程序的运行速度。对于使用 PyTorch 进行开发的用户来说，Lightning Thunder 是一个很有价值的工具，可以帮助他们提升程序的性能和效率，并提供更好的用户体验。感兴趣的开发者可以在 GitHub 上找到 Lightning Thunder 的源代码和详细信息。 <div>
【Lightning Thunder：开源 PyTorch 代码编译器，可以使 PyTorch 程序更快，无论是单个加速器还是分布式环境】'Lightning Thunder - Source to source compiler for PyTorch. It makes PyTorch programs faster on single accelerators and distributed.' GitHub: github.com/Lightning-AI/lightning-thunder <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnyk7u6d9gj216t0u0gpw.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:41:03 GMT</pubDate>
</item>
<item>
<title>【大语言模型与工具使用相关论文资源列表】’Awesome LMs with Tools' GitHub: github.com/zorazrw/awesome-tool-llm #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O61ud4TmF</link>
<guid>https://weibo.com/1402400261/O61ud4TmF</guid>
<content:encoded><![CDATA[
<div> 大语言模型、工具使用、GitHub、资源列表、论文、LM、工具、使用、相关、Awesome<br />
<br />
提供了一个名为'Awesome LMs with Tools'的GitHub资源列表，包含了大语言模型与工具使用相关的论文。这个资源列表汇总了一些优秀的工具和语言模型，并为研究人员和开发者提供了丰富的参考资料。可以帮助人们更好地了解大语言模型的发展和应用，为相关研究和实践提供支持。通过这个GitHub项目，用户可以方便地获得最新的研究成果和工具推荐，促进学术交流和技术应用的发展。<br /><br /> 
总结:提供了一个包含大量论文资源的GitHub项目，方便研究人员和开发者获取最新的工具和语言模型推荐，促进大语言模型与工具使用相关研究的发展。 <div>
【大语言模型与工具使用相关论文资源列表】’Awesome LMs with Tools' GitHub: github.com/zorazrw/awesome-tool-llm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnyk1hgkfcj21550u0dkt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:34:58 GMT</pubDate>
</item>
<item>
<title>【GritQL 是一个描述式查询语言，可以用于搜索和修改代码，支持多种编程语言】'GritQL is a query language for searching, linting, and modifying code.' GitH...</title>
<link>https://weibo.com/1402400261/O61rC2jl3</link>
<guid>https://weibo.com/1402400261/O61rC2jl3</guid>
<content:encoded><![CDATA[
<div> GritQL, 查询语言, 搜索, 代码, 修改, 多种编程语言, GitHub, getgrit, gritql <br />
<br />
要点一: GritQL是一个用于搜索、审查和修改代码的查询语言。<br />
要点二: 它支持多种编程语言。<br />
要点三: GritQL在GitHub上有开源代码，并且可以访问github.com/getgrit/gritql。 <br /> <div>
【GritQL 是一个描述式查询语言，可以用于搜索和修改代码，支持多种编程语言】'GritQL is a query language for searching, linting, and modifying code.' GitHub: github.com/getgrit/gritql <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%BC%96%E7%A8%8B%23&amp;isnewpage=1"><span class="surl-text">#编程#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnyju2vf6kj21a90u043i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:28:34 GMT</pubDate>
</item>
<item>
<title>【李世乭“人机大战”8年后的反思和感悟】- 本文是世界围棋冠军李世乭(Lee Sedol)在 AlphaGo 战胜他 8 年后的一些反思和感悟。 - 李世乭回顾了 2016 年与 AlphaG...</title>
<link>https://weibo.com/1402400261/O5Zrf9g14</link>
<guid>https://weibo.com/1402400261/O5Zrf9g14</guid>
<content:encoded><![CDATA[
<div> 李世乭, AlphaGo, 人工智能, 围棋, 人机协作, AI 技术, 伦理, 安全性, 人类参与, 发展<br />
<br />
总结:<br />
李世乭回顾了与AlphaGo的历史性对决，被其出色表现震撼，改变了对人工智能的看法，认为人机协作是未来的发展趋势。他指出AI的发展需要人类参与和引导，呼吁保持理性和谨慎，并重视AI的伦理和安全性。他对AI技术持开放态度，强调人机合作能够充分发挥AI的价值，造福人类。 <div>
【李世乭“人机大战”8年后的反思和感悟】<br />- 本文是世界围棋冠军李世乭(Lee Sedol)在 AlphaGo 战胜他 8 年后的一些反思和感悟。  <br />- 李世乭回顾了 2016 年与 AlphaGo 的那场历史性对决，当时他对人工智能在围棋领域的能力持怀疑态度。但经过五番棋后，他被 AlphaGo 的出色表现所震惊。  <br />- 这场对决不仅改变了李世乭对人工智能的看法，也让全世界看到了 AI 在复杂决策领域的无限潜力。  <br />- 李世乭认为，AlphaGo 的诞生标志着人工智能时代的到来，它将深刻影响人类的生活和工作方式。  <br />- 尽管 AlphaGo 在围棋上战胜了人类，但李世乭并不认为人工智能会完全取代人类，相反，人机协作将成为未来的发展趋势。  <br />- 李世乭呼吁人们拥抱 AI 技术，但同时也要保持理性和谨慎，注重 AI 的伦理和安全性，确保其为人类社会带来利益而非危害。  <br />- 他认为，人工智能的发展需要人类的参与和引导，只有人机合作，才能充分发挥 AI 的价值，造福人类。  <br /><br />点评：<br />- 李世乭作为人工智能时代的见证者和参与者，他的反思和观点具有独特的洞见和权威性。  <br />- 他对人机协作的展望，体现了一种积极拥抱新技术的开放心态，而非对 AI 的盲目恐惧或排斥。  <br />- 他强调 AI 发展需要人类的参与和引导，这一观点具有前瞻性，有助于促进人工智能的健康发展。  <br />- 他对 AI 伦理和安全性的重视，反映出对这一新兴技术的理性思考和审慎态度，值得肯定。  <br />- 李世乭的观点富有洞见，既展现了对人工智能的热情，也蕴含了对其潜在风险的警示，是一种平衡和中庸之道。<br />《8 years later: A world Go champion’s reflections on AlphaGo》 <a href="https://blog.google/around-the-globe/google-asia/8-years-later-a-world-go-champions-reflections-on-alphago/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span> <span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnyb01j2yaj20qu0i077f.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 00:22:10 GMT</pubDate>
</item>
<item>
<title>【OpenAI的GPT商店充斥大量违规内容】 - OpenAI 推出的 GPT 商店(GPT Store)旨在让开发者构建基于 OpenAI 生成式 AI 模型的定制聊天机器人，用于完成各种任务。 ...</title>
<link>https://weibo.com/1402400261/O5ZpaE0pX</link>
<guid>https://weibo.com/1402400261/O5ZpaE0pX</guid>
<content:encoded><![CDATA[
<div> 开AI、GPT商店、违规内容、审核、管理、挑战、安全、监管、AI创新、人们担忧<br /><br />总结:
OpenAI推出的GPT商店遭遇大量违规内容，包括侵犯版权的机器人和不当内容。管理和审核不足暴露了OpenAI的问题，需要加强内容审核和监管措施。AI系统面临伦理和安全挑战，需要制定严格准则。OpenAI需清理违规内容，确保商店健康发展。此事件引发人们对AI系统的担忧，平衡创新与秩序成为难题。 <div>
【OpenAI的GPT商店充斥大量违规内容】  <br />- OpenAI 推出的 GPT 商店(GPT Store)旨在让开发者构建基于 OpenAI 生成式 AI 模型的定制聊天机器人，用于完成各种任务。  <br />- 然而，该商店目前被大量奇怪的、可能侵犯版权的 GPT 机器人所淹没，这些机器人宣称能够生成迪士尼和漫威等知名 IP 的艺术作品。  <br />- 这些 GPT 机器人实际上只是将用户引导至第三方付费服务，并自称能够绕过 AI 内容检测工具。  <br />- 这一现象暴露了 OpenAI 在审核和管理 GPT 商店内容方面的不足，存在着较为宽松的监管。  <br />- 一些 GPT 机器人还声称能够生成令人反感或不当的内容，如仇恨言论、暴力内容等，这进一步加剧了对 OpenAI 内容审核的质疑。  <br /><br />点评：  <br />- OpenAI 在推出 GPT 商店时，可能低估了管理和审核内容的难度，导致了目前的混乱局面。  <br />- 过于宽松的审核政策，不仅可能助长版权侵权行为，还有引导 AI 系统产生有害内容的风险。  <br />- 这一事件再次凸显了 AI 系统在伦理和安全方面的挑战，需要制定更加严格的准则和监管措施。  <br />- 尽管 GPT 商店的初衷是推动 AI 创新，但如果缺乏有效管控，反而可能适得其反，损害 OpenAI 的声誉和公众对 AI 的信任。  <br />- OpenAI 需要及时采取行动，加强内容审核，清理违规内容，并制定更加透明和负责任的管理机制，以确保 GPT 商店的健康发展。  <br />- 这一事件也引发了人们对 AI 系统的担忧，如何在促进创新与维护秩序之间寻求平衡，是一个亟待解决的难题。<br />《OpenAI’s chatbot store is filling up with spam | TechCrunch》 <a href="https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnyau3kilwj20z60u0ti0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 00:17:04 GMT</pubDate>
</item>
<item>
<title>【AnimateDiff-Lightning：超快的文生视频实现】《AnimateDiff-Lightning - Lightning-fast text-to-video generation - a Hugging Face Space by ByteDance》 ...</title>
<link>https://weibo.com/1402400261/O5ZlXunOm</link>
<guid>https://weibo.com/1402400261/O5ZlXunOm</guid>
<content:encoded><![CDATA[
<div> 超快、文本生成、视频、实现、Hugging Face、ByteDance、AnimateDiff-Lightning、Lightning-fast、生成、实现

<br /><br />总结:
ByteDance推出了一款名为AnimateDiff-Lightning的工具，能够实现超快的文本生成视频。这个工具利用了Hugging Face的技术，并由ByteDance开发。用户可以通过输入文本来生成相应的视频内容，极大地提高了文本到视频的生成速度。AnimateDiff-Lightning可以帮助用户快速创建个性化的视频内容，为文本生成领域带来了新的可能性。 <div>
【AnimateDiff-Lightning：超快的文生视频实现】《AnimateDiff-Lightning - Lightning-fast text-to-video generation - a Hugging Face Space by ByteDance》 <a href="https://huggingface.co/spaces/ByteDance/AnimateDiff-Lightning"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <a href="https://video.weibo.com/show?fid=1034:5014274796617730"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可-爱生活的微博视频</span></a> <br clear="both" /><div style="clear: both;"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/5396ee05ly1hnyamdymnpj20ks0k0t8y.jpg" style="width: 100%;"><source src="https://f.video.weibocdn.com/o0/FQbKlqxElx08ds03YsbK010412001I340E010.mp4?label=mp4_720p&amp;template=748x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1710983937&amp;ssig=BPGTmcJN26&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/ckileuT4lx08ds03WHbG010412000VAs0E010.mp4?label=mp4_hd&amp;template=496x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1710983937&amp;ssig=4CBR22jtlO&amp;KID=unistore,video" /><source src="https://f.video.weibocdn.com/o0/lsaLbCSXlx08ds03WtoQ010412000DV10E010.mp4?label=mp4_ld&amp;template=372x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1710983937&amp;ssig=VoFISDuZqH&amp;KID=unistore,video" /><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5014274796617730" rel="noopener noreferrer" target="_blank">微博视频</a>观看。</p></video>
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 00:09:09 GMT</pubDate>
</item>
<item>
<title>【用GaLore在消费级硬件上训练大模型】 - GaLore 是一种新的参数高效微调(Parameter Efficient Finetuning， PEFT)方法，可以在消费级GPU(如 RTX 3090)上高效训...</title>
<link>https://weibo.com/1402400261/O5ZkH1crh</link>
<guid>https://weibo.com/1402400261/O5ZkH1crh</guid>
<content:encoded><![CDATA[
<div> GaLore, 参数高效微调, 消费级硬件, 训练, 大模型, 语言模型, 低秩, 稀疏, 性能, 内存, 计算资源 

<br /><br />总结:
GaLore 是一种新的参数高效微调方法，可以在消费级硬件上训练大型语言模型，采用了低秩和稀疏的参数分解方式，显著降低了内存和计算资源消耗。与其他方法相比表现出较高性能，使得在消费级GPU上训练包含70亿参数的语言模型成为可能，仅需较少优化器状态和梯度所需内存。GaLore不仅适用于自然语言处理领域，也具有广泛的应用前景，有望促进大型模型的民主化。其提出的新颖思路和性能突出，有望改变大型模型训练的范式，但还需面临一些挑战，如泛化性能和训练稳定性，并需要关注能源消耗、隐私和安全性等问题。GaLore的出现值得关注，体现了对问题的深入思考和创新。 <div>
【用GaLore在消费级硬件上训练大模型】 <br />- GaLore 是一种新的参数高效微调(Parameter Efficient Finetuning， PEFT)方法，可以在消费级GPU(如 RTX 3090)上高效训练大型语言模型。  <br />- 与其他PEFT方法(如LoRA、Prefix-Tuning等)相比，GaLore在保持性能的同时，显著降低了所需的内存和计算资源。<br />- GaLore 的关键创新在于引入了一种新的参数分解方式，将模型参数分解为低秩和稀疏两部分，从而大幅减少需要微调的参数数量。<br />- GaLore使得在消费级GPU如RTX 4090上训练包含多达70亿参数的语言模型成为可能，这是通过显著减少优化器状态和梯度所需的内存实现的。   <br />- 在 GPT-2 等基准测试中，GaLore 展现出与完整模型微调相当的性能，但仅需 1/10 的内存和计算资源。  <br />- GaLore 不仅适用于自然语言处理任务，对于计算机视觉等其他领域也具有广阔的应用前景。  <br />- 该技术有望推动大型模型的民主化，使更多个人研究者和小型机构能够在普通硬件上训练和部署这些模型。<br /><br />点评： <br />- GaLore 的提出打破了人们对大型模型训练必须依赖昂贵硬件的传统观念，这一反常规的创新值得关注。  <br />- 将模型参数分解为低秩和稀疏两部分的思路具有很高的创新性和独创性，体现了作者对问题的深入思考。  <br />- 如果 GaLore 的性能优势得到进一步验证，它有望彻底改变大型模型训练的范式，推动 AI 民主化进程。  <br />- 尽管取得了突破性进展，但 GaLore 在实际应用中可能还面临一些挑战，如泛化性能、训练稳定性等，需要持续优化和改进。  <br />- 该技术的出现也引发了一些值得深思的问题，比如大型模型的能源消耗、隐私和安全性等，需要引起足够重视。<br />《GaLore: Advancing Large Model Training on Consumer-grade Hardware》 <a href="https://huggingface.co/blog/galore"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnyaj8wnlkj20vg0u0dkt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 00:06:02 GMT</pubDate>
</item>
<item>
<title>【泛洪预警的"AI力量"：跨界协作,开放创新】 - 洪水是最常见的自然灾害，每年全球造成约500亿美元经济损失。气候变化导致洪水灾害频率上升。约15亿人面临洪水风...</title>
<link>https://weibo.com/1402400261/O5Zh7dYN0</link>
<guid>https://weibo.com/1402400261/O5Zh7dYN0</guid>
<content:encoded><![CDATA[
<div> 洪水预警、AI技术、Google、全球预报系统、机器学习、数据训练、合作伙伴、开放创新、挑战、实际应用

总结:<br /><br />本文介绍了Google利用人工智能技术提高洪水预警系统的全球规模预报能力。通过机器学习技术，Google建立了实时全球洪水预报系统，提前5天扩大了预报时间窗口，尤其在非洲和亚洲地区取得了较好的预报质量。模型训练数据包括公开天气数据和流域数据，利用LSTM模型表现优异。Google的模型比当前最佳全球预报系统提前5天就可达到其发布当天的准确度，尤其在极端洪水预报方面具有明显优势。未来，Google将继续拓展覆盖范围，加入更多洪水类型，与合作伙伴共同提升洪水预报质量，为社区提供更加可靠的洪水抗灾能力。该研究充分体现了人工智能技术在解决现实世界问题中的潜力，并积极倡导开放数据和开放科学合作精神，值得在其他领域进行进一步探索和推广。虽然取得了令人鼓舞的成果，但在实际应用中仍需持续关注和改进，如模型可解释性、偏差问题等挑战。 <div>
【泛洪预警的"AI力量"：跨界协作,开放创新】   <br />- 洪水是最常见的自然灾害，每年全球造成约500亿美元经济损失。气候变化导致洪水灾害频率上升。约15亿人面临洪水风险。提高预警系统准确性和及时性，每年可挽救成千上万条生命。   <br />- Google自2017年开始洪水预报研究，通过多年努力，建立了实时全球洪水预报系统，为搜索、地图、手机通知等提供预警。但要实现全球规模预报，特别是数据匮乏地区，需要更多技术突破。   <br />- Google最新Nature论文采用机器学习技术，相比当前最佳全球预报系统，平均将预报提前时间从0天扩大到5天，使非洲和亚洲地区预报质量与欧洲接近。该成果可为上亿人提供提前7天的河流预警。   <br />- 机器学习模型训练数据包括公开天气数据、流域数据等。一个模型训练全球5680个流域站点数据，可扩展到无监测数据流域。LSTM模型表现优异。   <br />- Google模型相比当前最佳全球预报系统GloFAS，提前5天就可达到GloFAS发布当天准确度，尤其在较大规模极端洪水预报方面优势明显。   <br />- 未来工作将继续拓展覆盖范围，加入更多洪水类型，与合作伙伴进一步提升预报质量，为社区提供洪水抗灾能力。<br /><br />点评： <br />- 该研究体现了人工智能在解决现实世界问题方面的巨大潜力，尤其是那些传统方法难以应对的挑战。  <br />- 利用机器学习模型克服数据匮乏的限制，是一种行之有效的创新方法，值得在其他领域进一步探索和推广。  <br />- 开放数据和开放科学精神，是推动该项目取得进展的关键因素之一，这种合作共赢的模式值得借鉴。  <br />- 该研究不仅关注技术创新本身，还重视与各界合作伙伴的协同，以最大程度发挥技术的社会影响力，这种全局观是可喜的。  <br />- 虽然取得了令人鼓舞的成果，但在实际应用中仍可能面临诸多挑战，如模型的可解释性、偏差问题、与现有系统的整合等，需要持续关注和改进。<br />《Using AI to expand global access to reliable flood forecasts – Google Research Blog》 <a href="https://blog.research.google/2024/03/using-ai-to-expand-global-access-to.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnya9urb60j20t70lwq60.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnya9w336lj20qo0f0q3q.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnya9xmpo2j20qo0dc0tv.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnya9zwf1xj213d0j5tb4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnyaa19x1yj21rj0u0gp8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 23:57:13 GMT</pubDate>
</item>
<item>
<title>【Common Corpus 让 AI 更透明】- Hugging Face发布了Common Corpus，这是迄今为训练大规模语言模型(LLM)发布的最大公共领域数据集。 - Common Corpus包含来自各...</title>
<link>https://weibo.com/1402400261/O5Zfw6TaS</link>
<guid>https://weibo.com/1402400261/O5Zfw6TaS</guid>
<content:encoded><![CDATA[
<div> 公开获取、透明度、可解释性、多主题、多语种、偏见、算力资源、模型权重、隐私、安全性
<br />
<br />
总结: Hugging Face发布了迄今为训练大规模语言模型(LLM)发布的最大公共领域数据集Common Corpus，包含来自各种文化遗产计划的500亿字，多语种且是包括1800亿英语词汇在内迄今为止最大的数据集。这一举措有望扭转AI过于集中于少数科技巨头的现状，促进AI民主化进程。公开数据有助于提高AI系统的透明度和可解释性，避免偏见和片面性。然而，实现AI民主化仍需更多努力，如算力资源的开放、模型权重的共享。同时，需注意隐私和安全性问题，平衡开放与管控之间的关系。Common Corpus为AI开放、多样和大众化提供了重要支持。 <div>
【Common Corpus 让 AI 更透明】<br />- Hugging Face发布了Common Corpus，这是迄今为训练大规模语言模型(LLM)发布的最大公共领域数据集。   <br />- Common Corpus包含来自各种文化遗产计划的500亿字。   <br />- Common Corpus是多语言的，是英语、法语、荷兰语、西班牙语、德语和意大利语等语种规模最大的语料库。   <br />- Common Corpus表明，可以在没有版权顾虑的来源上训练完全开放的LLM。   <br />- Common Corpus包含1800亿英语词汇，是迄今为止最大的英语数据集。还包括法语、德语、西班牙语、荷兰语和意大利语等语言的最大开放数据集。   <br />- Common Corpus不仅是开放的，而且质量更高、更多样化，比通常用于预训练的网页存档数据集更理想。   <br />- 这只是工作的开始，未来还会继续丰富这个集合，以支持AI的开放可复现的研究，也使AI更加开放、多样和大众化。<br /><br />点评： <br />- Common Corpus 的发布是 AI 民主化进程中的一个重要里程碑，有望扭转目前 AI 发展过于集中于少数科技巨头的现状。  <br />- 公开获取训练数据，有助于提高 AI 系统的透明度和可解释性，这是构建可信赖 AI 的关键一步。  <br />- 数据集的多语种和多主题特性，有利于培养更加通用和包容的 AI 模型，避免偏见和片面性。  <br />- 尽管取得了可喜进展，但要真正实现 AI 民主化仍需要更多的努力，包括算力资源的开放、模型权重的共享等。  <br />- 开放数据和模型的同时，也需要注重隐私和安全性，防止滥用。如何在开放与管控之间寻求平衡，是一个值得深入探讨的课题。<br />《Releasing Common Corpus: the largest public domain dataset for training LLMs》 <a href="https://huggingface.co/blog/Pclanglais/common-corpus"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnya5zh93gj20xq0u0gps.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 23:53:17 GMT</pubDate>
</item>
<item>
<title>[good] - 转发 @张俊林say:&amp;ensp;这里以通俗易懂的方式来分析Sora的可能做法，包括它的整体结构以及关键组件。我希望即使您不太懂技术，也能大致看明白Sora的可...</title>
<link>https://weibo.com/1402400261/O5ZdD4U3Z</link>
<guid>https://weibo.com/1402400261/O5ZdD4U3Z</guid>
<content:encoded><![CDATA[
<div> Sora, 分析, 结构, 关键组件, 图解, 技术, 理解, 机制, 复杂, 易懂

<br /><br />
Sora 的可能做法通过通俗易懂的方式进行分析，主要包括了其整体结构和关键组件，作者通过几十张图解来帮助读者更好地理解。即使不懂技术的读者也能大致了解 Sora 的可能做法，作者保证如果读者对某部分不理解，那是作者的责任。整篇文章分析清晰，内容包括 Sora 的结构、关键组件、机制等，通过图解的方式使整个过程看似复杂的机制变得更加直观易懂。文章引人入胜，对于想要了解 Sora 的读者极具帮助和启发。

<br /><br />
总结: 
1. Sora 的可能做法通过图解分析，便于理解。
2. 内容涵盖整体结构、关键组件、机制等要点。
3. 作者承诺保证即使对技术不熟悉的读者也能明白。
4. 文章引人入胜，对读者提供了有益的启发。 <div>
<span class="url-icon"><img alt="[good]" src="https://h5.sinaimg.cn/m/emoticon/icon/others/h_good-0c51afc69c.png" style="width: 1em; height: 1em;" /></span><br /><blockquote> - 转发 <a href="https://weibo.com/1064649941" target="_blank">@张俊林say</a>: 这里以通俗易懂的方式来分析Sora的可能做法，包括它的整体结构以及关键组件。我希望即使您不太懂技术，也能大致看明白Sora的可能做法，所以画了几十张图来让看似复杂的机制更好理解，如果您看完对某部分仍不理解，那是我的问题。<br /><a href="https://zhuanlan.zhihu.com/p/687928845"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">技术神秘化的去魅：Sora关键技术逆向工程图解</span></a> <img src="https://tvax3.sinaimg.cn/large/3f7544d5ly1hnx6es8uc5j223o16wnj5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/3f7544d5ly1hnx6f6gt4ij22761801kx.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/3f7544d5ly1hnx6fgpk12j225c16kx01.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/3f7544d5ly1hnx6fsmhuvj21zm184kjl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/3f7544d5ly1hnx6gclielj227g16k7wh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/3f7544d5ly1hnx6gpi2tcj224u18w4qp.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 23:48:38 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O5Zd1EKiB</link>
<guid>https://weibo.com/1402400261/O5Zd1EKiB</guid>
<content:encoded><![CDATA[
<div> 大语言模型，全彩，内在机理，应用实践，系统性，实践性，杨青，度小满，经验，训练。<br />
<br />
总结：本书《大语言模型：原理与工程实践(全彩)》由度小满轩辕大模型负责人杨青编写，揭开大语言模型的神秘面纱，重点解读其内在机理和应用实践。书中系统性强，涵盖了多种不同参数规模的大语言模型训练经验，充满干货且内容实用，具有较高的参考价值。截止日期为2024年3月24日中午12点，*可可粉*转发+评论即可参与赢取3本书。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 23:47:09 GMT</pubDate>
</item>
<item>
<title>今日推介(第1351期)：用语言纠正即时提高机器人性能、基于图表的推理、基于大型语言模型的大规模文本挖掘、端到端视频条件策略学习与交叉注意力Transformer、非...</title>
<link>https://weibo.com/1402400261/O5YETn8cu</link>
<guid>https://weibo.com/1402400261/O5YETn8cu</guid>
<content:encoded><![CDATA[
<div> 机器人性能、图表推理、大规模文本挖掘、视频条件策略学习、交叉注意力Transformer、非负性对比学习

总结:<br />
本文介绍了几篇关于机器学习领域的研究论文，涉及到用语言纠正即时提高机器人性能、基于图表的推理、基于大型语言模型的大规模文本挖掘、端到端视频条件策略学习与交叉注意力Transformer以及非负性对比学习等技术。这些研究为机器学习领域的发展探索了新的可能性，对于提升机器智能的水平具有重要意义。通过不断地探索和实践，可以使机器学习技术得到更好的应用和发展，进一步推动人工智能领域的进步。 <div>
今日推介(第1351期)：用语言纠正即时提高机器人性能、基于图表的推理、基于大型语言模型的大规模文本挖掘、端到端视频条件策略学习与交叉注意力Transformer、非负性对比学习  公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/688164480"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.21)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hny7jruc6kj20go06x0to.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hny7ju4scbj20go0gldh3.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hny7jwsfcxj20go0cb75r.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hny7k0dyhlj20go07ewfh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hny7k2yzxoj20go06kmxo.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 22:23:03 GMT</pubDate>
</item>
<item>
<title>[CV] HUGS: Holistic Urban 3D Scene Understanding via Gaussian Splatting 网页链接 介绍了一种新的HUGS管道，用于实现城市3D场景的整体理解，仅依靠RGB图像。...</title>
<link>https://weibo.com/1402400261/O5YBl0oTU</link>
<guid>https://weibo.com/1402400261/O5YBl0oTU</guid>
<content:encoded><![CDATA[
<div> 关键词: HUGS, 3D场景理解, 高斯Splatting, 动态对象定位, 物理约束, 实时渲染, 2D和3D语义信息, KITTI数据集, 3D边界框, 姿态优化

总结:<br /><br />本研究介绍了一种名为HUGS的新管道，利用高斯Splatting技术实现城市3D场景的整体理解，仅依靠RGB图像。该方法结合静态和动态3D高斯模型，优化几何结构、外观、语义及运动，特别是能有效处理动态对象定位噪声。关键创新在于利用物理约束规则化移动对象的姿态，减少跟踪噪声影响，提高性能。HUGS支持实时渲染新视角，并准确提取2D和3D语义信息。实验证实了该方法在KITTI、KITTI-360和Virtual KITTI 2数据集上的有效性，填补了现有方法在动态城市场景理解中的不足，如需人工标注的3D边界框和实时渲染挑战。 <div>
[CV] HUGS: Holistic Urban 3D Scene Understanding via Gaussian Splatting  <br /><a href="https://arxiv.org/abs/2403.12722"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种新的HUGS管道，用于实现城市3D场景的整体理解，仅依靠RGB图像。HUGS通过3D高斯Splatting技术，结合静态和动态3D高斯模型，优化几何结构、外观、语义及运动，特别是在动态对象定位噪声较大的情况下也能有效工作。该方法的关键创新在于利用物理约束规则化移动对象的姿态，减少跟踪噪声的影响，从而提高性能。此外，HUGS支持实时渲染新视角，并准确提取2D和3D语义信息。在KITTI、KITTI-360和Virtual KITTI 2数据集上的实验表明了该方法的有效性。该研究填补了现有方法在动态城市场景理解中的不足，如需大量人工标注的3D边界框和实时渲染的挑战。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hny7ay8od7j21a61ictvw.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hny7ayu74pj21oi0rwn7v.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 22:14:17 GMT</pubDate>
</item>
<item>
<title>[LG] Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices 网页链接 全面探讨了大型语言模型(LLM)在安全性和隐私方面的各种挑...</title>
<link>https://weibo.com/1402400261/O5YyJCGSc</link>
<guid>https://weibo.com/1402400261/O5YyJCGSc</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、安全性、隐私、风险、攻击、脆弱性、红队测试、水印、AI文本检测、风险管理

总结:<br />
本文全面探讨了大型语言模型（LLMs）在安全性和隐私方面面临的挑战，指出了信息泄露、记忆化和安全缺陷等风险。文章分析了模型本身、训练时和推理时的攻击脆弱性，提出了红队测试、模型编辑、水印和AI文本检测等策略来减轻风险。尽管已有策略存在局限，但建议未来研究应该更全面、跨学科地考虑LLMs的安全性和风险管理，以促进其负责任和道德的使用。 <div>
[LG] Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices  <br /><a href="https://arxiv.org/abs/2403.12503"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />全面探讨了大型语言模型(LLM)在安全性和隐私方面的各种挑战。LLM虽在自然语言处理领域取得革命性进展，但同时也带来了信息泄露、记忆化和安全缺陷等风险。本文研究分析了模型本身、训练时和推理时的攻击脆弱性，并讨论了红队测试、模型编辑、水印和AI文本检测等减轻风险的策略。尽管已有策略存在局限，文章建议未来研究应更全面、跨学科地考虑LLMs的安全性和风险管理，以促进其负责任和道德的使用。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hny74a6qjcj213o1je4ig.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hny74aqwdcj211818m47v.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hny74b8vp5j219y0wwqbh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 22:07:53 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.20)》 爱可可微博热门分享(3.20) [图片]</title>
<link>https://weibo.com/1402400261/O5VrIvUz3</link>
<guid>https://weibo.com/1402400261/O5VrIvUz3</guid>
<content:encoded><![CDATA[
<div> 微博，爱可可，热门，分享，热点，3.20，关注，话题，讨论，社交

《爱可可微博热门分享(3.20)》报道了当日在微博上热门的话题和讨论内容。用户们热烈关注并分享了各种热点话题，展开了讨论和交流。这些热门话题引发了社交媒体上的热议，显示出用户对各种议题的关注和兴趣。大家纷纷在微博上发表看法，分享观点，形成了热门内容和吸引了众多关注。总的来说，这些讨论内容和话题在社交媒体上引起了广泛的关注和讨论。 <br /><br />总结: <div>
《爱可可微博热门分享(3.20)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405014124667994223"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.20)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnxtddcnroj20rf0ffmyp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 14:12:21 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments》(ICLR 2024) GitHub: github.co...</title>
<link>https://weibo.com/1402400261/O5VqD8Dwz</link>
<guid>https://weibo.com/1402400261/O5VqD8Dwz</guid>
<content:encoded><![CDATA[
<div> 关键词：图像分割、神经网络、模型、变化检测、数据集、生成环境、模型修剪、视觉-语言模型、卷积神经网络、迁移学习

总结：<br />
这篇综述了几篇最新的论文以及他们在GitHub上的代码实现，涉及到图像分割、神经网络、模型稳定性、变化检测、数据集处理、生成环境、模型修剪、视觉-语言模型等多个领域。通过这些论文和代码的介绍，读者可以了解到最新的研究进展和方法，以及如何应用这些方法解决实际问题。同时，这些研究也展示了人工智能领域的多样性和个性化，为未来的研究和应用提供了思路和启发。 <br /><br />总结: <div>
几篇论文实现代码：<br />《Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments》(ICLR 2024) GitHub: github.com/YangYangGirl/BoS<br />《Diversified and Personalized Multi-rater Medical Image Segmentation》(CVPR 2024) GitHub: github.com/ycwu1997/D-Persona<br />《Arc2Face: A Foundation Model of Human Faces》(2024) GitHub: github.com/foivospar/Arc2Face [fig1]<br />《LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images》(2024) GitHub: github.com/thunlp/LLaVA-UHD [fig2]<br />《Generic 3D Diffusion Adapter Using Controlled Multi-View Editing》(2024) GitHub: github.com/Lakonik/MVEdit<br />《POCO: Pose and Shape Estimation with Confidence》(2024) GitHub: github.com/saidwivedi/POCO<br />《A Change Detection Reality Check》(2024) GitHub: github.com/isaaccorley/a-change-detection-reality-check<br />《Unified Training of Universal Time Series Forecasting Transformers》(2024) GitHub: github.com/SalesforceAIResearch/uni2ts<br />《The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning》(2024) GitHub: github.com/centerforaisafety/wmdp [fig3]<br />《Do Membership Inference Attacks Work on Large Language Models?》(2024) GitHub: github.com/iamgroot42/mimir<br />《RSBuilding: Towards General Remote Sensing Image Building Extraction and Change Detection with Foundation Model》(2024) GitHub: github.com/Meize0729/RSBuilding [fig4]<br />《InstructAny2Pix: Flexible Visual Editing via Multimodal Instruction Following》(2024) GitHub: github.com/jacklishufan/InstructAny2Pix<br />《Distilling Datasets Into Less Than One Image》(2024) GitHub: github.com/AsafShul/PoDD<br />《Chain-of-Spot: Interactive Reasoning Improves Large Vision-Language Models》(2024) GitHub: github.com/dongyh20/Chain-of-Spot<br />《RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback》(2024) GitHub: github.com/OceannTwT/ra-isf [fig5]<br />《EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents》(2024) GitHub: github.com/aszala/EnvGen [fig6]<br />《Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes》(2024) GitHub: github.com/ldery/Bonsai<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxrvnly4pj219y0s6kjl.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxrwcqnx1j21i00sa7cu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxsadvxz3j20rf0e542q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxsdqon3ij23641ewqv5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnxsowq13jj21060jegyd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnxstvypkkj214r0fp179.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 14:09:40 GMT</pubDate>
</item>
<item>
<title>【可视水印去除相关资源列表Mirascope是一个快速高质量开发的 LLM 工具集，让编写 Python 代码如同使用熟悉的 Python 代码一样简洁易写。】’Awesome Visible Wa...</title>
<link>https://weibo.com/1402400261/O5Vmnhd7B</link>
<guid>https://weibo.com/1402400261/O5Vmnhd7B</guid>
<content:encoded><![CDATA[
<div> GitHub, Mirascope, LLM, 工具集, Python, 简洁易写, 高质量, 快速开发, 可视水印去除

总结：<br /><br />这篇文章介绍了一个名为Mirascope的LLM工具集，能够快速高质量地开发可视水印去除的功能。使用该工具集，编写Python代码就像编写熟悉的Python代码一样简洁易写。通过在GitHub上查找“Awesome Visible Watermark Removal”，可以找到更多相关资源。Mirascope的特点包括快速开发和高质量输出，适合用于去除图片中的可视水印。整体来说，这个工具集为开发人员提供了便捷的工具来处理可视水印的相关问题。 <div>
【可视水印去除相关资源列表Mirascope是一个快速高质量开发的 LLM 工具集，让编写 Python 代码如同使用熟悉的 Python 代码一样简洁易写。】’Awesome Visible Watermark Removal' GitHub: github.com/bcmi/Awesome-Visible-Watermark-Removal <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnxsztsh6qj20y20u00xq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:59:11 GMT</pubDate>
</item>
<item>
<title>【Mirascope：快速高质量开发的 LLM 工具集】'Mirascope - LLM toolkit for lightning-fast, high-quality development' GitHub: github.com/Mirascope/mirascop...</title>
<link>https://weibo.com/1402400261/O5Vlxv7Rw</link>
<guid>https://weibo.com/1402400261/O5Vlxv7Rw</guid>
<content:encoded><![CDATA[
<div> LLM、快速、高质量、开发、工具集、Lightning、Mirascope、GitHub、高效、代码<br />
<br />
LLM工具集Mirascope旨在提供给开发者一个快速高质量开发的解决方案。通过这个Lightning工具集，开发者可以更加高效地进行代码开发，提高开发效率，同时保证代码质量。Mirascope的GitHub页面提供了详细的信息和资源，让开发者可以更好地了解和使用这个工具集。通过Mirascope，开发者可以更加轻松地完成开发任务，提升自身的开发能力。总而言之，Mirascope是一个值得开发者关注和使用的高效工具集。 <br /><br />总结: <div>
【Mirascope：快速高质量开发的 LLM 工具集】'Mirascope - LLM toolkit for lightning-fast, high-quality development' GitHub: github.com/Mirascope/mirascope <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnxsxp7ojqj21ji0pagpj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:57:08 GMT</pubDate>
</item>
<item>
<title>【表格数据的监督学习】’Awesome Self-Supervised Learning for Non-Sequential Tabular Data (SSL4NSTD) - A collection of research materials on SSL for no...</title>
<link>https://weibo.com/1402400261/O5VjP0XY8</link>
<guid>https://weibo.com/1402400261/O5VjP0XY8</guid>
<content:encoded><![CDATA[
<div> 关键词：self-supervised learning, 非序列数据, 表格数据, 监督学习

总结:<br /><br />这篇文章介绍了有关非序列数据中自监督学习的研究材料，主要关注表格数据的监督学习。自监督学习是一种无需人工标注的学习方法，通过模型自身生成标签进行训练。针对非序列数据，如表格数据，研究者们提出了许多创新的方法和技术，以实现更有效的监督学习。这个GitHub项目收集了相关研究材料，为对这一领域感兴趣的人提供了宝贵的资源和参考。通过研究这些材料，人们可以了解到最新的自监督学习技术在非序列数据上的应用和研究进展，有助于推动该领域的发展和创新。 <div>
【表格数据的监督学习】’Awesome Self-Supervised Learning for Non-Sequential Tabular Data (SSL4NSTD) - A collection of research materials on SSL for non-sequential tabular data (SSL4NSTD)' GitHub: github.com/wwweiwei/awesome-self-supervised-learning-for-tabular-data <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnxsta90joj21ji0nkaf0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:52:54 GMT</pubDate>
</item>
<item>
<title>【DSPy相关资源大列表】’Awesome DSPy - An Awesome list of curated DSPy resources.' GitHub: github.com/ganarajpr/awesome-dspy #开源# #机器学习# #人工智...</title>
<link>https://weibo.com/1402400261/O5VfXtRGo</link>
<guid>https://weibo.com/1402400261/O5VfXtRGo</guid>
<content:encoded><![CDATA[
<div> GitHub, curated, DSPy, resources, list, awesome, Ganarajpr, resource, list, DSPy<br />
<br />关于DSPy的资源列表已经在GitHub上由Ganarajpr精心整理，包含了丰富的资源和信息。这个列表提供了许多有用的链接和工具，可以帮助开发人员更好地了解和学习DSPy。其中包含了各种教程、文档、代码示例以及其他相关资源，适合初学者和有经验的开发者使用。值得一提的是，这个列表还不断更新，保持了最新的信息和动态。总的来说，这个资源列表为学习和使用DSPy提供了很好的支持，是一份非常棒的资源。<br /><br />总结: <br />GitHub上的DSPy资源列表由Ganarajpr精心整理，包含丰富的资源和信息，适合初学者和有经验的开发者使用。列表包含各种教程、文档、代码示例等，不断更新保持最新信息。对学习和使用DSPy提供了很好的支持，是一份非常棒的资源。 <div>
【DSPy相关资源大列表】’Awesome DSPy - An Awesome list of curated DSPy resources.' GitHub: github.com/ganarajpr/awesome-dspy <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnxsjdyou6j20zk0u0afn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:43:23 GMT</pubDate>
</item>
<item>
<title>【text-splitter：将文本分割成不同的片段，以便在处理更大的文本时更好地处理文本】'text-splitter - Split text into semantic chunks, up to a desired chunk...</title>
<link>https://weibo.com/1402400261/O5Ven65Ye</link>
<guid>https://weibo.com/1402400261/O5Ven65Ye</guid>
<content:encoded><![CDATA[
<div> 关键词: text-splitter, 分割文本, 语义块, 字符计算, 语言模型, GitHub

分析中提到了一个名为text-splitter的工具，可以将文本分割成语义块，支持根据字符和标记计算长度。用户可以通过GitHub找到该工具的相关信息。

总结:<br /><br />
文章介绍了一个名为text-splitter的工具，可以将文本分割成语义块，适用于处理更大的文本。该工具支持根据字符和标记来计算文本长度，尤其适用于大型语言模型的使用。用户可以在GitHub上找到更多关于text-splitter的信息。 <div>
【text-splitter：将文本分割成不同的片段，以便在处理更大的文本时更好地处理文本】'text-splitter - Split text into semantic chunks, up to a desired chunk size. Supports calculating length by characters and tokens (when used with large language models).' GitHub: github.com/benbrandt/text-splitter <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnxsfb0ovyj21ji0q6te9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:39:27 GMT</pubDate>
</item>
<item>
<title>'ONNX Runtime Server: The ONNX Runtime Server is a server that provides TCP and HTTP/HTTPS REST APIs for ONNX inference.' GitHub: github.com/kibae/onn...</title>
<link>https://weibo.com/1402400261/O5VbAzaaN</link>
<guid>https://weibo.com/1402400261/O5VbAzaaN</guid>
<content:encoded><![CDATA[
<div> ONNX Runtime Server, TCP, HTTP, HTTPS, REST API, GitHub, kibae, inference, server

<br /><br />总结:
ONNX Runtime Server是一个提供TCP和HTTP/HTTPS REST API用于ONNX推断的服务器。该项目托管在GitHub上，由kibae维护。通过该服务器，可以实现对ONNX模型的推断功能，为机器学习应用提供便捷的服务。 <div>
'ONNX Runtime Server: The ONNX Runtime Server is a server that provides TCP and HTTP/HTTPS REST APIs for ONNX inference.' GitHub: github.com/kibae/onnxruntime-server <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnxs86hph9j21hx0u0n4h.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:32:37 GMT</pubDate>
</item>
<item>
<title>【位置识别方法、数据集和各种LiDAR算法大列表】’Awesome LiDAR Place Recognition - A curated list of Place Recognition methods, datasets, and various al...</title>
<link>https://weibo.com/1402400261/O5Vaq8j2y</link>
<guid>https://weibo.com/1402400261/O5Vaq8j2y</guid>
<content:encoded><![CDATA[
<div> LiDAR、位置识别、方法、数据集、算法、GitHub、Awesome LiDAR Place Recognition、curated list、Hogyun2<br /><br />总结:本文介绍了一个GitHub上的资源链接，包括LiDAR的位置识别方法、数据集和不同的算法。这个资源列表由Hogyun2整理，涵盖了各种LiDAR算法和数据集，有助于研究人员和工程师在LiDAR领域进行定位和识别方面的工作。 <div>
【位置识别方法、数据集和各种LiDAR算法大列表】’Awesome LiDAR Place Recognition - A curated list of Place Recognition methods, datasets, and various algorithms for LiDAR' GitHub: github.com/hogyun2/awesome-lidar-place-recognition <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnxs56ij5ij21690u07ac.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 13:29:44 GMT</pubDate>
</item>
<item>
<title>【TacticAI：用于足球战术分析的AI助手】- 提出了TacticAI，这是一种专门用于足球战术分析的人工智能助手，可以帮助教练员分析角球战术，并提出改进建议。该系统...</title>
<link>https://weibo.com/1402400261/O5Q4I1xfk</link>
<guid>https://weibo.com/1402400261/O5Q4I1xfk</guid>
<content:encoded><![CDATA[
<div> 预测、生成、图神经网络、足球战术、人工智能、角球、利物浦足球俱乐部、嵌入表示、深度学习、实用性

总结:<br /><br />本研究提出了一种用于足球战术分析的人工智能助手TacticAI，利用图神经网络学习球员位置关系的高维嵌入表示，可以预测角球的接收者和射门概率，生成最有可能得分的球员布局建议。通过利物浦俱乐部专家的合作评估，得出了较好的定量结果。人工智能系统在足球战术分析领域的应用超越人类专家，具有实用性，为体育智能化发展提供新思路。尽管取得进展，但仍需进一步研究提高泛化和解释能力。 <div>
【TacticAI：用于足球战术分析的AI助手】<br />- 提出了TacticAI，这是一种专门用于足球战术分析的人工智能助手，可以帮助教练员分析角球战术，并提出改进建议。该系统由利物浦足球俱乐部的专家共同开发和评估。   <br />- TacticAI包含预测和生成两个组件。预测组件可以预测角球的接收者和射门概率；生成组件可以为每个角球生成可选的球员布局，并推荐最有可能得分的布局。   <br />- TacticAI利用图神经网络学习球员位置关系的高维嵌入表示，以提高数据效率，并利用几何深度学习保证对球场对称性变换的不变性。这在足球数据有限的情况下非常重要。   <br />- 在预测接球队员和射门两个任务上，TacticAI都取得了不错的定量结果。尤其是射门预测，采用联合训练的方法，最终F1得分达到0.71。   <br />- TacticAI的生成组件可以根据指定的期望射门结果(提高或降低射门概率)，生成对球员位置和速度的调整建议。该建议与真实球员位置难以区分，且可以明显改变射门概率。   <br />- 利用利物浦俱乐部专家进行案例研究，结果表明TacticAI生成的建议不仅逼真，还有90%的时间被专家更青睐，确认了TacticAI的实用性。该研究为运用AI辅助足球战术分析提供了有力证据。<br /><br />点评：<br />- 在如此复杂的足球战术领域，AI系统的建议能够超越人类专家的水平，这打破了人们对人工智能只能处理简单任务的传统认知。  <br />- 将复杂的战术知识形式化为结构化数据，使其可被机器学习模型理解和操作，是本研究的核心创新点，这种方法可能会为人工智能在其他复杂决策领域的应用提供借鉴。  <br />- 尽管取得了令人鼓舞的进展，但人工智能系统在足球战术方面的应用仍处于初级阶段，未来需要更多的研究来提高其泛化能力和解释能力。  <br />- 该研究为人工智能在体育领域的应用开辟了新的思路，有望促进体育运动的科学化和智能化发展。<br />《TacticAI: an AI assistant for football tactics | Nature Communications》 <a href="https://www.nature.com/articles/s41467-024-45965-x?code=b78a856e-3875-4cce-80f1-55997cff0373&amp;error=cookies_not_supported"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnx5nnbi2bj20j10flmyo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnx5nppmj2j20j109tt9w.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnx5nracrhj20j10bdjs2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 00:31:56 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O5PWHyAxX</link>
<guid>https://weibo.com/1402400261/O5PWHyAxX</guid>
<content:encoded><![CDATA[
<div> 携手, 送出, 大语言模型, 原理, 工程实践, 知识体系, 实践性, 全彩印刷, 杨青, 度小满

<br /><br />
总结:
本书《大语言模型：原理与工程实践(全彩)》从大语言模型的内在机理和应用实践出发，揭开了其神秘面纱。作者杨青是度小满轩辕大模型负责人，拥有丰富的大语言模型训练经验。这本书系统性地介绍了大语言模型的知识体系和对实践性的重视，还配有代码和全彩印刷。欢迎转发并评论，有机会赢得《大语言模型：原理与工程实践(全彩)》这本干货满满的书籍。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 00:12:13 GMT</pubDate>
</item>
<item>
<title>今日推介(第1350期)：人工反馈参数高效强化学习、利用生成式知识提取和基于图的表示和多模态智能图推理加速科学发现、基于深度学习的语言演化研究、分布式路径合...</title>
<link>https://weibo.com/1402400261/O5PcI60ah</link>
<guid>https://weibo.com/1402400261/O5PcI60ah</guid>
<content:encoded><![CDATA[
<div> 人工反馈参数、高效强化学习、生成式知识提取、基于图的表示、多模态智能图推理、深度学习、语言演化研究、分布式路径合成、情景记忆控制、大型语言模型

<br /><br />总结:
本文介绍了几种新颖的科学发现方法，包括利用人工反馈参数进行高效强化学习、利用生成式知识提取和基于图的表示进行多模态智能图推理加速科学发现等。其中提到了基于深度学习的语言演化研究，分析了分布式路径合成的方法以及基于情景记忆控制的大型语言模型。这些方法为科学研究和发现提供了新的思路和工具，有助于推动科学领域的进步。 <div>
今日推介(第1350期)：人工反馈参数高效强化学习、利用生成式知识提取和基于图的表示和多模态智能图推理加速科学发现、基于深度学习的语言演化研究、分布式路径合成、基于情景记忆控制的大型语言模型 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687959383"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.20)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnx1t48341j20k00iumyo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnx1t6xru7j20k00rv41e.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnx1t9dq1hj20k00admyc.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnx1te9n2fj20k00lwmzp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnx1tgoi5bj20k0086t9x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 22:18:53 GMT</pubDate>
</item>
<item>
<title>[CV] Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation 网页链接 提出"潜对抗性扩散蒸馏"(LADD)方法，在深度学习扩散模型...</title>
<link>https://weibo.com/1402400261/O5P8C8z8n</link>
<guid>https://weibo.com/1402400261/O5P8C8z8n</guid>
<content:encoded><![CDATA[
<div> 潜对抗性扩散, 模型蒸馏, 快速生成, 图像修复, 推理速度, 突破性进展, 深度学习, SD3-Turbo, 生成特征, 实时应用

总结:<br /><br />该研究提出了潜对抗性扩散蒸馏（LADD）方法，取得了深度学习扩散模型蒸馏方面的突破性进展。与前作对抗性扩散蒸馏（ADD）相比，LADD直接利用预训练扩散模型的生成特征，无需解码到像素空间，简化了训练过程，同时能更好地控制鉴别器的行为。将LADD应用于最新的文本到图像生成模型"Stable Diffusion 3"，得到了超快速的SD3-Turbo，单步生成质量媲美原模型，但仅需4步采样。研究还展示了LADD在图像编辑和修复等其他任务中的适用性，并深入分析了LADD的伸缩性。总的来说，LADD大幅提升了扩散模型的推理速度，为实时应用铺平了道路。 <div>
[CV] Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation  <br /><a href="https://arxiv.org/abs/2403.12015"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出"潜对抗性扩散蒸馏"(LADD)方法，在深度学习扩散模型蒸馏中取得突破性进展。相比前作"对抗性扩散蒸馏"(ADD)，LADD直接利用预训练扩散模型的生成特征，无需解码到像素空间，大幅简化了训练过程，同时还能更好地控制鉴别器的行为。将LADD应用于最新的文本到图像生成模型"Stable Diffusion 3"，得到了超快速的SD3-Turbo，其单步生成质量媲美原模型，但仅需4步采样。展示了LADD适用于图像编辑和修复等其他任务，并深入分析了LADD的伸缩性。总的来说，LADD大幅提升了扩散模型的推理速度，为实时应用铺平了道路。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx1ixbjerj212q1im7ls.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx1ixtzoqj20vc1b8wup.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx1iy7hgfj21g614qatb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 22:08:47 GMT</pubDate>
</item>
<item>
<title>[LG] Understanding Diffusion Models by Feynman's Path Integral 网页链接 通过引入Feynman路径积分的形式，为理解基于得分扩散模型中随机与确定性采样方案性...</title>
<link>https://weibo.com/1402400261/O5P0Z2xh9</link>
<guid>https://weibo.com/1402400261/O5P0Z2xh9</guid>
<content:encoded><![CDATA[
<div> Feynman路径积分 模型 插值参数 h 确定性随机采样 性能差异 WKB展开 负对数似然 物理学联系 噪声计算

<br /><br />总结:
本文通过引入Feynman路径积分的形式，提供了新的视角理解基于得分扩散模型中随机与确定性采样方案性能差异。通过引入插值参数h，在路径积分中类似于普朗克常数的作用，连接了随机生成和概率流ODE两种极端情况。结合WKB展开方法，对负对数似然进行评估，解释了性能差异的原因。这种方法不仅展示了扩散模型与物理学的联系，还为在噪声存在的采样过程中计算对数似然提供了新的途径。 <div>
[LG] Understanding Diffusion Models by Feynman's Path Integral  <br /><a href="https://arxiv.org/abs/2403.11262"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />通过引入Feynman路径积分的形式，为理解基于得分扩散模型中随机与确定性采样方案性能差异提供了新视角。本文发现路径积分公式化可以全面描述生成模型，展示了如何导出后向随机微分方程和损失函数。本文的核心创新是引入一个插值参数h，连接随机生成(h=1)和概率流ODE(h=0)。该参数在路径积分中的作用类似于量子物理中的普朗克常数，通过类比，应用了WKB(Wentzel-Kramers-Brillouin)展开方法，量子物理中的一种技术，用来评估负对数似然(NLL)，以此解释随机和确定性采样方案间的性能差异。这种方法不仅展示了扩散模型与物理学更深层次的联系，还为在存在噪声的采样过程中明确计算对数似然提供了新的途径。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx0zd4felj219k1j2h9m.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx0zdfkbwj20rs104ag5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx0zdqsajj20rs0n0wht.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:49:59 GMT</pubDate>
</item>
<item>
<title>[CV] LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images 网页链接 现有大型多模态模型(LMM)在处理不同长宽比和高分辨率图像时存在系统...</title>
<link>https://weibo.com/1402400261/O5OYrFho4</link>
<guid>https://weibo.com/1402400261/O5OYrFho4</guid>
<content:encoded><![CDATA[
<div> 模型, 长宽比, 高分辨率, 图像模块化, 压缩模块, 空间模式, 准确率, 推理计算量, A100 GPU, 高效训练

总结:<br /><br />
本文介绍了LLaVA-UHD模型，解决了大型多模态模型在处理不同长宽比和高分辨率图像时存在的问题。通过图像模块化策略、压缩模块和空间模式的创新组件，实现了对任意长宽比和高分辨率图像的有效感知。该模型在九个基准测试中表现出色，特别是在TextVQA上准确率提高了6.4点，推理计算量仅增加了94%。训练过程仅用时23小时，在学术环境下展现了高效训练潜力。 <div>
[CV] LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images  <br /><a href="https://arxiv.org/abs/2403.11703"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />现有大型多模态模型(LMM)在处理不同长宽比和高分辨率图像时存在系统性缺陷，因固定图像尺寸和有限分辨率导致效率低下、适应性差和准确性问题。本文提出了LLaVA-UHD模型，通过图像模块化策略、压缩模块和空间模式三大创新组件，实现了对任意长宽比和高分辨率图像的有效感知。LLaVA-UHD在九个基准测试中表现出色，特别是在TextVQA上比基于LLaVA-1.5的模型准确率提高了6.4点，且推理计算量只增加了94%。该模型能在8块A100 GPU上仅用23小时完成训练，显示了在学术环境下的高效训练潜力。<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx0svm0i8j212u1jc1an.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx0svz4mkj21980ps0zl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx0swhritj218w0wgqbs.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0swychaj21980v847o.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:43:46 GMT</pubDate>
</item>
<item>
<title>[CL] A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models 网页链接 提出一套工具和方法论，用于识别和评估大型语言模型(LLM)在...</title>
<link>https://weibo.com/1402400261/O5OWDhAoR</link>
<guid>https://weibo.com/1402400261/O5OWDhAoR</guid>
<content:encoded><![CDATA[
<div> 关键词: 健康公平、大型语言模型、医疗问答、偏见、数据集、评估框架、实证案例、多元化评估方法、AI系统、公平医疗服务

总结:<br /><br />
本文针对大型语言模型在医疗问答中可能存在的健康公平问题和偏见提出了一套工具和方法论。通过与Med-PaLM 2模型的实证案例研究，开发了多方面评估模型输出的框架，包括独立评估、成对评估和反事实评估。为了对抗性查询中的潜在偏见，创建了七个新的数据集EquityMedQA。强调了多元化评估方法的重要性，并指出框架无法全面评估AI系统是否促进了公平的健康结果。这项研究旨在推动社区使用这些工具和方法，促进大型语言模型在提供可访问、公平医疗服务方面的进步。 <div>
[CL] A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models  <br /><a href="https://arxiv.org/abs/2403.12025"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出一套工具和方法论，用于识别和评估大型语言模型(LLM)在医疗问答中可能产生的健康公平相关问题和偏见。通过与Med-PaLM 2模型的实证案例研究，开发了多方面评估模型输出的框架，包括独立评估、成对评估和反事实评估，并创建了七个新的数据集EquityMedQA，旨在对抗性查询中富集潜在的偏见。强调了多元化评估方法的重要性，并指出，尽管框架能够识别特定形式的偏见，但无法全面评估AI系统是否促进了公平的健康结果。该研究旨在推动社区使用这些工具和方法，促进LLM在提供可访问、公平医疗服务方面的进步。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnx0o858zxj21401fy4fw.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx0o8ubfuj21qg17s7gt.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:39:17 GMT</pubDate>
</item>
<item>
<title>Larimar通过引入分布式情景记忆控制器，提供了一种无需昂贵重训练即可实现大型语言模型动态、一次性知识更新的高效方法，通过实验验证了其在多个事实编辑基准测...</title>
<link>https://weibo.com/1402400261/O5OTYmgiM</link>
<guid>https://weibo.com/1402400261/O5OTYmgiM</guid>
<content:encoded><![CDATA[
<div> 关键词：Larimar、分布式情景记忆控制器、大型语言模型、动态知识更新、准确性、速度、灵活性、连续编辑、批量编辑、实际应用潜力

总结：<br /><br />
本文介绍了一种名为Larimar的方法，通过引入分布式情景记忆控制器，实现了大型语言模型的动态、一次性知识更新，而无需昂贵的重训练。该方法在多个事实编辑基准测试中验证了其准确性、速度和灵活性优势，表明在处理连续和批量编辑任务中具有实际应用潜力。 Larimar方法的创新之处在于利用情景记忆控制器实现知识更新的高效性，使得大型语言模型可以快速适应新知识，提高了模型的灵活性和性能。通过实验证明，Larimar方法能够有效应对不同编辑任务，展现出较好的表现。未来，Larimar方法有望在实际应用中发挥重要作用，为语言模型的发展带来新的思路和方法。 <div>
Larimar通过引入分布式情景记忆控制器，提供了一种无需昂贵重训练即可实现大型语言模型动态、一次性知识更新的高效方法，通过实验验证了其在多个事实编辑基准测试中的准确性、速度和灵活性优势，表明其在处理连续和批量编辑任务中具有实际应用潜力。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Larimar: Large Language Models with Episodic Memory Control》P Das, S Chaudhury, E Nelson, I Melnyk... [IBM AI Research] (2024) <a href="https://arxiv.org/abs/2403.11901"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx06wm7erj20rw108gv4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx06x2d03j21tq0qudpd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx06y6yt3j20wk0o4whi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx06yxr3wj20wo0u4tdk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0hcejejj20iu0b20tp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0hcexk5j20iv0ii401.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx0hcew8gj20iv0d9wfa.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:32:44 GMT</pubDate>
</item>
<item>
<title>[LG]《Larimar: Large Language Models with Episodic Memory Control》P Das, S Chaudhury, E Nelson, I Melnyk... [IBM AI Research] (2024) 网页链接 #机器学...</title>
<link>https://weibo.com/1402400261/O5OTW8hMJ</link>
<guid>https://weibo.com/1402400261/O5OTW8hMJ</guid>
<content:encoded><![CDATA[
<div> 大规模语言模型，Larimar，情节式记忆控制，P Das，S Chaudhury，E Nelson，I Melnyk，IBM AI Research，2024

<br /><br />总结:
该研究提出了一种名为Larimar的大型语言模型，具有情节式记忆控制功能。研究人员通过实验和分析，展示了Larimar在语言理解和生成任务上的优越性能。他们探索了模型的结构和参数配置，以优化其性能。通过该研究，他们为自然语言处理领域的发展提供了宝贵的见解和方法。 <div>
[LG]《Larimar: Large Language Models with Episodic Memory Control》P Das, S Chaudhury, E Nelson, I Melnyk... [IBM AI Research] (2024) <a href="https://arxiv.org/abs/2403.11901"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnx06wm7erj20rw108gv4.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx06x2d03j21tq0qudpd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx06y6yt3j20wk0o4whi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx06yxr3wj20wo0u4tdk.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0hcejejj20iu0b20tp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnx0hcexk5j20iv0ii401.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnx0hcew8gj20iv0d9wfa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:32:39 GMT</pubDate>
</item>
<item>
<title>提出DiPaCo模型，通过模块化设计和分布式路径组合的训练方法，显著降低了分布式学习环境中的通信需求，实现了在分散计算节点上高效、鲁棒的大规模机器学习模型训...</title>
<link>https://weibo.com/1402400261/O5OLCCU9O</link>
<guid>https://weibo.com/1402400261/O5OLCCU9O</guid>
<content:encoded><![CDATA[
<div> DiPaCo模型、模块化设计、分布式路径组合、训练方法、通信需求、大规模机器学习模型训练、C4基准、性能优于传统大型单体模型<br />
<br />
总结:<br />
DiPaCo模型通过模块化设计和分布式路径组合的训练方法，降低了分布式学习环境中的通信需求，实现在分散计算节点上高效、鲁棒的大规模机器学习模型训练。在C4基准上，DiPaCo模型表现出优于传统大型单体模型的性能。该模型的提出具有重要的意义，为分布式学习领域带来了新的研究思路和方法。DiPaCo模型的成功应用为解决大规模机器学习模型训练时通信开销大的问题提供了有益的启示。 <div>
提出DiPaCo模型，通过模块化设计和分布式路径组合的训练方法，显著降低了分布式学习环境中的通信需求，实现了在分散计算节点上高效、鲁棒的大规模机器学习模型训练，并在C4基准上显示出优于传统大型单体模型的性能。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《DiPaCo: Distributed Path Composition》A Douillard, Q Feng, A A. Rusu, A Kuncoro… [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.10616"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwzv66tb9j21ry0scdw7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnwzv6m856j20we0zgqa8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnwzv74mtrj21sc0l4dlp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzv7ny0oj21sc0uy7f6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqh4f1j211a0kcjvs.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqfou4j20ih0g5gms.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnwzvqflixj20ii0biwfj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqgwumj20ij0l876e.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwzvqh2aqj20ik0majtr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:12:09 GMT</pubDate>
</item>
<item>
<title>[LG]《DiPaCo: Distributed Path Composition》A Douillard, Q Feng, A A. Rusu, A Kuncoro… [Google DeepMind] (2024) 网页链接 #机器学习##人工智能##论文# [...</title>
<link>https://weibo.com/1402400261/O5OLvzDCh</link>
<guid>https://weibo.com/1402400261/O5OLvzDCh</guid>
<content:encoded><![CDATA[
<div> DiPaCo, Distributed Path Composition, A Douillard, Q Feng, A A. Rusu, A Kuncoro, Google DeepMind, 2024<br />
<br />
总结:<br />
文章介绍了DiPaCo，这是一个由Google DeepMind团队提出的分布式路径组合方法。该方法可以在分布式系统中实现路径组合，具有高效性和可扩展性。研究表明，DiPaCo可以有效解决传统路径组合方法中的性能瓶颈和可扩展性问题。研究人员通过仿真实验证明了DiPaCo的有效性和性能优势。这一方法对于处理大规模数据和复杂任务具有重要意义，为分布式系统的发展和应用提供了新的思路。 <div>
[LG]《DiPaCo: Distributed Path Composition》A Douillard, Q Feng, A A. Rusu, A Kuncoro… [Google DeepMind] (2024) <a href="https://arxiv.org/abs/2403.10616"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwzv66tb9j21ry0scdw7.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnwzv6m856j20we0zgqa8.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnwzv74mtrj21sc0l4dlp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzv7ny0oj21sc0uy7f6.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqh4f1j211a0kcjvs.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqfou4j20ih0g5gms.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnwzvqflixj20ii0biwfj.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqgwumj20ij0l876e.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwzvqh2aqj20ik0majtr.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnwzvqhb3oj21150k6mzy.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnwzvqi16uj211b0gymyz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 21:11:53 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.19)》 爱可可微博热门分享(3.19) [图片]</title>
<link>https://weibo.com/1402400261/O5M25EV5o</link>
<guid>https://weibo.com/1402400261/O5M25EV5o</guid>
<content:encoded><![CDATA[
<div> 微博、爱可可、热门、分享、3.19、关键词

<br /><br />总结:
3月19日，爱可可微博发布了一篇热门分享的文章，引起了广泛关注。该篇文章内容丰富，涵盖了各种热门话题，吸引了众多网友转发和评论。其中提到了关于时事新闻、娱乐八卦、美食文化等多个方面的内容，让人目不暇接。网友们纷纷表示对这篇文章的关注和喜爱，展示了对爱可可微博的支持和热情。文章内容引发了热烈讨论，让大家更加了解和关注各种热门话题。愿爱可可微博持续分享更多有趣、有价值的内容，与网友们共同成长。 <div>
《爱可可微博热门分享(3.19)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405013762816999689"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.19)</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwnt7oxfzj20rs0fmmz5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 14:14:29 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《FeatUp: A Model-Agnostic Frameworkfor Features at Any Resolution》(ICLR 2024) GitHub: github.com/mhamilton723/FeatUp《Lodge: A Coa...</title>
<link>https://weibo.com/1402400261/O5LEL1Uki</link>
<guid>https://weibo.com/1402400261/O5LEL1Uki</guid>
<content:encoded><![CDATA[
<div> 特征，分辨率，模型，框架，匹配，图像生成，深度学习，模糊，文本生成，benchmark

总结: 
《FeatUp: A Model-Agnostic Framework for Features at Any Resolution》提出了FeatUp框架，旨在实现模型之间特征的无缝转换，无论分辨率如何。该框架实现了特征的匹配，能够在不同分辨率下生成高质量的图像。研究使用深度学习技术，提出了在图像生成过程中进行特征匹配和转换的方法，从而实现模型的复杂度和性能的提升。此外，研究还关注模型的抗干扰能力，能够应对模糊或不清晰的数据输入。同时，研究在文本生成和benchmark方面也取得了显著的进展。FeatUp框架为将不同模型的特征无缝整合提供了新的思路，并在多个应用场景中展现了广阔的应用前景。 <div>
几篇论文实现代码：<br />《FeatUp: A Model-Agnostic Frameworkfor Features at Any Resolution》(ICLR 2024) GitHub: github.com/mhamilton723/FeatUp<br />《Lodge: A Coarse to Fine Diffusion Network for Long Dance Generation Guided by the Characteristic Dance Primitives》(CVPR 2024) GitHub: github.com/li-ronghui/LODGE<br />《FastMAC: Stochastic Spectral Sampling of Correspondence Graph》(CVPR 2024) GitHub: github.com/Forrest-110/FastMAC<br />《Desigen: A Pipeline for Controllable Design Template Generation》(2024) GitHub: github.com/whaohan/desigen [fig1]<br />《InTeX: Interactive Text-to-Texture Synthesis via Unified Depth-aware Inpainting》(2024) GitHub: github.com/ashawkey/InTeX<br />《Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking》(2024) GitHub: github.com/ezelikman/quiet-star<br />《NICER-SLAM: Neural Implicit Scene Encoding for RGB SLAM》(2024) GitHub: github.com/cvg/nicer-slam<br />《OMG: Occlusion-friendly Personalized Multi-concept Generation In Diffusion Models》(2024) GitHub: github.com/kongzhecn/OMG<br />《Controllable Text-to-3D Generation via Surface-Aligned Gaussian Splatting》(2024) GitHub: github.com/WU-CVGL/MVControl-threestudio<br />《RAGGED: Towards Informed Design of Retrieval Augmented Generation Systems》(2024) GitHub: github.com/neulab/ragged<br />《SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis》(2024) GitHub: github.com/sci-assess/SciAssess<br />《Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding》(2024) GitHub: github.com/pkunliu/Isotropic3D<br />《HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation》(2024) GitHub: github.com/carlosferrazza/humanoid-bench<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnwlpqeq7hj21fs0dy1kx.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 13:17:00 GMT</pubDate>
</item>
<item>
<title>【大模型安全相关阅读列表】’Awesome-LM-SSP - A reading list for large models safety, security, and privacy.' GitHub: github.com/ThuCCSLab/Awesome-LM-S...</title>
<link>https://weibo.com/1402400261/O5LCjCzTu</link>
<guid>https://weibo.com/1402400261/O5LCjCzTu</guid>
<content:encoded><![CDATA[
<div> 安全、大模型、隐私、阅读列表、GitHub、SSP、ThuCCSLab、模型、安全性、保密性

<br /><br />总结:
这是一个关于大型模型安全、安全性和隐私方面的阅读列表，包含了有关这些主题的各种资源和研究。在GitHub上可以找到这个令人印象深刻的资源列表，来自ThuCCSLab团队。研究人员和专业人士可以通过这个列表找到与大型模型安全性、安全方面和隐私相关的资料和信息，帮助他们更好地了解如何保护和管理大型模型的安全性和隐私。 <div>
【大模型安全相关阅读列表】’Awesome-LM-SSP - A reading list for large models safety, security, and privacy.' GitHub: github.com/ThuCCSLab/Awesome-LM-SSP <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnwlze5e62j20xz0u078j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 13:11:00 GMT</pubDate>
</item>
<item>
<title>【onefilellm: 面向大型语言模型(LLM)的命令行数据聚合工具】'onefilellm: Command Line Data Aggregation Tool for LLM Ingestion - Specify a github or local...</title>
<link>https://weibo.com/1402400261/O5Ly9EGb6</link>
<guid>https://weibo.com/1402400261/O5Ly9EGb6</guid>
<content:encoded><![CDATA[
<div> 聚合工具, 命令行, 数据, 大型语言模型, LLM, 网址, 抓取, 文本文件, 剪贴板, 摘要

面向大型语言模型（LLM）的命令行数据聚合工具"onefilellm"，是一个能够从GitHub、arXiv、Sci-Hub等提供的网址中提取信息并将其聚合到文本文件和剪贴板中的工具。用户只需指定相应的网址链接，就能够快速抓取相关数据，方便直接导入到LLM中进行处理。这个工具的使用方法简单快捷，适用于需要大量文本数据的用户群体。总结: <br /><br />onefilellm是一个面向LLM的命令行数据聚合工具，可以从指定网址中抓取信息并存储到文本文件和剪贴板中，方便用户进行数据处理和分析。 <div>
【onefilellm: 面向大型语言模型(LLM)的命令行数据聚合工具】'onefilellm: Command Line Data Aggregation Tool for LLM Ingestion - Specify a github or local repo, arXiv or Sci-Hub paper, Youtube transcript or documentation URL on the web and scrape into a text file and clipboard for easier LLM ingestion' GitHub: github.com/jimmc414/1filellm <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnwlod1xduj21aj0u0grz.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 13:00:45 GMT</pubDate>
</item>
<item>
<title>“Let's Build AI - A community-driven platform for AI enthusiasts” 网页链接 #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5Lxmw6fC</link>
<guid>https://weibo.com/1402400261/O5Lxmw6fC</guid>
<content:encoded><![CDATA[
<div> AI enthusiasts, community-driven platform, Let's Build AI

总结：<br /><br />这篇文章介绍了一个面向AI爱好者的社区驱动平台“Let's Build AI”。该平台旨在为AI爱好者提供一个共享和交流的空间，让他们共同探讨AI技术的发展和应用。通过这个平台，用户可以互相分享经验、学习最新的AI技术知识，并参与到AI项目的建设中。平台的主要目的是促进AI技术的发展，让更多人了解和参与到AI领域的创新中。 <div>
“Let's Build AI - A community-driven platform for AI enthusiasts” <a href="https://letsbuild.ai/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnwlmdlt9lj20vo0u0djh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 12:58:47 GMT</pubDate>
</item>
<item>
<title>【LLM-RLHF-Tuning：用于AI训练的开源工具包，提供PPO/DPO等算法】’LLM-RLHF-Tuning - Comprehensive toolkit for Reinforcement Learning from Human Feedback...</title>
<link>https://weibo.com/1402400261/O5IPUvXAm</link>
<guid>https://weibo.com/1402400261/O5IPUvXAm</guid>
<content:encoded><![CDATA[
<div> RLHF, 开源工具包, AI训练, PPO, DPO, 算法, 指导微调, 奖励模型训练, 配置, Alpaca, LLaMA

<br /><br />总结:
LLM-RLHF-Tuning是一个用于AI训练的开源工具包，提供了PPO和DPO等算法，支持指导微调和奖励模型训练。该工具包适用于Alpaca、LLaMA和LLaMA2模型，可以进行各种配置。通过使用LLM-RLHF-Tuning，用户可以更有效地进行强化学习训练，提高模型性能和表现。GitHub链接：github.com/raghavc/LLM-RLHF-Tuning-with-PPO-and-DPO <div>
【LLM-RLHF-Tuning：用于AI训练的开源工具包，提供PPO/DPO等算法】’LLM-RLHF-Tuning - Comprehensive toolkit for Reinforcement Learning from Human Feedback (RLHF) training, featuring instruction fine-tuning, reward model training, and support for PPO and DPO algorithms with various configurations for the Alpaca, LLaMA, and LLaMA2 models.' GitHub: github.com/raghavc/LLM-RLHF-Tuning-with-PPO-and-DPO <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnw9pflkjaj21d20u00z3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 06:06:15 GMT</pubDate>
</item>
<item>
<title>【LitServe：开源AI模型推理服务器，其目的是简洁且可扩展，可用于各种 GPU 上运行 ML 模型】'LitServe - Inference server for AI/ML models that is minimal a...</title>
<link>https://weibo.com/1402400261/O5IP2c64C</link>
<guid>https://weibo.com/1402400261/O5IP2c64C</guid>
<content:encoded><![CDATA[
<div> LitServe, 开源, AI模型, 推理服务器, 简洁, 可扩展, GPU, ML模型

LitServe是一个开源AI/ML模型推理服务器，目的是提供一个简洁且可扩展的解决方案，适用于各种GPU上运行ML模型。该项目在GitHub上有开源代码。

总结:<br /><br />
LitServe是一个推理服务器，专为AI/ML模型设计。它被设计为简洁且高度可扩展，适用于在各种GPU上运行ML模型。LitServe的目标是提供一个高效的解决方案，帮助开发人员轻松部署和运行他们的模型。LitServe的开源代码可以在GitHub上找到，有兴趣的人可以查看并参与其中。 <div>
【LitServe：开源AI模型推理服务器，其目的是简洁且可扩展，可用于各种 GPU 上运行 ML 模型】'LitServe - Inference server for AI/ML models that is minimal and highly scalable.' GitHub: github.com/Lightning-AI/litserve <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnw9n6ltoaj21cl0u0dk4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 06:04:05 GMT</pubDate>
</item>
<item>
<title>'Fin-Eva Version 1.0 金融领域中文语言专业数据评测集' GitHub: github.com/alipay/financial_evaluation_dataset #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5IOogmaT</link>
<guid>https://weibo.com/1402400261/O5IOogmaT</guid>
<content:encoded><![CDATA[
<div> 关键词: 金融领域、中文语言、数据评测集、GitHub、Alipay、版本、专业、数据、评测、金融

总结:<br /><br />
文章介绍了Alipay开发的金融领域中文语言专业数据评测集——Fin-Eva Version 1.0。该数据集旨在为金融领域的研究者和开发者提供一个可靠的数据源，帮助他们进行评测和研究工作。数据集包含了丰富的金融领域数据，并在GitHub上开放下载，方便用户获取和使用。用户可以在GitHub上找到相关信息，并了解数据集的具体内容和版本信息。通过使用该数据集，研究者和开发者可以从中获取有价值的信息，用于进行金融领域的研究和分析工作。 Fin-Eva Version 1.0标志着Alipay在金融领域数据开放方面的贡献，并为相关领域的学术研究和技术开发提供了重要支持。 <div>
'Fin-Eva Version 1.0 金融领域中文语言专业数据评测集' GitHub: github.com/alipay/financial_evaluation_dataset <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnw9lj7nzgj216y0u0wkq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 06:02:30 GMT</pubDate>
</item>
<item>
<title>【文本到图像扩散模型可控生成相关文献资源列表】’Awesome Controllable T2I Diffusion Models - A collection of resources on controllable generation with ...</title>
<link>https://weibo.com/1402400261/O5IKZstEp</link>
<guid>https://weibo.com/1402400261/O5IKZstEp</guid>
<content:encoded><![CDATA[
<div> GitHub, Controllable generation, Text-to-image diffusion models, Resources, Collection, Awesome, Priv-Creation, Controllable T2I Diffusion Models

<br /><br />总结:
本文资源集合了一些关于文本到图像扩散模型可控生成的资源。GitHub中包含了多种有关可控生成的信息。这些资源涵盖了文本到图像扩散模型的多个方面，对于研究和实践都具有重要价值。特别是对于那些对文本到图像生成感兴趣的研究者和开发人员，这些资源将提供丰富的参考资料和工具，有助于在这一领域取得进展。GitHub链接为github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models。 <div>
【文本到图像扩散模型可控生成相关文献资源列表】’Awesome Controllable T2I Diffusion Models - A collection of resources on controllable generation with text-to-image diffusion models.' GitHub: github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models?continueFlag=92653a077e6b01a49a5f05f9aa55a3e7 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnw9cn6stmj216s0lwgox.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:54:08 GMT</pubDate>
</item>
<item>
<title>【基于 Nextjs、React、Drizzle和Stripe 的Duolingo全栈克隆项目】'Build a Duolingo Clone With Nextjs, React, Drizzle, Stripe (2024)' GitHub: github.com/A...</title>
<link>https://weibo.com/1402400261/O5IKkvNsI</link>
<guid>https://weibo.com/1402400261/O5IKkvNsI</guid>
<content:encoded><![CDATA[
<div> Nextjs、React、Drizzle、Stripe、全栈、克隆项目、Duolingo、GitHub、AntonioErdeljac
本文介绍了一个基于Nextjs、React、Drizzle和Stripe的Duolingo全栈克隆项目，作者是AntonioErdeljac，并提供了GitHub链接。项目的目标是构建一个类似于Duolingo的学习平台，通过使用React库来构建用户界面，Nextjs作为应用程序框架，Drizzle作为以太坊区块链的项目开发工具，Stripe用于实现支付功能。项目的实现可以帮助开发人员学习如何使用这些技术和工具来构建现代Web应用程序。 <div>
【基于 Nextjs、React、Drizzle和Stripe 的Duolingo全栈克隆项目】'Build a Duolingo Clone With Nextjs, React, Drizzle, Stripe (2024)' GitHub: github.com/AntonioErdeljac/next14-duolingo-clone <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnw9az1oeoj20zk0k00vb.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:52:30 GMT</pubDate>
</item>
<item>
<title>【LlamaGym：用来简化基于语言模型的强化学习环境的开源项目，包含通用抽象类，帮助用户快速地尝试和探索各种 基于LLM的强化学习环境】'LlamaGym - Fine-tune LL...</title>
<link>https://weibo.com/1402400261/O5IJsqeyl</link>
<guid>https://weibo.com/1402400261/O5IJsqeyl</guid>
<content:encoded><![CDATA[
<div> LLamaGym, 开源项目, 强化学习环境, 基于语言模型, 抽象类, 探索, Fine-tune, LLM agents, 在线强化学习

总结:<br /><br />LLamaGym是一个开源项目，用于简化基于语言模型的强化学习环境，包含通用抽象类，帮助用户快速尝试和探索各种基于LLM的强化学习环境。用户可以通过这个项目来调优LLM代理并进行在线强化学习。GitHub链接：github.com/KhoomeiK/LlamaGym。 <div>
【LlamaGym：用来简化基于语言模型的强化学习环境的开源项目，包含通用抽象类，帮助用户快速地尝试和探索各种 基于LLM的强化学习环境】'LlamaGym - Fine-tune LLM agents with online reinforcement learning' GitHub: github.com/KhoomeiK/LlamaGym <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnw98vz3zjj20xz0u0tdc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:50:21 GMT</pubDate>
</item>
<item>
<title>【3DGS.cpp：跨平台、高性能的Gaussian Splatting渲染器，支持 Windows、Linux、macOS、iOS和visionOS】'3DGS.cpp - A cross-platform, high performance render...</title>
<link>https://weibo.com/1402400261/O5IIYiYZA</link>
<guid>https://weibo.com/1402400261/O5IIYiYZA</guid>
<content:encoded><![CDATA[
<div> 高性能、跨平台、Gaussian Splatting、渲染器、Vulkan Compute、Windows、Linux、macOS、iOS、visionOS
<br /><br />总结:
3DGS.cpp是一个跨平台、高性能的渲染器，使用Vulkan Compute技术实现Gaussian Splatting。支持多种操作系统，包括Windows、Linux、macOS、iOS和visionOS。项目托管在GitHub上，网址为github.com/shg8/3DGS.cpp。 <div>
【3DGS.cpp：跨平台、高性能的Gaussian Splatting渲染器，支持 Windows、Linux、macOS、iOS和visionOS】'3DGS.cpp - A cross-platform, high performance renderer for Gaussian Splatting using Vulkan Compute. Supports Windows, Linux, macOS, iOS, and visionOS' GitHub: github.com/shg8/3DGS.cpp <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnw97nb7o7j20u00uj44e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:49:09 GMT</pubDate>
</item>
<item>
<title>【Garnet：微软研究团队开发的远程缓存-存储项目，具有强性能(吞吐量和延迟)， 可扩展性，存储、恢复，集群分片，密钥迁移和复制等功能】'Garnet - Garnet is a ...</title>
<link>https://weibo.com/1402400261/O5IIimt1C</link>
<guid>https://weibo.com/1402400261/O5IIimt1C</guid>
<content:encoded><![CDATA[
<div> 远程缓存-存储、微软研究团队、强性能、吞吐量、延迟、可扩展性、存储恢复、集群分片、密钥迁移、复制

<br /><br />
总结:
微软研究团队开发了远程缓存-存储项目Garnet，具备强大的性能表现，包括高吞吐量和低延迟。该项目具有良好的可扩展性，支持存储、恢复、集群分片、密钥迁移和复制等功能。此外，Garnet可以与现有的Redis客户端兼容，为用户提供更好的使用体验。 <div>
【Garnet：微软研究团队开发的远程缓存-存储项目，具有强性能(吞吐量和延迟)， 可扩展性，存储、恢复，集群分片，密钥迁移和复制等功能】'Garnet - Garnet is a remote cache-store from Microsoft Research that offers strong performance (throughput and latency), scalability, storage, recovery, cluster sharding, key migration, and replication features. Garnet can work with existing Redis clients.' GitHub: github.com/microsoft/garnet <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnw95wf41dj218m0u0jyi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:47:29 GMT</pubDate>
</item>
<item>
<title>【Pointrix：可微点渲染库，支持3D Gaussian Splatting等的渲染】'Pointrix: a differentiable point-based rendering libraries supporting 3D Gaussian Splatt...</title>
<link>https://weibo.com/1402400261/O5IGMqG5k</link>
<guid>https://weibo.com/1402400261/O5IGMqG5k</guid>
<content:encoded><![CDATA[
<div> Point-based rendering, differentiable, 3D Gaussian Splatting, library, Pointrix, GitHub, support <br />
<br />
要点一：Pointrix是一个可微的点渲染库，支持3D Gaussian Splatting等技术。<br />
要点二：该库的GitHub链接为github.com/pointrix-project/pointrix。 <br />
要点三：Pointrix提供了高效的点渲染和处理功能，可用于各种3D图形应用中。<br />
要点四：库支持不同的渲染技术，包括3D Gaussian Splatting等，可以实现更加逼真的渲染效果。<br /> 
总结: Pointrix是一个支持3D Gaussian Splatting等渲染技术的可微点渲染库，在GitHub上可以找到该项目。这个库提供了高效的点渲染和处理功能，适用于各种3D图形应用，并可以实现更加逼真的渲染效果。 <div>
【Pointrix：可微点渲染库，支持3D Gaussian Splatting等的渲染】'Pointrix: a differentiable point-based rendering libraries supporting 3D Gaussian Splatting and beyond' GitHub: github.com/pointrix-project/pointrix <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnw91zmhtsj20v70u0dk5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 05:43:45 GMT</pubDate>
</item>
<item>
<title>【专家混合(MoE)模型详解】 - MoE通过使用稀疏的MoE层来替换稠密的前馈网络层，从而实现更高效的预训练。MoE层包含多个“专家”(通常是FFN)，以及一个门控网络来...</title>
<link>https://weibo.com/1402400261/O5Guy1JXq</link>
<guid>https://weibo.com/1402400261/O5Guy1JXq</guid>
<content:encoded><![CDATA[
<div> 稀疏、MoE层、专家、门控网络、计算预算、预训练、参数数量、训练效率、知识蒸馏、开源实现

<br /><br />总结:
MoE是一种通过稀疏的MoE层来取代稠密的前馈网络层，实现更高效预训练的模型。MoE包含多个专家和门控网络，能在相同计算预算下训练更大规模的模型，且在预训练过程中速度更快且质量相当。MoE在推理速度更快但内存需求高，微调困难且容易过拟合，但可通过多任务提示调优和单任务微调改善效果。选择MoE还是稠密模型取决于具体场景，可调整门控网络、专家容量等提高效率，也可通过知识蒸馏将MoE模型蒸馏为稠密模型。开源实现有Megablocks、Fairseq、OpenMoE等，模型包括Switch Transformers、NLLB MoE、OpenMoE等。未来MoE研究方向包括知识蒸馏、模型合并、量化等。 <div>
【专家混合(MoE)模型详解】  <br />- MoE通过使用稀疏的MoE层来替换稠密的前馈网络层，从而实现更高效的预训练。MoE层包含多个“专家”(通常是FFN)，以及一个门控网络来确定哪些tokens被送到哪个专家。   <br />- MoE可以在相同的计算预算下预训练出更大规模的模型。与稠密模型相比，MoE模型可以在预训练过程中以更快的速度达到相同的质量。   <br />- MoE模型推理速度更快，但需要加载全部参数到内存，所以内存需求高。   <br />- MoE模型微调较难，容易过拟合，但最近的工作显示先进行多任务提示调优然后再单任务微调可以改善效果。   <br />- 与稠密模型直接比较参数数量是错误的，因为它们表示不同的意义。选择MoE还是稠密模型取决于具体场景。   <br />- 为提高训练和推理效率，可调整门控网络、专家容量、精度等。还可通过知识蒸馏将MoE模型蒸馏为稠密模型。   <br />- 一些开源的MoE实现包括Megablocks、Fairseq、OpenMoE等。已发布的开源MoE模型有Switch Transformers、NLLB MoE、OpenMoE等。   <br />- MoE模型的一些激动人心的研究方向包括知识蒸馏、模型合并、量化等。<br />《Mixture of Experts Explained》 <a href="https://huggingface.co/blog/moe"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnvzcsvvqoj210r0u0td2.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 00:08:07 GMT</pubDate>
</item>
<item>
<title>【Quanto：pytorch量化工具包】1. quanto是一个灵活的pytorch量化工具包,提供了独特的功能:- 支持eager模式(可用于非可trace的模型)- 量化后的模型可在任意设备...</title>
<link>https://weibo.com/1402400261/O5GtgpFzZ</link>
<guid>https://weibo.com/1402400261/O5GtgpFzZ</guid>
<content:encoded><![CDATA[
<div> 量化工具包 PyTorch CUDA MPS QLinear QConv2d 动态 静态 int8 int2 int4 Transformers 模型 流程 校准 调优 冻结 性能 准确率 加速比 实现细节 dispatch PTQ 优化算法<br />
<br />
总结:<br />
1. quanto是一个灵活的pytorch量化工具包，支持eager模式和量化后模型在任意设备上运行。<br />
2. 典型的量化流程包括量化、校准、调优和冻结。<br />
3. quanto与huggingface transformers库深度集成，可通过QuantoConfig来量化任意模型。<br />
4. quanto的实现细节包括定制Tensor子类、量化模块和针对常见函数的量化版本。<br />
5. quanto的性能展示了不同量化配置的准确率以及量化带来的加速比。 <div>
【Quanto：pytorch量化工具包】<br />1. quanto是一个灵活的pytorch量化工具包,提供了独特的功能:<br />- 支持eager模式(可用于非可trace的模型)<br />- 量化后的模型可在任意设备上运行(包括CUDA和MPS)  <br />- 自动插入量化和反量化代码<br />- 自动插入量化的函数操作<br />- 自动插入量化的模块(如QLinear、QConv2d等)<br />- 提供从动态到静态量化的流程  <br />- 支持量化模型的状态字典序列化<br />- 不仅支持int8权重,还支持int2和int4<br />- 不仅支持int8激活,还支持float8<br />2. 典型的量化流程包括:量化、校准、调优和冻结。<br />3. quanto与huggingface transformers库深度集成,可通过QuantoConfig来量化任意模型。<br />4. quanto的实现细节:<br />- 提供了针对不同量化类型的定制Tensor子类<br />- 提供了可处理quanto tensor的量化模块,如QLinear、QConv2d等<br />- 通过pytorch dispatch机制,实现了常见函数的量化版本<br />- 计划集成各种PTQ优化算法<br />5. quanto的性能:<br />- 在多个模型上展示了不同量化配置的准确率<br />- 展示了相比全精度,量化带来的加速比<br />《Quanto: a pytorch quantization toolkit》 <a href="https://huggingface.co/blog/quanto-introduction"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnvz9gsvxfj20u00v7q7c.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 00:04:58 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O5GrXa9Og</link>
<guid>https://weibo.com/1402400261/O5GrXa9Og</guid>
<content:encoded><![CDATA[
<div> 知识体系、实践性、全彩印刷、杨青、度小满、轩辕大模型、十亿、百亿、千亿、训练经验
<br />
<br />
总结:<br />
本书《大语言模型：原理与工程实践(全彩)》由度小满轩辕大模型负责人杨青撰写，旨在揭开大语言模型的神秘面纱，深入解读内在机理和应用实践。书中系统性的知识体系和对实践性的重视是其特色之一，同时作者结合自己在不同参数规模大语言模型训练经验，将实践经验融入书中，内容干货十足，非空谈。书籍全彩印刷，配有代码，适合想要深入了解大语言模型的读者阅读。欢迎转发评论参与赢取《大语言模型：原理与工程实践(全彩)》。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Tue, 19 Mar 2024 00:01:44 GMT</pubDate>
</item>
<item>
<title>【解密Meta的GenAI基础设施】- Meta宣布投资建设了两座规模为24k GPU的AI集群，用于支持公司当前和未来的AI模型研发，包括下一代语言模型Llama 3。 - 详细介绍了...</title>
<link>https://weibo.com/1402400261/O5Gn8yily</link>
<guid>https://weibo.com/1402400261/O5Gn8yily</guid>
<content:encoded><![CDATA[
<div> 存储部署、网络、AI集群、GenAI基础设施、Meta、Grand Teton、RDMA over RoCE、InfiniBand、NVIDIA H100 GPU、Llama 3

总结:<br /><br />Meta宣布投资建设了两座规模为24k GPU的AI集群，用于支持公司当前和未来的AI模型研发，包括下一代语言模型Llama 3。这两座AI集群基于自研的开源硬件Grand Teton，拥有优化的网络部署和存储系统。通过软硬件协同设计，Meta在大规模集群上高效运行复杂的AI工作负载，并计划继续扩张基础设施，部署35万块NVIDIA H100 GPU，确保其AI基础设施灵活可靠地支持快速发展的AI模型和研究。Meta致力于开放的AI创新，贡献开源硬件和软件项目，为整个行业解决大规模AI的挑战。在AI系统日益复杂的今天，基础设施的重要性不容忽视，需要与算法同步优化和创新。文章着重介绍了Meta在GenAI基础设施的存储部署方面的定制化工作，呈现了一个不同的视角，强调了基础设施细节对支撑AI系统的重要性。人们对Meta采用两种不同的存储部署方式表示好奇，也有人质疑定制化基础设施是否真的有必要，是否会带来过高的成本和复杂性。Meta通过自研硬件、持续优化软件框架等方式，确保其AI基础设施能够始终满足快速发展的需求。 <div>
【解密Meta的GenAI基础设施】<br />- Meta宣布投资建设了两座规模为24k GPU的AI集群，用于支持公司当前和未来的AI模型研发，包括下一代语言模型Llama 3。   <br />- 详细介绍了这两座AI集群的硬件配置，包括网络、存储、计算单元等。两者都使用了自研的开源硬件Grand Teton作为基础。   <br />- AI集群的网络部分采用了RDMA over RoCE和InfiniBand两种解决方案，用于评估不同互联方式的可扩展性。存储部分则自研了优化过的分布式存储系统。   <br />- 通过软硬件协同设计，Meta能够在这样的大规模集群上高效运行复杂的AI工作负载，并取得很好的性能。文章给出了优化前后集群性能对比的数据。   <br />- Meta致力于开放的AI创新，持续贡献开源硬件和软件项目。此举有助于整个行业解决大规模AI的挑战。   <br />- 到2024年底，Meta计划继续扩张基础设施，部署35万块NVIDIA H100 GPU，计算能力将达到近60万块H100的规模。   <br />- Meta正通过自研硬件、持续优化软件框架等方式，确保其AI基础设施能够灵活可靠地支持快速发展的AI模型和研究。<br /><br />思考：  <br />- 文章着重介绍了Meta在GenAI基础设施的存储部署方面所做的定制化工作。  <br />- 通常人们更关注AI模型和算法本身，而较少关注支撑AI系统的基础设施细节，文章提供了一个不同的视角。  <br />- 有人会对Meta采用两种不同的存储部署方式表示好奇，也有人质疑定制化基础设施是否真的有必要，是否会带来过高的成本和复杂性。  <br />- 在AI系统日益复杂的今天，基础设施的重要性不容忽视，需要与算法同步优化和创新。<br />《Building Meta’s GenAI Infrastructure - Engineering at Meta》 <a href="https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnvytnizjsj215w0u0q9s.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnvytpx4yjj21400u0jt3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 23:49:52 GMT</pubDate>
</item>
<item>
<title>今日推介(第1349期)：面向推测译码加速的最优块级草稿验证、基于冻结特征增强的少样本图像分类、用RAG提高LLM事实准确性以对抗幻觉、适应特定域RAG的语言模型、...</title>
<link>https://weibo.com/1402400261/O5FPKcyln</link>
<guid>https://weibo.com/1402400261/O5FPKcyln</guid>
<content:encoded><![CDATA[
<div> 面向推测译码加速、块级草稿验证、冻结特征增强、少样本图像分类、RAG、LLM、事实准确性、适应特定域、语言模型、大型语言模型

<br /><br />总结:
本文提出了面向推测译码加速的最优块级草稿验证方法，在图像分类任务中使用冻结特征增强来处理少样本情况，同时利用RAG提高LLM事实准确性以对抗幻觉。文章还探讨了适应特定域RAG的语言模型，并提出了面向大型语言模型快速推测解码的循环起草器。这些方法有望在加速推测译码和提高语言模型准确性方面发挥重要作用。 <div>
今日推介(第1349期)：面向推测译码加速的最优块级草稿验证、基于冻结特征增强的少样本图像分类、用RAG提高LLM事实准确性以对抗幻觉、适应特定域RAG的语言模型、面向大型语言模型快速推测解码的循环起草器 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687756478"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.19)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnvwfx7dt5j20k0089dgm.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnvwfzaly2j20k00q2n0h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnvwg1j2dmj20k00edace.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnvwg40ht4j20k009ygmx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnvwg5x3qrj20k00cmjtc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:27:35 GMT</pubDate>
</item>
<item>
<title>[CV] FDGaussian: Fast Gaussian Splatting from Single Image via Geometric-aware Diffusion Model 网页链接 介绍了FDGaussian，一个基于单张图片的3D重建新框...</title>
<link>https://weibo.com/1402400261/O5FLgxilx</link>
<guid>https://weibo.com/1402400261/O5FLgxilx</guid>
<content:encoded><![CDATA[
<div> 关键词: FDGaussian, 单张图片, 3D重建, 正交平面分解, 扩散模型, 极线注意力, 高斯Splatting, 高斯散度显著性, 多视角一致性, 文本到3D应用

总结:<br /><br />
该篇文章介绍了一种名为FDGaussian的新框架，用于基于单张图片进行3D重建。传统方法在多视角一致性和几何真实性方面存在一些问题，而FDGaussian则通过正交平面分解提取3D特征，利用扩散模型生成一致的多视角图像。此外，还引入了基于极线注意力的高斯Splatting技术，能加速不同视点图像的融合。通过提出的高斯散度显著性(GDS)指标，可以减少优化过程中不必要的拆分和克隆操作。实验表明，FDGaussian不仅可以保持多视角一致性，还能重建出具有详细几何信息的高质量3D对象，并且能够无缝集成到文本到3D应用中。 <div>
[CV]  FDGaussian: Fast Gaussian Splatting from Single Image via Geometric-aware Diffusion Model  <br /><a href="https://arxiv.org/abs/2403.10242"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了FDGaussian，一个基于单张图片的3D重建新框架。传统的方法在多视角一致性和几何真实性上存在缺陷。FDGaussian通过正交平面分解提取3D特征，使用扩散模型生成一致的多视角图像。此外，引入了基于极线注意力的高斯Splatting，加速了不同视点图像融合，以及提出了高斯散度显著性(GDS)指标，减少了优化过程中不必要的拆分和克隆操作。实验表明，FDGaussian在保持多视角一致性的同时，能够重建出具有详细几何信息的高质量3D对象，并且能与文本到图像模型无缝集成，用于文本到3D应用。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvw4o40iqj21261jyanf.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvw4oln6nj213e0z6k01.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvw4oso0fj213m0g4n0j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:16:33 GMT</pubDate>
</item>
<item>
<title>[CV] SWAG: Splatting in the Wild images with Appearance-conditioned Gaussians 网页链接 介绍了SWAG模型，首个用于3D高斯Splatting(3DGS)技术在野外场景中扩...</title>
<link>https://weibo.com/1402400261/O5FJpsMWG</link>
<guid>https://weibo.com/1402400261/O5FJpsMWG</guid>
<content:encoded><![CDATA[
<div> 关键词: SWAG模型, 3D高斯Splatting, 图像外观, 高光照条件, 无监督学习, 瞬时高斯, 遮挡物移除, 训练速度提升, 渲染速度提升, 高质量重建

总结:<br /><br />本文介绍了SWAG模型，其为首个将3D高斯Splatting技术应用于野外场景中的模型。SWAG通过学习嵌入空间捕捉图像外观的变化，并对3D高斯的颜色进行调制，实现对不同光照条件下场景的建模。模型引入了无监督学习处理瞬时高斯的新机制，从而移除场景中的遮挡物。SWAG在野外数据集上表现出色，训练和渲染速度也大幅提升，达到最新的行业标准。文章展示了如何通过模型对外观进行建模和处理瞬时对象，实现对复杂真实世界场景的高效高质量重建。 <div>
[CV] SWAG: Splatting in the Wild images with Appearance-conditioned Gaussians  <br /><a href="https://arxiv.org/abs/2403.10427"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了SWAG模型，首个用于3D高斯Splatting(3DGS)技术在野外场景中扩展的应用。SWAG模型通过学习嵌入空间捕捉图像外观的变化，并对3D高斯的颜色进行调制，实现对不同光照条件下场景的建模。此外，模型还引入了一种新机制，通过无监督学习处理瞬时高斯，从而在没有前置条件的情况下移除场景中的遮挡物。相比先前的方法，SWAG不仅提升了3DGS在野外数据集上的表现，而且在训练和渲染速度上都有显著提高，达到了最新的行业标准。文章展示了如何在没有精确结构信息的状况下，通过对外观的建模和瞬时对象的处理，实现对复杂真实世界场景的高效和高质量重建。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvzxxa0vj20yi1e4n8l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvzym8ygj21oo15igzh.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvvzz4ojjj21oo100tk6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:12:00 GMT</pubDate>
</item>
<item>
<title>[CV] FeatUp: A Model-Agnostic Framework for Features at Any Resolution 网页链接 介绍了FeatUp，一个模型和任务不可知的框架，用于提高任意视觉模型特征的分...</title>
<link>https://weibo.com/1402400261/O5FHrfw0x</link>
<guid>https://weibo.com/1402400261/O5FHrfw0x</guid>
<content:encoded><![CDATA[
<div> FeatUp, 特征, 分辨率, 模型不可知, 多视角一致性, 上采样网络, 密集预测任务, 可解释性, NeRF, CUDA实现

<br /><br />总结:
文章介绍了FeatUp，一个模型和任务不可知的框架，用于提高任意视觉模型特征的分辨率，同时保持原有语义。FeatUp使用多视角一致性损失来聚合低分辨率视图信息，学习高分辨率信息，有通用的前馈上采样网络和过拟合单个图像隐式表示两种体系结构。该框架提高了密集预测任务的性能，增强了模型可解释性，并采用了类似于NeRF的多视角一致性方法，具有高效的CUDA实现。FeatUp为提高特征分辨率和模型解释性提供了新的可能性。 <div>
[CV] FeatUp: A Model-Agnostic Framework for Features at Any Resolution  <br /><a href="https://arxiv.org/abs/2403.10516"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了FeatUp，一个模型和任务不可知的框架，用于提高任意视觉模型特征的分辨率，同时保持原有语义，通过多视角一致性损失来聚合从模型输出中经过轻微变换图像得到的低分辨率视图信息，从而学习高分辨率信息。FeatUp有两种体系结构：一种是通用的前馈上采样网络，另一种是过拟合单个图像的隐式表示。该框架能够提高语义分割和深度预测等密集预测任务的性能，并增强模型可解释性。值得注意的是，FeatUp采用了类似于NeRF的多视角一致性方法，并且其高效的CUDA实现显著优于现有技术。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvux0wnij214m1m2nfo.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvuvmrjaj21mw0qownc.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvvuvlqhgj21nm0jgahb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvvuvky7pj21nk0f20yk.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:07:08 GMT</pubDate>
</item>
<item>
<title>[CV] VideoAgent: Long-form Video Understanding with Large Language Model as Agent 网页链接 提出了一种新的基于Agent的系统VideoAgent，用于长视频理解。该...</title>
<link>https://weibo.com/1402400261/O5FFDAV2O</link>
<guid>https://weibo.com/1402400261/O5FFDAV2O</guid>
<content:encoded><![CDATA[
<div> 大型语言模型(LLM)、视觉语言模型(VLM)、对比语言-图像模型(CLIP)、长视频理解、Agent、交互式推理、零样本准确率、EgoSchema、NExT-QA、效率。

总结:<br /><br />
研究提出了基于Agent的VideoAgent系统，以大型语言模型(LLM)为中心Agent，通过交互式推理和规划来理解长视频。利用视觉语言模型(VLM)和对比语言-图像模型(CLIP)来提取和转换视觉信息。实验结果显示，VideoAgent在EgoSchema和NExT-QA基准测试中表现出色，零样本准确率分别达到54.1%和71.3%，同时仅平均使用8.4和8.2帧。这表明以Agent为基础的方法在长视频理解领域具有潜在的潜力，效率和效果优于现有方法。 <div>
[CV] VideoAgent: Long-form Video Understanding with Large Language Model as Agent  <br /><a href="https://arxiv.org/abs/2403.10517"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出了一种新的基于Agent的系统VideoAgent，用于长视频理解。该系统以大型语言模型(LLM)作为中心Agent，通过迭代式识别和汇总关键信息以回答问题，利用视觉语言模型(VLM)和对比语言-图像模型(CLIP)作为工具提取和转换视觉信息。该方法模仿人类理解长视频的认知过程，重在交互式推理和规划而非直接处理长期视觉输入。实验结果显示，VideoAgent在EgoSchema和NExT-QA基准测试中分别取得了54.1%和71.3%的零样本准确率，仅平均使用8.4和8.2帧，效率和效果均优于现有最先进方法。本研究突显了以Agent为基础的方法在推进长视频理解方面的潜力。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvvq9ed7qj214o1m0dxb.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvvq9rvh2j21ck0t612p.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvvqaegkpj21c80nuqaz.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvvqb1w9ij21c81c4x0m.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 22:02:42 GMT</pubDate>
</item>
<item>
<title>[LG] Understanding the Double Descent Phenomenon in Deep Learning 网页链接 解析了深度学习中的“双重下降”现象，这一现象与传统机器学习理论相悖，即超参...</title>
<link>https://weibo.com/1402400261/O5FCWiOLD</link>
<guid>https://weibo.com/1402400261/O5FCWiOLD</guid>
<content:encoded><![CDATA[
<div> 关键词: 双重下降现象, 深度学习, 统计学习, 泛化误差, 归纳偏差, 梯度下降, 超参数化模型, 线性模型, 超参数化优化, 神经网络

总结:<br /><br />
本文解析了深度学习中的双重下降现象，即超参数化模型在数据插值点之后继续增加复杂度，测试误差反而降低。文章首先梳理了经典统计学习中的泛化误差概念，引入了双重下降现象。接着讨论了归纳偏差在选择平滑经验风险最小化解中的关键作用，特别是梯度下降在有多个解的情形下偏向于某些解的隐性特性。进一步通过两个线性模型具体探讨了双重下降的原因，并回顾了相关研究，如超参数化优化和神经网络中的拥塞转换现象。文章深入剖析了深度学习中的泛化行为，为理解深度学习提供了重要见解。 <div>
[LG] Understanding the Double Descent Phenomenon in Deep Learning  <br /><a href="https://arxiv.org/abs/2403.10459"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />解析了深度学习中的“双重下降”现象，这一现象与传统机器学习理论相悖，即超参数化模型在数据插值点之后继续增加复杂度，测试误差反而降低。文中首先梳理了经典统计学习中的泛化误差概念，并以此引入双重下降现象。接着，讨论了归纳偏差在选择平滑经验风险最小化解中的关键作用，特别是梯度下降在有多个解的情形下偏向于某些解的隐性特性。最后，文章通过两个线性模型具体探讨了双重下降的原因，并回顾了相关研究，如超参数化优化和作为物理系统的神经网络中的拥塞转换(jamming transition)现象。本文对于理解深度学习中的泛化行为提供了深刻见解。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvvjbzd2yj212s1ie14m.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvvjcgs1sj21640dywh6.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvvjcwillj216m0imjvr.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvvjdc28rj21680fu0vf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:56:03 GMT</pubDate>
</item>
<item>
<title>通过结合经典推测性解码与Medusa方法的优势，提出一种新的单模型推测性解码策略“循环起草器”(ReDrafter)，采用循环依赖设计的轻量级草稿头和动态树注意力算法...</title>
<link>https://weibo.com/1402400261/O5Ftyf0Gw</link>
<guid>https://weibo.com/1402400261/O5Ftyf0Gw</guid>
<content:encoded><![CDATA[
<div> 关键词：推测性解码，Medusa方法，单模型，循环起草器，循环依赖设计，轻量级草稿头，动态树注意力算法，推断延迟，模型部署，优势

<br /><br />总结:
本文提出了一种新的单模型推测性解码策略“循环起草器”(ReDrafter)，结合经典推测性解码与Medusa方法，采用循环依赖设计的轻量级草稿头和动态树注意力算法。该方法有效降低了大型语言模型的推断延迟，简化了模型部署，具有显著优势。研究结果表明，“循环起草器”能够在大型语言模型中表现出色，为实际应用提供了新的思路和可能性。 <div>
通过结合经典推测性解码与Medusa方法的优势，提出一种新的单模型推测性解码策略“循环起草器”(ReDrafter)，采用循环依赖设计的轻量级草稿头和动态树注意力算法，有效降低了大型语言模型的推断延迟，简化了模型部署，具有实际应用中的显著优势。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Recurrent Drafter for Fast Speculative Decoding in Large Language Models》A Zhang, C Wang, Y Wang, X Zhang, Y Cheng [Apple] (2024) <a href="https://arxiv.org/abs/2403.09919"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvulnyqnwj218k0tqang.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvuloc2kcj21gq12edl5.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvuloksbtj21ho0xu4a2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvulons0hj21hc0o2n4k.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvuv4qsh0j21gy0mcjyf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvuumqosxj20vh0k7diu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvuv5fakoj21hg0tiqbd.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:32:55 GMT</pubDate>
</item>
<item>
<title>[CL]《Recurrent Drafter for Fast Speculative Decoding in Large Language Models》A Zhang, C Wang, Y Wang, X Zhang, Y Cheng [Apple] (2024) 网页链接 #机...</title>
<link>https://weibo.com/1402400261/O5FtvAoqi</link>
<guid>https://weibo.com/1402400261/O5FtvAoqi</guid>
<content:encoded><![CDATA[
<div> 大语言模型，高效解码，快速推测，反复草案，苹果，研究，技术，人工智能，科技，语言处理

<br /><br />总结:
本文介绍了一种在大型语言模型中进行快速推测解码的方法，称为“Recurrent Drafter”。该方法通过反复草案的方式，利用循环神经网络来提高解码效率和速度。研究是由苹果公司的张、王和程等人共同完成的，对人工智能和语言处理技术领域具有重要意义。通过该方法，可以在大语言模型中实现高效的快速推测，为科技领域带来新的突破。 <div>
[CL]《Recurrent Drafter for Fast Speculative Decoding in Large Language Models》A Zhang, C Wang, Y Wang, X Zhang, Y Cheng [Apple] (2024) <a href="https://arxiv.org/abs/2403.09919"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvulnyqnwj218k0tqang.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvuloc2kcj21gq12edl5.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvuloksbtj21ho0xu4a2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvulons0hj21hc0o2n4k.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvuv4qsh0j21gy0mcjyf.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvuumqosxj20vh0k7diu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvuv5fakoj21hg0tiqbd.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:32:48 GMT</pubDate>
</item>
<item>
<title>论文提出检索增强微调(RAFT)策略，通过训练大型语言模型区分并利用相关文档来提升特定领域内的问题回答能力，创新地解决了模型在面对分心文档时的适应性问题，并...</title>
<link>https://weibo.com/1402400261/O5FmW7B1p</link>
<guid>https://weibo.com/1402400261/O5FmW7B1p</guid>
<content:encoded><![CDATA[
<div> 增强微调, 检索, 大型语言模型, 问题回答, 领域特定, 适应性问题, 数据集, 有效性, 传统微调方法

<br /><br />总结:
本论文提出了检索增强微调（RAFT）策略，该策略通过训练大型语言模型，在特定领域内区分并利用相关文档，提升问题回答能力。研究创新地解决了模型在面对分心文档时的适应性问题，经多个数据集验证，RAFT策略优于传统微调方法，具有更好的有效性。这一研究结果对语言模型领域具有重要意义，为解决领域特定问题提供了一种新的探索思路。 <div>
论文提出检索增强微调(RAFT)策略，通过训练大型语言模型区分并利用相关文档来提升特定领域内的问题回答能力，创新地解决了模型在面对分心文档时的适应性问题，并在多个数据集上验证了其优于传统微调方法的有效性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《RAFT: Adapting Language Model to Domain Specific RAG》T Zhang, S G. Patil, N Jain, S Shen, M Zaharia, I Stoica, J E. Gonzalez [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2403.10131"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvud0zq50j20ma13eqcp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvud1htzhj21p60mgdpq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvud1p1qfj21oq0u8k08.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvud1v4naj21p010cqhm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvudzt6mpj212b0ckgo5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvudztbeqj212c0hewhu.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:16:37 GMT</pubDate>
</item>
<item>
<title>[CL]《RAFT: Adapting Language Model to Domain Specific RAG》T Zhang, S G. Patil, N Jain, S Shen, M Zaharia, I Stoica, J E. Gonzalez [UC Berkeley] (202...</title>
<link>https://weibo.com/1402400261/O5FmNEWOr</link>
<guid>https://weibo.com/1402400261/O5FmNEWOr</guid>
<content:encoded><![CDATA[
<div> 领域自适应语言模型，RAFT，特定领域RAG，UC Berkeley，语言模型

总结:<br /><br />本文介绍了一种新颖的方法，称为RAFT，用于将通用语言模型适应到特定领域的RAG中。研究人员提出了一种新颖的自适应机制，以提高领域特定问答生成的性能。他们在UC Berkeley进行了实验，并展示了该方法的有效性。这项工作对于提高领域特定语言模型的性能具有重要意义。 <div>
[CL]《RAFT: Adapting Language Model to Domain Specific RAG》T Zhang, S G. Patil, N Jain, S Shen, M Zaharia, I Stoica, J E. Gonzalez [UC Berkeley] (2024) <a href="https://arxiv.org/abs/2403.10131"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvud0zq50j20ma13eqcp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnvud1htzhj21p60mgdpq.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvud1p1qfj21oq0u8k08.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnvud1v4naj21p010cqhm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnvudzt6mpj212b0ckgo5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvudztbeqj212c0hewhu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 21:16:18 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.18)》 爱可可微博热门分享(3.18) [图片]</title>
<link>https://weibo.com/1402400261/O5CuSxxnf</link>
<guid>https://weibo.com/1402400261/O5CuSxxnf</guid>
<content:encoded><![CDATA[
<div> 微博, 热门分享, 爱可可, 3.18, 热门话题, 社交媒体, 网络流行, 网友讨论, 最新动态

<br /><br />总结:
3月18日，爱可可的微博帖子成为了热门分享内容，引发了广泛讨论。网友们热烈讨论了该话题，纷纷在社交媒体上分享并转发。这反映了爱可可在网络流行中的重要地位，也展示了热门话题如何在网上引起轰动。 <div>
《爱可可微博热门分享(3.18)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405013396264190226"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.18)</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnvhpqexuoj20og0drabu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 13:57:57 GMT</pubDate>
</item>
<item>
<title>【Mistral-7b模型DPO微调实战】《Fine-tune a Mistral-7b model with Direct Preference Optimization | by Maxime Labonne | Towards Data Science》 网页链接 ...</title>
<link>https://weibo.com/1402400261/O5zuA01tt</link>
<guid>https://weibo.com/1402400261/O5zuA01tt</guid>
<content:encoded><![CDATA[
<div> 模型微调、Mistral-7b、DPO、实战、Direct Preference Optimization、Maxime Labonne、Towards Data Science  

<br />总结: 本文介绍了如何使用Direct Preference Optimization (DPO)技术对Mistral-7b模型进行微调。作者详细讲解了DPO的原理和操作步骤，以及如何在实战中应用这一技术来提高模型性能。通过对模型进行微调，可以更好地适应特定任务需求，提升模型的表现效果。文章为想要了解和应用DPO微调的人提供了有用的指导和思路。 <div>
【Mistral-7b模型DPO微调实战】《Fine-tune a Mistral-7b model with Direct Preference Optimization | by Maxime Labonne | Towards Data Science》 <a href="https://towardsdatascience.com/fine-tune-a-mistral-7b-model-with-direct-preference-optimization-708042745aac"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnv4fpp48tj20u00vqn3w.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnv4g7mtn0j212w0ecac3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 06:18:58 GMT</pubDate>
</item>
<item>
<title>【Grok-1开源：Musk的AI大众化还是对OpenAI的"报复"?】- Grok-1是由Elon Musk的xAI公司开发的大型语言模型，具有3140亿个参数。 - xAI决定以Apache 2.0许可证的...</title>
<link>https://weibo.com/1402400261/O5zt6FiHP</link>
<guid>https://weibo.com/1402400261/O5zt6FiHP</guid>
<content:encoded><![CDATA[
<div> 关键词: Grok-1, Elon Musk, xAI, 开源, Apache 2.0, Mixture-of-Experts, AI技术, 创新, OpenAI, 大众化

总结:<br /><br />Elon Musk的xAI公司开发了3140亿参数的大型语言模型Grok-1，并以Apache 2.0许可证开源发布其基础模型权重和网络架构。这一举措旨在推动AI技术的大众化，提高可及性，鼓励创新和知识共享。Grok-1采用Mixture-of-Experts架构，提高效率，但性能仍落后于GPT-4。开源Grok-1引发了关于Musk对OpenAI的“反击”和AI公司商业模式的讨论，但也有利于促进AI技术的发展，体现了AI领域复杂的利益博弈。 Musk的举动反映了他对于开源理念的批评，致力于推动AI透明发展的理念。Gro-1作为大型语言模型的技术细节的披露也具有一定的创新性，探索了AI公司通常保密的内容。 <div>
【Grok-1开源：Musk的AI大众化还是对OpenAI的"报复"?】<br />- Grok-1是由Elon Musk的xAI公司开发的大型语言模型，具有3140亿个参数。  <br />- xAI决定以Apache 2.0许可证的形式开源发布Grok-1的基础模型权重和网络架构。  <br />- 这是Grok-1预训练阶段的原始基础模型检查点，未经过任何特定任务的微调。  <br />- Grok-1采用Mixture-of-Experts(MoE)架构，每个token只激活25%的权重，提高了效率。  <br />- xAI团队使用自主开发的基于Kubernetes、Rust和JAX的定制训练栈，在短短4个月内从头训练出Grok。  <br />- 开源Grok-1是为了促进AI技术的大众化，提高可及性，鼓励创新和知识共享。  <br />- 这一举措反映了Musk对OpenAI等公司背离开源理念的批评，体现了他推动AI透明发展的理念。  <br /><br />思考：  <br />- 披露了Grok-1作为一款大型语言模型的技术细节，这在AI公司通常都是保密的，具有一定的创新性。  <br />- 尽管Grok-1的性能优于GPT-3.5，但仍落后于GPT-4等顶尖模型，引发了网友对其实际能力的质疑。  <br />- 有观点认为，开源Grok-1只是Musk对OpenAI的一次"反击"，质疑其真正目的是否在于推动AI大众化。  <br />- 另一方面，也有观点认为，即使出于某种动机，开源本身就是一种进步，有利于促进AI技术的发展。  <br />- 引发了大众对AI公司商业模式、开源与闭源码之争的深入思考，体现了AI领域复杂的利益博弈。<br />《Open Release of Grok-1》 <a href="https://x.ai/blog/grok-os"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnv4cloolbj210a0u0wl5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 06:15:21 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《Dynamic Adapter Meets Prompt Tuning:Parameter-Efficient Transfer Learning for Point Cloud Analysis》(CVPR 2024) GitHub: github.com...</title>
<link>https://weibo.com/1402400261/O5zpVkm35</link>
<guid>https://weibo.com/1402400261/O5zpVkm35</guid>
<content:encoded><![CDATA[
<div> Dynamic Adapter, Prompt Tuning, Parameter-Efficient, Transfer Learning, Point Cloud Analysis, Dense Predictions, Vision Transformer, Convolutional Multi-scale Feature Interaction, Pretrained Model Merging, Decompiling Binary Code, Large Language Models, Open Graph Foundation Models, Graph Structure Learning, Variational Learning, Deep Networks, Low-bit Diffusion Model Quantization, Selective Finetuning

<br /><br />总结:《Dynamic Adapter Meets Prompt Tuning: Parameter-Efficient Transfer Learning for Point Cloud Analysis》提出了一种参数高效的迁移学习方法，通过动态适配器和提示调整技术实现点云分析。《ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature Interaction for Dense Predictions》结合了视觉Transformer和卷积多尺度特征交互，用于密集预测任务。《Training-free Pretrained Model Merging》介绍了一种无需训练的预训练模型融合方法。《LLM4Decompile: Decompiling Binary Code with Large Language Models》展示了使用大型语言模型进行反汇编的方法。《OpenGraph: Towards Open Graph Foundation Models》提出了开放图基础模型的概念。《GraphEdit: Large Language Models for Graph Structure Learning》利用大型语言模型学习图结构信息。《Variational Learning is Effective for Large Deep Networks》表明变分学习对于大型深度网络是有效的。《QuEST: Low-bit Diffusion Model Quantization via Efficient Selective Finetuning》提出了一种低比特扩散模型量化方法，通过高效的选择性微调实现。 <div>
几篇论文实现代码：<br />《Dynamic Adapter Meets Prompt Tuning:<br />Parameter-Efficient Transfer Learning for Point Cloud Analysis》(CVPR 2024) GitHub: github.com/LMD0311/DAPT [fig3] <br />《ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature Interaction for Dense Predictions》(CVPR 2024) GitHub: github.com/Traffic-X/ViT-CoMer [fig4] <br />《Training-free Pretrained Model Merging》(CVPR 2024) GitHub: github.com/zju-vipa/training_free_model_merging<br />《LLM4Decompile: Decompiling Binary Code with Large Language Models》(2024) GitHub: github.com/albertan017/LLM4Decompile [fig1]<br />《OpenGraph: Towards Open Graph Foundation Models》(2024) GitHub: github.com/HKUDS/OpenGraph [fig2] <br />《GraphEdit: Large Language Models for Graph Structure Learning》(2024) GitHub: github.com/HKUDS/GraphEdit [fig5] <br />《Variational Learning is Effective for Large Deep Networks》(2024) GitHub: github.com/team-approx-bayes/ivon<br />《QuEST: Low-bit Diffusion Model Quantization via Efficient Selective Finetuning》(2024) GitHub: github.com/hatchetProject/QuEST<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnv2v4e953j243r4v5e82.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnv32rj34xj224i0dan57.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnv36w50wqj21cy0k0gsb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnv3ik1f5wj21ch09yq7y.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnv3l0345lj248p1mvqv6.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 06:07:30 GMT</pubDate>
</item>
<item>
<title>'《AI 辅助编程：借助 GitHub Copilot 和 ChatGPT 掌握 Python》 - 《Learn AI-Assisted Python Programming: With GitHub Copilot and ChatGPT》一书的非官方翻...</title>
<link>https://weibo.com/1402400261/O5znFfuof</link>
<guid>https://weibo.com/1402400261/O5znFfuof</guid>
<content:encoded><![CDATA[
<div> 辅助编程、GitHub Copilot、ChatGPT、Python、非官方翻译、学习、人工智能、技术、程序员、工具

<br /><br />总结:
《AI 辅助编程：借助 GitHub Copilot 和 ChatGPT 掌握 Python》一书的非官方翻译介绍了如何利用人工智能工具GitHub Copilot和ChatGPT来提升Python编程技能。通过本书，读者可以学习如何更高效地使用这些工具，从而提高编程的效率和质量。GitHub Copilot能够自动生成代码建议，提供实时的智能编程支持，而ChatGPT则可以帮助解决编程中的困惑和问题。对于想要深入了解人工智能在编程领域的应用的程序员和技术爱好者来说，本书是一本值得一读的教材。 <div>
'《AI 辅助编程：借助 GitHub Copilot 和 ChatGPT 掌握 Python》 - 《Learn AI-Assisted Python Programming: With GitHub Copilot and ChatGPT》一书的非官方翻译' GitHub: github.com/cssmagic/Learn-AI-Assisted-Python-Programming <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnv3yhaqhwj20u011ljuh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 06:01:56 GMT</pubDate>
</item>
<item>
<title>【Lite-Sora是一个旨在复制 Sora 的开源项目，致力于通过简洁易懂的代码，探索和提高视频生成算法的基础框架】'Lite-Sora - An initiative to replicate Sora' G...</title>
<link>https://weibo.com/1402400261/O5zl1iU2Y</link>
<guid>https://weibo.com/1402400261/O5zl1iU2Y</guid>
<content:encoded><![CDATA[
<div> Sora, 开源项目, Lite-Sora, 视频生成算法, 基础框架, 探索, 提高, 简洁, 易懂, 代码

<br /><br />总结：
Lite-Sora是一个旨在复制Sora的开源项目，致力于通过简洁易懂的代码，探索和提高视频生成算法的基础框架。该项目旨在提供一个更简单、更易理解的代码实现，以帮助研究人员和开发者进一步探索视频生成算法。通过这一努力，Lite-Sora有望为视频算法领域的发展做出贡献，并促进相关技术的提升和应用。 <div>
【Lite-Sora是一个旨在复制 Sora 的开源项目，致力于通过简洁易懂的代码，探索和提高视频生成算法的基础框架】'Lite-Sora - An initiative to replicate Sora' GitHub: github.com/modelscope/lite-sora <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnv3rv4bkuj212l0u0gq0.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:55:25 GMT</pubDate>
</item>
<item>
<title>【视觉语言模型架构大列表】’Awesome Vision Language Model Architectures - Famous Vision Language Models and Their Architectures' GitHub: github.com/go...</title>
<link>https://weibo.com/1402400261/O5zjq0Nxe</link>
<guid>https://weibo.com/1402400261/O5zjq0Nxe</guid>
<content:encoded><![CDATA[
<div> 关键词: 视觉语言模型架构, GitHub, 模型, 架构, 论文, 研究, 深度学习, 计算机视觉

视觉语言模型架构大列表是一个GitHub项目，收集了一些知名的视觉语言模型以及它们的架构。这些模型包括了通过深度学习技术在计算机视觉领域取得了显著成就的一些论文和研究工作。该项目为研究人员提供了一个参考和学习的资源，帮助他们更好地了解和应用视觉语言模型的相关技术和架构。如果对视觉语言模型感兴趣的研究人员可以通过GitHub项目找到各种信息和资料，加深对该领域的理解和应用。<br /><br />总结:视觉语言模型架构大列表是一个收集了知名视觉语言模型及其架构的GitHub项目，为研究人员提供了丰富的参考和学习资源，帮助他们更好地应用深度学习技术在计算机视觉领域。 <div>
【视觉语言模型架构大列表】’Awesome Vision Language Model Architectures - Famous Vision Language Models and Their Architectures' GitHub: github.com/gokayfem/Awesome-VLM-Architectures <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnv3np7gf4j211p0u079s.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:51:28 GMT</pubDate>
</item>
<item>
<title>【ThreePipe：基于 Three.js 的3D渲染框架，致力于渲染、模块化和可扩展性】'ThreePipe - A 3D viewer framework built on top of three.js with a focus on ren...</title>
<link>https://weibo.com/1402400261/O5zia1jpe</link>
<guid>https://weibo.com/1402400261/O5zia1jpe</guid>
<content:encoded><![CDATA[
<div> ThreePipe、Three.js、3D、渲染、模块化、可扩展性、GitHub、框架、渲染器、扩展性

<br /><br />总结:
ThreePipe是一个基于Three.js的3D查看器框架，专注于渲染、模块化和可扩展性。它提供了一个强大的渲染引擎，允许用户创建各种3D效果。框架采用模块化设计，使得用户可以轻松地扩展和定制功能。同时，ThreePipe具有良好的可扩展性，可以满足不同项目的需求。用户可以在GitHub上找到该项目，并利用其强大功能来实现各种3D渲染效果。Overall, ThreePipe是一个强大而灵活的3D渲染框架，适用于各种项目和需求。 <div>
【ThreePipe：基于 Three.js 的3D渲染框架，致力于渲染、模块化和可扩展性】'ThreePipe - A 3D viewer framework built on top of three.js with a focus on rendering, modularity and extensibility.' GitHub: github.com/repalash/threepipe <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%233D%23"><span class="surl-text">#3D#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnv3kip681j20zr0u00yp.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:48:22 GMT</pubDate>
</item>
<item>
<title>【Beyond Jupyter 是一个用于聚焦机器学习应用的软件设计资源/课程，旨在帮助软件设计人员以更原则的方式实现机器学习项目】'Beyond Jupyter - Software design ...</title>
<link>https://weibo.com/1402400261/O5zfKpymb</link>
<guid>https://weibo.com/1402400261/O5zfKpymb</guid>
<content:encoded><![CDATA[
<div> GitHub, Beyond Jupyter, 软件设计资源, 课程, 机器学习应用, 原则, 实现, 项目

<br /><br />总结:
"Beyond Jupyter - Software design principles for machine learning applications" 是一个旨在帮助软件设计人员以更原则的方式实现机器学习项目的课程和软件设计资源。通过 GitHub 上的项目，可以了解和学习如何聚焦机器学习应用，以更高效和可靠的方式设计和实现项目。这个资源是为那些希望深入了解机器学习应用的软件设计人员而设计的，帮助他们掌握关键的设计原则和方法，提升项目的质量和效率。通过 Beyond Jupyter，软件设计人员可以更好地理解如何应用这些原则，进而在实际项目中取得更好的成果。这个资源将成为学习和实践机器学习应用开发的重要指南，为软件设计人员提供了更多设计优化的思路和技巧，帮助他们在机器学习领域取得更大的成功。 <div>
【Beyond Jupyter 是一个用于聚焦机器学习应用的软件设计资源/课程，旨在帮助软件设计人员以更原则的方式实现机器学习项目】'Beyond Jupyter - Software design principles for machine learning applications' GitHub: github.com/aai-institute/beyond-jupyter <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnv3dnznbdj20u60u043r.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:42:25 GMT</pubDate>
</item>
<item>
<title>【Mechanoid：用于嵌入系统上构建和运行 WebAssembly 应用的开放源框架，有助于创建更安全的和可扩展的应用】'Mechanoid - Mechanoid is a framework for WebAss...</title>
<link>https://weibo.com/1402400261/O5zeX4TwZ</link>
<guid>https://weibo.com/1402400261/O5zeX4TwZ</guid>
<content:encoded><![CDATA[
<div> 嵌入系统、WebAssembly、开放源框架、安全、可扩展、应用、Mechanoid、GitHub、embedded systems、应用程序

<br /><br />总结:
Mechanoid是一个用于嵌入式系统上构建和运行WebAssembly应用的开放源框架。它有助于创建更安全和可扩展的应用程序，通过GitHub可以找到该项目。Mechanoid为嵌入式系统提供了一种新的方式来构建和运行WebAssembly应用，从而提高了系统的安全性和可扩展性。 <div>
【Mechanoid：用于嵌入系统上构建和运行 WebAssembly 应用的开放源框架，有助于创建更安全的和可扩展的应用】'Mechanoid - Mechanoid is a framework for WebAssembly applications on embedded systems.' GitHub: github.com/hybridgroup/mechanoid <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23WebAssembly%23"><span class="surl-text">#WebAssembly#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnv3cb2vxcj20x50u0n20.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:40:28 GMT</pubDate>
</item>
<item>
<title>【Developer Portfolio：软件开发者的个人网站，使用 Next.js 和 Tailwind CSS，帮助用户展示他们的代码和技能】'Developer Portfolio - Software Developer Por...</title>
<link>https://weibo.com/1402400261/O5zdocRSc</link>
<guid>https://weibo.com/1402400261/O5zdocRSc</guid>
<content:encoded><![CDATA[
<div> Next.js, Tailwind CSS, Developer Portfolio, Software Developer, Showcase, GitHub

<br /><br />总结: 该软件开发者个人网站采用了 Next.js 和 Tailwind CSS 技术，帮助用户展示其代码和技能。用户可以通过该网站展示自己作为软件开发者的工作和技能，同时在 GitHub 上查看源代码。 <div>
【Developer Portfolio：软件开发者的个人网站，使用 Next.js 和 Tailwind CSS，帮助用户展示他们的代码和技能】'Developer Portfolio - Software Developer Portfolio Website built with next.js and tailwind CSS that helps you showcase your work and skills as a software developer.' GitHub: github.com/said7388/developer-portfolio <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnv3885smgj21f60ol0wr.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Mon, 18 Mar 2024 05:36:37 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.2...</title>
<link>https://weibo.com/1402400261/O5wrb274Y</link>
<guid>https://weibo.com/1402400261/O5wrb274Y</guid>
<content:encoded><![CDATA[
<div> 关键词: 大语言模型, 系统性, 实践性, 全彩印刷, 作者杨青, 经验, 训练, 干货, 度小满, 轩辕

总结:<br /><br />
本书《大语言模型：原理与工程实践(全彩)》揭开大语言模型的神秘面纱，重点在于系统性和实践性。作者杨青是度小满轩辕大模型负责人，具有丰富的训练经验，将这些经验融入书中，引导读者深入理解大语言模型的内在机理和应用实践。书中以全彩印刷方式呈现，配有代码示例，干货满满，让读者能够从中获益良多。欢迎参与转发并评论，有机会赢得3本《大语言模型：原理与工程实践(全彩)》。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:32:21 GMT</pubDate>
</item>
<item>
<title>今日推介(第1348期)：用于LLM近无损生成式推理高效KV缓存压缩方案、分散专家混合实现、面向自动驾驶的广义预测模型、半参数化token-sequence协同监督、大规模监...</title>
<link>https://weibo.com/1402400261/O5wqWCDe7</link>
<guid>https://weibo.com/1402400261/O5wqWCDe7</guid>
<content:encoded><![CDATA[
<div> LLM、生成式推理、KV缓存压缩、分散专家混合、广义预测模型、自动驾驶、半参数化token-sequence、协同监督、大规模监控、人工智能修改内容

<br /><br />总结:
本文介绍了几种新颖的技术方案，包括用于LLM近无损生成式推理高效KV缓存压缩方案、分散专家混合实现、面向自动驾驶的广义预测模型、半参数化token-sequence协同监督和大规模监控人工智能修改内容等。这些技术方案在不同领域具有广泛的应用前景，有助于提高推理和预测的精度和效率，推动自动驾驶、监控和人工智能领域的发展。 <div>
今日推介(第1348期)：用于LLM近无损生成式推理高效KV缓存压缩方案、分散专家混合实现、面向自动驾驶的广义预测模型、半参数化token-sequence协同监督、大规模监控人工智能修改内容 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687551508"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.18)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnuqxnm0mij20k009egn1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnuqxqs7cwj20k00ccwg4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnuqxyljvsj20k00b4dhx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnuqy42myvj20k00llq53.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnuqy7wavlj20k00aa0ts.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:31:46 GMT</pubDate>
</item>
<item>
<title>[RO] SemGauss-SLAM: Dense Semantic Gaussian Splatting SLAM 网页链接 提出SemGauss-SLAM，首个利用3D高斯表示的语义SLAM系统，解决了传统语义SLAM系统在未知...</title>
<link>https://weibo.com/1402400261/O5wmb3Pkm</link>
<guid>https://weibo.com/1402400261/O5wmb3Pkm</guid>
<content:encoded><![CDATA[
<div> 提取关键词：
SemGauss-SLAM, 3D高斯表示, 语义SLAM系统, 语义信息, 地图存储, 特征级损失函数, 语义关联, 累积漂移, Replica, ScanNet

总结:
<br /><br />总结:
SemGauss-SLAM是首个利用3D高斯表示的语义SLAM系统，解决了传统语义SLAM系统在未知区域预测和地图存储需求大的限制。系统通过将语义特征嵌入到3D高斯表示中，并引入特征级损失函数来更新3D高斯表示，提供更高层次的优化指导。另外，系统还引入了基于语义关联的束调整，以减少累积漂移并提高重建精度。经过在Replica和ScanNet数据集上的测试，SemGauss-SLAM在映射和追踪精度、新视角语义合成和3D语义映射方面均表现优于现有的密集语义SLAM方法。SemGauss-SLAM的提出为语义SLAM系统的发展带来了新的可能性。 <div>
[RO] SemGauss-SLAM: Dense Semantic Gaussian Splatting SLAM  <br /><a href="https://arxiv.org/abs/2403.07494"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出SemGauss-SLAM，首个利用3D高斯表示的语义SLAM系统，解决了传统语义SLAM系统在未知区域预测和地图存储需求大的限制。SemGauss-SLAM通过将语义特征嵌入到3D高斯表示中，有效编码了语义信息，实现了精确的语义场景表示。此外， 提出了特征级损失函数来更新3D高斯表示，以提供更高层次的优化指导。系统还引入了基于语义关联的束调整，以减少累积漂移并提高重建精度。在Replica和ScanNet数据集上的测试结果显示，SemGauss-SLAM在映射和追踪精度、新视角语义合成和3D语义映射方面均优于现有的密集语义SLAM方法。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuqlyt63fj21861jk1cb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuqlyraxbj21d00x6tjo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuqlysfhfj21cc11ok6d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuqlyqecqj21cg0vsakf.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:20:02 GMT</pubDate>
</item>
<item>
<title>[CV] StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control 网页链接 介绍了一种名为StreamMultiDiffusion的新型实时交...</title>
<link>https://weibo.com/1402400261/O5wk5pWuI</link>
<guid>https://weibo.com/1402400261/O5wk5pWuI</guid>
<content:encoded><![CDATA[
<div> StreamMultiDiffusion, 实时交互式生成, 区域语义控制, 多提示流批处理, 高质量图像生成, 语义调色板, 用户交互性, 推断速度, 实时图像生成, 手绘区域图像

<br /><br />总结:
StreamMultiDiffusion是一种新型实时交互式文本到图像生成框架，通过稳定快速推断技术和多提示流批处理架构，实现了基于区域的语义控制下的实时图像生成。该框架速度比现有解决方案快10倍，在单个GPU上可达到1.57 FPS的生成速度。它结合了高质量图像生成和强大的批处理能力，提供了名为"语义调色板"的新范式，用户可实时生成具有预设语义意义的手绘区域图像。StreamMultiDiffusion解决了之前模型在提高推断速度与增强用户交互性之间的不兼容问题，为实时交互式生成领域带来了重要的技术突破。 <div>
[CV] StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control  <br /><a href="https://arxiv.org/abs/2403.09055"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为StreamMultiDiffusion的新型实时交互式文本到图像生成框架。该框架解决了之前模型在提高推断速度与增强用户交互性之间的不兼容问题。通过稳定快速推断技术并将模型重新架构为多提示流批处理架构，StreamMultiDiffusion实现了基于区域的语义控制下的实时图像生成，速度比现有解决方案快10倍，且在单个GPU上达到1.57 FPS的生成速度。此框架的创新之处在于将高质量图像生成与强大的批处理能力相结合，提供了名为"语义调色板"的新范式，用户可实时生成具有预设语义意义的手绘区域图像。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuqgnrbgfj211u1ik4ek.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuqgnpwqij214i0r8gtu.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuqgno87oj214g0j0wj9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:14:53 GMT</pubDate>
</item>
<item>
<title>[LG] UPS: Towards Foundation Models for PDE Solving via Cross-Modal Adaptation 网页链接 介绍了一种名为UPS(Unified PDE Solver)的方法，用于解决不同空间...</title>
<link>https://weibo.com/1402400261/O5wgPnoUr</link>
<guid>https://weibo.com/1402400261/O5wgPnoUr</guid>
<content:encoded><![CDATA[
<div> UPS, PDE Solver, 预训练大型语言模型, 跨模态适应, 多任务学习, PDEBench, 基础模型, 计算效率, 模态对齐, 分辨率

<br /><br />总结:
本文介绍了一种名为UPS(Unified PDE Solver)的方法，用于解决不同空间时间偏微分方程(PDE)。UPS通过将预训练大型语言模型适应到PDE求解中，实现了在各种域、维度和分辨率上有效、数据高效的求解。该方法采用两阶段的跨模态适应过程，结合模态对齐和多任务学习的概念，使得UPS在使用的训练样本较少的情况下仍能获得强大的实证结果。在PDEBench的1D和2D数据集上，UPS超越了现有基准，在10个任务中取得了8个最佳成绩，并能够通过少量样本迁移到不同的PDE家族、系数和分辨率。这项工作为PDE求解领域的基础模型建设迈出了重要一步，并展示了在计算效率方面的优势。UPS方法的提出为PDE求解领域注入了新的活力和创新思路，有望进一步推动该领域的发展。 <div>
[LG] UPS: Towards Foundation Models for PDE Solving via Cross-Modal Adaptation  <br /><a href="https://arxiv.org/abs/2403.07187"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为UPS(Unified PDE Solver)的方法，用于解决不同空间时间偏微分方程(PDE)。UPS通过将预训练大型语言模型(LLM )适应到PDE求解中，实现了在各种域、维度和分辨率上有效、数据高效的求解。两阶段的跨模态适应过程利用了模态对齐和多任务学习的概念，使得UPS在使用的训练样本远少于以往方法的情况下，仍能获得强大的实证结果。特别地，UPS在PDEBench的1D和2D数据集上超越了现有基准，实现了10个任务中8个的最佳成绩，并能够通过少量样本迁移到不同的PDE家族、系数和分辨率。这项工作为PDE求解领域的基础模型建设迈出了重要一步，并展示了在计算效率方面的优势。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuq8awiipj21as1jsh9j.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnuq8b8r02j21oo0tu7ji.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:06:51 GMT</pubDate>
</item>
<item>
<title>[CL] Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance 网页链接 深入探讨了字节对比编码(BPE)算法中压缩的重...</title>
<link>https://weibo.com/1402400261/O5wfamsiJ</link>
<guid>https://weibo.com/1402400261/O5wfamsiJ</guid>
<content:encoded><![CDATA[
<div> 压缩、BPE算法、0-gram语言模型、训练文档量、英文语言模型、下游任务、分词器、模型性能、生成任务、土耳其语

<br /><br />总结:
本文深入探讨了字节对比编码(BPE)算法在文本压缩中的重要性，并指出BPE实际上是一个潜在的0-gram语言模型。研究通过控制BPE的训练文档量，从100万份文档到零文档(即字符级的分词器)，并分别基于这些分词器预训练英文语言模型，在多个任务上进行微调。结果显示，分词器的压缩能力与模型的下游任务表现存在明显的相关性，压缩性能更好的分词器能显著提高模型整体性能。特别是在生成任务上，这种相关性更为显著，并且小模型比大模型更依赖高质量的分词。通过在土耳其语上的实验验证，研究证实这一结论不仅适用于英语，而且在跨语言上具有普适性。因此，构建更好的压缩分词器被认为是提升语言模型性能的有效途径。 <div>
[CL] Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance  <br /><a href="https://arxiv.org/abs/2403.06265"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />深入探讨了字节对比编码(BPE)算法中压缩的重要性，并指出其实为一个潜在的0-gram语言模型。研究通过控制BPE的训练文档量，从100万份文档到零文档(即字符级的分词器)，并分别基于这些分词器预训练英文语言模型，在多个任务上进行微调。结果显示，分词器的压缩能力与模型的下游任务表现存在明显的相关性，压缩性能更好的分词器能显著提高模型整体性能。此外，该相关性在生成任务上更为显著，并且小模型比大模型更依赖高质量的分词。通过在土耳其语上的实验验证，确认了这一结论不仅适用于英语，而是具有跨语言的普适性。研究表明，构建更好的压缩分词器是提升语言模型性能的有效途径。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuq42bb6ij213a1j0kb3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuq42d1ooj21580j2jur.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 22:02:46 GMT</pubDate>
</item>
<item>
<title>针对大规模语言模型(如ChatGPT)在科学同行评审中的应用，提出一种新的分布式GPT量化框架，通过极大似然估计结合特定形容词的使用频率，有效地监测并估计信息生态...</title>
<link>https://weibo.com/1402400261/O5wdcqM4V</link>
<guid>https://weibo.com/1402400261/O5wdcqM4V</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模语言模型、科学同行评审、分布式GPT量化、极大似然估计、特定形容词、信息生态系统、AI修改内容、使用频率、计算效率、高风险生态系统

总结:<br /><br />
这篇文章提出了一种新的分布式GPT量化框架，结合极大似然估计和特定形容词的使用频率，可以有效监测和估计大规模语言模型在信息生态系统中修改或生成内容的比例。这种方法计算效率高于现有方法，为理解和管理LLM在高风险信息生态系统中的影响提供了重要工具。作者通过在AI会议同行评审中的案例研究，展示了这种框架在实际应用中的效果，来自Stanford University & NEC Labs的研究团队对此进行了深入研究。 <div>
针对大规模语言模型(如ChatGPT)在科学同行评审中的应用，提出一种新的分布式GPT量化框架，通过极大似然估计结合特定形容词的使用频率，有效地监测并估计信息生态系统中AI修改或生成的内容比例，计算效率远超现有方法，对于理解和管理LLM在高风险信息生态系统中的影响提供了重要工具。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews》W Liang, Z Izzo, Y Zhang, H Lepp... [Stanford University &amp; NEC Labs] (2024) <a href="https://arxiv.org/abs/2403.07183"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupehnp17j20rm1beamr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupei7riyj20w40te7bm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupeildg5j21s60wyn62.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupeit8cej20vy0v4q9s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvs56mj20iz0h2wgv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupyvs6pij20j10f9taj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnupyvsbv7j20iz0g50ut.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupyvs1ouj20iz0bj759.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvrzpjj20iz0cjab9.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 21:57:54 GMT</pubDate>
</item>
<item>
<title>[CL]《Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews》W Liang, Z Izzo, Y Zhang, H Lepp.....</title>
<link>https://weibo.com/1402400261/O5wd9mRwc</link>
<guid>https://weibo.com/1402400261/O5wd9mRwc</guid>
<content:encoded><![CDATA[
<div> 关键词: 监测，AI修改内容，ChatGPT，会议审稿，规模，影响，案例研究，人工智能，会议，同行评审

总结:<br /><br />这篇文章是由斯坦福大学和NEC实验室的研究人员撰写的，旨在研究AI修改内容对人工智能会议审稿的影响。研究使用ChatGPT进行了案例研究，探讨了AI技术在会议审稿中的规模化应用。他们发现AI修改内容可能对同行评审过程产生影响，提出了一些监测和应对AI修改内容影响的建议。这项研究展示了AI技术在学术领域中的潜在影响，并呼吁对AI修改内容进行更加深入的研究和监测。 <div>
[CL]《Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews》W Liang, Z Izzo, Y Zhang, H Lepp... [Stanford University &amp; NEC Labs] (2024) <a href="https://arxiv.org/abs/2403.07183"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupehnp17j20rm1beamr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupei7riyj20w40te7bm.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupeildg5j21s60wyn62.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupeit8cej20vy0v4q9s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvs56mj20iz0h2wgv.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupyvs6pij20j10f9taj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnupyvsbv7j20iz0g50ut.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupyvs1ouj20iz0bj759.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvrzpjj20iz0cjab9.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnupyvs356j20jd0c80u1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnupyvs27ij20iz0df75s.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnupyvs9jej20iv0f575x.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnupyvsggfj20wa0krwh4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnupyvsr8zj20wj0knju5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 21:57:48 GMT</pubDate>
</item>
<item>
<title>提出一种半参数化token-sequence协同监督训练方法，通过同时利用参数化token嵌入空间和非参数化sequence嵌入空间的监督，显著提升了语言模型在信息检索任务中的...</title>
<link>https://weibo.com/1402400261/O5w1DlH5W</link>
<guid>https://weibo.com/1402400261/O5w1DlH5W</guid>
<content:encoded><![CDATA[
<div> 半参数化token-sequence、协同监督、训练方法、嵌入空间、信息检索、表现力、泛化能力、预测模式、局限<br />
<br />
提出的半参数化token-sequence协同监督训练方法结合了参数化token嵌入空间和非参数化sequence嵌入空间的优势，在信息检索任务中表现出显著的提升，并具备较强的泛化能力。这一方法突破了传统单一预测模式的局限，通过同时利用两种不同嵌入空间的监督，达到了更好的训练效果。提出的方法为语言模型的发展带来了新的思路和方法，为相关研究领域提供了有价值的参考。<br /><br />总结: <br />这篇文章介绍了一种半参数化token-sequence协同监督训练方法，通过结合参数化token嵌入空间和非参数化sequence嵌入空间的优势，提升了语言模型在信息检索任务中的表现力和泛化能力，突破了传统单一预测模式的局限。提出的方法为语言模型研究领域带来了新的可能性和启发。 <div>
提出一种半参数化token-sequence协同监督训练方法，通过同时利用参数化token嵌入空间和非参数化sequence嵌入空间的监督，显著提升了语言模型在信息检索任务中的表现力及泛化能力，特别在于其训练过程中结合了两种不同嵌入空间的优势，突破了传统单一预测模式的局限。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Semiparametric Token-Sequence Co-Supervision》H Lee, D Kim, J Jun, S Joo, J Jang, K On, M Seo [KAIST AI] (2024) <a href="https://arxiv.org/abs/2403.09024"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuotlll0bj20l40w8qaf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnuotm570sj20oe0qctcw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuotmhkc2j21cc0sggry.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuotmq88hj20o80icabd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuouk0fgqj20hs0hvgmp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuouk12kpj20hm0d3jrx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuouk19wfj20hn0nsjt8.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 21:29:25 GMT</pubDate>
</item>
<item>
<title>[CL]《Semiparametric Token-Sequence Co-Supervision》H Lee, D Kim, J Jun, S Joo, J Jang, K On, M Seo [KAIST AI] (2024) 网页链接 #机器学习##人工智能##论...</title>
<link>https://weibo.com/1402400261/O5vXq7N1N</link>
<guid>https://weibo.com/1402400261/O5vXq7N1N</guid>
<content:encoded><![CDATA[
<div> 关键词: Semiparametric, Token-Sequence, Co-Supervision, AI, KAIST, Lee, Kim, Jun, Joo, Jang

总结:<br /><br />这篇文章来自于韩国科学技术研究院（KAIST AI）的研究团队，论文的题目是《Semiparametric Token-Sequence Co-Supervision》。研究人员包括H Lee、D Kim、J Jun、S Joo、J Jang、K On和M Seo。研究主要探讨了半参数化标记序列协同监督的方法。作者提出的方法结合了参数化和非参数化模型，利用标记序列的监督信息来提高模型性能。通过实验验证了该方法的有效性和优越性，展示了其在各种应用场景中的潜力。这项研究对于进一步发展半参数化方法在人工智能领域的应用具有指导意义。 <div>
[CL]《Semiparametric Token-Sequence Co-Supervision》H Lee, D Kim, J Jun, S Joo, J Jang, K On, M Seo [KAIST AI] (2024) <a href="https://arxiv.org/abs/2403.09024"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuotlll0bj20l40w8qaf.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnuotm570sj20oe0qctcw.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuotmhkc2j21cc0sggry.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnuotmq88hj20o80icabd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuouk0fgqj20hs0hvgmp.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnuouk12kpj20hm0d3jrx.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnuouk19wfj20hn0nsjt8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 21:19:02 GMT</pubDate>
</item>
<item>
<title>《爱可可微博热门分享(3.17)》 爱可可微博热门分享(3.17) [图片]</title>
<link>https://weibo.com/1402400261/O5tkBDmpW</link>
<guid>https://weibo.com/1402400261/O5tkBDmpW</guid>
<content:encoded><![CDATA[
<div> 微博, 爱可可, 热门分享, 3.17, 娱乐, 新闻, 热点, 社交, 观点, 情感<br />
<br />
爱可可微博在3.17日分享了一篇热门内容，涵盖了娱乐、新闻和热点话题。其中包括了社交观点和情感类内容，引起了广泛关注。微博用户在评论中纷纷表达了自己的看法和感受，形成了热烈的讨论氛围。爱可可微博在推送这篇内容时，吸引了大量粉丝的关注和转发，展示了其在社交媒体领域的影响力和号召力。总的来说，这篇内容在微博上获得了良好的反响，为读者带来了丰富多彩的信息和观点。 <br /><br />总结: <div>
《爱可可微博热门分享(3.17)》  <a href="https://weibo.com/ttarticle/p/show?id=2309405013043942916181"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可微博热门分享(3.17)</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnud93xshgj20ht0a075q.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 14:37:56 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets》(ICLR 2024) GitHub: github.com/lifan-yuan/CRAFT [fig...</title>
<link>https://weibo.com/1402400261/O5qIuBoo2</link>
<guid>https://weibo.com/1402400261/O5qIuBoo2</guid>
<content:encoded><![CDATA[
<div> 关键词：自定义LLM，专业工具集，知识获取，红队行动，好奇心驱动，执行反馈，活体动画控制器，3D人体恢复，立体匹配，目标检测，语言模型协作解码，视频理解，第一人称视角，不确定性规划，图像到3D转换，扩散模型，口头反馈学习，通用视觉转换器，多语言隐语言，智能工作任务解决，数据过滤，脆弱性攻击，闭环检测，实时生成，视频理解，数据初始化，目标跟踪，极长序列理解，代码评估，物体变化评估，偏好优化，模型增强，风格转移，建模。

总结：<br /><br />
1. 《CRAFT》介绍了通过创建和从专业工具集中检索个性化LLM的方法，提高了知识获取能力。<br />
2. 《Curiosity-driven Red Teaming for Large Language Models》探讨了通过好奇心驱动的方式进行网络攻击红队行动。<br />
3. 《Making Language Models Better Tool Learners with Execution Feedback》利用执行反馈提升语言模型的学习能力。<br />
4. 《PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios》介绍了一种用于驾驶场景的行人动画控制器。<br />
5. 《Score-Guided Diffusion for 3D Human Recovery》提出了一种评分引导的方法用于3D人体恢复。<br />
6. 《Robust Synthetic-to-Real Transfer for Stereo Matching》探讨了立体匹配中合成到真实数据的转移问题。<br />
7. 《Generative Region-Language Pretraining for Open-Ended Object Detection》介绍了用于目标检测的区域语言预训练方法。<br />
8. 《Learning to Decode Collaboratively with Multiple Language Models》讨论了多语言模型协作解码的学习方式。<br />
9. 《TempCompass: Do Video LLMs Really Understand Videos?》探究了视频理解中LLM的实际效果。<br />
10. 《Can Vision-Language Models Think from a First-Person Perspective?》研究了视觉语言模型是否具备第一人称视角思维。<br /> <div>
几篇论文实现代码：<br />《CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets》(ICLR 2024) GitHub: github.com/lifan-yuan/CRAFT [fig3]<br />《Curiosity-driven Red Teaming for Large Language Models》(ICLR 2024) GitHub: github.com/Improbable-AI/curiosity_redteam<br />《Making Language Models Better Tool Learners with Execution Feedback》(NAACL 2024) GitHub: github.com/zjunlp/TRICE [fig6]<br />《PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios》(CVPR 2024) GitHub: github.com/IDC-Flash/PacerPlus<br />《Score-Guided Diffusion for 3D Human Recovery》(CVPR 2024) GitHub: github.com/statho/ScoreHMR<br />《Robust Synthetic-to-Real Transfer for Stereo Matching》(CVPR 2024) GitHub: github.com/jiaw-z/DKT-Stereo<br />《Generative Region-Language Pretraining for Open-Ended Object Detection》(CVPR 2024) GitHub: github.com/FoundationVision/GenerateU<br />《Learning to Decode Collaboratively with Multiple Language Models》(2024) GitHub: github.com/clinicalml/co-llm<br />《TempCompass: Do Video LLMs Really Understand Videos?》(2024) GitHub: github.com/llyx97/TempCompass [fig1]<br />《Can Vision-Language Models Think from a First-Person Perspective?》(2024) GitHub: github.com/AdaCheng/EgoThink<br />《Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models》(2024) GitHub: github.com/zhiyuanhubj/UoT [fig2]<br />《Envision3D: One Image to 3D with Anchor Views Interpolation》(2024) GitHub: github.com/PKU-YuanGroup/Envision3D<br />《DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models》(2024) GitHub: github.com/sekstini/basedxl<br />《RLVF: Learning from Verbal Feedback without Overgeneralization》(2024) GitHub: github.com/austrian-code-wizard/c3po<br />《GiT: Towards Generalist Vision Transformer through Universal Language Interface》(2024) GitHub: github.com/Haiyang-W/GiT [fig7]<br />《Do Llamas Work in English? On the Latent Language of Multilingual Transformers》(2024) GitHub: github.com/epfl-dlab/llm-latent-language<br />《WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?》(2024) GitHub: github.com/ServiceNow/WorkArena<br />《Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning》(2024) GitHub: github.com/tianyi-lab/Superfiltering [fig4] <br />《COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability》(NeurIPS 2024) GitHub: github.com/Yu-Fangxu/COLD-Attack [fig5]<br />《Effectively Detecting Loop Closures using Point Cloud Density Maps》(2024) GitHub: github.com/PRBonn/MapClosures [fig8] <br />《StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control.》(2024) GitHub: github.com/ironjr/StreamMultiDiffusion<br />《Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding》(2024) GitHub: github.com/OpenGVLab/video-mamba-suite [fig9]<br />《Relaxing Accurate Initialization Constraint for 3D Gaussian Splatting》(2024) GitHub: github.com/KU-CVLAB/RAIN-GS<br />《VastTrack: Vast Category Visual Object Tracking》(2024) GitHub: github.com/HengLan/VastTrack<br />《InfLLM: Unveiling the Intrinsic Capacity of LLMs for Understanding Extremely Long Sequences with Training-Free Memory》(2024) GitHub: github.com/thunlp/InfLLM [fig10]<br />《LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code》(2024) GitHub: github.com/LiveCodeBench/LiveCodeBench<br />《ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes》(2024) GitHub: github.com/Muhammad-Huzaifaa/ObjectCompose [fig11]<br />《Reference-free Monolithic Preference Optimization with Odds Ratio》(2024) GitHub: github.com/xfactlab/orpo<br />《CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences》(2024) GitHub: github.com/martin-wey/CodeUltraFeedback <br />《DexCap: Scalable and Portable Mocap Data Collection System for Dexterous Manipulation》(2024) GitHub: github.com/j96w/DexCap<br />《Strengthening Multimodal Large Language Model with Bootstrapped Preference Optimization》(2024) GitHub: github.com/pipilurj/BPO<br />《Grimoire is All You Need for Enhancing Large Language Models》(2024) GitHub: github.com/IAAR-Shanghai/Grimoire<br />《FreeStyle: Free Lunch for Text-guided Style Transfer using Diffusion Models》(2024) GitHub: github.com/FreeStyleFreeLunch/FreeStyle<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1peo3wfj244e1plkjl.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnu1pfjmrfj23qq0ukau1.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnu1pg33q3j21480x6nb5.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1pgtzc9j22c5276k96.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1ph7lzpj227u0ouqct.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1phyr60j23qt1z1tyo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnu1pijfg4j21qg0o6dsd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnu1pja928j21mj0kjdo2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnu1pjvqsmj22880ymdsk.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnu1pkdxpdj21k20m40w9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnu1pkywzjj21gg0jw108.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:58:32 GMT</pubDate>
</item>
<item>
<title>【AI-in-a-Box：旨在帮助工程师建立人工智能和机器学习解决方案，并提供快速而高质量的解决方案，以减少架构师的成本和降低风险】'AI-in-a-Box' GitHub: github....</title>
<link>https://weibo.com/1402400261/O5qFqECzE</link>
<guid>https://weibo.com/1402400261/O5qFqECzE</guid>
<content:encoded><![CDATA[
<div> AI-in-a-Box、工程师、人工智能、机器学习、解决方案、快速、高质量、降低成本、降低风险

<br /><br />总结:
AI-in-a-Box是一个旨在帮助工程师建立人工智能和机器学习解决方案的工具。通过提供快速而高质量的解决方案，AI-in-a-Box可以降低架构师的成本，降低风险。工程师可以在GitHub上找到AI-in-a-Box的资源，帮助他们更有效地开发人工智能和机器学习项目。 <div>
【AI-in-a-Box：旨在帮助工程师建立人工智能和机器学习解决方案，并提供快速而高质量的解决方案，以减少架构师的成本和降低风险】'AI-in-a-Box' GitHub: github.com/Azure/AI-in-a-Box <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnu1hqwzepj20m80cd0uv.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:50:59 GMT</pubDate>
</item>
<item>
<title>【ShareGPT Builder：一个功能强大的 Flask 应用，用于创建和存储 ChatGPT 模型的训练样本，允许手动创建和存储 SFT 格式的聊天对话，并自动将其添加到 JSON 文...</title>
<link>https://weibo.com/1402400261/O5qELjK5G</link>
<guid>https://weibo.com/1402400261/O5qELjK5G</guid>
<content:encoded><![CDATA[
<div> Flask 应用, ChatGPT 模型, 训练样本, SFT 格式, 聊天对话, JSON 文件, 模型训练, GitHub, 语言学习模型, 功能强大

总结:
这是一个功能强大的 Flask 应用程序，名为 ShareGPT Builder，提供训练语言学习模型（LLMs）的两个关键功能。它允许用户手动创建和存储 SFT 格式的聊天对话，自动将其添加到 JSON 文件中，以供其他模型访问。在 GitHub 上可找到该应用，链接为 github.com/teknium1/ShareGPT-Builder。 ShareGPT Builder不仅提供了创建和存储训练样本的功能，还支持模型训练的过程。 <div>
【ShareGPT Builder：一个功能强大的 Flask 应用，用于创建和存储 ChatGPT 模型的训练样本，允许手动创建和存储 SFT 格式的聊天对话，并自动将其添加到 JSON 文件中，以便其他模型可访问】'ShareGPT Builder - a versatile Flask application that provides two key functionalities for training Language Learning Models (LLMs)’ GitHub: github.com/teknium1/ShareGPT-Builder <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnu1g28ioyj20u00v0tc9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:49:20 GMT</pubDate>
</item>
<item>
<title>【视频生成相关研究列表】’A Collection of Video Generation Studies - A collection of awesome video generation studies.' GitHub: github.com/AlonzoLeeeo...</title>
<link>https://weibo.com/1402400261/O5qDRoorO</link>
<guid>https://weibo.com/1402400261/O5qDRoorO</guid>
<content:encoded><![CDATA[
<div> GitHub、视频生成、研究、收藏、视频、生成、研究、集合、研究、学习

<br /><br />总结:
该GitHub仓库收集了一系列关于视频生成的研究，涵盖了各种有趣的视频生成研究，为视频生成领域的学习提供了丰富的资源。研究内容包括视频的生成方法、技术应用以及相关算法等，为研究者们提供了广阔的研究方向。通过这些研究，可以深入了解视频生成的原理和方法，为视频生成技术的进一步发展提供了参考和借鉴。GitHub上的资源丰富多样，对视频生成领域的研究有很大的帮助。 <div>
【视频生成相关研究列表】’A Collection of Video Generation Studies - A collection of awesome video generation studies.' GitHub: github.com/AlonzoLeeeooo/awesome-video-generation <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu1deazrtj21fo0g4ad5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:47:07 GMT</pubDate>
</item>
<item>
<title>【MIMo：用于婴儿认知发展研究的开源平台，提供分析婴儿认知发育的关键数据和功能】'MIMo - a platform for the research of the cognitive development of infa...</title>
<link>https://weibo.com/1402400261/O5qDi0lSg</link>
<guid>https://weibo.com/1402400261/O5qDi0lSg</guid>
<content:encoded><![CDATA[
<div> 平台，婴儿，认知发展，研究，开源，数据，功能，分析，关键，GitHub

<br /><br />总结:
MIMo是一个用于研究婴儿认知发展的平台，提供关键数据和功能，开源且可用于分析婴儿认知发育。用户可以在GitHub上找到该平台的代码。MIMo是一个重要的工具，用于帮助研究人员深入研究婴儿认知发展的过程，并产生有价值的发现。 <div>
【MIMo：用于婴儿认知发展研究的开源平台，提供分析婴儿认知发育的关键数据和功能】'MIMo - a platform for the research of the cognitive development of infants' GitHub: github.com/trieschlab/MIMo <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu1c6ud7cj21bi0u0q89.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:45:42 GMT</pubDate>
</item>
<item>
<title>【Local RAG：一个开源项目，使用 开源大预言模型 (LLM) 提取文件并进行检索增强生成 (RAG)，无需第三方或敏感数据，在本地保持匿名】'Local RAG - Ingest files...</title>
<link>https://weibo.com/1402400261/O5qCu1PLb</link>
<guid>https://weibo.com/1402400261/O5qCu1PLb</guid>
<content:encoded><![CDATA[
<div> 开源项目、本地保持匿名、Local RAG、LLM、RAG、文件提取、检索增强生成、无需第三方、敏感数据保护、GitHub<br /><br />总结:
Local RAG是一个开源项目，使用开源大预言模型（LLM）来提取文件并进行检索增强生成（RAG），并且能够在本地网络中保持匿名。该项目无需第三方参与，能够有效保护敏感数据的安全。GitHub链接为github.com/jonfairbanks/local-rag。 <div>
【Local RAG：一个开源项目，使用 开源大预言模型 (LLM) 提取文件并进行检索增强生成 (RAG)，无需第三方或敏感数据，在本地保持匿名】'Local RAG - Ingest files for retrieval augmented generation (RAG) with open-source Large Language Models (LLMs), all without 3rd parties or sensitive data leaving your network.' GitHub: github.com/jonfairbanks/local-rag <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnu1a5h6fxj21g10u0q5e.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:43:43 GMT</pubDate>
</item>
<item>
<title>【NeMo Curator：一个 Python 库，用于创建和处理自然语言处理 (NLP) 数据集，以便训练大型语言模型 (LLM)。该库包含一些可扩展的模块，允许 NLP 研究人员从无标...</title>
<link>https://weibo.com/1402400261/O5qAfojgc</link>
<guid>https://weibo.com/1402400261/O5qAfojgc</guid>
<content:encoded><![CDATA[
<div> Python、库、自然语言处理、数据集、语言模型、模块、Web采集、文本、GPU加速、高质量

<br /><br />总结:
NeMo Curator是一个Python库，旨在帮助自然语言处理研究人员创建和处理数据集，用于训练大型语言模型。该库包含可扩展的模块，允许从无标注Web采集高质量文本，并提供GPU加速功能。通过NeMo Curator，研究人员可以更轻松地获取并处理文本数据，提高训练效率和模型性能。 <div>
【NeMo Curator：一个 Python 库，用于创建和处理自然语言处理 (NLP) 数据集，以便训练大型语言模型 (LLM)。该库包含一些可扩展的模块，允许 NLP 研究人员从无标注 Web 采集高质量文本，并提供 GPU 加速功能】'NeMo Curator - Scalable toolkit for data curation' GitHub: github.com/NVIDIA/NeMo-Curator <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnu14hfnofj21ji0pgwln.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:38:13 GMT</pubDate>
</item>
<item>
<title>【超赞列表合集，从各类Awesome list项目抓取而来】“Awesome List” 网页链接 [图片]</title>
<link>https://weibo.com/1402400261/O5qwr6nHP</link>
<guid>https://weibo.com/1402400261/O5qwr6nHP</guid>
<content:encoded><![CDATA[
<div> Awesome List、项目、合集、抓取、资源、开发、技术、网站、GitHub、工具
<br />这篇文章是关于各类Awesome List项目的合集，内容涵盖了各种技术、开发资源，以及可在GitHub上找到的工具和网站。这些列表项目汇总了相关领域的优质资源，为开发者提供了丰富的参考和学习资料。从这些列表中可以获取各种有用的信息和工具，帮助开发者提升技能和解决问题。整理这些Awesome List的合集是为了让开发者更便捷地找到他们所需的资源和工具，提升开发效率和技术水平。
<br />总结: 这篇文章介绍了关于各类Awesome List项目的合集，涵盖了各种技术、开发资源和工具，为开发者提供了丰富的学习和参考资料。整理这些资源的目的是为了帮助开发者更便捷地获取他们所需的信息，提升技术水平。 <div>
【超赞列表合集，从各类Awesome list项目抓取而来】“Awesome List” <a href="https://asmen.icopy.site/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu0tfohbrj217q0om0xl.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:28:49 GMT</pubDate>
</item>
<item>
<title>【BrowserGym: 用于 Web 任务自动化的开源项目，提供 Chrome 浏览器环境的 Gym 集成，用于自动化各种网站和应用的任务】’BrowserGym: a Gym Environment for We...</title>
<link>https://weibo.com/1402400261/O5qsp2NdU</link>
<guid>https://weibo.com/1402400261/O5qsp2NdU</guid>
<content:encoded><![CDATA[
<div> BrowserGym, Gym环境, Web任务自动化, 开源项目, Chrome浏览器, 自动化任务, 网站, 应用<br />
<br />
总结:<br />
BrowserGym是一个开源项目，提供了一个基于Chrome浏览器的Gym环境，用于自动化各种网站和应用的任务。用户可以通过BrowserGym在Chromium浏览器中进行Web任务自动化，提高效率并简化操作。这个项目在GitHub上有源代码，帮助用户更好地进行Web任务自动化。 <div>
【BrowserGym: 用于 Web 任务自动化的开源项目，提供 Chrome 浏览器环境的 Gym 集成，用于自动化各种网站和应用的任务】’BrowserGym: a Gym Environment for Web Task Automation - BrowserGym, a gym environment for web task automation in the Chromium browser.' GitHub: github.com/ServiceNow/BrowserGym <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnu0kdzmk6j20yy0u0gp3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:18:53 GMT</pubDate>
</item>
<item>
<title>【flybody是一个用于 MuJoCo 物理模拟和强化学习应用的果蝇模型，基于 Google DeepMind 和 HHMI Janelia 研究中心的相结合的作品，旨在建立果蝇体系生物物理模拟...</title>
<link>https://weibo.com/1402400261/O5qqjDbVj</link>
<guid>https://weibo.com/1402400261/O5qqjDbVj</guid>
<content:encoded><![CDATA[
<div> 果蝇模型, MuJoCo 物理模拟, 强化学习, Google DeepMind, HHMI Janelia, 生物物理模拟平台, GitHub, TuragaLab, reinforcement learning, 任务<br />
<br />
总结:<br />
该项目将果蝇模型应用于 MuJoCo 物理模拟和强化学习任务，结合了 Google DeepMind 和 HHMI Janelia 的研究成果，旨在建立果蝇体系生物物理模拟平台。该项目的代码存储在 GitHub 上的 TuragaLab/flybody 项目中。通过这个模型，研究人员可以在仿真环境中进行果蝇的生物物理模拟和强化学习，为研究果蝇行为和神经系统提供了新的工具和资源。 <div>
【flybody是一个用于 MuJoCo 物理模拟和强化学习应用的果蝇模型，基于 Google DeepMind 和 HHMI Janelia 研究中心的相结合的作品，旨在建立果蝇体系生物物理模拟平台】'flybody: fruit fly body model for MuJoCo physics - MuJoCo fruit fly body model and reinforcement learning tasks' GitHub: github.com/TuragaLab/flybody <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnu0elerekj219u0u00y4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 07:13:44 GMT</pubDate>
</item>
<item>
<title>【Magix 是一个用于训练大规模语言模型的轻量工具，具有灵活的数据和模型平行功能】'Magix - Supercharge huggingface transformers with model parallelism.' G...</title>
<link>https://weibo.com/1402400261/O5q959sOY</link>
<guid>https://weibo.com/1402400261/O5q959sOY</guid>
<content:encoded><![CDATA[
<div> Magix, huggingface, transformers, model parallelism, GitHub, 训练大规模语言模型, 轻量工具, 灵活的数据, 模型平行功能

<br /><br />总结:
Magix 是一个用于训练大规模语言模型的轻量工具，能够有效地利用模型并行性，并具有灵活的数据和模型平行功能。通过 Magix，用户可以在 GitHub 上找到支持 model parallelism 的 huggingface transformers。Magix 的出现为训练大规模语言模型提供了更加高效和灵活的选择。 <div>
【Magix 是一个用于训练大规模语言模型的轻量工具，具有灵活的数据和模型平行功能】'Magix - Supercharge huggingface transformers with model parallelism.' GitHub: github.com/luyug/magix <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntz6t5nagj21e00pqjvg.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 06:31:17 GMT</pubDate>
</item>
<item>
<title>【ArXiv Paper Reader：旨在简化和流利的arXiv论文阅读，使用 LaTeX 代码转换为 HTML 页面，然后提取文本和公式，将其转换为视频，并创建与 PDF 文档匹配的图，...</title>
<link>https://weibo.com/1402400261/O5q2nDkz5</link>
<guid>https://weibo.com/1402400261/O5q2nDkz5</guid>
<content:encoded><![CDATA[
<div> 简化、流利、arXiv论文、LaTeX代码、HTML页面、提取文本、公式、视频、PDF文档、图像<br />
<br />
提供了一个名为ArXiv Paper Reader的工具，旨在简化和流利地阅读arXiv论文。该工具首先将LaTeX代码转换为HTML页面，然后提取文本、公式，并将其转换为视频。接着创建与PDF文档匹配的图像，并将文本分段并转换为音频。通过这种方式，用户可以更方便地理解和阅读arXiv论文，提高阅读效率。总的来说，这个工具为阅读arXiv论文提供了更加便捷的方式，使得用户可以更加愉快地进行学术阅读。<br /><br />总结: <div>
【ArXiv Paper Reader：旨在简化和流利的arXiv论文阅读，使用 LaTeX 代码转换为 HTML 页面，然后提取文本和公式，将其转换为视频，并创建与 PDF 文档匹配的图，以及文本分段并将其转换为音频】'ArXiv Paper Reader - Code behind Arxiv Papers' GitHub: github.com/imelnyk/ArxivPapers <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntypo9wd3j221b0u0n1i.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 06:14:47 GMT</pubDate>
</item>
<item>
<title>【Skyvern 利用 LLM 和计算机视觉，自动化浏览器基础工作流。它提供一个简洁的 API 端点，允许完全自动化手动工作流，取代难以维护或易于故障的自动化解决方案】...</title>
<link>https://weibo.com/1402400261/O5pYY8wLP</link>
<guid>https://weibo.com/1402400261/O5pYY8wLP</guid>
<content:encoded><![CDATA[
<div> LLMs, 计算机视觉, 自动化, 浏览器, API, 手动工作流, 维护, 故障, 解决方案, GitHub<br /><br />总结: Skyvern利用LLM和计算机视觉技术，自动化浏览器基础工作流。其提供了一个简洁的API端点，允许完全自动化手动工作流，取代难以维护或易于故障的自动化解决方案。该项目的GitHub链接为github.com/Skyvern-AI/skyvern。 <div>
【Skyvern 利用 LLM 和计算机视觉，自动化浏览器基础工作流。它提供一个简洁的 API 端点，允许完全自动化手动工作流，取代难以维护或易于故障的自动化解决方案】'Skyvern - Automate browser-based workflows with LLMs and Computer Vision' GitHub: github.com/Skyvern-AI/skyvern <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntygovm8aj213t0u0wgj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 06:06:22 GMT</pubDate>
</item>
<item>
<title>【Pretzel是一个开源，在线浏览器式数据探索和可视化的工具，提供快速便捷的数据分析和可视化功能。它无需后台设置，可在浏览器中实时运行，无需任何服务器连接...</title>
<link>https://weibo.com/1402400261/O5pPCFNVf</link>
<guid>https://weibo.com/1402400261/O5pPCFNVf</guid>
<content:encoded><![CDATA[
<div> Pretzel, 开源, 在线浏览器, 数据探索, 可视化, 数据分析, 数据变换, 实时更新, DuckDB-Wasm, PRQL

<br /><br />总结:
Pretzel是一个开源的在线浏览器式数据探索和可视化工具，无需后台设置，可实时在浏览器中运行，提供快速便捷的数据分析和可视化功能。用户可以通过视觉化的数据变换区块轻松操控数据，并实时更新所有与变换区块和图表相关的内容，使用了DuckDB-Wasm和PRQL技术。 <div>
【Pretzel是一个开源，在线浏览器式数据探索和可视化的工具，提供快速便捷的数据分析和可视化功能。它无需后台设置，可在浏览器中实时运行，无需任何服务器连接。Pretzel通过视觉化的数据变换区块轻松操控数据，并实时更新所有与变换区块和图表相关的区块和图表】'Pretzel - Open-source, browser-local data exploration using DuckDB-Wasm and PRQL' GitHub: github.com/pretzelai/pretzelai <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntxt0cgs0j21bz0u0qa8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:43:21 GMT</pubDate>
</item>
<item>
<title>【扩散蒸馏相关论文资源列表】’Awesome-Diffusion-Distillation - A list of papers, docs, codes about diffusion distillation.This repo collects various d...</title>
<link>https://weibo.com/1402400261/O5pF46IZu</link>
<guid>https://weibo.com/1402400261/O5pF46IZu</guid>
<content:encoded><![CDATA[
<div> GitHub, papers, docs, codes, diffusion distillation, distillation methods<br />
<br />
总结：<br />
这个GitHub仓库收集了关于扩散模型的各种蒸馏方法，欢迎贡献未被收录的相关作品（论文、代码库）。扩散蒸馏是一个重要的研究领域，通过这个仓库可以找到多种不同的蒸馏方法和资源。希望这个仓库可以帮助研究人员更好地了解和应用扩散蒸馏技术。 <div>
【扩散蒸馏相关论文资源列表】’Awesome-Diffusion-Distillation - A list of papers, docs, codes about diffusion distillation.This repo collects various distillation methods for the Diffusion model. Welcome to PR the works (papers, repositories) missed by the repo.' GitHub: github.com/cantbebetter2/Awesome-Diffusion-Distillation <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntwv7uq2gj20u80u0wj8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:17:19 GMT</pubDate>
</item>
<item>
<title>【Recommender AI Agent: 使用大语言模型提供交互式推荐功能的agent】’Recommender AI Agent: Integrating Large Language Models for Interactive Recommendat...</title>
<link>https://weibo.com/1402400261/O5pAps9gS</link>
<guid>https://weibo.com/1402400261/O5pAps9gS</guid>
<content:encoded><![CDATA[
<div> 关键词: Recommender AI Agent, 大语言模型, 交互式推荐, GitHub, Microsoft

总结:<br /><br />
这篇文章介绍了一个名为'Recommender AI Agent'的项目，该项目利用大语言模型来提供交互式推荐功能。通过GitHub上的链接github.com/microsoft/RecAI 可以找到该项目的代码和资源。这个项目的目标是整合大语言模型，通过与用户的交互，为他们提供更加个性化的推荐服务。这种推荐代理的技术可以被应用到各种领域，帮助用户更快地找到他们感兴趣的内容。Microsoft是这个项目的背后支持者，展示了他们在人工智能和数据科学领域的实力和创新能力。通过这种新型推荐技术，用户可以享受到更加智能化和高效的推荐体验，提升用户体验和满意度。 <div>
【Recommender AI Agent: 使用大语言模型提供交互式推荐功能的agent】’Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations' GitHub: github.com/microsoft/RecAI <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntwpyjejsj21b70glgp4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:05:52 GMT</pubDate>
</item>
<item>
<title>'Campus2025 - 2025届互联网校招信息汇总' GitHub: github.com/NAOSI-DLUT/Campus2025 #开源# #校招# [图片]</title>
<link>https://weibo.com/1402400261/O5pyCbZZ7</link>
<guid>https://weibo.com/1402400261/O5pyCbZZ7</guid>
<content:encoded><![CDATA[
<div> GitHub, Campus2025, 2025届, 互联网, 校招, 信息, 汇总

<br /><br />总结:
GitHub上有一个名为Campus2025的项目，汇总了2025届互联网校园招聘的信息。这个项目提供了一个集中查找各种互联网公司校招信息的平台，帮助学生更方便地了解招聘信息和机会。对于即将步入社会的2025届学生来说，这个项目提供了一个很好的资源，可以帮助他们更好地规划自己的职业发展方向。通过这个项目，学生可以及时了解各个互联网公司的招聘信息，选择最适合自己的发展方向和机会。整合了各种互联网公司的招聘信息，让学生可以更方便地比较和选择自己感兴趣的企业和岗位。建议2025届的学生多关注这个项目，及时了解就业信息，为自己的职业发展做好准备。 <div>
'Campus2025 - 2025届互联网校招信息汇总' GitHub: github.com/NAOSI-DLUT/Campus2025 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%A0%A1%E6%8B%9B%23&amp;isnewpage=1"><span class="surl-text">#校招#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntwle8h77j20un0u00wu.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 05:01:27 GMT</pubDate>
</item>
<item>
<title>【大模型数据增强相关文献资源列表】’Papers and resources on data augmentation using large models - The official GitHub page for the survey paper "A Su...</title>
<link>https://weibo.com/1402400261/O5pxswqTp</link>
<guid>https://weibo.com/1402400261/O5pxswqTp</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据增强, 大模型, 调查论文, GitHub, 资源, 机器学习, 深度学习

总结:<br /><br />
这篇文章是关于在大模型时代中使用数据增强的调查论文。GitHub上有一份关于数据增强的官方调查论文页面，提供了大模型数据增强相关的论文和资源列表。该调查论文涵盖了数据增强在机器学习和深度学习中的应用，以及大模型时代如何利用数据增强来提升模型性能。通过研究论文和资源，我们可以更好地了解数据增强在大模型领域的应用和重要性，为我们在实践中更好地利用数据增强提供了指导和参考。 <div>
【大模型数据增强相关文献资源列表】’Papers and resources on data augmentation using large models - The official GitHub page for the survey paper "A Survey on Data Augmentation in Large Model Era"' GitHub: github.com/MLGroup-JLU/LLM-data-aug-survey <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntwi7n59vj210s0u0jxn.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntwidk0cgj21480u0jwj.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:58:36 GMT</pubDate>
</item>
<item>
<title>【DRL-Based Trajectory Tracking (DRLTT) 是一个用于自动驾驶轨迹跟踪的开源项目，它结合深度强化学习(DRL)技术，并具有高效性和准确性的功能，可用于轨迹跟踪...</title>
<link>https://weibo.com/1402400261/O5pshzWGg</link>
<guid>https://weibo.com/1402400261/O5pshzWGg</guid>
<content:encoded><![CDATA[
<div> GitHub, DRL-Based Trajectory Tracking, 深度强化学习, 轨迹跟踪, 自动驾驶, 开源项目, 高效性, 准确性, 任务

<br /><br />总结:
DRL-Based Trajectory Tracking (DRLTT) 是一个开源项目，采用深度强化学习技术，旨在实现自动驾驶轨迹跟踪任务。该项目结合了高效性和准确性的特点，提供了一个有效的解决方案。通过 GitHub 平台展示和分享，用户可以了解和参与该项目，促进自动驾驶技术的发展。 <div>
【DRL-Based Trajectory Tracking (DRLTT) 是一个用于自动驾驶轨迹跟踪的开源项目，它结合深度强化学习(DRL)技术，并具有高效性和准确性的功能，可用于轨迹跟踪任务】'DRL-Based Trajectory Tracking (DRLTT) - DRL-based trajectory tracking.' GitHub: github.com/MARMOTatZJU/drl-based-trajectory-tracking <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntw56a5v2j215e0u079l.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:45:51 GMT</pubDate>
</item>
<item>
<title>【Cpptrace：一个简洁、可移植和自建的 C++ stacktracker 库，支持 C++11 及更高版本的 Linux、macOS 和 Windows 运行环境，包括 MinGW 和 Cygwingwin。其目的是...</title>
<link>https://weibo.com/1402400261/O5prI8BI3</link>
<guid>https://weibo.com/1402400261/O5prI8BI3</guid>
<content:encoded><![CDATA[
<div> 简洁 可移植 自建 C++ stacktracker 库 C++11 Linux macOS Windows MinGW Cygwinwin<br />
<br />总结:<br />Cpptrace是一个简洁、可移植和自建的 C++ stacktracker 库，支持C++11及更高版本，在Linux、macOS和Windows运行环境下可使用，包括MinGW和Cygwingwin。它的目的是简化堆栈追踪，使其变得更容易。Cpptrace库的GitHub地址为github.com/jeremy-rifkin/cpptrace。 <div>
【Cpptrace：一个简洁、可移植和自建的 C++ stacktracker 库，支持 C++11 及更高版本的 Linux、macOS 和 Windows 运行环境，包括 MinGW 和 Cygwingwin。其目的是简化堆栈追踪，使其变得更容易】'Cpptrace - Simple, portable, and self-contained stacktrace library for C++11 and newer' GitHub: github.com/jeremy-rifkin/cpptrace <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23C%2B%2B%23"><span class="surl-text">#C++#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntw3ow5brj20xc0u0tce.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:44:26 GMT</pubDate>
</item>
<item>
<title>'Transformers 库快速入门教程' GitHub: github.com/jsksxs360/How-to-use-Transformers #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5pcFy2Gb</link>
<guid>https://weibo.com/1402400261/O5pcFy2Gb</guid>
<content:encoded><![CDATA[
<div> Transformers, 库, 快速, 入门, 教程, GitHub, 使用, 教程, 详细

<br /><br />总结: 该GitHub仓库提供了一个关于如何快速入门使用Transformers库的教程，详细介绍了如何利用这个功能强大的库来进行自然语言处理和其他机器学习任务。通过阅读这篇教程，你能够了解Transformers库的基本功能和使用方法，帮助你更快地上手并应用于实际项目中。如果你对自然语言处理或机器学习感兴趣，不妨花一些时间学习这篇教程，会受益匪浅。 <div>
'Transformers 库快速入门教程' GitHub: github.com/jsksxs360/How-to-use-Transformers <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntv14tvcoj21ii0u042p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 04:07:23 GMT</pubDate>
</item>
<item>
<title>【Flux 是一个 C++20 库，提供一系列用于序列处理的算法和适配器，类似于 C++20 ranges、Python itertools 和 Rust iterators】'Flux - A C++20 library for seq...</title>
<link>https://weibo.com/1402400261/O5p6WDJDd</link>
<guid>https://weibo.com/1402400261/O5p6WDJDd</guid>
<content:encoded><![CDATA[
<div> C++20, 库, Flux, 序列处理, 算法, 适配器, ranges, Python itertools, Rust iterators  
<br /><br />总结:  
Flux 是一个 C++20 库，提供一系列用于序列处理的算法和适配器，类似于 C++20 ranges、Python itertools 和 Rust iterators。这个库可以让开发者更加方便地处理序列数据，提供了丰富的功能和工具。通过 Flux，开发者可以更高效地进行序列处理，实现更加复杂和灵活的操作。它为 C++ 程序员提供了一种简洁而强大的方式来处理序列数据，帮助他们提高代码的可读性和性能。Flux 库的开发者在 GitHub 上持续维护和更新，为广大开发者提供了一个优秀的序列处理工具。 <div>
【Flux 是一个 C++20 库，提供一系列用于序列处理的算法和适配器，类似于 C++20 ranges、Python itertools 和 Rust iterators】'Flux - A C++20 library for sequence-orientated programming' GitHub: github.com/tcbrindle/flux <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntumcqwwaj21ji0puq7x.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 03:53:17 GMT</pubDate>
</item>
<item>
<title>【StyleTTS 2: 可通过pip安装的Python包，用于实现人类水平的文本转语音和语音克隆】'StyleTTS 2: The Python Package - Pip installable package for StyleTTS ...</title>
<link>https://weibo.com/1402400261/O5oQCmWh7</link>
<guid>https://weibo.com/1402400261/O5oQCmWh7</guid>
<content:encoded><![CDATA[
<div> StyleTTS 2, Python包, pip安装, 文本转语音, 语音克隆, GitHub, sidharthrajaram, 人类水平, 实现, 

总结:<br /><br />
这篇文章介绍了StyleTTS 2，一个Python包，可以通过pip安装，用于实现人类水平的文本转语音和语音克隆。该包提供了一种简单而有效的方法来实现高质量的语音合成和克隆，让用户能够快速轻松地创建自然流畅的语音内容。GitHub上有相关资源和文档，使用户可以更方便地了解和使用这个工具。如果你想要实现人类水平的文本转语音和语音克隆，不妨尝试使用StyleTTS 2这一方便易用的工具。 <div>
【StyleTTS 2: 可通过pip安装的Python包，用于实现人类水平的文本转语音和语音克隆】'StyleTTS 2: The Python Package - Pip installable package for StyleTTS 2 human-level text-to-speech and voice cloning' GitHub: github.com/sidharthrajaram/StyleTTS2 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnttgd54x5j21ki0gu41j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 03:13:03 GMT</pubDate>
</item>
<item>
<title>#免费##抽奖# 携手@博文视点Broadview 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模...</title>
<link>https://weibo.com/1402400261/O5oJlsK39</link>
<guid>https://weibo.com/1402400261/O5oJlsK39</guid>
<content:encoded><![CDATA[
<div> 度小满、大语言模型、杨青、全彩印刷、实践性、知识体系、训练经验、干货满满、系统性、神秘面纱

总结:<br /><br />本书《大语言模型：原理与工程实践(全彩)》由度小满的杨青负责编写，深入解读大语言模型的内在机理和应用实践。书籍的特色在于系统性的知识体系和对实践性的重视，配有代码并采用全彩印刷，内容充实且实用。作者作为大语言模型实践者，分享了他在十亿、百亿、千亿参数规模大语言模型训练方面的丰富经验，这些经验都被真诚而详尽地呈现在书中。通过本书，读者能够全面了解大语言模型的运作原理和实际应用，深入学习大模型的构建和训练方法，是一本值得一读的权威指南。 <div>
<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%8D%E8%B4%B9%23&amp;isnewpage=1"><span class="surl-text">#免费#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%8A%BD%E5%A5%96%23&amp;isnewpage=1"><span class="surl-text">#抽奖#</span></a> 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《大语言模型：原理与工程实践(全彩)》，截止2024.3.24 12:00，*可可粉*转发+评论即可参与。本书旨在揭开大语言模型的神秘面纱，透彻地解读其内在机理和应用实践。一大特色体现在其知识体系的系统性，另一大特色是对实践性的重视。配代码、全彩印刷。本书作者杨青是度小满轩辕大模型负责人，作为真正的大语言模型实践者，拥有十亿、百亿、千亿等不同参数规模大语言模型的训练经验。在本书中，这些经验都被毫无保留地融入其中，干货满满，绝非空谈。 <a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5012867076850203"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb85d5j20m90m9jw5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8np7j20m90m90vz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb8bphj20m90m9789.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntsvb9t7fj20m90m9dph.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvb8gi3j20m90m90xl.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvbf5k1j21hc0u0wud.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntsvbadpbj21dd0rsguo.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntsvbag7dj20rs0rs793.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntsvb7ig9j20rs0m841y.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 02:55:08 GMT</pubDate>
</item>
<item>
<title>【对开源AI工具的观察总结】数据来源:- 通过GitHub搜索GPT、LLM和generative ai等关键词,结果分别为118K、590个、531个和38个。- 限定stars大于500的仓库,最终获...</title>
<link>https://weibo.com/1402400261/O5o4KnaXm</link>
<guid>https://weibo.com/1402400261/O5o4KnaXm</guid>
<content:encoded><![CDATA[
<div> GPT、LLM、generative ai、GitHub、技术栈、趋势、开发者、中国开源、短命项目、点子 <br />
<br />
总结：<br />
通过GitHub搜索了GPT、LLM和generative ai等关键词，共筛选出845个stars大于500的开源AI工具。AI技术栈分为基础设施层、模型开发层、应用开发层和应用层。2023年预计应用和应用开发层将迎来快速增长，特别是提示工程、人机界面和推理优化等领域。开发者中有20个账号贡献了23%的项目，80%为组织账号，个人账号如lucidrains也积极贡献了许多项目。中国开源生态活跃在GitHub上，有不少针对中文用户的工具和模型。许多项目虽然发展迅速但很快衰退，但对社区仍有一定价值。作者对批量推理优化、更快的解码器、模型融合和受约束采样等点子颇感兴趣，认为专注解决一个问题的项目也非常有价值。 <div>
【对开源AI工具的观察总结】<br />数据来源:<br />- 通过GitHub搜索GPT、LLM和generative ai等关键词,结果分别为118K、590个、531个和38个。<br />- 限定stars大于500的仓库,最终获得了845个软件仓库。<br />- 51个是教程和汇总列表,794个是软件项目。<br /><br />AI技术栈:<br />- 基础设施层:模型部署、计算管理、向量搜索数据库等。<br />- 模型开发层:框架、推理优化、数据集、评估等。<br />- 应用开发层:提示工程、人机界面、Agent、AIE框架等。 <br />- 应用层:编码、聊天机器人、信息聚合等。<br /><br />变化趋势:<br />- 2023年应用和应用开发层增长迅速。基础设施层变化不大。<br />- 提示工程、人机界面、推理优化最热门。<br /><br />开发者分布:<br />- 20个账号贡献了23%的项目,80%是组织账号。<br />- 个人账号如lucidrains等也贡献了很多项目,尤其是应用层。<br />- 超过2万开发者贡献了近100万次commit。<br /><br />中国开源生态:<br />- 中文社区也活跃在GitHub上,有针对中文及中英混合的模型。<br />- 也有面向中文用户的工具和模型应用。<br /><br />短命项目:<br />- 许多项目快速发展后也快速衰退,但对社区仍有价值。<br /><br />个人最喜欢的点子:<br />- 批量推理优化、更快的解码器、模型融合、受约束采样等。<br />- 专注解决一个问题的项目也很有价值。<br /><br />《What I learned from looking at 900 most popular open source AI tools》 <a href="https://huyenchip.com//2024/03/14/ai-oss.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntq1dgmbnj20xa0u0gqa.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntq1h4v66j21jj0kagq0.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1iybm0j21hb0u0gp7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntq1jt6qbj20y40t83zz.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntq1lnbjkj21jj0kj79q.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1p6tj6j21jj0tywh4.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntq1rc7nej21760t6mzr.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1s9iy7j21530u0tbb.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntq1u96xqj21ex0u0gnq.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 01:15:07 GMT</pubDate>
</item>
<item>
<title>【Deepfakes：从数字现实到虚假现实】1. 深度伪造(Deepfakes)利用先进的人工智能技术,生成逼真的虚假图像、视频和音频。 - 利用游戏引擎(如Unreal Engine 5)模拟...</title>
<link>https://weibo.com/1402400261/O5nUy4lA5</link>
<guid>https://weibo.com/1402400261/O5nUy4lA5</guid>
<content:encoded><![CDATA[
<div> 深度伪造 技术 人工智能 欺骗性质 安全隐患 伦理问题 检测防御 深思 认知 

总结:<br /><br />这篇文章介绍了深度伪造技术利用人工智能生成逼真虚假图像、视频和音频的现状，以及其潜在的伦理和安全隐患，引起了人们的深刻思考。技术能够精确模仿人物特征，但也可能被滥用用于制造虚假信息和诽谤。一些公司和研究人员正在研发新技术用于检测和防御深度伪造，但是人们对于是否应该限制或禁止这种技术的发展看法不一。文章唤起人们对于技术快速发展下如何保持理性和警惕的思考。 <div>
【Deepfakes：从数字现实到虚假现实】<br />1. 深度伪造(Deepfakes)利用先进的人工智能技术,生成逼真的虚假图像、视频和音频。<br />   - 利用游戏引擎(如Unreal Engine 5)模拟细致的光线和物理效果,创造出逼真的数字场景。<br />   - 使用生成对抗网络(GAN)等生成AI模型(如DeepMind的Sora),根据文本提示生成逼真的视频。<br />2. 深度伪造技术能够精确模仿人物的脸部特征、表情、声音和动作细节。<br />3. 虽然深度伪造在游戏、娱乐等领域具有创意应用潜力,但其欺骗性质也引发了严重的伦理和安全隐患。<br />   - 可能被滥用于制造虚假信息、诽谤等违法行为。<br />4. 一些公司和研究人员正在开发新技术,以检测和防御深度伪造。<br />5. 深度伪造技术的发展将继续模糊数字与现实世界的界限,引发人们对"真实"的重新思考。<br /><br />点评:<br />1. 文章揭示了深度伪造技术的发展现状和潜在风险,引发读者对技术伦理的深思。<br />2. 深度伪造不仅挑战了人们对"真实"的认知,也可能对社会造成严重的不实信息危害。<br />3. 一些读者质疑,是否应该限制或禁止这种技术的发展,以防被滥用。<br />4. 另一种观点认为,深度伪造只是一种工具,关键在于如何正确使用和管控。<br />5. 文章启发人们思考,在技术快速发展的今天,我们如何保持理性和警惕。<br /><br />《Deepfakes: From Digital Reality to Fake Reality | Datafloq》 <a href="https://datafloq.com/read/deepfakes-digital-reality-fake-reality/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntpbqv5atj213j0u0n3d.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:49:59 GMT</pubDate>
</item>
<item>
<title>【大型语言模型(LLM)文本生成的理论速度极限】- LLM文本生成是一个按词(token)顺序进行的过程，当前词生成时依赖之前的所有词的状态，不存在并行的可能。 - LLM...</title>
<link>https://weibo.com/1402400261/O5nRLvdhX</link>
<guid>https://weibo.com/1402400261/O5nRLvdhX</guid>
<content:encoded><![CDATA[
<div> LLM 文本生成、速度极限、矩阵向量乘法、注意力计算、内存带宽限制、Mistral 7B模型、RTX 4090、理论速度极限分析、性能优化、推理性能

总结：<br /><br />本文从理论角度分析了LLM推理速度的极限，提出了计算最大FLOPS利用率和最小延迟时间的方法，为推理性能的衡量和优化提供了新思路。同时指出了影响实际推理速度的多个因素，启示我们在性能优化时需要全面考虑，不仅局限于计算本身。虽然理论极限难以达到，但仍是一个有意义的目标。文章专业性强，但对理解LLM推理性能优化具有重要指导意义。 <div>
【大型语言模型(LLM)文本生成的理论速度极限】<br />- LLM文本生成是一个按词(token)顺序进行的过程，当前词生成时依赖之前的所有词的状态，不存在并行的可能。   <br />- LLM主要包含两个运算：矩阵向量乘法和注意力计算，这两种运算都只需要对每个元素进行很少的浮点运算。   <br />- 现代CPU和GPU的算术运算速度远高于内存读取速度。因此LLM生成这类只需要对每个元素做少量运算的任务，其速度主要受内存带宽限制。   <br />- 以Mistral 7B模型为例，矩阵中的参数数量约为71亿，使用FP16时需要读取14.2GB数据。在RTX 4090(1008GB/s带宽)上理论最小生成时间是14.1ms/词。   <br />- 对比不同架构的实际速度与理论速度极限，可以评估软硬件实现的效率，并给进一步优化提供指导。   <br />- 矩阵向量乘法易受内存带宽限制，而注意力计算对内存大小也有严重影响。使用分组查询注意力(GQA)可以大幅减少注意力计算的内存需求。   <br />- 对于单用户单请求场景，理论速度极限是一个常数，可用于跨模型和设备评估预期性能，但多用户并发请求时，情况会改变。   <br />- 理论速度极限分析对于理解和优化LLM生成性能至关重要。<br /><br />点评：  <br />- 文章从理论角度分析了LLM推理速度的极限，这一视角有别于一般的性能优化讨论，具有独到之处。  <br />- 作者提出了计算理论最大FLOPS利用率和最小延迟时间的方法，为衡量和优化推理性能提供了新的思路。  <br />- 文章指出了影响实际推理速度的诸多因素，这启示我们在性能优化时需要全面考虑，而不仅仅局限于计算本身。  <br />- 尽管理论极限难以达到，但作者认为它仍然是一个有意义的目标，这一观点值得深思。  <br />- 文章虽然专业性强，但对于理解LLM推理性能优化具有重要指导意义。<br /><br />《zeux.io - LLM inference speed of light》 <a href="https://zeux.io/2024/03/15/llm-inference-sol/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hntp4m8oolj20u00ubtek.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:43:08 GMT</pubDate>
</item>
<item>
<title>【整数标记化(tokenization)：语言模型数字处理的”bug"?】- GPT模型的整数标记化(tokenize)方式存在很大问题，这让模型学习数学知识和表示数学事实变得非常困难...</title>
<link>https://weibo.com/1402400261/O5nMx2bXx</link>
<guid>https://weibo.com/1402400261/O5nMx2bXx</guid>
<content:encoded><![CDATA[
<div> 整数标记化, 语言模型, GPT模型, 十进制系统, 数学知识, 数学运算, 数字处理, 算法, 问题

<br /><br />总结: 
作者对GPT模型的整数标记化方式存在的问题提出了质疑，表示现有方法可能影响模型对数学知识的学习和运用。理想的数字系统应该遵循十进制系统，对0-9的整数使用唯一的token，而更大的整数则用这些token的组合表示。然而，GPT在处理整数时为大量整数分配了独立的token，导致模型无法应用通用数学运算算法，只能依赖记忆特殊情况出现的结果。这种不一致的整数分块标记化方式影响了模型的推理能力，对其理解和应用数学运算与算法的提高具有重要意义。整数tokenize的改进是关键所在，有望让GPT模型在数学能力上取得进步。 <div>
【整数标记化(tokenization)：语言模型数字处理的”bug"?】<br />- GPT模型的整数标记化(tokenize)方式存在很大问题，这让模型学习数学知识和表示数学事实变得非常困难。   <br />- 理想的数字系统应该对0-9的整数使用唯一的token，而更大的整数则用这些token的组合表示，以体现十进制系统。   <br />- 但GPT的tokenize方式并未遵循十进制系统，而是为大量整数独立分配了唯一的token。这导致模型无法应用通用的数学运算算法，只能依赖大量模式匹配记忆。   <br />- 不仅小整数受影响，在较大的整数中也存在大量独立token的情况，这同样导致了无法应用通用算法的问题。   <br />- 即使在非独立token的整数中，分割整数的方式也不一致，导致模型同样无法应用统一的运算逻辑。   <br />- 这让模型进行数字运算时必须记忆大量特殊情况下的结果，而非应用通用算法，增加了学习和推理的难度。   <br />- 整数tokenize的这些问题说明，GPT模型距离真正理解和应用数学运算与算法还有很长的路要走。tokenize方式的改进是模型在数学能力上提高的关键。<br /><br />点评:<br />1. 作者对现有的整数标记化方法提出质疑,认为其存在不合理之处。<br />2. 揭示了语言模型在处理数字时的特殊机制可能影响模型对数字的理解和运算能力。<br />3. 举例说明了整数分块标记化的不一致性,这一发现对优化语言模型的数字处理方式具有启发意义。<br /><br />《Integer tokenization is insane》 <a href="https://www.beren.io/2023-02-04-Integer-tokenization-is-insane/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntor0oe8lj20hs0dcwet.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hntor291rsj20hs0dcgn3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:30:14 GMT</pubDate>
</item>
<item>
<title>【开源路上，别让心理健康成了绊脚石】1. 开源维护者面临的心理健康挑战: - 工作与生活平衡 - 来自社区的期望和压力 - 个人对完美的追求2. 作者的应对方式: - 放...</title>
<link>https://weibo.com/1402400261/O5nGUCOBu</link>
<guid>https://weibo.com/1402400261/O5nGUCOBu</guid>
<content:encoded><![CDATA[
<div> 心理健康, 开源维护者, 压力, 应对方式, 社区, 建议, 展望, 资源, 可持续发展, 平衡

总结:<br /><br />本文探讨了开源维护者在面临心理健康挑战时的困境，包括工作与生活平衡、社区压力、追求完美等问题。作者提出了应对方式，如放慢节奏、写博客宣泄情绪、与社区沟通，以及对开源贡献者的建议，如设定合理预期、寻求帮助、关注自我等。同时，指出开源社区应营造友善氛围、关注心理健康、提供支持资源。关键在于不断学习调整，找到适合自己的方式，平衡投入和自我保护。 <div>
【开源路上，别让心理健康成了绊脚石】<br />1. 开源维护者面临的心理健康挑战:<br />   - 工作与生活平衡<br />   - 来自社区的期望和压力<br />   - 个人对完美的追求<br />2. 作者的应对方式:<br />   - 放慢节奏,享受过程而非执着于立竿见影的结果<br />   - 写博客梳理思路,宣泄负面情绪<br />   - 与社区保持开诚布公的沟通<br />3. 作者对开源贡献者的建议:<br />   - 设定合理预期,接纳"够好"的结果<br />   - 必要时寻求帮助,与他人分享感受<br />   - 关注自我,投入个人生活与兴趣爱好<br />4. 作者对开源社区的展望:<br />   - 营造友善、包容的氛围<br />   - 关注贡献者的心理健康<br />   - 提供更多帮助和支持资源<br />5. 开源之路没有完美的解决方案,关键是不断学习、调整,找到适合自己的方式。<br /><br />点评:<br />1. 开源工作获得回报的周期较长,需要贡献者保持耐心和动力。<br />2. 部分评论质疑开源是否必然导致心理压力,认为关键在于自我管理。<br />3. 有建议指出,参与者应主动控制参与度,必要时"说不"以保障个人生活。<br />4. 开源社区应提供更多支持资源,如心理健康指南、互助小组等。<br />5. 开源项目的可持续发展,需要在贡献者投入和自我保护间找到平衡。<br /><br />《Mental Health in Open Source》 <a href="https://antfu.me/posts/mental-health-oss"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntocrscepj20x00u0n1p.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sun, 17 Mar 2024 00:16:24 GMT</pubDate>
</item>
<item>
<title>今日推介(第1347期)：语言模型算法带来的改进速率评估、用合成数据进行模型高效评估、检索增强思维在长程生成中实现上下文感知推理、面向向量嵌入和结构化数据的...</title>
<link>https://weibo.com/1402400261/O5nfJ9Pv8</link>
<guid>https://weibo.com/1402400261/O5nfJ9Pv8</guid>
<content:encoded><![CDATA[
<div> 语言模型算法、改进速率评估、合成数据、模型高效评估、检索增强思维、长程生成、上下文感知推理、面向向量嵌入、结构化数据、高性能、谓词不可知搜索方法、持续学习、灾难性遗忘

总结:<br /><br />本文分析了语言模型算法带来的改进速率评估以及使用合成数据进行模型高效评估的方法。进一步讨论了检索增强思维在长程生成中实现上下文感知推理的重要性。同时介绍了面向向量嵌入和结构化数据的高性能和谓词不可知搜索方法的应用。最后，探讨了持续学习与灾难性遗忘的问题，为相关领域的研究提供了启示。 <div>
今日推介(第1347期)：语言模型算法带来的改进速率评估、用合成数据进行模型高效评估、检索增强思维在长程生成中实现上下文感知推理、面向向量嵌入和结构化数据的高性能和谓词不可知搜索方法、持续学习与灾难性遗忘  公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687438947"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.17)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntmepeyz2j20k0094jsj.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntmet15vnj20k00g50us.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hntmevbeezj20k00eptaq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntmezj2v6j20k00bfjs2.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hntmf23pboj20k006v0ty.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 23:09:24 GMT</pubDate>
</item>
<item>
<title>[LG] Poly-View Contrastive Learning 网页链接 展示了一种名为多视对比学习(Poly-View Contrastive Learning)的新框架，挑战了传统对比学习中常见的观点，即需...</title>
<link>https://weibo.com/1402400261/O5nbmvDDn</link>
<guid>https://weibo.com/1402400261/O5nbmvDDn</guid>
<content:encoded><![CDATA[
<div> 对比学习、多视对比学习、视角数量、样本总量、计算资源、训练周期、批次数量、表现优势、图像表示学习、高效性
<br /><br />总结:
研究展示了一种新框架——多视对比学习，挑战了传统对比学习观点，证明增加单个样本的视角数量而非样本总量可以获得更好的表现。使用多视角对比模型，在限定的训练周期和批次设置下，可以超越传统对比学习模型的效果。这一研究改变了对大批量和长周期训练需求的传统看法，为图像表示学习提供了新方向，突显了高效性。 <div>
[LG] Poly-View Contrastive Learning  <br /><a href="https://arxiv.org/abs/2403.05490"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />展示了一种名为多视对比学习(Poly-View Contrastive Learning)的新框架，挑战了传统对比学习中常见的观点，即需要大量样本和多个训练周期来提高性能。研究表明，通过增加单个样本的视角数量而非样本总量，可以在有限的计算资源下获得更优的表现。具体来说，使用多视角对比模型，在128个训练周期、每批次256个样本的设置下，就能超越标准对比学习模型SimCLR在1024个周期、每批次4096个样本的训练效果。该研究改变了对大批量和长周期训练需求的传统看法，为高效的图像表示学习指明了新方向。<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntm3w9ye2j213u1m2qoj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntm3wx3pxj21ui10awtc.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:58:40 GMT</pubDate>
</item>
<item>
<title>[CV] Score-Guided Diffusion for 3D Human Recovery 网页链接 介绍了一种名为Score-Guided Human Mesh Recovery(ScoreHMR)的新方法，用于解决3D人体姿态和形状...</title>
<link>https://weibo.com/1402400261/O5n8ZBO7k</link>
<guid>https://weibo.com/1402400261/O5n8ZBO7k</guid>
<content:encoded><![CDATA[
<div> Score-Guided Human Mesh Recovery, 3D人体姿态和形状重建, 扩散模型, 得分引导, 图像观测, 单帧模型拟合, 多视角重建, 视频序列, 基准测试

<br /><br />总结:
本文介绍了一种新方法Score-Guided Human Mesh Recovery (ScoreHMR) 用于解决3D人体姿态和形状重建的逆问题。与传统方法不同，该方法利用扩散模型的潜空间并通过得分引导实现与图像观测的对齐。该方法在多项基准测试中展现出较高的准确性，有效提高了单帧模型拟合、多视角重建和视频序列中人体动作的精度，超越了所有优化基准模型。ScoreHMR不需要特定任务的扩散模型再训练，具有较高的实用性。 <div>
[CV] Score-Guided Diffusion for 3D Human Recovery  <br /><a href="https://arxiv.org/abs/2403.09623"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为Score-Guided Human Mesh Recovery(ScoreHMR)的新方法，用于解决3D人体姿态和形状重建的逆问题。与传统优化或回归方法不同，ScoreHMR利用扩散模型的潜空间并通过得分引导来实现与图像观测的对齐。这种方法不需要对无依赖任务的扩散模型进行特定任务的再训练，有效地提高了单帧模型拟合、多视角重建和视频序列中人体动作的准确性，并在多项基准测试中超越了所有优化基准模型。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntlxtzz9ij21a81ich9h.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntlxunm8nj21qa0y8dt3.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:52:50 GMT</pubDate>
</item>
<item>
<title>[LG] Defending Against Unforeseen Failure Modes with Latent Adversarial Training 网页链接 深入探讨了AI系统部署后出现的意外行为，并提出一种新的防御手段...</title>
<link>https://weibo.com/1402400261/O5n6f85Bk</link>
<guid>https://weibo.com/1402400261/O5n6f85Bk</guid>
<content:encoded><![CDATA[
<div> 潜对抗训练, 意外行为, 防御手段, 潜表示层, 压缩, 抽象, 结构化, 图像分类, 文本分类, 文本生成

<br /><br />

总结: 本文深入探讨了AI系统部署后可能出现的意外行为，并提出了一种新的防御手段——潜对抗训练（LAT）。LAT通过在模型的潜表示层面干预，利用更加压缩、抽象和结构化的概念表示来防御未知的失败模式。实验证明，LAT在图像分类、文本分类和文本生成任务中，相比传统的对抗训练（AT），能提高模型对未知对抗样本类别的鲁棒性，同时移除特洛伊木马。这一发现显示LAT的潜力，为防御开发者无法明确识别的失败模式提供了可能的解决方案。 <div>
[LG] Defending Against Unforeseen Failure Modes with Latent Adversarial Training  <br /><a href="https://arxiv.org/abs/2403.05030"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />深入探讨了AI系统部署后出现的意外行为，并提出一种新的防御手段：潜对抗训练(LAT)。LAT区别于传统的对抗训练(AT)，它不通过生成触发模型失败的输入，而是在模型的潜表示层面进行干预，利用网络对信息进行处理时构建的更加压缩、抽象和结构化的概念表示。通过在图像分类、文本分类和文本生成任务中的实验表明，与AT相比，LAT通常能在不损害干净数据性能的同时，提高模型对未见过的对抗样本类别的鲁棒性，并能移除特洛伊木马。这一发现表明LAT可以成为一种有前景的工具，用于防御开发者无法显式识别的失败模式。<img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntlqrmnlzj212u1jctr6.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntlqql6xrj21hi1cudyi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:46:03 GMT</pubDate>
</item>
<item>
<title>[LG] ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training 网页链接 提出PROTLLM，一个能同时处理蛋白质中心和蛋白质-语言任务的...</title>
<link>https://weibo.com/1402400261/O5n3Awz5o</link>
<guid>https://weibo.com/1402400261/O5n3Awz5o</guid>
<content:encoded><![CDATA[
<div> PROTLLM、蛋白质挂载机制、蛋白质词表、InterPT、跨模态大型语言模型、零样本学习、上下文学习、蛋白质中心任务、蛋白质-语言任务、预训练数据集

<br /><br />总结:
PROTLLM是一个跨模态大型语言模型，具有动态蛋白质挂载机制，可以处理复杂输入中的任意数量蛋白质。通过专门的蛋白质词表，模型能够同时预测自然语言和蛋白质。研究构建了大规模的蛋白质-文本数据集InterPT用于预训练，融合了结构化和非结构化数据源。PROTLLM在蛋白质中心任务上表现优于基线模型，并展现出零样本学习和上下文学习的能力。这项研究为蛋白质-语言任务提供了新的解决方案，并为蛋白质研究领域带来了创新的进展。 <div>
[LG] ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training  <br /><a href="https://arxiv.org/abs/2403.07920"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出PROTLLM，一个能同时处理蛋白质中心和蛋白质-语言任务的跨模态大型语言模型(LLM)。其特色是动态蛋白质挂载机制，使模型能够处理含有任意数量蛋白质的复杂输入。通过开发专门的蛋白质词表，模型能够从大量候选者中预测自然语言和蛋白质。构建了一个大规模交错的蛋白质-文本数据集InterPT用于预训练，融合了结构化和非结构化数据源。PROTLLM在蛋白质中心任务上优于专门的基线，并且在蛋白质-语言任务上展示了零样本和上下文学习能力。<img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntljyrwk6j213a1je7nq.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntljzjjocj21fu11kakh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:39:31 GMT</pubDate>
</item>
<item>
<title>[CL] CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences 网页链接 介绍了CodeUltraFeedback和CODAL-Ben...</title>
<link>https://weibo.com/1402400261/O5n0v593n</link>
<guid>https://weibo.com/1402400261/O5n0v593n</guid>
<content:encoded><![CDATA[
<div> CodeUltraFeedback, CODAL-Bench, 数据集, 大型语言模型, 编程偏好, AI反馈, LLM-as-a-Judge方法, 偏好优化, 微调, RLAIF, 功能正确性, CodeLlama-7B-Instruct模型, SFT, DPO

总结:<br /><br />本文介绍了CodeUltraFeedback和CODAL-Bench，提供了一套用于微调和评估大型语言模型(LLM)以符合编程偏好的数据集和基准。CodeUltraFeedback包含复杂指令，通过AI反馈调整LLM偏好，反映了五种编程偏好。利用LLM-as-a-Judge方法对LLM的响应进行了标注，包括数值评分和文本反馈。研究表明经过微调的CodeLlama-7B-Instruct模型在功能正确性和偏好对齐方面表现优于基础模型和更大的34B LLM。这证明了CodeUltraFeedback在偏好调整中的实用性，以及SFT和DPO在提升LLM与人类编程偏好对齐方面的潜力。 <div>
[CL] CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences  <br /><a href="https://arxiv.org/abs/2403.09032"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了CodeUltraFeedback和CODAL-Bench，一套用于微调和评估大型语言模型(LLM)以符合编程偏好的数据集和基准。CodeUltraFeedback包含10000条复杂指令，用于通过AI反馈调整LLM偏好，反映了五种编程偏好。利用来自GPT-3.5的LLM-as-a-Judge方法，对LLM的响应进行了标注，包括数值评分和文本反馈。通过直接偏好优化(DPO)和AI反馈强化学习(RLAIF)的研究表明，经过微调的CodeLlama-7B-Instruct模型在功能正确性和偏好对齐方面均优于未微调的基础模型和更大的34B LLM。这证明了CodeUltraFeedback在偏好调整中的实用性，以及SFT和DPO在提升LLM与人类编程偏好对齐方面的潜力。<img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntlc1minqj218a1ic4nd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntlc27482j21b01c2du8.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntlc2bylej20y019cjyn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:31:54 GMT</pubDate>
</item>
<item>
<title>详尽分析了人工神经网络在持续学习过程中面临的灾难性遗忘挑战，探讨了六种主要的计算方法来提高持续学习能力，强调了在深度学习与认知科学之间建立联系的重要性...</title>
<link>https://weibo.com/1402400261/O5mVI6XCv</link>
<guid>https://weibo.com/1402400261/O5mVI6XCv</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工神经网络，持续学习，灾难性遗忘，深度学习，认知科学，计算方法，互相启发，发展，联系，挑战

总结:<br /><br />
本文详细分析了人工神经网络在持续学习过程中所面临的灾难性遗忘挑战，并通过探讨六种主要的计算方法来提高持续学习能力。作者强调了在深度学习与认知科学之间建立联系的重要性，旨在促进两个领域之间的互相启发和发展。文章指出，在人工智能领域持续学习是一个关键的问题，因为传统神经网络容易忘记之前学到的知识，导致新知识的学习会覆盖旧知识。为解决这一问题，提出了六种方法，包括反向传播、重放缓冲区、正交正则化、动态权重、增量学习和任务分解等。这些方法在一定程度上提高了人工神经网络的持续学习能力。同时，文章呼吁深度学习与认知科学之间建立更多的联系，通过相互启发和发展推动这两个领域的进步。这种综合性的研究方法可以为人工智能领域的持续学习问题带来新的突破。通过深入探讨人工神经网络如何应对灾难性遗忘挑战，可以不断提升其在持续学习任务中的表现，推动人工智能技术的发展。 <div>
详尽分析了人工神经网络在持续学习过程中面临的灾难性遗忘挑战，探讨了六种主要的计算方法来提高持续学习能力，强调了在深度学习与认知科学之间建立联系的重要性，旨在推动两领域的互相启发和发展。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Continual Learning and Catastrophic Forgetting》G M. v d Ven, N Soures, D Kudithipudi [KU Leuve &amp; University of Texas at San Antonio] (2024) <a href="https://arxiv.org/abs/2403.05175"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklqwed9j21eo0dwgs1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntklrqmumj21na0motf2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsa9x2j21n40kaaj9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsujzaj21n20nk7cy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntkznz89nj21120o7439.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:20:06 GMT</pubDate>
</item>
<item>
<title>[LG]《Continual Learning and Catastrophic Forgetting》G M. v d Ven, N Soures, D Kudithipudi [KU Leuve &amp; University of Texas at San Antonio] (2024) 网...</title>
<link>https://weibo.com/1402400261/O5mVF0Qpu</link>
<guid>https://weibo.com/1402400261/O5mVF0Qpu</guid>
<content:encoded><![CDATA[
<div> 学习，持续学习，灾难性遗忘，机器学习，人工智能，神经网络，模型，挑战，解决方案，实验<br />
<br />
总结:<br />
本文讨论了持续学习和灾难性遗忘的问题，提出了一种解决方案来解决这一挑战。研究人员指出，传统的机器学习算法在面对持续学习任务时会出现灾难性遗忘的情况，导致已学习过的知识被遗忘。为了克服这一问题，他们提出了一种基于神经网络的方法，通过对模型进行增量学习和保留重要信息的方式来解决灾难性遗忘。研究人员进行了一系列实验来验证他们的方法的有效性，结果表明他们的方法在持续学习任务中具有较好的性能表现。这项研究为解决持续学习和灾难性遗忘问题提供了新的思路和方法。 <div>
[LG]《Continual Learning and Catastrophic Forgetting》G M. v d Ven, N Soures, D Kudithipudi [KU Leuve &amp; University of Texas at San Antonio] (2024) <a href="https://arxiv.org/abs/2403.05175"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklqwed9j21eo0dwgs1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntklrqmumj21na0motf2.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsa9x2j21n40kaaj9.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntklsujzaj21n20nk7cy.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hntkznz89nj21120o7439.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:19:59 GMT</pubDate>
</item>
<item>
<title>ACORN是一种新的、性能优异且不限制谓词类型的混合搜索方法，通过改良HNSW索引和引入谓词子图遍历来同时高效处理向量和结构化数据，克服了传统方法在性能和搜索...</title>
<link>https://weibo.com/1402400261/O5mPdmC1P</link>
<guid>https://weibo.com/1402400261/O5mPdmC1P</guid>
<content:encoded><![CDATA[
<div> ACORN, HNSW索引, 混合搜索方法, 向量数据, 结构化数据, 高性能, 不限制谓词类型, 复杂多模态数据集, 高查询吞吐量, 低构建开销

<br /><br />总结:
研究介绍了一种新的混合搜索方法ACORN，它通过改良HNSW索引和引入谓词子图遍历来同时处理向量数据和结构化数据。ACORN能够高效处理复杂多模态数据集，克服了传统方法在性能和搜索谓词表达式上的限制。研究表明，ACORN实现了高查询吞吐量和低构建开销的优异性能，为搜索领域带来了新的可能性。 <div>
ACORN是一种新的、性能优异且不限制谓词类型的混合搜索方法，通过改良HNSW索引和引入谓词子图遍历来同时高效处理向量和结构化数据，克服了传统方法在性能和搜索谓词表达式上的限制，实现了在复杂多模态数据集上的高查询吞吐量和低构建开销。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [IR]《ACORN: Performant and Predicate-Agnostic Search Over Vector Embeddings and Structured Data》L Patel, P Kraft, C Guestrin, M Zaharia [Stanford University &amp; DBOS, Inc &amp; UC Berkeley] (2024) <a href="https://arxiv.org/abs/2403.04871"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkivhxhvj211e11eao2.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkivwjjlj210y0l4wh3.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkiwh65wj211a0tyjws.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hntkiwpg9jj21160jetb3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkiy3hepj213s0e2gnl.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkiy2ugdj20jg0d33zo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkiy3nidj213r0csgob.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hntkiy2z5dj213m08qgn0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hntkiy3nxyj20jg0f175q.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 22:04:06 GMT</pubDate>
</item>
<item>
<title>几篇论文实现代码：《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》(CVPR 2024) GitHub: github.c...</title>
<link>https://weibo.com/1402400261/O5jwVne0V</link>
<guid>https://weibo.com/1402400261/O5jwVne0V</guid>
<content:encoded><![CDATA[
<div> DNGaussian, 优化, 稀疏视图, 3D, 高斯辐射场, 全局局部深度规范化, GitHub, Pix2Gif, 运动引导扩散, GIF 生成, SSM, 视频扩散模型, 有效视频生成, 结构化状态空间, 语言模型, 可靠性, 过度训练, 下游任务

<br /><br />总结: 《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》提出了一种优化稀疏视图3D高斯辐射场的方法，通过全局局部深度规范化来改善渲染效果，代码可在GitHub上找到。《Pix2Gif: Motion-Guided Diffusion for GIF Generation》介绍了Pix2Gif，一种运动引导扩散技术，用于生成GIF图像。《SSM Meets Video Diffusion Models: Efficient Video Generation with Structured State Spaces》展示了SSM与视频扩散模型相结合，实现了有效的视频生成，采用了结构化状态空间。《Language models scale reliably with over-training and on downstream tasks》研究表明，语言模型在过度训练和下游任务中表现出可靠的扩展性，相关代码可在GitHub上获取。 <div>
几篇论文实现代码：<br />《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》(CVPR 2024) GitHub: github.com/Fictionarry/DNGaussian [fig1]<br />《Pix2Gif: Motion-Guided Diffusion for GIF Generation》(2024) GitHub: github.com/hiteshK03/Pix2Gif<br />《SSM Meets Video Diffusion Models: Efficient Video Generation with Structured State Spaces》(2024) GitHub: github.com/shim0114/SSM-Meets-Video-Diffusion-Models [fig2]<br />《Language models scale reliably with over-training and on downstream tasks》(2024) GitHub: github.com/mlfoundations/scaling<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnt3oac1q5j21iu0jiasp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnt3p0dq0hj22801904ns.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 13:40:48 GMT</pubDate>
</item>
<item>
<title>'Awesome-AISourceHub - AI科技领域高质量信息源列表’ GitHub: github.com/AmbroseX/Awesome-AISourceHub #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5jwP9UrG</link>
<guid>https://weibo.com/1402400261/O5jwP9UrG</guid>
<content:encoded><![CDATA[
<div> GitHub, AI, 科技, 高质量, 信息源, 列表, 开源项目, AmbroseX, Awesome-AISourceHub

总结:<br /><br />这是一个收集AI科技领域高质量信息源的开源项目，其中包括了各种资源列表和信息源，可以帮助人们更好地了解和学习关于人工智能的知识。由AmbroseX创建并维护，项目地址为github.com/AmbroseX/Awesome-AISourceHub。欢迎大家积极参与和贡献，共同打造一个强大的AI资源集合。 <div>
'Awesome-AISourceHub - AI科技领域高质量信息源列表’ GitHub: github.com/AmbroseX/Awesome-AISourceHub <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnt5z3jp2mj20y40u00y9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 13:40:33 GMT</pubDate>
</item>
<item>
<title>【EasyDetect：易于使用的多模态幻觉检测框架，用于多模态大型语言模型(MLLMs)如GPT-4V、Gemini、LlaVA的研究实验，通过统一的视角对多模态幻觉进行检测，包括模...</title>
<link>https://weibo.com/1402400261/O5j2octGD</link>
<guid>https://weibo.com/1402400261/O5j2octGD</guid>
<content:encoded><![CDATA[
<div> 多模态 幻觉检测框架 GPT-4V Gemini LlaVA 研究实验 统一视角 模态冲突 幻觉 事实冲突 幻觉

<br /><br />总结:
EasyDetect是一个易于使用的多模态幻觉检测框架，专为大型语言模型如GPT-4V、Gemini和LlaVA的研究实验而设计。该框架通过统一的视角对多模态幻觉进行检测，包括模态冲突幻觉和事实冲突幻觉。通过EasyDetect，研究人员可以更方便地进行多模态幻觉的实验和研究，从而深入探讨语言模型的表现和特性。 <div>
【EasyDetect：易于使用的多模态幻觉检测框架，用于多模态大型语言模型(MLLMs)如GPT-4V、Gemini、LlaVA的研究实验，通过统一的视角对多模态幻觉进行检测，包括模态冲突幻觉和事实冲突幻觉】’EasyDetect - An Easy-to-use Hallucination Detection Framework for LLMs.' GitHub: github.com/OpenKG-ORG/EasyDetect <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnt3t2xe1zj20i60fbdj0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnt3t5cqj1j20pp0gegqn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 12:25:34 GMT</pubDate>
</item>
<item>
<title>【ChatOllama：基于Nuxt 3和Ollama的聊天Web应用】'ChatOllama - a Nuxt 3 + Ollama web application. It's an example of Ollama Javascript library’ GitHub:...</title>
<link>https://weibo.com/1402400261/O5j0hzQkC</link>
<guid>https://weibo.com/1402400261/O5j0hzQkC</guid>
<content:encoded><![CDATA[
<div> ChatOllama、Nuxt 3、Ollama、web应用、GitHub、Javascript库、聊天应用、示例、开发、实现<br />
<br />总结:
ChatOllama是基于Nuxt 3和Ollama的聊天Web应用示例，使用Ollama Javascript库开发，代码托管在GitHub上，展示了如何开发和实现一个聊天应用。 <div>
【ChatOllama：基于Nuxt 3和Ollama的聊天Web应用】'ChatOllama - a Nuxt 3 + Ollama web application. It's an example of Ollama Javascript library’ GitHub: github.com/sugarforever/chat-ollama <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnt3ns8meej219c0jogny.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 12:20:23 GMT</pubDate>
</item>
<item>
<title>【Data is Better Together：由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。目前，该项目已经创...</title>
<link>https://weibo.com/1402400261/O5ihKbqgZ</link>
<guid>https://weibo.com/1402400261/O5ihKbqgZ</guid>
<content:encoded><![CDATA[
<div> Hugging Face, Argilla, 开源机器学习社区, 数据集, 合作, 提示, 排名, 10,000个, 质量

<br /><br />总结:
Data is Better Together是一个由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。该项目已经创建了一个由10,000个提示组成的数据集，并按照质量进行了排名。这个项目的目标是让开源社区共同努力，创造更好的数据集，为机器学习研究和实践提供更丰富的资源和支持。通过协作和合作，我们可以共同构建更具影响力和实用性的数据集，推动机器学习领域的发展和创新。 <div>
【Data is Better Together：由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。目前，该项目已经创建了一个由10,000个提示组成的数据集，按质量进行了排名】'Data is Better Together - Let's build better datasets, together!' GitHub: github.com/huggingface/data-is-better-together <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnt0hi5cbfj211y0lc78w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 10:30:39 GMT</pubDate>
</item>
<item>
<title>【OPEN TEACH: 多功能遥操作框架，使用Meta Quest3进行机器人操作，具有灵活性和多样性，包括VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，支持在各种...</title>
<link>https://weibo.com/1402400261/O5ih2p7R0</link>
<guid>https://weibo.com/1402400261/O5ih2p7R0</guid>
<content:encoded><![CDATA[
<div> 多功能遥操作框架, Meta Quest3, 机器人操作, 灵活性, 多样性, Unity脚本, 遥操作流程, 数据收集流程, 策略训练, GitHub  

<br /><br />总结:  
这篇文章介绍了一个名为"OPEN TEACH"的多功能遥操作框架，使用Meta Quest3进行机器人操作，并具有灵活性和多样性。该框架包括了VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，能够支持在各种机器人和仿真环境下进行遥操作和数据收集，并针对不同机器人和仿真进行策略训练。该框架的GitHub链接为github.com/aadhithya14/Open-Teach。 <div>
【OPEN TEACH: 多功能遥操作框架，使用Meta Quest3进行机器人操作，具有灵活性和多样性，包括VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，支持在各种机器人和仿真环境下进行遥操作和数据收集，并针对不同机器人和仿真进行策略训练】'OPEN TEACH: A Versatile Teleoperation System for Robotic Manipulation - A Versatile Teleoperation framework for Robotic Manipulation using Meta Quest3' GitHub: github.com/aadhithya14/Open-Teach <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnt0fre8fpj21ji0twwkh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 10:28:54 GMT</pubDate>
</item>
<item>
<title>今日推介(第1346期)：让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、用Moment Pooling简化机器学习...</title>
<link>https://weibo.com/1402400261/O5dqgdQEc</link>
<guid>https://weibo.com/1402400261/O5dqgdQEc</guid>
<content:encoded><![CDATA[
<div> 语言模型、结构化训练、灾难性遗忘、预期性恢复、马尔可夫决策过程、学习算法、Moment Pooling、机器学习潜空间、API保护、LLM的Logits

<br /><br />总结:
本文介绍了几个关键的技术和方法，包括让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、以及用Moment Pooling简化机器学习潜空间。另外，还提到了API保护LLM的Logits会泄漏模型专有信息的问题。这些方法和技术对于改进语言模型的能力，提高机器学习算法的效率和精确度都具有重要意义。通过不断探索和应用这些新技术，我们可以进一步推动人工智能领域的发展，为未来带来更多可能性。 <div>
今日推介(第1346期)：让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、用Moment Pooling简化机器学习潜空间、API保护LLM的Logits会泄漏模型专有信息 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687311397"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.16)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnsf0htg36j20k00b9gn7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnsf0k1lqgj20k006m751.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnsf0ml60tj20k007d0t5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnsf0p0i2ij20k00kq762.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnsf0repglj20k008pwfi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 22:07:54 GMT</pubDate>
</item>
<item>
<title>[RO] GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping 网页链接 提出一种名为GaussianGrasper的开放词表机器人抓取技术...</title>
<link>https://weibo.com/1402400261/O5dn86Ikc</link>
<guid>https://weibo.com/1402400261/O5dn86Ikc</guid>
<content:encoded><![CDATA[
<div> 高斯Splatting、机器人抓取技术、3D构建、视角输入、推理效率、特征蒸馏、对比学习、抓取姿态、语言指令、场景更新
<br /><br />总结:
提出了一种名为GaussianGrasper的开放词表机器人抓取技术，通过3D高斯Splatting构建场景，解决了传统隐式场景表达的问题。利用有限的RGB-D视角和高效特征蒸馏模块，结合对比学习来准确提取语言嵌入，使得预训练的抓取模型可以生成无碰撞的抓取姿态候选。通过法向引导的抓取模块选取最佳姿态。实验证明，该系统能准确响应语言指令，执行抓取任务，并实现快速场景更新。提供了新的解决方案用于语言引导操作任务，并公开了数据和代码资源。 <div>
[RO] GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping  <br /><a href="https://arxiv.org/abs/2403.09637"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出一种名为GaussianGrasper的开放词表机器人抓取技术，它通过3D高斯Splatting显式构建场景，解决了传统隐式场景表达(例如NeRF)需要大量视角输入和推理效率低下的问题。GaussianGrasper利用有限的RGB-D视角并通过一种高效特征蒸馏(EFD)模块，结合对比学习来准确提取语言嵌入。这使得其预训练的抓取模型能生成无碰撞的抓取姿态候选，并通过法向引导的抓取模块选取最佳姿态。实验表明，该系统能准确响应语言指令，执行抓取任务，并实现快速场景更新。此外，提供了用于语言引导操作任务的新解决方案，并公开了数据和代码资源。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsesr3i0dj219w1kc1kx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsesrglfpj21hq17uqlw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsesrlyxgj21h40uqqif.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 22:00:11 GMT</pubDate>
</item>
<item>
<title>[CV] Reconstruction and Simulation of Elastic Objects with Spring-Mass 3D Gaussians 网页链接 提出了Spring-Gaus框架，一个整合物理仿真和3D高斯模型的新方...</title>
<link>https://weibo.com/1402400261/O5difnNAc</link>
<guid>https://weibo.com/1402400261/O5difnNAc</guid>
<content:encoded><![CDATA[
<div> Spring-Gaus, 物理仿真, 3D高斯模型, 弹性物体, 多视角视频, 参数优化, 模拟粒子, 样本效率, 泛化能力, 形变预测

<br /><br />总结:
本文提出了Spring-Gaus框架，结合了物理仿真和3D高斯模型，用于重建和模拟弹性物体。通过3D弹簧-质点模型在个体点级别优化物理参数，解决了物理和外观学习的问题，提高了样本效率和泛化能力。Spring-Gaus在合成和真实数据集上证明了有效性，特别是在形变预测和不同环境参数下的模拟中表现出色。这一研究突破了物理参数优化和异质物体建模的限制，为预测视觉感知和沉浸式体验的应用提供了新的可能性。 <div>
[CV] Reconstruction and Simulation of Elastic Objects with Spring-Mass 3D Gaussians  <br /><a href="https://arxiv.org/abs/2403.09434"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出了Spring-Gaus框架，一个整合物理仿真和3D高斯模型的新方法，用于从多视角视频重建和模拟弹性物体。与传统的3D高斯方法相比，Spring-Gaus通过3D弹簧-质点模型在个体点级别优化物理参数，有效解缠物理和外观学习。这种方法提高了样本效率，增强了泛化能力，并减少了对仿真粒子分布的敏感性。在合成和真实世界数据集上的评估证明了Spring-Gaus在准确重建和模拟弹性物体方面的有效性，尤其是在进行未来形变预测和不同初始状态及环境参数下的模拟时。该研究突破了物理参数优化和异质物体建模的限制，为预测视觉感知和沉浸式体验的应用开辟了可能。<img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnseg8bri1j20z41e6wrp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnseg8nm5cj21fa0wstjg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnseg9gk2gj21fa1au18j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:48:10 GMT</pubDate>
</item>
<item>
<title>[LG] Majority-of-Three: The Simplest Optimal Learner? 网页链接 讨论了PAC学习中的一个开放问题：在实现环境下，寻找最简单的最优学习算法。分析了一个简单的...</title>
<link>https://weibo.com/1402400261/O5deGfwNR</link>
<guid>https://weibo.com/1402400261/O5deGfwNR</guid>
<content:encoded><![CDATA[
<div> 多数投票法, 最优学习算法, PAC学习, 期望误差, 高概率误差, Bagging算法, ERM分类器, 最优误差界, one-inclusion graph算法, 简化算法结构

<br /><br />总结:
本文讨论了在实现环境下寻找最简单的最优学习算法的问题，并提出了多数投票法可能是一个简单且最优的解决方案。该算法使用三个ERM分类器，在期望误差上达到了最优，并且在高概率误差上也接近最优。该发现挑战了之前认为ERM分类器无法独自实现最优误差界的观点。文章还提出了改进的Bagging算法，简化了之前复杂的算法结构。另外，研究指出了one-inclusion graph算法在高概率误差上的局限性，与之前的猜想相反。通过进一步分析，多数投票法可能在高概率误差上也是最优的。整体而言，本文为最简单有效的学习算法提供了新的思路，并拓展了对学习算法的理解。 <div>
[LG] Majority-of-Three: The Simplest Optimal Learner?  <br /><a href="https://arxiv.org/abs/2403.08831"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />讨论了PAC学习中的一个开放问题：在实现环境下，寻找最简单的最优学习算法。分析了一个简单的算法——多数投票法，其中只使用三个ERM分类器。文章的核心是这个算法在期望误差上达到了最优，并且近似于高概率误差上的最优。这一发现挑战了之前的认知，即ERM分类器无法独自实现最优误差界。本文还提出一种改进的Bagging算法，简化了之前复杂的算法结构，但分析过程仍然复杂。此外，一项新的研究揭示了one-inclusion graph算法在高概率误差上的局限性，这与之前Warmuth的猜想相反。本文认为，通过进一步分析，上述多数投票法可能在高概率误差上也是最优的。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnse738777j21841gmh1p.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnse73lpebj21co0zoqa5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:39:22 GMT</pubDate>
</item>
<item>
<title>[CV] MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training 网页链接 介绍了多模态大型语言模型(MLLM)的构建，重点在于体系结构组件和数据选择...</title>
<link>https://weibo.com/1402400261/O5dbMeVyI</link>
<guid>https://weibo.com/1402400261/O5dbMeVyI</guid>
<content:encoded><![CDATA[
<div> 模态语言模型 构建 组件 数据 体系结构 图像编码器 视觉语言连接器 预训练数据<br />
<br />
总结: 本文介绍了多模态大型语言模型(MLLM)的构建方法和分析，强调了体系结构组件和数据选择的重要性。研究发现，混合使用图像-文字、交错图像-文字和纯文字数据对实现少样本最先进结果(SOTA)至关重要。此外，图像编码器、图像分辨率和图像标记数量对结果有显著影响。作者构建了一个最高达30B参数的模型族MM1，通过大规模预训练实现了竞争性性能，并展现了吸引人的特性，能够实现少样本的连锁思维提示。 <div>
[CV] MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training  <br /><a href="https://arxiv.org/abs/2403.09611"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了多模态大型语言模型(MLLM)的构建，重点在于体系结构组件和数据选择的重要性。通过对图像编码器、视觉语言连接器和不同预训练数据选项的详尽剖析，揭示了几个关键设计经验。研究表明，混合使用图像-文字、交错图像-文字和纯文字数据对于实现多项基准测试中的少样本最先进结果(SOTA)至关重要。此外，图像编码器、图像分辨率和图像标记数量对结果有显著影响，而视觉-语言连接器设计的影响相对较小。作者通过扩大模型规模，构建了一个最高达30B参数的模型族MM1，包括密集型模型和专家混合型变体，这些模型在预训练度量上表现出色，并在一系列多模态基准测试中经过监督微调后获得了竞争性性能。MM1的大规模预训练赋予了它如上下文预测、多图像推理等吸引人的特性，使其能够实现少样本的连锁思维提示。<img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdzmld2pj21201iuapu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdzn0s90j21hk13aaq5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdznf268j21hk0tytm5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdznnj32j21hm0qiaiy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:32:13 GMT</pubDate>
</item>
<item>
<title>揭示了通过分析LLM API的输出，即便是在API保护下，仍能通过较少的成本就能获取大量关于大型语言模型(如OpenAI gpt-3.5-turbo)的私有参数和结构信息，强调了这种...</title>
<link>https://weibo.com/1402400261/O5d99bA9M</link>
<guid>https://weibo.com/1402400261/O5d99bA9M</guid>
<content:encoded><![CDATA[
<div> API保护、LLM、私有参数、结构信息、模型透明度、问责性、信息泄露、特性、分析、有效性<br />
<br />
提到了一种通过分析LLM API输出获取私有参数和结构信息的方法，即使在API保护下也能实现。强调了这种方法的有效性，指出可以将其作为一种特性来提高模型的透明度和问责性。文章的研究结果揭示了重要的信息泄露问题，也提示了提高模型透明度的重要性。这种方法对于模型的安全性和隐私保护具有重要影响，值得深入研究和思考。<br /><br />总结: 提出了一种通过分析LLM API输出泄露私有信息的方法，并强调了其有效性以及作为提高模型透明度和问责性的特性。 <div>
揭示了通过分析LLM API的输出，即便是在API保护下，仍能通过较少的成本就能获取大量关于大型语言模型(如OpenAI gpt-3.5-turbo)的私有参数和结构信息，强调了这种获取信息方法的有效性，指出如何将此作为一种特性来提高模型的透明度和问责性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) <a href="https://arxiv.org/abs/2403.09539"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdhz8pyhj21oc15s7p2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdhzlf91j21ks0w4wqg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdhzq3auj21ke0oigsg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdi02jdij21l80pe118.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdsgpg07j20ve0dy764.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdsgoh8fj20vg0dqq55.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdsgpg6xj20vd090aar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:25:44 GMT</pubDate>
</item>
<item>
<title>[CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) 网页链接...</title>
<link>https://weibo.com/1402400261/O5d8YfyGJ</link>
<guid>https://weibo.com/1402400261/O5d8YfyGJ</guid>
<content:encoded><![CDATA[
<div> API-Protected LLMs, Logits, Leakage, Proprietary Information, Privacy, Data Security, Machine Learning, Information Disclosure

总结:<br /><br />本文研究了API保护的语言模型（LLMs）的Logits可能泄漏专有信息的问题。研究人员发现，即使在API保护的情况下，LLMs的输出Logits也可能包含公司的机密信息。这种信息泄漏可能导致数据隐私和安全方面的问题。因此，需要采取相应的措施来确保机器学习模型不会泄露敏感信息，保障数据安全。 <div>
[CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) <a href="https://arxiv.org/abs/2403.09539"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdhz8pyhj21oc15s7p2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdhzlf91j21ks0w4wqg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdhzq3auj21ke0oigsg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdi02jdij21l80pe118.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdsgpg07j20ve0dy764.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdsgoh8fj20vg0dqq55.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdsgpg6xj20vd090aar.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:25:18 GMT</pubDate>
</item>
<item>
<title>提出一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来显著降低潜空间维数，同时保持或提升模型性能，并以更少的基函数构建相同的机器学习...</title>
<link>https://weibo.com/1402400261/O5d3xurjA</link>
<guid>https://weibo.com/1402400261/O5d3xurjA</guid>
<content:encoded><![CDATA[
<div> 关键词: Moment Pooling, 深度集网络, 多变量矩, 潜空间维数, 模型性能, 基函数, 机器学习观测值, 可视化, 解释.

总结:<br /><br />本文提出了一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来降低潜空间维数，以提升模型性能。这一方法能够在更少的基函数下构建相同的机器学习观测值，使得模型内部表示可以更简单地进行可视化和解释。 Moment Pooling 的应用可以显著简化潜在空间的维数，帮助提升模型的性能，并且使得模型更容易解释和理解。通过对多变量矩的运用，Moment Pooling 可以在保持甚至提升模型性能的同时，降低所需的基函数数量，从而简化模型构建和解释过程。这一方法有望为机器学习领域带来更高效和可解释的模型设计。 <div>
提出一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来显著降低潜空间维数，同时保持或提升模型性能，并以更少的基函数构建相同的机器学习观测值，使得模型内部表示的可视化和解释变得更加简单。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) <a href="https://arxiv.org/abs/2403.08854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdd9vs67j21is0gyk1g.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsddafjn1j21mo0w2472.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddapji1j21901amtg7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddav53cj20vi10c79w.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c6wmj20jp0o3q5d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6f420j2140147afj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6bkxyj20jp0litak.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsde6g62dj2140156dpr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6drm7j2140156jva.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:11:56 GMT</pubDate>
</item>
<item>
<title>[LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) 网页链接 ...</title>
<link>https://weibo.com/1402400261/O5d3oBouU</link>
<guid>https://weibo.com/1402400261/O5d3oBouU</guid>
<content:encoded><![CDATA[
<div> Streamlining, Latent Spaces, Machine Learning, Moment Pooling, MIT, Gambhir, Osathapan, Thaler, 2024

<br /><br />总结:
本文探讨了在机器学习中利用矩阵池化来简化潜在空间的方法。研究人员提出了一种称为Moment Pooling的新技术，通过将不同阶数的矩阵进行池化，从而提高了模型在学习高阶统计特性方面的能力。这种技术不仅能够提高模型的效率，还能够减少模型对大规模数据集的需求。研究还表明，Moment Pooling技术在训练时间和模型性能之间取得了良好的平衡，为机器学习领域的实践带来了新的启示。MIT的研究人员Gambhir、Osathapan和Thaler的工作为机器学习领域的发展提供了有益的思路和方法。 <div>
[LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) <a href="https://arxiv.org/abs/2403.08854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdd9vs67j21is0gyk1g.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsddafjn1j21mo0w2472.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddapji1j21901amtg7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddav53cj20vi10c79w.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c6wmj20jp0o3q5d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6f420j2140147afj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6bkxyj20jp0litak.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsde6g62dj2140156dpr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6drm7j2140156jva.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6ceorj20jp0l1dhh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6d31vj21400ki77c.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c36cj20jp0khgn1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6d5zdj20z20jpgny.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6dr66j20zc0jqtb4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:11:35 GMT</pubDate>
</item>
<item>
<title>创新性地提出了一个学习算法框架，用于在完全和部分知识情况下进行马尔可夫决策过程的验证，特别是在不需要MDP结构特性假设和时间界限的情况下，通过启发式方法...</title>
<link>https://weibo.com/1402400261/O5d2K9Lno</link>
<guid>https://weibo.com/1402400261/O5d2K9Lno</guid>
<content:encoded><![CDATA[
<div> 马尔可夫决策过程、学习算法、验证、完全知识、部分知识、MDP结构、时间界限、概率可达性、启发式方法、停止准则

<br /><br />总结:
该研究提出了一个学习算法框架，可用于验证马尔可夫决策过程，在完全和部分知识情况下，无需MDP结构特性假设和时间界限。通过启发式方法提供了概率可达性的精确和概率界，同时提出了适应性强的停止准则。这一创新性方法有望在解决复杂决策问题中发挥重要作用。 <div>
创新性地提出了一个学习算法框架，用于在完全和部分知识情况下进行马尔可夫决策过程的验证，特别是在不需要MDP结构特性假设和时间界限的情况下，通过启发式方法提供了概率可达性的精确和概率界，同时提出了适应性强的停止准则。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Learning Algorithms for Verification of Markov Decision Processes》T Brázdil, K Chatterjee, M Chmelik, V Forejt, J Křetínský, M Kwiatkowska, T Meggendorfer, D Parker, M Ujma [Google LLC &amp; IST Austria &amp; Lancaster University Leipzig] (2024) <a href="https://arxiv.org/abs/2403.09184"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdb2ek9bj210m0mb12q.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdb2s9l9j21ce0pwtbu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdb38x14j21n20lqq6c.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdb3sanvj21rg0ecwgs.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:09:58 GMT</pubDate>
</item>
<item>
<title>恭喜@sayfh_wu-wuy_su私人领域-_- 等3名用户获得【《SPSSAU科研数据分析方法与应用》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效...</title>
<link>https://weibo.com/1402400261/O56k4DmCh</link>
<guid>https://weibo.com/1402400261/O56k4DmCh</guid>
<content:encoded><![CDATA[
<div> SPSSAU, 数据分析, 科研, 应用, 抽奖, 微博, 研究方法, 问卷数据, 医学数据, 视频讲解

<br /><br />总结:
微博举办了一次抽奖活动，三名幸运用户将获得《SPSSAU科研数据分析方法与应用》。这本书系统介绍了科研数据分析方法，适合研究者快速学习和掌握。活动截止时间是2024年3月15日12:00，感兴趣的用户需要转发和评论才能参与。活动结果将通过微博官方唯一抽奖工具监督，公正有效。该书涵盖了数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等方面，并配有171集视频讲解，帮助研究者更好地理解科研数据分析方法。 <div>
恭喜<a href="https://weibo.com/n/sayfh_wu-wuy_su%E7%A7%81%E4%BA%BA%E9%A2%86%E5%9F%9F-_-">@sayfh_wu-wuy_su私人领域-_-</a> 等3名用户获得【《SPSSAU科研数据分析方法与应用》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20117566&amp;pageid=100140E51183068"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00，*可可粉*转发+评论即可参与。近万篇研究论文选用SPSSAU快速入门，本书从数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等五个方面系统地介绍科研数据的分析方法，涉及13项知识类应用（如影响关系、权重关系、数据预测、问卷研究）附赠171集配套视频讲解，适合研究者快速学习和掌握科研数据分析方法。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5009557898134749"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnj8n91y6bj20m80m8n19.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnj8n9h45kj20m80m8mzs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9rlbnj20m80m8tbk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9wj7pj20m80m80vr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 04:03:26 GMT</pubDate>
</item>
<item>
<title>【艺术成功之路：声誉与网络的量化分析】- 研究人员重建了50万名艺术家的展览历史，绘制出反映艺术在机构之间流动的共同展览网络。 - 在这个网络中的中心性捕捉...</title>
<link>https://weibo.com/1402400261/O54JlkeLD</link>
<guid>https://weibo.com/1402400261/O54JlkeLD</guid>
<content:encoded><![CDATA[
<div> 艺术家、声誉、网络、展览历史、职业轨迹、早期进入高声望机构、马尔可夫模型、原籍国、潜在政策、彩票系统

<br /><br />总结:研究人员通过重建艺术家展览历史，揭示了艺术界展览网络结构和声誉对艺术家职业成功的影响。进入声誉高的机构能提供终身影响，早期选择机构会影响职业轨迹。原籍国可影响艺术家初始声誉和职业发展，建议实施彩票系统以提高公平竞争。研究虽然量化了准入壁垒，但仍需关注艺术评估的主观性和非实物艺术形式。艺术家应在更广泛机构展出，挑战传统观点，同时要面对可能的阻力。不同原籍国在全球化艺术世界中仍对艺术家有影响，呼吁更多关注多维度的审视。 <div>
【艺术成功之路：声誉与网络的量化分析】<br />- 研究人员重建了50万名艺术家的展览历史，绘制出反映艺术在机构之间流动的共同展览网络。  <br />- 在这个网络中的中心性捕捉了机构的声望，允许分析单个艺术家在获取理想机构方面的职业轨迹。  <br />- 早期进入声望高、处于中心位置的机构，可以为艺术家提供终身进入高声望场所的机会，并降低退出率。  <br />- 从网络边缘开始职业生涯会导致高退出率，限制进入中心机构的机会。  <br />- 一个马尔可夫模型可以预测艺术家的职业轨迹，记录了艺术价值评估中强烈的路径依赖和历史依赖。  <br />- 艺术家最初声望(前五次展览)的分布因其原籍国而异，影响他们职业成功的机会。  <br />- 该研究量化了艺术界的分层和准入壁垒，提出了潜在的政策，如彩票系统，以营造公平的竞争环境。  <br /><br />思考：  <br />- 该研究提供了声誉和网络在主观领域(如艺术)中决定资源和回报获取的量化见解，在这些领域中很难客观衡量表现。  <br />- 早期进入声望高的机构会产生终身影响，这一发现挑战了精英制的概念，凸显了初始机会的重要性。  <br />- 该研究关注机构准入和经济价值，可能忽略了艺术丰富社会的其他维度，如文化和情感价值。  <br />- 艺术家原籍国影响其初始声望和职业轨迹，这一观察结果引发了对艺术界系统性偏见和不平等的质疑。  <br />- 建议在艺术界实施彩票系统或盲选程序以提高代表性不足艺术家的包容性，可能面临既得利益机构和艺术界的阻力。  <br />- 尽管该研究量化了准入壁垒，但并未直接解决艺术评估的主观性质以及评估过程中固有的潜在偏见。  <br />- 该研究依赖展览和拍卖数据，可能低估了非实物艺术形式，如行为艺术，因为这些艺术形式无法通过这些渠道捕捉。   <br />- 研究发现，在职业生涯早期在更广泛的机构展出可以提高突破的机会，这挑战了专注于特定领域或风格的传统观点。  <br />- 该研究建议在艺术界实施彩票系统或盲选程序，这些做法更常见于就业或音乐试演等领域。  <br />- 观察到艺术家的原籍国影响其初始声望和职业轨迹，这一点有悖常理，因为在全球化的艺术世界中，人们可能认为天赋与地理因素无关。<br />《Quantifying reputation and success in art | Science》 <a href="https://www.science.org/doi/10.1126/science.aau7224"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnrcnblrptj20u00x113j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 00:00:12 GMT</pubDate>
</item>
<item>
<title>【Cappy：用小型评分器提升大型语言模型性能】 - Google研究人员提出了一种名为Cappy的新方法，可以通过一个小型评分器(scorer)来提升和增强大型多任务语言模型...</title>
<link>https://weibo.com/1402400261/O54Dc9dTt</link>
<guid>https://weibo.com/1402400261/O54Dc9dTt</guid>
<content:encoded><![CDATA[
<div> Cappy, 小型评分器, 大型语言模型, 性能提升, 多任务, 输出质量, 灵活性, 高效性, 实际应用, 可扩展性

<br /><br />总结: 
Google研究人员提出了一种名为Cappy的新方法，通过引入一个小型评分器来提升和增强大型多任务语言模型的性能。Cappy利用评分器重新排序生成的候选输出，提高输出质量。评分器是一个轻量级神经网络模型，专门用于评估候选输出质量，并与大型语言模型结合。Cappy在多个基准测试中展现出优异性能，提高大型模型表现。该方法灵活性强，可与各种大型语言模型结合，适用于不同任务。尽管在基准测试中表现出色，实际应用场景中的效果和可扩展性还需进一步验证。Cappy的高效性和轻量设计或将受益于未来硬件发展，如专用AI加速器。然而，引入新的偏差和不确定性也需进一步研究和优化。Cappy为提高大型语言模型性能提供了新的范式。 <div>
【Cappy：用小型评分器提升大型语言模型性能】  <br />- Google研究人员提出了一种名为Cappy的新方法，可以通过一个小型评分器(scorer)来提升和增强大型多任务语言模型的性能。  <br />- Cappy利用一个小型评分器来重新排序大型语言模型生成的候选输出，从而提高输出质量。  <br />- 评分器是一个轻量级的神经网络模型，专门用于评估候选输出的质量，而不负责生成输出。  <br />- 在多个基准测试中，Cappy展现出优于大型语言模型的性能，同时也能够提升这些大型模型的表现。  <br />- Cappy的优势在于其高效性和灵活性，可以与各种大型语言模型相结合，并在不同任务上发挥作用。  <br />- 研究人员认为，Cappy为提高大型语言模型的性能和效率提供了一种新的范式。  <br /><br />思考：  <br />- Cappy的提出解决了大型语言模型在某些任务上表现不佳的问题，通过引入一个小型评分器来提升整体性能，这种思路值得关注。  <br />- 将生成和评估分离的方法使Cappy具有灵活性，可以与不同的大型模型相结合，提高了其适用范围。  <br />- 尽管Cappy在基准测试中表现出色，但其在实际应用场景中的效果和可扩展性仍有待进一步验证。  <br />- Cappy的高效性和轻量设计可能会受益于未来硬件的发展，如专用AI加速器等，从而进一步提升其性能。  <br />- 虽然Cappy旨在提高大型语言模型的性能，但其本身也可能引入新的偏差和不确定性，需要进一步研究和优化。<br />《Cappy: Outperforming and boosting large multi-task language models with a small scorer – Google Research Blog》 <a href="https://blog.research.google/2024/03/cappy-outperforming-and-boosting-large.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnrc7chdqkj21780go75q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc7csa3qj21jj0r3q63.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnrc7dkpzrj21jj0c6jv0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc7ffs7jj21jj0sw42p.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnrc7fyfiuj21hb0u0goi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:45:03 GMT</pubDate>
</item>
<item>
<title>【聊天机器人变身生产力助手：Command-R用Tool Use功能重塑业务工作流】- Cohere推出了Command-R模型的Tool Use功能，使语言模型能够与用户定义的工具交互，实现...</title>
<link>https://weibo.com/1402400261/O54B6h2pa</link>
<guid>https://weibo.com/1402400261/O54B6h2pa</guid>
<content:encoded><![CDATA[
<div> Command-R, Tool Use, 应用示例, 生产力助手, 跨平台, 自动化工作流程, 部署灵活性, 实施过程, AI应用, 语言模型

<br /><br />总结: 
Command-R推出了Tool Use功能，使语言模型能够与外部工具交互，执行复杂任务，提升生产力。该功能连接不同应用程序和系统，实现跨平台的自动化工作流程。结合Tool Use，Command-R从聊天机器人发展为强大的生产力助手和研究工具，可能改变AI交互方式。平衡了性能、效率和部署灵活性，适用于构建AI应用，突破了单一云环境的限制。企业实施Tool Use的简化四步过程降低了门槛，加速了应用，但需评估具体需求和系统兼容性。 <div>
【聊天机器人变身生产力助手：Command-R用Tool Use功能重塑业务工作流】<br />- Cohere推出了Command-R模型的Tool Use功能，使语言模型能够与用户定义的工具交互，实现高度复杂任务的自动化。  <br />- Command-R在Tool Use模式下可以根据用户交互和对话历史创建API负载(包含特定参数的JSON)，用于指示其他应用程序或工具。  <br />- Tool Use的应用示例包括自动分类和路由支持凭证、更新客户关系管理软件(CRM)中的状态，以及从向量数据库中检索相关片段。  <br />- 应用的输出会反馈给Command-R，用于生成最终响应。响应中包含引用，便于用户从源数据或工具结果中追溯声明。  <br />- Tool Use使Command-R的应用从简单的聊天机器人发展为强大的代理和研究工具，提高了生产力。  <br />- Command-R在高效率、强大性能和跨主要云提供商的灵活部署之间取得了平衡，是构建依赖Tool Use的AI应用的有竞争力的解决方案。  <br />- 在企业中实施Tool Use对开发人员来说是一个简单的四步过程。  <br /><br />思考：  <br />- Tool Use功能突破了语言模型仅限于自然语言处理的边界，使其能够与外部工具交互，执行复杂的任务和工作流程，开辟了语言模型应用的新领域。  <br />- Command-R与Tool Use的结合，使聊天机器人从简单的对话工具转变为强大的生产力助手和研究辅助工具，这可能改变我们与AI交互和协作的方式。  <br />- Tool Use通过自然语言交互连接不同的应用程序和系统，实现了跨平台的自动化工作流程，这种方法简化了复杂任务的自动化过程，提高了效率。  <br />- Command-R在性能、效率和部署灵活性方面的平衡，使其成为构建基于Tool Use的AI应用的理想选择，这表明语言模型的应用不再局限于单一的云环境。  <br />- 简化的四步实施过程降低了企业采用Tool Use的门槛，有望加速其在实际业务场景中的应用，但企业仍需评估其具体需求和现有系统的兼容性。<br />《Introducing Tool Use With Command-R: Seamlessly Automate Business Workflows》 <a href="https://txt.cohere.com/tool-use-with-command-r/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnrc23fa5bj20v40l83zo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc23o7u5j20qo0f00ue.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:39:53 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;携手@博文视点Broadview 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00...</title>
<link>https://weibo.com/1402400261/O54zSFqzU</link>
<guid>https://weibo.com/1402400261/O54zSFqzU</guid>
<content:encoded><![CDATA[
<div> SPSSAU、数据分析、研究方法、应用、科研、快速入门、知识类、视频讲解、研究者、学习

总结:<br /><br />今天开奖活动欢迎大家参与，“可可粉”转发+评论即可参与赢取《SPSSAU科研数据分析方法与应用》这本书。该书系统介绍了科研数据分析方法，包括数据分析入门、常用研究方法应用、数据综合评价与预测、问卷数据分析、医学数据分析等五个方面，涵盖了13个知识类应用，同时还附赠了171集配套视频讲解。这本书适合研究者快速学习和掌握科研数据分析方法，近万篇研究论文选择SPSSAU作为快速入门工具。截止日期为2024年3月15日。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00，*可可粉*转发+评论即可参与。近万篇研究论文选用SPSSAU快速入门，本书从数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等五个方面系统地介绍科研数据的分析方法，涉及13项知识类应用（如影响关系、权重关系、数据预测、问卷研究）附赠171集配套视频讲解，适合研究者快速学习和掌握科研数据分析方法。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5009557898134749"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnj8n91y6bj20m80m8n19.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnj8n9h45kj20m80m8mzs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9rlbnj20m80m8tbk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9wj7pj20m80m80vr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:36:53 GMT</pubDate>
</item>
<item>
<title>今日推介(第1345期)：基于在线偏好优化的大型语言模型与人类偏好对齐、自注意力的下一token预测机制 、持续预训练大型语言模型的简单可扩展策略、现代大规模数据...</title>
<link>https://weibo.com/1402400261/O548I0b8m</link>
<guid>https://weibo.com/1402400261/O548I0b8m</guid>
<content:encoded><![CDATA[
<div> 在线偏好优化、大型语言模型、人类偏好对齐、自注意力、下一token预测机制、持续预训练、简单可扩展策略、现代大规模数据集、偏差问题、过训练语言模型

总结:<br />
本篇文章介绍了基于在线偏好优化的大型语言模型与人类偏好对齐的方法，通过自注意力的下一token预测机制实现了优化。同时提出了一种简单可扩展的持续预训练大型语言模型的策略，探讨了现代大规模数据集是否还存在偏差问题，并研究了过训练语言模型在下游任务中的可靠性扩展。这些研究对于优化大型语言模型的训练方法和应用具有重要意义。 <div>
今日推介(第1345期)：基于在线偏好优化的大型语言模型与人类偏好对齐、自注意力的下一token预测机制 、持续预训练大型语言模型的简单可扩展策略、现代大规模数据集是否还存在偏差问题、过训练语言模型在下游任务中的可靠扩展 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687109258"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.15)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra0zsf8qj20k00aawf0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra126v1dj20k008gjsd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnra15w1cdj20k00c3mzg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra1b1fw5j20k00hsad3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra1dmuy3j20k00e1q56.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:29:56 GMT</pubDate>
</item>
<item>
<title>[CV] DAM: Dynamic Adapter Merging for Continual Video QA Learning 网页链接 介绍了一种名为DAM的视频问答(VidQA)持续学习方法，以解决灾难性遗忘问题、适应...</title>
<link>https://weibo.com/1402400261/O544i5YCV</link>
<guid>https://weibo.com/1402400261/O544i5YCV</guid>
<content:encoded><![CDATA[
<div> 动态适配器合并, 持续学习, VidQA, 适配器训练, 路由器函数, 跨域知识共享, 性能优于当前方法, 图像分类, 图像问答

总结:<br /><br />
这篇文章介绍了一种名为DAM的视频问答持续学习方法，旨在解决灾难性遗忘、适应新数据集、处理未知数据集输入以及促进跨域知识共享等挑战。DAM通过动态适配器合并，在训练过程中训练特定数据集的适配器并冻结预训练的视频语言骨干网络。在推理过程中，利用非参数路由器函数计算适配器相关性概率，动态合并适配器权重定制新的适配器实例进行VidQA预测，从而降低路由器预测不准确的影响并提升跨域知识共享。DAM在多个VidQA数据集上的表现优于当前持续学习方法，并在图像分类和图像问答任务上也具有明显优势。 <div>
[CV] DAM: Dynamic Adapter Merging for Continual Video QA Learning  <br /><a href="https://arxiv.org/abs/2403.08755"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为DAM的视频问答(VidQA)持续学习方法，以解决灾难性遗忘问题、适应持续到来的数据集、处理未知数据集的输入以及跨相似数据集域共享知识等挑战。DAM通过动态适配器合并，训练特定数据集的适配器并冻结预训练的视频语言骨干网络。推理时，DAM使用非参数路由器函数计算每个适配器的相关性概率，随后动态合并适配器权重，以定制新的适配器实例进行VidQA预测，从而降低路由器预测不准确的影响并促进跨域知识共享。DAM在多个VidQA数据集上的性能超过了当前最先进的持续学习方法，并且在图像分类和图像问答任务上也展现出显著优势。<img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9q1w748j212s1lm4i4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9q2da9lj21pc0zitl9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9q2wsp9j21pa1b6nc5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:19:03 GMT</pubDate>
</item>
<item>
<title>[CV] GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting 网页链接 介绍了一种名为GaussianImage的新的图像表示和压缩方...</title>
<link>https://weibo.com/1402400261/O541SxwIU</link>
<guid>https://weibo.com/1402400261/O541SxwIU</guid>
<content:encoded><![CDATA[
<div> GaussianImage, 2D高斯Splatting, GPU资源, 隐式神经表示, INR, 渲染算法, GPU内存占用, 拟合时间, 渲染速度, 向量量化技术

总结:<br /><br />该文章介绍了一种名为GaussianImage的新的图像表示和压缩方法，基于2D高斯Splatting技术。与依赖GPU资源且训练时间长的隐式神经表示(INR)不同，GaussianImage通过每个2D高斯的8个参数来表示图像，使用累积求和的新渲染算法。这一方法显著减少了GPU内存占用和拟合时间，同时提供了与INR相当的表示性能和更快的渲染速度。该方法配合现有向量量化技术的编解码器在实验中表现出与基于压缩的INR（如COIN和COIN++）相当的速率失真性能，同时实现了约1000 FPS的解码速度。初步概念验证显示，在使用部分比特回传编码时，该编解码器的性能超过了COIN和COIN++。 <div>
[CV] GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting  <br /><a href="https://arxiv.org/abs/2403.08551"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为GaussianImage的新的图像表示和压缩方法，基于2D高斯Splatting技术。不同于依赖GPU资源且训练时间长的隐式神经表示(INR)，GaussianImage通过每个2D高斯的8个参数来表示图像，用累积求和的新渲染算法。这一方法显著减少了GPU内存占用(至少减少3倍)和拟合时间(加快5倍)，同时提供了与INR相当的表示性能和更快的渲染速度(1500-2000 FPS)。此外，集成了现有向量量化技术的图像编解码器在实验中展现出了与基于压缩的INR(如COIN和COIN++)相当的速率失真性能，并实现了约1000 FPS的解码速度。初步概念验证还表明，使用部分比特回传编码时，该编解码器的性能超过了COIN和COIN++。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9jwd3olj213i1kw18a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9jwqeu2j21hq0t0qay.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr9jwv8uyj21hc0gudmi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr9jx0572j21ha0mi7a8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:13:07 GMT</pubDate>
</item>
<item>
<title>[CL] Gemma: Open Models Based on Gemini Research and Technology 网页链接 介绍了Google DeepMind团队开发的Gemma模型，这是一组基于Gemini研究和技术构建的...</title>
<link>https://weibo.com/1402400261/O53Z1zK3Y</link>
<guid>https://weibo.com/1402400261/O53Z1zK3Y</guid>
<content:encoded><![CDATA[
<div> Google DeepMind, Gemma, Gemini, 轻量, 开放, 性能, 安全性, Transformer, TPUv5e, 负责任
<br />
<br />
总结: 
Google DeepMind团队开发了基于Gemini研究和技术的Gemma模型，是一组轻量、开放的最新模型。Gemma在语言理解、推理和安全性方面表现出强大性能，在18项文本任务中有11项超越同等规模的开放模型。该模型使用了基于Transformer的架构，优化了多查询注意力、RoPE嵌入、GeGLU激活函数和RMSNorm等技术，并使用TPUv5e硬件和分布式系统技术进行训练。发布了规模为20亿和70亿参数的两种模型，提供了预训练和微调检查点。强调了负责任发布大型语言模型对提升安全性、促进技术公平获取和驱动创新的重要性。对模型的安全性和负责任也进行了全面评估。 <div>
[CL] Gemma: Open Models Based on Gemini Research and Technology  <br /><a href="https://arxiv.org/abs/2403.08295"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了Google DeepMind团队开发的Gemma模型，这是一组基于Gemini研究和技术构建的轻量、开放的最新模型。Gemma在语言理解、推理和安全性方面在学术基准测试中展现出强大的性能。发布了两种规模的模型(20亿和70亿参数)，提供了预训练和微调的检查点。Gemma在18项文本任务中的11项上超越了同等规模的开放模型，并对模型的安全性和负责任进行了全面评估。Gemma利用了基于Transformer的架构，优化了多查询注意力、RoPE嵌入、GeGLU激活函数和RMSNorm等技术。训练使用了TPUv5e硬件和先进的分布式系统技术。强调了负责任发布大型语言模型(LLM)对于提升前沿模型安全性、促进技术公平获取、严格评估现有技术和驱动创新的重要性。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9ckrwzaj215e1ia7qg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9cl1imxj21ee0suwjs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9clc1n5j20p40n6adb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9clj4cfj20pc0ksgoa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:06:05 GMT</pubDate>
</item>
<item>
<title>创新地研究了在过训练情况下的语言模型扩展律，并建立了模型困惑度与其在下游任务表现之间的关联，提供了在减少计算成本的同时有效预测模型表现的方法，挑战了只...</title>
<link>https://weibo.com/1402400261/O53WGwMw8</link>
<guid>https://weibo.com/1402400261/O53WGwMw8</guid>
<content:encoded><![CDATA[
<div> 扩展律、语言模型、过训练、模型困惑度、下游任务、关联、计算成本、预测、模型表现、传统观点

<br /><br />总结：
该研究创新地研究了语言模型在过训练情况下的扩展律，并建立了模型困惑度与在下游任务表现之间的关联。提供了一种方法，在减少计算成本的同时有效预测模型表现，挑战了传统观点认为只有在计算最优训练阶段才能应用扩展律的观点。Researchers在此研究中展示了语言模型在过训练时表现稳定，并且其性能与下游任务的表现存在关联。他们的研究结果具有实践意义，可以帮助在研究领域中更有效地运用语言模型。 <div>
创新地研究了在过训练情况下的语言模型扩展律，并建立了模型困惑度与其在下游任务表现之间的关联，提供了在减少计算成本的同时有效预测模型表现的方法，挑战了只有在计算最优训练阶段才能应用扩展律的传统观点。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University &amp; UT Austin &amp; Apple] (2024) <a href="https://arxiv.org/abs/2403.08540"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96ao77pj21ga0qanai.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96b57p7j21my15caoy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96bitojj21n61167jj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96c1k8zj21mi0xo49l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyggij210z0ken19.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz8taj21120ir78f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gyotij21120lln0l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gz5nqj21170oktd1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz9y5j21110fkacs.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:00:19 GMT</pubDate>
</item>
<item>
<title>[CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University...</title>
<link>https://weibo.com/1402400261/O53WE06Ly</link>
<guid>https://weibo.com/1402400261/O53WE06Ly</guid>
<content:encoded><![CDATA[
<div> Language models, scale, over-training, downstream tasks, reliability, Columbia University, UT Austin, Apple

<br /><br />总结:
这篇文章研究了语言模型在超过训练规模以及在下游任务中的表现，发现语言模型在这些情况下能够可靠地扩展，通过在哥伦比亚大学、德克萨斯大学奥斯汀分校和苹果公司的合作进行了实验。他们的研究结果为语言模型的发展提供了有益的参考，为今后的研究和应用提供了新的思路。 <div>
[CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University &amp; UT Austin &amp; Apple] (2024) <a href="https://arxiv.org/abs/2403.08540"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96ao77pj21ga0qanai.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96b57p7j21my15caoy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96bitojj21n61167jj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96c1k8zj21mi0xo49l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyggij210z0ken19.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz8taj21120ir78f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gyotij21120lln0l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gz5nqj21170oktd1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz9y5j21110fkacs.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gypmlj210y0hg42h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96h0bszj210z0umjxf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gzuksj21120pbafd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gzkggj21110j1whm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gypocj21110j1who.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyc00j21120domzf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96h0emmj21131blqc1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:00:13 GMT</pubDate>
</item>
</channel>
</rss>