<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>爱可可-爱生活的微博</title>
<link>https://weibo.com/1402400261/</link>


<item>
<title>几篇论文实现代码：《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》(CVPR 2024) GitHub: github.c...</title>
<link>https://weibo.com/1402400261/O5jwVne0V</link>
<guid>https://weibo.com/1402400261/O5jwVne0V</guid>
<content:encoded><![CDATA[
<div> DNGaussian, 优化, 稀疏视图, 3D, 高斯辐射场, 全局局部深度规范化, GitHub, Pix2Gif, 运动引导扩散, GIF 生成, SSM, 视频扩散模型, 有效视频生成, 结构化状态空间, 语言模型, 可靠性, 过度训练, 下游任务

<br /><br />总结: 《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》提出了一种优化稀疏视图3D高斯辐射场的方法，通过全局局部深度规范化来改善渲染效果，代码可在GitHub上找到。《Pix2Gif: Motion-Guided Diffusion for GIF Generation》介绍了Pix2Gif，一种运动引导扩散技术，用于生成GIF图像。《SSM Meets Video Diffusion Models: Efficient Video Generation with Structured State Spaces》展示了SSM与视频扩散模型相结合，实现了有效的视频生成，采用了结构化状态空间。《Language models scale reliably with over-training and on downstream tasks》研究表明，语言模型在过度训练和下游任务中表现出可靠的扩展性，相关代码可在GitHub上获取。 <div>
几篇论文实现代码：<br />《DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization》(CVPR 2024) GitHub: github.com/Fictionarry/DNGaussian [fig1]<br />《Pix2Gif: Motion-Guided Diffusion for GIF Generation》(2024) GitHub: github.com/hiteshK03/Pix2Gif<br />《SSM Meets Video Diffusion Models: Efficient Video Generation with Structured State Spaces》(2024) GitHub: github.com/shim0114/SSM-Meets-Video-Diffusion-Models [fig2]<br />《Language models scale reliably with over-training and on downstream tasks》(2024) GitHub: github.com/mlfoundations/scaling<img src="https://tvax4.sinaimg.cn/large/5396ee05ly1hnt3oac1q5j21iu0jiasp.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnt3p0dq0hj22801904ns.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 13:40:48 GMT</pubDate>
</item>
<item>
<title>'Awesome-AISourceHub - AI科技领域高质量信息源列表’ GitHub: github.com/AmbroseX/Awesome-AISourceHub #开源# #机器学习# #人工智能# [图片]</title>
<link>https://weibo.com/1402400261/O5jwP9UrG</link>
<guid>https://weibo.com/1402400261/O5jwP9UrG</guid>
<content:encoded><![CDATA[
<div> GitHub, AI, 科技, 高质量, 信息源, 列表, 开源项目, AmbroseX, Awesome-AISourceHub

总结:<br /><br />这是一个收集AI科技领域高质量信息源的开源项目，其中包括了各种资源列表和信息源，可以帮助人们更好地了解和学习关于人工智能的知识。由AmbroseX创建并维护，项目地址为github.com/AmbroseX/Awesome-AISourceHub。欢迎大家积极参与和贡献，共同打造一个强大的AI资源集合。 <div>
'Awesome-AISourceHub - AI科技领域高质量信息源列表’ GitHub: github.com/AmbroseX/Awesome-AISourceHub <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnt5z3jp2mj20y40u00y9.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 13:40:33 GMT</pubDate>
</item>
<item>
<title>【EasyDetect：易于使用的多模态幻觉检测框架，用于多模态大型语言模型(MLLMs)如GPT-4V、Gemini、LlaVA的研究实验，通过统一的视角对多模态幻觉进行检测，包括模...</title>
<link>https://weibo.com/1402400261/O5j2octGD</link>
<guid>https://weibo.com/1402400261/O5j2octGD</guid>
<content:encoded><![CDATA[
<div> 多模态 幻觉检测框架 GPT-4V Gemini LlaVA 研究实验 统一视角 模态冲突 幻觉 事实冲突 幻觉

<br /><br />总结:
EasyDetect是一个易于使用的多模态幻觉检测框架，专为大型语言模型如GPT-4V、Gemini和LlaVA的研究实验而设计。该框架通过统一的视角对多模态幻觉进行检测，包括模态冲突幻觉和事实冲突幻觉。通过EasyDetect，研究人员可以更方便地进行多模态幻觉的实验和研究，从而深入探讨语言模型的表现和特性。 <div>
【EasyDetect：易于使用的多模态幻觉检测框架，用于多模态大型语言模型(MLLMs)如GPT-4V、Gemini、LlaVA的研究实验，通过统一的视角对多模态幻觉进行检测，包括模态冲突幻觉和事实冲突幻觉】’EasyDetect - An Easy-to-use Hallucination Detection Framework for LLMs.' GitHub: github.com/OpenKG-ORG/EasyDetect <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnt3t2xe1zj20i60fbdj0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnt3t5cqj1j20pp0gegqn.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 12:25:34 GMT</pubDate>
</item>
<item>
<title>【ChatOllama：基于Nuxt 3和Ollama的聊天Web应用】'ChatOllama - a Nuxt 3 + Ollama web application. It's an example of Ollama Javascript library’ GitHub:...</title>
<link>https://weibo.com/1402400261/O5j0hzQkC</link>
<guid>https://weibo.com/1402400261/O5j0hzQkC</guid>
<content:encoded><![CDATA[
<div> ChatOllama、Nuxt 3、Ollama、web应用、GitHub、Javascript库、聊天应用、示例、开发、实现<br />
<br />总结:
ChatOllama是基于Nuxt 3和Ollama的聊天Web应用示例，使用Ollama Javascript库开发，代码托管在GitHub上，展示了如何开发和实现一个聊天应用。 <div>
【ChatOllama：基于Nuxt 3和Ollama的聊天Web应用】'ChatOllama - a Nuxt 3 + Ollama web application. It's an example of Ollama Javascript library’ GitHub: github.com/sugarforever/chat-ollama <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnt3ns8meej219c0jogny.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 12:20:23 GMT</pubDate>
</item>
<item>
<title>【Data is Better Together：由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。目前，该项目已经创...</title>
<link>https://weibo.com/1402400261/O5ihKbqgZ</link>
<guid>https://weibo.com/1402400261/O5ihKbqgZ</guid>
<content:encoded><![CDATA[
<div> Hugging Face, Argilla, 开源机器学习社区, 数据集, 合作, 提示, 排名, 10,000个, 质量

<br /><br />总结:
Data is Better Together是一个由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。该项目已经创建了一个由10,000个提示组成的数据集，并按照质量进行了排名。这个项目的目标是让开源社区共同努力，创造更好的数据集，为机器学习研究和实践提供更丰富的资源和支持。通过协作和合作，我们可以共同构建更具影响力和实用性的数据集，推动机器学习领域的发展和创新。 <div>
【Data is Better Together：由Hugging Face、Argilla和开源机器学习社区共同合作的项目，旨在赋予开源社区共同构建有影响力的数据集的能力。目前，该项目已经创建了一个由10,000个提示组成的数据集，按质量进行了排名】'Data is Better Together - Let's build better datasets, together!' GitHub: github.com/huggingface/data-is-better-together <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnt0hi5cbfj211y0lc78w.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 10:30:39 GMT</pubDate>
</item>
<item>
<title>【OPEN TEACH: 多功能遥操作框架，使用Meta Quest3进行机器人操作，具有灵活性和多样性，包括VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，支持在各种...</title>
<link>https://weibo.com/1402400261/O5ih2p7R0</link>
<guid>https://weibo.com/1402400261/O5ih2p7R0</guid>
<content:encoded><![CDATA[
<div> 多功能遥操作框架, Meta Quest3, 机器人操作, 灵活性, 多样性, Unity脚本, 遥操作流程, 数据收集流程, 策略训练, GitHub  

<br /><br />总结:  
这篇文章介绍了一个名为"OPEN TEACH"的多功能遥操作框架，使用Meta Quest3进行机器人操作，并具有灵活性和多样性。该框架包括了VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，能够支持在各种机器人和仿真环境下进行遥操作和数据收集，并针对不同机器人和仿真进行策略训练。该框架的GitHub链接为github.com/aadhithya14/Open-Teach。 <div>
【OPEN TEACH: 多功能遥操作框架，使用Meta Quest3进行机器人操作，具有灵活性和多样性，包括VR应用程序的Unity脚本、遥操作流程和演示数据收集流程，支持在各种机器人和仿真环境下进行遥操作和数据收集，并针对不同机器人和仿真进行策略训练】'OPEN TEACH: A Versatile Teleoperation System for Robotic Manipulation - A Versatile Teleoperation framework for Robotic Manipulation using Meta Quest3' GitHub: github.com/aadhithya14/Open-Teach <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23"><span class="surl-text">#开源#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnt0fre8fpj21ji0twwkh.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Sat, 16 Mar 2024 10:28:54 GMT</pubDate>
</item>
<item>
<title>今日推介(第1346期)：让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、用Moment Pooling简化机器学习...</title>
<link>https://weibo.com/1402400261/O5dqgdQEc</link>
<guid>https://weibo.com/1402400261/O5dqgdQEc</guid>
<content:encoded><![CDATA[
<div> 语言模型、结构化训练、灾难性遗忘、预期性恢复、马尔可夫决策过程、学习算法、Moment Pooling、机器学习潜空间、API保护、LLM的Logits

<br /><br />总结:
本文介绍了几个关键的技术和方法，包括让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、以及用Moment Pooling简化机器学习潜空间。另外，还提到了API保护LLM的Logits会泄漏模型专有信息的问题。这些方法和技术对于改进语言模型的能力，提高机器学习算法的效率和精确度都具有重要意义。通过不断探索和应用这些新技术，我们可以进一步推动人工智能领域的发展，为未来带来更多可能性。 <div>
今日推介(第1346期)：让语言模型教自己先想再说、通过结构化训练从灾难性遗忘中预期性恢复、用于验证马尔可夫决策过程的学习算法、用Moment Pooling简化机器学习潜空间、API保护LLM的Logits会泄漏模型专有信息 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687311397"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.16)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnsf0htg36j20k00b9gn7.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnsf0k1lqgj20k006m751.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnsf0ml60tj20k007d0t5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnsf0p0i2ij20k00kq762.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnsf0repglj20k008pwfi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 22:07:54 GMT</pubDate>
</item>
<item>
<title>[RO] GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping 网页链接 提出一种名为GaussianGrasper的开放词表机器人抓取技术...</title>
<link>https://weibo.com/1402400261/O5dn86Ikc</link>
<guid>https://weibo.com/1402400261/O5dn86Ikc</guid>
<content:encoded><![CDATA[
<div> 高斯Splatting、机器人抓取技术、3D构建、视角输入、推理效率、特征蒸馏、对比学习、抓取姿态、语言指令、场景更新
<br /><br />总结:
提出了一种名为GaussianGrasper的开放词表机器人抓取技术，通过3D高斯Splatting构建场景，解决了传统隐式场景表达的问题。利用有限的RGB-D视角和高效特征蒸馏模块，结合对比学习来准确提取语言嵌入，使得预训练的抓取模型可以生成无碰撞的抓取姿态候选。通过法向引导的抓取模块选取最佳姿态。实验证明，该系统能准确响应语言指令，执行抓取任务，并实现快速场景更新。提供了新的解决方案用于语言引导操作任务，并公开了数据和代码资源。 <div>
[RO] GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping  <br /><a href="https://arxiv.org/abs/2403.09637"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出一种名为GaussianGrasper的开放词表机器人抓取技术，它通过3D高斯Splatting显式构建场景，解决了传统隐式场景表达(例如NeRF)需要大量视角输入和推理效率低下的问题。GaussianGrasper利用有限的RGB-D视角并通过一种高效特征蒸馏(EFD)模块，结合对比学习来准确提取语言嵌入。这使得其预训练的抓取模型能生成无碰撞的抓取姿态候选，并通过法向引导的抓取模块选取最佳姿态。实验表明，该系统能准确响应语言指令，执行抓取任务，并实现快速场景更新。此外，提供了用于语言引导操作任务的新解决方案，并公开了数据和代码资源。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsesr3i0dj219w1kc1kx.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsesrglfpj21hq17uqlw.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsesrlyxgj21h40uqqif.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 22:00:11 GMT</pubDate>
</item>
<item>
<title>[CV] Reconstruction and Simulation of Elastic Objects with Spring-Mass 3D Gaussians 网页链接 提出了Spring-Gaus框架，一个整合物理仿真和3D高斯模型的新方...</title>
<link>https://weibo.com/1402400261/O5difnNAc</link>
<guid>https://weibo.com/1402400261/O5difnNAc</guid>
<content:encoded><![CDATA[
<div> Spring-Gaus, 物理仿真, 3D高斯模型, 弹性物体, 多视角视频, 参数优化, 模拟粒子, 样本效率, 泛化能力, 形变预测

<br /><br />总结:
本文提出了Spring-Gaus框架，结合了物理仿真和3D高斯模型，用于重建和模拟弹性物体。通过3D弹簧-质点模型在个体点级别优化物理参数，解决了物理和外观学习的问题，提高了样本效率和泛化能力。Spring-Gaus在合成和真实数据集上证明了有效性，特别是在形变预测和不同环境参数下的模拟中表现出色。这一研究突破了物理参数优化和异质物体建模的限制，为预测视觉感知和沉浸式体验的应用提供了新的可能性。 <div>
[CV] Reconstruction and Simulation of Elastic Objects with Spring-Mass 3D Gaussians  <br /><a href="https://arxiv.org/abs/2403.09434"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />提出了Spring-Gaus框架，一个整合物理仿真和3D高斯模型的新方法，用于从多视角视频重建和模拟弹性物体。与传统的3D高斯方法相比，Spring-Gaus通过3D弹簧-质点模型在个体点级别优化物理参数，有效解缠物理和外观学习。这种方法提高了样本效率，增强了泛化能力，并减少了对仿真粒子分布的敏感性。在合成和真实世界数据集上的评估证明了Spring-Gaus在准确重建和模拟弹性物体方面的有效性，尤其是在进行未来形变预测和不同初始状态及环境参数下的模拟时。该研究突破了物理参数优化和异质物体建模的限制，为预测视觉感知和沉浸式体验的应用开辟了可能。<img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnseg8bri1j20z41e6wrp.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnseg8nm5cj21fa0wstjg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnseg9gk2gj21fa1au18j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:48:10 GMT</pubDate>
</item>
<item>
<title>[LG] Majority-of-Three: The Simplest Optimal Learner? 网页链接 讨论了PAC学习中的一个开放问题：在实现环境下，寻找最简单的最优学习算法。分析了一个简单的...</title>
<link>https://weibo.com/1402400261/O5deGfwNR</link>
<guid>https://weibo.com/1402400261/O5deGfwNR</guid>
<content:encoded><![CDATA[
<div> 多数投票法, 最优学习算法, PAC学习, 期望误差, 高概率误差, Bagging算法, ERM分类器, 最优误差界, one-inclusion graph算法, 简化算法结构

<br /><br />总结:
本文讨论了在实现环境下寻找最简单的最优学习算法的问题，并提出了多数投票法可能是一个简单且最优的解决方案。该算法使用三个ERM分类器，在期望误差上达到了最优，并且在高概率误差上也接近最优。该发现挑战了之前认为ERM分类器无法独自实现最优误差界的观点。文章还提出了改进的Bagging算法，简化了之前复杂的算法结构。另外，研究指出了one-inclusion graph算法在高概率误差上的局限性，与之前的猜想相反。通过进一步分析，多数投票法可能在高概率误差上也是最优的。整体而言，本文为最简单有效的学习算法提供了新的思路，并拓展了对学习算法的理解。 <div>
[LG] Majority-of-Three: The Simplest Optimal Learner?  <br /><a href="https://arxiv.org/abs/2403.08831"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />讨论了PAC学习中的一个开放问题：在实现环境下，寻找最简单的最优学习算法。分析了一个简单的算法——多数投票法，其中只使用三个ERM分类器。文章的核心是这个算法在期望误差上达到了最优，并且近似于高概率误差上的最优。这一发现挑战了之前的认知，即ERM分类器无法独自实现最优误差界。本文还提出一种改进的Bagging算法，简化了之前复杂的算法结构，但分析过程仍然复杂。此外，一项新的研究揭示了one-inclusion graph算法在高概率误差上的局限性，这与之前Warmuth的猜想相反。本文认为，通过进一步分析，上述多数投票法可能在高概率误差上也是最优的。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnse738777j21841gmh1p.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnse73lpebj21co0zoqa5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:39:22 GMT</pubDate>
</item>
<item>
<title>[CV] MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training 网页链接 介绍了多模态大型语言模型(MLLM)的构建，重点在于体系结构组件和数据选择...</title>
<link>https://weibo.com/1402400261/O5dbMeVyI</link>
<guid>https://weibo.com/1402400261/O5dbMeVyI</guid>
<content:encoded><![CDATA[
<div> 模态语言模型 构建 组件 数据 体系结构 图像编码器 视觉语言连接器 预训练数据<br />
<br />
总结: 本文介绍了多模态大型语言模型(MLLM)的构建方法和分析，强调了体系结构组件和数据选择的重要性。研究发现，混合使用图像-文字、交错图像-文字和纯文字数据对实现少样本最先进结果(SOTA)至关重要。此外，图像编码器、图像分辨率和图像标记数量对结果有显著影响。作者构建了一个最高达30B参数的模型族MM1，通过大规模预训练实现了竞争性性能，并展现了吸引人的特性，能够实现少样本的连锁思维提示。 <div>
[CV] MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training  <br /><a href="https://arxiv.org/abs/2403.09611"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了多模态大型语言模型(MLLM)的构建，重点在于体系结构组件和数据选择的重要性。通过对图像编码器、视觉语言连接器和不同预训练数据选项的详尽剖析，揭示了几个关键设计经验。研究表明，混合使用图像-文字、交错图像-文字和纯文字数据对于实现多项基准测试中的少样本最先进结果(SOTA)至关重要。此外，图像编码器、图像分辨率和图像标记数量对结果有显著影响，而视觉-语言连接器设计的影响相对较小。作者通过扩大模型规模，构建了一个最高达30B参数的模型族MM1，包括密集型模型和专家混合型变体，这些模型在预训练度量上表现出色，并在一系列多模态基准测试中经过监督微调后获得了竞争性性能。MM1的大规模预训练赋予了它如上下文预测、多图像推理等吸引人的特性，使其能够实现少样本的连锁思维提示。<img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdzmld2pj21201iuapu.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdzn0s90j21hk13aaq5.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdznf268j21hk0tytm5.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdznnj32j21hm0qiaiy.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:32:13 GMT</pubDate>
</item>
<item>
<title>揭示了通过分析LLM API的输出，即便是在API保护下，仍能通过较少的成本就能获取大量关于大型语言模型(如OpenAI gpt-3.5-turbo)的私有参数和结构信息，强调了这种...</title>
<link>https://weibo.com/1402400261/O5d99bA9M</link>
<guid>https://weibo.com/1402400261/O5d99bA9M</guid>
<content:encoded><![CDATA[
<div> API保护、LLM、私有参数、结构信息、模型透明度、问责性、信息泄露、特性、分析、有效性<br />
<br />
提到了一种通过分析LLM API输出获取私有参数和结构信息的方法，即使在API保护下也能实现。强调了这种方法的有效性，指出可以将其作为一种特性来提高模型的透明度和问责性。文章的研究结果揭示了重要的信息泄露问题，也提示了提高模型透明度的重要性。这种方法对于模型的安全性和隐私保护具有重要影响，值得深入研究和思考。<br /><br />总结: 提出了一种通过分析LLM API输出泄露私有信息的方法，并强调了其有效性以及作为提高模型透明度和问责性的特性。 <div>
揭示了通过分析LLM API的输出，即便是在API保护下，仍能通过较少的成本就能获取大量关于大型语言模型(如OpenAI gpt-3.5-turbo)的私有参数和结构信息，强调了这种获取信息方法的有效性，指出如何将此作为一种特性来提高模型的透明度和问责性。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) <a href="https://arxiv.org/abs/2403.09539"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdhz8pyhj21oc15s7p2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdhzlf91j21ks0w4wqg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdhzq3auj21ke0oigsg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdi02jdij21l80pe118.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdsgpg07j20ve0dy764.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdsgoh8fj20vg0dqq55.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdsgpg6xj20vd090aar.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:25:44 GMT</pubDate>
</item>
<item>
<title>[CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) 网页链接...</title>
<link>https://weibo.com/1402400261/O5d8YfyGJ</link>
<guid>https://weibo.com/1402400261/O5d8YfyGJ</guid>
<content:encoded><![CDATA[
<div> API-Protected LLMs, Logits, Leakage, Proprietary Information, Privacy, Data Security, Machine Learning, Information Disclosure

总结:<br /><br />本文研究了API保护的语言模型（LLMs）的Logits可能泄漏专有信息的问题。研究人员发现，即使在API保护的情况下，LLMs的输出Logits也可能包含公司的机密信息。这种信息泄漏可能导致数据隐私和安全方面的问题。因此，需要采取相应的措施来确保机器学习模型不会泄露敏感信息，保障数据安全。 <div>
[CL]《Logits of API-Protected LLMs Leak Proprietary Information》M Finlayson, S Swayamdipta, X Ren [University of Southern California] (2024) <a href="https://arxiv.org/abs/2403.09539"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdhz8pyhj21oc15s7p2.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdhzlf91j21ks0w4wqg.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdhzq3auj21ke0oigsg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdi02jdij21l80pe118.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdsgpg07j20ve0dy764.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdsgoh8fj20vg0dqq55.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdsgpg6xj20vd090aar.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:25:18 GMT</pubDate>
</item>
<item>
<title>提出一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来显著降低潜空间维数，同时保持或提升模型性能，并以更少的基函数构建相同的机器学习...</title>
<link>https://weibo.com/1402400261/O5d3xurjA</link>
<guid>https://weibo.com/1402400261/O5d3xurjA</guid>
<content:encoded><![CDATA[
<div> 关键词: Moment Pooling, 深度集网络, 多变量矩, 潜空间维数, 模型性能, 基函数, 机器学习观测值, 可视化, 解释.

总结:<br /><br />本文提出了一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来降低潜空间维数，以提升模型性能。这一方法能够在更少的基函数下构建相同的机器学习观测值，使得模型内部表示可以更简单地进行可视化和解释。 Moment Pooling 的应用可以显著简化潜在空间的维数，帮助提升模型的性能，并且使得模型更容易解释和理解。通过对多变量矩的运用，Moment Pooling 可以在保持甚至提升模型性能的同时，降低所需的基函数数量，从而简化模型构建和解释过程。这一方法有望为机器学习领域带来更高效和可解释的模型设计。 <div>
提出一种名为“Moment Pooling”的方法，通过扩展深度集网络并利用多变量矩来显著降低潜空间维数，同时保持或提升模型性能，并以更少的基函数构建相同的机器学习观测值，使得模型内部表示的可视化和解释变得更加简单。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) <a href="https://arxiv.org/abs/2403.08854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdd9vs67j21is0gyk1g.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsddafjn1j21mo0w2472.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddapji1j21901amtg7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddav53cj20vi10c79w.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c6wmj20jp0o3q5d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6f420j2140147afj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6bkxyj20jp0litak.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsde6g62dj2140156dpr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6drm7j2140156jva.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:11:56 GMT</pubDate>
</item>
<item>
<title>[LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) 网页链接 ...</title>
<link>https://weibo.com/1402400261/O5d3oBouU</link>
<guid>https://weibo.com/1402400261/O5d3oBouU</guid>
<content:encoded><![CDATA[
<div> Streamlining, Latent Spaces, Machine Learning, Moment Pooling, MIT, Gambhir, Osathapan, Thaler, 2024

<br /><br />总结:
本文探讨了在机器学习中利用矩阵池化来简化潜在空间的方法。研究人员提出了一种称为Moment Pooling的新技术，通过将不同阶数的矩阵进行池化，从而提高了模型在学习高阶统计特性方面的能力。这种技术不仅能够提高模型的效率，还能够减少模型对大规模数据集的需求。研究还表明，Moment Pooling技术在训练时间和模型性能之间取得了良好的平衡，为机器学习领域的实践带来了新的启示。MIT的研究人员Gambhir、Osathapan和Thaler的工作为机器学习领域的发展提供了有益的思路和方法。 <div>
[LG]《Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling》R Gambhir, A Osathapan, J Thaler [MIT] (2024) <a href="https://arxiv.org/abs/2403.08854"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsdd9vs67j21is0gyk1g.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsddafjn1j21mo0w2472.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddapji1j21901amtg7.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsddav53cj20vi10c79w.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c6wmj20jp0o3q5d.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6f420j2140147afj.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6bkxyj20jp0litak.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnsde6g62dj2140156dpr.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6drm7j2140156jva.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6ceorj20jp0l1dhh.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6d31vj21400ki77c.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsde6c36cj20jp0khgn1.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6d5zdj20z20jpgny.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsde6dr66j20zc0jqtb4.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:11:35 GMT</pubDate>
</item>
<item>
<title>创新性地提出了一个学习算法框架，用于在完全和部分知识情况下进行马尔可夫决策过程的验证，特别是在不需要MDP结构特性假设和时间界限的情况下，通过启发式方法...</title>
<link>https://weibo.com/1402400261/O5d2K9Lno</link>
<guid>https://weibo.com/1402400261/O5d2K9Lno</guid>
<content:encoded><![CDATA[
<div> 马尔可夫决策过程、学习算法、验证、完全知识、部分知识、MDP结构、时间界限、概率可达性、启发式方法、停止准则

<br /><br />总结:
该研究提出了一个学习算法框架，可用于验证马尔可夫决策过程，在完全和部分知识情况下，无需MDP结构特性假设和时间界限。通过启发式方法提供了概率可达性的精确和概率界，同时提出了适应性强的停止准则。这一创新性方法有望在解决复杂决策问题中发挥重要作用。 <div>
创新性地提出了一个学习算法框架，用于在完全和部分知识情况下进行马尔可夫决策过程的验证，特别是在不需要MDP结构特性假设和时间界限的情况下，通过启发式方法提供了概率可达性的精确和概率界，同时提出了适应性强的停止准则。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [LG]《Learning Algorithms for Verification of Markov Decision Processes》T Brázdil, K Chatterjee, M Chmelik, V Forejt, J Křetínský, M Kwiatkowska, T Meggendorfer, D Parker, M Ujma [Google LLC &amp; IST Austria &amp; Lancaster University Leipzig] (2024) <a href="https://arxiv.org/abs/2403.09184"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdb2ek9bj210m0mb12q.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnsdb2s9l9j21ce0pwtbu.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnsdb38x14j21n20lqq6c.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnsdb3sanvj21rg0ecwgs.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 21:09:58 GMT</pubDate>
</item>
<item>
<title>恭喜@sayfh_wu-wuy_su私人领域-_- 等3名用户获得【《SPSSAU科研数据分析方法与应用》】。微博官方唯一抽奖工具@微博抽奖平台 对本次抽奖进行监督，结果公正有效...</title>
<link>https://weibo.com/1402400261/O56k4DmCh</link>
<guid>https://weibo.com/1402400261/O56k4DmCh</guid>
<content:encoded><![CDATA[
<div> SPSSAU, 数据分析, 科研, 应用, 抽奖, 微博, 研究方法, 问卷数据, 医学数据, 视频讲解

<br /><br />总结:
微博举办了一次抽奖活动，三名幸运用户将获得《SPSSAU科研数据分析方法与应用》。这本书系统介绍了科研数据分析方法，适合研究者快速学习和掌握。活动截止时间是2024年3月15日12:00，感兴趣的用户需要转发和评论才能参与。活动结果将通过微博官方唯一抽奖工具监督，公正有效。该书涵盖了数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等方面，并配有171集视频讲解，帮助研究者更好地理解科研数据分析方法。 <div>
恭喜<a href="https://weibo.com/n/sayfh_wu-wuy_su%E7%A7%81%E4%BA%BA%E9%A2%86%E5%9F%9F-_-">@sayfh_wu-wuy_su私人领域-_-</a> 等3名用户获得【《SPSSAU科研数据分析方法与应用》】。微博官方唯一抽奖工具<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> 对本次抽奖进行监督，结果公正有效。公示链接：<a href="https://lottery.media.weibo.com/lottery/h5/result/new?id=20117566&amp;pageid=100140E51183068"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a><br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00，*可可粉*转发+评论即可参与。近万篇研究论文选用SPSSAU快速入门，本书从数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等五个方面系统地介绍科研数据的分析方法，涉及13项知识类应用（如影响关系、权重关系、数据预测、问卷研究）附赠171集配套视频讲解，适合研究者快速学习和掌握科研数据分析方法。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5009557898134749"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnj8n91y6bj20m80m8n19.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnj8n9h45kj20m80m8mzs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9rlbnj20m80m8tbk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9wj7pj20m80m80vr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 04:03:26 GMT</pubDate>
</item>
<item>
<title>【艺术成功之路：声誉与网络的量化分析】- 研究人员重建了50万名艺术家的展览历史，绘制出反映艺术在机构之间流动的共同展览网络。 - 在这个网络中的中心性捕捉...</title>
<link>https://weibo.com/1402400261/O54JlkeLD</link>
<guid>https://weibo.com/1402400261/O54JlkeLD</guid>
<content:encoded><![CDATA[
<div> 艺术家、声誉、网络、展览历史、职业轨迹、早期进入高声望机构、马尔可夫模型、原籍国、潜在政策、彩票系统

<br /><br />总结:研究人员通过重建艺术家展览历史，揭示了艺术界展览网络结构和声誉对艺术家职业成功的影响。进入声誉高的机构能提供终身影响，早期选择机构会影响职业轨迹。原籍国可影响艺术家初始声誉和职业发展，建议实施彩票系统以提高公平竞争。研究虽然量化了准入壁垒，但仍需关注艺术评估的主观性和非实物艺术形式。艺术家应在更广泛机构展出，挑战传统观点，同时要面对可能的阻力。不同原籍国在全球化艺术世界中仍对艺术家有影响，呼吁更多关注多维度的审视。 <div>
【艺术成功之路：声誉与网络的量化分析】<br />- 研究人员重建了50万名艺术家的展览历史，绘制出反映艺术在机构之间流动的共同展览网络。  <br />- 在这个网络中的中心性捕捉了机构的声望，允许分析单个艺术家在获取理想机构方面的职业轨迹。  <br />- 早期进入声望高、处于中心位置的机构，可以为艺术家提供终身进入高声望场所的机会，并降低退出率。  <br />- 从网络边缘开始职业生涯会导致高退出率，限制进入中心机构的机会。  <br />- 一个马尔可夫模型可以预测艺术家的职业轨迹，记录了艺术价值评估中强烈的路径依赖和历史依赖。  <br />- 艺术家最初声望(前五次展览)的分布因其原籍国而异，影响他们职业成功的机会。  <br />- 该研究量化了艺术界的分层和准入壁垒，提出了潜在的政策，如彩票系统，以营造公平的竞争环境。  <br /><br />思考：  <br />- 该研究提供了声誉和网络在主观领域(如艺术)中决定资源和回报获取的量化见解，在这些领域中很难客观衡量表现。  <br />- 早期进入声望高的机构会产生终身影响，这一发现挑战了精英制的概念，凸显了初始机会的重要性。  <br />- 该研究关注机构准入和经济价值，可能忽略了艺术丰富社会的其他维度，如文化和情感价值。  <br />- 艺术家原籍国影响其初始声望和职业轨迹，这一观察结果引发了对艺术界系统性偏见和不平等的质疑。  <br />- 建议在艺术界实施彩票系统或盲选程序以提高代表性不足艺术家的包容性，可能面临既得利益机构和艺术界的阻力。  <br />- 尽管该研究量化了准入壁垒，但并未直接解决艺术评估的主观性质以及评估过程中固有的潜在偏见。  <br />- 该研究依赖展览和拍卖数据，可能低估了非实物艺术形式，如行为艺术，因为这些艺术形式无法通过这些渠道捕捉。   <br />- 研究发现，在职业生涯早期在更广泛的机构展出可以提高突破的机会，这挑战了专注于特定领域或风格的传统观点。  <br />- 该研究建议在艺术界实施彩票系统或盲选程序，这些做法更常见于就业或音乐试演等领域。  <br />- 观察到艺术家的原籍国影响其初始声望和职业轨迹，这一点有悖常理，因为在全球化的艺术世界中，人们可能认为天赋与地理因素无关。<br />《Quantifying reputation and success in art | Science》 <a href="https://www.science.org/doi/10.1126/science.aau7224"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax2.sinaimg.cn/large/5396ee05ly8hnrcnblrptj20u00x113j.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 00:00:12 GMT</pubDate>
</item>
<item>
<title>【Cappy：用小型评分器提升大型语言模型性能】 - Google研究人员提出了一种名为Cappy的新方法，可以通过一个小型评分器(scorer)来提升和增强大型多任务语言模型...</title>
<link>https://weibo.com/1402400261/O54Dc9dTt</link>
<guid>https://weibo.com/1402400261/O54Dc9dTt</guid>
<content:encoded><![CDATA[
<div> Cappy, 小型评分器, 大型语言模型, 性能提升, 多任务, 输出质量, 灵活性, 高效性, 实际应用, 可扩展性

<br /><br />总结: 
Google研究人员提出了一种名为Cappy的新方法，通过引入一个小型评分器来提升和增强大型多任务语言模型的性能。Cappy利用评分器重新排序生成的候选输出，提高输出质量。评分器是一个轻量级神经网络模型，专门用于评估候选输出质量，并与大型语言模型结合。Cappy在多个基准测试中展现出优异性能，提高大型模型表现。该方法灵活性强，可与各种大型语言模型结合，适用于不同任务。尽管在基准测试中表现出色，实际应用场景中的效果和可扩展性还需进一步验证。Cappy的高效性和轻量设计或将受益于未来硬件发展，如专用AI加速器。然而，引入新的偏差和不确定性也需进一步研究和优化。Cappy为提高大型语言模型性能提供了新的范式。 <div>
【Cappy：用小型评分器提升大型语言模型性能】  <br />- Google研究人员提出了一种名为Cappy的新方法，可以通过一个小型评分器(scorer)来提升和增强大型多任务语言模型的性能。  <br />- Cappy利用一个小型评分器来重新排序大型语言模型生成的候选输出，从而提高输出质量。  <br />- 评分器是一个轻量级的神经网络模型，专门用于评估候选输出的质量，而不负责生成输出。  <br />- 在多个基准测试中，Cappy展现出优于大型语言模型的性能，同时也能够提升这些大型模型的表现。  <br />- Cappy的优势在于其高效性和灵活性，可以与各种大型语言模型相结合，并在不同任务上发挥作用。  <br />- 研究人员认为，Cappy为提高大型语言模型的性能和效率提供了一种新的范式。  <br /><br />思考：  <br />- Cappy的提出解决了大型语言模型在某些任务上表现不佳的问题，通过引入一个小型评分器来提升整体性能，这种思路值得关注。  <br />- 将生成和评估分离的方法使Cappy具有灵活性，可以与不同的大型模型相结合，提高了其适用范围。  <br />- 尽管Cappy在基准测试中表现出色，但其在实际应用场景中的效果和可扩展性仍有待进一步验证。  <br />- Cappy的高效性和轻量设计可能会受益于未来硬件的发展，如专用AI加速器等，从而进一步提升其性能。  <br />- 虽然Cappy旨在提高大型语言模型的性能，但其本身也可能引入新的偏差和不确定性，需要进一步研究和优化。<br />《Cappy: Outperforming and boosting large multi-task language models with a small scorer – Google Research Blog》 <a href="https://blog.research.google/2024/03/cappy-outperforming-and-boosting-large.html"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnrc7chdqkj21780go75q.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc7csa3qj21jj0r3q63.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnrc7dkpzrj21jj0c6jv0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc7ffs7jj21jj0sw42p.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05ly8hnrc7fyfiuj21hb0u0goi.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:45:03 GMT</pubDate>
</item>
<item>
<title>【聊天机器人变身生产力助手：Command-R用Tool Use功能重塑业务工作流】- Cohere推出了Command-R模型的Tool Use功能，使语言模型能够与用户定义的工具交互，实现...</title>
<link>https://weibo.com/1402400261/O54B6h2pa</link>
<guid>https://weibo.com/1402400261/O54B6h2pa</guid>
<content:encoded><![CDATA[
<div> Command-R, Tool Use, 应用示例, 生产力助手, 跨平台, 自动化工作流程, 部署灵活性, 实施过程, AI应用, 语言模型

<br /><br />总结: 
Command-R推出了Tool Use功能，使语言模型能够与外部工具交互，执行复杂任务，提升生产力。该功能连接不同应用程序和系统，实现跨平台的自动化工作流程。结合Tool Use，Command-R从聊天机器人发展为强大的生产力助手和研究工具，可能改变AI交互方式。平衡了性能、效率和部署灵活性，适用于构建AI应用，突破了单一云环境的限制。企业实施Tool Use的简化四步过程降低了门槛，加速了应用，但需评估具体需求和系统兼容性。 <div>
【聊天机器人变身生产力助手：Command-R用Tool Use功能重塑业务工作流】<br />- Cohere推出了Command-R模型的Tool Use功能，使语言模型能够与用户定义的工具交互，实现高度复杂任务的自动化。  <br />- Command-R在Tool Use模式下可以根据用户交互和对话历史创建API负载(包含特定参数的JSON)，用于指示其他应用程序或工具。  <br />- Tool Use的应用示例包括自动分类和路由支持凭证、更新客户关系管理软件(CRM)中的状态，以及从向量数据库中检索相关片段。  <br />- 应用的输出会反馈给Command-R，用于生成最终响应。响应中包含引用，便于用户从源数据或工具结果中追溯声明。  <br />- Tool Use使Command-R的应用从简单的聊天机器人发展为强大的代理和研究工具，提高了生产力。  <br />- Command-R在高效率、强大性能和跨主要云提供商的灵活部署之间取得了平衡，是构建依赖Tool Use的AI应用的有竞争力的解决方案。  <br />- 在企业中实施Tool Use对开发人员来说是一个简单的四步过程。  <br /><br />思考：  <br />- Tool Use功能突破了语言模型仅限于自然语言处理的边界，使其能够与外部工具交互，执行复杂的任务和工作流程，开辟了语言模型应用的新领域。  <br />- Command-R与Tool Use的结合，使聊天机器人从简单的对话工具转变为强大的生产力助手和研究辅助工具，这可能改变我们与AI交互和协作的方式。  <br />- Tool Use通过自然语言交互连接不同的应用程序和系统，实现了跨平台的自动化工作流程，这种方法简化了复杂任务的自动化过程，提高了效率。  <br />- Command-R在性能、效率和部署灵活性方面的平衡，使其成为构建基于Tool Use的AI应用的理想选择，这表明语言模型的应用不再局限于单一的云环境。  <br />- 简化的四步实施过程降低了企业采用Tool Use的门槛，有望加速其在实际业务场景中的应用，但企业仍需评估其具体需求和现有系统的兼容性。<br />《Introducing Tool Use With Command-R: Seamlessly Automate Business Workflows》 <a href="https://txt.cohere.com/tool-use-with-command-r/"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnrc23fa5bj20v40l83zo.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnrc23o7u5j20qo0f00ue.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:39:53 GMT</pubDate>
</item>
<item>
<title>//@爱可可-爱生活：今日开奖，欢迎参与～ - 转发 @爱可可-爱生活:&amp;ensp;携手@博文视点Broadview 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00...</title>
<link>https://weibo.com/1402400261/O54zSFqzU</link>
<guid>https://weibo.com/1402400261/O54zSFqzU</guid>
<content:encoded><![CDATA[
<div> SPSSAU、数据分析、研究方法、应用、科研、快速入门、知识类、视频讲解、研究者、学习

总结:<br /><br />今天开奖活动欢迎大家参与，“可可粉”转发+评论即可参与赢取《SPSSAU科研数据分析方法与应用》这本书。该书系统介绍了科研数据分析方法，包括数据分析入门、常用研究方法应用、数据综合评价与预测、问卷数据分析、医学数据分析等五个方面，涵盖了13个知识类应用，同时还附赠了171集配套视频讲解。这本书适合研究者快速学习和掌握科研数据分析方法，近万篇研究论文选择SPSSAU作为快速入门工具。截止日期为2024年3月15日。 <div>
//<a href="https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB">@爱可可-爱生活</a>：今日开奖，欢迎参与～<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: 携手<a href="https://weibo.com/n/%E5%8D%9A%E6%96%87%E8%A7%86%E7%82%B9Broadview">@博文视点Broadview</a> 送出3本《SPSSAU科研数据分析方法与应用》，截至2024.3.15 12:00，*可可粉*转发+评论即可参与。近万篇研究论文选用SPSSAU快速入门，本书从数据分析入门、常用研究方法应用、数据综合评价及预测、问卷数据分析和医学数据分析等五个方面系统地介绍科研数据的分析方法，涉及13项知识类应用（如影响关系、权重关系、数据预测、问卷研究）附赠171集配套视频讲解，适合研究者快速学习和掌握科研数据分析方法。<a href="https://weibo.com/n/%E5%BE%AE%E5%8D%9A%E6%8A%BD%E5%A5%96%E5%B9%B3%E5%8F%B0">@微博抽奖平台</a> <a href="https://lottery.media.weibo.com/lottery/h5/history/list?mid=5009557898134749"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">抽奖详情</span></a><img src="https://tvax1.sinaimg.cn/large/5396ee05ly1hnj8n91y6bj20m80m8n19.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05ly1hnj8n9h45kj20m80m8mzs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9rlbnj20m80m8tbk.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly1hnj8n9wj7pj20m80m80vr.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 23:36:53 GMT</pubDate>
</item>
<item>
<title>今日推介(第1345期)：基于在线偏好优化的大型语言模型与人类偏好对齐、自注意力的下一token预测机制 、持续预训练大型语言模型的简单可扩展策略、现代大规模数据...</title>
<link>https://weibo.com/1402400261/O548I0b8m</link>
<guid>https://weibo.com/1402400261/O548I0b8m</guid>
<content:encoded><![CDATA[
<div> 在线偏好优化、大型语言模型、人类偏好对齐、自注意力、下一token预测机制、持续预训练、简单可扩展策略、现代大规模数据集、偏差问题、过训练语言模型

总结:<br />
本篇文章介绍了基于在线偏好优化的大型语言模型与人类偏好对齐的方法，通过自注意力的下一token预测机制实现了优化。同时提出了一种简单可扩展的持续预训练大型语言模型的策略，探讨了现代大规模数据集是否还存在偏差问题，并研究了过训练语言模型在下游任务中的可靠性扩展。这些研究对于优化大型语言模型的训练方法和应用具有重要意义。 <div>
今日推介(第1345期)：基于在线偏好优化的大型语言模型与人类偏好对齐、自注意力的下一token预测机制 、持续预训练大型语言模型的简单可扩展策略、现代大规模数据集是否还存在偏差问题、过训练语言模型在下游任务中的可靠扩展 公·众·号：爱可可爱生活 <a href="https://zhuanlan.zhihu.com/p/687109258"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">爱可可 AI 前沿推介(3.15)</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra0zsf8qj20k00aawf0.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra126v1dj20k008gjsd.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05ly8hnra15w1cdj20k00c3mzg.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra1b1fw5j20k00hsad3.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05ly8hnra1dmuy3j20k00e1q56.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:29:56 GMT</pubDate>
</item>
<item>
<title>[CV] DAM: Dynamic Adapter Merging for Continual Video QA Learning 网页链接 介绍了一种名为DAM的视频问答(VidQA)持续学习方法，以解决灾难性遗忘问题、适应...</title>
<link>https://weibo.com/1402400261/O544i5YCV</link>
<guid>https://weibo.com/1402400261/O544i5YCV</guid>
<content:encoded><![CDATA[
<div> 动态适配器合并, 持续学习, VidQA, 适配器训练, 路由器函数, 跨域知识共享, 性能优于当前方法, 图像分类, 图像问答

总结:<br /><br />
这篇文章介绍了一种名为DAM的视频问答持续学习方法，旨在解决灾难性遗忘、适应新数据集、处理未知数据集输入以及促进跨域知识共享等挑战。DAM通过动态适配器合并，在训练过程中训练特定数据集的适配器并冻结预训练的视频语言骨干网络。在推理过程中，利用非参数路由器函数计算适配器相关性概率，动态合并适配器权重定制新的适配器实例进行VidQA预测，从而降低路由器预测不准确的影响并提升跨域知识共享。DAM在多个VidQA数据集上的表现优于当前持续学习方法，并在图像分类和图像问答任务上也具有明显优势。 <div>
[CV] DAM: Dynamic Adapter Merging for Continual Video QA Learning  <br /><a href="https://arxiv.org/abs/2403.08755"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为DAM的视频问答(VidQA)持续学习方法，以解决灾难性遗忘问题、适应持续到来的数据集、处理未知数据集的输入以及跨相似数据集域共享知识等挑战。DAM通过动态适配器合并，训练特定数据集的适配器并冻结预训练的视频语言骨干网络。推理时，DAM使用非参数路由器函数计算每个适配器的相关性概率，随后动态合并适配器权重，以定制新的适配器实例进行VidQA预测，从而降低路由器预测不准确的影响并促进跨域知识共享。DAM在多个VidQA数据集上的性能超过了当前最先进的持续学习方法，并且在图像分类和图像问答任务上也展现出显著优势。<img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9q1w748j212s1lm4i4.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9q2da9lj21pc0zitl9.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9q2wsp9j21pa1b6nc5.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:19:03 GMT</pubDate>
</item>
<item>
<title>[CV] GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting 网页链接 介绍了一种名为GaussianImage的新的图像表示和压缩方...</title>
<link>https://weibo.com/1402400261/O541SxwIU</link>
<guid>https://weibo.com/1402400261/O541SxwIU</guid>
<content:encoded><![CDATA[
<div> GaussianImage, 2D高斯Splatting, GPU资源, 隐式神经表示, INR, 渲染算法, GPU内存占用, 拟合时间, 渲染速度, 向量量化技术

总结:<br /><br />该文章介绍了一种名为GaussianImage的新的图像表示和压缩方法，基于2D高斯Splatting技术。与依赖GPU资源且训练时间长的隐式神经表示(INR)不同，GaussianImage通过每个2D高斯的8个参数来表示图像，使用累积求和的新渲染算法。这一方法显著减少了GPU内存占用和拟合时间，同时提供了与INR相当的表示性能和更快的渲染速度。该方法配合现有向量量化技术的编解码器在实验中表现出与基于压缩的INR（如COIN和COIN++）相当的速率失真性能，同时实现了约1000 FPS的解码速度。初步概念验证显示，在使用部分比特回传编码时，该编解码器的性能超过了COIN和COIN++。 <div>
[CV] GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting  <br /><a href="https://arxiv.org/abs/2403.08551"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了一种名为GaussianImage的新的图像表示和压缩方法，基于2D高斯Splatting技术。不同于依赖GPU资源且训练时间长的隐式神经表示(INR)，GaussianImage通过每个2D高斯的8个参数来表示图像，用累积求和的新渲染算法。这一方法显著减少了GPU内存占用(至少减少3倍)和拟合时间(加快5倍)，同时提供了与INR相当的表示性能和更快的渲染速度(1500-2000 FPS)。此外，集成了现有向量量化技术的图像编解码器在实验中展现出了与基于压缩的INR(如COIN和COIN++)相当的速率失真性能，并实现了约1000 FPS的解码速度。初步概念验证还表明，使用部分比特回传编码时，该编解码器的性能超过了COIN和COIN++。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9jwd3olj213i1kw18a.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9jwqeu2j21hq0t0qay.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr9jwv8uyj21hc0gudmi.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr9jx0572j21ha0mi7a8.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:13:07 GMT</pubDate>
</item>
<item>
<title>[CL] Gemma: Open Models Based on Gemini Research and Technology 网页链接 介绍了Google DeepMind团队开发的Gemma模型，这是一组基于Gemini研究和技术构建的...</title>
<link>https://weibo.com/1402400261/O53Z1zK3Y</link>
<guid>https://weibo.com/1402400261/O53Z1zK3Y</guid>
<content:encoded><![CDATA[
<div> Google DeepMind, Gemma, Gemini, 轻量, 开放, 性能, 安全性, Transformer, TPUv5e, 负责任
<br />
<br />
总结: 
Google DeepMind团队开发了基于Gemini研究和技术的Gemma模型，是一组轻量、开放的最新模型。Gemma在语言理解、推理和安全性方面表现出强大性能，在18项文本任务中有11项超越同等规模的开放模型。该模型使用了基于Transformer的架构，优化了多查询注意力、RoPE嵌入、GeGLU激活函数和RMSNorm等技术，并使用TPUv5e硬件和分布式系统技术进行训练。发布了规模为20亿和70亿参数的两种模型，提供了预训练和微调检查点。强调了负责任发布大型语言模型对提升安全性、促进技术公平获取和驱动创新的重要性。对模型的安全性和负责任也进行了全面评估。 <div>
[CL] Gemma: Open Models Based on Gemini Research and Technology  <br /><a href="https://arxiv.org/abs/2403.08295"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a>  <br />介绍了Google DeepMind团队开发的Gemma模型，这是一组基于Gemini研究和技术构建的轻量、开放的最新模型。Gemma在语言理解、推理和安全性方面在学术基准测试中展现出强大的性能。发布了两种规模的模型(20亿和70亿参数)，提供了预训练和微调的检查点。Gemma在18项文本任务中的11项上超越了同等规模的开放模型，并对模型的安全性和负责任进行了全面评估。Gemma利用了基于Transformer的架构，优化了多查询注意力、RoPE嵌入、GeGLU激活函数和RMSNorm等技术。训练使用了TPUv5e硬件和先进的分布式系统技术。强调了负责任发布大型语言模型(LLM)对于提升前沿模型安全性、促进技术公平获取、严格评估现有技术和驱动创新的重要性。<img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9ckrwzaj215e1ia7qg.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9cl1imxj21ee0suwjs.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr9clc1n5j20p40n6adb.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr9clj4cfj20pc0ksgoa.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:06:05 GMT</pubDate>
</item>
<item>
<title>创新地研究了在过训练情况下的语言模型扩展律，并建立了模型困惑度与其在下游任务表现之间的关联，提供了在减少计算成本的同时有效预测模型表现的方法，挑战了只...</title>
<link>https://weibo.com/1402400261/O53WGwMw8</link>
<guid>https://weibo.com/1402400261/O53WGwMw8</guid>
<content:encoded><![CDATA[
<div> 扩展律、语言模型、过训练、模型困惑度、下游任务、关联、计算成本、预测、模型表现、传统观点

<br /><br />总结：
该研究创新地研究了语言模型在过训练情况下的扩展律，并建立了模型困惑度与在下游任务表现之间的关联。提供了一种方法，在减少计算成本的同时有效预测模型表现，挑战了传统观点认为只有在计算最优训练阶段才能应用扩展律的观点。Researchers在此研究中展示了语言模型在过训练时表现稳定，并且其性能与下游任务的表现存在关联。他们的研究结果具有实践意义，可以帮助在研究领域中更有效地运用语言模型。 <div>
创新地研究了在过训练情况下的语言模型扩展律，并建立了模型困惑度与其在下游任务表现之间的关联，提供了在减少计算成本的同时有效预测模型表现的方法，挑战了只有在计算最优训练阶段才能应用扩展律的传统观点。<br /><blockquote> - 转发 <a href="https://weibo.com/1402400261" target="_blank">@爱可可-爱生活</a>: [CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University &amp; UT Austin &amp; Apple] (2024) <a href="https://arxiv.org/abs/2403.08540"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96ao77pj21ga0qanai.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96b57p7j21my15caoy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96bitojj21n61167jj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96c1k8zj21mi0xo49l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyggij210z0ken19.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz8taj21120ir78f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gyotij21120lln0l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gz5nqj21170oktd1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz9y5j21110fkacs.jpg" /><br /><br /></blockquote>
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:00:19 GMT</pubDate>
</item>
<item>
<title>[CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University...</title>
<link>https://weibo.com/1402400261/O53WE06Ly</link>
<guid>https://weibo.com/1402400261/O53WE06Ly</guid>
<content:encoded><![CDATA[
<div> Language models, scale, over-training, downstream tasks, reliability, Columbia University, UT Austin, Apple

<br /><br />总结:
这篇文章研究了语言模型在超过训练规模以及在下游任务中的表现，发现语言模型在这些情况下能够可靠地扩展，通过在哥伦比亚大学、德克萨斯大学奥斯汀分校和苹果公司的合作进行了实验。他们的研究结果为语言模型的发展提供了有益的参考，为今后的研究和应用提供了新的思路。 <div>
[CL]《Language models scale reliably with over-training and on downstream tasks》S Y Gadre, G Smyrnis, V Shankar, S Gururangan... [Columbia University &amp; UT Austin &amp; Apple] (2024) <a href="https://arxiv.org/abs/2403.08540"><span class="url-icon"><img src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" style="width: 1rem; height: 1rem;" /></span><span class="surl-text">网页链接</span></a> <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%23&amp;isnewpage=1"><span class="surl-text">#机器学习#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%23&amp;isnewpage=1"><span class="surl-text">#人工智能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%BA%E6%96%87%23&amp;isnewpage=1"><span class="surl-text">#论文#</span></a> <img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96ao77pj21ga0qanai.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96b57p7j21my15caoy.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96bitojj21n61167jj.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96c1k8zj21mi0xo49l.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyggij210z0ken19.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz8taj21120ir78f.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gyotij21120lln0l.jpg" /><br /><br /><img src="https://tvax2.sinaimg.cn/large/5396ee05gy1hnr96gz5nqj21170oktd1.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gz9y5j21110fkacs.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gypmlj210y0hg42h.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96h0bszj210z0umjxf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gzuksj21120pbafd.jpg" /><br /><br /><img src="https://tvax3.sinaimg.cn/large/5396ee05gy1hnr96gzkggj21110j1whm.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96gypocj21110j1who.jpg" /><br /><br /><img src="https://tvax4.sinaimg.cn/large/5396ee05gy1hnr96gyc00j21120domzf.jpg" /><br /><br /><img src="https://tvax1.sinaimg.cn/large/5396ee05gy1hnr96h0emmj21131blqc1.jpg" /><br /><br />
]]></content:encoded>
<pubDate>Thu, 14 Mar 2024 22:00:13 GMT</pubDate>
</item>
</channel>
</rss>